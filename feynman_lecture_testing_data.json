[
    {
        "input": "Application of Gaussâ€™ Law",
        "output": "There are two laws of electrostatics: that the flux of the electric field from a volume is proportional to the charge inside\u2014Gauss\u2019 law, and that the circulation of the electric field is zero\u2014E is a gradient. From these two laws, all the predictions of electrostatics follow. But to say these things mathematically is one thing; to use them easily, and with a certain amount of ingenuity, is another. In this chapter we will work through a number of calculations which can be made with Gauss\u2019 law directly. We will prove theorems and describe some effects, particularly in conductors, that can be understood very easily from Gauss\u2019 law. Gauss\u2019 law by itself cannot give the solution of any problem because the other law must be obeyed too. So when we use Gauss\u2019 law for the solution of particular problems, we will have to add something to it. We will have to presuppose, for instance, some idea of how the field looks\u2014based, for example, on arguments of symmetry. Or we may have to introduce specifically the idea that the field is the gradient of a potential. Consider first the following question: When can a point charge be in stable mechanical equilibrium in the electric field of other charges? As an example, imagine three negative charges at the corners of an equilateral triangle in a horizontal plane. Would a positive charge placed at the center of the triangle remain there? (It will be simpler if we ignore gravity for the moment, although including it would not change the results.) The force on the positive charge is zero, but is the equilibrium stable? Would the charge return to the equilibrium position if displaced slightly? The answer is no. There are no points of stable equilibrium in any electrostatic field\u2014except right on top of another charge. Using Gauss\u2019 law, it is easy to see why. First, for a charge to be in equilibrium at any particular point P0 , the field must be zero. Second, if the equilibrium is to be a stable one, we require that if we move the charge away from P0 in any direction, there should be a restoring force directed opposite to the displacement. The electric field at all nearby points must be pointing inward\u2014toward the point P0 . But that is in violation of Gauss\u2019 law if there is no charge at P0 , as we can easily see. Consider a tiny imaginary surface that encloses P0 , as in Fig. 5\u20131. If the electric field everywhere in the vicinity is pointed toward P0 , the surface integral of the normal component is certainly not zero. For the case shown in the figure, the flux through the surface must be a negative number. But Gauss\u2019 law says that the flux of electric field through any surface is proportional to the total charge inside. If there is no charge at P0 , the field we have imagined violates Gauss\u2019 law. It is impossible to balance a positive charge in empty space\u2014at a point where there is not some negative charge. A positive charge can be in equilibrium if it is in the middle of a distributed negative charge. Of course, the negative charge distribution would have to be held in place by other than electrical forces! Our result has been obtained for a point charge. Does the same conclusion hold for a complicated arrangement of charges held together in fixed relative positions\u2014with rods, for example? We consider the question for two equal charges fixed on a rod. Is it possible that this combination can be in equilibrium in some electrostatic field? The answer is again no. The total force on the rod cannot be restoring for displacements in every direction. Call F the total force on the rod in any position\u2014F is then a vector field. Following the argument used above, we conclude that at a position of stable equilibrium, the divergence of F must be a negative number. But the total force on the rod is the first charge times the field at its position, plus the second charge times the field at its position: F=q1E1+q2E2. The divergence of F is given by \u2207\u22c5F=q1(\u2207\u22c5E1)+q2(\u2207\u22c5E2). If each of the two charges q1 and q2 is in free space, both \u2207\u22c5E1 and \u2207\u22c5E2 are zero, and \u2207\u22c5F is zero\u2014not negative, as would be required for equilibrium. You can see that an extension of the argument shows that no rigid combination of any number of charges can have a position of stable equilibrium in an electrostatic field in free space. Now we have not shown that equilibrium is forbidden if there are pivots or other mechanical constraints. As an example, consider a hollow tube in which a charge can move back and forth freely, but not sideways. Now it is very easy to devise an electric field that points inward at both ends of the tube if it is allowed that the field may point laterally outward near the center of the tube. We simply place positive charges at each end of the tube, as in Fig. 5\u20132. There can now be an equilibrium point even though the divergence of E is zero. The charge, of course, would not be in stable equilibrium for sideways motion were it not for \u201cnonelectrical\u201d forces from the tube walls. There is no stable spot in the field of a system of fixed charges. What about a system of charged conductors? Can a system of charged conductors produce a field that will have a stable equilibrium point for a point charge? (We mean at a point other than on a conductor, of course.) You know that conductors have the property that charges can move freely around in them. Perhaps when the point charge is displaced slightly, the other charges on the conductors will move in a way that will give a restoring force to the point charge? The answer is still no\u2014although the proof we have just given doesn\u2019t show it. The proof for this case is more difficult, and we will only indicate how it goes. First, we note that when charges redistribute themselves on the conductors, they can only do so if their motion decreases their total potential energy. (Some energy is lost to heat as they move in the conductor.) Now we have already shown that if the charges producing a field are stationary, there is, near any zero point P0 in the field, some direction for which moving a point charge away from P0 will decrease the energy of the system (since the force is away from P0 ). Any readjustment of the charges on the conductors can only lower the potential energy still more, so (by the principle of virtual work) their motion will only increase the force in that particular direction away from P0 , and not reverse it. Our conclusions do not mean that it is not possible to balance a charge by electrical forces. It is possible if one is willing to control the locations or the sizes of the supporting charges with suitable devices. You know that a rod standing on its point in a gravitational field is unstable, but this does not prove that it cannot be balanced on the end of a finger. Similarly, a charge can be held in one spot by electric fields if they are variable. But not with a passive\u2014that is, a static\u2014system. If charges cannot be held stably in position, it is surely not proper to imagine matter to be made up of static point charges (electrons and protons) governed only by the laws of electrostatics. Such a static configuration is impossible; it would collapse! It was once suggested that the positive charge of an atom could be distributed uniformly in a sphere, and the negative charges, the electrons, could be at rest inside the positive charge, as shown in Fig. 5\u20133. This was the first atomic model, proposed by Thomson. But Rutherford concluded from the experiment of Geiger and Marsden that the positive charges were very much concentrated, in what he called the nucleus. Thomson\u2019s static model had to be abandoned. Rutherford and Bohr then suggested that the equilibrium might be dynamic, with the electrons revolving in orbits, as shown in Fig. 5\u20134. The electrons would be kept from falling in toward the nucleus by their orbital motion. We already know at least one difficulty with this picture. With such motion, the electrons would be accelerating (because of the circular motion) and would, therefore, be radiating energy. They would lose the kinetic energy required to stay in orbit, and would spiral in toward the nucleus. Again unstable! The stability of the atoms is now explained in terms of quantum mechanics. The electrostatic forces pull the electron as close to the nucleus as possible, but the electron is compelled to stay spread out in space over a distance given by the uncertainty principle. If it were confined in too small a space, it would have a great uncertainty in momentum. But that means that it would have a high expected energy\u2014which it would use to escape from the electrical attraction. The net result is an electrical equilibrium not too different from the idea of Thomson\u2014only it is the negative charge that is spread out (because the mass of the electron is so much smaller than the mass of the proton). Gauss\u2019 law can be used to solve a number of electrostatic field problems involving a special symmetry\u2014usually spherical, cylindrical, or planar symmetry. In the remainder of this chapter we will apply Gauss\u2019 law to a few such problems. The ease with which these problems can be solved may give the misleading impression that the method is very powerful, and that one should be able to go on to many other problems. It is unfortunately not so. One soon exhausts the list of problems that can be solved easily with Gauss\u2019 law. In later chapters we will develop more powerful methods for investigating electrostatic fields. As our first example, we consider a system with cylindrical symmetry. Suppose that we have a very long, uniformly charged rod. By this we mean that electric charges are distributed uniformly along an indefinitely long straight line, with the charge \u03bb per unit length. We wish to know the electric field. The problem can, of course, be solved by integrating the contribution to the field from every part of the line. We are going to do it without integrating, by using Gauss\u2019 law and some guesswork. First, we surmise that the electric field will be directed radially outward from the line. Any axial component from charges on one side would be accompanied by an equal axial component from charges on the other side. The result could only be a radial field. It also seems reasonable that the field should have the same magnitude at all points equidistant from the line. This is obvious. (It may not be easy to prove, but it is true if space is symmetric\u2014as we believe it is.) We can use Gauss\u2019 law in the following way. We consider an imaginary surface in the shape of a cylinder coaxial with the line, as shown in Fig. 5\u20135. According to Gauss\u2019 law, the total flux of E from this surface is equal to the charge inside divided by \u03f50 . Since the field is assumed to be normal to the surface, the normal component is the magnitude of the field. Let\u2019s call it E . Also, let the radius of the cylinder be r , and its length be taken as one unit, for convenience. The flux through the cylindrical surface is equal to E times the area of the surface, which is 2\u03c0r . The flux through the two end faces is zero because the electric field is tangential to them. The total charge inside our surface is just \u03bb , because the length of the line inside is one unit. Gauss\u2019 law then gives E\u22c52\u03c0r=\u03bb/\u03f50, E= \u03bb 2\u03c0\u03f50r . The electric field of a line charge depends inversely on the first power of the distance from the line. As another example, we will calculate the field from a uniform plane sheet of charge. Suppose that the sheet is infinite in extent and that the charge per unit area is \u03c3 . We are going to take another guess. Considerations of symmetry lead us to believe that the field direction is everywhere normal to the plane, and if we have no field from any other charges in the world, the fields must be the same (in magnitude) on each side. This time we choose for our Gaussian surface a rectangular box that cuts through the sheet, as shown in Fig. 5\u20136. The two faces parallel to the sheet will have equal areas, say A . The field is normal to these two faces, and parallel to the other four. The total flux is E times the area of the first face, plus E times the area of the opposite face\u2014with no contribution from the other four faces. The total charge enclosed in the box is \u03c3A . Equating the flux to the charge inside, we have EA+EA= \u03c3A \u03f50 , from which E= \u03c3 2\u03f50 , a simple but important result. You may remember that the same result was obtained in an earlier chapter by an integration over the entire surface. Gauss\u2019 law gives us the answer, in this instance, much more quickly (although it is not as generally applicable as the earlier method). We emphasize that this result applies only to the field due to the charges on the sheet. If there are other charges in the neighborhood, the total field near the sheet would be the sum of (5.3) and the field of the other charges. Gauss\u2019 law would then tell us only that E1+E2= \u03c3 \u03f50 , where E1 and E2 are the fields directed outward on each side of the sheet. The problem of two parallel sheets with equal and opposite charge densities, +\u03c3 and \u2212\u03c3 , is equally simple if we assume again that the outside world is quite symmetric. Either by superposing two solutions for a single sheet or by constructing a Gaussian box that includes both sheets, it is easily seen that the field is zero outside of the two sheets (Fig. 5\u20137a). By considering a box that includes only one surface or the other, as in (b) or (c) of the figure, it can be seen that the field between the sheets must be twice what it is for a single sheet. The result is E(between the sheets) = \u03c3/\u03f50, E(outside) = 0. We have already (in Chapter 4) used Gauss\u2019 law to find the field outside a uniformly charged spherical region. The same method can also give us the field at points inside the sphere. For example, the computation can be used to obtain a good approximation to the field inside an atomic nucleus. In spite of the fact that the protons in a nucleus repel each other, they are, because of the strong nuclear forces, spread nearly uniformly throughout the body of the nucleus. Suppose that we have a sphere of radius R filled uniformly with charge. Let \u03c1 be the charge per unit volume. Again using arguments of symmetry, we assume the field to be radial and equal in magnitude at all points at the same distance from the center. To find the field at the distance r from the center, we take a spherical Gaussian surface of radius r ( r<R ), as shown in Fig. 5\u20138. The flux out of this surface is 4\u03c0 r 2 E. The charge inside our Gaussian surface is the volume inside times \u03c1 , or 4 3 \u03c0 r 3 \u03c1. Using Gauss\u2019 law, it follows that the magnitude of the field is given by E= \u03c1r 3 \u03f5 0 (r<R). (5.7) You can see that this formula gives the proper result for r=R . The electric field is proportional to the radius and is directed radially outward. The arguments we have just given for a uniformly charged sphere can be applied also to a thin spherical shell of charge. Assuming that the field is everywhere radial and is spherically symmetric, one gets immediately from Gauss\u2019 law that the field outside the shell is like that of a point charge, while the field everywhere inside the shell is zero. (A Gaussian surface inside the shell will contain no charge.) If we look in a little more detail at how the field inside the shell gets to be zero, we can see more clearly why it is that Gauss\u2019 law is true only because the Coulomb force depends exactly on the square of the distance. Consider any point P inside a uniform spherical shell of charge. Imagine a small cone whose apex is at P and which extends to the surface of the sphere, where it cuts out a small surface area \u0394 a 1 , as in Fig. 5\u20139. An exactly symmetric cone diverging from the opposite side of P would cut out the surface area \u0394 a 2 . If the distances from P to these two elements of area are r 1 and r 2 , the areas are in the ratio \u0394 a 2 \u0394 a 1 = r 2 2 r 2 1 . 2 (You can show this by geometry for any point P inside the sphere.) If the surface of the sphere is uniformly charged, the charge \u0394q on each of the elements of area is proportional to the area, so \u0394 q 2 \u0394 q 1 = \u0394 a 2 \u0394 a 1 . \u0394 Coulomb\u2019s law then says that the magnitudes of the fields produced at P by these two surface elements are in the ratio E 2 E 1 = \u0394 q 2 / r 2 2 \u0394 q 1 / r 2 1 =1. 2 The fields cancel exactly. Since all parts of the surface can be paired off in the same way, the total field at P is zero. But you can see that it would not be so if the exponent of r in Coulomb\u2019s law were not exactly two. The validity of Gauss\u2019 law depends upon the inverse square law of Coulomb. If the force law were not exactly the inverse square, it would not be true that the field inside a uniformly charged sphere would be exactly zero. For instance, if the force varied more rapidly, like, say, the inverse cube of r , that portion of the surface which is nearer to an interior point would produce a field which is larger than that which is farther away, resulting in a radial inward field for a positive surface charge. These conclusions suggest an elegant way of finding out whether the inverse square law is precisely correct. We need only determine whether or not the field inside of a uniformly charged spherical shell is precisely zero. It is lucky that such a method exists. It is usually difficult to measure a physical quantity to high precision\u2014a one percent result may not be too difficult, but how would one go about measuring, say, Coulomb\u2019s law to an accuracy of one part in a billion? It is almost certainly not possible with the best available techniques to measure the force between two charged objects with such an accuracy. But by determining only that the electric fields inside a charged sphere are smaller than some value we can make a highly accurate measurement of the correctness of Gauss\u2019 law, and hence of the inverse square dependence of Coulomb\u2019s law. What one does, in effect, is compare the force law to an ideal inverse square. Such comparisons of things that are equal, or nearly so, are usually the bases of the most precise physical measurements. How shall we observe the field inside a charged sphere? One way is to try to charge an object by touching it to the inside of a spherical conductor. You know that if we touch a small metal ball to a charged object and then touch it to an electrometer the meter will become charged and the pointer will move from zero (Fig. 5\u201310a). The ball picks up charge because there are electric fields outside the charged sphere that cause charges to run onto (or off) the little ball. If you do the same experiment by touching the little ball to the inside of the charged sphere, you find that no charge is carried to the electrometer. With such an experiment you can easily show that the field inside is, at most, a few percent of the field outside, and that Gauss\u2019 law is at least approximately correct. It appears that Benjamin Franklin was the first to notice that the field inside a conducting shell is zero. The result seemed strange to him. When he reported his observation to Priestley, the latter suggested that it might be connected with an inverse square law, since it was known that a spherical shell of matter produced no gravitational field inside. But Coulomb didn\u2019t measure the inverse square dependence until 18 years later, and Gauss\u2019 law came even later still. Gauss\u2019 law has been checked carefully by putting an electrometer inside a large sphere and observing whether any deflections occur when the sphere is charged to a high voltage. A null result is always obtained. Knowing the geometry of the apparatus and the sensitivity of the meter, it is possible to compute the minimum field that would be observed. From this number it is possible to place an upper limit on the deviation of the exponent from two. If we write that the electrostatic force depends on r \u22122+\u03f5 , we can place an upper bound on \u03f5 . By this method Maxwell determined that \u03f5 was less than 1/10,000 . The experiment was repeated and improved upon in 1936 by Plimpton and Lawton. They found that Coulomb\u2019s exponent differs from two by less than one part in a billion. Now that brings up an interesting question: How accurate do we know this Coulomb law to be in various circumstances? The experiments we just described measure the dependence of the field on distance for distances of some tens of centimeters. But what about the distances inside an atom\u2014in the hydrogen atom, for instance, where we believe the electron is attracted to the nucleus by the same inverse square law? It is true that quantum mechanics must be used for the mechanical part of the behavior of the electron, but the force is the usual electrostatic one. In the formulation of the problem, the potential energy of an electron must be known as a function of distance from the nucleus, and Coulomb\u2019s law gives a potential which varies inversely with the first power of the distance. How accurately is the exponent known for such small distances? As a result of very careful measurements in 1947 by Lamb and Retherford on the relative positions of the energy levels of hydrogen, we know that the exponent is correct again to one part in a billion on the atomic scale\u2014that is, at distances of the order of one angstrom ( 10 \u22128 centimeter). The accuracy of the Lamb-Retherford measurement was possible again because of a physical \u201caccident.\u201d Two of the states of a hydrogen atom are expected to have almost identical energies only if the potential varies exactly as 1/r . A measurement was made of the very slight difference in energies by finding the frequency \u03c9 of the photons that are emitted or absorbed in the transition from one state to the other, using for the energy difference \u0394E=\u210f\u03c9 . Computations showed that \u0394E would have been noticeably different from what was observed if the exponent in the force law 1/ r 2 differed from 2 by as much as one part in a billion. Is the same exponent correct at still shorter distances? From measurements in nuclear physics it is found that there are electrostatic forces at typical nuclear distances\u2014at about 10 \u221213 centimeter\u2014and that they still vary approximately as the inverse square. We shall look at some of the evidence in a later chapter. Coulomb\u2019s law is, we know, still valid, at least to some extent, at distances of the order of 10 \u221213 centimeter. How about 10 \u221214 centimeter? This range can be investigated by bombarding protons with very energetic electrons and observing how they are scattered. Results to date seem to indicate that the law fails at these distances. The electrical force seems to be about 10 times too weak at distances less than 10 \u221214 centimeter. Now there are two possible explanations. One is that the Coulomb law does not work at such small distances; the other is that our objects, the electrons and protons, are not point charges. Perhaps either the electron or proton, or both, is some kind of a smear. Most physicists prefer to think that the charge of the proton is smeared. We know that protons interact strongly with mesons. This implies that a proton will, from time to time, exist as a neutron with a \u03c0 + meson around it. Such a configuration would act\u2014on the average\u2014like a little sphere of positive charge. We know that the field from a sphere of charge does not vary as 1/ r 2 all the way into the center. It is quite likely that the proton charge is smeared, but the theory of pions is still quite incomplete, so it may also be that Coulomb\u2019s law fails at very small distances. The question is still open. One more point: The inverse square law is valid at distances like one meter and also at 10 \u221210 m; but is the coefficient 1/4\u03c0 \u03f5 0 the same? The answer is yes; at least to an accuracy of 15 parts in a million. We go back now to an important matter that we slighted when we spoke of the experimental verification of Gauss\u2019 law. You may have wondered how the experiment of Maxwell or of Plimpton and Lawton could give such an accuracy unless the spherical conductor they used was a perfect sphere. An accuracy of one part in a billion is really something to achieve, and you might well ask whether they could make a sphere which was that precise. There are certain to be slight irregularities in any real sphere and if there are irregularities, will they not produce fields inside? We wish to show now that it is not necessary to have a perfect sphere. It is possible, in fact, to show that there is no field inside a closed conducting shell of any shape. In other words, the experiments depended on 1/ r 2 , but had nothing to do with the surface being a sphere (except that with a sphere it is easier to calculate what the fields would be if Coulomb had been wrong), so we take up that subject now. To show this, it is necessary to know some of the properties of electrical conductors. An electrical conductor is a solid that contains many \u201cfree\u201d electrons. The electrons can move around freely in the material, but cannot leave the surface. In a metal there are so many free electrons that any electric field will set large numbers of them into motion. Either the current of electrons so set up must be continually kept moving by external sources of energy, or the motion of the electrons will cease as they discharge the sources producing the initial field. In \u201celectrostatic\u201d situations, we do not consider continuous sources of current (they will be considered later when we study magnetostatics), so the electrons move only until they have arranged themselves to produce zero electric field everywhere inside the conductor. (This usually happens in a small fraction of a second.) If there were any field left, this field would urge still more electrons to move; the only electrostatic solution is that the field is everywhere zero inside. Now consider the interior of a charged conducting object. (By \u201cinterior\u201d we mean in the metal itself.) Since the metal is a conductor, the interior field must be zero, and so the gradient of the potential \u03d5 is zero. That means that \u03d5 does not vary from point to point. Every conductor is an equipotential region, and its surface is an equipotential surface. Since in a conducting material the electric field is everywhere zero, the divergence of E is zero, and by Gauss\u2019 law the charge density in the interior of the conductor must be zero. If there can be no charges in a conductor, how can it ever be charged? What do we mean when we say a conductor is \u201ccharged\u201d? Where are the charges? The answer is that they reside at the surface of the conductor, where there are strong forces to keep them from leaving\u2014they are not completely \u201cfree.\u201d When we study solid-state physics, we shall find that the excess charge of any conductor is on the average within one or two atomic layers of the surface. For our present purposes, it is accurate enough to say that if any charge is put on, or in, a conductor it all accumulates on the surface; there is no charge in the interior of a conductor. We note also that the electric field just outside the surface of a conductor must be normal to the surface. There can be no tangential component. If there were a tangential component, the electrons would move along the surface; there are no forces preventing that. Saying it another way: we know that the electric field lines must always go at right angles to an equipotential surface. We can also, using Gauss\u2019 law, relate the field strength just outside a conductor to the local density of the charge at the surface. For a Gaussian surface, we take a small cylindrical box half inside and half outside the surface, like the one shown in Fig. 5\u201311. There is a contribution to the total flux of E only from the side of the box outside the conductor. The field just outside the surface of a conductor is then Outside a conductor: E= \u03c3 \u03f5 0 , (5.8) where \u03c3 is the local surface charge density. Why does a sheet of charge on a conductor produce a different field than just a sheet of charge? In other words, why is (5.8) twice as large as (5.3)? The reason, of course, is that we have not said for the conductor that there are no \u201cother\u201d charges around. There must, in fact, be some to make E=0 in the conductor. The charges in the immediate neighborhood of a point P on the surface do, in fact, give a field E local = \u03c3 local /2 \u03f5 0 both inside and outside the surface. But all the rest of the charges on the conductor \u201cconspire\u201d to produce an additional field at the point P equal in magnitude to E local . The total field inside goes to zero and the field outside to 2 E local =\u03c3/ \u03f5 0 . We return now to the problem of the hollow container\u2014a conductor with a cavity. There is no field in the metal, but what about in the cavity? We shall show that if the cavity is empty then there are no fields in it, no matter what the shape of the conductor or the cavity\u2014say for the one in Fig. 5\u201312. Consider a Gaussian surface, like S in Fig. 5\u201312, that encloses the cavity but stays everywhere in the conducting material. Everywhere on S the field is zero, so there is no flux through S and the total charge inside S is zero. For a spherical shell, one could then argue from symmetry that there could be no charge inside. But, in general, we can only say that there are equal amounts of positive and negative charge on the inner surface of the conductor. There could be a positive surface charge on one part and a negative one somewhere else, as indicated in Fig. 5\u201312. Such a thing cannot be ruled out by Gauss\u2019 law. What really happens, of course, is that any equal and opposite charges on the inner surface would slide around to meet each other, cancelling out completely. We can show that they must cancel completely by using the law that the circulation of E is always zero (electrostatics). Suppose there were charges on some parts of the inner surface. We know that there would have to be an equal number of opposite charges somewhere else. Now any lines of E would have to start on the positive charges and end on the negative charges (since we are considering only the case that there are no free charges in the cavity). Now imagine a loop \u0393 that crosses the cavity along a line of force from some positive charge to some negative charge, and returns to its starting point via the conductor (as in Fig. 5\u201312). The integral along such a line of force from the positive to the negative charges would not be zero. The integral through the metal is zero, since E=0 . So we would have \u222eE\u22c5ds\u22600??? \u222e But the line integral of E around any closed loop in an electrostatic field is always zero. So there can be no fields inside the empty cavity, nor any charges on the inside surface. You should notice carefully one important qualification we have made. We have always said \u201cinside an empty\u201d cavity. If some charges are placed at some fixed locations in the cavity\u2014as on an insulator or on a small conductor insulated from the main one\u2014then there can be fields in the cavity. But then that is not an \u201cempty\u201d cavity. We have shown that if a cavity is completely enclosed by a conductor, no static distribution of charges outside can ever produce any fields inside. This explains the principle of \u201cshielding\u201d electrical equipment by placing it in a metal can. The same arguments can be used to show that no static distribution of charges inside a closed grounded conductor can produce any fields outside. Shielding works both ways! In electrostatics\u2014but not in varying fields\u2014the fields on the two sides of a closed grounded conducting shell are completely independent. Now you see why it was possible to check Coulomb\u2019s law to such a great precision. The shape of the hollow shell used doesn\u2019t matter. It doesn\u2019t need to be spherical; it could be square! If Gauss\u2019 law is exact, the field inside is always zero. Now you also understand why it is safe to sit inside the high-voltage terminal of a million-volt Van de Graaff generator, without worrying about getting a shock\u2014because of Gauss\u2019 law."
    },
    {
        "input": "Elasticity",
        "output": "The subject of elasticity deals with the behavior of those substances which have the property of recovering their size and shape when the forces producing deformations are removed. We find this elastic property to some extent in all solid bodies. If we had the time to deal with the subject at length, we would want to look into many things: the behavior of materials, the general laws of elasticity, the general theory of elasticity, the atomic machinery that determine the elastic properties, and finally the limitations of elastic laws when the forces become so great that plastic flow and fracture occur. It would take more time than we have to cover all these subjects in detail, so we will have to leave out some things. For example, we will not discuss plasticity or the limitations of the elastic laws. (We touched on these subjects briefly when we were talking about dislocations in metals.) Also, we will not be able to discuss the internal mechanisms of elasticity\u2014so our treatment will not have the completeness we have tried to achieve in the earlier chapters. Our aim is mainly to give you an acquaintance with some of the ways of dealing with such practical problems as the bending of beams. When you push on a piece of material, it \u201cgives\u201d\u2014the material is deformed. If the force is small enough, the relative displacements of the various points in the material are proportional to the force\u2014we say the behavior is elastic. We will discuss only the elastic behavior. First, we will write down the fundamental laws of elasticity, and then we will apply them to a number of different situations. Suppose we take a rectangular block of material of length l , width w , and height h , as shown in Fig. 38\u20131. If we pull on the ends with a force F , then the length increases by an amount \u0394l . We will suppose in all cases that the change in length is a small fraction of the original length. As a matter of fact, for materials like wood and steel, the material will break if the change in length is more than a few percent of the original length. For a large number of materials, experiments show that for sufficiently small extensions the force is proportional to the extension F\u221d\u0394l. This relation is known as Hooke\u2019s law. The lengthening \u0394l of the bar will also depend on its length. We can figure out how by the following argument. If we cement two identical blocks together, end to end, the same forces act on each block; each will stretch by \u0394l . Thus, the stretch of a block of length 2l would be twice as big as a block of the same cross section, but of length l . In order to get a number more characteristic of the material, and less of any particular shape, we choose to deal with the ratio \u0394l/l of the extension to the original length. This ratio is proportional to the force but independent of l : F\u221d \u0394l l . The force F will also depend on the area of the block. Suppose that we put two blocks side by side. Then for a given stretch \u0394l we would have the force F on each block, or twice as much on the combination of the two blocks. The force, for a given amount of stretch, must be proportional to the cross-sectional area A of the block. To obtain a law in which the coefficient of proportionality is independent of the dimensions of the body, we write Hooke\u2019s law for a rectangular block in the form F=YA \u0394l l . (38.3) The constant Y is a property only of the nature of the material; it is known as Young\u2019s modulus. (Usually you will see Young\u2019s modulus called E . But we\u2019ve used E for electric fields, energy, and emf\u2019s, so we prefer to use a different letter.) The force per unit area is called the stress, and the stretch per unit length\u2014the fractional stretch\u2014is called the strain. Equation (38.3) can therefore be rewritten in the following way: F A =Y\u00d7 \u0394l l , Stress=(Young\u2019s modulus)\u00d7(Strain). (38.4) There is another part to Hooke\u2019s law: When you stretch a block of material in one direction it contracts at right angles to the stretch. The contraction in width is proportional to the width w and also to \u0394l/l . The sideways contraction is in the same proportion for both width and height, and is usually written \u0394w w = \u0394h h =\u2212\u03c3 \u0394l l , (38.5) where the constant \u03c3 is another property of the material called Poisson\u2019s ratio. It is always positive in sign and is a number less than 1/2 . (It is \u201creasonable\u201d that \u03c3 should be generally positive, but it is not quite clear that it must be so.) The two constants Y and \u03c3 specify completely the elastic properties of a homogeneous isotropic (that is, noncrystalline) material. In crystalline materials the stretches and contractions can be different in different directions, so there can be many more elastic constants. We will restrict our discussion temporarily to homogeneous isotropic materials whose properties can be described by Y and \u03c3 . As usual there are different ways of describing things\u2014some people like to describe the elastic properties of materials by different constants. It always takes two, and they can be related to \u03c3 and Y . The last general law we need is the principle of superposition. Since the two laws (38.4) and (38.5) are linear in the forces and in the displacements, superposition will work. If you have one set of forces and get some displacements, and then you add a new set of forces and get some additional displacements, the resulting displacements will be the sum of the ones you would get with the two sets of forces acting independently. Now we have all the general principles\u2014the superposition principle and Eqs. (38.4) and (38.5)\u2014and that\u2019s all there is to elasticity. But that is like saying that once you have Newton\u2019s laws that\u2019s all there is to mechanics. Or, given Maxwell\u2019s equations, that\u2019s all there is to electricity. It is, of course, true that with these principles you have a great deal, because with your present mathematical ability you could go a long way. We will, however, work out a few special applications. As our first example let\u2019s find out what happens to a rectangular block under uniform hydrostatic pressure. Let\u2019s put a block under water in a pressure tank. Then there will be a force acting inward on every face of the block proportional to the area (see Fig. 38\u20132). Since the hydrostatic pressure is uniform, the stress (force per unit area) on each face of the block is the same. We will work out first the change in the length. The change in length of the block can be thought of as the sum of changes in length that would occur in the three independent problems which are sketched in Fig. 38\u20133. Problem 1. If we push on the ends of the block with a pressure p , the compressional strain is p/Y , and it is negative, \u0394 l 1 l =\u2212 p Y . \u0394 l Problem 2. If we push on the two sides of the block with pressure p , the compressional strain is again p/Y , but now we want the lengthwise strain. We can get that from the sideways strain multiplied by \u2212\u03c3 . The sideways strain is \u0394w w =\u2212 p Y ; \u0394 so \u0394 l 2 l =+\u03c3 p Y . \u0394 l Problem 3. If we push on the top of the block, the compressional strain is once more p/Y , and the corresponding strain in the sideways direction is again \u2212\u03c3p/Y . We get \u0394 l 3 l =+\u03c3 p Y . \u0394 l Combining the results of the three problems\u2014that is, taking \u0394l=\u0394 l 1 +\u0394 l 2 +\u0394 l 3 \u2014we get \u0394l l =\u2212 p Y (1\u22122\u03c3). (38.6) The problem is, of course, symmetrical in all three directions; it follows that \u0394w w = \u0394h h =\u2212 p Y (1\u22122\u03c3). (38.7) The change in the volume under hydrostatic pressure is also of some interest. Since V=lwh , we can write, for small displacements, \u0394V V = \u0394l l + \u0394w w + \u0394h h . \u0394 V \u0394 l \u0394 \u0394 h Using (38.6) and (38.7), we have \u0394V V =\u22123 p Y (1\u22122\u03c3). (38.8) People like to call \u0394V/V the volume strain and write p=\u2212K \u0394V V . \u0394 V The volume stress p is proportional to the volume strain\u2014Hooke\u2019s law once more. The coefficient K is called the bulk modulus; it is related to the other constants by K= Y 3(1\u22122\u03c3) . (38.9) Since K is of some practical interest, many handbooks give Y and K instead of Y and \u03c3 . If you want \u03c3 you can always get it from Eq. (38.9). We can also see from Eq. (38.9) that Poisson\u2019s ratio, \u03c3 , must be less than one-half. If it were not, the bulk modulus K would be negative, and the material would expand under increasing pressure. That would allow us to get mechanical energy out of any old block\u2014it would mean that the block was in unstable equilibrium. If it started to expand it would continue by itself with a release of energy. Now we want to consider what happens when you put a \u201cshear\u201d strain on something. By shear strain we mean the kind of distortion shown in Fig. 38\u20134. As a preliminary to this, let us look at the strains in a cube of material subjected to the forces shown in Fig. 38\u20135. Again we can break it up into two problems: the vertical pushes, and the horizontal pulls. Calling A the area of the cube face, we have for the change in horizontal length \u0394l l = 1 Y F A +\u03c3 1 Y F A = 1+\u03c3 Y F A . (38.10) The change in the vertical height is just the negative of this. Now suppose we have the same cube and subject it to the shearing forces shown in Fig. 38\u20136(a). Note that all the forces have to be equal if there are to be no net torques and the cube is to be in equilibrium. (Similar forces must also exist in Fig. 38\u20134, since the block is in equilibrium. They are provided through the \u201cglue\u201d that holds the block to the table.) The cube is then said to be in a state of pure shear. But note that if we cut the cube by a plane at 45 \u2218 \u2014say along the diagonal A in the figure\u2014the total force acting across the plane is normal to the plane and is equal to 2 \u2013 \u221a G . The area over which this force acts is 2 \u2013 \u221a A ; therefore, the tensile stress normal to this plane is simply G/A . Similarly, if we examine a plane at an angle of 45 \u2218 the other way\u2014the diagonal B in the figure\u2014we see that there is a compressional stress normal to this plane of \u2212G/A . From this, we see that the stress in a \u201cpure shear\u201d is equivalent to a combination of tension and compression stresses of equal strength and at right angles to each other, and at 45 \u2218 to the original faces of the cube. The internal stresses and strains are the same as we would find in the larger block of material with the forces shown in Fig. 38\u20136(b). But this is the problem we have already solved. The change in length of the diagonal is given by Eq. (38.10), \u0394D D = 1+\u03c3 Y G A . (38.11) (One diagonal is shortened; the other is elongated.) It is often convenient to express a shear strain in terms of the angle by which the cube is twisted\u2014the angle \u03b8 in Fig. 38\u20137. From the geometry of the figure you can see that the horizontal shift \u03b4 of the top edge is equal to 2 \u2013 \u221a \u0394D . So \u03b8= \u03b4 l = 2 \u2013 \u221a \u0394D l =2 \u0394D D . (38.12) The shear stress g is defined as the tangential force on one face divided by the area, g=G/A . Using Eq. (38.11) in (38.12), we get \u03b8=2 1+\u03c3 Y g. 1 Or, writing this in the form \u201cstress = constant times strain,\u201d g=\u03bc\u03b8. (38.13) The proportionality coefficient \u03bc is called the shear modulus (or, sometimes, the coefficient of rigidity). It is given in terms of Y and \u03c3 by \u03bc= Y 2(1+\u03c3) . (38.14) Incidentally, the shear modulus must be positive\u2014otherwise you could get work out of a self-shearing block. From Eq. (38.14), \u03c3 must be greater than \u22121 . We know, then, that \u03c3 must be between \u22121 and + 1 2 ; in practice, however, it is always greater than zero. As a last example of the type of situation where the stresses are uniform through the material, let\u2019s consider the problem of a block which is stretched, while it is at the same time constrained so that no lateral contraction can take place. (Technically, it\u2019s a little easier to compress it while keeping the sides from bulging out\u2014but it\u2019s the same problem.) What happens? Well, there must be sideways forces which keep it from changing its thickness\u2014forces we don\u2019t know off-hand but will have to calculate. It\u2019s the same kind of problem we have already done, only with a little different algebra. We imagine forces on all three sides, as shown in Fig. 38\u20138; we calculate the changes in dimensions, and we choose the transverse forces to make the width and height remain constant. Following the usual arguments, we get for the three strains: \u0394 l x l x \u0394 l y l y \u0394 l z l z = 1 Y F x A x \u2212 \u03c3 Y F y A y \u2212 \u03c3 Y F z A z = 1 Y [ F x A x \u2212\u03c3( F y A y + F z A z )], = 1 Y [ F y A y \u2212\u03c3( F x A x + F z A z )], = 1 Y [ F z A z \u2212\u03c3( F x A x + F y A y )]. (38.15) (38.16) (38.17) Now since \u0394 l y and \u0394 l z are supposed to be zero, Eqs. (38.16) and (38.17) give two equations relating F y and F z to F x . Solving them together, we get that F y A y = F z A z = \u03c3 1\u2212\u03c3 F x A x . (38.18) Substituting in (38.15), we have \u0394 l x l x = 1 Y (1\u2212 2 \u03c3 2 1\u2212\u03c3 ) F x A x = 1 Y ( 1\u2212\u03c3\u22122 \u03c3 2 1\u2212\u03c3 ) F x A x . (38.19) Often, you will see this turned around, and with the quadratic in \u03c3 factored out, it is then written F A = 1\u2212\u03c3 (1+\u03c3)(1\u22122\u03c3) Y \u0394l l . (38.20) When we constrain the sides, Young\u2019s modulus gets multiplied by a complicated function of \u03c3 . As you can most easily see from Eq. (38.19), the factor in front of Y is always greater than 1 . It is harder to stretch the block when the sides are held\u2014which also means that a block is stronger when the sides are held than when they are not. Let\u2019s now turn our attention to an example which is more complicated because different parts of the material are stressed by different amounts. We consider a twisted rod such as you would find in a drive shaft of some machinery, or in a quartz fiber suspension used in a delicate instrument. As you probably know from experiments with the torsion pendulum, the torque on a twisted rod is proportional to the angle\u2014the constant of proportionality obviously depending upon the length of the rod, on the radius of the rod, and on the properties of the material. The question is: In what way? We are now in a position to answer this question; it\u2019s just a matter of working out some geometry. Fig. 38\u20139(a) shows a cylindrical rod of length L , and radius a , with one end twisted by the angle \u03d5 with respect to the other. If we want to relate the strains to what we already know, we can think of the rod as being made up of many cylindrical shells and work out separately what happens to each shell. We start by looking at a thin, short cylinder of radius r (less than a ) and thickness \u0394r \u2014as drawn in Fig. 38\u20139(b). Now if we look at a piece of this cylinder that was originally a small square, we see that it has been distorted into a parallelogram. Each such element of the cylinder is in shear, and the shear angle \u03b8 is \u03b8= r\u03d5 L . \u03d5 The shear stress g in the material is, therefore [from Eq. (38.13)], g=\u03bc\u03b8=\u03bc r\u03d5 L . (38.21) The shear stress is the tangential force \u0394F on the end of the square divided by the area \u0394l\u0394r of the end [see Fig. 38\u20139(c)] g= \u0394F \u0394l\u0394r . \u0394 F The force \u0394F on the end of such a square contributes a torque \u0394\u03c4 around the axis of the rod equal to \u0394\u03c4=r\u0394F=rg\u0394l\u0394r. (38.22) The total torque \u03c4 is the sum of such torques around a complete circumference of the cylinder. So putting together enough pieces so that the \u0394l \u2019s add up to 2\u03c0r , we find that the total torque, for a hollow tube, is rg(2\u03c0r)\u0394r. (38.23) Or, using (38.21), \u03c4=2\u03c0\u03bc r 3 \u0394r\u03d5 L . (38.24) We get that the rotational stiffness, \u03c4/\u03d5 , of a hollow tube is proportional to the cube of the radius r and to the thickness \u0394r , and inversely proportional to the length L . We can now imagine a solid rod to be made up of a series of concentric tubes, each twisted by the same angle \u03d5 (although the internal stresses are different for each tube). The total torque is the sum of the torques required to rotate each shell; for the solid rod \u03c4=2\u03c0\u03bc \u03d5 L \u222b r 3 dr, \u222b where the integral goes from r=0 to r=a , the radius of the rod. Integrating, we have \u03c4=\u03bc \u03c0 a 4 2L \u03d5. (38.25) For a rod in torsion, the torque is proportional to the angle and is proportional to the fourth power of the diameter\u2014a rod twice as thick is sixteen times as stiff for torsion. Before leaving the subject of torsion, let us apply what we have just learned to an interesting problem: torsional waves. If you take a long rod and suddenly twist one end, a wave of twist works its way along the rod, as sketched in Fig. 38\u201310(a). That\u2019s a little more exciting than a steady twist\u2014let\u2019s see whether we can work out what happens. Let z be the distance to some point down the rod. For a static torsion the torque is the same everywhere along the rod, and is proportional to \u03d5/L , the total torsion angle over the total length. What matters to the material is the local torsional strain, which is, you will appreciate, \u2202\u03d5/\u2202z . When the torsion along the rod is not uniform, we should replace Eq. (38.25) by \u03c4(z)=\u03bc \u03c0 a 4 2 \u2202\u03d5 \u2202z . (38.26) Now let\u2019s look at what happens to an element of length \u0394z shown magnified in Fig. 38\u201310(b). There is a torque \u03c4(z) at end 1 of the little hunk of rod, and a different torque \u03c4(z+\u0394z) at end 2 . If \u0394z is small enough, we can use a Taylor expansion and write \u03c4(z+\u0394z)=\u03c4(z)+( \u2202\u03c4 \u2202z )\u0394z. (38.27) The net torque \u0394\u03c4 acting on the little piece of rod between z and z+\u0394z is clearly the difference between \u03c4(z) and \u03c4(z+\u0394z) , or \u0394\u03c4=(\u2202\u03c4/\u2202z)\u0394z . Differentiating Eq. (38.26), we get \u0394\u03c4=\u03bc \u03c0 a 4 2 \u2202 2 \u03d5 \u2202 z 2 \u0394z. (38.28) The effect of this net torque is to give an angular acceleration to the little slice of the rod. The mass of the slice is \u0394M=(\u03c0 a 2 \u0394z)\u03c1, 2 where \u03c1 is the density of the material. We worked out in Chapter 19, Vol. I, that the moment of inertia of a circular cylinder is m r 2 /2 ; calling the moment of inertia of our piece \u0394I , we have \u0394I= \u03c0 2 \u03c1 a 4 \u0394z. (38.29) Newton\u2019s law says the torque is equal to the moment of inertia times the angular acceleration, or \u0394\u03c4=\u0394I \u2202 2 \u03d5 \u2202 t 2 . (38.30) Pulling everything together, we get \u03bc \u03c0 a 4 2 \u2202 2 \u03d5 \u2202 z 2 \u0394z= \u03c0 2 \u03c1 a 4 \u0394z \u2202 2 \u03d5 \u2202 t 2 , 2 2 or \u2202 2 \u03d5 \u2202 z 2 \u2212 \u03c1 \u03bc \u2202 2 \u03d5 \u2202 t 2 =0. (38.31) You will recognize this as the one-dimensional wave equation. We have found that waves of torsion will propagate down the rod with the speed C shear = \u03bc \u03c1 \u2212 \u2212 \u221a . (38.32) The denser the rod\u2014for the same stiffness\u2014the slower the waves; and the stiffer the rod, the quicker the waves work their way down. The speed does not depend upon the diameter of the rod. Torsional waves are a special example of shear waves. In general, shear waves are those in which the strains do not change the volume of any part of the material. In torsional waves, we have a particular distribution of such shear stresses\u2014namely, distributed on a circle. But for any arrangement of shear stresses, waves will propagate with the same speed\u2014the one given in Eq. (38.32). For example, the seismologists find such shear waves travelling in the interior of the earth. We can have another kind of a wave in the elastic world inside a solid material. If you push something, you can start \u201clongitudinal\u201d waves\u2014also called \u201ccompressional\u201d waves. They are like the sound waves in air or in water\u2014the displacements are in the same direction as the wave propagation. (At the surfaces of an elastic body there can also be other types of waves\u2014called \u201cRayleigh waves\u201d or \u201cLove waves.\u201d In them, the strains are neither purely longitudinal nor purely transverse. We will not have time to study them.) While we\u2019re on the subject of waves, what is the velocity of the pure compressional waves in a large solid body like the earth? We say \u201clarge\u201d because the speed of sound in a thick body is different from what it is, for instance, along a thin rod. By a \u201cthick\u201d body we mean one in which the transverse dimensions are much larger than the wavelength of the sound. Then, when we push on the object, it cannot expand sideways\u2014it can only compress in one dimension. Fortunately, we have already worked out the special case of the compression of a constrained elastic material. We have also worked out in Chapter 47, Vol. I, the speed of sound waves in a gas. Following the same arguments you can see that the speed of sound in a solid is equal to Y \u2032 /\u03c1 \u2212 \u2212 \u2212 \u2212 \u221a , where Y \u2032 is the \u201clongitudinal modulus\u201d\u2014or pressure divided by the relative change in length\u2014for the constrained case. This is just the ratio of \u0394l/l to F/A we got in Eq. (38.20). So the speed of the longitudinal waves is given by C 2 long = Y \u2032 \u03c1 = 1\u2212\u03c3 (1+\u03c3)(1\u22122\u03c3) Y \u03c1 . (38.33) So long as \u03c3 is between zero and 1/2 , the shear modulus \u03bc is less than Young\u2019s modulus Y , and also Y \u2032 is greater than Y , so \u03bc<Y< Y \u2032 . \u2032 This means that longitudinal waves travel faster than shear waves. One of the most precise ways of measuring the elastic constants of a substance is by measuring the density of the material and the speeds of the two kinds of waves. From this information one can get both Y and \u03c3 . It is, incidentally, by measuring the difference in the arrival times of the two kinds of waves from an earthquake that a seismologist can estimate\u2014even from the signals at only one station\u2014the distance to the quake. We want now to look at another practical matter\u2014the bending of a rod or a beam. What are the forces when we bend a bar of some arbitrary cross section? We will work it out thinking of a bar with a circular cross section, but our answer will be good for any shape. To save time, however, we will cut some corners, so our theory we will work out is only approximate. Our results will be correct only when the radius of the bend is much larger than the thickness of the beam. Suppose you grab the two ends of a straight bar and bend it into some curve like the one shown in Fig. 38\u201311. What goes on inside the bar? Well, if it is curved, that means that the material on the inside of the curve is compressed and the material on the outside is stretched. There is some surface which goes along more or less parallel to the axis of the bar that is neither stretched nor compressed. This is called the neutral surface. You would expect this surface to be near the \u201cmiddle\u201d of the cross section. It can be shown (but we won\u2019t do it here) that, for small bending of simple beams, the neutral surface goes through the \u201ccenter of gravity\u201d of the cross section. This is true only for \u201cpure\u201d bending\u2014if you are not stretching or compressing the beam at the same time. For pure bending, then, a thin transverse slice of the bar is distorted as shown in Fig. 38\u201312(a). The material below the neutral surface has a compressional strain which is proportional to the distance from the neutral surface; and the material above is stretched, also in proportion to its distance from the neutral surface. So the longitudinal stretch \u0394l is proportional to the height y . The constant of proportionality is just l over the radius of curvature of the bar\u2014see Fig. 38\u201312: \u0394l l = y R . \u0394 l So the force per unit area\u2014the stress\u2014in a small strip at y is also proportional to the distance from the neutral surface \u0394F \u0394A =Y y R . (38.34) Now let\u2019s look at the forces that would produce such a strain. The forces acting on the little segment drawn in Fig. 38\u201312 are shown in the figure. If we think of any transverse cut, the forces acting across it are one way above the neutral surface and the other way below. They come in pairs to make a \u201cbending moment\u201d M \u2014by which we mean the torque about the neutral line. We can compute the total moment by integrating the force times the distance from the neutral surface for one of the faces of the segment of Fig. 38\u201312: M= \u222b cross sect ydF. (38.35) From Eq. (38.34), dF=Yy/RdA , so M= Y R \u222b y 2 dA. \u222b The integral of y 2 dA is what we can call the \u201cmoment of inertia\u201d of the geometric cross section about a horizontal axis through its \u201ccenter of mass\u201d;1 we will call it I : M I = YI R =\u222b y 2 dA. (38.36) (38.37) Equation (38.36), then, gives us the relation between the bending moment M and the curvature 1/R of the beam. The \u201cstiffness\u201d of the beam is proportional to Y and to the moment of inertia I . In other words, if you want the stiffest possible beam with a given amount of, say, aluminum, you want to put as much of it as possible as far as you can from the neutral surface, to make a large moment of inertia. You can\u2019t carry this to an extreme, however, because then the thing will not curve as we have supposed\u2014it will buckle or twist and become weaker again. But now you see why structural beams are made in the form of an I or an H\u2014as shown in Fig. 38\u201313. As an example of the use of our beam equation (38.36), let\u2019s work out the deflection of a cantilevered beam with a concentrated force W acting at the free end, as sketched in Fig. 38\u201314. (By \u201ccantilevered\u201d we simply mean that the beam is supported in such a way that both the position and the slope are fixed at one end\u2014it is stuck into a cement wall.) What is the shape of the beam? Let\u2019s call the deflection at the distance x from the fixed end z ; we want to know z(x) . We\u2019ll work it out only for small deflections. We will also assume that the beam is long in comparison with its cross section. Now, as you know from your mathematics courses, the curvature 1/R of any curve z(x) is given by 1 R = d 2 z/d x 2 [1+(dz/dx ) 2 ] 3/2 . (38.38) Since we are interested only in small slopes\u2014this is usually the case in engineering structures\u2014we neglect (dz/dx ) 2 in comparison with 1 , and take 1 R = d 2 z d x 2 . (38.39) We also need to know the bending moment M . It is a function of x because it is equal to the torque about the neutral axis of any cross section. Let\u2019s neglect the weight of the beam and take only the downward force W at the end of the beam. (You can put in the beam weight yourself if you want.) Then the bending moment at x is M(x)=W(L\u2212x), ( ) ( ) because that is the torque about the point at x , exerted by the weight W \u2014the torque which the beam must support at x . We get W(L\u2212x)= YI R =YI d 2 z d x 2 2 or d 2 z d x 2 = W YI (L\u2212x). (38.40) This one we can integrate without any tricks; we get z= W YI ( L x 2 2 \u2212 x 3 6 ), (38.41) using our assumptions that z(0)=0 and that dz/dx is also zero at x=0 . That is the shape of the beam. The displacement of the end is z(L)= W YI L 3 3 ; (38.42) the displacement of the end of a beam increases as the cube of the length. In deriving our approximate beam theory, we have assumed that the cross section of the beam did not change when the beam was bent. When the thickness of the beam is small compared to the radius of curvature, the cross section changes very little and our result is O.K. In general, however, this effect cannot be neglected, as you can easily demonstrate for yourselves by bending a soft-rubber eraser in your fingers. If the cross section was originally rectangular, you will find that when it is bent it bulges at the bottom (see Fig. 38\u201315). This happens because when we compress the bottom, the material expands sideways\u2014as described by Poisson\u2019s ratio. Rubber is easy to bend or stretch, but it is somewhat like a liquid in that it\u2019s hard to change the volume\u2014as shows up nicely when you bend the eraser. For an incompressible material, Poisson\u2019s ratio would be exactly 1/2 \u2014for rubber it is nearly that. We want now to use our beam theory to understand the theory of the \u201cbuckling\u201d of beams, or columns, or rods. Consider the situation sketched in Fig. 38\u201316 in which a rod that would normally be straight is held in its bent shape by two opposite forces that push on the ends of the rod. We would like to calculate the shape of the rod and the magnitude of the forces on the ends. Let the deflection of the rod from the straight line between the ends be y(x) , where x is the distance from one end. The bending moment M at the point P in the figure is equal to the force F multiplied by the moment arm, which is the perpendicular distance y , M(x)=Fy. (38.43) Using the beam equation (38.36), we have YI R =Fy. (38.44) For small deflections, we can take 1/R=\u2212 d 2 y/d x 2 (the minus sign because the curvature is downward). We get d 2 y d x 2 =\u2212 F YI y, (38.45) which is the differential equation of a sine wave. So for small deflections, the curve of such a bent beam is a sine curve. The \u201cwavelength\u201d \u03bb of the sine wave is twice the distance L between the ends. If the bending is small, this is just twice the unbent length of the rod. So the curve is y=Ksin\u03c0x/L. K sin / L Taking the second derivative, we get d 2 y d x 2 =\u2212 \u03c0 2 L 2 y. 2 Comparing this to Eq. (38.45), we see that the force is F= \u03c0 2 YI L 2 . (38.46) For small bendings the force is independent of the bending displacement y ! We have, then, the following thing physically. If the force is less than the F given in Eq. (38.46), there will be no bending at all. But if it is slightly greater than this force, the material will suddenly bend a large amount\u2014that is, for forces above the critical force \u03c0 2 YI/ L 2 (often called the \u201cEuler force\u201d) the beam will \u201cbuckle.\u201d If the loading on the second floor of a building exceeds the Euler force for the supporting columns, the building will collapse. Another place where the buckling force is most important is in space rockets. On one hand, the rocket must be able to hold its own weight on the launching pad and endure the stresses during acceleration; on the other hand, it is important to keep the weight of the structure to a minimum, so that the payload and fuel capacity may be made as large as possible. Actually a beam will not necessarily collapse completely when the force exceeds the Euler force. When the displacements get large, the force is larger than what we have found because of the terms in 1/R in Eq. (38.38) that we have neglected. To find the forces for a large bending of the beam, we have to go back to the exact equation, Eq. (38.44), which we had before we used the approximate relation between R and y . Equation (38.44) has a rather simple geometrical property.2 It\u2019s a little complicated to work out, but rather interesting. Instead of describing the curve in terms of x and y , we can use two new variables: S , the distance along the curve, and \u03b8 the slope of the tangent to the curve. See Fig. 38\u201317. The curvature is the rate of change of angle with distance: 1 R = d\u03b8 dS . d \u03b8 We can, therefore write the exact equation (38.44) as d\u03b8 dS =\u2212 F YI y. d \u03b8 F If we take the derivative of this equation with respect to S and replace dy/dS by sin\u03b8 , we get d 2 \u03b8 d S 2 =\u2212 F YI sin\u03b8. (38.47) [If \u03b8 is small, we get back Eq. (38.45). Everything is O.K.] Now it may or may not delight you to know that Eq. (38.47) is exactly the same one you get for the large amplitude oscillations of a pendulum\u2014with F/YI replaced by another constant, of course. We learned way back in Chapter 9, Vol. I, how to find the solution of such an equation by a numerical calculation.3 The answers you get are some fascinating curves\u2014known as the curves of the \u201cElastica.\u201d Figure 38\u201318 shows three curves for different values of F/YI ."
    },
    {
        "input": "Time and Distance",
        "output": "In this chapter we shall consider some aspects of the concepts of time and distance. It has been emphasized earlier that physics, as do all the sciences, depends on observation. One might also say that the development of the physical sciences to their present form has depended to a large extent on the emphasis which has been placed on the making of quantitative observations. Only with quantitative observations can one arrive at quantitative relationships, which are the heart of physics. Many people would like to place the beginnings of physics with the work done 350 years ago by Galileo, and to call him the first physicist. Until that time, the study of motion had been a philosophical one based on arguments that could be thought up in one\u2019s head. Most of the arguments had been presented by Aristotle and other Greek philosophers, and were taken as \u201cproven.\u201d Galileo was skeptical, and did an experiment on motion which was essentially this: He allowed a ball to roll down an inclined trough and observed the motion. He did not, however, just look; he measured how far the ball went in how long a time. The way to measure a distance was well known long before Galileo, but there were no accurate ways of measuring time, particularly short times. Although he later devised more satisfactory clocks (though not like the ones we know), Galileo\u2019s first experiments on motion were done by using his pulse to count off equal intervals of time. Let us do the same. We may count off beats of a pulse as the ball rolls down the track: \u201cone \u2026 two \u2026 three \u2026 four \u2026 five \u2026 six \u2026 seven \u2026 eight \u2026\u201d We ask a friend to make a small mark at the location of the ball at each count; we can then measure the distance the ball travelled from the point of release in one, or two, or three, etc., equal intervals of time. Galileo expressed the result of his observations in this way: if the location of the ball is marked at 1, 2, 3, 4, \u2026 units of time from the instant of its release, those marks are distant from the starting point in proportion to the numbers 1, 4, 9, 16, \u2026 Today we would say the distance is proportional to the square of the time: D\u221dt2. The study of motion, which is basic to all of physics, treats with the questions: where? and when? Let us consider first what we mean by time. What is time? It would be nice if we could find a good definition of time. Webster defines \u201ca time\u201d as \u201ca period,\u201d and the latter as \u201ca time,\u201d which doesn\u2019t seem to be very useful. Perhaps we should say: \u201cTime is what happens when nothing else happens.\u201d Which also doesn\u2019t get us very far. Maybe it is just as well if we face the fact that time is one of the things we probably cannot define (in the dictionary sense), and just say that it is what we already know it to be: it is how long we wait! What really matters anyway is not how we define time, but how we measure it. One way of measuring time is to utilize something which happens over and over again in a regular fashion\u2014something which is periodic. For example, a day. A day seems to happen over and over again. But when you begin to think about it, you might well ask: \u201cAre days periodic; are they regular? Are all days the same length?\u201d One certainly has the impression that days in summer are longer than days in winter. Of course, some of the days in winter seem to get awfully long if one is very bored. You have certainly heard someone say, \u201cMy, but this has been a long day!\u201d It does seem, however, that days are about the same length on the average. Is there any way we can test whether the days are the same length\u2014either from one day to the next, or at least on the average? One way is to make a comparison with some other periodic phenomenon. Let us see how such a comparison might be made with an hour glass. With an hour glass, we can \u201ccreate\u201d a periodic occurrence if we have someone standing by it day and night to turn it over whenever the last grain of sand runs out. We could then count the turnings of the glass from each morning to the next. We would find, this time, that the number of \u201chours\u201d (i.e., turnings of the glass) was not the same each \u201cday.\u201d We should distrust the sun, or the glass, or both. After some thought, it might occur to us to count the \u201chours\u201d from noon to noon. (Noon is here defined not as 12:00 o\u2019clock, but that instant when the sun is at its highest point.) We would find, this time, that the number of \u201chours\u201d each day is the same. We now have some confidence that both the \u201chour\u201d and the \u201cday\u201d have a regular periodicity, i.e., mark off successive equal intervals of time, although we have not proved that either one is \u201creally\u201d periodic. Someone might question whether there might not be some omnipotent being who would slow down the flow of sand every night and speed it up during the day. Our experiment does not, of course, give us an answer to this sort of question. All we can say is that we find that a regularity of one kind fits together with a regularity of another kind. We can just say that we base our definition of time on the repetition of some apparently periodic event. We should now notice that in the process of checking on the reproducibility of the day, we have received an important by-product. We have found a way of measuring, more accurately, fractions of a day. We have found a way of counting time in smaller pieces. Can we carry the process further, and learn to measure even smaller intervals of time? Galileo decided that a given pendulum always swings back and forth in equal intervals of time so long as the size of the swing is kept small. A test comparing the number of swings of a pendulum in one \u201chour\u201d shows that such is indeed the case. We can in this way mark fractions of an hour. If we use a mechanical device to count the swings\u2014and to keep them going\u2014we have the pendulum clock of our grandfathers. Let us agree that if our pendulum oscillates 3600 times in one hour (and if there are 24 such hours in a day), we shall call each period of the pendulum one \u201csecond.\u201d We have then divided our original unit of time into approximately 105 parts. We can apply the same principles to divide the second into smaller and smaller intervals. It is, you will realize, not practical to make mechanical pendulums which go arbitrarily fast, but we can now make electrical pendulums, called oscillators, which can provide a periodic occurrence with a very short period of swing. In these electronic oscillators it is an electrical current which swings to and fro, in a manner analogous to the swinging of the bob of the pendulum. We can make a series of such electronic oscillators, each with a period 10 times shorter than the previous one. We may \u201ccalibrate\u201d each oscillator against the next slower one by counting the number of swings it makes for one swing of the slower oscillator. When the period of oscillation of our clock is shorter than a fraction of a second, we cannot count the oscillations without the help of some device which extends our powers of observation. One such device is the electron-beam oscilloscope, which acts as a sort of microscope for short times. This device plots on a fluorescent screen a graph of electrical current (or voltage) versus time. By connecting the oscilloscope to two of our oscillators in sequence, so that it plots a graph first of the current in one of our oscillators and then of the current in the other, we get two graphs like those shown in Fig. 5\u20132. We can readily determine the number of periods of the faster oscillator in one period of the slower oscillator. With modern electronic techniques, oscillators have been built with periods as short as about 10\u221212 second, and they have been calibrated (by comparison methods such as we have described) in terms of our standard unit of time, the second. With the invention and perfection of the \u201claser,\u201d or light amplifier, in the past few years, it has become possible to make oscillators with even shorter periods than 10\u221212 second, but it has not yet been possible to calibrate them by the methods which have been described, although it will no doubt soon be possible. Times shorter than 10\u221212 second have been measured, but by a different technique. In effect, a different definition of \u201ctime\u201d has been used. One way has been to observe the distance between two happenings on a moving object. If, for example, the headlights of a moving automobile are turned on and then off, we can figure out how long the lights were on if we know where they were turned on and off and how fast the car was moving. The time is the distance over which the lights were on divided by the speed. Within the past few years, just such a technique was used to measure the lifetime of the \u03c00 -meson. By observing in a microscope the minute tracks left in a photographic emulsion in which \u03c00 -mesons had been created one saw that a \u03c00 -meson (known to be travelling at a certain speed nearly that of light) went a distance of about 10\u22127 meter, on the average, before disintegrating. It lived for only about 10\u221216 sec. It should be emphasized that we have here used a somewhat different definition of \u201ctime\u201d than before. So long as there are no inconsistencies in our understanding, however, we feel fairly confident that our definitions are sufficiently equivalent. By extending our techniques\u2014and if necessary our definitions\u2014still further we can infer the time duration of still faster physical events. We can speak of the period of a nuclear vibration. We can speak of the lifetime of the newly discovered strange resonances (particles) mentioned in Chapter 2. Their complete life occupies a time span of only 10\u221224 second, approximately the time it would take light (which moves at the fastest known speed) to cross the nucleus of hydrogen (the smallest known object). What about still smaller times? Does \u201ctime\u201d exist on a still smaller scale? Does it make any sense to speak of smaller times if we cannot measure\u2014or perhaps even think sensibly about\u2014something which happens in a shorter time? Perhaps not. These are some of the open questions which you will be asking and perhaps answering in the next twenty or thirty years. Let us now consider times longer than one day. Measurement of longer times is easy; we just count the days\u2014so long as there is someone around to do the counting. First we find that there is another natural periodicity: the year, about 365 days. We have also discovered that nature has sometimes provided a counter for the years, in the form of tree rings or river-bottom sediments. In some cases we can use these natural time markers to determine the time which has passed since some early event. When we cannot count the years for the measurement of long times, we must look for other ways to measure. One of the most successful is the use of radioactive material as a \u201cclock.\u201d In this case we do not have a periodic occurrence, as for the day or the pendulum, but a new kind of \u201cregularity.\u201d We find that the radioactivity of a particular sample of material decreases by the same fraction for successive equal increases in its age. If we plot a graph of the radioactivity observed as a function of time (say in days), we obtain a curve like that shown in Fig. 5\u20133. We observe that if the radioactivity decreases to one-half in T days (called the \u201chalf-life\u201d), then it decreases to one-quarter in another T days, and so on. In an arbitrary time interval t there are t/T \u201chalf-lives,\u201d and the fraction left after this time t is ( 1 2 )t/T . If we knew that a piece of material, say a piece of wood, had contained an amount A of radioactive material when it was formed, and we found out by a direct measurement that it now contains the amount B , we could compute the age of the object, t , by solving the equation ( 1 2 )t/T=B/A. There are, fortunately, cases in which we can know the amount of radioactivity that was in an object when it was formed. We know, for example, that the carbon dioxide in the air contains a certain small fraction of the radioactive carbon isotope C14 (replenished continuously by the action of cosmic rays). If we measure the total carbon content of an object, we know that a certain fraction of that amount was originally the radioactive C14 ; we know, therefore, the starting amount A to use in the formula above. Carbon-14 has a half-life of 5000 years. By careful measurements we can measure the amount left after 20 half-lives or so and can therefore \u201cdate\u201d organic objects which grew as long as 100,000 years ago. We would like to know, and we think we do know, the life of still older things. Much of our knowledge is based on the measurements of other radioactive isotopes which have different half-lives. If we make measurements with an isotope with a longer half-life, then we are able to measure longer times. Uranium, for example, has an isotope whose half-life is about 109 years, so that if some material was formed with uranium in it 109 years ago, only half the uranium would remain today. When the uranium disintegrates, it changes into lead. Consider a piece of rock which was formed a long time ago in some chemical process. Lead, being of a chemical nature different from uranium, would appear in one part of the rock and uranium would appear in another part of the rock. The uranium and lead would be separate. If we look at that piece of rock today, where there should only be uranium we will now find a certain fraction of uranium and a certain fraction of lead. By comparing these fractions, we can tell what percent of the uranium disappeared and changed into lead. By this method, the age of certain rocks has been determined to be several billion years. An extension of this method, not using particular rocks but looking at the uranium and lead in the oceans and using averages over the earth, has been used to determine (within the past few years) that the age of the earth itself is approximately 4.5 billion years. It is encouraging that the age of the earth is found to be the same as the age of the meteorites which land on the earth, as determined by the uranium method. It appears that the earth was formed out of rocks floating in space, and that the meteorites are, quite likely, some of that material left over. At some time more than five billion years ago, the universe started. It is now believed that at least our part of the universe had its beginning about ten or twelve billion years ago. We do not know what happened before then. In fact, we may well ask again: Does the question make any sense? Does an earlier time have any meaning? We have implied that it is convenient if we start with some standard unit of time, say a day or a second, and refer all other times to some multiple or fraction of this unit. What shall we take as our basic standard of time? Shall we take the human pulse? If we compare pulses, we find that they seem to vary a lot. On comparing two clocks, one finds they do not vary so much. You might then say, well, let us take a clock. But whose clock? There is a story of a Swiss boy who wanted all of the clocks in his town to ring noon at the same time. So he went around trying to convince everyone of the value of this. Everyone thought it was a marvelous idea so long as all of the other clocks rang noon when his did! It is rather difficult to decide whose clock we should take as a standard. Fortunately, we all share one clock\u2014the earth. For a long time the rotational period of the earth has been taken as the basic standard of time. As measurements have been made more and more precise, however, it has been found that the rotation of the earth is not exactly periodic, when measured in terms of the best clocks. These \u201cbest\u201d clocks are those which we have reason to believe are accurate because they agree with each other. We now believe that, for various reasons, some days are longer than others, some days are shorter, and on the average the period of the earth becomes a little longer as the centuries pass. Until very recently we had found nothing much better than the earth\u2019s period, so all clocks have been related to the length of the day, and the second has been defined as 1/86,400 of an average day. Recently we have been gaining experience with some natural oscillators which we now believe would provide a more constant time reference than the earth, and which are also based on a natural phenomenon available to everyone. These are the so-called \u201catomic clocks.\u201d Their basic internal period is that of an atomic vibration which is very insensitive to the temperature or any other external effects. These clocks keep time to an accuracy of one part in 109 or better. Within the past two years an improved atomic clock which operates on the vibration of the hydrogen atom has been designed and built by Professor Norman Ramsey at Harvard University. He believes that this clock might be 100 times more accurate still. Measurements now in progress will show whether this is true or not. We may expect that since it has been possible to build clocks much more accurate than astronomical time, there will soon be an agreement among scientists to define the unit of time in terms of one of the atomic clock standards. Let us now turn to the question of distance. How far, or how big, are things? Everybody knows that the way you measure distance is to start with a stick and count. Or start with a thumb and count. You begin with a unit and count. How does one measure smaller things? How does one subdivide distance? In the same way that we subdivided time: we take a smaller unit and count the number of such units it takes to make up the longer unit. So we can measure smaller and smaller lengths. But we do not always mean by distance what one gets by counting off with a meter stick. It would be difficult to measure the horizontal distance between two mountain tops using only a meter stick. We have found by experience that distance can be measured in another fashion: by triangulation. Although this means that we are really using a different definition of distance, when they can both be used they agree with each other. Space is more or less what Euclid thought it was, so the two types of definitions of distance agree. Since they do agree on the earth it gives us some confidence in using triangulation for still larger distances. For example, we were able to use triangulation to measure the height of the first Sputnik. We found that it was roughly 5\u00d7105 meters high. By more careful measurements the distance to the moon can be measured in the same way. Two telescopes at different places on the earth can give us the two angles we need. It has been found in this way that the moon is 4\u00d7108 meters away. We cannot do the same with the sun, or at least no one has been able to yet. The accuracy with which one can focus on a given point on the sun and with which one can measure angles is not good enough to permit us to measure the distance to the sun. Then how can we measure the distance to the sun? We must invent an extension of the idea of triangulation. We measure the relative distances of all the planets by astronomical observations of where the planets appear to be, and we get a picture of the solar system with the proper relative distances of everything, but with no absolute distance. One absolute measurement is then required, which has been obtained in a number of ways. One of the ways, which was believed until recently to be the most accurate, was to measure the distance from the earth to Eros, one of the small planetoids which passes near the earth every now and then. By triangulation on this little object, one could get the one required scale measurement. Knowing the relative distances of the rest, we can then tell the distance, for example, from the earth to the sun, or from the earth to Pluto. Within the past year there has been a big improvement in our knowledge of the scale of the solar system. At the Jet Propulsion Laboratory the distance from the earth to Venus was measured quite accurately by a direct radar observation. This, of course, is a still different type of inferred distance. We say we know the speed at which light travels (and therefore, at which radar waves travel), and we assume that it is the same speed everywhere between the earth and Venus. We send the radio wave out, and count the time until the reflected wave comes back. From the time we infer a distance, assuming we know the speed. We have really another definition of a measurement of distance. How do we measure the distance to a star, which is much farther away? Fortunately, we can go back to our triangulation method, because the earth moving around the sun gives us a large baseline for measurements of objects outside the solar system. If we focus a telescope on a star in summer and in winter, we might hope to determine these two angles accurately enough to be able to measure the distance to a star. What if the stars are too far away for us to use triangulation? Astronomers are always inventing new ways of measuring distance. They find, for example, that they can estimate the size and brightness of a star by its color. The color and brightness of many nearby stars\u2014whose distances are known by triangulation\u2014have been measured, and it is found that there is a smooth relationship between the color and the intrinsic brightness of stars (in most cases). If one now measures the color of a distant star, one may use the color-brightness relationship to determine the intrinsic brightness of the star. By measuring how bright the star appears to us at the earth (or perhaps we should say how dim it appears), we can compute how far away it is. (For a given intrinsic brightness, the apparent brightness decreases with the square of the distance.) A nice confirmation of the correctness of this method of measuring stellar distances is given by the results obtained for groups of stars known as globular clusters. A photograph of such a group is shown in Fig. 5\u20136. Just from looking at the photograph one is convinced that these stars are all together. The same result is obtained from distance measurements by the color-brightness method. A study of many globular clusters gives another important bit of information. It is found that there is a high concentration of such clusters in a certain part of the sky and that most of them are about the same distance from us. Coupling this information with other evidence, we conclude that this concentration of clusters marks the center of our galaxy. We then know the distance to the center of the galaxy\u2014about 10 20 meters. Knowing the size of our own galaxy, we have a key to the measurement of still larger distances\u2014the distances to other galaxies. Figure 5\u20137 is a photograph of a galaxy, which has much the same shape as our own. Probably it is the same size, too. (Other evidence supports the idea that galaxies are all about the same size.) If it is the same size as ours, we can tell its distance. We measure the angle it subtends in the sky; we know its diameter, and we compute its distance\u2014triangulation again! Photographs of exceedingly distant galaxies have recently been obtained with the giant Palomar telescope. One is shown in Fig. 5\u20138. It is now believed that some of these galaxies are about halfway to the limit of the universe\u2014 10 26 meters away\u2014the largest distance we can contemplate! Now let\u2019s think about smaller distances. Subdividing the meter is easy. Without much difficulty we can mark off one thousand equal spaces which add up to one meter. With somewhat more difficulty, but in a similar way (using a good microscope), we can mark off a thousand equal subdivisions of the millimeter to make a scale of microns (millionths of a meter). It is difficult to continue to smaller scales, because we cannot \u201csee\u201d objects smaller than the wavelength of visible light (about 5\u00d7 10 \u22127 meter). We need not stop, however, at what we can see. With an electron microscope, we can continue the process by making photographs on a still smaller scale, say down to 10 \u22128 meter (Fig. 5\u20139). By indirect measurements\u2014by a kind of triangulation on a microscopic scale\u2014we can continue to measure to smaller and smaller scales. First, from an observation of the way light of short wavelength (x-radiation) is reflected from a pattern of marks of known separation, we determine the wavelength of the light vibrations. Then, from the pattern of the scattering of the same light from a crystal, we can determine the relative location of the atoms in the crystal, obtaining results which agree with the atomic spacings also determined by chemical means. We find in this way that atoms have a diameter of about 10 \u221210 meter. There is a large \u201cgap\u201d in physical sizes between the typical atomic dimension of about 10 \u221210 meter and the nuclear dimensions 10 \u221215 meter, 10 \u22125 times smaller. For nuclear sizes, a different way of measuring size becomes convenient. We measure the apparent area, \u03c3 , called the effective cross section. If we wish the radius, we can obtain it from \u03c3=\u03c0 r 2 , since nuclei are nearly spherical. Measurement of a nuclear cross section can be made by passing a beam of high-energy particles through a thin slab of material and observing the number of particles which do not get through. These high-energy particles will plow right through the thin cloud of electrons and will be stopped or deflected only if they hit the concentrated weight of a nucleus. Suppose we have a piece of material 1 centimeter thick. There will be about 10 8 atomic layers. But the nuclei are so small that there is little chance that any nucleus will lie behind another. We might imagine that a highly magnified view of the situation\u2014looking along the particle beam\u2014would look like Fig. 5\u201310. The chance that a very small particle will hit a nucleus on the trip through is just the total area covered by the profiles of the nuclei divided by the total area in the picture. Suppose that we know that in an area A of our slab of material there are N atoms (each with one nucleus, of course). Then the fraction of the area \u201ccovered\u201d by the nuclei is N\u03c3/A . Now let the number of particles of our beam which arrive at the slab be n 1 and the number which come out the other side be n 2 . The fraction which do not get through is ( n 1 \u2212 n 2 )/ n 1 , which should just equal the fraction of the area covered. We can obtain the radius of the nucleus from the equation1 \u03c0 r 2 =\u03c3= A N n 1 \u2212 n 2 n 1 . From such an experiment we find that the radii of the nuclei are from about 1 to 6 times 10 \u221215 meter. The length unit 10 \u221215 meter is called the fermi, in honor of Enrico Fermi (1901\u20131954). What do we find if we go to smaller distances? Can we measure smaller distances? Such questions are not yet answerable. It has been suggested that the still unsolved mystery of nuclear forces may be unravelled only by some modification of our idea of space, or measurement, at such small distances. It might be thought that it would be a good idea to use some natural length as our unit of length\u2014say the radius of the earth or some fraction of it. The meter was originally intended to be such a unit and was defined to be (\u03c0/2)\u00d7 10 \u22127 times the earth\u2019s radius. It is neither convenient nor very accurate to determine the unit of length in this way. For a long time it has been agreed internationally that the meter would be defined as the distance between two scratches on a bar kept in a special laboratory in France. More recently, it has been realized that this definition is neither as precise as would be useful, nor as permanent or universal as one would like. It is currently being considered that a new definition be adopted, an agreed-upon (arbitrary) number of wavelengths of a chosen spectral line. Measurements of distance and of time give results which depend on the observer. Two observers moving with respect to each other will not measure the same distances and times when measuring what appear to be the same things. Distances and time intervals have different magnitudes, depending on the coordinate system (or \u201cframe of reference\u201d) used for making the measurements. We shall study this subject in more detail in a later chapter. Perfectly precise measurements of distances or times are not permitted by the laws of nature. We have mentioned earlier that the errors in a measurement of the position of an object must be at least as large as \u0394x\u2265\u210f/2\u0394p, \u0394 \u210f / \u0394 where \u210f is a small fundamental physical constant called the reduced Planck constant and \u0394p is the error in our knowledge of the momentum (mass times velocity) of the object whose position we are measuring. It was also mentioned that the uncertainty in position measurements is related to the wave nature of particles. The relativity of space and time implies that time measurements have also a minimum error, given in fact by \u0394t\u2265\u210f/2\u0394E, \u0394 \u210f / \u0394 E where \u0394E is the error in our knowledge of the energy of the process whose time period we are measuring. If we wish to know more precisely when something happened we must know less about what happened, because our knowledge of the energy involved will be less. The time uncertainty is also related to the wave nature of matter."
    },
    {
        "input": "Ratchet and Pawl",
        "output": "In this chapter we discuss the ratchet and pawl, a very simple device which allows a shaft to turn only one way. The possibility of having something turn only one way requires some detailed and careful analysis, and there are some very interesting consequences. The plan of the discussion came about in attempting to devise an elementary explanation, from the molecular or kinetic point of view, for the fact that there is a maximum amount of work which can be extracted from a heat engine. Of course we have seen the essence of Carnot\u2019s argument, but it would be nice to find an explanation which is elementary in the sense that we can see what is happening physically. Now, there are complicated mathematical demonstrations which follow from Newton\u2019s laws to demonstrate that we can get only a certain amount of work out when heat flows from one place to another, but there is great difficulty in converting this into an elementary demonstration. In short, we do not understand it, although we can follow the mathematics. In Carnot\u2019s argument, the fact that more than a certain amount of work cannot be extracted in going from one temperature to another is deduced from another axiom, which is that if everything is at the same temperature, heat cannot be converted to work by means of a cyclic process. First, let us back up and try to see, in at least one elementary example, why this simpler statement is true. Let us try to invent a device which will violate the Second Law of Thermodynamics, that is, a gadget which will generate work from a heat reservoir with everything at the same temperature. Let us say we have a box of gas at a certain temperature, and inside there is an axle with vanes in it. (See Fig. 46\u20131 but take T 1 = T 2 = T , say.) Because of the bombardments of gas molecules on the vane, the vane oscillates and jiggles. All we have to do is to hook onto the other end of the axle a wheel which can turn only one way\u2014the ratchet and pawl. Then when the shaft tries to jiggle one way, it will not turn, and when it jiggles the other, it will turn. Then the wheel will slowly turn, and perhaps we might even tie a flea onto a string hanging from a drum on the shaft, and lift the flea! Now let us ask if this is possible. According to Carnot\u2019s hypothesis, it is impossible. But if we just look at it, we see, prima facie, that it seems quite possible. So we must look more closely. Indeed, if we look at the ratchet and pawl, we see a number of complications. First, our idealized ratchet is as simple as possible, but even so, there is a pawl, and there must be a spring in the pawl. The pawl must return after coming off a tooth, so the spring is necessary. Another feature of this ratchet and pawl, not shown in the figure, is quite essential. Suppose the device were made of perfectly elastic parts. After the pawl is lifted off the end of the tooth and is pushed back by the spring, it will bounce against the wheel and continue to bounce. Then, when another fluctuation came, the wheel could turn the other way, because the tooth could get underneath during the moment when the pawl was up! Therefore an essential part of the irreversibility of our wheel is a damping or deadening mechanism which stops the bouncing. When the damping happens, of course, the energy that was in the pawl goes into the wheel and shows up as heat. So, as it turns, the wheel will get hotter and hotter. To make the thing simpler, we can put a gas around the wheel to take up some of the heat. Anyway, let us say the gas keeps rising in temperature, along with the wheel. Will it go on forever? No! The pawl and wheel, both at some temperature T , also have Brownian motion. This motion is such that, every once in a while, by accident, the pawl lifts itself up and over a tooth just at the moment when the Brownian motion on the vanes is trying to turn the axle backwards. And as things get hotter, this happens more often. So, this is the reason this device does not work in perpetual motion. When the vanes get kicked, sometimes the pawl lifts up and goes over the end. But sometimes, when it tries to turn the other way, the pawl has already lifted due to the fluctuations of the motions on the wheel side, and the wheel goes back the other way! The net result is nothing. It is not hard to demonstrate that when the temperature on both sides is equal, there will be no net average motion of the wheel. Of course the wheel will do a lot of jiggling this way and that way, but it will not do what we would like, which is to turn just one way. Let us look at the reason. It is necessary to do work against the spring in order to lift the pawl to the top of a tooth. Let us call this energy \u03f5 , and let \u03b8 be the angle between the teeth. The chance that the system can accumulate enough energy, \u03f5 , to get the pawl over the top of the tooth, is e \u2212\u03f5/kT . But the probability that the pawl will accidentally be up is also e \u2212\u03f5/kT . So the number of times that the pawl is up and the wheel can turn backwards freely is equal to the number of times that we have enough energy to turn it forward when the pawl is down. We thus get a \u201cbalance,\u201d and the wheel will not go around. Let us now go further. Take the example where the temperature of the vanes is T 1 and the temperature of the wheel, or ratchet, is T 2 , and T 2 is less than T 1 . Because the wheel is cold and the fluctuations of the pawl are relatively infrequent, it will be very hard for the pawl to attain an energy \u03f5 . Because of the high temperature T 1 , the vanes will often attain the energy \u03f5 , so our gadget will go in one direction, as designed. We would now like to see if it can lift weights. Onto the drum in the middle we tie a string, and put a weight, such as our flea, on the string. We let L be the torque due to the weight. If L is not too great, our machine will lift the weight because the Brownian fluctuations make it more likely to move in one direction than the other. We want to find how much weight it can lift, how fast it goes around, and so on. First we consider a forward motion, the usual way one designs a ratchet to run. In order to make one step forward, how much energy has to be borrowed from the vane end? We must borrow an energy \u03f5 to lift the pawl. The wheel turns through an angle \u03b8 against a torque L , so we also need the energy L\u03b8 . The total amount of energy that we have to borrow is thus \u03f5+L\u03b8 . The probability that we get this energy is proportional to e \u2212(\u03f5+L\u03b8)/k T 1 . Actually, it is not only a question of getting the energy, but we also would like to know the number of times per second it has this energy. The probability per second is proportional to e \u2212(\u03f5+L\u03b8)/k T 1 , and we shall call the proportionality constant 1/\u03c4 . It will cancel out in the end anyway. When a forward step happens, the work done on the weight is L\u03b8 . The energy taken from the vane is \u03f5+L\u03b8 . The spring gets wound up with energy \u03f5 , then it goes clatter, clatter, bang, and this energy goes into heat. All the energy taken out goes to lift the weight and to drive the pawl, which then falls back and gives heat to the other side. Now we look at the opposite case, which is backward motion. What happens here? To get the wheel to go backwards all we have to do is supply the energy to lift the pawl high enough so that the ratchet will slip. This is still energy \u03f5 . Our probability per second for the pawl to lift this high is now (1/\u03c4) e \u2212\u03f5/k T 2 . Our proportionality constant is the same, but this time k T 2 shows up because of the different temperature. When this happens, the work is released because the wheel slips backward. It loses one notch, so it releases work L\u03b8 . The energy taken from the ratchet system is \u03f5 , and the energy given to the gas at T 1 on the vane side is L\u03b8+\u03f5 . It takes a little thinking to see the reason for that. Suppose the pawl has lifted itself up accidentally by a fluctuation. Then when it falls back and the spring pushes it down against the tooth, there is a force trying to turn the wheel, because the tooth is pushing on an inclined plane. This force is doing work, and so is the force due to the weights. So both together make up the total force, and all the energy which is slowly released appears at the vane end as heat. (Of course it must, by conservation of energy, but one must be careful to think the thing through!) We notice that all these energies are exactly the same, but reversed. So, depending upon which of these two rates is greater, the weight is either slowly lifted or slowly released. Of course, it is constantly jiggling around, going up for a while and down for a while, but we are talking about the average behavior. Suppose that for a particular weight the rates happen to be equal. Then we add an infinitesimal weight to the string. The weight will slowly go down, and work will be done on the machine. Energy will be taken from the wheel and given to the vanes. If instead we take off a little bit of weight, then the imbalance is the other way. The weight is lifted, and heat is taken from the vane and put into the wheel. So we have the conditions of Carnot\u2019s reversible cycle, provided that the weight is just such that these two are equal. This condition is evidently that (\u03f5+L\u03b8)/ T 1 =\u03f5/ T 2 . Let us say that the machine is slowly lifting the weight. Energy Q 1 is taken from the vanes and energy Q 2 is delivered to the wheel, and these energies are in the ratio (\u03f5+L\u03b8)/\u03f5 . If we are lowering the weight, we also have Q 1 / Q 2 =(\u03f5+L\u03b8)/\u03f5 . Thus (Table 46\u20131) we have Q 1 / Q 2 = T 1 / T 2 . Q / Q T / T Furthermore, the work we get out is to the energy taken from the vane as L\u03b8 is to L\u03b8+\u03f5 , hence as ( T 1 \u2212 T 2 )/ T 1 . We see that our device cannot extract more work than this, operating reversibly. This is the result that we expected from Carnot\u2019s argument, and the main result of this lecture. However, we can use our device to understand a few other phenomena, even out of equilibrium, and therefore beyond the range of thermodynamics. Let us now calculate how fast our one-way device would turn if everything were at the same temperature and we hung a weight on the drum. If we pull very, very hard, of course, there are all kinds of complications. The pawl slips over the ratchet, or the spring breaks, or something. But suppose we pull gently enough that everything works nicely. In those circumstances, the above analysis is right for the probability of the wheel going forward and backward, if we remember that the two temperatures are equal. In each step an angle \u03b8 is obtained, so the angular velocity is \u03b8 times the probability of one of these jumps per second. It goes forward with probability (1/\u03c4) e \u2212(\u03f5+L\u03b8)/kT and backward with probability (1/\u03c4) e \u2212\u03f5/kT , so that for the angular velocity we have \u03c9 =(\u03b8/\u03c4)( e \u2212(\u03f5+L\u03b8)/kT \u2212 e \u2212\u03f5/kT ) =(\u03b8/\u03c4) e \u2212\u03f5/kT ( e \u2212L\u03b8/kT \u22121). (46.1) If we plot \u03c9 against L , we get the curve shown in Fig. 46\u20132. We see that it makes a great difference whether L is positive or negative. If L increases in the positive range, which happens when we try to drive the wheel backward, the backward velocity approaches a constant. As L becomes negative, \u03c9 really \u201ctakes off\u201d forward, since e to a tremendous power is very great! The angular velocity that was obtained from different forces is thus very unsymmetrical. Going one way it is easy: we get a lot of angular velocity for a little force. Going the other way, we can put on a lot of force, and yet the wheel hardly goes around. We find the same thing in an electrical rectifier. Instead of the force, we have the electric field, and instead of the angular velocity, we have the electric current. In the case of a rectifier, the voltage is not proportional to resistance, and the situation is unsymmetrical. The same analysis that we made for the mechanical rectifier will also work for an electrical rectifier. In fact, the kind of formula we obtained above is typical of the current-carrying capacities of rectifiers as a function of their voltages. Now let us take all the weights away, and look at the original machine. If T 2 were less than T 1 , the ratchet would go forward, as anybody would believe. But what is hard to believe, at first sight, is the opposite. If T 2 is greater than T 1 , the ratchet goes around the opposite way! A dynamic ratchet with lots of heat in it runs itself backwards, because the ratchet pawl is bouncing. If the pawl, for a moment, is on the incline somewhere, it pushes the inclined plane sideways. But it is always pushing on an inclined plane, because if it happens to lift up high enough to get past the point of a tooth, then the inclined plane slides by, and it comes down again on an inclined plane. So a hot ratchet and pawl is ideally built to go around in a direction exactly opposite to that for which it was originally designed! In spite of all our cleverness of lopsided design, if the two temperatures are exactly equal there is no more propensity to turn one way than the other. The moment we look at it, it may be turning one way or the other, but in the long run, it gets nowhere. The fact that it gets nowhere is really the fundamental deep principle on which all of thermodynamics is based. What deeper mechanical principle tells us that, in the long run, if the temperature is kept the same everywhere, our gadget will turn neither to the right nor to the left? We evidently have a fundamental proposition that there is no way to design a machine which, left to itself, will be more likely to be turning one way than the other after a long enough time. We must try to see how this follows from the laws of mechanics. The laws of mechanics go something like this: the mass times the acceleration is the force, and the force on each particle is some complicated function of the positions of all the other particles. There are other situations in which forces depend on velocity, such as in magnetism, but let us not consider that now. We take a simpler case, such as gravity, where forces depend only on position. Now suppose that we have solved our set of equations and we have a certain motion x(t) for each particle. In a complicated enough system, the solutions are very complicated, and what happens with time turns out to be very surprising. If we write down any arrangement we please for the particles, we will see this arrangement actually occur if we wait long enough! If we follow our solution for a long enough time, it tries everything that it can do, so to speak. This is not absolutely necessary in the simplest devices, but when systems get complicated enough, with enough atoms, it happens. Now there is something else the solution can do. If we solve the equations of motion, we may get certain functions such as t+ t 2 + t 3 . We claim that another solution would be \u2212t+ t 2 \u2212 t 3 . In other words, if we substitute \u2212t everywhere for t throughout the entire solution, we will once again get a solution of the same equation. This follows from the fact that if we substitute \u2212t for t in the original differential equation, nothing is changed, since only second derivatives with respect to t appear. This means that if we have a certain motion, then the exact opposite motion is also possible. In the complete confusion which comes if we wait long enough, it finds itself going one way sometimes, and it finds itself going the other way sometimes. There is nothing more beautiful about one of the motions than about the other. So it is impossible to design a machine which, in the long run, is more likely to be going one way than the other, if the machine is sufficiently complicated. One might think up an example for which this is obviously untrue. If we take a wheel, for instance, and spin it in empty space, it will go the same way forever. So there are some conditions, like the conservation of angular momentum, which violate the above argument. This just requires that the argument be made with a little more care. Perhaps the walls take up the angular momentum, or something like that, so that we have no special conservation laws. Then, if the system is complicated enough, the argument is true. It is based on the fact that the laws of mechanics are reversible. For historical interest, we would like to remark on a device invented by Maxwell, who first worked out the dynamical theory of gases. He supposed the following situation: We have two boxes of gas at the same temperature, with a little hole between them. At the hole sits a little demon (who may be a machine of course!). There is a door on the hole, which can be opened or closed by the demon. He watches the molecules coming from the left. Whenever he sees a fast molecule, he opens the door. When he sees a slow one, he leaves it closed. If we want him to be an extra special demon, he can have eyes at the back of his head, and do the opposite to the molecules from the other side. He lets the slow ones through to the left, and the fast through to the right. Pretty soon the left side will get cold and the right side hot. Then, are the ideas of thermodynamics violated because we could have such a demon? It turns out, if we build a finite-sized demon, that the demon himself gets so warm that he cannot see very well after a while. The simplest possible demon, as an example, would be a trap door held over the hole by a spring. A fast molecule comes through, because it is able to lift the trap door. The slow molecule cannot get through, and bounces back. But this thing is nothing but our ratchet and pawl in another form, and ultimately the mechanism will heat up. If we assume that the specific heat of the demon is not infinite, it must heat up. It has but a finite number of internal gears and wheels, so it cannot get rid of the extra heat that it gets from observing the molecules. Soon it is shaking from Brownian motion so much that it cannot tell whether it is coming or going, much less whether the molecules are coming or going, so it does not work. Are all the laws of physics reversible? Evidently not! Just try to unscramble an egg! Run a moving picture backwards, and it takes only a few minutes for everybody to start laughing. The most natural characteristic of all phenomena is their obvious irreversibility. Where does irreversibility come from? It does not come from Newton\u2019s laws. If we claim that the behavior of everything is ultimately to be understood in terms of the laws of physics, and if it also turns out that all the equations have the fantastic property that if we put t=\u2212t we have another solution, then every phenomenon is reversible. How then does it come about in nature on a large scale that things are not reversible? Obviously there must be some law, some obscure but fundamental equation, perhaps in electricity, maybe in neutrino physics, in which it does matter which way time goes. Let us discuss that question now. We already know one of those laws, which says that the entropy is always increasing. If we have a hot thing and a cold thing, the heat goes from hot to cold. So the law of entropy is one such law. But we expect to understand the law of entropy from the point of view of mechanics. In fact, we have just been successful in obtaining all the consequences of the argument that heat cannot flow backwards by itself from just mechanical arguments, and we thereby obtained an understanding of the Second Law. Apparently we can get irreversibility from reversible equations. But was it only a mechanical argument that we used? Let us look into it more closely. Since our question has to do with the entropy, our problem is to try to find a microscopic description of entropy. If we say we have a certain amount of energy in something, like a gas, then we can get a microscopic picture of it, and say that every atom has a certain energy. All these energies added together give us the total energy. Similarly, maybe every atom has a certain entropy. If we add everything up, we would have the total entropy. It does not work so well, but let us see what happens. As an example, we calculate the entropy difference between a gas at a certain temperature at one volume, and a gas at the same temperature at another volume. We remember, from Chapter 44, that we had, for the change in entropy, \u0394S=\u222b dQ T . \u222b In the present case, the energy of the gas is the same before and after expansion, since the temperature does not change. So we have to add enough heat to equal the work done by the gas or, for each little change in volume, dQ=PdV. d Q P d V Putting this in for dQ , we get \u0394S = \u222b V 2 V 1 P dV T = \u222b V 2 V 1 NkT V dV T =Nkln V 2 V 1 , as we obtained in Chapter 44. For instance, if we expand the volume by a factor of 2 , the entropy change is Nkln2 . Let us now consider another interesting example. Suppose we have a box with a barrier in the middle. On one side is neon (\u201cblack\u201d molecules), and on the other, argon (\u201cwhite\u201d molecules). Now we take out the barrier, and let them mix. How much has the entropy changed? It is possible to imagine that instead of the barrier we have a piston, with holes in it that let the whites through but not the blacks, and another kind of piston which is the other way around. If we move one piston to each end, we see that, for each gas, the problem is like the one we just solved. So we get an entropy change of Nkln2 , which means that the entropy has increased by kln2 per molecule. The 2 has to do with the extra room that the molecule has, which is rather peculiar. It is not a property of the molecule itself, but of how much room the molecule has to run around in. This is a strange situation, where entropy increases but where everything has the same temperature and the same energy! The only thing that is changed is that the molecules are distributed differently. We well know that if we just pull the barrier out, everything will get mixed up after a long time, due to the collisions, the jiggling, the banging, and so on. Every once in a while a white molecule goes toward a black, and a black one goes toward a white, and maybe they pass. Gradually the whites worm their way, by accident, across into the space of blacks, and the blacks worm their way, by accident, into the space of whites. If we wait long enough we get a mixture. Clearly, this is an irreversible process in the real world, and ought to involve an increase in the entropy. Here we have a simple example of an irreversible process which is completely composed of reversible events. Every time there is a collision between any two molecules, they go off in certain directions. If we took a moving picture of a collision in reverse, there would be nothing wrong with the picture. In fact, one kind of collision is just as likely as another. So the mixing is completely reversible, and yet it is irreversible. Everyone knows that if we started with white and with black, separated, we would get a mixture within a few minutes. If we sat and looked at it for several more minutes, it would not separate again but would stay mixed. So we have an irreversibility which is based on reversible situations. But we also see the reason now. We started with an arrangement which is, in some sense, ordered. Due to the chaos of the collisions, it becomes disordered. It is the change from an ordered arrangement to a disordered arrangement which is the source of the irreversibility. It is true that if we took a motion picture of this, and showed it backwards, we would see it gradually become ordered. Someone would say, \u201cThat is against the laws of physics!\u201d So we would run the film over again, and we would look at every collision. Every one would be perfect, and every one would be obeying the laws of physics. The reason, of course, is that every molecule\u2019s velocities are just right, so if the paths are all followed back, they get back to their original condition. But that is a very unlikely circumstance to have. If we start with the gas in no special arrangement, just whites and blacks, it will never get back. So we now have to talk about what we mean by disorder and what we mean by order. It is not a question of pleasant order or unpleasant disorder. What is different in our mixed and unmixed cases is the following. Suppose we divide the space into little volume elements. If we have white and black molecules, how many ways could we distribute them among the volume elements so that white is on one side, and black on the other? On the other hand, how many ways could we distribute them with no restriction on which goes where? Clearly, there are many more ways to arrange them in the latter case. We measure \u201cdisorder\u201d by the number of ways that the insides can be arranged, so that from the outside it looks the same. The logarithm of that number of ways is the entropy. The number of ways in the separated case is less, so the entropy is less, or the \u201cdisorder\u201d is less. So with the above technical definition of disorder we can understand the proposition. First, the entropy measures the disorder. Second, the universe always goes from \u201corder\u201d to \u201cdisorder,\u201d so entropy always increases. Order is not order in the sense that we like the arrangement, but in the sense that the number of different ways we can hook it up, and still have it look the same from the outside, is relatively restricted. In the case where we reversed our motion picture of the gas mixing, there was not as much disorder as we thought. Every single atom had exactly the correct speed and direction to come out right! The entropy was not high after all, even though it appeared so. What about the reversibility of the other physical laws? When we talked about the electric field which comes from an accelerating charge, it was said that we must take the retarded field. At a time t and at a distance r from the charge, we take the field due to the acceleration at a time t\u2212r/c , not t+r/c . So it looks, at first, as if the law of electricity is not reversible. Very strangely, however, the laws we used come from a set of equations called Maxwell\u2019s equations, which are, in fact, reversible. Furthermore, it is possible to argue that if we were to use only the advanced field, the field due to the state of affairs at t+r/c , and do it absolutely consistently in a completely enclosed space, everything happens exactly the same way as if we use retarded fields! This apparent irreversibility in electricity, at least in an enclosure, is thus not an irreversibility at all. We have some feeling for that already, because we know that when we have an oscillating charge which generates fields which are bounced from the walls of an enclosure we ultimately get to an equilibrium in which there is no one-sidedness. The retarded field approach is only a convenience in the method of solution. So far as we know, all the fundamental laws of physics, like Newton\u2019s equations, are reversible. Then where does irreversibility come from? It comes from order going to disorder, but we do not understand this until we know the origin of the order. Why is it that the situations we find ourselves in every day are always out of equilibrium? One possible explanation is the following. Look again at our box of mixed white and black molecules. Now it is possible, if we wait long enough, by sheer, grossly improbable, but possible, accident, that the distribution of molecules gets to be mostly white on one side and mostly black on the other. After that, as times goes on and accidents continue, they get more mixed up again. Thus one possible explanation of the high degree of order in the present-day world is that it is just a question of luck. Perhaps our universe happened to have had a fluctuation of some kind in the past, in which things got somewhat separated, and now they are running back together again. This kind of theory is not unsymmetrical, because we can ask what the separated gas looks like either a little in the future or a little in the past. In either case, we see a grey smear at the interface, because the molecules are mixing again. No matter which way we run time, the gas mixes. So this theory would say the irreversibility is just one of the accidents of life. We would like to argue that this is not the case. Suppose we do not look at the whole box at once, but only at a piece of the box. Then, at a certain moment, suppose we discover a certain amount of order. In this little piece, white and black are separate. What should we deduce about the condition in places where we have not yet looked? If we really believe that the order arose from complete disorder by a fluctuation, we must surely take the most likely fluctuation which could produce it, and the most likely condition is not that the rest of it has also become disentangled! Therefore, from the hypothesis that the world is a fluctuation, all of the predictions are that if we look at a part of the world we have never seen before, we will find it mixed up, and not like the piece we just looked at. If our order were due to a fluctuation, we would not expect order anywhere but where we have just noticed it. Now we assume the separation is because the past of the universe was really ordered. It is not due to a fluctuation, but the whole thing used to be white and black. This theory now predicts that there will be order in other places\u2014the order is not due to a fluctuation, but due to a much higher ordering at the beginning of time. Then we would expect to find order in places where we have not yet looked. The astronomers, for example, have only looked at some of the stars. Every day they turn their telescopes to other stars, and the new stars are doing the same thing as the other stars. We therefore conclude that the universe is not a fluctuation, and that the order is a memory of conditions when things started. This is not to say that we understand the logic of it. For some reason, the universe at one time had a very low entropy for its energy content, and since then the entropy has increased. So that is the way toward the future. That is the origin of all irreversibility, that is what makes the processes of growth and decay, that makes us remember the past and not the future, remember the things which are closer to that moment in the history of the universe when the order was higher than now, and why we are not able to remember things where the disorder is higher than now, which we call the future. So, as we commented in an earlier chapter, the entire universe is in a glass of wine, if we look at it closely enough. In this case the glass of wine is complex, because there is water and glass and light and everything else. Another delight of our subject of physics is that even simple and idealized things, like the ratchet and pawl, work only because they are part of the universe. The ratchet and pawl works in only one direction because it has some ultimate contact with the rest of the universe. If the ratchet and pawl were in a box and isolated for some sufficient time, the wheel would be no more likely to go one way than the other. But because we pull up the shades and let the light out, because we cool off on the earth and get heat from the sun, the ratchets and pawls that we make can turn one way. This one-wayness is interrelated with the fact that the ratchet is part of the universe. It is part of the universe not only in the sense that it obeys the physical laws of the universe, but its one-way behavior is tied to the one-way behavior of the entire universe. It cannot be completely understood until the mystery of the beginnings of the history of the universe are reduced still further from speculation to scientific understanding."
    },
    {
        "input": "Geometrical Optics",
        "output": "In this chapter we shall discuss some elementary applications of the ideas of the previous chapter to a number of practical devices, using the approximation called geometrical optics. This is a most useful approximation in the practical design of many optical systems and instruments. Geometrical optics is either very simple or else it is very complicated. By that we mean that we can either study it only superficially, so that we can design instruments roughly, using rules that are so simple that we hardly need deal with them here at all, since they are practically of high school level, or else, if we want to know about the small errors in lenses and similar details, the subject gets so complicated that it is too advanced to discuss here! If one has an actual, detailed problem in lens design, including analysis of aberrations, then he is advised to read about the subject or else simply to trace the rays through the various surfaces (which is what the book tells how to do), using the law of refraction from one side to the other, and to find out where they come out and see if they form a satisfactory image. People have said that this is too tedious, but today, with computing machines, it is the right way to do it. One can set up the problem and make the calculation for one ray after another very easily. So the subject is really ultimately quite simple, and involves no new principles. Furthermore, it turns out that the rules of either elementary or advanced optics are seldom characteristic of other fields, so that there is no special reason to follow the subject very far, with one important exception. The most advanced and abstract theory of geometrical optics was worked out by Hamilton, and it turns out that this has very important applications in mechanics. It is actually even more important in mechanics than it is in optics, and so we leave Hamilton\u2019s theory for the subject of advanced analytical mechanics, which is studied in the senior year or in graduate school. So, appreciating that geometrical optics contributes very little, except for its own sake, we now go on to discuss the elementary properties of simple optical systems on the basis of the principles outlined in the last chapter. In order to go on, we must have one geometrical formula, which is the following: if we have a triangle with a small altitude h and a long base d , then the diagonal s (we are going to need it to find the difference in time between two different routes) is longer than the base (Fig. 27\u20131). How much longer? The difference \u0394=s\u2212d can be found in a number of ways. One way is this. We see that s 2 \u2212 d 2 = h 2 , or (s\u2212d)(s+d)= h 2 . But s\u2212d=\u0394 , and s+d\u22482s . Thus \u0394\u2248 h 2 /2s. (27.1) This is all the geometry we need to discuss the formation of images by curved surfaces! The first and simplest situation to discuss is a single refracting surface, separating two media with different indices of refraction (Fig. 27\u20132). We leave the case of arbitrary indices of refraction to the student, because ideas are always the most important thing, not the specific situation, and the problem is easy enough to do in any case. So we shall suppose that, on the left, the speed is 1 and on the right it is 1/n , where n is the index of refraction. The light travels more slowly in the glass by a factor n . Now suppose that we have a point at O , at a distance s from the front surface of the glass, and another point O \u2032 at a distance s \u2032 inside the glass, and we desire to arrange the curved surface in such a manner that every ray from O which hits the surface, at any point P , will be bent so as to proceed toward the point O \u2032 . For that to be true, we have to shape the surface in such a way that the time it takes for the light to go from O to P , that is, the distance OP divided by the speed of light (the speed here is unity), plus n\u22c5 O \u2032 P , which is the time it takes to go from P to O \u2032 , is equal to a constant independent of the point P . This condition supplies us with an equation for determining the surface. The answer is that the surface is a very complicated fourth-degree curve, and the student may entertain himself by trying to calculate it by analytic geometry. It is simpler to try a special case that corresponds to s\u2192\u221e , because then the curve is a second-degree curve and is more recognizable. It is interesting to compare this curve with the parabolic curve we found for a focusing mirror when the light is coming from infinity. So the proper surface cannot easily be made\u2014to focus the light from one point to another requires a rather complicated surface. It turns out in practice that we do not try to make such complicated surfaces ordinarily, but instead we make a compromise. Instead of trying to get all the rays to come to a focus, we arrange it so that only the rays fairly close to the axis O O \u2032 come to a focus. The farther ones may deviate if they want to, unfortunately, because the ideal surface is complicated, and we use instead a spherical surface with the right curvature at the axis. It is so much easier to fabricate a sphere than other surfaces that it is profitable for us to find out what happens to rays striking a spherical surface, supposing that only the rays near the axis are going to be focused perfectly. Those rays which are near the axis are sometimes called paraxial rays, and what we are analyzing are the conditions for the focusing of paraxial rays. We shall discuss later the errors that are introduced by the fact that all rays are not always close to the axis. Thus, supposing P is close to the axis, we drop a perpendicular PQ such that the height PQ is h . For a moment, we imagine that the surface is a plane passing through P . In that case, the time needed to go from O to P would exceed the time from O to Q , and also, the time from P to O \u2032 would exceed the time from Q to O \u2032 . But that is why the glass must be curved, because the total excess time must be compensated by the delay in passing from V to Q ! Now the excess time along route OP is h 2 /2s , and the excess time on the other route is n h 2 /2 s \u2032 . This excess time, which must be matched by the delay in going along VQ , differs from what it would have been in a vacuum, because there is a medium present. In other words, the time to go from V to Q is not as if it were straight in the air, but it is slower by the factor n , so that the excess delay in this distance is then (n\u22121)VQ . And now, how large is VQ ? If the point C is the center of the sphere and if its radius is R , we see by the same formula that the distance VQ is equal to h 2 /2R . Therefore we discover that the law that connects the distances s and s \u2032 , and that gives us the radius of curvature R of the surface that we need, is ( h 2 /2s)+(n h 2 /2 s \u2032 )=(n\u22121) h 2 /2R (27.2) or (1/s)+(n/ s \u2032 )=(n\u22121)/R. (27.3) If we have a position O and another position O \u2032 , and want to focus light from O to O \u2032 , then we can calculate the required radius of curvature R of the surface by this formula. Now it turns out, interestingly, that the same lens, with the same curvature R , will focus for other distances, namely, for any pair of distances such that the sum of the two reciprocals, one multiplied by n , is a constant. Thus a given lens will (so long as we limit ourselves to paraxial rays) focus not only from O to O \u2032 , but between an infinite number of other pairs of points, so long as those pairs of points bear the relationship that 1/s+n/ s \u2032 is a constant, characteristic of the lens. In particular, an interesting case is that in which s\u2192\u221e . We can see from the formula that as one s increases, the other decreases. In other words, if point O goes out, point O \u2032 comes in, and vice versa. As point O goes toward infinity, point O \u2032 keeps moving in until it reaches a certain distance, called the focal length f \u2032 , inside the material. If parallel rays come in, they will meet the axis at a distance f \u2032 . Likewise, we could imagine it the other way. (Remember the reciprocity rule: if light will go from O to O \u2032 , of course it will also go from O \u2032 to O .) Therefore, if we had a light source inside the glass, we might want to know where the focus is. In particular, if the light in the glass were at infinity (same problem) where would it come to a focus outside? This distance is called f . Of course, we can also put it the other way. If we had a light source at f and the light went through the surface, then it would go out as a parallel beam. We can easily find out what f and f \u2032 are: n/ f \u2032 1/f =(n\u22121)/Ror f \u2032 =(n\u22121)/Rorf =Rn/(n\u22121), =R/(n\u22121). (27.4) (27.5) We see an interesting thing: if we divide each focal length by the corresponding index of refraction we get the same result! This theorem, in fact, is general. It is true of any system of lenses, no matter how complicated, so it is interesting to remember. We did not prove here that it is general\u2014we merely noted it for a single surface, but it happens to be true in general that the two focal lengths of a system are related in this way. Sometimes Eq. (27.3) is written in the form 1/s+n/ s \u2032 =1/f. (27.6) This is more useful than (27.3) because we can measure f more easily than we can measure the curvature and index of refraction of the lens: if we are not interested in designing a lens or in knowing how it got that way, but simply lift it off a shelf, the interesting quantity is f , not the n and the 1 and the R ! Now an interesting situation occurs if s becomes less than f . What happens then? If s<f , then (1/s)>(1/f) , and therefore s \u2032 is negative; our equation says that the light will focus only with a negative value of s \u2032 , whatever that means! It does mean something very interesting and very definite. It is still a useful formula, in other words, even when the numbers are negative. What it means is shown in Fig. 27\u20133. If we draw the rays which are diverging from O , they will be bent, it is true, at the surface, and they will not come to a focus, because O is so close in that they are \u201cbeyond parallel.\u201d However, they diverge as if they had come from a point O \u2032 outside the glass. This is an apparent image, sometimes called a virtual image. The image O \u2032 in Fig. 27\u20132 is called a real image. If the light really comes to a point, it is a real image. But if the light appears to be coming from a point, a fictitious point different from the original point, it is a virtual image. So when s \u2032 comes out negative, it means that O \u2032 is on the other side of the surface, and everything is all right. Now consider the interesting case where R is equal to infinity; then we have (1/s)+(n/ s \u2032 )=0 . In other words, s \u2032 =\u2212ns , which means that if we look from a dense medium into a rare medium and see a point in the rare medium, it appears to be deeper by a factor n . Likewise, we can use the same equation backwards, so that if we look into a plane surface at an object that is at a certain distance inside the dense medium, it will appear as though the light is coming from not as far back (Fig. 27\u20134). When we look at the bottom of a swimming pool from above, it does not look as deep as it really is, by a factor 3/4 , which is the reciprocal of the index of refraction of water. We could go on, of course, to discuss the spherical mirror. But if one appreciates the ideas involved, he should be able to work it out for himself. Therefore we leave it to the student to work out the formula for the spherical mirror, but we mention that it is well to adopt certain conventions concerning the distances involved: The object distance s is positive if the point O is to the left of the surface. The image distance s \u2032 is positive if the point O \u2032 is to the right of the surface. The radius of curvature of the surface is positive if the center is to the right of the surface. In Fig. 27\u20132, for example, s , s \u2032 , and R are all positive; in Fig. 27\u20133, s and R are positive, but s \u2032 is negative. If we had used a concave surface, our formula (27.3) would still give the correct result if we merely make R a negative quantity. In working out the corresponding formula for a mirror, using the above conventions, you will find that if you put n=\u22121 throughout the formula (27.3) (as though the material behind the mirror had an index \u22121 ), the right formula for a mirror results! Although the derivation of formula (27.3) is simple and elegant, using least time, one can of course work out the same formula using Snell\u2019s law, remembering that the angles are so small that the sines of angles can be replaced by the angles themselves. Now we go on to consider another situation, a very practical one. Most of the lenses that we use have two surfaces, not just one. How does this affect matters? Suppose that we have two surfaces of different curvature, with glass filling the space between them (Fig. 27\u20135). We want to study the problem of focusing from a point O to an alternate point O \u2032 . How can we do that? The answer is this: First, use formula (27.3) for the first surface, forgetting about the second surface. This will tell us that the light which was diverging from O will appear to be converging or diverging, depending on the sign, from some other point, say O \u2032 . Now we consider a new problem. We have a different surface, between glass and air, in which rays are converging toward a certain point O \u2032 . Where will they actually converge? We use the same formula again! We find that they converge at O \u2032\u2032 . Thus, if necessary, we can go through 75 surfaces by just using the same formula in succession, from one to the next! There are some rather high-class formulas that would save us considerable energy in the few times in our lives that we might have to chase the light through five surfaces, but it is easier just to chase it through five surfaces when the problem arises than it is to memorize a lot of formulas, because it may be we will never have to chase it through any surfaces at all! In any case, the principle is that when we go through one surface we find a new position, a new focal point, and then take that point as the starting point for the next surface, and so on. In order to actually do this, since on the second surface we are going from n to 1 rather than from 1 to n , and since in many systems there is more than one kind of glass, so that there are indices n 1 , n 2 , \u2026, we really need a generalization of formula (27.3) for a case where there are two different indices, n 1 and n 2 , rather than only n . Then it is not difficult to prove that the general form of (27.3) is ( n 1 /s)+( n 2 / s \u2032 )=( n 2 \u2212 n 1 )/R. (27.7) Particularly simple is the special case in which the two surfaces are very close together\u2014so close that we may ignore small errors due to the thickness. If we draw the lens as shown in Fig. 27\u20136, we may ask this question: How must the lens be built so as to focus light from O to O \u2032 ? Suppose the light comes exactly to the edge of the lens, at point P . Then the excess time in going from O to O \u2032 is ( n 1 h 2 /2s)+( n 1 h 2 /2 s \u2032 ) , ignoring for a moment the presence of the thickness T of glass of index n 2 . Now, to make the time for the direct path equal to that for the path OP O \u2032 , we have to use a piece of glass whose thickness T at the center is such that the delay introduced in going through this thickness is enough to compensate for the excess time above. Therefore the thickness of the lens at the center must be given by the relationship ( n 1 h 2 /2s)+( n 1 h 2 /2 s \u2032 )=( n 2 \u2212 n 1 )T. (27.8) We can also express T in terms of the radii R 1 and R 2 of the two surfaces. Paying attention to our convention (3), we thus find, for R 1 < R 2 (a convex lens), T=( h 2 /2 R 1 )\u2212( h 2 /2 R 2 ). (27.9) Therefore, we finally get ( n 1 /s)+( n 1 / s \u2032 )=( n 2 \u2212 n 1 )(1/ R 1 \u22121/ R 2 ). (27.10) Now we note again that if one of the points is at infinity, the other will be at a point which we will call the focal length f . The focal length f is given by 1/f=(n\u22121)(1/ R 1 \u22121/ R 2 ). (27.11) where n= n 2 / n 1 . Now, if we take the opposite case, where s goes to infinity, we see that s \u2032 is at the focal length f \u2032 . This time the focal lengths are equal. (This is another special case of the general rule that the ratio of the two focal lengths is the ratio of the indices of refraction in the two media in which the rays focus. In this particular optical system, the initial and final indices are the same, so the two focal lengths are equal.) Forgetting for a moment about the actual formula for the focal length, if we bought a lens that somebody designed with certain radii of curvature and a certain index, we could measure the focal length, say, by seeing where a point at infinity focuses. Once we had the focal length, it would be better to write our equation in terms of the focal length directly, and the formula then is (1/s)+(1/ s \u2032 )=1/f. (27.12) Now let us see how the formula works and what it implies in different circumstances. First, it implies that if s or s \u2032 is infinite the other one is f . That means that parallel light focuses at a distance f , and this in effect defines f . Another interesting thing it says is that both points move in the same direction. If one moves to the right, the other does also. Another thing it says is that s and s \u2032 are equal if they are both equal to 2f . In other words, if we want a symmetrical situation, we find that they will both focus at a distance 2f . So far we have discussed the focusing action only for points on the axis. Now let us discuss also the imaging of objects not exactly on the axis, but a little bit off, so that we can understand the properties of magnification. When we set up a lens so as to focus light from a small filament onto a \u201cpoint\u201d on a screen, we notice that on the screen we get a \u201cpicture\u201d of the same filament, except of a larger or smaller size than the true filament. This must mean that the light comes to a focus from each point of the filament. In order to understand this a little better, let us analyze the thin lens system shown schematically in Fig. 27\u20137. We know the following facts: Any ray that comes in parallel on one side proceeds toward a certain particular point called the focus on the other side, at a distance f from the lens. Any ray that arrives at the lens from the focus on one side comes out parallel to the axis on the other side. This is all we need to establish formula (27.12) by geometry, as follows: Suppose we have an object at some distance x from the focus; let the height of the object be y . Then we know that one of the rays, namely PQ , will be bent so as to pass through the focus R on the other side. Now if the lens will focus point P at all, we can find out where if we find out where just one other ray goes, because the new focus will be where the two intersect again. We need only use our ingenuity to find the exact direction of one other ray. But we remember that a parallel ray goes through the focus and vice versa: a ray which goes through the focus will come out parallel! So we draw ray PT through U . (It is true that the actual rays which are doing the focusing may be much more limited than the two we have drawn, but they are harder to figure, so we make believe that we can make this ray.) Since it would come out parallel, we draw TS parallel to XW . The intersection S is the point we need. This will determine the correct place and the correct height. Let us call the height y \u2032 and the distance from the focus, x \u2032 . Now we may derive a lens formula. Using the similar triangles PVU and TXU , we find y \u2032 f = y x . (27.13) Similarly, from triangles SWR and QXR , we get y \u2032 x \u2032 = y f . (27.14) Solving each for y \u2032 /y , we find that y \u2032 y = x \u2032 f = f x . (27.15) Equation (27.15) is the famous lens formula; in it is everything we need to know about lenses: It tells us the magnification, y \u2032 /y , in terms of the distances and the focal lengths. It also connects the two distances x and x \u2032 with f : x x \u2032 = f 2 , (27.16) which is a much neater form to work with than Eq. (27.12). We leave it to the student to demonstrate that if we call s=x+f and s \u2032 = x \u2032 +f , Eq. (27.12) is the same as Eq. (27.16). Without actually deriving it, we shall briefly describe the general result when we have a number of lenses. If we have a system of several lenses, how can we possibly analyze it? That is easy. We start with some object and calculate where its image is for the first lens, using formula (27.16) or (27.12) or any other equivalent formula, or by drawing diagrams. So we find an image. Then we treat this image as the source for the next lens, and use the second lens with whatever its focal length is to again find an image. We simply chase the thing through the succession of lenses. That is all there is to it. It involves nothing new in principle, so we shall not go into it. However, there is a very interesting net result of the effects of any sequence of lenses on light that starts and ends up in the same medium, say air. Any optical instrument\u2014a telescope or a microscope with any number of lenses and mirrors\u2014has the following property: There exist two planes, called the principal planes of the system (these planes are often fairly close to the first surface of the first lens and the last surface of the last lens), which have the following properties: (1) If light comes into the system parallel from the first side, it comes out at a certain focus, at a distance from the second principal plane equal to the focal length, just as though the system were a thin lens situated at this plane. (2) If parallel light comes in the other way, it comes to a focus at the same distance f from the first principal plane, again as if a thin lens were situated there. (See Fig. 27\u20138.) Of course, if we measure the distances x and x \u2032 , and y and y \u2032 as before, the formula (27.16) that we have written for the thin lens is absolutely general, provided that we measure the focal length from the principal planes and not from the center of the lens. It so happens that for a thin lens the principal planes are coincident. It is just as though we could take a thin lens, slice it down the middle, and separate it, and not notice that it was separated. Every ray that comes in pops out immediately on the other side of the second plane from the same point as it went into the first plane! The principal planes and the focal length may be found either by experiment or by calculation, and then the whole set of properties of the optical system are described. It is very interesting that the result is not complicated when we are all finished with such a big, complicated optical system. Before we get too excited about how marvelous lenses are, we must hasten to add that there are also serious limitations, because of the fact that we have limited ourselves, strictly speaking, to paraxial rays, the rays near the axis. A real lens having a finite size will, in general, exhibit aberrations. For example, a ray that is on the axis, of course, goes through the focus; a ray that is very close to the axis will still come to the focus very well. But as we go farther out, the ray begins to deviate from the focus, perhaps by falling short, and a ray striking near the top edge comes down and misses the focus by quite a wide margin. So, instead of getting a point image, we get a smear. This effect is called spherical aberration, because it is a property of the spherical surfaces we use in place of the right shape. This could be remedied, for any specific object distance, by re-forming the shape of the lens surface, or perhaps by using several lenses arranged so that the aberrations of the individual lenses tend to cancel each other. Lenses have another fault: light of different colors has different speeds, or different indices of refraction, in the glass, and therefore the focal length of a given lens is different for different colors. So if we image a white spot, the image will have colors, because when we focus for the red, the blue is out of focus, or vice versa. This property is called chromatic aberration. There are still other faults. If the object is off the axis, then the focus really isn\u2019t perfect any more, when it gets far enough off the axis. The easiest way to verify this is to focus a lens and then tilt it so that the rays are coming in at a large angle from the axis. Then the image that is formed will usually be quite crude, and there may be no place where it focuses well. There are thus several kinds of errors in lenses that the optical designer tries to remedy by using many lenses to compensate each other\u2019s errors. How careful do we have to be to eliminate aberrations? Is it possible to make an absolutely perfect optical system? Suppose we had built an optical system that is supposed to bring light exactly to a point. Now, arguing from the point of view of least time, can we find a condition on how perfect the system has to be? The system will have some kind of an entrance opening for the light. If we take the farthest ray from the axis that can come to the focus (if the system is perfect, of course), the times for all rays are exactly equal. But nothing is perfect, so the question is, how wrong can the time be for this ray and not be worth correcting any further? That depends on how perfect we want to make the image. But suppose we want to make the image as perfect as it possibly can be made. Then, of course, our impression is that we have to arrange that every ray takes as nearly the same time as possible. But it turns out that this is not true, that beyond a certain point we are trying to do something that is too fine, because the theory of geometrical optics does not work! Remember that the principle of least time is not an accurate formulation, unlike the principle of conservation of energy or the principle of conservation of momentum. The principle of least time is only an approximation, and it is interesting to know how much error can be allowed and still not make any apparent difference. The answer is that if we have arranged that between the maximal ray\u2014the worst ray, the ray that is farthest out\u2014and the central ray, the difference in time is less than about the period that corresponds to one oscillation of the light, then there is no use improving it any further. Light is an oscillatory thing with a definite frequency that is related to the wavelength, and if we have arranged that the time difference for different rays is less than about a period, there is no use going any further. Another interesting question\u2014a very important technical question with all optical instruments\u2014is how much resolving power they have. If we build a microscope, we want to see the objects that we are looking at. That means, for instance, that if we are looking at a bacterium with a spot on each end, we want to see that there are two dots when we magnify them. One might think that all we have to do is to get enough magnification\u2014we can always add another lens, and we can always magnify again and again, and with the cleverness of designers, all the spherical aberrations and chromatic aberrations can be cancelled out, and there is no reason why we cannot keep on magnifying the image. So the limitations of a microscope are not that it is impossible to build a lens that magnifies more than 2000 diameters. We can build a system of lenses that magnifies 10,000 diameters, but we still could not see two points that are too close together because of the limitations of geometrical optics, because of the fact that least time is not precise. To discover the rule that determines how far apart two points have to be so that at the image they appear as separate points can be stated in a very beautiful way associated with the time it takes for different rays. Suppose that we disregard the aberrations now, and imagine that for a particular point P (Fig. 27\u20139) all the rays from object to image T take exactly the same time. (It is not true, because it is not a perfect system, but that is another problem.) Now take another nearby point, P \u2032 , and ask whether its image will be distinct from T . In other words, whether we can make out the difference between them. Of course, according to geometrical optics, there should be two point images, but what we see may be rather smeared and we may not be able to make out that there are two points. The condition that the second point is focused in a distinctly different place from the first one is that the two times for the extreme rays P \u2032 ST and P \u2032 RT on each side of the big opening of the lenses to go from one end to the other, must not be equal from the two possible object points to a given image point. Why? Because, if the times were equal, of course both would focus at the same point. So the times are not going to be equal. But by how much do they have to differ so that we can say that both do not come to a common focus, so that we can distinguish the two image points? The general rule for the resolution of any optical instrument is this: two different point sources can be resolved only if one source is focused at such a point that the times for the maximal rays from the other source to reach that point, as compared with its own true image point, differ by more than one period. It is necessary that the difference in time between the top ray and the bottom ray to the wrong focus shall exceed a certain amount, namely, approximately the period of oscillation of the light: t 2 \u2212 t 1 >1/\u03bd, (27.17) where \u03bd is the frequency of the light (number of oscillations per second; also speed divided by wavelength). If the distance of separation of the two points is called D , and if the opening half-angle of the lens is called \u03b8 , then one can demonstrate that (27.17) is exactly equivalent to the statement that D must exceed \u03bb/2nsin\u03b8 , where n is the index of refraction at P and \u03bb is the wavelength. The smallest things that we can see are therefore approximately the wavelength of light. A corresponding formula exists for telescopes, which tells us the smallest difference in angle between two stars that can just be distinguished.1"
    },
    {
        "input": "Problems and Solutionsâ€”Review Lecture C",
        "output": "We\u2019re continuing this review of how to do physics by doing a number of problems. All of the problems I chose are elaborate and complicated and difficult; I\u2019ll leave you to do the easy problems. Also, I suffer from the disease that all professors suffer from\u2014that is, there never seems to be enough time, and I invented more problems than undoubtedly we\u2019ll be able to do, and therefore I\u2019ve tried to speed things up by writing some things on the board beforehand, with the illusion that every professor has: that if he talks about more things, he\u2019ll teach more things. Of course, there\u2019s only a finite rate at which material can be absorbed by the human mind, yet we disregard that phenomenon, and in spite of it we go too fast. So, I think I\u2019ll just go along slowly, and see how far we get. The last problem that we were talking about was satellite motion. We were discussing the question of whether a particle that was moving perpendicular to the radius of the sun, of a planet, or any other mass M, at a distance a, and having the escape velocity at that distance, would, in fact, escape\u2014because it\u2019s not self-evident. It would be, if it were headed straight out, radially; but whether it would make it or not if it were headed perpendicular to the radius, is another question. (See Fig. 3-1.) It turns out that\u2014if we can remember some of Kepler\u2019s laws, and add some other laws like the conservation of energy\u2014we can figure out that if the particle didn\u2019t escape, it would make an ellipse, and we can figure out how far away it would get, and that\u2019s what we\u2019re going to do now. If the perihelion of the ellipse is a , how far is the aphelion, b ? (By the way, I tried to write this problem on the board, but I found I couldn\u2019t spell \u201cperihelion\u201d!) (See Fig. 3-2.) Last time we figured out the escape velocity by using the conservation of energy. (See Fig. 3-3.) K.E.+P.E. at a =K.E.+P.E. at \u221e mv 2 escape 2 \u2212 GMm a =0+0 v 2 escape 2 = GM a vescape = \u221a 2GM a Now, this is the formula for the escape velocity at the radius a , but suppose the velocity va is arbitrary, and we\u2019re trying to find b in terms of va . The conservation of energy tells us that the kinetic energy plus the potential energy of the particle at the perihelion must equal the kinetic energy plus the potential energy at the aphelion\u2014and that\u2019s what we can use to calculate b , at first sight: mv 2 a 2 \u2212 GMm a = mv 2 b 2 \u2212 GMm b . Infelizmente,1 however,we do not have vb so unless there\u2019s some external machinery or analysis to obtain vb , we\u2019re never going to solve Eq. (3.2) for b . But if we remember Kepler\u2019s law of equal areas, we know that in a given time the same area is swept out at the aphelion as is swept out at the perihelion: in a short time \u0394t the particle at the perihelion moves a distance va\u0394t so the area swept out is about ava\u0394t/2 while at the aphelion, where the particle moves vb\u0394t the area swept out is about bvb\u0394t/2 . And so \u201cequal areas\u201d means that ava\u0394t/2 equals bvb\u0394t/2 \u2014which means that the velocities vary inversely as the radii. (See Fig. 3-4.) ava\u0394t/2 =bvb\u0394t/2 vb = a b va That gives us, then, a formula for vb in terms of va which we can substitute in Eq. (3.2). Then we will have an equation to determine b : mv 2 a 2 \u2212 GMm a = m( a b va)2 2 \u2212 GMm b . Dividing by m , and rearranging, we get av 2 a 2 ( 1 b )2\u2212GM( 1 b )+( GM a \u2212 v 2 a 2 )=0. If you look at Eq. (3.5) a while, you could say, \u201cWell, I can multiply by b2 and then it\u2019ll be a quadratic equation in b ,\u201d or, if you prefer, you could look at it just the way it is, and solve the quadratic equation for 1/b \u2014either way. The solution for 1/b is 1 b = GM a2v 2 a \u00b1 \u221a ( GM a2v 2 a )2+ v 2 a /2\u2212GM/a a2v 2 a /2 = GM a2v 2 a \u00b1( GM a2v 2 a \u2212 1 a ). I\u2019m not going to discuss the algebra from here on; you know how to solve a quadratic equation, and there are two solutions for b : one of them is b equals a , it turns out\u2014and that\u2019s happy, because if you look at Eq. (3.2) you see it\u2019s obvious that if b equals a , the equation will match. (Of course, that doesn\u2019t mean that b is a .) With the other solution, we get a formula for b in terms of a , which is given here: b= a 2GM av 2 a \u22121 . The question is whether we can write the formula in such a way that the relationship of v a to the escape velocity at the distance a can readily be seen. Notice that by Eq. (3.1) 2GM/a is the square of the escape velocity, and therefore we can write the formula this way: b= a ( v escape / v a ) 2 \u22121 . (3.8) That\u2019s the final result, and it is rather interesting. Suppose, first, that v a is less than the escape velocity. Under those circumstances, we\u2019d expect the particle not to escape, so we should get a sensible value for b . And sure enough, if v a is less than v escape , then v escape / v a is greater than 1 , and the square is also greater than 1 ; taking away 1 , you get some nice positive number, and a divided by that number tells us b . To check roughly how accurate our analysis is, a good thing to play around with is the numerical calculation we made of the orbit in the ninth lecture,2 to see how close the b that we calculated then agrees with the b we get from Eq. (3.8). Why should they not agree perfectly? Because, of course, the numerical method of integration treats time as little blobs instead of continuous, and therefore it isn\u2019t perfect. Anyway, that\u2019s how we get b when v a is less than v escape . (Incidentally, knowing b and knowing a , we know the semi-major axis of the ellipse, and thus we could figure out the period of the orbit from Eq. (3.2), if we wanted to.) But the interesting thing is this: suppose, first, that v a is exactly the velocity of escape. Then v escape / v a is 1 , and Eq. (3.8) says that then b is infinite. That means that the orbit is not an ellipse; it means that the orbit goes off to infinity. (It can be shown that it is a parabola, in this special case.) So, it turns out, that if you\u2019re anywhere near a star or a planet, and no matter what direction you\u2019re moving, if you have the velocity of escape, you\u2019ll escape, all right\u2014you won\u2019t get caught, even though you\u2019re not pointed in the right direction. Still another question is, what happens if v a exceeds the velocity of escape? Then v escape / v a is less than 1 , and b turns out negative\u2014and that doesn\u2019t mean anything; there is no real b . Physically, that solution looks more like this: with a very high velocity, much higher than the velocity of escape, a particle coming in is deflected\u2014but its orbit is not an ellipse. It is, in fact, a hyperbola. So the orbits of objects moving around the sun are not only ellipses, as Kepler thought, but the generalization to higher speeds includes ellipses, parabolas, and hyperbolas. (We didn\u2019t prove here that they are ellipses, parabolas, or hyperbolas, but that\u2019s the answer to the problem.) This hyperbolic orbit business is interesting, and has a very interesting historical application, which I\u2019d like to show you; it is illustrated in Figure 3-5. We take the limiting case of an enormously high speed, and a relatively small force. That is, the object is going by so fast that in the first approximation it goes in a straight line. (See Fig. 3-5.) Suppose we have a nucleus with charge +Z q el (where \u2212 q el is the electron charge), and a charged particle that is moving past it at a distance b \u2014an ion of some kind (it was originally done with an alpha particle), it doesn\u2019t make any difference; you can put in your own case\u2014let\u2019s take a proton of mass m , velocity v , and charge + q el (for an alpha particle, it would be +2 q el ). The proton doesn\u2019t go quite in a straight line, but is deflected through a very small angle. The question is, what\u2019s the angle? Now, I\u2019m not going to do it exactly, but roughly\u2014to get some idea of how the angle varies with b . (I\u2019ll do it nonrelativistically, although it\u2019s just as easy to take relativity into account\u2014just a minor change that you can figure out for yourself.) Of course, the bigger b is, the smaller the angle ought to be. And the question is, does the angle decrease as the square of b , the cube of b , as b , or what? We want to get some idea about this. (This is, as a matter of fact, the way you start on any complicated or unfamiliar problem: you first get a rough idea; then you go back when you understand it better and do it more carefully.) So the first rough analysis will run something like this: as the proton flies by, there are sideways forces on it from the nucleus\u2014of course, there are forces in other directions too, but it\u2019s the sideways force that makes it deflect so instead of going straight as it did before, it now has an upward component of velocity. In other words, it acquired some upward momentum as a result of the forces in that direction. Now, how big is the upward force? Well, it changes as the proton goes along, but more or less, roughly, the force has to depend on b , and the maximum force (as the proton is passing the central position) is vertical force\u2248 Z q 2 el 4\u03c0 \u03f5 0 b 2 = Z e 2 b 2 . (3.9) (I substituted e 2 for q 2 el 4\u03c0 \u03f5 0 so I can write the equations quicker.3) If I knew how long that force acted, I could estimate the momentum that was delivered. How long does the force act? Well, it doesn\u2019t act when the proton is a mile away, but, roughly speaking, a force of that general order of magnitude is acting as long as the proton is in the general neighborhood. How far? More or less, when it\u2019s passing within a distance b of the nucleus. So the time during which the force acts is of an order of magnitude of the distance b divided by the speed, v . (See Fig. 3-6.) time\u2248 b v . (3.10) Newton\u2019s law says that force equals the rate of change of the momentum\u2014so, if we multiply the force by the time over which it\u2019s acting, we get the change in momentum. Therefore, the vertical momentum acquired by the proton is vertical momentum =vertical force\u22c5time \u2248 Z e 2 b 2 \u22c5 b v = Z e 2 bv . (3.11) That\u2019s not exactly right; ultimately, when we do an exact integration of this thing, there may be a numerical factor of 2.716 or something\u2014but for now, we\u2019re just trying to find the order of magnitude as it depends on the various letters. The horizontal momentum that the particle has when it comes out is, for all intents and purposes, the same as when it went in, which is mv : horizontal momentum=mv. (3.12) (This is the only thing you need to change to take relativity into account.) Now, then, what is the angle of deflection? Well, we know the \u201cup\u201d momentum is Z e 2 /bv and the \u201csideways\u201d momentum is mv , and the proportion of \u201cup\u201d to \u201csideways\u201d is the tangent of the angle\u2014or, practically, the angle itself, since it\u2019s so small. (See Fig. 3-7.) \u03b8\u2248 Z e 2 bv /mv= Z e 2 bm v 2 (3.13) Eq. (3.13) shows how the angle depends on the velocity, on the mass, on the charge, and on the so-called \u201cimpact parameter\u201d\u2014the distance b . When you actually calculate \u03b8 by integrating the force instead of just estimating it, it turns out that there is indeed a numerical factor missing, and that factor is exactly 2 . I don\u2019t know whether you\u2019ve gotten that far in integrations or not: if you can\u2019t do it, all right; it\u2019s not essential, but the correct angle is \u03b8= 2Z e 2 bm v 2 . (3.14) (Actually, you can work the formula out exactly for any hyperbolic orbit, but never mind: you can understand everything for this case, for small angles. Of course Eq. (3.14) is not true when the angles get to 30 or 50 degrees; then we\u2019ve made too rough an approximation.) Now, this has a very interesting application in the history of physics\u2014it is the way Rutherford discovered that the atom has a nucleus. He had a very simple idea: by making an arrangement in which alpha particles from a radioactive source would go through a slit\u2014so he knew that they were going in a definite direction\u2014and letting them impinge on a zinc sulfide screen, he could see scintillations in a single spot right behind the slit. But if he put a gold foil between the slit and the screen, the scintillations would sometimes appear elsewhere! (See Fig. 3-8.) Of course, the reason was, the alpha particles coming past the little nuclei in the gold foil were deflected. By measuring the angles of deflection and using Eq. (3.14) in reverse, Rutherford was able to obtain the distances, b , required to produce that much deflection. The great surprise was, these distances were very much smaller than an atom. Before Rutherford made this experiment it was believed that the positive charge of the atom was not concentrated at a point in the center, but distributed uniformly throughout. Under those circumstances, the alpha particle could never get the big force needed to make the observed deflections, because if it were outside the atom it wouldn\u2019t be close enough to the charge, and if it were inside the atom there\u2019d be as much charge above it as below it, and that wouldn\u2019t produce enough force. So it was demonstrated by the large deflections that there were sources of strong electric force inside the atom, and then it was guessed that there must be a central point where all the positive charges are, and by observing the deflections as far out as possible, and how many times they occurred, one could obtain an estimate of how small b might be, and ultimately obtain the size of the nucleus\u2014and the size of the nucleus turned out to be 10 \u22125 times smaller than the atom! This was the way that it was discovered that nuclei exist. Now, the next problem I want to talk about is completely different: it has to do with rocket propulsion, and I\u2019m going to take a rocket floating around in empty space first\u2014forgetting all about gravity, and so on. The rocket\u2019s built to hold a lot of fuel; it\u2019s got some kind of engine by which it squirts fuel out the back\u2014and from the point of view of the rocket, it\u2019s always squirting it out at the same speed. It doesn\u2019t turn on and off; we start it, and it just keeps squirting stuff out the rear end until it runs out. We\u2019ll suppose that the stuff is squirted out at a rate of (that\u2019s mass per second), and that it goes out at velocity u . (See Fig. 3-9.) You might say, \u201cAren\u2019t those the same thing? You know the mass per second; isn\u2019t that the velocity?\u201d No. I can dump a certain amount of mass per second by taking a great big lump of stuff and putting it quietly out each time, or I can take the same mass and throw it out each time. So, you see, they\u2019re two independent ideas. Now, the question is, how much velocity will the rocket accumulate after a time? Suppose, for instance, that it uses up 90 percent of its weight: that is, when it\u2019s finished using all its fuel the mass of the shell that\u2019s left is one-tenth as great as the mass of the whole thing loaded before it started. What speed will the rocket acquire? Anybody in his right mind would say that it is impossible to get any faster than the speed u , but that\u2019s not true, as you\u2019ll see in a moment. Maybe you\u2019ll say that\u2019s perfectly obvious; well, all right. But it is, in fact, true for the following reason. Let\u2019s look at the rocket at any moment, moving at any speed at all. If we move along with the rocket and watch for a time \u0394t , what do we see? Well, there\u2019s a certain mass \u0394m that goes out\u2014which is, of course, the rocket\u2019s rate of loss \u03bc times the time \u0394t . And the velocity that this mass comes out at is u . (See Fig. 3-10.) Now, the moment after this mass is thrown back, how fast is the rocket moving forward? The speed at which it\u2019s moving forward must be such that the total momentum is conserved. That is to say, it picks up a little speed \u0394v , in such a manner that, if the mass of the rocket shell and remaining fuel at that instant is m , then m times \u0394v matches the outgoing momentum during that time, which is \u0394m times u . And that\u2019s all there is to the theory of rockets; that\u2019s the fundamental rocket equation: m\u0394v=u\u0394m. (3.15) We could put in \u03bc\u0394t for \u0394m and by fiddling around, find out how long it takes to get up to a given velocity,4 but our problem is to find the final velocity, and we can do that directly from Eq. (3.15): \u0394v \u0394m = u m dv=u dm m . (3.16) In order to find the velocity that the rocket acquires, starting from rest, you integrate u(dm/m) from the initial mass to the final mass. Now, u was assumed constant, so it can be taken outside the integral, and we have, therefore, v=u \u222b m initial m final dm m . (3.17) The integral of dm/m may or may not be known to you; let\u2019s suppose that it isn\u2019t. You say, \u201c 1/m is such a simple function, I must know the derivative: I\u2019ll fiddle around with differentiating things until I find it.\u201d But it turns out you can\u2019t find anything that\u2019s simple\u2014in terms of m , powers of m , and things like that\u2014which, when you differentiate it, gives 1/m . So, not knowing how to do it that way, we\u2019ll do it a different way. We\u2019ll do it by numerical integration. Remember: Whenever you\u2019re stuck in a mathematical analysis, you can always do it by arithmetic! Let\u2019s suppose that the initial mass is 10 , and take as a simple approximation that we drop one unit of mass at a time. Furthermore, let\u2019s measure all the velocities in terms of the unit u , because then we will have simply \u0394v=\u0394m/m . We want to find the total accumulated velocity. Well, let\u2019s see: during the first dropping of one unit of mass, how much speed is acquired? Well, that\u2019s easy; it\u2019s \u0394v= \u0394m m = 1 10 . \u0394 1 But that isn\u2019t exactly right, because while you\u2019re spitting one unit of mass out, the mass that\u2019s reacting is not 10 ; when you\u2019re all finished spitting it out, it\u2019s only 9 . You see, after \u0394m is shot out, the mass of the rocket is only m\u2212\u0394m so maybe it would be better to put \u0394v= \u0394m m\u2212\u0394m = 1 9 . \u0394 1 But that isn\u2019t exactly right either. It would be true if the rocket were really throwing out blobs, but it\u2019s not\u2014it\u2019s dumping mass continuously. At the beginning the mass of the rocket is 10 . At the end of the one unit going out, the mass is only 9 \u2014so on average, it\u2019s more or less like 9.5 . During the time the first unit is dropped, we\u2019ll say that is the effective average inertia that reacts against the \u0394m=1 , so that the rocket receives an impulse \u0394v equal to 1/9.5 : \u0394v\u2248 \u0394m m\u2212\u0394m/2 = 1 9.5 . \u0394 1 It helps to put these halves in, because then you need fewer steps to get high accuracy. Of course, it still isn\u2019t exact. If we wanted to do it more carefully, we could use smaller blobs of mass, like \u0394m=1/10 , and do much more analysis. But we\u2019ll do it roughly, with \u0394m=1 and keep on going. Now the mass of the rocket is only 9 . We drop another unit off the rear end of the thing, and we find next that \u0394v is \u20261/9 ? No. \u20261/8 ? No! It\u2019s \u0394v=1/8.5 because the mass has been continuously changing from 9 to 8 , and on the average it was roughly 8.5 . For the next unit we get \u0394v=1/7.5 , and so we discover that the answer is the sum of 1/9.5 , 1/8.5 , 1/7.5 , 1/6.5 , ta, ta, ta, ta, tum\u2014to the end. With the last step we go from 2 units of mass down to 1 , on the average the mass is 1.5 , and we\u2019re left with one unit of mass. Finally, we calculate all these ratios (which takes only a moment to do; these numbers are all honest; it\u2019s easy to figure them out) and merely add them together to get the answer, 2.268 , which means that the final velocity v is 2.268 times faster than the velocity of the exhaust u . That\u2019s the answer to this one\u2014nothin\u2019 to it! 1/9.5 1/8.5 1/7.5 1/6.5 1/5.5 1/4.5 1/3.5 1/2.5 1/1.5 0.106 0.118 0.133 0.154 0.182 0.222 0.286 0.400 0.667 \u2212 \u2212 \u2212 \u2212 \u2212 2.268 v\u22482.268u (3.18) Now you might say, \u201cI don\u2019t like the accuracy here\u2014this is a little sloppy. It\u2019s all very well to say, \u2018in the first step the mass changes from 10 to 9 , so it\u2019s about 9.5 \u2019. But in the last step, it changes from 2 to 1 and you\u2019ve taken that all on the average of 1.5 . Wouldn\u2019t it be better to split the last step, dropping half a unit at a time, to get a little bit better accuracy?\u201d (This is a technical point of arithmetic.) a technical point of arithmetic.) Let\u2019s see. While the first half a unit goes out, the mass drops from 2 to 1.5 ; on average it\u2019s 1.75 , so I take 1/1.75 times a half unit for my \u0394m/m . Then I do the same thing for the second half a unit; the mass drops from 1.5 to 1 , averaging 1.25 : \u0394v \u2248 0.5 (2+1.5)/2 + 0.5 (1.5+1)/2 = 0.5 1.75 + 0.5 1.25 =0.686. So you can make an improvement in the last step\u2014you can improve all the rest of them too, the same way, if you want to go to the trouble\u2014and it comes out 0.686 instead of 0.667 , which means that our answer was a little bit low. When you figure it out better it comes out v\u22482.287u . The last digit is really not reliable, but our estimate is pretty close, and the exact answer isn\u2019t going to be far from 2.3 . Now, I must tell you, that because the integral \u222b x 1 dm/m is such a simple function and comes up in so many problems, people have made tables of it and given it a name: it\u2019s called the natural logarithm, ln(x) . And if you ever look up ln(10) in a table of natural logs, you will find it\u2019s actually 2.302585 : v=u \u222b 10 1 dm m =ln(10)u=2.302585u. (3.19) You can get that many digits of accuracy by the same technique we used, provided you use a much finer spacing like \u0394m=1/1,000 or so, instead of 1 \u2014and that\u2019s precisely what\u2019s been done. Anyway, we did pretty well in no time at all, without knowing anything, and without looking in tables. So, I keep emphasizing that in emergencies you can always do arithmetic. Now, this question of rocket propulsion is interesting. You\u2019ll notice, first of all, that the speed that is finally acquired is proportional to u , the speed of the exhaust. Therefore all kinds of effort has been put into trying to get the exhaust gases to go out as fast as possible. If you burn hydrogen peroxide with this and that, or oxygen with hydrogen or something, then you get a certain chemical energy generated per gram of fuel. And if you design the nozzles and whatnot correctly, you can get a high percentage of that chemical energy to go into the outgoing velocity. But you can\u2019t get more than 100 percent, naturally, and so there\u2019s an upper limit for a given fuel as to what speed can be acquired by the most ideal design with a given mass ratio, because there\u2019s an upper limit to the value of u that can be acquired from a given chemical reaction. Consider two reactions, a and b , which have the same energy per atom liberated, but atoms of different masses, m a and m b . Then, if u a and u b are the exhaust velocities, we have m a u 2 a 2 = m b u 2 b 2 . (3.20) The velocities will therefore be higher for the reaction with the lighter atom, because whenever m a < m b , Eq. (3.20) implies that u a > u b . That\u2019s why most of the fuels used in rockets are light materials. The engineers would like to burn helium with hydrogen, but unfortunately that mixture doesn\u2019t burn, so for instance, they make do with oxygen and hydrogen. Instead of using chemical reactions, another proposal is to make a device by which you ionize atoms, and accelerate them electrically. Then you can get a terrific velocity, because you can accelerate the ions as much as you want. And so I have another problem here for you. Suppose we have a so-called ion propulsion rocket. Out of the rear end we are going to squirt cesium ions, accelerated by an electrostatic accelerator. The ions start at the front of the rocket, and a voltage V 0 has been applied between the front and the rear end\u2014in our particular problem, it\u2019s not an unreasonable voltage\u2014I took V 0 =200,000 volts. Now, the problem is, what thrust is this going to produce? It\u2019s a different problem than we had before, which was to find how fast would the rocket go. This time, we would like to know what force is produced if the rocket is held in a test stand. (See Fig. 3-11.) The way it works is this: Suppose that in a time \u0394t the rocket were to shoot an amount of mass \u0394m=\u03bc\u0394t at velocity u . Then the momentum going out is (\u03bc\u0394t)u ; since action equals reaction, that much momentum is being poured into the rocket. In the other problem the rocket was in space, and so it took off. This time, it\u2019s held by the test stand, and the momentum per second that is acquired by the ions is the force that must be applied to hold the rocket in place. The total amount of momentum per second acquired by the ions is (\u03bc\u0394t)u/\u0394t . So the thrust force of the rocket is simply \u03bcu , the mass per second that is liberated times the velocity at which it goes out. And therefore all I have to do is figure out for my cesium ion what mass per second would go out, and at what velocity: thrust = \u0394(momentum out) \u0394t =(\u03bc\u0394t)u/\u0394t =\u03bcu. (3.21) We work out the velocity of the ions first, as follows: the kinetic energy of a cesium ion coming out of the rocket is equal to its charge times the voltage difference across the accelerator. That\u2019s what voltage is: it\u2019s like potential energy, just like field is like force\u2014you just have to multiply by the charge to get the potential energy difference. The cesium ion is univalent\u2014it has one electron charge\u2014so m Cs + u 2 2 u = q el V 0 = 2 V 0 q el m Cs + \u2212 \u2212 \u2212 \u2212 \u2212 \u2212 \u2212 \u2212 \u221a (3.22) Now, let\u2019s figure out this q el / m Cs + . The charge per mole5 is that famous number 96,500 coulombs per mole. The mass per mole is what\u2019s called the atomic weight, and if you look it up in the periodic table, for cesium it\u2019s 0.133 kilograms per mole. You say, \u201cWhat about these moles? I want to get rid of them!\u201d They\u2019re already gotten rid of: all we need is the ratio between the charge and the mass. I can measure that in one atom, or in one mole of atoms, and it\u2019s the same ratio. So we get for the outgoing speed u = 2 V 0 q el m Cs + \u2212 \u2212 \u2212 \u2212 \u2212 \u2212 \u2212 \u2212 \u221a = 400,000\u22c5 96,500 0.133 \u2212 \u2212 \u2212 \u2212 \u2212 \u2212 \u2212 \u2212 \u2212 \u2212 \u2212 \u2212 \u2212 \u221a \u22485.387\u00d7 10 5 m/sec. (3.23) Incidentally, 5\u00d7 10 5 m/s is much faster than you can ever get by a chemical reaction. Chemical reactions correspond to voltages of the order of one volt, and so this ion propulsion rocket provides 200,000 times more energy than a chemical rocket. Now, that\u2019s fine, but we don\u2019t want just the velocity; we want the thrust. And so we have to multiply the velocity by the mass per second, \u03bc . I want to give the answer in terms of the current of electricity that is pouring out of the rocket\u2014because of course, that\u2019s proportional to the mass per second. So, I want to find out how much thrust there is per ampere of current. Suppose that one ampere is going out: how much mass is that? That\u2019s one coulomb per second, or 1/96,500 moles per second, because that\u2019s how many coulombs are in a mole. But one mole weighs 0.133 kilograms, so it\u2019s 0.133/96,500 kilograms per second, and that\u2019s the rate of flow of the mass: 1 ampere=1 coulomb/sec \u2192 1 96,500 mole/sec \u03bc=( 1 96,500 mole/sec)\u22c5(0.133 kg/mole) =1.378\u00d7 10 \u22126 kg/sec. (3.24) I multiply \u03bc by the speed, u , to find the thrust per ampere, and the result is thrust per ampere=\u03bcu =(1.378\u00d7 10 \u22126 )\u22c5(5.387\u00d7 10 5 ). \u22480.74 newtons/ampere. (3.25) So, we get less than three-quarters of a newton per ampere\u2014that\u2019s very poor, lousy, low. An ampere isn\u2019t a hell of a lot of current, but 100 amperes or 1,000 amperes is quite a job, and it still hardly gives any push. It\u2019s hard to get a reasonable amount of ions. Now let\u2019s figure out how much energy is being consumed. When the current is 1 ampere, 1 coulomb of charge per second is dropping through a potential of 200,000 volts. To get the energy (in joules) I multiply the charge by the voltage because volts, really, are nothing but energy per unit charge (joules/coulumb). Therefore 1\u00d7200,000 joules per second is consumed, which is 200,000 watts: 1 coulomb/sec\u00d7200,000 volts =200,000 watts. (3.26) We get only 0.74 newtons out of 200,000 watts, which is a pretty punk machine, from an energetic standpoint. The thrust to power ratio is only 3.7\u00d7 10 \u22126 newtons per watt\u2014which is very, very weak: thrust/power \u2248 0.74 200,000 =3.7\u00d7 10 \u22126 newtons/watt. (3.27) So, although it\u2019s a nice idea, it takes an awful lot of energy to get anywhere in this thing! Another rocket has been proposed on the basis that the faster you can push the exhaust out the better things are, and so why not push out photons\u2014they\u2019re the fastest thing on Earth\u2014shoot light out the back! You get out there at the rear end of the rocket, you turn on a flashlight, and you get a push! However, you can appreciate that you can pour an awful lot of light out without getting much of a push: you know from experience that when you turn on a flashlight, you don\u2019t find yourself thrown off your feet; even if you turn on a 100 -watt bulb and put a focuser on it, you don\u2019t feel a damn thing! So it\u2019s very unlikely that we\u2019re going to get much push per watt. Nevertheless, let\u2019s try to figure out the thrust-to-power ratio for a photon rocket. Each photon we throw out the back carries a certain momentum p , and a certain energy E , and the relationship, for photons, is that the energy is the momentum times the speed of light: E=pc. (3.28) So for a photon the momentum per energy is equal to 1/c . That means that, no matter how many photons we use, the momentum we throw out per second has a definite ratio to the energy we throw out per second\u2014and that ratio is unique and fixed; it\u2019s 1 over the speed of light. But the momentum per second thrown out is the force needed to hold the rocket in place, while the energy per second thrown out is the power of the engine generating the photons. So the thrust-to-power ratio is also 1/c (c being 3\u00d7 10 8 ), or 3.3\u00d7 10 \u22129 newtons per watt, which is a thousand times worse than the cesium ion accelerator, and a million times worse than a chemical engine! These are some of the points of rocket design. I am showing you all these rather complicated semi-new things so you can appreciate that you have learned something, and that you can now understand a great deal of what goes on in the world. Now, the next problem that I cooked up, to show you how you can do things, is the following. In the Kellogg Laboratory,6 we have a Van de Graaff generator that generates protons at 2 million volts. The potential difference is generated electrostatically by a moving belt. The protons drop through this potential, pick up a lot of energy, and come out in a beam. Suppose, for certain experimental reasons, we would like the protons to come out at a different angle, so that we need to deflect them. Now, the most practical way to do this is with a magnet; nevertheless, we can also work out how it can be done electrically\u2014they have been made that way\u2014and that\u2019s what we\u2019re going to do now. We take a pair of curved plates that are very close together compared to the radius of their curvature\u2014say they\u2019re about d=1 cm apart, separated by insulators. The plates are curved in a circle, and we put as high a voltage as we can across them, from a voltage supply, so that we get an electric field in between that deflects the beam radially, around the circle. (See Fig. 3-12.) In fact, if you put much more than 20 kilovolts across a 1 cm gap in a vacuum, you have breakdown troubles\u2014whenever there is a little leak, dirt gets in and it\u2019s very hard to keep it from sparking over\u2014so let\u2019s say we put 20 kilovolts across the plates. (However, I\u2019m not going to do this problem with numbers; I\u2019m just explaining it all with the numbers, so I\u2019ll call the voltage across the plates V p .) Now, we would like to know: to what radius of curvature do we have to bend the plates so that 2 MeV protons will be deflected between them? This simply depends on the centripetal force. If m is the mass of a proton, then Eq. (2.17) tells us that m v 2 /R equals the force that\u2019s needed to pull it in. And the force that we have pulling it in is the charge of the proton\u2014which is again our famous q el \u2014multiplied by the electric field E that\u2019s in between the plates: q el E=m v 2 R . (3.29) This equation is Newton\u2019s law: you have force equals mass times acceleration. In order to use it, however, you\u2019ve got to know the velocity of the protons coming out of the Van de Graaf generator. Now, information on the velocity of the protons comes from our knowledge of how much potential they have fallen through\u2014 2 million volts\u2014which I\u2019ll call V 0 . The conservation of energy tells us that the kinetic energy of the proton, m v 2 /2 , equals the charge of the proton multiplied by the voltage through which it has fallen. We can calculate v 2 directly from this: m v 2 2 v 2 = q el V 0 = 2 q el V 0 m (3.30) When I substitute v 2 from Eq. (3.30) into Eq. (3.29), I get q el E=m ( 2 q el V 0 m ) R = 2 q el V 0 R R= 2 V 0 E . (3.31) So if I knew what the electric field between the plates was, I could easily find the radius\u2014because of this simple relationship between the electric field, the voltage at which the protons started, and the curvature of the plates. Well, what is the electric field? If the plates don\u2019t bend too much, the electric field is approximately the same everywhere between them. And when I put a voltage across the plates, there\u2019s an energy difference between a charge on one plate and a charge on the other. The energy difference per unit charge is the voltage difference\u2014that\u2019s what voltage means. Now, if I carried a charge q from one plate to the other through a constant electric field E the force on the charge would be qE and the energy difference would be qEd , where d is the distance between the plates. By multiplying force times distance I get energy\u2014or by multiplying field times distance, I get potential. So the voltage on the plates is Ed : V p = energy difference charge = qEd q =Ed E= V p d . (3.32) I have therefore substituted E from Eq. (3.32) into Eq. (3.31) and by fiddling around, I get the formula for the radius\u2014it\u2019s 2 V 0 / V p times the distance between the plates: R= 2 V 0 ( V p /d) =2 V 0 V p d. (3.33) In our particular problem, the ratio of V 0 to V p \u2014 2 million volts to 20 kilovolts\u2014is 100 to 1 , and d=1 centimeter. Therefore the radius of curvature should be 200 cm, or 2 meters. An assumption that\u2019s been made here is that the electric field between the plates is constant. If the electric field isn\u2019t constant, how good is our deflector? Pretty good anyway, because with a 2 -meter radius, the plates are almost flat, so the field is nearly constant, and if we\u2019ve got the beam right in the middle, it\u2019s just right. But even if we don\u2019t, it\u2019s very good because if the field is too strong on one side, it\u2019ll be too weak on the other, and those things will compensate, nearly. In other words, by using the field near the middle, we\u2019re getting an excellent estimate: even if it\u2019s not perfect, it\u2019s damn close for such dimensions; at R/d=200 to 1 , it\u2019s almost exact. I have no more time, but I\u2019ll ask you to stay just a minute extra, so I can tell you about one more problem: this is historically the way the mass of the pi meson ( \u03c0 ) was determined. In fact, the pi meson was first discovered on photographic plates in which there were tracks of mu mesons7 ( \u03bc ): some unknown particle had come in and stopped, and where it stopped, there was a little track coming off whose properties were found to be those of a mu meson. (Mu mesons were known before, but the pi meson was just discovered from these pictures.) It was presumed that a neutrino ( \u03bd ) went off in the opposite direction (leaving no track, because it is neutral). (See Fig. 3-13.) The rest energy of the \u03bc was known to be 105 MeV, and its kinetic energy was found from the properties of the track to be 4.5 MeV. Supposing all that, how can we find the mass of the \u03c0 ? (See Fig. 3-14.) Let\u2019s suppose that the \u03c0 is at rest, and that it disintegrates into a \u03bc and a neutrino. We know the rest energy of the \u03bc , as well as the kinetic energy of the \u03bc and therefore the total energy of the \u03bc . But we also need to know the energy of the neutrino because, by relativity, the mass of the \u03c0 times c squared is its energy, and all that energy goes into the \u03bc and the neutrino. You see, the \u03c0 disappears, and the \u03bc and the neutrino are left, and by the conservation of energy, the energy of the \u03c0 must be the energy of the \u03bc plus the energy of the neutrino: E \u03c0 = E \u03bc + E \u03bd . (3.34) So we need to calculate both the energy of the \u03bc and the energy of the neutrino. The energy of the \u03bc is easy; it\u2019s practically given: it\u2019s 4.5 MeV kinetic, added to the rest energy\u2014so you get E \u03bc =109.5 MeV. Now what\u2019s the energy of the neutrino? That\u2019s the hard one. But by the conservation of momentum, we know the momentum of the neutrino because it\u2019s exactly equal and opposite to the momentum of the \u03bc \u2014and that\u2019s the key. You see, I\u2019m running it backwards here: if we knew the momentum of the neutrino, we could probably figure out its energy. So, let\u2019s try. We calculate the momentum of the \u03bc from the formula E 2 = m 2 c 4 + p 2 c 2 , choosing a system of units for which c=1 so that E 2 = m 2 + p 2 . Then, for the momentum of the \u03bc we get p \u03bc = E 2 \u03bc \u2212 m 2 \u03bc \u2212 \u2212 \u2212 \u2212 \u2212 \u2212 \u2212 \u221a = (109.5 ) 2 \u2212(105 ) 2 \u2212 \u2212 \u2212 \u2212 \u2212 \u2212 \u2212 \u2212 \u2212 \u2212 \u2212 \u2212 \u2212 \u2212 \u221a \u224831 MeV. (3.35) But the momentum of the neutrino is equal and opposite, so\u2014not worrying about signs, only magnitude\u2014the momentum of the neutrino is also 31 MeV. What about its energy? Because the neutrino has zero rest mass, its energy equals its momentum times c . We talked about that for the \u201cphoton rocket.\u201d For this problem we let c=1 , so the energy of the neutrino is the same as its momentum, 31 MeV. Well, we\u2019re all finished: the energy of the \u03bc is 109.5 MeV, the energy of the neutrino is 31 MeV, so the total energy liberated in the reaction was 140.5 MeV\u2014all given by the rest mass of the \u03c0 : m \u03c0 = E \u03bc + E \u03bd \u2248109.5+31=140.5 MeV. (3.36) And this is the way that the mass of the \u03c0 was originally determined. That\u2019s all I have time for. Thank you. See you next term. Best of luck!"
    },
    {
        "input": "The Maxwell Equations",
        "output": "In this chapter we come back to the complete set of the four Maxwell equations that we took as our starting point in Chapter 1. Until now, we have been studying Maxwell\u2019s equations in bits and pieces; it is time to add one final piece, and to put them all together. We will then have the complete and correct story for electromagnetic fields that may be changing with time in any way. Anything said in this chapter that contradicts something said earlier is true and what was said earlier is false\u2014because what was said earlier applied to such special situations as, for instance, steady currents or fixed charges. Although we have been very careful to point out the restrictions whenever we wrote an equation, it is easy to forget all of the qualifications and to learn too well the wrong equations. Now we are ready to give the whole truth, with no qualifications (or almost none). The complete Maxwell equations are written in Table 18\u20131, in words as well as in mathematical symbols. The fact that the words are equivalent to the equations should by this time be familiar\u2014you should be able to translate back and forth from one form to the other. The first equation\u2014that the divergence of E is the charge density over \u03f50 \u2014is true in general. In dynamic as well as in static fields, Gauss\u2019 law is always valid. The flux of E through any closed surface is proportional to the charge inside. The third equation is the corresponding general law for magnetic fields. Since there are no magnetic charges, the flux of B through any closed surface is always zero. The second equation, that the curl of E is \u2212\u2202B/\u2202t , is Faraday\u2019s law and was discussed in the last two chapters. It also is generally true. The last equation has something new. We have seen before only the part of it which holds for steady currents. In that case we said that the curl of B is j/\u03f50c2 , but the correct general equation has a new part that was discovered by Maxwell. Until Maxwell\u2019s work, the known laws of electricity and magnetism were those we have studied in Chapters 3 through 17. In particular, the equation for the magnetic field of steady currents was known only as \u2207\u00d7B= j \u03f50c2 . Maxwell began by considering these known laws and expressing them as differential equations, as we have done here. (Although the \u2207 notation was not yet invented, it is mainly due to Maxwell that the importance of the combinations of derivatives, which we today call the curl and the divergence, first became apparent.) He then noticed that there was something strange about Eq. (18.1). If one takes the divergence of this equation, the left-hand side will be zero, because the divergence of a curl is always zero. So this equation requires that the divergence of j also be zero. But if the divergence of j is zero, then the total flux of current out of any closed surface is also zero. The flux of current from a closed surface is the decrease of the charge inside the surface. This certainly cannot in general be zero because we know that the charges can be moved from one place to another. The equation \u2207\u22c5j=\u2212 \u2202\u03c1 \u2202t has, in fact, been almost our definition of j . This equation expresses the very fundamental law that electric charge is conserved\u2014any flow of charge must come from some supply. Maxwell appreciated this difficulty and proposed that it could be avoided by adding the term \u2202E/\u2202t to the right-hand side of Eq. (18.1); he then got the fourth equation in Table 18\u20131: IV.c2\u2207\u00d7B= j \u03f50 + \u2202E \u2202t . It was not yet customary in Maxwell\u2019s time to think in terms of abstract fields. Maxwell discussed his ideas in terms of a model in which the vacuum was like an elastic solid. He also tried to explain the meaning of his new equation in terms of the mechanical model. There was much reluctance to accept his theory, first because of the model, and second because there was at first no experimental justification. Today, we understand better that what counts are the equations themselves and not the model used to get them. We may only question whether the equations are true or false. This is answered by doing experiments, and untold numbers of experiments have confirmed Maxwell\u2019s equations. If we take away the scaffolding he used to build it, we find that Maxwell\u2019s beautiful edifice stands on its own. He brought together all of the laws of electricity and magnetism and made one complete and beautiful theory. Let us show that the extra term is just what is required to straighten out the difficulty Maxwell discovered. Taking the divergence of his equation (IV in Table 18\u20131), we must have that the divergence of the right-hand side is zero: \u2207\u22c5 j \u03f5 0 +\u2207\u22c5 \u2202E \u2202t =0. (18.3) In the second term, the order of the derivatives with respect to coordinates and time can be reversed, so the equation can be rewritten as \u2207\u22c5j+ \u03f5 0 \u2202 \u2202t \u2207\u22c5E=0. (18.4) But the first of Maxwell\u2019s equations says that the divergence of E is \u03c1/ \u03f5 0 . Inserting this equality in Eq. (18.4), we get back Eq. (18.2), which we know is true. Conversely, if we accept Maxwell\u2019s equations\u2014and we do because no one has ever found an experiment that disagrees with them\u2014we must conclude that charge is always conserved. The laws of physics have no answer to the question: \u201cWhat happens if a charge is suddenly created at this point\u2014what electromagnetic effects are produced?\u201d No answer can be given because our equations say it doesn\u2019t happen. If it were to happen, we would need new laws, but we cannot say what they would be. We have not had the chance to observe how a world without charge conservation behaves. According to our equations, if you suddenly place a charge at some point, you had to carry it there from somewhere else. In that case, we can say what would happen. When we added a new term to the equation for the curl of E , we found that a whole new class of phenomena was described. We shall see that Maxwell\u2019s little addition to the equation for \u2207\u00d7B also has far-reaching consequences. We can touch on only a few of them in this chapter. As our first example we consider what happens with a spherically symmetric radial distribution of current. Suppose we imagine a little sphere with radioactive material on it. This radioactive material is squirting out some charged particles. (Or we could imagine a large block of jello with a small hole in the center into which some charge had been injected with a hypodermic needle and from which the charge is slowly leaking out.) In either case we would have a current that is everywhere radially outward. We will assume that it has the same magnitude in all directions. Let the total charge inside any radius r be Q(r) . If the radial current density at the same radius is j(r) , then Eq. (18.2) requires that Q decreases at the rate \u2202Q(r) \u2202t =\u22124\u03c0 r 2 j(r). (18.5) We now ask about the magnetic field produced by the currents in this situation. Suppose we draw some loop \u0393 on a sphere of radius r , as shown in Fig. 18\u20131. There is some current through this loop, so we might expect to find a magnetic field circulating in the direction shown. But we are already in difficulty. How can the B have any particular direction on the sphere? A different choice of \u0393 would allow us to conclude that its direction is exactly opposite to that shown. So how can there be any circulation of B around the currents? We are saved by Maxwell\u2019s equation. The circulation of B depends not only on the total current through \u0393 but also on the rate of change with time of the electric flux through it. It must be that these two parts just cancel. Let\u2019s see if that works out. The electric field at the radius r must be Q(r)/4\u03c0 \u03f5 0 r 2 \u2014so long as the charge is symmetrically distributed, as we assume. It is radial, and its rate of change is then \u2202E \u2202t = 1 4\u03c0 \u03f5 0 r 2 \u2202Q \u2202t . (18.6) Comparing this with Eq. (18.5), we see \u2202E \u2202t =\u2212 j \u03f5 0 . (18.7) In Eq. IV the two source terms cancel and the curl of B is always zero. There is no magnetic field in our example. As our second example, we consider the magnetic field of a wire used to charge a parallel-plate condenser (see Fig. 18\u20132). If the charge Q on the plates is changing with time (but not too fast), the current in the wires is equal to dQ/dt . We would expect that this current will produce a magnetic field that encircles the wire. Surely, the current close to the plate must produce the normal magnetic field\u2014it cannot depend on where the current is going. Suppose we take a loop \u0393 1 which is a circle with radius r , as shown in part (a) of the figure. The line integral of the magnetic field should be equal to the current I divided by \u03f5 0 c 2 . We have 2\u03c0rB= I \u03f5 0 c 2 . (18.8) This is what we would get for a steady current, but it is also correct with Maxwell\u2019s addition, because if we consider the plane surface S inside the circle, there are no electric fields on it (assuming the wire to be a very good conductor). The surface integral of \u2202E/\u2202t is zero. Suppose, however, that we now slowly move the curve \u0393 downward. We get always the same result until we draw even with the plates of the condenser. Then the current I goes to zero. Does the magnetic field disappear? That would be quite strange. Let\u2019s see what Maxwell\u2019s equation says for the curve \u0393 2 , which is a circle of radius r whose plane passes between the condenser plates [Fig. 18\u20132(b)]. The line integral of B around \u0393 2 is 2\u03c0rB . This must equal the time derivative of the flux of E through the plane circular surface S 2 . This flux of E , we know from Gauss\u2019 law, must be equal to 1/ \u03f5 0 times the charge Q on one of the condenser plates. We have c 2 2\u03c0rB= d dt ( Q \u03f5 0 ). (18.9) That is very convenient. It is the same result we found in Eq. (18.8). Integrating over the changing electric field gives the same magnetic field as does integrating over the current in the wire. Of course, that is just what Maxwell\u2019s equation says. It is easy to see that this must always be so by applying our same arguments to the two surfaces S 1 and S \u2032 1 that are bounded by the same circle \u0393 1 in Fig. 18\u20132(b). Through S 1 there is the current I , but no electric flux. Through S \u2032 1 there is no current, but an electric flux changing at the rate I/ \u03f5 0 . The same B is obtained if we use Eq. IV with either surface. From our discussion so far of Maxwell\u2019s new term, you may have the impression that it doesn\u2019t add much\u2014that it just fixes up the equations to agree with what we already expect. It is true that if we just consider Eq. IV by itself, nothing particularly new comes out. The words \u201cby itself\u201d are, however, all-important. Maxwell\u2019s small change in Eq. IV, when combined with the other equations, does indeed produce much that is new and important. Before we take up these matters, however, we want to speak more about Table 18\u20131. In Table 18\u20131 we have all that was known of fundamental classical physics, that is, the physics that was known by 1905. Here it all is, in one table. With these equations we can understand the complete realm of classical physics. First we have the Maxwell equations\u2014written in both the expanded form and the short mathematical form. Then there is the conservation of charge, which is even written in parentheses, because the moment we have the complete Maxwell equations, we can deduce from them the conservation of charge. So the table is even a little redundant. Next, we have written the force law, because having all the electric and magnetic fields doesn\u2019t tell us anything until we know what they do to charges. Knowing E and B , however, we can find the force on an object with the charge q moving with velocity v . Finally, having the force doesn\u2019t tell us anything until we know what happens when a force pushes on something; we need the law of motion, which is that the force is equal to the rate of change of the momentum. (Remember? We had that in Volume I.) We even include relativity effects by writing the momentum as p= m 0 v/ 1\u2212 v 2 / c 2 \u2212 \u2212 \u2212 \u2212 \u2212 \u2212 \u2212 \u2212 \u221a . If we really want to be complete, we should add one more law\u2014Newton\u2019s law of gravitation\u2014so we put that at the end. Therefore in one small table we have all the fundamental laws of classical physics\u2014even with room to write them out in words and with some redundancy. This is a great moment. We have climbed a great peak. We are on the top of K2\u2014we are nearly ready for Mount Everest, which is quantum mechanics. We have climbed the peak of a \u201cGreat Divide,\u201d and now we can go down the other side. We have mainly been trying to learn how to understand the equations. Now that we have the whole thing put together, we are going to study what the equations mean\u2014what new things they say that we haven\u2019t already seen. We\u2019ve been working hard to get up to this point. It has been a great effort, but now we are going to have nice coasting downhill as we see all the consequences of our accomplishment. Now for the new consequences. They come from putting together all of Maxwell\u2019s equations. First, let\u2019s see what would happen in a circumstance which we pick to be particularly simple. By assuming that all the quantities vary only in one coordinate, we will have a one-dimensional problem. The situation is shown in Fig. 18\u20133. We have a sheet of charge located on the yz -plane. The sheet is first at rest, then instantaneously given a velocity u in the y -direction, and kept moving with this constant velocity. You might worry about having such an \u201cinfinite\u201d acceleration, but it doesn\u2019t really matter; just imagine that the velocity is brought to u very quickly. So we have suddenly a surface current J ( J is the current per unit width in the z -direction). To keep the problem simple, we suppose that there is also a stationary sheet of charge of opposite sign superposed on the yz -plane, so that there are no electrostatic effects. Also, although in the figure we show only what is happening in a finite region, we imagine that the sheet extends to infinity in \u00b1y and \u00b1z . In other words, we have a situation where there is no current, and then suddenly there is a uniform sheet of current. What will happen? Well, when there is a sheet of current in the plus y -direction, there is, as we know, a magnetic field generated which will be in the minus z -direction for x>0 and in the opposite direction for x<0 . We could find the magnitude of B by using the fact that the line integral of the magnetic field will be equal to the current over \u03f5 0 c 2 . We would get that B=J/2 \u03f5 0 c 2 (since the current I in a strip of width w is Jw and the line integral of B is 2Bw ). This gives us the field next to the sheet\u2014for small x \u2014but since we are imagining an infinite sheet, we would expect the same argument to give the magnetic field farther out for larger values of x . However, that would mean that the moment we turn on the current, the magnetic field is suddenly changed from zero to a finite value everywhere. But wait! If the magnetic field is suddenly changed, it will produce tremendous electrical effects. (If it changes in any way, there are electrical effects.) So because we moved the sheet of charge, we make a changing magnetic field, and therefore electric fields must be generated. If there are electric fields generated, they had to start from zero and change to something else. There will be some \u2202E/\u2202t that will make a contribution, together with the current J , to the production of the magnetic field. So through the various equations there is a big intermixing, and we have to try to solve for all the fields at once. By looking at the Maxwell equations alone, it is not easy to see directly how to get the solution. So we will first show you what the answer is and then verify that it does indeed satisfy the equations. The answer is the following: The field B that we computed is, in fact, generated right next to the current sheet (for small x ). It must be so, because if we make a tiny loop around the sheet, there is no room for any electric flux to go through it. But the field B out farther\u2014for larger x \u2014is, at first, zero. It stays zero for awhile, and then suddenly turns on. In short, we turn on the current and the magnetic field immediately next to it turns on to a constant value B ; then the turning on of B spreads out from the source region. After a certain time, there is a uniform magnetic field everywhere out to some value x , and then zero beyond. Because of the symmetry, it spreads in both the plus and minus x -directions. The E -field does the same thing. Before t=0 (when we turn on the current), the field is zero everywhere. Then after the time t , both E and B are uniform out to the distance x=vt , and zero beyond. The fields make their way forward like a tidal wave, with a front moving at a uniform velocity which turns out to be c , but for a while we will just call it v . A graph of the magnitude of E or B versus x , as they appear at the time t , is shown in Fig. 18\u20134(a). Looking again at Fig. 18\u20133, at the time t , the region between x=\u00b1vt is \u201cfilled\u201d with the fields, but they have not yet reached beyond. We emphasize again that we are assuming that the current sheet and, therefore the fields E and B , extend infinitely far in both the y - and z -directions. (We cannot draw an infinite sheet, so we have shown only what happens in a finite area.) We want now to analyze quantitatively what is happening. To do that, we want to look at two cross-sectional views, a top view looking down along the y -axis, as shown in Fig. 18\u20135, and a side view looking back along the z -axis, as shown in Fig. 18\u20136. Suppose we start with the side view. We see the charged sheet moving up; the magnetic field points into the page for +x , and out of the page for \u2212x , and the electric field is downward everywhere\u2014out to x=\u00b1vt . Let\u2019s see if these fields are consistent with Maxwell\u2019s equations. Let\u2019s first draw one of those loops that we use to calculate a line integral, say the rectangle \u0393 2 shown in Fig. 18\u20136. You notice that one side of the rectangle is in the region where there are fields, but one side is in the region the fields have still not reached. There is some magnetic flux through this loop. If it is changing, there should be an emf around it. If the wavefront is moving, we will have a changing magnetic flux, because the area in which B exists is progressively increasing at the velocity v . The flux inside \u0393 2 is B times the part of the area inside \u0393 2 which has a magnetic field. The rate of change of the flux, since the magnitude of B is constant, is the magnitude times the rate of change of the area. The rate of change of the area is easy. If the width of the rectangle \u0393 2 is L , the area in which B exists changes by Lv\u0394t in the time \u0394t . (See Fig. 18\u20136.) The rate of change of flux is then BLv . According to Faraday\u2019s law, this should equal minus the line integral of E around \u0393 2 , which is just EL . We have the equation E=vB. (18.10) So if the ratio of E to B is v , the fields we have assumed will satisfy Faraday\u2019s equation. But that is not the only equation; we have the other equation relating E and B : c 2 \u2207\u00d7B= j \u03f5 0 + \u2202E \u2202t . (18.11) To apply this equation, we look at the top view in Fig. 18\u20135. We have seen that this equation will give us the value of B next to the current sheet. Also, for any loop drawn outside the sheet but behind the wavefront, there is no curl of B nor any j or changing E , so the equation is correct there. Now let\u2019s look at what happens for the curve \u0393 1 that intersects the wavefront, as shown in Fig. 18\u20135. Here there are no currents, so Eq. (18.11) can be written\u2014in integral form\u2014as c 2 \u222e \u0393 1 B\u22c5ds= d dt \u222b inside \u0393 1 E\u22c5nda. (18.12) The line integral of B is just B times L . The rate of change of the flux of E is due only to the advancing wavefront. The area inside \u0393 1 , where E is not zero, is increasing at the rate vL . The right-hand side of Eq. (18.12) is then vLE . That equation becomes c 2 B=Ev. (18.13) We have a solution in which we have a constant B and a constant E behind the front, both at right angles to the direction in which the front is moving and at right angles to each other. Maxwell\u2019s equations specify the ratio of E to B . From Eqs. (18.10) and (18.13), E=vB,andE= c 2 v B. 2 But one moment! We have found two different conditions on the ratio E/B . Can such a field as we describe really exist? There is, of course, only one velocity v for which both of these equations can hold, namely v=c . The wavefront must travel with the velocity c . We have an example in which the electrical influence from a current propagates at a certain finite velocity c . Now let\u2019s ask what happens if we suddenly stop the motion of the charged sheet after it has been on for a short time T . We can see what will happen by the principle of superposition. We had a current that was zero and then was suddenly turned on. We know the solution for that case. Now we are going to add another set of fields. We take another charged sheet and suddenly start it moving, in the opposite direction with the same speed, only at the time T after we started the first current. The total current of the two added together is first zero, then on for a time T , then off again\u2014because the two currents cancel. We have a square \u201cpulse\u201d of current. The new negative current produces the same fields as the positive one, only with all the signs reversed and, of course, delayed in time by T . A wavefront again travels out at the velocity c . At the time t it has reached the distance x=\u00b1c(t\u2212T) , as shown in Fig. 18\u20134(b). So we have two \u201cblocks\u201d of field marching out at the speed c , as in parts (a) and (b) of Fig. 18\u20134. The combined fields are as shown in part (c) of the figure. The fields are zero for x>ct , they are constant (with the values we found above) between x=c(t\u2212T) and x=ct , and again zero for x<c(t\u2212T) . In short, we have a little piece of field\u2014a block of thickness cT \u2014which has left the current sheet and is travelling through space all by itself. The fields have \u201ctaken off\u201d; they are propagating freely through space, no longer connected in any way with the source. The caterpillar has turned into a butterfly! How can this bundle of electric and magnetic fields maintain itself? The answer is: by the combined effects of the Faraday law, \u2207\u00d7E=\u2212\u2202B/\u2202t , and the new term of Maxwell, c 2 \u2207\u00d7B=\u2202E/\u2202t . They cannot help maintaining themselves. Suppose the magnetic field were to disappear. There would be a changing magnetic field which would produce an electric field. If this electric field tries to go away, the changing electric field would create a magnetic field back again. So by a perpetual interplay\u2014by the swishing back and forth from one field to the other\u2014they must go on forever. It is impossible for them to disappear.1 They maintain themselves in a kind of a dance\u2014one making the other, the second making the first\u2014propagating onward through space. We have a wave which leaves the material source and goes outward at the velocity c , which is the speed of light. But let\u2019s go back a moment. From a historical point of view, it wasn\u2019t known that the coefficient c in Maxwell\u2019s equations was also the speed of light propagation. There was just a constant in the equations. We have called it c from the beginning, because we knew what it would turn out to be. We didn\u2019t think it would be sensible to make you learn the formulas with a different constant and then go back to substitute c wherever it belonged. From the point of view of electricity and magnetism, however, we just start out with two constants, \u03f5 0 and c 2 , that appear in the equations of electrostatics and magnetostatics: \u2207\u22c5E= \u03c1 \u03f5 0 (18.14) and \u2207\u00d7B= j \u03f5 0 c 2 . (18.15) If we take any arbitrary definition of a unit of charge, we can determine experimentally the constant \u03f5 0 required in Eq. (18.14)\u2014say by measuring the force between two unit charges at rest, using Coulomb\u2019s law. We must also determine experimentally the constant \u03f5 0 c 2 that appears in Eq. (18.15), which we can do, say, by measuring the force between two unit currents. (A unit current means one unit of charge per second.) The ratio of these two experimental constants is c 2 \u2014just another \u201celectromagnetic constant.\u201d Notice now that this constant c 2 is the same no matter what we choose for our unit of charge. If we put twice as much \u201ccharge\u201d\u2014say twice as many proton charges\u2014in our \u201cunit\u201d of charge, \u03f5 0 would need to be one-fourth as large. When we pass two of these \u201cunit\u201d currents through two wires, there will be twice as much \u201ccharge\u201d per second in each wire, so the force between two wires is four times larger. The constant \u03f5 0 c 2 must be reduced by one-fourth. But the ratio \u03f5 0 c 2 / \u03f5 0 is unchanged. So just by experiments with charges and currents we find a number c 2 which turns out to be the square of the velocity of propagation of electromagnetic influences. From static measurements\u2014by measuring the forces between two unit charges and between two unit currents\u2014we find that c=3.00\u00d7 10 8 meters/sec. When Maxwell first made this calculation with his equations, he said that bundles of electric and magnetic fields should be propagated at this speed. He also remarked on the mysterious coincidence that this was the same as the speed of light. \u201cWe can scarcely avoid the inference,\u201d said Maxwell, \u201cthat light consists in the transverse undulations of the same medium which is the cause of electric and magnetic phenomena.\u201d Maxwell had made one of the great unifications of physics. Before his time, there was light, and there was electricity and magnetism. The latter two had been unified by the experimental work of Faraday, Oersted, and Amp\u00e8re. Then, all of a sudden, light was no longer \u201csomething else,\u201d but was only electricity and magnetism in this new form\u2014little pieces of electric and magnetic fields which propagate through space on their own. We have called your attention to some characteristics of this special solution, which turn out to be true, however, for any electromagnetic wave: that the magnetic field is perpendicular to the direction of motion of the wavefront; that the electric field is likewise perpendicular to the direction of motion of the wavefront; and that the two vectors E and B are perpendicular to each other. Furthermore, the magnitude of the electric field E is equal to c times the magnitude of the magnetic field B . These three facts\u2014that the two fields are transverse to the direction of propagation, that B is perpendicular to E , and that E=cB \u2014are generally true for any electromagnetic wave. Our special case is a good one\u2014it shows all the main features of electromagnetic waves. Now we would like to do something mathematical; we want to write Maxwell\u2019s equations in a simpler form. You may consider that we are complicating them, but if you will be patient a little bit, they will suddenly come out simpler. Although by this time you are thoroughly used to each of the Maxwell equations, there are many pieces that must all be put together. That\u2019s what we want to do. We begin with \u2207\u22c5B=0 \u2014the simplest of the equations. We know that it implies that B is the curl of something. So, if we write B=\u2207\u00d7A, (18.16) we have already solved one of Maxwell\u2019s equations. (Incidentally, you appreciate that it remains true that another vector A \u2032 would be just as good if A \u2032 =A+\u2207\u03c8 \u2014where \u03c8 is any scalar field\u2014because the curl of \u2207\u03c8 is zero, and B is still the same. We have talked about that before.) We take next the Faraday law, \u2207\u00d7E=\u2212\u2202B/\u2202t , because it doesn\u2019t involve any currents or charges. If we write B as \u2207\u00d7A and differentiate with respect to t , we can write Faraday\u2019s law in the form \u2207\u00d7E=\u2212 \u2202 \u2202t \u2207\u00d7A. \u2202 Since we can differentiate either with respect to time or to space first, we can also write this equation as \u2207\u00d7(E+ \u2202A \u2202t )=0. (18.17) We see that E+\u2202A/\u2202t is a vector whose curl is equal to zero. Therefore that vector is the gradient of something. When we worked on electrostatics, we had \u2207\u00d7E=0 , and then we decided that E itself was the gradient of something. We took it to be the gradient of \u2212\u03d5 (the minus for technical convenience). We do the same thing for E+\u2202A/\u2202t ; we set E+ \u2202A \u2202t =\u2212\u2207\u03d5. (18.18) We use the same symbol \u03d5 so that, in the electrostatic case where nothing changes with time and the \u2202A/\u2202t term disappears, E will be our old \u2212\u2207\u03d5 . So Faraday\u2019s equation can be put in the form E=\u2212\u2207\u03d5\u2212 \u2202A \u2202t . (18.19) We have solved two of Maxwell\u2019s equations already, and we have found that to describe the electromagnetic fields E and B , we need four potential functions: a scalar potential \u03d5 and a vector potential A , which is, of course, three functions. Now that A determines part of E , as well as B , what happens when we change A to A \u2032 =A+\u2207\u03c8 ? In general, E would change if we didn\u2019t take some special precaution. We can, however, still allow A to be changed in this way without affecting the fields E and B \u2014that is, without changing the physics\u2014if we always change A and \u03d5 together by the rules A \u2032 =A+\u2207\u03c8, \u03d5 \u2032 =\u03d5\u2212 \u2202\u03c8 \u2202t . (18.20) Then neither B nor E , obtained from Eq. (18.19), is changed. Previously, we chose to make \u2207\u22c5A=0 , to make the equations of statics somewhat simpler. We are not going to do that now; we are going to make a different choice. But we\u2019ll wait a bit before saying what the choice is, because later it will be clear why the choice is made. Now we return to the two remaining Maxwell equations which will give us relations between the potentials and the sources \u03c1 and j . Once we can determine A and \u03d5 from the currents and charges, we can always get E and B from Eqs. (18.16) and (18.19), so we will have another form of Maxwell\u2019s equations. We begin by substituting Eq. (18.19) into \u2207\u22c5E=\u03c1/ \u03f5 0 ; we get \u2207\u22c5(\u2212\u2207\u03d5\u2212 \u2202A \u2202t )= \u03c1 \u03f5 0 , \u2202 A which we can write also as \u2212 \u2207 2 \u03d5\u2212 \u2202 \u2202t \u2207\u22c5A= \u03c1 \u03f5 0 . (18.21) This is one equation relating \u03d5 and A to the sources. Our final equation will be the most complicated. We start by rewriting the fourth Maxwell equation as c 2 \u2207\u00d7B\u2212 \u2202E \u2202t = j \u03f5 0 , \u2202 E j and then substitute for B and E in terms of the potentials, using Eqs. (18.16) and (18.19): c 2 \u2207\u00d7(\u2207\u00d7A)\u2212 \u2202 \u2202t (\u2212\u2207\u03d5\u2212 \u2202A \u2202t )= j \u03f5 0 . \u2202 \u2202 A j The first term can be rewritten using the algebraic identity: \u2207\u00d7(\u2207\u00d7A)= \u2207(\u2207\u22c5A)\u2212 \u2207 2 A ; we get \u2212 c 2 \u2207 2 A + c 2 \u2207(\u2207\u22c5A) + \u2202 \u2202t \u2207\u03d5+ \u2202 2 A \u2202 t 2 = j \u03f5 0 . (18.22) It\u2019s not very simple! Fortunately, we can now make use of our freedom to choose arbitrarily the divergence of A . What we are going to do is to use our choice to fix things so that the equations for A and for \u03d5 are separated but have the same form. We can do this by taking2 \u2207\u22c5A=\u2212 1 c 2 \u2202\u03d5 \u2202t . (18.23) When we do that, the two middle terms in A and \u03d5 in Eq. (18.22) cancel, and that equation becomes much simpler: \u2207 2 A\u2212 1 c 2 \u2202 2 A \u2202 t 2 =\u2212 j \u03f5 0 c 2 . (18.24) And our equation for \u03d5 \u2014Eq. (18.21)\u2014takes on the same form: \u2207 2 \u03d5\u2212 1 c 2 \u2202 2 \u03d5 \u2202 t 2 =\u2212 \u03c1 \u03f5 0 . (18.25) What a beautiful set of equations! They are beautiful, first, because they are nicely separated\u2014with the charge density, goes \u03d5 ; with the current, goes A . Furthermore, although the left side looks a little funny\u2014a Laplacian together with a \u2202 2 /\u2202 t 2 \u2014when we unfold it we see \u2202 2 \u03d5 \u2202 x 2 + \u2202 2 \u03d5 \u2202 y 2 + \u2202 2 \u03d5 \u2202 z 2 \u2212 1 c 2 \u2202 2 \u03d5 \u2202 t 2 =\u2212 \u03c1 \u03f5 0 . (18.26) It has a nice symmetry in x , y , z , t \u2014the \u22121/ c 2 is necessary because, of course, time and space are different; they have different units. Maxwell\u2019s equations have led us to a new kind of equation for the potentials \u03d5 and A but to the same mathematical form for all four functions \u03d5 , A x , A y , and A z . Once we learn how to solve these equations, we can get B and E from \u2207\u00d7A and \u2212\u2207\u03d5\u2212\u2202A/\u2202t . We have another form of the electromagnetic laws exactly equivalent to Maxwell\u2019s equations, and in many situations they are much simpler to handle. We have, in fact, already solved an equation much like Eq. (18.26). When we studied sound in Chapter 47 of Vol. I, we had an equation of the form \u2202 2 \u03d5 \u2202 x 2 = 1 c 2 \u2202 2 \u03d5 \u2202 t 2 , 2 2 and we saw that it described the propagation of waves in the x -direction at the speed c . Equation (18.26) is the corresponding wave equation for three dimensions. So in regions where there are no longer any charges and currents, the solution of these equations is not that \u03d5 and A are zero. (Although that is indeed one possible solution.) There are solutions in which there is some set of \u03d5 and A which are changing in time but always moving out at the speed c . The fields travel onward through free space, as in our example at the beginning of the chapter. With Maxwell\u2019s new term in Eq. IV, we have been able to write the field equations in terms of A and \u03d5 in a form that is simple and that makes immediately apparent that there are electromagnetic waves. For many practical purposes, it will still be convenient to use the original equations in terms of E and B . But they are on the other side of the mountain we have already climbed. Now we are ready to cross over to the other side of the peak. Things will look different\u2014we are ready for some new and beautiful views."
    },
    {
        "input": "Vectors",
        "output": "In this chapter we introduce a subject that is technically known in physics as symmetry in physical law. The word \u201csymmetry\u201d is used here with a special meaning, and therefore needs to be defined. When is a thing symmetrical\u2014how can we define it? When we have a picture that is symmetrical, one side is somehow the same as the other side. Professor Hermann Weyl has given this definition of symmetry: a thing is symmetrical if one can subject it to a certain operation and it appears exactly the same after the operation. For instance, if we look at a silhouette of a vase that is left-and-right symmetrical, then turn it 180\u2218 around the vertical axis, it looks the same. We shall adopt the definition of symmetry in Weyl\u2019s more general form, and in that form we shall discuss symmetry of physical laws. Suppose we build a complex machine in a certain place, with a lot of complicated interactions, and balls bouncing around with forces between them, and so on. Now suppose we build exactly the same kind of equipment at some other place, matching part by part, with the same dimensions and the same orientation, everything the same only displaced laterally by some distance. Then, if we start the two machines in the same initial circumstances, in exact correspondence, we ask: will one machine behave exactly the same as the other? Will it follow all the motions in exact parallelism? Of course the answer may well be no, because if we choose the wrong place for our machine it might be inside a wall and interferences from the wall would make the machine not work. All of our ideas in physics require a certain amount of common sense in their application; they are not purely mathematical or abstract ideas. We have to understand what we mean when we say that the phenomena are the same when we move the apparatus to a new position. We mean that we move everything that we believe is relevant; if the phenomenon is not the same, we suggest that something relevant has not been moved, and we proceed to look for it. If we never find it, then we claim that the laws of physics do not have this symmetry. On the other hand, we may find it\u2014we expect to find it\u2014if the laws of physics do have this symmetry; looking around, we may discover, for instance, that the wall is pushing on the apparatus. The basic question is, if we define things well enough, if all the essential forces are included inside the apparatus, if all the relevant parts are moved from one place to another, will the laws be the same? Will the machinery work the same way? It is clear that what we want to do is to move all the equipment and essential influences, but not everything in the world\u2014planets, stars, and all\u2014for if we do that, we have the same phenomenon again for the trivial reason that we are right back where we started. No, we cannot move everything. But it turns out in practice that with a certain amount of intelligence about what to move, the machinery will work. In other words, if we do not go inside a wall, if we know the origin of the outside forces, and arrange that those are moved too, then the machinery will work the same in one location as in another. We shall limit our analysis to just mechanics, for which we now have sufficient knowledge. In previous chapters we have seen that the laws of mechanics can be summarized by a set of three equations for each particle: m(d2x/dt2)=Fx, m(d2y/dt2)=Fy, m(d2z/dt2)=Fz. Now this means that there exists a way to measure x , y , and z on three perpendicular axes, and the forces along those directions, such that these laws are true. These must be measured from some origin, but where do we put the origin? All that Newton would tell us at first is that there is some place that we can measure from, perhaps the center of the universe, such that these laws are correct. But we can show immediately that we can never find the center, because if we use some other origin it would make no difference. In other words, suppose that there are two people\u2014Joe, who has an origin in one place, and Moe, who has a parallel system whose origin is somewhere else (Fig. 11\u20131). Now when Joe measures the location of the point in space, he finds it at x , y , and z (we shall usually leave z out because it is too confusing to draw in a picture). Moe, on the other hand, when measuring the same point, will obtain a different x (in order to distinguish it, we will call it x\u2032 ), and in principle a different y , although in our example they are numerically equal. So we have x\u2032 =x\u2212a, y\u2032 =y, z\u2032 =z. Now in order to complete our analysis we must know what Moe would obtain for the forces. The force is supposed to act along some line, and by the force in the x -direction we mean the part of the total which is in the x -direction, which is the magnitude of the force times this cosine of its angle with the x -axis. Now we see that Moe would use exactly the same projection as Joe would use, so we have a set of equations Fx\u2032 =Fx, Fy\u2032 =Fy, Fz\u2032 =Fz. These would be the relationships between quantities as seen by Joe and Moe. The question is, if Joe knows Newton\u2019s laws, and if Moe tries to write down Newton\u2019s laws, will they also be correct for him? Does it make any difference from which origin we measure the points? In other words, assuming that equations (11.1) are true, and the Eqs. (11.2) and (11.3) give the relationship of the measurements, is it or is it not true that (a) m(d2x\u2032 /dt2)=Fx\u2032 , (b) m(d2y\u2032 /dt2)=Fy\u2032 , (c) m(d2z\u2032 /dt2)=Fz\u2032 ? In order to test these equations we shall differentiate the formula for x\u2032 twice. First of all dx\u2032 dt = d dt (x\u2212a)= dx dt \u2212 da dt . Now we shall assume that Moe\u2019s origin is fixed (not moving) relative to Joe\u2019s; therefore a is a constant and da/dt=0 , so we find that dx\u2032/dt=dx/dt and therefore d2x\u2032/dt2=d2x/dt2; therefore we know that Eq. (11.4a) becomes m(d2x/dt2)=Fx\u2032. (We also suppose that the masses measured by Joe and Moe are equal.) Thus the acceleration times the mass is the same as the other fellow\u2019s. We have also found the formula for Fx\u2032 , for, substituting from Eq. (11.1), we find that Fx\u2032=Fx. Therefore the laws as seen by Moe appear the same; he can write Newton\u2019s laws too, with different coordinates, and they will still be right. That means that there is no unique way to define the origin of the world, because the laws will appear the same, from whatever position they are observed. This is also true: if there is a piece of equipment in one place with a certain kind of machinery in it, the same equipment in another place will behave in the same way. Why? Because one machine, when analyzed by Moe, has exactly the same equations as the other one, analyzed by Joe. Since the equations are the same, the phenomena appear the same. So the proof that an apparatus in a new position behaves the same as it did in the old position is the same as the proof that the equations when displaced in space reproduce themselves. Therefore we say that the laws of physics are symmetrical for translational displacements, symmetrical in the sense that the laws do not change when we make a translation of our coordinates. Of course it is quite obvious intuitively that this is true, but it is interesting and entertaining to discuss the mathematics of it. The above is the first of a series of ever more complicated propositions concerning the symmetry of a physical law. The next proposition is that it should make no difference in which direction we choose the axes. In other words, if we build a piece of equipment in some place and watch it operate, and nearby we build the same kind of apparatus but put it up on an angle, will it operate in the same way? Obviously it will not if it is a Grandfather clock, for example! If a pendulum clock stands upright, it works fine, but if it is tilted the pendulum falls against the side of the case and nothing happens. The theorem is then false in the case of the pendulum clock, unless we include the earth, which is pulling on the pendulum. Therefore we can make a prediction about pendulum clocks if we believe in the symmetry of physical law for rotation: something else is involved in the operation of a pendulum clock besides the machinery of the clock, something outside it that we should look for. We may also predict that pendulum clocks will not work the same way when located in different places relative to this mysterious source of asymmetry, perhaps the earth. Indeed, we know that a pendulum clock up in an artificial satellite, for example, would not tick either, because there is no effective force, and on Mars it would go at a different rate. Pendulum clocks do involve something more than just the machinery inside, they involve something on the outside. Once we recognize this factor, we see that we must turn the earth along with the apparatus. Of course we do not have to worry about that, it is easy to do; one simply waits a moment or two and the earth turns; then the pendulum clock ticks again in the new position the same as it did before. While we are rotating in space our angles are always changing, absolutely; this change does not seem to bother us very much, for in the new position we seem to be in the same condition as in the old. This has a certain tendency to confuse one, because it is true that in the new turned position the laws are the same as in the unturned position, but it is not true that as we turn a thing it follows the same laws as it does when we are not turning it. If we perform sufficiently delicate experiments, we can tell that the earth is rotating, but not that it had rotated. In other words, we cannot locate its angular position, but we can tell that it is changing. Now we may discuss the effects of angular orientation upon physical laws. Let us find out whether the same game with Joe and Moe works again. This time, to avoid needless complication, we shall suppose that Joe and Moe use the same origin (we have already shown that the axes can be moved by translation to another place). Assume that Moe\u2019s axes have rotated relative to Joe\u2019s by an angle \u03b8 . The two coordinate systems are shown in Fig. 11\u20132, which is restricted to two dimensions. Consider any point P having coordinates (x,y) in Joe\u2019s system and (x\u2032,y\u2032) in Moe\u2019s system. We shall begin, as in the previous case, by expressing the coordinates x\u2032 and y\u2032 in terms of x , y , and \u03b8 . To do so, we first drop perpendiculars from P to all four axes and draw AB perpendicular to PQ . Inspection of the figure shows that x\u2032 can be written as the sum of two lengths along the x\u2032 -axis, and y\u2032 as the difference of two lengths along AB . All these lengths are expressed in terms of x , y , and \u03b8 in equations (11.5), to which we have added an equation for the third dimension. x\u2032 =x cos\u03b8+y sin\u03b8, y\u2032 =y cos\u03b8\u2212x sin\u03b8, z\u2032 =z . The next step is to analyze the relationship of forces as seen by the two observers, following the same general method as before. Let us assume that a force F , which has already been analyzed as having components Fx and Fy (as seen by Joe), is acting on a particle of mass m , located at point P in Fig. 11\u20132. For simplicity, let us move both sets of axes so that the origin is at P , as shown in Fig. 11\u20133. Moe sees the components of F along his axes as Fx\u2032 and Fy\u2032 . Fx has components along both the x\u2032 - and y\u2032 -axes, and Fy likewise has components along both these axes. To express Fx\u2032 in terms of Fx and Fy , we sum these components along the x\u2032 -axis, and in a like manner we can express Fy\u2032 in terms of Fx and Fy . The results are Fx\u2032 =Fx cos\u03b8+Fy sin\u03b8, Fy\u2032 =Fy cos\u03b8\u2212Fx sin\u03b8, Fz\u2032 =Fz . It is interesting to note an accident of sorts, which is of extreme importance: the formulas (11.5) and (11.6), for coordinates of P and components of F , respectively, are of identical form. As before, Newton\u2019s laws are assumed to be true in Joe\u2019s system, and are expressed by equations (11.1). The question, again, is whether Moe can apply Newton\u2019s laws\u2014will the results be correct for his system of rotated axes? In other words, if we assume that Eqs. (11.5) and (11.6) give the relationship of the measurements, is it true or not true that m(d2x\u2032 /dt2)=Fx\u2032, m(d2y\u2032 /dt2)=Fy\u2032, m(d2z\u2032 /dt2)=Fz\u2032? To test these equations, we calculate the left and right sides independently, and compare the results. To calculate the left sides, we multiply equations (11.5) by m , and differentiate twice with respect to time, assuming the angle \u03b8 to be constant. This gives m(d2 x\u2032/dt2)= m(d2x/dt2)cos\u03b8+m(d2y/dt2)sin\u03b8, m(d2 y\u2032/dt2)= m(d2y/dt2)cos\u03b8\u2212m(d2x/dt2)sin\u03b8, m(d2 z\u2032/dt2)=m(d2z/dt2). We calculate the right sides of equations (11.7) by substituting equations (11.1) into equations (11.6). This gives Fx\u2032 =m(d2x /dt2)cos\u03b8+m(d2y /dt2)sin\u03b8, Fy\u2032 =m(d2y /dt2)cos\u03b8\u2212m(d2x /dt2)sin\u03b8, Fz\u2032 =m(d2z /dt2). Behold! The right sides of Eqs. (11.8) and (11.9) are identical, so we conclude that if Newton\u2019s laws are correct on one set of axes, they are also valid on any other set of axes. This result, which has now been established for both translation and rotation of axes, has certain consequences: first, no one can claim his particular axes are unique, but of course they can be more convenient for certain particular problems. For example, it is handy to have gravity along one axis, but this is not physically necessary. Second, it means that any piece of equipment which is completely self-contained, with all the force-generating equipment completely inside the apparatus, would work the same when turned at an angle. Not only Newton\u2019s laws, but also the other laws of physics, so far as we know today, have the two properties which we call invariance (or symmetry) under translation of axes and rotation of axes. These properties are so important that a mathematical technique has been developed to take advantage of them in writing and using physical laws. The foregoing analysis involved considerable tedious mathematical work. To reduce the details to a minimum in the analysis of such questions, a very powerful mathematical machinery has been devised. This system, called vector analysis, supplies the title of this chapter; strictly speaking, however, this is a chapter on the symmetry of physical laws. By the methods of the preceding analysis we were able to do everything required for obtaining the results that we sought, but in practice we should like to do things more easily and rapidly, so we employ the vector technique. We began by noting some characteristics of two kinds of quantities that are important in physics. (Actually there are more than two, but let us start out with two.) One of them, like the number of potatoes in a sack, we call an ordinary quantity, or an undirected quantity, or a scalar. Temperature is an example of such a quantity. Other quantities that are important in physics do have direction, for instance velocity: we have to keep track of which way a body is going, not just its speed. Momentum and force also have direction, as does displacement: when someone steps from one place to another in space, we can keep track of how far he went, but if we wish also to know where he went, we have to specify a direction. All quantities that have a direction, like a step in space, are called vectors. A vector is three numbers. In order to represent a step in space, say from the origin to some particular point P whose location is (x,y,z) , we really need three numbers, but we are going to invent a single mathematical symbol, r , which is unlike any other mathematical symbols we have so far used.1 It is not a single number, it represents three numbers: x , y , and z . It means three numbers, but not really only those three numbers, because if we were to use a different coordinate system, the three numbers would be changed to x\u2032 , y\u2032 , and z\u2032 . However, we want to keep our mathematics simple and so we are going to use the same mark to represent the three numbers (x,y,z) and the three numbers (x\u2032,y\u2032,z\u2032) . That is, we use the same mark to represent the first set of three numbers for one coordinate system, but the second set of three numbers if we are using the other coordinate system. This has the advantage that when we change the coordinate system, we do not have to change the letters of our equations. If we write an equation in terms of x,y,z , and then use another system, we have to change to x\u2032,y\u2032,z\u2032 , but we shall just write r , with the convention that it represents (x,y,z) if we use one set of axes, or (x\u2032,y\u2032,z\u2032) if we use another set of axes, and so on. The three numbers which describe the quantity in a given coordinate system are called the components of the vector in the direction of the coordinate axes of that system. That is, we use the same symbol for the three letters that correspond to the same object, as seen from different axes. The very fact that we can say \u201cthe same object\u201d implies a physical intuition about the reality of a step in space, that is independent of the components in terms of which we measure it. So the symbol r will represent the same thing no matter how we turn the axes. Now suppose there is another directed physical quantity, any other quantity, which also has three numbers associated with it, like force, and these three numbers change to three other numbers by a certain mathematical rule, if we change the axes. It must be the same rule that changes (x,y,z) into (x\u2032,y\u2032,z\u2032) . In other words, any physical quantity associated with three numbers which transform as do the components of a step in space is a vector. An equation like F=r would thus be true in any coordinate system if it were true in one. This equation, of course, stands for the three equations Fx=x,Fy=y,Fz=z, or, alternatively, for Fx\u2032=x\u2032,Fy\u2032=y\u2032,Fz\u2032=z\u2032. The fact that a physical relationship can be expressed as a vector equation assures us the relationship is unchanged by a mere rotation of the coordinate system. That is the reason why vectors are so useful in physics. Now let us examine some of the properties of vectors. As examples of vectors we may mention velocity, momentum, force, and acceleration. For many purposes it is convenient to represent a vector quantity by an arrow that indicates the direction in which it is acting. Why can we represent force, say, by an arrow? Because it has the same mathematical transformation properties as a \u201cstep in space.\u201d We thus represent it in a diagram as if it were a step, using a scale such that one unit of force, or one newton, corresponds to a certain convenient length. Once we have done this, all forces can be represented as lengths, because an equation like F=kr, where k is some constant, is a perfectly legitimate equation. Thus we can always represent forces by lines, which is very convenient, because once we have drawn the line we no longer need the axes. Of course, we can quickly calculate the three components as they change upon turning the axes, because that is just a geometric problem. Now we must describe the laws, or rules, for combining vectors in various ways. The first such combination is the addition of two vectors: suppose that a is a vector which in some particular coordinate system has the three components (ax,ay,az) , and that b is another vector which has the three components (bx,by,bz) . Now let us invent three new numbers (ax+bx,ay+by,az+bz) . Do these form a vector? \u201cWell,\u201d we might say, \u201cthey are three numbers, and every three numbers form a vector.\u201d No, not every three numbers form a vector! In order for it to be a vector, not only must there be three numbers, but these must be associated with a coordinate system in such a way that if we turn the coordinate system, the three numbers \u201crevolve\u201d on each other, get \u201cmixed up\u201d in each other, by the precise laws we have already described. So the question is, if we now rotate the coordinate system so that (ax,ay,az) become (ax\u2032,ay\u2032,az\u2032) and (bx,by,bz) become (bx\u2032,by\u2032,bz\u2032) , what do (ax+bx,ay+by,az+bz) become? Do they become (ax\u2032+bx\u2032,ay\u2032+by\u2032,az\u2032+bz\u2032) or not? The answer is, of course, yes, because the prototype transformations of Eq. (11.5) constitute what we call a linear transformation. If we apply those transformations to ax and bx to get ax\u2032+bx\u2032 , we find that the transformed ax+bx is indeed the same as ax\u2032+bx\u2032 . When a and b are \u201cadded together\u201d in this sense, they will form a vector which we may call c . We would write this as c=a+b. Now c has the interesting property c=b+a, as we can immediately see from its components. Thus also, a+(b+c)=(a+b)+c. We can add vectors in any order. What is the geometric significance of a+b ? Suppose that a and b were represented by lines on a piece of paper, what would c look like? This is shown in Fig. 11\u20134. We see that we can add the components of b to those of a most conveniently if we place the rectangle representing the components of b next to that representing the components of a in the manner indicated. Since b just \u201cfits\u201d into its rectangle, as does a into its rectangle, this is the same as putting the \u201ctail\u201d of b on the \u201chead\u201d of a , the arrow from the \u201ctail\u201d of a to the \u201chead\u201d of b being the vector c . Of course, if we added a to b the other way around, we would put the \u201ctail\u201d of a on the \u201chead\u201d of b , and by the geometrical properties of parallelograms we would get the same result for c . Note that vectors can be added in this way without reference to any coordinate axes. Suppose we multiply a vector by a number \u03b1 , what does this mean? We define it to mean a new vector whose components are \u03b1 a x , \u03b1 a y , and \u03b1 a z . We leave it as a problem for the student to prove that it is a vector. Now let us consider vector subtraction. We may define subtraction in the same way as addition, but instead of adding, we subtract the components. Or we might define subtraction by defining a negative vector, \u2212b=\u22121b , and then we would add the components. It comes to the same thing. The result is shown in Fig. 11\u20135. This figure shows d= a\u2212b= a+(\u2212b) ; we also note that the difference a\u2212b can be found very easily from a and b by using the equivalent relation a=b+d . Thus the difference is even easier to find than the sum: we just draw the vector from b to a , to get a\u2212b ! Next we discuss velocity. Why is velocity a vector? If position is given by the three coordinates (x,y,z) , what is the velocity? The velocity is given by dx/dt , dy/dt , and dz/dt . Is that a vector, or not? We can find out by differentiating the expressions in Eq. (11.5) to find out whether d x \u2032 /dt transforms in the right way. We see that the components dx/dt and dy/dt do transform according to the same law as x and y , and therefore the time derivative is a vector. So the velocity is a vector. We can write the velocity in an interesting way as v=dr/dt. d / d What the velocity is, and why it is a vector, can also be understood more pictorially: How far does a particle move in a short time \u0394t ? Answer: \u0394r , so if a particle is \u201chere\u201d at one instant and \u201cthere\u201d at another instant, then the vector difference of the positions \u0394r= r 2 \u2212 r 1 , which is in the direction of motion shown in Fig. 11\u20136, divided by the time interval \u0394t= t 2 \u2212 t 1 , is the \u201caverage velocity\u201d vector. In other words, by vector velocity we mean the limit, as \u0394t goes to 0 , of the difference between the radius vectors at the time t+\u0394t and the time t , divided by \u0394t : v= lim \u0394t\u21920 (\u0394r/\u0394t)=dr/dt. (11.10) Thus velocity is a vector because it is the difference of two vectors. It is also the right definition of velocity because its components are dx/dt , dy/dt , and dz/dt . In fact, we see from this argument that if we differentiate any vector with respect to time we produce a new vector. So we have several ways of producing new vectors: (1) multiply by a constant, (2) differentiate with respect to time, (3) add or subtract two vectors. In order to write Newton\u2019s laws in vector form, we have to go just one step further, and define the acceleration vector. This is the time derivative of the velocity vector, and it is easy to demonstrate that its components are the second derivatives of x , y , and z with respect to t : a= dv dt =( d dt )( dr dt )= d 2 r d t 2 , (11.11) a x a y a z = d v x dt = d v y dt = d v z dt = d 2 x d t 2 , = d 2 y d t 2 , = d 2 z d t 2 . (11.12) With this definition, then, Newton\u2019s laws can be written in this way: ma=F (11.13) or m( d 2 r/d t 2 )=F. (11.14) Now the problem of proving the invariance of Newton\u2019s laws under rotation of coordinates is this: prove that a is a vector; this we have just done. Prove that F is a vector; we suppose it is. So if force is a vector, then, since we know acceleration is a vector, Eq. (11.13) will look the same in any coordinate system. Writing it in a form which does not explicitly contain x \u2019s, y \u2019s, and z \u2019s has the advantage that from now on we need not write three laws every time we write Newton\u2019s equations or other laws of physics. We write what looks like one law, but really, of course, it is the three laws for any particular set of axes, because any vector equation involves the statement that each of the components is equal. The fact that the acceleration is the rate of change of the vector velocity helps us to calculate the acceleration in some rather complicated circumstances. Suppose, for instance, that a particle is moving on some complicated curve (Fig. 11\u20137) and that, at a given instant t 1 , it had a certain velocity v 1 , but that when we go to another instant t 2 a little later, it has a different velocity v 2 . What is the acceleration? Answer: Acceleration is the difference in the velocity divided by the small time interval, so we need the difference of the two velocities. How do we get the difference of the velocities? To subtract two vectors, we put the vector across the ends of v 2 and v 1 ; that is, we draw \u0394v as the difference of the two vectors, right? No! That only works when the tails of the vectors are in the same place! It has no meaning if we move the vector somewhere else and then draw a line across, so watch out! We have to draw a new diagram to subtract the vectors. In Fig. 11\u20138, v 1 and v 2 are both drawn parallel and equal to their counterparts in Fig. 11\u20137, and now we can discuss the acceleration. Of course the acceleration is simply \u0394v/\u0394t . It is interesting to note that we can compose the velocity difference out of two parts; we can think of acceleration as having two components, \u0394 v \u2225 , in the direction tangent to the path and \u0394 v \u22a5 at right angles to the path, as indicated in Fig. 11\u20138. The acceleration tangent to the path is, of course, just the change in the length of the vector, i.e., the change in the speed v : a \u2225 =dv/dt. (11.15) The other component of acceleration, at right angles to the curve, is easy to calculate, using Figs. 11\u20137 and 11\u20138. In the short time \u0394t let the change in angle between v 1 and v 2 be the small angle \u0394\u03b8 . If the magnitude of the velocity is called v , then of course \u0394 v \u22a5 =v\u0394\u03b8 \u0394 \u0394 \u03b8 and the acceleration a will be a \u22a5 =v(\u0394\u03b8/\u0394t). ( \u03b8 / ) Now we need to know \u0394\u03b8/\u0394t , which can be found this way: If, at the given moment, the curve is approximated as a circle of a certain radius R , then in a time \u0394t the distance s is, of course, v\u0394t , where v is the speed. \u0394\u03b8=(v\u0394t)/R,or\u0394\u03b8/\u0394t=v/R. \u03b8 ( ) / \u03b8 / / Therefore, we find a \u22a5 = v 2 /R, (11.16) as we have seen before. Now let us examine a little further the properties of vectors. It is easy to see that the length of a step in space would be the same in any coordinate system. That is, if a particular step r is represented by x,y,z , in one coordinate system, and by x \u2032 , y \u2032 , z \u2032 in another coordinate system, surely the distance r=|r| would be the same in both. Now r= x 2 + y 2 + z 2 \u2212 \u2212 \u2212 \u2212 \u2212 \u2212 \u2212 \u2212 \u2212 \u2212 \u221a and also r \u2032 = x \u20322 + y \u20322 + z \u20322 \u2212 \u2212 \u2212 \u2212 \u2212 \u2212 \u2212 \u2212 \u2212 \u2212 \u2212 \u221a . So what we wish to verify is that these two quantities are equal. It is much more convenient not to bother to take the square root, so let us talk about the square of the distance; that is, let us find out whether x 2 + y 2 + z 2 = x \u20322 + y \u20322 + z \u20322 . (11.17) It had better be\u2014and if we substitute Eq. (11.5) we do indeed find that it is. So we see that there are other kinds of equations which are true for any two coordinate systems. Something new is involved. We can produce a new quantity, a function of x , y , and z , called a scalar function, a quantity which has no direction but which is the same in both systems. Out of a vector we can make a scalar. We have to find a general rule for that. It is clear what the rule is for the case just considered: add the squares of the components. Let us now define a new thing, which we call a\u22c5a . This is not a vector, but a scalar; it is a number that is the same in all coordinate systems, and it is defined to be the sum of the squares of the three components of the vector: a\u22c5a= a 2 x + a 2 y + a 2 z . (11.18) Now you say, \u201cBut with what axes?\u201d It does not depend on the axes, the answer is the same in every set of axes. So we have a new kind of quantity, a new invariant or scalar produced by one vector \u201csquared.\u201d If we now define the following quantity for any two vectors a and b : a\u22c5b= a x b x + a y b y + a z b z , (11.19) we find that this quantity, calculated in the primed and unprimed systems, also stays the same. To prove it we note that it is true of a\u22c5a , b\u22c5b , and c\u22c5c , where c=a+b . Therefore the sum of the squares ( a x + b x ) 2 +( a y + b y ) 2 +( a z + b z ) 2 will be invariant: ( a x + b x ) 2 +( a y + b y ) 2 +( a z + b z ) 2 = ( a x \u2032 + b x \u2032 ) 2 +( a y \u2032 + b y \u2032 ) 2 +( a z \u2032 + b z \u2032 ) 2 . (11.20) If both sides of this equation are expanded, there will be cross products of just the type appearing in Eq. (11.19), as well as the sums of squares of the components of a and b . The invariance of terms of the form of Eq. (11.18) then leaves the cross product terms (11.19) invariant also. The quantity a\u22c5b is called the scalar product of two vectors, a and b , and it has many interesting and useful properties. For instance, it is easily proved that a\u22c5(b+c)=a\u22c5b+a\u22c5c. (11.21) Also, there is a simple geometrical way to calculate a\u22c5b , without having to calculate the components of a and b : a\u22c5b is the product of the length of a and the length of b times the cosine of the angle between them. Why? Suppose that we choose a special coordinate system in which the x -axis lies along a ; in those circumstances, the only component of a that will be there is a x , which is of course the whole length of a . Thus Eq. (11.19) reduces to a\u22c5b= a x b x for this case, and this is the length of a times the component of b in the direction of a , that is, bcos\u03b8 : a\u22c5b=abcos\u03b8. b b \u03b8 Therefore, in that special coordinate system, we have proved that a\u22c5b is the length of a times the length of b times cos\u03b8 . But if it is true in one coordinate system, it is true in all, because a\u22c5b is independent of the coordinate system; that is our argument. What good is the dot product? Are there any cases in physics where we need it? Yes, we need it all the time. For instance, in Chapter 4 the kinetic energy was called 1 2 m v 2 , but if the object is moving in space it should be the velocity squared in the x -direction, the y -direction, and the z -direction, and so the formula for kinetic energy according to vector analysis is K.E.= 1 2 m(v\u22c5v)= 1 2 m( v 2 x + v 2 y + v 2 z ). (11.22) Energy does not have direction. Momentum has direction; it is a vector, and it is the mass times the velocity vector. Another example of a dot product is the work done by a force when something is pushed from one place to the other. We have not yet defined work, but it is equivalent to the energy change, the weights lifted, when a force F acts through a distance s : Work=F\u22c5s. (11.23) It is sometimes very convenient to talk about the component of a vector in a certain direction (say the vertical direction because that is the direction of gravity). For such purposes, it is useful to invent what we call a unit vector in the direction that we want to study. By a unit vector we mean one whose dot product with itself is equal to unity. Let us call this unit vector i ; then i\u22c5i=1 . Then, if we want the component of some vector in the direction of i , we see that the dot product a\u22c5i will be acos\u03b8 , i.e., the component of a in the direction of i . This is a nice way to get the component; in fact, it permits us to get all the components and to write a rather amusing formula. Suppose that in a given system of coordinates, x , y , and z , we invent three vectors: i , a unit vector in the direction x ; j , a unit vector in the direction y ; and k , a unit vector in the direction z . Note first that i\u22c5i=1 . What is i\u22c5j ? When two vectors are at right angles, their dot product is zero. Thus i\u22c5i i\u22c5j i\u22c5k =1 =0 =0 j\u22c5j j\u22c5k =1 =0 k\u22c5k =1 (11.24) Now with these definitions, any vector whatsoever can be written this way: a= a x i+ a y j+ a z k. (11.25) By this means we can go from the components of a vector to the vector itself. This discussion of vectors is by no means complete. However, rather than try to go more deeply into the subject now, we shall first learn to use in physical situations some of the ideas so far discussed. Then, when we have properly mastered this basic material, we shall find it easier to penetrate more deeply into the subject without getting too confused. We shall later find that it is useful to define another kind of product of two vectors, called the vector product, and written as a\u00d7b . However, we shall undertake a discussion of such matters in a later chapter."
    },
    {
        "input": "Elastic Materials",
        "output": "In the last chapter we talked about the distortions of particular elastic objects. In this chapter we want to look at what can happen in general inside an elastic material. We would like to be able to describe the conditions of stress and strain inside some big glob of jello which is twisted and squashed in some complicated way. To do this, we need to be able to describe the local strain at every point in an elastic body; we can do it by giving a set of six numbers\u2014which are the components of a symmetric tensor\u2014for each point. Earlier, we spoke of the stress tensor (Chapter 31); now we need the tensor of strain. Imagine that we start with the material initially unstrained and watch the motion of a small speck of \u201cdirt\u201d embedded in the material when the strain is applied. A speck that was at the point P located at r=(x,y,z) moves to a new position P\u2032 at r\u2032=(x\u2032,y\u2032,z\u2032) as shown in Fig. 39\u20131. We will call u the vector displacements from P to P\u2032. Then u=r\u2032\u2212r. The displacement u depends, of course, on which point P we start with, so u is a vector function of r\u2014or, if you prefer, of (x,y,z). Let\u2019s look first at a simple situation in which the strain is constant over the material\u2014so we have what is called a homogeneous strain. Suppose, for instance, that we have a block of material and we stretch it uniformly. We just change its dimensions uniformly in one direction\u2014say, in the x-direction, as shown in Fig. 39\u20132. The motion ux of a speck at x is proportional to x. In fact, ux x = \u0394l l . We will write ux this way: ux=exxx. The proportionality constant exx is, of course, the same thing as \u0394l/l. (You will see shortly why we use a double subscript.) If the strain is not uniform, the relation between ux and x will vary from place to place in the material. For the general situation, we define the exx by a kind of local \u0394l/l, namely by exx=\u2202ux/\u2202x. This number\u2014which is now a function of x, y, and z\u2014describes the amount of stretching in the x-direction throughout the hunk of jello. There may, of course, also be stretching in the y- and z-directions. We describe them by the numbers eyy= \u2202uy \u2202y ,ezz= \u2202uz \u2202z . We need to be able to describe also the shear-type strains. Suppose we imagine a little cube marked out in the initially undisturbed jello. When the jello is pushed out of shape, this cube may get changed into a parallelogram, as sketched in Fig. 39\u20133.1 In this kind of a strain, the x-motion of each particle is proportional to its y-coordinate, ux= \u03b8 2 y. And there is also a y-motion proportional to x, uy= \u03b8 2 x. So we can describe such a shear-type strain by writing ux=exyy,uy=eyxx with exy=eyx= \u03b8 2 . Now you might think that when the strains are not homogeneous we could describe the generalized shear strains by defining the quantities exy and eyx by exy= \u2202ux \u2202y ,eyx= \u2202uy \u2202x . But there is one difficulty. Suppose that the displacements ux and uy were given by ux= \u03b8 2 y,uy=\u2212 \u03b8 2 x They are like Eqs. (39.4) and (39.5) except that the sign of uy is reversed. With these displacements a little cube in the jello simply gets shifted by the angle \u03b8/2 , as shown in Fig. 39\u20134. There is no strain at all\u2014just a rotation in space. There is no distortion of the material; the relative positions of all the atoms are not changed at all. We must somehow make our definitions so that pure rotations are not included in our definitions of a shear strain. The key point is that if \u2202uy/\u2202x and \u2202ux/\u2202y are equal and opposite, there is no strain; so we can fix things up by defining exy=eyx= 1 2 (\u2202uy/\u2202x+\u2202ux/\u2202y). For a pure rotation they are both zero, but for a pure shear we get that exy is equal to eyx , as we would like. In the most general distortion\u2014which may include stretching or compression as well as shear\u2014we define the state of strain by giving the nine numbers exx = \u2202ux \u2202x , eyy = \u2202uy \u2202y , \u22ee exy = 1 2 (\u2202uy/\u2202x+\u2202ux/\u2202y), \u22ee These are the terms of a tensor of strain. Because it is a symmetric tensor\u2014our definitions make exy=eyx , always\u2014there are really only six different numbers. You remember (see Chapter 31) that the general characteristic of a tensor is that the terms transform like the products of the components of two vectors. (If A and B are vectors, Cij=AiBj is a tensor.) Each term of eij is a product (or the sum of such products) of the components of the vector u=(ux,uy,uz) , and of the operator \u2207=(\u2202/\u2202x,\u2202/\u2202y,\u2202/\u2202z) , which we know transforms like a vector. Let\u2019s let x1 , x2 , and x3 stand for x , y , and z and u1 , u2 , and u3 stand for ux , uy , and uz ; then we can write the general term eij of the strain tensor as eij= 1 2 (\u2202uj/\u2202xi+\u2202ui/\u2202xj), where i and j can be 1 , 2 , or 3 . When we have a homogeneous strain\u2014which may include both stretching and shear\u2014all of the eij are constants, and we can write ux=exxx+exyy+exzz. (We choose our origin of x , y , z at the point where u is zero.) In this case, the strain tensor eij gives the relationship between two vectors: the coordinate vector r=(x,y,z) and the displacement vector u=(ux,uy,uz) . When the strains are not homogeneous, any piece of the jello may also get somewhat twisted\u2014there will be a local rotation. If the distortions are all small, we would have \u0394ui= \u2211 j (eij\u2212\u03c9ij)\u0394xj, where \u03c9ij is an antisymmetric tensor, \u03c9ij= 1 2 (\u2202uj/\u2202xi\u2212\u2202ui/\u2202xj), which describes the rotation. We will, however, not worry any more about rotations, but only about the strains described by the symmetric tensor eij . Now that we have described the strains, we want to relate them to the internal forces\u2014the stresses in the material. For each small piece of the material, we assume Hooke\u2019s law holds and write that the stresses are proportional to the strains. In Chapter 31 we defined the stress tensor Sij as the i th component of the force across a unit-area perpendicular to the j -axis. Hooke\u2019s law says that each component of Sij is linearly related to each of the components of strain. Since S and e each have nine components, there are 9\u00d79=81 possible coefficients which describe the elastic properties of the material. They are constants if the material itself is homogeneous. We write these coefficients as Cijkl and define them by the equation Sij= \u2211 k,l Cijklekl, where i , j , k , l all take on the values 1 , 2 , or 3 . Since the coefficients Cijkl relate one tensor to another, they also form a tensor\u2014a tensor of the fourth rank. We can call it the tensor of elasticity. Suppose that all the C \u2019s are known and that you put a complicated force on an object of some peculiar shape. There will be all kinds of distortion, and the thing will settle down with some twisted shape. What are the displacements? You can see that it is a complicated problem. If you knew the strains, you could find the stresses from Eq. (39.12)\u2014or vice versa. But the stresses and strains you end up with at any point depend on what happens in all the rest of the material. The easiest way to get at the problem is by thinking of the energy. When there is a force F proportional to a displacement x , say F=kx , the work required for any displacement x is kx2/2 . In a similar way, the work w that goes into each unit volume of a distorted material turns out to be w= 1 2 \u2211 ijkl Cijkleijekl. The total work W done in distorting the body is the integral of w over its volume: W=\u222b 1 2 \u2211 ijkl CijkleijekldV. This is then the potential energy stored in the internal stresses of the material. Now when a body is in equilibrium, this internal energy must be at a minimum. So the problem of finding the strains in a body can be solved by finding the set of displacements u throughout the body which will make W a minimum. In Chapter 19 we gave some of the general ideas of the calculus of variations that are used in tackling minimization problems like this. We cannot go into the problem in any more detail here. What we are mainly interested in now is what we can say about the general properties of the tensor of elasticity. First, it is clear that there are not really 81 different terms in Cijkl . Since both Sij and eij are symmetric tensors, each with only six different terms, there can be at most 36 different terms in Cijkl . There are, however, usually many fewer than this. Let\u2019s look at the special case of a cubic crystal. In it, the energy density w starts out like this: w= 1 2 { Cxxxxe 2 xx +Cxxxyexxexy+Cxxxzexxexz + Cxxyxexxexy+Cxxyyexxeyy\u2026etc\u2026 + Cyyyye 2 yy +\u2026etc\u2026etc\u2026}, with 81 terms in all! Now a cubic crystal has certain symmetries. In particular, if the crystal is rotated 90\u2218 , it has the same physical properties. It has the same stiffness for stretching in the y -direction as for stretching in the x -direction. Therefore, if we change our definition of the coordinate directions x and y in Eq. (39.15), the energy wouldn\u2019t change. It must be that for a cubic crystal Cxxxx=Cyyyy=Czzzz. Next we can show that the terms like Cxxxy must be zero. A cubic crystal has the property that it is symmetric under a reflection about any plane perpendicular to one of the axes. If we replace y by \u2212y , nothing is different. But changing y to \u2212y changes exy to \u2212exy \u2014a displacement which was toward +y is now toward \u2212y . If the energy is not to change, Cxxxy must go into \u2212Cxxxy when we make a reflection. But a reflected crystal is the same as before, so Cxxxy must be the same as \u2212Cxxxy . This can happen only if both are zero. You say, \u201cBut the same argument will make Cyyyy=0 !\u201d No, because there are four y \u2019s. The sign changes once for each y , and four minuses make a plus. If there are two or four y \u2019s, the term does not have to be zero. It is zero only when there is one, or three. So, for a cubic crystal, any nonzero term of C will have only an even number of identical subscripts. (The arguments we have made for y obviously hold also for x and z .) We might then have terms like Cxxyy , Cxyxy , Cxyyx , and so on. We have already shown, however, that if we change all x \u2019s to y \u2019s and vice versa (or all z \u2019s and x \u2019s, and so on) we must get\u2014for a cubic crystal\u2014the same number. This means that there are only three different nonzero possibilities: Cxxxx(=Cyyyy=Czzzz), Cxxyy(=Cyyxx=Cxxzz,etc.), Cxyxy(=Cyxyx=Cxzxz,etc.). For a cubic crystal, then, the energy density will look like this: w = 1 2 {Cxxxx(e 2 xx +e 2 yy +e 2 zz ) +2Cxxyy(exxeyy+eyyezz+ezzexx) +4Cxyxy(e 2 xy +e 2 yz +e 2 zx )}. For an isotropic\u2014that is, noncrystalline\u2014material, the symmetry is still higher. The C \u2019s must be the same for any choice of the coordinate system. Then it turns out that there is another relation among the C \u2019s, namely, that Cxxxx=Cxxyy+2Cxyxy. We can see that this is so by the following general argument. The stress tensor Sij has to be related to eij in a way that doesn\u2019t depend at all on the coordinate directions\u2014it must be related only by scalar quantities. \u201cThat\u2019s easy,\u201d you say. \u201cThe only way to obtain Sij from eij is by multiplication by a scalar constant. It\u2019s just Hooke\u2019s law. It must be that Sij=(const)eij .\u201d But that\u2019s not quite right; there could also be the unit tensor \u03b4ij multiplied by some scalar, linearly related to eij . The only invariant you can make that is linear in the e \u2019s is \u2211eii . (It transforms like x2+y2+z2 , which is a scalar.) So the most general form for the equation relating Sij to eij \u2014for isotropic materials\u2014is Sij=2\u03bceij+\u03bb( \u2211 k ekk)\u03b4ij. (The first constant is usually written as two times \u03bc ; then the coefficient \u03bc is equal to the shear modulus we defined in the last chapter.) The constants \u03bc and \u03bb are called the Lam\u00e9 elastic constants. Comparing Eq. (39.20) with Eq. (39.12), you see that Cxxyy =\u03bb, Cxyxy =\u03bc, Cxxxx =2\u03bc+\u03bb. So we have proved that Eq. (39.19) is indeed true. You also see that the elastic properties of an isotropic material are completely given by two constants, as we said in the last chapter. The C \u2019s can be put in terms of any two of the elastic constants we have used earlier\u2014for instance, in terms of Young\u2019s modulus Y and Poisson\u2019s ratio \u03c3 . We will leave it for you to show that Cxxxx = Y 1+\u03c3 (1+ \u03c3 1\u22122\u03c3 ), Cxxyy = Y 1+\u03c3 ( \u03c3 1\u22122\u03c3 ), Cxyxy = Y 2(1+\u03c3) . We have pointed out that for an elastic body in equilibrium the internal stresses adjust themselves to make the energy a minimum. Now we take a look at what happens when the internal forces are not in equilibrium. Let\u2019s say we have a small piece of the material inside some surface A . See Fig. 39\u20135. If the piece is in equilibrium, the total force F acting on it must be zero. We can think of this force as being made up of two parts. There could be one part due to \u201cexternal\u201d forces like gravity, which act from a distance on the matter in the piece to produce a force per unit volume fext . The total external force Fext is the integral of fext over the volume of the piece: Fext=\u222bfextdV. In equilibrium, this force would be balanced by the total force Fint from the neighboring material which acts across the surface A . When the piece is not in equilibrium\u2014if it is moving\u2014the sum of the internal and external forces is equal to the mass times the acceleration. We would have Fext+Fint=\u222b\u03c1 \u00a8 r dV, where \u03c1 is the density of the material, and \u00a8 r is its acceleration. We can now combine Eqs. (39.23) and (39.24), writing Fint=\u222bv(\u2212fext+\u03c1 \u00a8 r )dV. We will simplify our writing by defining f=\u2212fext+\u03c1 \u00a8 r . Then Eq. (39.25) is written Fint=\u222bvfdV. What we have called Fint is related to the stresses in the material. The stress tensor Sij was defined (Chapter 31) so that the x -component of the force dF across a surface element da , whose unit normal is n , is given by dFx=(Sxxnx+Sxyny+Sxznz)da. The x -component of Fint on our little piece is then the integral of dFx over the surface. Substituting this into the x -component of Eq. (39.27), we get \u222bA(Sxxnx+Sxyny+Sxznz)da=\u222bvfxdV. We have a surface integral related to a volume integral\u2014and that reminds us of something we learned in electricity. Note that if you ignore the first subscript x on each of the S \u2019s in the left-hand side of Eq. (39.29), it looks just like the integral of a quantity \u201cS\u201d\u22c5n \u2014that is, the normal component of a vector\u2014over the surface. It would be the flux of \u201cS\u201d out of the volume. And this could be written, using Gauss law, as the volume integral of the divergence of \u201cS\u201d . It is, in fact, true whether the x -subscript is there or not\u2014it is just a mathematical theorem you get by integrating by parts. In other words, we can change Eq. (39.29) into \u222bv( \u2202Sxx \u2202x + \u2202Sxy \u2202y + \u2202Sxz \u2202z )dV=\u222bvfxdV. Now we can leave off the volume integrals and write the differential equation for the general component of f as fi= \u2211 j \u2202Sij \u2202xj . This tells us how the force per unit volume is related to the stress tensor Sij . The theory of the motions inside a solid works this way. If we start out knowing the initial displacements\u2014given by, say, u \u2014we can work out the strains eij . From the strains we can get the stresses from Eq. (39.12). From the stresses we can get the force density f in Eq. (39.31). Knowing f , we can get, from Eq. (39.26), the acceleration \u00a8 r of the material, which tells us how the displacements will be changing. Putting everything together, we get the horrible equation of motion for an elastic solid. We will just write down the results that come out for an isotropic material. If you use (39.20) for Sij , and write the eij as 1 2 (\u2202ui/\u2202xj+\u2202uj/\u2202xi) , you end up with the vector equation f=(\u03bb+\u03bc)\u2207(\u2207\u22c5u)+\u03bc\u22072u. You can, in fact, see that the equation relating f and u must have this form. The force must depend on the second derivatives of the displacements u . What second derivatives of u are there that are vectors? One is \u2207(\u2207\u22c5u) ; that\u2019s a true vector. The only other one is \u2207 2 u . So the most general form is f=a\u2207(\u2207\u22c5u)+b \u2207 2 u, 2 which is just (39.32) with a different definition of the constants. You may be wondering why we don\u2019t have a third term using \u2207\u00d7\u2207\u00d7u , which is also a vector. But remember that \u2207\u00d7\u2207\u00d7u is the same thing as \u2207(\u2207\u22c5u)\u2212 \u2207 2 u , so it is a linear combination of the two terms we have. Adding it would add nothing new. We have proved once more that isotropic material has only two elastic constants. For the equation of motion of the material, we can set (39.32) equal to \u03c1 \u2202 2 u/\u2202 t 2 \u2014neglecting for now any body forces like gravity\u2014and get \u03c1 \u2202 2 u \u2202 t 2 =(\u03bb+\u03bc)\u2207(\u2207\u22c5u)+\u03bc \u2207 2 u. (39.33) It looks something like the wave equation we had in electromagnetism, except that there is an additional complicating term. For materials whose elastic properties are everywhere the same we can see what the general solutions look like in the following way. You will remember that any vector field can be written as the sum of two vectors: one whose divergence is zero, and the other whose curl is zero. In other words, we can put u= u 1 + u 2 , (39.34) where \u2207\u22c5 u 1 =0,\u2207\u00d7 u 2 =0. (39.35) Substituting u 1 + u 2 for u in (39.33), we get \u03c1 \u2202 2 / \u2202 t 2 [ u 1 + u 2 ]= (\u03bb+\u03bc)\u2207(\u2207\u22c5 u 2 )+\u03bc \u2207 2 ( u 1 + u 2 ). (39.36) We can eliminate u 1 by taking the divergence of this equation, \u03c1 \u2202 2 / \u2202 t 2 (\u2207\u22c5 u 2 )= (\u03bb+\u03bc) \u2207 2 (\u2207\u22c5 u 2 )+\u03bc\u2207\u22c5 \u2207 2 ( u 2 ). Since the operators ( \u2207 2 ) and ( \u2207\u22c5 ) can be interchanged, we can factor out the divergence to get \u2207\u22c5{\u03c1 \u2202 2 u 2 /\u2202 t 2 \u2212(\u03bb+2\u03bc) \u2207 2 u 2 }=0. (39.37) Since \u2207\u00d7 u 2 is zero by definition, the curl of the bracket {} is also zero; so the bracket itself is identically zero, and \u03c1 \u2202 2 u 2 /\u2202 t 2 =(\u03bb+2\u03bc) \u2207 2 u 2 . (39.38) This is the vector wave equation for waves which move at the speed C 2 = (\u03bb+2\u03bc)/\u03c1 \u2212 \u2212 \u2212 \u2212 \u2212 \u2212 \u2212 \u2212 \u2212 \u221a . Since the curl of u 2 is zero, there is no shearing associated with this wave; this wave is just the compressional\u2014sound-type\u2014wave we discussed in the last chapter, and the velocity is just what we found for C long . In a similar way\u2014by taking the curl of Eq. (39.36)\u2014we can show that u 1 satisfies the equation \u03c1 \u2202 2 u 1 /\u2202 t 2 =\u03bc \u2207 2 u 1 . (39.39) This is again a vector wave equation for waves with the speed C 1 = \u03bc/\u03c1 \u2212 \u2212 \u2212 \u221a . Since \u2207\u22c5 u 1 is zero, u 1 produces no changes in density; the vector u 1 corresponds to the transverse, or shear-type, wave we saw in the last chapter, and C 1 = C shear . If we wished to know the static stresses in an isotropic material, we could, in principle, find them by solving Eq. (39.32) with f equal to zero\u2014or equal to the static body forces from gravity such as \u03c1g \u2014under certain conditions which are related to the forces acting on the surfaces of our large block of material. This is somewhat more difficult to do than the corresponding problems in electromagnetism. It is more difficult, first, because the equations are a little more difficult to handle, and second, because the shape of the elastic bodies we are likely to be interested in are usually much more complicated. In electromagnetism, we are often interested in solving Maxwell\u2019s equations around relatively simple geometric shapes such as cylinders, spheres, and so on, since these are convenient shapes for electrical devices. In elasticity, the objects we would like to analyze may have quite complicated shapes\u2014like a crane hook, or an automobile crankshaft, or the rotor of a gas turbine. Such problems can sometimes be worked out approximately by numerical methods, using the minimum energy principle we mentioned earlier. Another way is to use a model of the object and measure the internal strains experimentally, using polarized light. It works this way: When a transparent isotropic material\u2014for example, a clear plastic like lucite\u2014is put under stress, it becomes birefringent. If you put polarized light through it, the plane of polarization will be rotated by an amount related to the stress: by measuring the rotation, you can measure the stress. Figure 39\u20136 shows how such a setup might look. Figure 39\u20137 is a photograph of a photoelastic model of a complicated shape under stress. In all that has been said so far, we have assumed that stress is proportional to strain; in general, that is not true. Figure 39\u20138 shows a typical stress-strain curve for a ductile material. For small strains, the stress is proportional to the strain. Eventually, however, after a certain point, the relationship between stress and strain begins to deviate from a straight line. For many materials\u2014the ones we would call \u201cbrittle\u201d\u2014the object breaks for strains only a little above the point where the curve starts to bend over. In general, there are other complications in the stress-strain relationship. For example, if you strain an object, the stresses may be high at first, but decrease slowly with time. Also if you go to high stresses, but still not to the \u201cbreaking\u201d point, when you lower the strain the stress will return along a different curve. There is a small hysteresis effect (like the one we saw between B and H in magnetic materials). The stress at which a material will break varies widely from one material to another. Some materials will break when the maximum tensile stress reaches a certain value. Other materials will fail when the maximum shear stress reaches a certain value. Chalk is an example of a material which is much weaker in tension than in shear. If you pull on the ends of a piece of blackboard chalk, the chalk will break perpendicular to the direction of the applied stress, as shown in Fig. 39\u20139(a). It breaks perpendicular to the applied force because it is only a bunch of particles packed together which are easily pulled apart. The material is, however, much harder to shear, because the particles get in each other\u2019s way. Now you will remember that when we had a rod in torsion there was a shear all around it. Also, we showed that a shear was equivalent to a combination of a tension and compression at 45 \u2218 . For these reasons, if you twist a piece of blackboard chalk, it will break along a complicated surface which starts out at 45 \u2218 to the axis. A photograph of a piece of chalk broken in this way is shown in Fig. 39\u20139(b). The chalk breaks where the material is in maximum tension. Other materials behave in strange and complicated ways. The more complicated the materials are, the more interesting their behavior. If we take a sheet of \u201cSaran-Wrap\u201d and crumple it up into a ball and throw it on the table, it slowly unfolds itself and returns toward its original flat form. At first sight, we might be tempted to think that it is inertia which prevents it from returning to its original form. However, a simple calculation shows that the inertia is several orders of magnitude too small to account for the effect. There appear to be two important competing effects: \u201csomething\u201d inside the material \u201cremembers\u201d the shape it had initially and \u201ctries\u201d to get back there, but something else \u201cprefers\u201d the new shape and \u201cresists\u201d the return to the old shape. We will not attempt to describe the mechanism at play in the Saran plastic, but you can get an idea of how such an effect might come about from the following model. Suppose you imagine a material made of long, flexible, but strong, fibers mixed together with some hollow cells filled with a viscous liquid. Imagine also that there are narrow pathways from one cell to the next so the liquid can leak slowly from a cell to its neighbor. When we crumple a sheet of this stuff, we distort the long fibers, squeezing the liquid out of the cells in one place and forcing it into other cells which are being stretched. When we let go, the long fibers try to return to their original shape. But to do this, they have to force the liquid back to its original location\u2014which will happen relatively slowly because of the viscosity. The forces we apply in crumpling the sheet are much larger than the forces exerted by the fibers. We can crumple the sheet quickly, but it will return more slowly. It is undoubtedly a combination of large stiff molecules and smaller, movable ones in the Saran-Wrap that is responsible for its behavior. This idea also fits with the fact that the material returns more quickly to its original shape when it\u2019s warmed up than when it\u2019s cold\u2014the heat increases the mobility (decreases the viscosity) of the smaller molecules. Although we have been discussing how Hooke\u2019s law breaks down, the remarkable thing is perhaps not that Hooke\u2019s law breaks down for large strains but that it should be so generally true. We can get some idea of why this might be by looking at the strain energy in a material. To say that the stress is proportional to the strain is the same thing as saying that the strain energy varies as the square of the strain. Suppose we have a rod and we twist it through a small angle \u03b8 . If Hooke\u2019s law holds, the strain energy should be proportional to the square of \u03b8 . Suppose we were to assume that the energy were some arbitrary function of the angle; we could write it as a Taylor expansion about zero angle U(\u03b8)=U(0) + U \u2032 (0)\u03b8+ 1 2 U \u2032\u2032 (0) \u03b8 2 + 1 6 U \u2032\u2032\u2032 (0) \u03b8 3 +\u22ef (39.40) The torque \u03c4 is the derivative of U with respect to angle; we would have \u03c4(\u03b8)= U \u2032 (0)+ U \u2032\u2032 (0)\u03b8+ 1 2 U \u2032\u2032\u2032 (0) \u03b8 2 +\u22ef (39.41) Now if we measure our angles from the equilibrium position, the first term is zero. So the first remaining term is proportional to \u03b8 ; and for small enough angles, it will dominate the term in \u03b8 2 . [Actually, materials are sufficiently symmetric internally so that \u03c4(\u03b8)=\u2212\u03c4(\u2212\u03b8) ; the term in \u03b8 2 will be zero, and the departures from linearity would come only from the \u03b8 3 term. There is, however, no reason why this should be true for compressions and tensions.] The thing we have not explained is why materials usually break soon after the higher-order terms become significant. As our last topic on elasticity we would like to show how one could try to calculate the elastic constants of a material, starting with some knowledge of the properties of the atoms which make up the material. We will take only the simple case of an ionic cubic crystal like sodium chloride. When a crystal is strained, its volume or its shape is changed. Such changes result in an increase in the potential energy of the crystal. To calculate the change in strain energy, we have to know where each atom goes. In complicated crystals, the atoms will rearrange themselves in the lattice in very complicated ways to make the total energy as small as possible. This makes the computation of the strain energy rather difficult. In the case of a simple cubic crystal, however, it is easy to see what will happen. The distortions inside the crystal will be geometrically similar to the distortions of the outside boundaries of the crystal. We can calculate the elastic constants for a cubic crystal in the following way. First, we assume some force law between each pair of atoms in the crystal. Then, we calculate the change in the internal energy of the crystal when it is distorted from its equilibrium shape. This gives us a relation between the energy and the strains which is quadratic in all the strains. Comparing the energy obtained this way with Eq. (39.13), we can identify the coefficient of each term with the elastic constants C ijkl . For our example we will assume a simple force law: that the force between neighboring atoms is a central force, by which we mean that it acts along the line between the two atoms. We would expect the forces in ionic crystals to be like this, since they are just primarily Coulomb forces. (The forces of covalent bonds are usually more complicated, since they can exert a sideways push on a nearby atom; we will leave out this complication.) We are also going to include only the forces between each atom and its nearest and next-nearest neighbors. In other words, we will make an approximation which neglects all forces beyond the next-nearest neighbor. The forces we will include are shown for the xy -plane in Fig. 39\u201310(a). The corresponding forces in the yz - and zx -planes also have to be included. Since we are only interested in the elastic coefficients which apply to small strains, and therefore only want the terms in the energy which vary quadratically with the strains, we can imagine that the force between each atom pair varies linearly with the displacements. We can then imagine that each pair of atoms is joined by a linear spring, as drawn in Fig. 39\u201310(b). All of the springs between a sodium atom and a chlorine atom should have the same spring constant, say k 1 . The springs between two sodiums and between two chlorines could have different constants, but we will make our discussion simpler by taking them equal; we call them k 2 . (We could come back later and make them different after we have seen how the calculations go.) Now we assume that the crystal is distorted by a homogeneous strain described by the strain tensor e ij . In general, it will have components involving x , y , and z ; but we will consider now only a strain with the three components e xx , e xy , and e yy so that it will be easy to visualize. If we pick one atom as our origin, the displacement of every other atom is given by equations like Eq. (39.9): u x u y = e xx x+ e xy y, = e xy x+ e yy y. (39.42) Suppose we call the atom at x=y=0 \u201catom 1 \u201d and number its neighbors in the xy -plane as shown in Fig. 39\u201311. Calling the lattice constant a , we get the x and y displacements u x and u y listed in Table 39\u20131. Now we can calculate the energy stored in the springs, which is k/2 times the square of the extension for each spring. For example, the energy in the horizontal spring between atom 1 and atom 2 is k 1 ( e xx a ) 2 2 . (39.43) Note that to first order, the y -displacement of atom 2 does not change the length of the spring between atom 1 and atom 2 . To get the strain energy in a diagonal spring, such as that to atom 3 , however, we need to calculate the change in length due to both the horizontal and vertical displacements. For small displacements from the original cube, we can write the change in the distance to atom 3 as the sum of the components of u x and u y in the diagonal direction, namely as 1 2 \u2013 \u221a ( u x + u y ). 1 Using the values of u x and u y from the table, we get the energy k 2 2 ( u x + u y 2 \u2013 \u221a ) 2 = k 2 a 2 4 ( e xx + e yx + e xy + e yy ) 2 . (39.44) For the total energy for all the springs in the xy -plane, we need the sum of eight terms like (39.43) and (39.44). Calling this energy U 0 , we get U 0 = a 2 2 { k 1 e 2 xx + k 2 2 ( e xx + e yx + e xy + e yy ) 2 + k 1 e 2 yy + k 2 2 ( e xx \u2212 e yx \u2212 e xy + e yy ) 2 + k 1 e 2 xx + k 2 2 ( e xx + e yx + e xy + e yy ) 2 + k 1 e 2 yy + k 2 2 ( e xx \u2212 e yx \u2212 e xy + e yy ) 2 }. (39.45) To get the total energy of all the springs connected to atom 1 , we must make one addition to the energy in Eq. (39.45). Even though we have only x - and y -components of the strain, there are still some energies associated with the next-nearest neighbors off the xy -plane. This additional energy is k 2 ( e 2 xx a 2 + e 2 yy a 2 ). (39.46) The elastic constants are related to the energy density w by Eq. (39.13). The energy we have calculated is the energy associated with one atom, or rather, it is twice the energy per atom, since one-half of the energy of each spring should be assigned to each of the two atoms it joins. Since there are 1/ a 3 atoms per unit volume, w and U 0 are related by w= U 0 2 a 3 . U To find the elastic constants C ijkl , we need only to expand out the squares in Eq. (39.45)\u2014adding the terms of (39.46)\u2014and compare the coefficients of e ij e kl with the corresponding coefficient in Eq. (39.13). For example, collecting the terms in e 2 xx and in e 2 yy , we get the factor ( k 1 +2 k 2 ) a 2 , 2 so C xxxx = C yyyy = k 1 +2 k 2 a . k 2 k For the remaining terms, there is a slight complication. Since we cannot distinguish the product of two terms like e xx e yy , from e yy e xx , the coefficient of such terms in our energy is equal to the sum of two terms in Eq. (39.13). The coefficient of e xx e yy in Eq. (39.45) is 2 k 2 , so we have that ( C xxyy + C yyxx )= 2 k 2 a . 2 k But because of the symmetry in our crystal, C xxyy = C yyxx , so we have that C xxyy = C yyxx = k 2 a . k By a similar process, we can also get C xyxy = C yxyx = k 2 a . k Finally, you will notice that any term which involves either x or y only once is zero\u2014as we concluded earlier from symmetry arguments. Summarizing our results: C xxxx C xyxy C xxyy C xxxy = C yyyy = k 1 +2 k 2 a , = C yxyx = k 2 a , = C yyxx = C xyyx = C yxxy = k 2 a , = C xyyy =etc.=0. (39.47) We have been able to relate the bulk elastic constants to the atomic properties which appear in the constants k 1 and k 2 . In our particular case, C xyxy = C xxyy . It turns out\u2014as you can perhaps see from the way the calculations went\u2014that these terms are always equal for a cubic crystal, no matter how many force terms are taken into account, provided only that the forces act along the line joining each pair of atoms\u2014that is, so long as the forces between atoms are like springs and don\u2019t have a sideways part such as you might get from a cantilevered beam (and you do get in covalent bonds). We can check this conclusion with the experimental measurements of the elastic constants. In Table 39\u20132 we give the observed values of the three elastic coefficients for several cubic crystals.2 You will notice that C xxyy and C xyxy are, in general, not equal. The reason is that in metals like sodium and potassium the interatomic forces are not along the line joining the atoms, as we assumed in our model. Diamond does not obey the law either, because the forces in diamond are covalent forces and have some directional properties\u2014the bonds would prefer to be at the tetrahedral angle. The ionic crystals like lithium fluoride, sodium chloride, and so on, do have nearly all the physical properties assumed in our model, and the table shows that the constants C xxyy and C xyxy are almost equal. It is not clear why silver chloride should not satisfy the condition that C xxyy = C xyxy ."
    },
    {
        "input": "AC Circuits",
        "output": "Most of our work in this course has been aimed at reaching the complete equations of Maxwell. In the last two chapters we have been discussing the consequences of these equations. We have found that the equations contain all the static phenomena we had worked out earlier, as well as the phenomena of electromagnetic waves and light that we had gone over in some detail in Volume I. The Maxwell equations give both phenomena, depending upon whether one computes the fields close to the currents and charges, or very far from them. There is not much interesting to say about the intermediate region; no special phenomena appear there. There still remain, however, several subjects in electromagnetism that we want to take up. We want to discuss the question of relativity and the Maxwell equations\u2014what happens when one looks at the Maxwell equations with respect to moving coordinate systems. There is also the question of the conservation of energy in electromagnetic systems. Then there is the broad subject of the electromagnetic properties of materials; so far, except for the study of the properties of dielectrics, we have considered only the electromagnetic fields in free space. And although we covered the subject of light in some detail in Volume I, there are still a few things we would like to do again from the point of view of the field equations. In particular, we want to take up again the subject of the index of refraction, particularly for dense materials. Finally, there are the phenomena associated with waves confined in a limited region of space. We touched on this kind of problem briefly when we were studying sound waves. Maxwell\u2019s equations lead also to solutions which represent confined waves of the electric and magnetic fields. We will take up this subject, which has important technical applications, in some of the following chapters. In order to lead up to that subject, we will begin by considering the properties of electrical circuits at low frequencies. We will then be able to make a comparison between those situations in which the almost static approximations of Maxwell\u2019s equations are applicable and those situations in which high-frequency effects are dominant. So we descend from the great and esoteric heights of the last few chapters and turn to the relatively low-level subject of electrical circuits. We will see, however, that even such a mundane subject, when looked at in sufficient detail, can contain great complications. We have already discussed some of the properties of electrical circuits in Chapters 23 and 25 of Vol. I. Now we will cover some of the same material again, but in greater detail. Again we are going to deal only with linear systems and with voltages and currents which all vary sinusoidally; we can then represent all voltages and currents by complex numbers, using the exponential notation described in Chapter 23 of Vol. I. Thus a time-varying voltage V(t) will be written V(t)= \u02c6 V ei\u03c9t, where \u02c6 V represents a complex number that is independent of t . It is, of course, understood that the actual time-varying voltage V(t) is given by the real part of the complex function on the right-hand side of the equation. Similarly, all of our other time-varying quantities will be taken to vary sinusoidally at the same frequency \u03c9 . So we write I = \u02c6 I ei\u03c9t(current), E = \u02c6 E ei\u03c9t(emf), E = \u02c6 E ei\u03c9t(electric field), and so on. Most of the time we will write our equations in terms of V , I , E , \u2026 (instead of in terms of \u02c6 V , \u02c6 I , \u02c6 E , \u2026), remembering, though, that the time variations are as given in (22.2). In our earlier discussion of circuits we assumed that such things as inductances, capacitances, and resistances were familiar to you. We want now to look in a little more detail at what is meant by these idealized circuit elements. We begin with the inductance. An inductance is made by winding many turns of wire in the form of a coil and bringing the two ends out to terminals at some distance from the coil, as shown in Fig. 22\u20131. We want to assume that the magnetic field produced by currents in the coil does not spread out strongly all over space and interact with other parts of the circuit. This is usually arranged by winding the coil in a doughnut-shaped form, or by confining the magnetic field by winding the coil on a suitable iron core, or by placing the coil in some suitable metal box, as indicated schematically in Fig. 22\u20131. In any case, we assume that there is a negligible magnetic field in the external region near the terminals a and b . We are also going to assume that we can neglect any electrical resistance in the wire of the coil. Finally, we will assume that we can neglect the amount of electrical charge that appears on the surface of a wire in building up the electric fields. With all these approximations we have what we call an \u201cideal\u201d inductance. (We will come back later and discuss what happens in a real inductance.) For an ideal inductance we say that the voltage across the terminals is equal to L(dI/dt) . Let\u2019s see why that is so. When there is a current through the inductance, a magnetic field proportional to the current is built up inside the coil. If the current changes with time, the magnetic field also changes. In general, the curl of E is equal to \u2212\u2202B/\u2202t ; or, put differently, the line integral of E all the way around any closed path is equal to the negative of the rate of change of the flux of B through the loop. Now suppose we consider the following path: Begin at terminal a and go along the coil (staying always inside the wire) to terminal b ; then return from terminal b to terminal a through the air in the space outside the inductance. The line integral of E around this closed path can be written as the sum of two parts: \u222eE\u22c5ds=\u222b b a via coil E\u22c5ds+\u222b a b outsideE\u22c5ds. As we have seen before, there can be no electric fields inside a perfect conductor. (The smallest fields would produce infinite currents.) Therefore the integral from a to b via the coil is zero. The whole contribution to the line integral of E comes from the path outside the inductance from terminal b to terminal a . Since we have assumed that there are no magnetic fields in the space outside of the \u201cbox,\u201d this part of the integral is independent of the path chosen and we can define the potentials of the two terminals. The difference of these two potentials is what we call the voltage difference, or simply the voltage V , so we have V=\u2212\u222b a b E\u22c5ds=\u2212\u222eE\u22c5ds. The complete line integral is what we have before called the electromotive force E and is, of course, equal to the rate of change of the magnetic flux in the coil. We have seen earlier that this emf is proportional to the negative rate of change of the current, so we have V=\u2212E=L dI dt , d I where L is the inductance of the coil. Since dI/dt=i\u03c9I , we have V=i\u03c9LI. (22.4) The way we have described the ideal inductance illustrates the general approach to other ideal circuit elements\u2014usually called \u201clumped\u201d elements. The properties of the element are described completely in terms of currents and voltages that appear at the terminals. By making suitable approximations, it is possible to ignore the great complexities of the fields that appear inside the object. A separation is made between what happens inside and what happens outside. For all the circuit elements we will find a relation like the one in Eq. (22.4), in which the voltage is proportional to the current with a proportionality constant that is, in general, a complex number. This complex coefficient of proportionality is called the impedance and is usually written as z (not to be confused with the z -coordinate). It is, in general, a function of the frequency \u03c9 . So for any lumped element we write V I = V ^ I ^ =z. (22.5) For an inductance, we have z(inductance)= z L =i\u03c9L. (22.6) Now let\u2019s look at a capacitor from the same point of view.1 A capacitor consists of a pair of conducting plates from which two wires are brought out to suitable terminals. The plates may be of any shape whatsoever, and are often separated by some dielectric material. We illustrate such a situation schematically in Fig. 22\u20132. Again we make several simplifying assumptions. We assume that the plates and the wires are perfect conductors. We also assume that the insulation between the plates is perfect, so that no charges can flow across the insulation from one plate to the other. Next, we assume that the two conductors are close to each other but far from all others, so that all field lines which leave one plate end up on the other. Then there are always equal and opposite charges on the two plates and the charges on the plates are much larger than the charges on the surfaces of the lead-in wires. Finally, we assume that there are no magnetic fields close to the capacitor. Suppose now we consider the line integral of E around a closed loop which starts at terminal a , goes along inside the wire to the top plate of the capacitor, jumps across the space between the plates, passes from the lower plate to terminal b through the wire, and returns to terminal a in the space outside the capacitor. Since there is no magnetic field, the line integral of E around this closed path is zero. The integral can be broken down into three parts: \u222eE\u22c5ds= \u222b along wires E\u22c5ds+ \u222b between plates E\u22c5ds+ \u222b a b outside E\u22c5ds. (22.7) The integral along the wires is zero, because there are no electric fields inside perfect conductors. The integral from b to a outside the capacitor is equal to the negative of the potential difference between the terminals. Since we imagined that the two plates are in some way isolated from the rest of the world, the total charge on the two plates must be zero; if there is a charge Q on the upper plate, there is an equal, opposite charge \u2212Q on the lower plate. We have seen earlier that if two conductors have equal and opposite charges, plus and minus Q , the potential difference between the plates is equal to Q/C , where C is called the capacity of the two conductors. From Eq. (22.7) the potential difference between the terminals a and b is equal to the potential difference between the plates. We have, therefore, that V= Q C . Q The electric current I entering the capacitor through terminal a (and leaving through terminal b ) is equal to dQ/dt , the rate of change of the electric charge on the plates. Writing dV/dt as i\u03c9V , we can put the voltage current relationship for a capacitor in the following way: i\u03c9V= I C , I or V= I i\u03c9C . (22.8) The impedance z of a capacitor, is then z(capacitor)= z C = 1 i\u03c9C . (22.9) The third element we want to consider is a resistor. However, since we have not yet discussed the electrical properties of real materials, we are not yet ready to talk about what happens inside a real conductor. We will just have to accept as fact that electric fields can exist inside real materials, that these electric fields give rise to a flow of electric charge\u2014that is, to a current\u2014and that this current is proportional to the integral of the electric field from one end of the conductor to the other. We then imagine an ideal resistor constructed as in the diagram of Fig. 22\u20133. Two wires which we take to be perfect conductors go from the terminals a and b to the two ends of a bar of resistive material. Following our usual line of argument, the potential difference between the terminals a and b is equal to the line integral of the external electric field, which is also equal to the line integral of the electric field through the bar of resistive material. It then follows that the current I through the resistor is proportional to the terminal voltage V : I= V R , V where R is called the resistance. We will see later that the relation between the current and the voltage for real conducting materials is only approximately linear. We will also see that this approximate proportionality is expected to be independent of the frequency of variation of the current and voltage only if the frequency is not too high. For alternating currents then, the voltage across a resistor is in phase with the current, which means that the impedance is a real number: z(resistance)= z R =R. (22.10) Our results for the three lumped circuit elements\u2014the inductor, the capacitor, and the resistor\u2014are summarized in Fig. 22\u20134. In this figure, as well as in the preceding ones, we have indicated the voltage by an arrow that is directed from one terminal to another. If the voltage is \u201cpositive\u201d\u2014that is, if the terminal a is at a higher potential than the terminal b \u2014the arrow indicates the direction of a positive \u201cvoltage drop.\u201d Although we are talking about alternating currents, we can of course include the special case of circuits with steady currents by taking the limit as the frequency \u03c9 goes to zero. For zero frequency\u2014that is, for dc\u2014the impedance of an inductance goes to zero; it becomes a short circuit. For dc, the impedance of a condenser goes to infinity; it becomes an open circuit. Since the impedance of a resistor is independent of frequency, it is the only element left when we analyze a circuit for dc. In the circuit elements we have described so far, the current and voltage are proportional to each other. If one is zero, so also is the other. We usually think in terms like these: An applied voltage is \u201cresponsible\u201d for the current, or a current \u201cgives rise to\u201d a voltage across the terminals; so in a sense the elements \u201crespond\u201d to the \u201capplied\u201d external conditions. For this reason these elements are called passive elements. They can thus be contrasted with the active elements, such as the generators we will consider in the next section, which are the sources of the oscillating currents or voltages in a circuit. Now we want to talk about an active circuit element\u2014one that is a source of the currents and voltages in a circuit\u2014namely, a generator. Suppose that we have a coil like an inductance except that it has very few turns, so that we may neglect the magnetic field of its own current. This coil, however, sits in a changing magnetic field such as might be produced by a rotating magnet, as sketched in Fig. 22\u20135. (We have seen earlier that such a rotating magnetic field can also be produced by a suitable set of coils with alternating currents.) Again we must make several simplifying assumptions. The assumptions we will make are all the ones that we described for the case of the inductance. In particular, we assume that the varying magnetic field is restricted to a definite region in the vicinity of the coil and does not appear outside the generator in the space between the terminals. Following closely the analysis we made for the inductance, we consider the line integral of E around a complete loop that starts at terminal a , goes through the coil to terminal b and returns to its starting point in the space between the two terminals. Again we conclude that the potential difference between the terminals is equal to the total line integral of E around the loop: V=\u2212\u222eE\u22c5ds. \u222e This line integral is equal to the emf in the circuit, so the potential difference V across the terminals of the generator is also equal to the rate of change of the magnetic flux linking the coil: V=\u2212E= d dt (flux). (22.11) For an ideal generator we assume that the magnetic flux linking the coil is determined by external conditions\u2014such as the angular velocity of a rotating magnetic field\u2014and is not influenced in any way by the currents through the generator. Thus a generator\u2014at least the ideal generator we are considering\u2014is not an impedance. The potential difference across its terminals is determined by the arbitrarily assigned electromotive force E(t) . Such an ideal generator is represented by the symbol shown in Fig. 22\u20136. The little arrow represents the direction of the emf when it is positive. A positive emf in the generator of Fig. 22\u20136 will produce a voltage V=E , with the terminal a at a higher potential than the terminal b . There is another way to make a generator which is quite different on the inside but which is indistinguishable from the one we have just described insofar as what happens beyond its terminals. Suppose we have a coil of wire which is rotated in a fixed magnetic field, as indicated in Fig. 22\u20137. We show a bar magnet to indicate the presence of a magnetic field; it could, of course, be replaced by any other source of a steady magnetic field, such as an additional coil carrying a steady current. As shown in the figure, connections from the rotating coil are made to the outside world by means of sliding contacts or \u201cslip rings.\u201d Again, we are interested in the potential difference that appears across the two terminals a and b , which is of course the integral of the electric field from terminal a to terminal b along a path outside the generator. Now in the system of Fig. 22\u20137 there are no changing magnetic fields, so we might at first wonder how any voltage could appear at the generator terminals. In fact, there are no electric fields anywhere inside the generator. We are, as usual, assuming for our ideal elements that the wires inside are made of a perfectly conducting material, and as we have said many times, the electric field inside a perfect conductor is equal to zero. But that is not true. It is not true when a conductor is moving in a magnetic field. The true statement is that the total force on any charge inside a perfect conductor must be zero. Otherwise there would be an infinite flow of the free charges. So what is always true is that the sum of the electric field E and the cross product of the velocity of the conductor and the magnetic field B \u2014which is the total force on a unit charge\u2014must have the value zero inside the conductor: F/unit charge =E+v\u00d7B =0(in a perfect conductor), (22.12) where v represents the velocity of the conductor. Our earlier statement that there is no electric field inside a perfect conductor is all right if the velocity v of the conductor is zero; otherwise the correct statement is given by Eq. (22.12). Returning to our generator of Fig. 22\u20137, we now see that the line integral of the electric field E from terminal a to terminal b through the conducting path of the generator must be equal to the line integral of v\u00d7B on the same path, \u222b b a inside conductor E\u22c5ds=\u2212 \u222b b a inside conductor (v\u00d7B)\u22c5ds. (22.13) It is still true, however, that the line integral of E around a complete loop, including the return from b to a outside the generator, must be zero, because there are no changing magnetic fields. So the first integral in Eq. (22.13) is also equal to V , the voltage between the two terminals. It turns out that the right-hand integral of Eq. (22.13) is just the rate of change of the flux linkage through the coil and is therefore\u2014by the flux rule\u2014equal to the emf in the coil. So we have again that the potential difference across the terminals is equal to the electromotive force in the circuit, in agreement with Eq. (22.11). So whether we have a generator in which a magnetic field changes near a fixed coil, or one in which a coil moves in a fixed magnetic field, the external properties of the generators are the same. There is a voltage difference V across the terminals, which is independent of the current in the circuit but depends only on the arbitrarily assigned conditions inside the generator. So long as we are trying to understand the operation of generators from the point of view of Maxwell\u2019s equations, we might also ask about the ordinary chemical cell, like a flashlight battery. It is also a generator, i.e., a voltage source, although it will of course only appear in dc circuits. The simplest kind of cell to understand is shown in Fig. 22\u20138. We imagine two metal plates immersed in some chemical solution. We suppose that the solution contains positive and negative ions. We suppose also that one kind of ion, say the negative, is much heavier than the one of opposite polarity, so that its motion through the solution by the process of diffusion is much slower. We suppose next that by some means or other it is arranged that the concentration of the solution is made to vary from one part of the liquid to the other, so that the number of ions of both polarities near, say, the lower plate is much larger than the concentration of ions near the upper plate. Because of their rapid mobility the positive ions will drift more readily into the region of lower concentration, so that there will be a slight excess of positive charge arriving at the upper plate. The upper plate will become positively charged and the lower plate will have a net negative charge. As more and more charges diffuse to the upper plate, the potential of this plate will rise until the resulting electric field between the plates produces forces on the ions which just compensate for their excess mobility, so the two plates of the cell quickly reach a potential difference which is characteristic of the internal construction. Arguing just as we did for the ideal capacitor, we see that the potential difference between the terminals a and b is just equal to the line integral of the electric field between the two plates when there is no longer any net diffusion of the ions. There is, of course, an essential difference between a capacitor and such a chemical cell. If we short-circuit the terminals of a condenser for a moment, the capacitor is discharged and there is no longer any potential difference across the terminals. In the case of the chemical cell a current can be drawn from the terminals continuously without any change in the emf\u2014until, of course, the chemicals inside the cell have been used up. In a real cell it is found that the potential difference across the terminals decreases as the current drawn from the cell increases. In keeping with the abstractions we have been making, however, we may imagine an ideal cell in which the voltage across the terminals is independent of the current. A real cell can then be looked at as an ideal cell in series with a resistor. As we have seen in the last section, the description of an ideal circuit element in terms of what happens outside the element is quite simple. The current and the voltage are linearly related. But what is actually happening inside the element is quite complicated, and it is quite difficult to give a precise description in terms of Maxwell\u2019s equations. Imagine trying to give a precise description of the electric and magnetic fields of the inside of a radio which contains hundreds of resistors, capacitors, and inductors. It would be an impossible task to analyze such a thing by using Maxwell\u2019s equations. But by making the many approximations we have described in Section 22\u20132 and summarizing the essential features of the real circuit elements in terms of idealizations, it becomes possible to analyze an electrical circuit in a relatively straightforward way. We will now show how that is done. Suppose we have a circuit consisting of a generator and several impedances connected together, as shown in Fig. 22\u20139. According to our approximations there is no magnetic field in the region outside the individual circuit elements. Therefore the line integral of E around any curve which does not pass through any of the elements is zero. Consider then the curve \u0393 shown by the broken line which goes all the way around the circuit in Fig. 22\u20139. The line integral of E around this curve is made up of several pieces. Each piece is the line integral from one terminal of a circuit element to the other. This line integral we have called the voltage drop across the circuit element. The complete line integral is then just the sum of the voltage drops across all of the elements in the circuit: \u222eE\u22c5ds=\u2211 V n . \u222e Since the line integral is zero, we have that the sum of the potential differences around a complete loop of a circuit is equal to zero: \u2211 around any loop V n =0. (22.14) This result follows from one of Maxwell\u2019s equations\u2014that in a region where there are no magnetic fields the line integral of E around any complete loop is zero. Suppose we consider now a circuit like that shown in Fig. 22\u201310. The horizontal line joining the terminals a , b , c , and d is intended to show that these terminals are all connected, or that they are joined by wires of negligible resistance. In any case, the drawing means that terminals a , b , c , and d are all at the same potential and, similarly, that the terminals e , f , g , and h are also at one common potential. Then the voltage drop V across each of the four elements is the same. Now one of our idealizations has been that negligible electrical charges accumulate on the terminals of the impedances. We now assume further that any electrical charges on the wires joining terminals can also be neglected. Then the conservation of charge requires that any charge which leaves one circuit element immediately enters some other circuit element. Or, what is the same thing, we require that the algebraic sum of the currents which enter any given junction must be zero. By a junction, of course, we mean any set of terminals such as a , b , c , and d which are connected. Such a set of connected terminals is usually called a \u201cnode.\u201d The conservation of charge then requires that for the circuit of Fig. 22\u201310, I 1 \u2212 I 2 \u2212 I 3 \u2212 I 4 =0. (22.15) The sum of the currents entering the node which consists of the four terminals e , f , g , and h must also be zero: \u2212 I 1 + I 2 + I 3 + I 4 =0. (22.16) This is, of course, the same as Eq. (22.15). The two equations are not independent. The general rule is that the sum of the currents into any node must be zero: \u2211 into a node I n =0. (22.17) Our earlier conclusion that the sum of the voltage drops around a closed loop is zero must apply to any loop in a complicated circuit. Also, our result that the sum of the currents into a node is zero must be true for any node. These two equations are known as Kirchhoff\u2019s rules. With these two rules it is possible to solve for the currents and voltages in any network whatever. Suppose we consider the more complicated circuit of Fig. 22\u201311. How shall we find the currents and voltages in this circuit? We can find them in the following straightforward way. We consider separately each of the four subsidiary closed loops, which appear in the circuit. (For instance, one loop goes from terminal a to terminal b to terminal e to terminal d and back to terminal a .) For each of the loops we write the equation for the first of Kirchhoff\u2019s rules\u2014that the sum of the voltages around each loop is equal to zero. We must remember to count the voltage drop as positive if we are going in the direction of the current and negative if we are going across an element in the direction opposite to the current; and we must remember that the voltage drop across a generator is the negative of the emf in that direction. Thus if we consider the small loop that starts and ends at terminal a we have the equation z 1 I 1 + z 3 I 3 + z 4 I 4 \u2212 E 1 =0. I I I E 0. Applying the same rule to the remaining loops, we would get three more equations of the same kind. Next, we must write the current equation for each of the nodes in the circuit. For example, summing the currents into the node at terminal b gives the equation I 1 \u2212 I 3 \u2212 I 2 =0. I I I 0. Similarly, for the node labeled e we would have the current equation I 3 \u2212 I 4 + I 8 \u2212 I 5 =0. I I I I 0. For the circuit shown there are five such current equations. It turns out, however, that any one of these equations can be derived from the other four; there are, therefore, only four independent current equations. We thus have a total of eight independent, linear equations: the four voltage equations and the four current equations. With these eight equations we can solve for the eight unknown currents. Once the currents are known the circuit is solved. The voltage drop across any element is given by the current through that element times its impedance (or, in the case of the voltage sources, it is already known). We have seen that when we write the current equations, we get one equation which is not independent of the others. Generally it is also possible to write down too many voltage equations. For example, in the circuit of Fig. 22\u201311, although we have considered only the four small loops, there are a large number of other loops for which we could write the voltage equation. There is, for example, the loop along the path abcfeda . There is another loop which follows the path abcfehgda . You can see that there are many loops. In analyzing complicated circuits it is very easy to get too many equations. There are rules which tell us how to proceed so that only the minimum number of equations is written down, but usually with a little thought it is possible to see how to get the right number of equations in the simplest form. Besides, writing an extra equation or two doesn\u2019t do any harm. They will not lead to any wrong answers, only perhaps a little unnecessary algebra. In Chapter 25 of Vol. I we showed that if the two impedances z 1 and z 2 are in series, they are equivalent to a single impedance z s given by z s = z 1 + z 2 . (22.18) We also showed that if the two impedances are connected in parallel, they are equivalent to the single impedance z p given by z p = 1 (1/ z 1 )+(1/ z 2 ) = z 1 z 2 z 1 + z 2 . (22.19) If you look back you will see that in deriving these results we were in effect making use of Kirchhoff\u2019s rules. It is often possible to analyze a complicated circuit by repeated application of the formulas for series and parallel impedances. For instance, the circuit of Fig. 22\u201312 can be analyzed that way. First, the impedances z 4 and z 5 can be replaced by their parallel equivalent, and so also can z 6 and z 7 . Then the impedance z 2 can be combined with the parallel equivalent of z 6 and z 7 by the series rule. Proceeding in this way, the whole circuit can be reduced to a generator in series with a single impedance Z . The current through the generator is then just E/Z . Then by working backward one can solve for the currents in each of the impedances. There are, however, quite simple circuits which cannot be analyzed by this method, as for example the circuit of Fig. 22\u201313. To analyze this circuit we must write down the current and voltage equations from Kirchhoff\u2019s rules. Let\u2019s do it. There is just one current equation: I 1 + I 2 + I 3 =0, I I I 0 so we know immediately that I 3 =\u2212( I 1 + I 2 ). ( ) We can save ourselves some algebra if we immediately make use of this result in writing the voltage equations. For this circuit there are two independent voltage equations; they are \u2212 E 1 + I 2 z 2 \u2212 I 1 z 1 =0 E I I 0 and E 2 \u2212( I 1 + I 2 ) z 3 \u2212 I 2 z 2 =0. ( ) There are two equations and two unknown currents. Solving these equations for I 1 and I 2 , we get I 1 = z 2 E 2 \u2212( z 2 + z 3 ) E 1 z 1 ( z 2 + z 3 )+ z 2 z 3 (22.20) and I 2 = z 1 E 2 + z 3 E 1 z 1 ( z 2 + z 3 )+ z 2 z 3 . (22.21) The third current is obtained from the sum of these two. Another example of a circuit that cannot be analyzed by using the rules for series and parallel impedance is shown in Fig. 22\u201314. Such a circuit is called a \u201cbridge.\u201d It appears in many instruments used for measuring impedances. With such a circuit one is usually interested in the question: How must the various impedances be related if the current through the impedance z 3 is to be zero? We leave it for you to find the conditions for which this is so. Suppose we connect a generator E to a circuit containing some complicated interconnection of impedances, as indicated schematically in Fig. 22\u201315(a). All of the equations we get from Kirchhoff\u2019s rules are linear, so when we solve them for the current I through the generator, we will get that I is proportional to E . We can write I= E z eff , E where now z eff is some complex number, an algebraic function of all the elements in the circuit. (If the circuit contains no generators other than the one shown, there is no additional term independent of E .) But this equation is just what we would write for the circuit of Fig. 22\u201315(b). So long as we are interested only in what happens to the left of the two terminals a and b , the two circuits of Fig. 22\u201315 are equivalent. We can, therefore, make the general statement that any two-terminal network of passive elements can be replaced by a single impedance z eff without changing the currents and voltages in the rest of the circuit. This statement is of course, just a remark about what comes out of Kirchhoff\u2019s rules\u2014and ultimately from the linearity of Maxwell\u2019s equations. The idea can be generalized to a circuit that contains generators as well as impedances. Suppose we look at such a circuit \u201cfrom the point of view\u201d of one of the impedances, which we will call z n , as in Fig. 22\u201316(a). If we were to solve the equation for the whole circuit, we would find that the voltage V n between the two terminals a and b is a linear function of I n , which we can write V n =A\u2212B I n , (22.22) where A and B depend on the generators and impedances in the circuit to the left of the terminals. For instance, for the circuit of Fig. 22\u201313, we find V 1 = I 1 z 1 . This can be written [by rearranging Eq. (22.20)] as V 1 =[( z 2 z 2 + z 3 ) E 2 \u2212 E 1 ]\u2212 z 2 z 3 z 2 + z 3 I 1 . (22.23) The complete solution is then obtained by combining this equation with the one for the impedance z 1 , namely, V 1 = I 1 z 1 , or in the general case, by combining Eq. (22.22) with V n = I n z n . V I If now we consider that z n is attached to a simple series circuit of a generator and an impedance, as in Fig. 22\u201316(b), the equation corresponding to Eq. (22.22) is V n = E eff \u2212 I n z eff , V E I which is identical to Eq. (22.22) provided we set E eff =A and z eff =B . So if we are interested only in what happens to the right of the terminals a and b , the arbitrary circuit of Fig. 22\u201316 can always be replaced by an equivalent combination of a generator in series with an impedance. We have seen that to build up the current I in an inductance, the energy U= 1 2 L I 2 must be provided by the external circuit. When the current falls back to zero, this energy is delivered back to the external circuit. There is no energy-loss mechanism in an ideal inductance. When there is an alternating current through an inductance, energy flows back and forth between it and the rest of the circuit, but the average rate at which energy is delivered to the circuit is zero. We say that an inductance is a nondissipative element; no electrical energy is dissipated\u2014that is, \u201clost\u201d\u2014in it. Similarly, the energy of a condenser, U= 1 2 C V 2 , is returned to the external circuit when a condenser is discharged. When a condenser is in an ac circuit energy flows in and out of it, but the net energy flow in each cycle is zero. An ideal condenser is also a nondissipative element. We know that an emf is a source of energy. When a current I flows in the direction of the emf, energy is delivered to the external circuit at the rate dU/dt=EI . If current is driven against the emf\u2014by other generators in the circuit\u2014the emf will absorb energy at the rate EI ; since I is negative, dU/dt will also be negative. If a generator is connected to a resistor R , the current through the resistor is I=E/R . The energy being supplied by the generator at the rate EI is being absorbed by the resistor. This energy goes into heat in the resistor and is lost from the electrical energy of the circuit. We say that electrical energy is dissipated in a resistor. The rate at which energy is dissipated in a resistor is dU/dt=R I 2 . In an ac circuit the average rate of energy lost to a resistor is the average of R I 2 over one cycle. Since I= I ^ e i\u03c9t \u2014by which we really mean that I varies as cos\u03c9t \u2014the average of I 2 over one cycle is | I ^ | 2 /2 , since the peak current is | I ^ | and the average of cos 2 \u03c9t is 1/2 . What about the energy loss when a generator is connected to an arbitrary impedance z ? (By \u201closs\u201d we mean, of course, conversion of electrical energy into thermal energy.) Any impedance z can be written as the sum of its real and imaginary parts. That is, z=R+iX, (22.24) where R and X are real numbers. From the point of view of equivalent circuits we can say that any impedance is equivalent to a resistance in series with a pure imaginary impedance\u2014called a reactance\u2014as shown in Fig. 22\u201317. We have seen earlier that any circuit that contains only L \u2019s and C \u2019s has an impedance that is a pure imaginary number. Since there is no energy loss into any of the L \u2019s and C \u2019s on the average, a pure reactance containing only L \u2019s and C \u2019s will have no energy loss. We can see that this must be true in general for a reactance. If a generator with the emf E is connected to the impedance z of Fig. 22\u201317, the emf must be related to the current I from the generator by E=I(R+iX). (22.25) To find the average rate at which energy is delivered, we want the average of the product EI . Now we must be careful. When dealing with such products, we must deal with the real quantities E(t) and I(t) . (The real parts of the complex functions will represent the actual physical quantities only when we have linear equations; now we are concerned with products, which are certainly not linear.) Suppose we choose our origin of t so that the amplitude I ^ is a real number, let\u2019s say I 0 ; then the actual time variation I is given by I= I 0 cos\u03c9t. I I t The emf of Eq. (22.25) is the real part of I 0 e i\u03c9t (R+iX) i t or E= I 0 Rcos\u03c9t\u2212 I 0 Xsin\u03c9t. (22.26) The two terms in Eq. (22.26) represent the voltage drops across R and X in Fig. 22\u201317. We see that the voltage drop across the resistance is in phase with the current, while the voltage drop across the purely reactive part is out of phase with the current. The average rate of energy loss, \u27e8P \u27e9 av , from the generator is the integral of the product EI over one cycle divided by the period T ; in other words, \u27e8P \u27e9 av = 1 T \u222b T 0 = 1 T \u222b T 0 \u2212 EIdt I 2 0 R cos 2 \u03c9tdt 1 T \u222b T 0 I 2 0 Xcos\u03c9tsin\u03c9tdt. The first integral is 1 2 I 2 0 R , and the second integral is zero. So the average energy loss in an impedance z=R+iX depends only on the real part of z , and is I 2 0 R/2 , which is in agreement with our earlier result for the energy loss in a resistor. There is no energy loss in the reactive part. We would like now to consider an interesting circuit which can be analyzed in terms of series and parallel combinations. Suppose we start with the circuit of Fig. 22\u201318(a). We can see right away that the impedance from terminal a to terminal b is simply z 1 + z 2 . Now let\u2019s take a little harder circuit, the one shown in Fig. 22\u201318(b). We could analyze this circuit using Kirchhoff\u2019s rules, but it is also easy to handle with series and parallel combinations. We can replace the two impedances on the right-hand end by a single impedance z 3 = z 1 + z 2 , as in part (c) of the figure. Then the two impedances z 2 and z 3 can be replaced by their equivalent parallel impedance z 4 , as shown in part (d) of the figure. Finally, z 1 and z 4 are equivalent to a single impedance z 5 , as shown in part (e). Now we may ask an amusing question: What would happen if in the network of Fig. 22\u201318(b) we kept on adding more sections forever\u2014as we indicate by the dashed lines in Fig. 22\u201319(a)? Can we solve such an infinite network? Well, that\u2019s not so hard. First, we notice that such an infinite network is unchanged if we add one more section at the \u201cfront\u201d end. Surely, if we add one more section to an infinite network it is still the same infinite network. Suppose we call the impedance between the two terminals a and b of the infinite network z 0 ; then the impedance of all the stuff to the right of the two terminals c and d is also z 0 . Therefore, so far as the front end is concerned, we can represent the network as shown in Fig. 22\u201319(b). Forming the parallel combination of z 2 with z 0 and adding the result in series with z 1 , we can immediately write down the impedance of this circuit: z= z 1 + 1 (1/ z 2 )+(1/ z 0 ) orz= z 1 + z 2 z 0 z 2 + z 0 . 1 But this impedance is also equal to z 0 , so we have the equation z 0 = z 1 + z 2 z 0 z 2 + z 0 . z z We can solve for z 0 to get z 0 = z 1 2 + ( z 2 1 /4)+ z 1 z 2 \u2212 \u2212 \u2212 \u2212 \u2212 \u2212 \u2212 \u2212 \u2212 \u2212 \u2212 \u221a . (22.27) So we have found the solution for the impedance of an infinite ladder of repeated series and parallel impedances. The impedance z 0 is called the characteristic impedance of such an infinite network. Let\u2019s now consider a specific example in which the series element is an inductance L and the shunt element is a capacitance C , as shown in Fig. 22\u201320(a). In this case we find the impedance of the infinite network by setting z 1 =i\u03c9L and z 2 =1/i\u03c9C . Notice that the first term, z 1 /2 , in Eq. (22.27) is just one-half the impedance of the first element. It would therefore seem more natural, or at least somewhat simpler, if we were to draw our infinite network as shown in Fig. 22\u201320(b). Looking at the infinite network from the terminal a \u2032 we would see the characteristic impedance z 0 = (L/C)\u2212( \u03c9 2 L 2 /4) \u2212 \u2212 \u2212 \u2212 \u2212 \u2212 \u2212 \u2212 \u2212 \u2212 \u2212 \u2212 \u2212 \u2212 \u2212 \u221a . (22.28) Now there are two interesting cases, depending on the frequency \u03c9 . If \u03c9 2 is less than 4/LC , the second term in the radical will be smaller than the first, and the impedance z 0 will be a real number. On the other hand, if \u03c9 2 is greater than 4/LC the impedance z 0 will be a pure imaginary number which we can write as z 0 =i ( \u03c9 2 L 2 /4)\u2212(L/C) \u2212 \u2212 \u2212 \u2212 \u2212 \u2212 \u2212 \u2212 \u2212 \u2212 \u2212 \u2212 \u2212 \u2212 \u2212 \u221a . We have said earlier that a circuit which contains only imaginary impedances, such as inductances and capacitances, will have an impedance which is purely imaginary. How can it be then that for the circuit we are now studying\u2014which has only L \u2019s and C \u2019s\u2014the impedance is a pure resistance for frequencies below 4/LC \u2212 \u2212 \u2212 \u2212 \u2212 \u221a ? For higher frequencies the impedance is purely imaginary, in agreement with our earlier statement. For lower frequencies the impedance is a pure resistance and will therefore absorb energy. But how can the circuit continuously absorb energy, as a resistance does, if it is made only of inductances and capacitances? Answer: Because there is an infinite number of inductances and capacitances, so that when a source is connected to the circuit, it supplies energy to the first inductance and capacitance, then to the second, to the third, and so on. In a circuit of this kind, energy is continually absorbed from the generator at a constant rate and flows constantly out into the network, supplying energy which is stored in the inductances and capacitances down the line. This idea suggests an interesting point about what is happening in the circuit. We would expect that if we connect a source to the front end, the effects of this source will be propagated through the network toward the infinite end. The propagation of the waves down the line is much like the radiation from an antenna which absorbs energy from its driving source; that is, we expect such a propagation to occur when the impedance is real, which occurs if \u03c9 is less than 4/LC \u2212 \u2212 \u2212 \u2212 \u2212 \u221a . But when the impedance is purely imaginary, which happens for \u03c9 greater than 4/LC \u2212 \u2212 \u2212 \u2212 \u2212 \u221a , we would not expect to see any such propagation. We saw in the last section that the infinite ladder network of Fig. 22\u201320 absorbs energy continuously if it is driven at a frequency below a certain critical frequency 4/LC \u2212 \u2212 \u2212 \u2212 \u2212 \u221a , which we will call the cutoff frequency \u03c9 0 . We suggested that this effect could be understood in terms of a continuous transport of energy down the line. On the other hand, at high frequencies, for w> \u03c9 0 , there is no continuous absorption of energy; we should then expect that perhaps the currents don\u2019t \u201cpenetrate\u201d very far down the line. Let\u2019s see whether these ideas are right. Suppose we have the front end of the ladder connected to some ac generator and we ask what the voltage looks like at, say, the 754 th section of the ladder. Since the network is infinite, whatever happens to the voltage from one section to the next is always the same; so let\u2019s just look at what happens when we go from some section, say the n th to the next. We will define the currents I n and voltages V n as shown in Fig. 22\u201321(a). We can get the voltage V n+1 from V n by remembering that we can always replace the rest of the ladder after the n th section by its characteristic impedance z 0 ; then we need only analyze the circuit of Fig. 22\u201321(b). First, we notice that any V n , since it is across z 0 , must equal I n z 0 . Also, the difference between V n and V n+1 is just I n z 1 : V n \u2212 V n+1 = I n z 1 = V n z 1 z 0 . z So we get the ratio V n+1 V n =1\u2212 z 1 z 0 = z 0 \u2212 z 1 z 0 . V We can call this ratio the propagation factor for one section of the ladder; we\u2019ll call it \u03b1 . It is, of course, the same for all sections: \u03b1= z 0 \u2212 z 1 z 0 . (22.29) The voltage after the n th section is then V n = \u03b1 n E. (22.30) You can now find the voltage after 754 sections; it is just \u03b1 to the 754 th power times E . Suppose we see what \u03b1 is like for the L - C ladder of Fig. 22\u201320(a). Using z 0 from Eq. (22.27), and z 1 =i\u03c9L , we get \u03b1= (L/C)\u2212( \u03c9 2 L 2 /4) \u2212 \u2212 \u2212 \u2212 \u2212 \u2212 \u2212 \u2212 \u2212 \u2212 \u2212 \u2212 \u2212 \u2212 \u2212 \u221a \u2212i(\u03c9L/2) (L/C)\u2212( \u03c9 2 L 2 /4) \u2212 \u2212 \u2212 \u2212 \u2212 \u2212 \u2212 \u2212 \u2212 \u2212 \u2212 \u2212 \u2212 \u2212 \u2212 \u221a +i(\u03c9L/2) . (22.31) If the driving frequency is below the cutoff frequency \u03c9 0 = 4/LC \u2212 \u2212 \u2212 \u2212 \u2212 \u221a , the radical is a real number, and the magnitudes of the complex numbers in the numerator and denominator are equal. Therefore, the magnitude of \u03b1 is one; we can write \u03b1= e i\u03b4 , i \u03b4 which means that the magnitude of the voltage is the same at every section; only its phase changes. The phase change \u03b4 is, in fact, a negative number and represents the \u201cdelay\u201d of the voltage as it passes along the network. For frequencies above the cutoff frequency \u03c9 0 it is better to factor out an i from the numerator and denominator of Eq. (22.31) and rewrite it as \u03b1= ( \u03c9 2 L 2 /4)\u2212(L/C) \u2212 \u2212 \u2212 \u2212 \u2212 \u2212 \u2212 \u2212 \u2212 \u2212 \u2212 \u2212 \u2212 \u2212 \u2212 \u221a \u2212(\u03c9L/2) ( \u03c9 2 L 2 /4)\u2212(L/C) \u2212 \u2212 \u2212 \u2212 \u2212 \u2212 \u2212 \u2212 \u2212 \u2212 \u2212 \u2212 \u2212 \u2212 \u2212 \u221a +(\u03c9L/2) . (22.32) The propagation factor \u03b1 is now a real number, and a number less than one. That means that the voltage at any section is always less than the voltage at the preceding section by the factor \u03b1 . For any frequency above \u03c9 0 , the voltage dies away rapidly as we go along the network. A plot of the absolute value of \u03b1 as a function of frequency looks like the graph in Fig. 22\u201322. We see that the behavior of \u03b1 , both above and below \u03c9 0 , agrees with our interpretation that the network propagates energy for \u03c9< \u03c9 0 and blocks it for \u03c9> \u03c9 0 . We say that the network \u201cpasses\u201d low frequencies and \u201crejects\u201d or \u201cfilters out\u201d the high frequencies. Any network designed to have its characteristics vary in a prescribed way with frequency is called a \u201cfilter.\u201d We have been analyzing a \u201clow-pass filter.\u201d You may be wondering why all this discussion of an infinite network which obviously cannot actually occur. The point is that the same characteristics are found in a finite network if we finish it off at the end with an impedance equal to the characteristic impedance z 0 . Now in practice it is not possible to exactly reproduce the characteristic impedance with a few simple elements\u2014like R \u2019s, L \u2019s, and C \u2019s. But it is often possible to do so with a fair approximation for a certain range of frequencies. In this way one can make a finite filter network whose properties are very nearly the same as those for the infinite case. For instance, the L - C ladder behaves much as we have described it if it is terminated in the pure resistance R= L/C \u2212 \u2212 \u2212 \u2212 \u221a . If in our L - C ladder we interchange the positions of the L \u2019s and C \u2019s, to make the ladder shown in Fig. 22\u201323(a), we can have a filter that propagates high frequencies and rejects low frequencies. It is easy to see what happens with this network by using the results we already have. You will notice that whenever we change an L to a C and vice versa, we also change every i\u03c9 to 1/i\u03c9 . So whatever happened at \u03c9 before will now happen at 1/\u03c9 . In particular, we can see how \u03b1 will vary with frequency by using Fig. 22\u201322 and changing the label on the axis to 1/\u03c9 , as we have done in Fig. 22\u201323(b). The low-pass and high-pass filters we have described have various technical applications. An L - C low-pass filter is often used as a \u201csmoothing\u201d filter in a dc power supply. If we want to manufacture dc power from an ac source, we begin with a rectifier which permits current to flow only in one direction. From the rectifier we get a series of pulses that look like the function V(t) shown in Fig. 22\u201324, which is lousy dc, because it wobbles up and down. Suppose we would like a nice pure dc, such as a battery provides. We can come close to that by putting a low-pass filter between the rectifier and the load. We know from Chapter 50 of Vol. I that the time function in Fig. 22\u201324 can be represented as a superposition of a constant voltage plus a sine wave, plus a higher-frequency sine wave, plus a still higher-frequency sine wave, etc.\u2014by a Fourier series. If our filter is linear (if, as we have been assuming, the L \u2019s and C \u2019s don\u2019t vary with the currents or voltages) then what comes out of the filter is the superposition of the outputs for each component at the input. If we arrange that the cutoff frequency \u03c9 0 of our filter is well below the lowest frequency in the function V(t) , the dc (for which \u03c9=0 ) goes through fine, but the amplitude of the first harmonic will be cut down a lot. And amplitudes of the higher harmonics will be cut down even more. So we can get the output as smooth as we wish, depending only on how many filter sections we are willing to buy. A high-pass filter is used if one wants to reject certain low frequencies. For instance, in a phonograph amplifier a high-pass filter may be used to let the music through, while keeping out the low-pitched rumbling from the motor of the turntable. It is also possible to make \u201cband-pass\u201d filters that reject frequencies below some frequency \u03c9 1 and above another frequency \u03c9 2 (greater than \u03c9 1 ), but pass the frequencies between \u03c9 1 and \u03c9 2 . This can be done simply by putting together a high-pass and a low-pass filter, but it is more usually done by making a ladder in which the impedances z 1 and z 2 are more complicated\u2014being each a combination of L \u2019s and C \u2019s. Such a band-pass filter might have a propagation constant like that shown in Fig. 22\u201325(a). It might be used, for example, in separating signals that occupy only an interval of frequencies, such as each of the many voice channels in a high-frequency telephone cable, or the modulated carrier of a radio transmission. We have seen in Chapter 25 of Vol. I that such filtering can also be done using the selectivity of an ordinary resonance curve, which we have drawn for comparison in Fig. 22\u201325(b). But the resonant filter is not as good for some purposes as the band-pass filter. You will remember (Chapter 48, Vol. I) that when a carrier of frequency \u03c9 c is modulated with a \u201csignal\u201d frequency \u03c9 s , the total signal contains not only the carrier frequency but also the two side-band frequencies \u03c9 c + \u03c9 s and \u03c9 c \u2212 \u03c9 s . With a resonant filter, these side-bands are always attenuated somewhat, and the attenuation is more, the higher the signal frequency, as you can see from the figure. So there is a poor \u201cfrequency response.\u201d The higher musical tones don\u2019t get through. But if the filtering is done with a band-pass filter designed so that the width \u03c9 2 \u2212 \u03c9 1 is at least twice the highest signal frequency, the frequency response will be \u201cflat\u201d for the signals wanted. We want to make one more point about the ladder filter: the L - C ladder of Fig. 22\u201320 is also an approximate representation of a transmission line. If we have a long conductor that runs parallel to another conductor\u2014such as a wire in a coaxial cable, or a wire suspended above the earth\u2014there will be some capacitance between the two conductors and also some inductance due to the magnetic field between them. If we imagine the line as broken up into small lengths \u0394\u2113 , each length will look like one section of the L - C ladder with a series inductance \u0394L and a shunt capacitance \u0394C . We can then use our results for the ladder filter. If we take the limit as \u0394\u2113 goes to zero, we have a good description of the transmission line. Notice that as \u0394\u2113 is made smaller and smaller, both \u0394L and \u0394C decrease, but in the same proportion, so that the ratio \u0394L/\u0394C remains constant. So if we take the limit of Eq. (22.28) as \u0394L and \u0394C go to zero, we find that the characteristic impedance z 0 is a pure resistance whose magnitude is \u0394L/\u0394C \u2212 \u2212 \u2212 \u2212 \u2212 \u2212 \u2212 \u221a . We can also write the ratio \u0394L/\u0394C as L 0 / C 0 , where L 0 and C 0 are the inductance and capacitance of a unit length of the line; then we have z 0 = L 0 C 0 \u2212 \u2212 \u2212 \u221a . (22.33) You will also notice that as \u0394L and \u0394C go to zero, the cutoff frequency \u03c9 0 = 4/LC \u2212 \u2212 \u2212 \u2212 \u2212 \u221a goes to infinity. There is no cutoff frequency for an ideal transmission line. We have so far defined only the ideal circuit impedances\u2014the inductance, the capacitance, and the resistance\u2014as well as the ideal voltage generator. We want now to show that other elements, such as mutual inductances or transistors or vacuum tubes, can be described by using only the same basic elements. Suppose that we have two coils and that on purpose, or otherwise, some flux from one of the coils links the other, as shown in Fig. 22\u201326(a). Then the two coils will have a mutual inductance M such that when the current varies in one of the coils, there will be a voltage generated in the other. Can we take into account such an effect in our equivalent circuits? We can in the following way. We have seen that the induced emf\u2019s in each of two interacting coils can be written as the sum of two parts: E 1 E 2 =\u2212 L 1 d I 1 dt \u00b1M d I 2 dt , =\u2212 L 2 d I 2 dt \u00b1M d I 1 dt . (22.34) The first term comes from the self-inductance of the coil, and the second term comes from its mutual inductance with the other coil. The sign of the second term can be plus or minus, depending on the way the flux from one coil links the other. Making the same approximations we used in describing an ideal inductance, we would say that the potential difference across the terminals of each coil is equal to the electromotive force in the coil. Then the two equations of (22.34) are the same as the ones we would get from the circuit of Fig. 22\u201326(b), provided the electromotive force in each of the two circuits shown depends on the current in the opposite circuit according to the relations E 1 =\u00b1i\u03c9M I 2 , E 2 =\u00b1i\u03c9M I 1 . (22.35) So what we can do is represent the effect of the self-inductance in a normal way but replace the effect of the mutual inductance by an auxiliary ideal voltage generator. We must in addition, of course, have the equation that relates this emf to the current in some other part of the circuit; but so long as this equation is linear, we have just added more linear equations to our circuit equations, and all of our earlier conclusions about equivalent circuits and so forth are still correct. In addition to mutual inductances there may also be mutual capacitances. So far, when we have talked about condensers we have always imagined that there were only two electrodes, but in many situations, for example in a vacuum tube, there may be many electrodes close to each other. If we put an electric charge on any one of the electrodes, its electric field will induce charges on each of the other electrodes and affect its potential. As an example, consider the arrangement of four plates shown in Fig. 22\u201327(a). Suppose these four plates are connected to external circuits by means of the wires A , B , C , and D . So long as we are only worried about electrostatic effects, the equivalent circuit of such an arrangement of electrodes is as shown in part (b) of the figure. The electrostatic interaction of any electrode with each of the others is equivalent to a capacity between the two electrodes. Finally, let\u2019s consider how we should represent such complicated devices as transistors and radio tubes in an ac circuit. We should point out at the start that such devices are often operated in such a way that the relationship between the currents and voltages is not at all linear. In such cases, those statements we have made which depend on the linearity of equations are, of course, no longer correct. On the other hand, in many applications the operating characteristics are sufficiently linear that we may consider the transistors and tubes to be linear devices. By this we mean that the alternating currents in, say, the plate of a vacuum tube are linearly proportional to the voltages that appear on the other electrodes, say the grid voltage and the plate voltage. When we have such linear relationships, we can incorporate the device into our equivalent circuit representation. As in the case of the mutual inductance, our representation will have to include auxiliary voltage generators which describe the influence of the voltages or currents in one part of the device on the currents or voltages in another part. For example, the plate circuit of a triode can usually be represented by a resistance in series with an ideal voltage generator whose source strength is proportional to the grid voltage. We get the equivalent circuit shown in Fig. 22\u201328.2 Similarly, the collector circuit of a transistor is conveniently represented as a resistor in series with an ideal voltage generator whose source strength is proportional to the current from the emitter to the base of the transistor. The equivalent circuit is then like that in Fig. 22\u201329. So long as the equations which describe the operation are linear, we can use such representations for tubes or transistors. Then, when they are incorporated in a complicated network, our general conclusions about the equivalent representation of any arbitrary connection of elements is still valid. There is one remarkable thing about transistor and radio tube circuits which is different from circuits containing only impedances: the real part of the effective impedance z eff can become negative. We have seen that the real part of z represents the loss of energy. But it is the important characteristic of transistors and tubes that they supply energy to the circuit. (Of course they don\u2019t just \u201cmake\u201d energy; they take energy from the dc circuits of the power supplies and convert it into ac energy.) So it is possible to have a circuit with a negative resistance. Such a circuit has the property that if you connect it to an impedance with a positive real part, i.e., a positive resistance, and arrange matters so that the sum of the two real parts is exactly zero, then there is no dissipation in the combined circuit. If there is no loss of energy, any alternating voltage once started will remain forever. This is the basic idea behind the operation of an oscillator or signal generator which can be used as a source of alternating voltage at any desired frequency."
    },
    {
        "input": "Center of Mass; Moment of Inertia",
        "output": "In the previous chapter we found that if a great many forces are acting on a complicated mass of particles, whether the particles comprise a rigid or a nonrigid body, or a cloud of stars, or anything else, and we find the sum of all the forces (that is, of course, the external forces, because the internal forces balance out), then if we consider the body as a whole, and say it has a total mass M , there is a certain point \u201cinside\u201d the body, called the center of mass, such that the net resulting external force produces an acceleration of this point, just as though the whole mass were concentrated there. Let us now discuss the center of mass in a little more detail. The location of the center of mass (abbreviated CM) is given by the equation RCM= \u2211miri \u2211mi . This is, of course, a vector equation which is really three equations, one for each of the three directions. We shall consider only the x -direction, because if we can understand that one, we can understand the other two. What does XCM=\u2211mixi/\u2211mi mean? Suppose for a moment that the object is divided into little pieces, all of which have the same mass m ; then the total mass is simply the number N of pieces times the mass of one piece, say one gram, or any unit. Then this equation simply says that we add all the x \u2019s, and then divide by the number of things that we have added: XCM= m\u2211xi/mN= \u2211xi/N . In other words, XCM is the average of all the x \u2019s, if the masses are equal. But suppose one of them were twice as heavy as the others. Then in the sum, that x would come in twice. This is easy to understand, for we can think of this double mass as being split into two equal ones, just like the others; then in taking the average, of course, we have to count that x twice because there are two masses there. Thus X is the average position, in the x -direction, of all the masses, every mass being counted a number of times proportional to the mass, as though it were divided into \u201clittle grams.\u201d From this it is easy to prove that X must be somewhere between the largest and the smallest x , and, therefore lies inside the envelope including the entire body. It does not have to be in the material of the body, for the body could be a circle, like a hoop, and the center of mass is in the center of the hoop, not in the hoop itself. Of course, if an object is symmetrical in some way, for instance, a rectangle, so that it has a plane of symmetry, the center of mass lies somewhere on the plane of symmetry. In the case of a rectangle there are two planes, and that locates it uniquely. But if it is just any symmetrical object, then the center of gravity lies somewhere on the axis of symmetry, because in those circumstances there are as many positive as negative x \u2019s. Another interesting proposition is the following very curious one. Suppose that we imagine an object to be made of two pieces, A and B (Fig. 19\u20131). Then the center of mass of the whole object can be calculated as follows. First, find the center of mass of piece A , and then of piece B . Also, find the total mass of each piece, MA and MB . Then consider a new problem, in which a point mass MA is at the center of mass of object A , and another point mass MB is at the center of mass of object B . The center of mass of these two point masses is then the center of mass of the whole object. In other words, if the centers of mass of various parts of an object have been worked out, we do not have to start all over again to find the center of mass of the whole object; we just have to put the pieces together, treating each one as a point mass situated at the center of mass of that piece. Let us see why that is. Suppose that we wanted to calculate the center of mass of a complete object, some of whose particles are considered to be members of object A and some members of object B . The total sum \u2211mixi can then be split into two pieces\u2014the sum \u2211Amixi for the A object only, and the sum \u2211Bmixi for object B only. Now if we were computing the center of mass of object A alone, we would have exactly the first of these sums, and we know that this by itself is MAXA , the total mass of all the particles in A times the position of the center of mass of A , because that is the theorem of the center of mass, applied to object A . In the same manner, just by looking at object B , we get MBXB , and of course, adding the two yields MXCM : MXCM = \u2211 A mixi+ \u2211 B mixi =MAXA+MBXB. Now since M is evidently the sum of MA and MB , we see that Eq. (19.2) can be interpreted as a special example of the center of mass formula for two point objects, one of mass MA located at XA and the other of mass MB located at XB . The theorem concerning the motion of the center of mass is very interesting, and has played an important part in the development of our understanding of physics. Suppose we assume that Newton\u2019s law is right for the small component parts of a much larger object. Then this theorem shows that Newton\u2019s law is also correct for the larger object, even if we do not study the details of the object, but only the total force acting on it and its mass. In other words, Newton\u2019s law has the peculiar property that if it is right on a certain small scale, then it will be right on a larger scale. If we do not consider a baseball as a tremendously complex thing, made of myriads of interacting particles, but study only the motion of the center of mass and the external forces on the ball, we find F=ma , where F is the external force on the baseball, m is its mass, and a is the acceleration of its center of mass. So F=ma is a law which reproduces itself on a larger scale. (There ought to be a good word, out of the Greek, perhaps, to describe a law which reproduces the same law on a larger scale.) Of course, one might suspect that the first laws that would be discovered by human beings would be those that would reproduce themselves on a larger scale. Why? Because the actual scale of the fundamental gears and wheels of the universe are of atomic dimensions, which are so much finer than our observations that we are nowhere near that scale in our ordinary observations. So the first things that we would discover must be true for objects of no special size relative to an atomic scale. If the laws for small particles did not reproduce themselves on a larger scale, we would not discover those laws very easily. What about the reverse problem? Must the laws on a small scale be the same as those on a larger scale? Of course it is not necessarily so in nature, that at an atomic level the laws have to be the same as on a large scale. Suppose that the true laws of motion of atoms were given by some strange equation which does not have the property that when we go to a larger scale we reproduce the same law, but instead has the property that if we go to a larger scale, we can approximate it by a certain expression such that, if we extend that expression up and up, it keeps reproducing itself on a larger and larger scale. That is possible, and in fact that is the way it works. Newton\u2019s laws are the \u201ctail end\u201d of the atomic laws, extrapolated to a very large size. The actual laws of motion of particles on a fine scale are very peculiar, but if we take large numbers of them and compound them, they approximate, but only approximate, Newton\u2019s laws. Newton\u2019s laws then permit us to go on to a higher and higher scale, and it still seems to be the same law. In fact, it becomes more and more accurate as the scale gets larger and larger. This self-reproducing factor of Newton\u2019s laws is thus really not a fundamental feature of nature, but is an important historical feature. We would never discover the fundamental laws of the atomic particles at first observation because the first observations are much too crude. In fact, it turns out that the fundamental atomic laws, which we call quantum mechanics, are quite different from Newton\u2019s laws, and are difficult to understand because all our direct experiences are with large-scale objects and the small-scale atoms behave like nothing we see on a large scale. So we cannot say, \u201cAn atom is just like a planet going around the sun,\u201d or anything like that. It is like nothing we are familiar with because there is nothing like it. As we apply quantum mechanics to larger and larger things, the laws about the behavior of many atoms together do not reproduce themselves, but produce new laws, which are Newton\u2019s laws, which then continue to reproduce themselves from, say, micro-microgram size, which still is billions and billions of atoms, on up to the size of the earth, and above. Let us now return to the center of mass. The center of mass is sometimes called the center of gravity, for the reason that, in many cases, gravity may be considered uniform. Let us suppose that we have small enough dimensions that the gravitational force is not only proportional to the mass, but is everywhere parallel to some fixed line. Then consider an object in which there are gravitational forces on each of its constituent masses. Let m i be the mass of one part. Then the gravitational force on that part is m i times g . Now the question is, where can we apply a single force to balance the gravitational force on the whole thing, so that the entire object, if it is a rigid body, will not turn? The answer is that this force must go through the center of mass, and we show this in the following way. In order that the body will not turn, the torque produced by all the forces must add up to zero, because if there is a torque, there is a change of angular momentum, and thus a rotation. So we must calculate the total of all the torques on all the particles, and see how much torque there is about any given axis; it should be zero if this axis is at the center of mass. Now, measuring x horizontally and y vertically, we know that the torques are the forces in the y -direction, times the lever arm x (that is to say, the force times the lever arm around which we want to measure the torque). Now the total torque is the sum \u03c4=\u2211 m i g x i =g\u2211 m i x i , (19.3) so if the total torque is to be zero, the sum \u2211 m i x i must be zero. But \u2211 m i x i =M X CM , the total mass times the distance of the center of mass from the axis. Thus the x -distance of the center of mass from the axis is zero. Of course, we have checked the result only for the x -distance, but if we use the true center of mass the object will balance in any position, because if we turned it 90 degrees, we would have y \u2019s instead of x \u2019s. In other words, when an object is supported at its center of mass, there is no torque on it because of a parallel gravitational field. In case the object is so large that the nonparallelism of the gravitational forces is significant, then the center where one must apply the balancing force is not simple to describe, and it departs slightly from the center of mass. That is why one must distinguish between the center of mass and the center of gravity. The fact that an object supported exactly at the center of mass will balance in all positions has another interesting consequence. If, instead of gravitation, we have a pseudo force due to acceleration, we may use exactly the same mathematical procedure to find the position to support it so that there are no torques produced by the inertial force of acceleration. Suppose that the object is held in some manner inside a box, and that the box, and everything contained in it, is accelerating. We know that, from the point of view of someone at rest relative to this accelerating box, there will be an effective force due to inertia. That is, to make the object go along with the box, we have to push on it to accelerate it, and this force is \u201cbalanced\u201d by the \u201cforce of inertia,\u201d which is a pseudo force equal to the mass times the acceleration of the box. To the man in the box, this is the same situation as if the object were in a uniform gravitational field whose \u201c g \u201d value is equal to the acceleration a . Thus the inertial force due to accelerating an object has no torque about the center of mass. This fact has a very interesting consequence. In an inertial frame that is not accelerating, the torque is always equal to the rate of change of the angular momentum. However, about an axis through the center of mass of an object which is accelerating, it is still true that the torque is equal to the rate of change of the angular momentum. Even if the center of mass is accelerating, we may still choose one special axis, namely, one passing through the center of mass, such that it will still be true that the torque is equal to the rate of change of angular momentum around that axis. Thus the theorem that torque equals the rate of change of angular momentum is true in two general cases: (1) a fixed axis in inertial space, (2) an axis through the center of mass, even though the object may be accelerating. The mathematical techniques for the calculation of centers of mass are in the province of a mathematics course, and such problems provide good exercise in integral calculus. After one has learned calculus, however, and wants to know how to locate centers of mass, it is nice to know certain tricks which can be used to do so. One such trick makes use of what is called the theorem of Pappus. It works like this: if we take any closed area in a plane and generate a solid by moving it through space such that each point is always moved perpendicular to the plane of the area, the resulting solid has a total volume equal to the area of the cross section times the distance that the center of mass moved! Certainly this is true if we move the area in a straight line perpendicular to itself, but if we move it in a circle or in some other curve, then it generates a rather peculiar volume. For a curved path, the outside goes around farther, and the inside goes around less, and these effects balance out. So if we want to locate the center of mass of a plane sheet of uniform density, we can remember that the volume generated by spinning it about an axis is the distance that the center of mass goes around, times the area of the sheet. For example, if we wish to find the center of mass of a right triangle of base D and height H (Fig. 19\u20132), we might solve the problem in the following way. Imagine an axis along H , and rotate the triangle about that axis through a full 360 degrees. This generates a cone. The distance that the x -coordinate of the center of mass has moved is 2\u03c0x . The area which is being moved is the area of the triangle, 1 2 HD . So the x -distance of the center of mass times the area of the triangle is the volume swept out, which is of course \u03c0 D 2 H/3 . Thus (2\u03c0x)( 1 2 HD)=\u03c0 D 2 H/3 , or x=D/3 . In a similar manner, by rotating about the other axis, or by symmetry, we find y=H/3 . In fact, the center of mass of any uniform triangular area is where the three medians, the lines from the vertices through the centers of the opposite sides, all meet. That point is 1/3 of the way along each median. Clue: Slice the triangle up into a lot of little pieces, each parallel to a base. Note that the median line bisects every piece, and therefore the center of mass must lie on this line. Now let us try a more complicated figure. Suppose that it is desired to find the position of the center of mass of a uniform semicircular disc\u2014a disc sliced in half. Where is the center of mass? For a full disc, it is at the center, of course, but a half-disc is more difficult. Let r be the radius and x be the distance of the center of mass from the straight edge of the disc. Spin it around this edge as axis to generate a sphere. Then the center of mass has gone around 2\u03c0x , the area is \u03c0 r 2 /2 (because it is only half a circle). The volume generated is, of course, 4\u03c0 r 3 /3 , from which we find that (2\u03c0x)( 1 2 \u03c0 r 2 )=4\u03c0 r 3 /3, 1 or x=4r/3\u03c0. / There is another theorem of Pappus which is a special case of the above one, and therefore equally true. Suppose that, instead of the solid semicircular disc, we have a semicircular piece of wire with uniform mass density along the wire, and we want to find its center of mass. In this case there is no mass in the interior, only on the wire. Then it turns out that the area which is swept by a plane curved line, when it moves as before, is the distance that the center of mass moves times the length of the line. (The line can be thought of as a very narrow area, and the previous theorem can be applied to it.) Now let us discuss the problem of finding the moments of inertia of various objects. The formula for the moment of inertia about the z -axis of an object is I=\u2211 m i ( x 2 i + y 2 i ) \u2211 or I=\u222b( x 2 + y 2 )dm=\u222b( x 2 + y 2 )\u03c1dV. (19.4) That is, we must sum the masses, each one multiplied by the square of its distance ( x 2 i + y 2 i ) from the axis. Note that it is not the three-dimensional distance, only the two-dimensional distance squared, even for a three-dimensional object. For the most part, we shall restrict ourselves to two-dimensional objects, but the formula for rotation about the z -axis is just the same in three dimensions. As a simple example, consider a rod rotating about a perpendicular axis through one end (Fig. 19\u20133). Now we must sum all the masses times the x -distances squared (the y \u2019s being all zero in this case). What we mean by \u201cthe sum,\u201d of course, is the integral of x 2 times the little elements of mass. If we divide the rod into small elements of length dx , the corresponding elements of mass are proportional to dx , and if dx were the length of the whole rod the mass would be M . Therefore dm=Mdx/L d M d / L and so I= \u222b L 0 x 2 Mdx L = M L \u222b L 0 x 2 dx= M L 2 3 . (19.5) The dimensions of moment of inertia are always mass times length squared, so all we really had to work out was the factor 1/3 . Now what is I if the rotation axis is at the center of the rod? We could just do the integral over again, letting x range from \u2212 1 2 L to + 1 2 L . But let us notice a few things about the moment of inertia. We can imagine the rod as two rods, each of mass M/2 and length L/2 ; the moments of inertia of the two small rods are equal, and are both given by the formula (19.5). Therefore the moment of inertia is I= 2(M/2)(L/2 ) 2 3 = M L 2 12 . (19.6) Thus it is much easier to turn a rod about its center, than to swing it around an end. Of course, we could go on to compute the moments of inertia of various other bodies of interest. However, while such computations provide a certain amount of important exercise in the calculus, they are not basically of interest to us as such. There is, however, an interesting theorem which is very useful. Suppose we have an object, and we want to find its moment of inertia around some axis. That means we want the inertia needed to carry it by rotation about that axis. Now if we support the object on pivots at the center of mass, so that the object does not turn as it rotates about the axis (because there is no torque on it from inertial effects, and therefore it will not turn when we start moving it), then the forces needed to swing it around are the same as though all the mass were concentrated at the center of mass, and the moment of inertia would be simply I 1 =M R 2 CM , where R CM is the distance from the axis to the center of mass. But of course that is not the right formula for the moment of inertia of an object which is really being rotated as it revolves, because not only is the center of it moving in a circle, which would contribute an amount I 1 to the moment of inertia, but also we must turn it about its center of mass. So it is not unreasonable that we must add to I 1 the moment of inertia I c about the center of mass. So it is a good guess that the total moment of inertia about any axis will be I= I c +M R 2 CM . (19.7) This theorem is called the parallel-axis theorem, and may be easily proved. The moment of inertia about any axis is the mass times the sum of the x i \u2019s and the y i \u2019s, each squared: I=\u2211( x 2 i + y 2 i ) m i . We shall concentrate on the x \u2019s, but of course the y \u2019s work the same way. Now x is the distance of a particular point mass from the origin, but let us consider how it would look if we measured x \u2032 from the CM, instead of x from the origin. To get ready for this analysis, we write x i = x \u2032 i + X CM . \u2032 Then we just square this to find x 2 i = x \u20322 i +2 X CM x \u2032 i + X 2 CM . 2 \u2032 2 \u2032 2 So, when this is multiplied by m i and summed over all i , what happens? Taking the constants outside the summation sign, we get I x =\u2211 m i x \u20322 i +2 X CM \u2211 m i x \u2032 i + X 2 CM \u2211 m i . \u2211 \u2032 \u2211 2 \u2211 The third sum is easy; it is just M X 2 CM . In the second sum there are two pieces, one of them is \u2211 m i x \u2032 i , which is the total mass times the x \u2032 -coordinate of the center of mass. But this contributes nothing, because x \u2032 is measured from the center of mass, and in these axes the average position of all the particles, weighted by the masses, is zero. The first sum, of course, is the x part of I c . Thus we arrive at Eq. (19.7), just as we guessed. Let us check (19.7) for one example. Let us just see whether it works for the rod. For an axis through one end, the moment of inertia should be M L 2 /3 , for we calculated that. The center of mass of a rod, of course, is in the center of the rod, at a distance L/2 . Therefore we should find that M L 2 /3=M L 2 /12+M(L/2 ) 2 . Since one-quarter plus one-twelfth is one-third, we have made no fundamental error. Incidentally, we did not really need to use an integral to find the moment of inertia (19.5). If we simply assume that it is M L 2 times \u03b3 , an unknown coefficient, and then use the argument about the two halves to get 1 4 \u03b3 for (19.6), then from our argument about transferring the axes we could prove that \u03b3= 1 4 \u03b3+ 1 4 , so \u03b3 must be 1/3 . There is always another way to do it! In applying the parallel-axis theorem, it is of course important to remember that the axis for I c must be parallel to the axis about which the moment of inertia is wanted. One further property of the moment of inertia is worth mentioning because it is often helpful in finding the moment of inertia of certain kinds of objects. This property is that if one has a plane figure and a set of coordinate axes with origin in the plane and z -axis perpendicular to the plane, then the moment of inertia of this figure about the z -axis is equal to the sum of the moments of inertia about the x - and y -axes. This is easily proved by noting that I x =\u2211 m i ( y 2 i + z 2 i )=\u2211 m i y 2 i \u2211 \u2211 (since z i =0 ). Similarly, I y =\u2211 m i ( x 2 i + z 2 i )=\u2211 m i x 2 i , \u2211 \u2211 but I z =\u2211 m i ( x 2 i + y 2 i ) =\u2211 m i x 2 i +\u2211 m i y 2 i = I x + I y . As an example, the moment of inertia of a uniform rectangular plate of mass M , width w , and length L , about an axis perpendicular to the plate and through its center is simply I=M( w 2 + L 2 )/12, 2 because its moment of inertia about an axis in its plane and parallel to its length is M w 2 /12 , i.e., just as for a rod of length w , and the moment of inertia about the other axis in its plane is M L 2 /12 , just as for a rod of length L . To summarize, the moment of inertia of an object about a given axis, which we shall call the z -axis, has the following properties: The moment of inertia is I z = \u2211 i m i ( x 2 i + y 2 i )=\u222b( x 2 + y 2 )dm. \u222b If the object is made of a number of parts, each of whose moment of inertia is known, the total moment of inertia is the sum of the moments of inertia of the pieces. The moment of inertia about any given axis is equal to the moment of inertia about a parallel axis through the CM plus the total mass times the square of the distance from the axis to the CM. If the object is a plane figure, the moment of inertia about an axis perpendicular to the plane is equal to the sum of the moments of inertia about any two mutually perpendicular axes lying in the plane and intersecting at the perpendicular axis. The moments of inertia of a number of elementary shapes having uniform mass densities are given in Table 19\u20131, and the moments of inertia of some other objects, which may be deduced from Table 19\u20131, using the above properties, are given in Table 19\u20132. Now let us go on to discuss dynamics further. In the analogy between linear motion and angular motion that we discussed in Chapter 18, we used the work theorem, but we did not talk about kinetic energy. What is the kinetic energy of a rigid body, rotating about a certain axis with an angular velocity \u03c9 ? We can immediately guess the correct answer by using our analogies. The moment of inertia corresponds to the mass, angular velocity corresponds to velocity, and so the kinetic energy ought to be 1 2 I \u03c9 2 , and indeed it is, as will now be demonstrated. Suppose the object is rotating about some axis so that each point has a velocity whose magnitude is \u03c9 r i , where r i is the radius from the particular point to the axis. Then if m i is the mass of that point, the total kinetic energy of the whole thing is just the sum of the kinetic energies of all of the little pieces: T= 1 2 \u2211 m i v 2 i = 1 2 \u2211 m i ( r i \u03c9 ) 2 . 1 1 Now \u03c9 2 is a constant, the same for all points. Thus T= 1 2 \u03c9 2 \u2211 m i r 2 i = 1 2 I \u03c9 2 . (19.8) At the end of Chapter 18 we pointed out that there are some interesting phenomena associated with an object which is not rigid, but which changes from one rigid condition with a definite moment of inertia, to another rigid condition. Namely, in our example of the turntable, we had a certain moment of inertia I 1 with our arms stretched out, and a certain angular velocity \u03c9 1 . When we pulled our arms in, we had a different moment of inertia, I 2 , and a different angular velocity, \u03c9 2 , but again we were \u201crigid.\u201d The angular momentum remained constant, since there was no torque about the vertical axis of the turntable. This means that I 1 \u03c9 1 = I 2 \u03c9 2 . Now what about the energy? That is an interesting question. With our arms pulled in, we turn faster, but our moment of inertia is less, and it looks as though the energies might be equal. But they are not, because what does balance is I\u03c9 , not I \u03c9 2 . So if we compare the kinetic energy before and after, the kinetic energy before is 1 2 I 1 \u03c9 2 1 = 1 2 L \u03c9 1 , where L= I 1 \u03c9 1 = I 2 \u03c9 2 is the angular momentum. Afterward, by the same argument, we have T= 1 2 L \u03c9 2 and since \u03c9 2 > \u03c9 1 the kinetic energy of rotation is greater than it was before. So we had a certain energy when our arms were out, and when we pulled them in, we were turning faster and had more kinetic energy. What happened to the theorem of the conservation of energy? Somebody must have done some work. We did work! When did we do any work? When we move a weight horizontally, we do not do any work. If we hold a thing out and pull it in, we do not do any work. But that is when we are not rotating! When we are rotating, there is centrifugal force on the weights. They are trying to fly out, so when we are going around we have to pull the weights in against the centrifugal force. So, the work we do against the centrifugal force ought to agree with the difference in rotational energy, and of course it does. That is where the extra kinetic energy comes from. There is still another interesting feature which we can treat only descriptively, as a matter of general interest. This feature is a little more advanced, but is worth pointing out because it is quite curious and produces many interesting effects. Consider that turntable experiment again. Consider the body and the arms separately, from the point of view of the man who is rotating. After the weights are pulled in, the whole object is spinning faster, but observe, the central part of the body is not changed, yet it is turning faster after the event than before. So, if we were to draw a circle around the inner body, and consider only objects inside the circle, their angular momentum would change; they are going faster. Therefore there must be a torque exerted on the body while we pull in our arms. No torque can be exerted by the centrifugal force, because that is radial. So that means that among the forces that are developed in a rotating system, centrifugal force is not the entire story, there is another force. This other force is called Coriolis force, and it has the very strange property that when we move something in a rotating system, it seems to be pushed sidewise. Like the centrifugal force, it is an apparent force. But if we live in a system that is rotating, and move something radially, we find that we must also push it sidewise to move it radially. This sidewise push which we have to exert is what turned our body around. Now let us develop a formula to show how this Coriolis force really works. Suppose Moe is sitting on a carousel that appears to him to be stationary. But from the point of view of Joe, who is standing on the ground and who knows the right laws of mechanics, the carousel is going around. Suppose that we have drawn a radial line on the carousel, and that Moe is moving some mass radially along this line. We would like to demonstrate that a sidewise force is required to do that. We can do this by paying attention to the angular momentum of the mass. It is always going around with the same angular velocity \u03c9 , so that the angular momentum is L=m v tang r=m\u03c9r\u22c5r=m\u03c9 r 2 . 2 So when the mass is close to the center, it has relatively little angular momentum, but if we move it to a new position farther out, if we increase r , m has more angular momentum, so a torque must be exerted in order to move it along the radius. (To walk along the radius in a carousel, one has to lean over and push sidewise. Try it sometime.) The torque that is required is the rate of change of L with time as m moves along the radius. If m moves only along the radius, omega stays constant, so that the torque is \u03c4= F c r= dL dt = d(m\u03c9 r 2 ) dt =2m\u03c9r dr dt , 2 where F c is the Coriolis force. What we really want to know is what sidewise force has to be exerted by Moe in order to move m out at speed v r =dr/dt . This is F c = \u03c4/r= 2m\u03c9 v r . Now that we have a formula for the Coriolis force, let us look at the situation a little more carefully, to see whether we can understand the origin of this force from a more elementary point of view. We note that the Coriolis force is the same at every radius, and is evidently present even at the origin! But it is especially easy to understand it at the origin, just by looking at what happens from the inertial system of Joe, who is standing on the ground. Figure 19\u20134 shows three successive views of m just as it passes the origin at t=0 . Because of the rotation of the carousel, we see that m does not move in a straight line, but in a curved path tangent to a diameter of the carousel where r=0 . In order for m to go in a curve, there must be a force to accelerate it in absolute space. This is the Coriolis force. This is not the only case in which the Coriolis force occurs. We can also show that if an object is moving with constant speed around the circumference of a circle, there is also a Coriolis force. Why? Moe sees a velocity v M around the circle. On the other hand, Joe sees m going around the circle with the velocity v J = v M +\u03c9r , because m is also carried by the carousel. Therefore we know what the force really is, namely, the total centripetal force due to the velocity v J , or m v 2 J /r ; that is the actual force. Now from Moe\u2019s point of view, this centripetal force has three pieces. We may write it all out as follows: F r =\u2212 m v 2 J r =\u2212 m v 2 M r \u22122m v M \u03c9\u2212m \u03c9 2 r. 2 2 Now, F r is the force that Moe would see. Let us try to understand it. Would Moe appreciate the first term? \u201cYes,\u201d he would say, \u201ceven if I were not turning, there would be a centripetal force if I were to run around a circle with velocity v M .\u201d This is simply the centripetal force that Moe would expect, having nothing to do with rotation. In addition, Moe is quite aware that there is another centripetal force that would act even on objects which are standing still on his carousel. This is the third term. But there is another term in addition to these, namely the second term, which is again 2m\u03c9v . The Coriolis force F c was tangential when the velocity was radial, and now it is radial when the velocity is tangential. In fact, one expression has a minus sign relative to the other. The force is always in the same direction, relative to the velocity, no matter in which direction the velocity is. The force is at right angles to the velocity, and of magnitude 2m\u03c9v ."
    },
    {
        "input": "The Hydrogen Atom and the Periodic Table",
        "output": "The most dramatic success in the history of the quantum mechanics was the understanding of the details of the spectra of some simple atoms and the understanding of the periodicities which are found in the table of chemical elements. In this chapter we will at last bring our quantum mechanics to the point of this important achievement, specifically to an understanding of the spectrum of the hydrogen atom. We will at the same time arrive at a qualitative explanation of the mysterious properties of the chemical elements. We will do this by studying in detail the behavior of the electron in a hydrogen atom\u2014for the first time making a detailed calculation of a distribution-in-space according to the ideas we developed in Chapter 16. For a complete description of the hydrogen atom we should describe the motions of both the proton and the electron. It is possible to do this in quantum mechanics in a way that is analogous to the classical idea of describing the motion of each particle relative to the center of gravity, but we will not do so. We will just discuss an approximation in which we consider the proton to be very heavy, so we can think of it as fixed at the center of the atom. We will make another approximation by forgetting that the electron has a spin and should be described by relativistic laws of mechanics. Some small corrections to our treatment will be required since we will be using the nonrelativistic Schr\u00f6dinger equation and will disregard magnetic effects. Small magnetic effects occur because from the electron\u2019s point-of-view the proton is a circulating charge which produces a magnetic field. In this field the electron will have a different energy with its spin up than with it down. The energy of the atom will be shifted a little bit from what we will calculate. We will ignore this small energy shift. Also we will imagine that the electron is just like a gyroscope moving around in space always keeping the same direction of spin. Since we will be considering a free atom in space the total angular momentum will be conserved. In our approximation we will assume that the angular momentum of the electron spin stays constant, so all the rest of the angular momentum of the atom\u2014what is usually called \u201corbital\u201d angular momentum\u2014will also be conserved. To an excellent approximation the electron moves in the hydrogen atom like a particle without spin\u2014the angular momentum of the motion is a constant. With these approximations the amplitude to find the electron at different places in space can be represented by a function of position in space and time. We let \u03c8(x,y,z,t) be the amplitude to find the electron somewhere at the time t . According to the quantum mechanics the rate of change of this amplitude with time is given by the Hamiltonian operator working on the same function. From Chapter 16, i\u210f \u2202\u03c8 \u2202t = \u02c6 H \u03c8, with \u02c6 H =\u2212 \u210f2 2m \u22072+V(r). Here, m is the electron mass, and V(r) is the potential energy of the electron in the electrostatic field of the proton. Taking V=0 at large distances from the proton we can write1 V=\u2212 e2 r . The wave function \u03c8 must then satisfy the equation i\u210f \u2202\u03c8 \u2202t =\u2212 \u210f2 2m \u22072\u03c8\u2212 e2 r \u03c8. We want to look for definite energy states, so we try to find solutions which have the form \u03c8(r,t)=e\u2212(i/\u210f)Et\u03c8(r). The function \u03c8(r) must then be a solution of \u2212 \u210f2 2m \u22072\u03c8=(E+ e2 r )\u03c8, where E is some constant\u2014the energy of the atom. Since the potential energy term depends only on the radius, it turns out to be much more convenient to solve this equation in polar coordinates rather than rectangular coordinates. The Laplacian is defined in rectangular coordinates by \u22072= \u22022 \u2202x2 + \u22022 \u2202y2 + \u22022 \u2202z2 . We want to use instead the coordinates r , \u03b8 , \u03d5 shown in Fig. 19\u20131. These coordinates are related to x , y , z by x=rsin\u03b8cos\u03d5;y=rsin\u03b8sin\u03d5;z=rcos\u03b8. It\u2019s a rather tedious mess to work through the algebra, but you can eventually show that for any function f(r)=f(r,\u03b8,\u03d5) , \u22072f(r,\u03b8,\u03d5)= 1 r \u22022 \u2202r2 (rf)+ 1 r2 { 1 sin\u03b8 \u2202 \u2202\u03b8 (sin\u03b8 \u2202f \u2202\u03b8 )+ 1 sin2\u03b8 \u22022f \u2202\u03d52 }. So in terms of the polar coordinates, the equation which is to be satisfied by \u03c8(r,\u03b8,\u03d5) is 1 r \u22022 \u2202r2 (r\u03c8)+ 1 r2 { 1 sin\u03b8 \u2202 \u2202\u03b8 (sin\u03b8 \u2202\u03c8 \u2202\u03b8 )+ 1 sin2\u03b8 \u22022\u03c8 \u2202\u03d52 } =\u2212 2m \u210f2 (E+ e2 r )\u03c8. Let\u2019s first try to find some very simple function that satisfies the horrible equation in (19.7). Although the wave function \u03c8 will, in general, depend on the angles \u03b8 and \u03d5 as well as on the radius r , we can see whether there might be a special situation in which \u03c8 does not depend on the angles. For a wave function that doesn\u2019t depend on the angles, none of the amplitudes will change in any way if you rotate the coordinate system. That means that all of the components of the angular momentum are zero. Such a \u03c8 must correspond to a state whose total angular momentum is zero. (Actually, it is only the orbital angular momentum which is zero because we still have the spin of the electron, but we are ignoring that part.) A state with zero orbital angular momentum is called by a special name. It is called an \u201cs -state\u201d\u2014you can remember \u201cs for spherically symmetric.\u201d2 Now if \u03c8 is not going to depend on \u03b8 and \u03d5 then the entire Laplacian contains only the first term and Eq. (19.7) becomes much simpler: 1 r d2 dr2 (r\u03c8)=\u2212 2m \u210f2 (E+ e2 r )\u03c8. Before you start to work on solving an equation like this, it\u2019s a good idea to get rid of all excess constants like e2 , m , and \u210f , by making some scale changes. Then the algebra will be easier. If we make the following substitutions: r= \u210f2 me2 \u03c1, and E= me4 2\u210f2 \u03f5, then Eq. (19.8) becomes (after multiplying through by \u03c1 ) d2(\u03c1\u03c8) d\u03c12 =\u2212(\u03f5+ 2 \u03c1 )\u03c1\u03c8. These scale changes mean that we are measuring the distance r and energy E as multiples of \u201cnatural\u201d atomic units. That is, \u03c1=r/rB , where rB=\u210f2/me2 , is called the \u201cBohr radius\u201d and is about 0.528 angstroms. Similarly, \u03f5=E/ER , with ER=me4/2\u210f2 . This energy is called the \u201cRydberg\u201d and is about 13.6 electron volts. Since the product \u03c1\u03c8 appears on both sides, it is convenient to work with it rather than with \u03c8 itself. Letting \u03c1\u03c8=f, we have the more simple-looking equation d2f d\u03c12 =\u2212(\u03f5+ 2 \u03c1 )f. Now we have to find some function f which satisfies Eq. (19.13)\u2014in other words, we just have to solve a differential equation. Unfortunately, there is no very useful, general method for solving any given differential equation. You just have to fiddle around. Our equation is not easy, but people have found that it can be solved by the following procedure. First, you replace f , which is some function of \u03c1 , by a product of two functions f(\u03c1)= e \u2212\u03b1\u03c1 g(\u03c1). (19.14) This just means that you are factoring e \u2212\u03b1\u03c1 out of f(\u03c1) . You can certainly do that for any f(\u03c1) at all. This just shifts our problem to finding the right function g(\u03c1) . Sticking (19.14) into (19.13), we get the following equation for g : d 2 g d \u03c1 2 \u22122\u03b1 dg d\u03c1 +( 2 \u03c1 +\u03f5+ \u03b1 2 )g=0. (19.15) Since we are free to choose \u03b1 , let\u2019s make \u03b1 2 =\u2212\u03f5, (19.16) and get d 2 g d \u03c1 2 \u22122\u03b1 dg d\u03c1 + 2 \u03c1 g=0. (19.17) You may think we are no better off than we were at Eq. (19.13), but the happy thing about our new equation is that it can be solved easily in terms of a power series in \u03c1 . (It is possible, in principle, to solve (19.13) that way too, but it is much harder.) We are saying that Eq. (19.17) can be satisfied by some g(\u03c1) which can be written as a series, g(\u03c1)= \u2211 k=1 \u221e a k \u03c1 k , (19.18) in which the a k are constant coefficients. Now all we have to do is find a suitable infinite set of coefficients! Let\u2019s check to see that such a solution will work. The first derivative of this g(\u03c1) is dg d\u03c1 = \u2211 k=1 \u221e a k k \u03c1 k\u22121 , \u221e and the second derivative is d 2 g d \u03c1 2 = \u2211 k=1 \u221e a k k(k\u22121) \u03c1 k\u22122 . 2 Using these expressions in (19.17) we have \u2211 k=1 \u221e k(k\u22121) a k \u03c1 k\u22122 \u2212 \u2211 k=1 \u221e 2\u03b1k a k \u03c1 k\u22121 + \u2211 k=1 \u221e 2 a k \u03c1 k\u22121 =0. (19.19) It\u2019s not obvious that we have succeeded; but we forge onward. It will all look better if we replace the first sum by an equivalent. Since the first term of the sum is zero, we can replace each k by k+1 without changing anything in the infinite series; with this change the first sum can equally well be written as \u2211 k=1 \u221e (k+1)k a k+1 \u03c1 k\u22121 . \u221e Now we can put all the sums together to get \u2211 k=1 \u221e [(k+1)k a k+1 \u22122\u03b1k a k +2 a k ] \u03c1 k\u22121 =0. (19.20) This power series must vanish for all possible values of \u03c1 . It can do that only if the coefficient of each power of \u03c1 is separately zero. We will have a solution for the hydrogen atom if we can find a set a k for which (k+1)k a k+1 \u22122(\u03b1k\u22121) a k =0 (19.21) for all k\u22651 . That is certainly easy to arrange. Pick any a 1 you like. Then generate all of the other coefficients from a k+1 = 2(\u03b1k\u22121) k(k+1) a k . (19.22) With this you will get a 2 , a 3 , a 4 , and so on, and each pair will certainly satisfy (19.21). We get a series for g(\u03c1) which satisfies (19.17). With it we can make a \u03c8 , that satisfies Schr\u00f6dinger\u2019s equation. Notice that the solutions depend on the assumed energy (through \u03b1 ), but for each value of \u03f5 , there is a corresponding series. We have a solution, but what does it represent physically? We can get an idea by seeing what happens far from the proton\u2014for large values of \u03c1 . Out there, the high-order terms of the series are the most important, so we should look at what happens for large k . When k\u226b1 , Eq. (19.22) is approximately the same as a k+1 = 2\u03b1 k a k , 2 which means that a k+1 \u2248 (2\u03b1 ) k k! . (19.23) But these are just the coefficients of the series for e +2\u03b1\u03c1 . The function of g is a rapidly increasing exponential. Even coupled with e \u2212\u03b1\u03c1 to produce f(\u03c1) \u2014see Eq. (19.14)\u2014it still gives a solution for f(\u03c1) which goes like e \u03b1\u03c1 for large \u03c1 . We have found a mathematical solution but not a physical one. It represents a situation in which the electron is least likely to be near the proton! It is always more likely to be found at a very large radius \u03c1 . A wave function for a bound electron must go to zero for large \u03c1 . We have to think whether there is some way to beat the game, and there is. Observe! If it just happened by luck that \u03b1 were equal to 1/n , where n is any positive integer, then Eq. (19.22) would make a n+1 =0 . All higher terms would also be zero. We wouldn\u2019t have an infinite series but a finite polynomial. Any polynomial increases more slowly than e \u03b1\u03c1 , so the term e \u2212\u03b1\u03c1 will eventually beat it down, and the function f will go to zero for large \u03c1 . The only bound-state solutions are those for which \u03b1=1/n , with n=1 , 2 , 3 , 4 , and so on. Looking back to Eq. (19.16), we see that the bound-state solutions to the spherically symmetric wave equation can exist only when \u2212\u03f5=1, 1 4 , 1 9 , 1 16 ,\u2026, 1 n 2 ,\u2026 1 1 1 1 The allowed energies are just these fractions times the Rydberg, E R =m e 4 /2 \u210f 2 , or the energy of the n th energy level is E n =\u2212 E R 1 n 2 . (19.24) There is, incidentally, nothing mysterious about negative numbers for the energy. The energies are negative because when we chose to write V=\u2212 e 2 /r , we picked our zero point as the energy of an electron located far from the proton. When it is close to the proton, its energy is less, so somewhat below zero. The energy is lowest (most negative) for n=1 , and increases toward zero with increasing n . Before the discovery of quantum mechanics, it was known from experimental studies of the spectrum of hydrogen that the energy levels could be described by Eq. (19.24), where E R was found from the observations to be about 13.6 electron volts. Bohr then devised a model which gave the same equation and predicted that E R should be m e 4 /2 \u210f 2 . But it was the first great success of the Schr\u00f6dinger theory that it could reproduce this result from a basic equation of motion for the electron. Now that we have solved our first atom, let\u2019s look at the nature of the solution we got. Pulling all the pieces together, each solution looks like this: \u03c8 n = f n (\u03c1) \u03c1 = e \u2212\u03c1/n \u03c1 g n (\u03c1), (19.25) where g n (\u03c1)= \u2211 k=1 n a k \u03c1 k (19.26) and a k+1 = 2(k/n\u22121) k(k+1) a k . (19.27) So long as we are mainly interested in the relative probabilities of finding the electron at various places we can pick any number we wish for a 1 . We may as well set a 1 =1 . (People often choose a 1 so that the wave function is \u201cnormalized,\u201d that is, so that the integrated probability of finding the electron anywhere in the atom is equal to 1 . We have no need to do that just now.) For the lowest energy state, n=1 , and \u03c8 1 (\u03c1)= e \u2212\u03c1 . (19.28) For a hydrogen atom in its ground (lowest-energy) state, the amplitude to find the electron at any point drops off exponentially with the distance from the proton. It is most likely to be found right at the proton, and the characteristic spreading distance is about one unit in \u03c1 , or about one Bohr radius, r B . Putting n=2 gives the next higher level. The wave function for this state will have two terms. It is \u03c8 2 (\u03c1)=(1\u2212 \u03c1 2 ) e \u2212\u03c1/2 . (19.29) The wave function for the next level is \u03c8 3 (\u03c1)=(1\u2212 2\u03c1 3 + 2 27 \u03c1 2 ) e \u2212\u03c1/3 . (19.30) The wave functions for these first three levels are plotted in Fig. 19\u20132. You can see the general trend. All of the wave functions approach zero rapidly for large \u03c1 after oscillating a few times. In fact, the number of \u201cbumps\u201d is just equal to n \u2014or, if you prefer, the number of zero-crossings of \u03c8 n is n\u22121 . In the states described by the \u03c8 n (r) we have found that the probability amplitude for finding the electron is spherically symmetric\u2014depending only on r , the distance from the proton. Such states have zero orbital angular momentum. We should now inquire about states which may have some angular dependences. We could, if we wished, just investigate the strictly mathematical problem of finding the functions of r , \u03b8 , and \u03d5 which satisfy the differential equation (19.7)\u2014putting in the additional physical conditions that the only acceptable functions are ones which go to zero for large r . You will find this done in many books. We are going to take a short cut by using the knowledge we already have about how amplitudes depend on angles in space. The hydrogen atom in any particular state is a particle with a certain \u201cspin\u201d j \u2014the quantum number of the total angular momentum. Part of this spin comes from the electron\u2019s intrinsic spin, and part from the electron\u2019s motion. Since each of these two components acts independently (to an excellent approximation) we will again ignore the spin part and think only about the \u201corbital\u201d angular momentum. This orbital motion behaves, however, just like a spin. For example, if the orbital quantum number is l , the z -component of angular momentum can be l , l\u22121 , l\u22122 , \u2026, \u2212l . (We are, as usual, measuring in units of \u210f .) Also, all the rotation matrices and other properties we have worked out still apply. (From now on we will really ignore the electron\u2019s spin; when we speak of \u201cangular momentum\u201d we will mean only the orbital part.) Since the potential V in which the electron moves depends only on r and not on \u03b8 or \u03d5 , the Hamiltonian is symmetric under all rotations. It follows that the angular momentum and all its components are conserved. (This is true for motion in any \u201ccentral field\u201d\u2014one which depends only on r \u2014so is not a special feature of the Coulomb e 2 /r potential.) Now let\u2019s think of some possible state of the electron; its internal angular structure will be characterized by the quantum number l . Depending on the \u201corientation\u201d of the total angular momentum with respect to the z -axis, the z -component of angular momentum will be m , which is one of the 2l+1 possibilities between +l and \u2212l . Let\u2019s say m=1 . With what amplitude will the electron be found on the z -axis at some distance r ? Zero. An electron on the z -axis cannot have any orbital angular momentum around that axis. Alright, suppose m is zero, then there can be some nonzero amplitude to find the electron at each distance from the proton. We\u2019ll call this amplitude F l (r) . It is the amplitude to find the electron at the distance r up along the z -axis, when the atom is in the state |l,0\u27e9 , by which we mean orbital spin l and z -component m=0 . If we know F l (r) everything is known. For any state |l,m\u27e9 , we know the amplitude \u03c8 l,m (r) to find the electron anywhere in the atom. How? Watch. Suppose we have the atom in the state |l,m\u27e9 , what is the amplitude to find the electron at the angle \u03b8,\u03d5 and the distance r from the origin? Put a new z -axis, say z \u2032 , at that angle (see Fig. 19\u20133), and ask what is the amplitude that the electron will be at the distance r along the new axis z \u2032 ? We know that it cannot be found along z \u2032 unless its z \u2032 -component of angular momentum, say m \u2032 , is zero. When m \u2032 is zero, however, the amplitude to find the electron along z \u2032 is F l (r) . Therefore, the result is the product of two factors. The first is the amplitude that an atom in the state |l,m\u27e9 along the z -axis will be in the state |l, m \u2032 =0\u27e9 with respect to the z \u2032 -axis. Multiply that amplitude by F l (r) and you have the amplitude \u03c8 l,m (r) to find the electron at (r,\u03b8,\u03d5) with respect to the original axes. Let\u2019s write it out. We have worked out earlier the transformation matrices for rotations. To go from the frame x,y,z to the frame x \u2032 , y \u2032 , z \u2032 of Fig. 19\u20133, we can rotate first around the z -axis by the angle \u03d5 , and then rotate about the new y -axis ( y \u2032 ) by the angle \u03b8 . This combined rotation is the product R y (\u03b8) R z (\u03d5). ( \u03b8 ) ( \u03d5 ) The amplitude to find the state l, m \u2032 =0 after the rotation is \u27e8l,0| R y (\u03b8) R z (\u03d5)|l,m\u27e9. (19.31) Our result, then, is \u03c8 l,m (r)=\u27e8l,0| R y (\u03b8) R z (\u03d5)|l,m\u27e9 F l (r). (19.32) The orbital motion can have only integral values of l . (If the electron can be found anywhere at r\u22600 , there is some amplitude to have m=0 in that direction. And m=0 states exist only for integral spins.) The rotation matrices for l=1 are given in Table 17\u20132. For larger l you can use the general formulas we worked out in Chapter 18. The matrices for R z (\u03d5) and R y (\u03b8) appear separately, but you know how to combine them. For the general case you would start with the state |l,m\u27e9 and operate with R z (\u03d5) to get the new state R z (\u03d5)|l,m\u27e9 (which is just e im\u03d5 |l,m\u27e9 ). Then you operate on this state with R y (\u03b8) to get the state R y (\u03b8) R z (\u03d5)|l,m\u27e9 . Multiplying by \u27e8l,0| gives the matrix element (19.31). The matrix elements of the rotation operation are functions of \u03b8 and \u03d5 . The particular functions which appear in (19.31) also show up in many kinds of problems which involve waves in spherical geometries and so has been given a special name. Not everyone uses the same convention; but one of the most common ones is \u27e8l,0| R y (\u03b8) R z (\u03d5)|l,m\u27e9\u2261a Y l,m (\u03b8,\u03d5). (19.33) The functions Y l,m (\u03b8,\u03d5) are called the spherical harmonics, and a is just a numerical factor which depends on the definition chosen for Y l,m . For the usual definition, a= 4\u03c0 2l+1 \u2212 \u2212 \u2212 \u2212 \u2212 \u2212 \u221a . (19.34) With this notation, the hydrogen wave functions can be written \u03c8 l,m (r)=a Y l,m (\u03b8,\u03d5) F l (r). (19.35) The angle functions Y l,m (\u03b8,\u03d5) are important not only in many quantum-mechanical problems, but also in many areas of classical physics in which the \u2207 2 operator appears, such as electromagnetism. As another example of their use in quantum mechanics, consider the disintegration of an excited state of Ne 20 (such as we discussed in the last chapter) which decays by emitting an \u03b1 -particle and going into O 16 : Ne 20\u2217 \u2192 O 16 + He 4 . 20 16 4 Suppose that the excited state has some spin l (necessarily an integer) and that the z -component of angular momentum is m . We might now ask the following: given l and m , what is the amplitude that we will find the \u03b1 -particle going off in a direction which makes the angle \u03b8 with respect to the z -axis and the angle \u03d5 with respect to the xz -plane\u2014as shown in Fig. 19\u20134. To solve this problem we make, first, the following observation. A decay in which the \u03b1 -particle goes straight up along z must come from a state with m=0 . This is so because both O 16 and the \u03b1 -particle have spin zero, and because their motion cannot have any angular momentum about the z -axis. Let\u2019s call this amplitude a (per unit solid angle). Then, to find the amplitude for a decay at the arbitrary angle of Fig. 19\u20134, all we need to know is what amplitude the given initial state has zero angular momentum about the decay direction. The amplitude for the decay at \u03b8 and \u03d5 is then a times the amplitude that a state |l,m\u27e9 with respect to the z -axis will be in the state |l,0\u27e9 with respect to z \u2032 \u2014the decay direction. This latter amplitude is just what we have written in (19.31). The probability to see the \u03b1 -particle at \u03b8,\u03d5 is P(\u03b8,\u03d5)= a 2 |\u27e8l,0| R y (\u03b8) R z (\u03d5)|l,m\u27e9 | 2 . 2 As an example, consider an initial state with l=1 and various values of m . From Table 17\u20132 we know the necessary amplitudes. They are \u27e81,0| R y (\u03b8) R z (\u03d5)|1,+1\u27e9 \u27e81,0| R y (\u03b8) R z (\u03d5)|1,0\u27e9 \u27e81,0| R y (\u03b8) R z (\u03d5)|1,\u22121\u27e9 =\u2212 1 2 \u2013 \u221a sin\u03b8 e i\u03d5 , =cos\u03b8, = 1 2 \u2013 \u221a sin\u03b8 e \u2212i\u03d5 . (19.36) These are the three possible angular distribution amplitudes\u2014depending on the m -value of the initial nucleus. Amplitudes such as the ones in (19.36) appear so often and are sufficiently important that they are given several names. If the angular distribution amplitude is proportional to any one of the three functions or any linear combination of them, we say, \u201cThe system has an orbital angular momentum of one.\u201d Or we may say, \u201cThe Ne 20\u2217 emits a p -wave \u03b1 -particle.\u201d Or we say, \u201cThe \u03b1 -particle is emitted in an l=1 state.\u201d Because there are so many ways of saying the same thing it is useful to have a dictionary. If you are going to understand what other physicists are talking about, you will just have to memorize the language. In Table 19\u20131 we give a dictionary of orbital angular momentum. If the orbital angular momentum is zero, then there is no change when you rotate the coordinate system and there is no variation with angle\u2014the \u201cdependence\u201d on angle is as a constant, say 1 . This is also called an \u201c s -state\u201d, and there is only one such state\u2014as far as angular dependence is concerned. If the orbital angular momentum is 1 , then the amplitude of the angular variation may be any one of the three functions given\u2014depending on the value of m \u2014or it may be a linear combination. These are called \u201c p -states,\u201d and there are three of them. If the orbital angular momentum is 2 then there are the five functions shown. Any linear combination is called an \u201c l=2 ,\u201d or a \u201c d -wave\u201d amplitude. Now you can immediately guess what the next letter is\u2014what should come after s , p , d ? Well, of course, f , g , h , and so on down the alphabet! The letters don\u2019t mean anything. (They did once mean something\u2014they meant \u201csharp\u201d lines, \u201cprincipal\u201d lines, \u201cdiffuse\u201d lines and \u201cfundamental\u201d lines of the optical spectra of atoms. But those were in the days when people did not know where the lines came from. After f there were no special names, so we now just continue with g , h , and so on.) The angular functions in the table go by several names\u2014and are sometimes defined with slightly different conventions about the numerical factors that appear out in front. Sometimes they are called \u201cspherical harmonics,\u201d and written as Y l,m (\u03b8,\u03d5) . Sometimes they are written P m l (cos\u03b8) e im\u03d5 , and if m=0 , simply as P l (cos\u03b8) . The functions P l (cos\u03b8) are called the \u201cLegendre polynomials\u201d in cos\u03b8 , and the functions P m l (cos\u03b8) are called the \u201cassociated Legendre functions.\u201d You will find tables of these functions in many books. Notice, incidentally, that all the functions for a given l have the property that they have the same parity\u2014for odd l they change sign under an inversion and for even l they don\u2019t change. So we can write that the parity of a state of orbital angular momentum l is (\u22121 ) l . As we have seen, these angular distributions may refer to a nuclear disintegration or some other process, or to the distribution of the amplitude to find an electron at some place in the hydrogen atom. For instance, if an electron is in a p -state ( l=1 ) the amplitude to find it can depend on the angle in many possible ways\u2014but all are linear combinations of the three functions for l=1 in Table 19\u20131. Let\u2019s take the case cos\u03b8 . That\u2019s interesting. That means that the amplitude is positive, say, in the upper part ( \u03b8<\u03c0/2 ), is negative in the lower part ( \u03b8>\u03c0/2 ), and is zero when \u03b8 is 90 \u2218 . Squaring this amplitude we see that the probability of finding the electron varies with \u03b8 as shown in Fig. 19\u20135\u2014and is independent of \u03d5 . This angular distribution is responsible for the fact that in molecular binding the attraction of an electron in an l=1 state for another atom depends on direction\u2014it is the origin of the directed valences of chemical attraction. In Eq. (19.35) we have written the wave functions for the hydrogen atom as \u03c8 l,m (r)=a Y l,m (\u03b8,\u03d5) F l (r). (19.37) These wave functions must be solutions of the differential equation (19.7). Let\u2019s see what that means. Put (19.37) into (19.7); you get Y l,m r \u2202 2 \u2202 r 2 (r F l ) + F l r 2 sin\u03b8 \u2202 \u2202\u03b8 (sin\u03b8 \u2202 Y l,m \u2202\u03b8 ) + F l r 2 sin 2 \u03b8 \u2202 2 Y l,m \u2202 \u03d5 2 =\u2212 2m \u210f 2 (E+ e 2 r ) Y l,m F l . (19.38) Now multiply through by r 2 / F l and rearrange terms. The result is 1 sin\u03b8 \u2202 \u2202\u03b8 (sin\u03b8 \u2202 Y l,m \u2202\u03b8 )+ 1 sin 2 \u03b8 \u2202 2 Y l,m \u2202 \u03d5 2 =\u2212[ r 2 F l { 1 r d 2 d r 2 (r F l )+ 2m \u210f 2 (E+ e 2 r ) F l }] Y l,m . (19.39) The left-hand side of this equation depends on \u03b8 and \u03d5 , but not on r . No matter what value we choose for r , the left side doesn\u2019t change. This must also be true for the right-hand side. Although the quantity in the square brackets has r \u2019s all over the place, the whole quantity cannot depend on r , otherwise we wouldn\u2019t have an equation good for all r . As you can see, the bracket also does not depend on \u03b8 or \u03d5 . It must be some constant. Its value may well depend on the l -value of the state we are studying, since the function F l must be the one appropriate to that state; we\u2019ll call the constant K l . Equation (19.39) is therefore equivalent to two equations: 1 sin\u03b8 \u2202 \u2202\u03b8 (sin\u03b8 \u2202 Y l,m \u2202\u03b8 )+ 1 sin 2 \u03b8 \u2202 2 Y l,m \u2202 \u03d5 2 =\u2212 K l Y l,m , 1 r d 2 d r 2 (r F l )+ 2m \u210f 2 (E+ e 2 r ) F l = K l F l r 2 . (19.40) (19.41) Now look at what we\u2019ve done. For any state described by l and m , we know the functions Y l,m ; we can use Eq. (19.40) to determine the constant K l . Putting K l into Eq. (19.41) we have a differential equation for the function F l (r) . If we can solve that equation for F l (r) , we have all of the pieces to put into (19.37) to give \u03c8(r) . What is K l ? First, notice that it must be the same for all m (which go with a particular l ), so we can pick any m we want for Y l,m and plug it into (19.40) to solve for K l . Perhaps the easiest one to use is Y l,l . From Eq. (18.24), R z (\u03d5)|l,l\u27e9= e il\u03d5 |l,l\u27e9. (19.42) The matrix element for R y (\u03b8) is also quite simple: \u27e8l,0| R y (\u03b8)|l,l\u27e9=b(sin\u03b8 ) l , (19.43) where b is some number.3 Combining the two, we obtain Y l,l \u221d e il\u03d5 sin l \u03b8. (19.44) Putting this function into (19.40) gives K l =l(l+1). (19.45) Now that we have determined K l , Eq. (19.41) tells us about the radial function F l (r) . It is, of course, just the Schr\u00f6dinger equation with the angular part replaced by its equivalent K l F l / r 2 . Let\u2019s rewrite (19.41) in the form we had in Eq. (19.8), as follows: 1 r d 2 d r 2 (r F l )=\u2212 2m \u210f 2 {E+ e 2 r \u2212 l(l+1) \u210f 2 2m r 2 } F l . (19.46) A mysterious term has been added to the potential energy. Although we got this term by some mathematical shenanigan, it has a simple physical origin. We can give you an idea about where it comes from in terms of a semi-classical argument. Then perhaps you will not find it quite so mysterious. Think of a classical particle moving around some center of force. The total energy is conserved and is the sum of the potential and kinetic energies U=V(r)+ 1 2 m v 2 =constant. 1 In general, v can be resolved into a radial component v r and a tangential component r \u03b8 \u02d9 ; then v 2 = v 2 r +(r \u03b8 \u02d9 ) 2 . Now the angular momentum m r 2 \u03b8 \u02d9 is also conserved; say it is equal to L . We can then write m r 2 \u03b8 \u02d9 =L,orr \u03b8 \u02d9 = L mr , L and the energy is U= 1 2 m v 2 r +V(r)+ L 2 2m r 2 . 2 If there were no angular momentum we would have just the first two terms. Adding the angular momentum L does to the energy just what adding a term L 2 /2m r 2 to the potential energy would do. But this is almost exactly the extra term in (19.46). The only difference is that l(l+1) \u210f 2 appears for the angular momentum instead of l 2 \u210f 2 as we might expect. But we have seen before (for example, Volume II, Section 34-7) that this is just the substitution that is usually required to make a quasi-classical argument agree with a correct quantum-mechanical calculation. We can, then, understand the new term as a \u201cpseudo-potential\u201d which gives the \u201ccentrifugal force\u201d term that appears in the equations of radial motion for a rotating system. (See the discussion of \u201cpseudo-forces\u201d in Volume I, Section 12-5.) We are now ready to solve Eq. (19.46) for F l (r) . It is very much like Eq. (19.8), so the same technique will work again. Everything goes as before until you get to Eq. (19.19) which will have the additional term \u2212l(l+1) \u2211 k=1 \u221e a k \u03c1 k\u22122 . (19.47) This term can also be written as \u2212l(l+1){ a 1 \u03c1 + \u2211 k=1 \u221e a k+1 \u03c1 k\u22121 }. (19.48) (We have taken out the first term and then shifted the running index k down by 1 .) Instead of Eq. (19.20) we have \u2211 k=1 \u221e [{k(k+1)\u2212l(l+1)} a k+1 \u22122(\u03b1k\u22121) a k ] \u03c1 k\u22121 \u2212 l(l+1) a 1 \u03c1 =0. (19.49) There is only one term in \u03c1 \u22121 , so it must be zero. The coefficient a 1 must be zero (unless l=0 and we have our previous solution). Each of the other terms is made zero by having the square bracket come out zero for every k . This condition replaces Eq. (19.22) by a k+1 = 2(\u03b1k\u22121) k(k+1)\u2212l(l+1) a k . (19.50) This is the only significant change from the spherically symmetric case. As before the series must terminate if we are to have solutions which can represent bound electrons. The series will end at k=n if \u03b1n=1 . We get again the same condition on \u03b1 , that it must be equal to 1/n , where n is some positive integer. However, Eq. (19.50) also gives a new restriction. The index k cannot be equal to l , the denominator becomes zero and a l+1 is infinite. That is, since a 1 =0 , Eq. (19.50) implies that all successive a k are zero until we get to a l+1 , which can be nonzero. This means that k must start at l+1 and end at n . Our final result is that for any l there are many possible solutions which we can call F n,l where n\u2265l+1 . Each solution has the energy E n =\u2212 m e 4 2 \u210f 2 ( 1 n 2 ). (19.51) The wave function for the state of this energy with the angular quantum numbers l and m is \u03c8 n,l,m =a Y l,m (\u03b8,\u03d5) F n,l (\u03c1), (19.52) with \u03c1 F n,l (\u03c1)= e \u2212\u03b1\u03c1 \u2211 k=l+1 n a k \u03c1 k . (19.53) The coefficients a k are obtained from (19.50). We have, finally, a complete description of the states of a hydrogen atom. Let\u2019s review what we have discovered. The states which satisfy Schr\u00f6dinger\u2019s equation for an electron in a Coulomb field are characterized by three quantum numbers n , l , m , all integers. The angular distribution of the electron amplitude can have only certain forms which we call Y l,m . They are labeled by l , the quantum number of total angular momentum, and m , the \u201cmagnetic\u201d quantum number, which can range from \u2212l to +l . For each angular configuration, various possible radial distributions F n,l (r) of the electron amplitude are possible; they are labeled by the principal quantum number n \u2014which can range from l+1 to \u221e . The energy of the state depends only on n , and increases with increasing n . The lowest energy, or ground, state is an s -state. It has l=0 , n=1 , and m=0 . It is a \u201cnondegenerate\u201d state\u2014there is only one with this energy, and its wave function is spherically symmetric. The amplitude to find the electron is a maximum at the center, and falls off monotonically with increasing distance from the center. We can visualize the electron amplitude as a blob as shown in Fig. 19\u20136(a). There are other s -states with higher energies, for n=2 , 3 , 4 , \u2026 For each energy there is only one version ( m=0 ), and they are all spherically symmetric. These states have amplitudes which alternate in sign one or more times with increasing r . There are n\u22121 spherical nodal surfaces\u2014the places where \u03c8 goes through zero. The 2s -state ( l=0 , n=2 ), for example, will look as sketched in Fig. 19\u20136(b). (The dark areas indicate regions where the amplitude is large, and the plus and minus signs indicate the relative phases of the amplitude.) The energy levels of the s -states are shown in the first column of Fig. 19\u20137. Then there are the p -states\u2014with l=1 . For each n , which must be 2 or greater, there are three states of the same energy, one each for m=+1 , m=0 , and m=\u22121 . The energy levels are as shown in Fig. 19\u20137. The angular dependences of these states are given in Table 19\u20131. For instance, for m=0 , if the amplitude is positive for \u03b8 near zero, it will be negative for \u03b8 near 180 \u2218 . There is a nodal plane coincident with the xy -plane. For n>2 there are also spherical nodes. The n=2 , m=0 amplitude is sketched in Fig. 19\u20136(c), and the n=3 , m=0 wave function is sketched in Fig. 19\u20136(d). You might think that since m represents a kind of \u201corientation\u201d in space, there should be similar distributions with the peaks of amplitude along the x -axis or along the y -axis. Are these perhaps the m=+1 and m=\u22121 states? No. But since we have three states with equal energies, any linear combinations of the three will also be stationary states of the same energy. It turns out that the \u201c x \u201d-state\u2014which corresponds to the \u201c z \u201d-state, or m=0 state, of Fig. 19\u20136(c)\u2014is a linear combination of the m=+1 and m=\u22121 states. The corresponding \u201c y \u201d-state is another combination. Specifically, we mean that \u201cz\u201d \u201cx\u201d \u201cy\u201d =|1,0\u27e9, =\u2212 |1,+1\u27e9\u2212|1,\u22121\u27e9 2 \u2013 \u221a , =\u2212 |1,+1\u27e9+|1,\u22121\u27e9 i 2 \u2013 \u221a . These states all look the same when referred to their particular axes. The d -states ( l=2 ) have five possible values of m for each energy, the lowest energy has n=3 . The levels go as shown in Fig. 19\u20137. The angular dependences get more complicated. For instance the m=0 states have two conical nodes, so the wave function reverses phase from + , to \u2212 , to + as you go around from the north pole to the south pole. The rough form of the amplitude is sketched in (e) and (f) of Fig. 19\u20136 for the m=0 states with n=3 and n=4 . Again, the larger n \u2019s have spherical nodes. We will not try to describe any more of the possible states. You will find the hydrogen wave functions described in more detail in many books. Two good references are L. Pauling and E. B. Wilson, Introduction to Quantum Mechanics, McGraw-Hill (1935); and R. B. Leighton, Principles of Modern Physics, McGraw-Hill (1959). You will find in them graphs of some of the functions and pictorial representations of many states. We would like to mention one particular feature of the wave functions for higher l : for l>0 the amplitudes are zero at the center. That is not surprising, since it\u2019s hard for an electron to have angular momentum when its radius arm is very small. For this reason, the higher the l , the more the amplitudes are \u201cpushed away\u201d from the center. If you look at the way the radial functions F n,l (r) vary for small r , you find from (19.53) that F n,l (r)\u2248 r l . l Such a dependence on r means that for larger l \u2019s you have to go farther from r=0 before you get an appreciable amplitude. This behavior is, incidentally, determined by the centrifugal force term in the radial equation, so the same thing will apply for any potential that varies slower than 1/ r 2 for small r \u2014which most atomic potentials do. We would like now to apply the theory of the hydrogen atom in an approximate way to get some understanding of the chemist\u2019s periodic table of the elements. For an element with atomic number Z there are Z electrons held together by the electric attraction of the nucleus but with mutual repulsion of the electrons. To get an exact solution we would have to solve Schr\u00f6dinger\u2019s equation for Z electrons in a Coulomb field. For helium the equation is \u2212 \u210f i \u2202\u03c8 \u2202t =\u2212 \u210f 2 2m ( \u2207 2 1 \u03c8+ \u2207 2 2 \u03c8)+(\u2212 2 e 2 r 1 \u2212 2 e 2 r 2 + e 2 r 12 )\u03c8, 2 where \u2207 2 1 is a Laplacian which operates on r 1 , the coordinate of one electron; \u2207 2 2 operates on r 2 ; and r 12 =| r 1 \u2212 r 2 | . (We are again neglecting the spin of the electrons.) To find the stationary states and energy levels we would have to find solutions of the form \u03c8=f( r 1 , r 2 ) e \u2212(i/\u210f)Et . ( i / \u210f ) E The geometrical dependence is contained in f , which is a function of six variables\u2014the simultaneous positions of the two electrons. No one has found an analytic solution, although solutions for the lowest energy states have been obtained by numerical methods. With 3 , 4 , or 5 electrons it is hopeless to try to obtain exact solutions, and it is going too far to say that quantum mechanics has given a precise understanding of the periodic table. It is possible, however, even with a sloppy approximation\u2014and some fixing\u2014to understand, at least qualitatively, many chemical properties which show up in the periodic table. The chemical properties of atoms are determined primarily by their lowest energy states. We can use the following approximate theory to find these states and their energies. First, we neglect the electron spin, except that we adopt the exclusion principle and say that any particular electronic state can be occupied by only one electron. This means that any particular orbital configuration can have up to two electrons\u2014one with spin up, the other with spin down. Next we disregard the details of the interactions between the electrons in our first approximation, and say that each electron moves in a central field which is the combined field of the nucleus and all the other electrons. For neon, which has 10 electrons, we say that one electron sees an average potential due to the nucleus plus the other nine electrons. We imagine then that in the Schr\u00f6dinger equation for each electron we put a V(r) which is a 1/r field modified by a spherically symmetric charge density coming from the other electrons. In this model each electron acts like an independent particle. The angular dependence of its wave function will be just the same as the ones we had for the hydrogen atom. There will be s -states, p -states, and so on; and they will have the various possible m -values. Since V(r) no longer goes as 1/r , the radial part of the wave functions will be somewhat different, but it will be qualitatively the same, so we will have the same radial quantum numbers, n . The energies of the states will also be somewhat different. With these ideas, let\u2019s see what we get. The ground state of hydrogen has l=m=0 and n=1 ; we say the electron configuration is 1s . The energy is \u221213.6 eV. This means that it takes 13.6 electron volts to pull the electron off the atom. We call this the \u201cionization energy\u201d, W I . A large ionization energy means that it is harder to pull the electron off and, in general, that the material is chemically less active. Now take helium. Both electrons can be in the same lowest state (one spin up and the other spin down). In this lowest state the electron moves in a potential which is for small r like a Coulomb field for z=2 and for large r like a Coulomb field for z=1 . The result is a \u201chydrogen-like\u201d 1s state with a somewhat lower energy. Both electrons occupy identical 1s states ( l=0 , m=0 ). The observed ionization energy (to remove one electron) is 24.6 electron volts. Since the 1s \u201cshell\u201d is now filled\u2014we allow only two electrons\u2014there is practically no tendency for an electron to be attracted from another atom. Helium is chemically inert. The lithium nucleus has a charge of 3 . The electron states will again be hydrogen-like, and the three electrons will occupy the lowest three energy levels. Two will go into 1s states and the third will go into an n=2 state. But with l=0 or l=1 ? In hydrogen these states have the same energy, but in other atoms they don\u2019t, for the following reason. Remember that a 2s state has some amplitude to be near the nucleus while the 2p state does not. That means that a 2s electron will feel some of the triple electric charge of the Li nucleus, but that a 2p electron will stay out where the field looks like the Coulomb field of a single charge. The extra attraction lowers the energy of the 2s state relative to the 2p state. The energy levels will be roughly as shown in Fig. 19\u20138\u2014which you should compare with the corresponding diagram for hydrogen in Fig. 19\u20137. So the lithium atom will have two electrons in 1s states and one in a 2s . Since the 2s electron has a higher energy than a 1s electron it is relatively easily removed. The ionization energy of lithium is only 5.4 electron volts, and it is quite active chemically. So you can see the patterns which develop; we have given in Table 19\u20132 a list of the first 36 elements, showing the states occupied by the electrons in the ground state of each atom. The Table gives the ionization energy for the most loosely bound electron, and the number of electrons occupying each \u201cshell\u201d\u2014by which we mean states with the same n . Since the different l -states have different energies, each l -value corresponds to a sub-shell of 2(2l+1) possible states (of different m and electron spin). These all have the same energy\u2014except for some very small effects we are neglecting. Beryllium is like lithium except that it has two electrons in the 2s state as well as two in the filled 1s shell. Boron has 5 electrons. The fifth must go into a 2p state. There are 2\u00d73=6 different 2p states, so we can keep adding electrons until we get to a total of 8 . This takes us to neon. As we add these electrons we are also increasing Z , so the whole electron distribution gets pulled in closer and closer to the nucleus and the energy of the 2p states goes down. By the time we get to neon the ionization energy is up to 21.6 electron volts. Neon does not easily give up an electron. Also there are no more low-energy slots to be filled, so it won\u2019t try to grab an extra electron. Neon is chemically inert. Fluorine, on the other hand, does have an empty position where an electron can drop into a state of low energy, so it is quite active in chemical reactions. With sodium the eleventh electron must start a new shell\u2014going into a 3s state. The energy level of this state is much higher; the ionization energy jumps down; and sodium is an active chemical. From sodium to argon the s and p states with n=3 are occupied in exactly the same sequence as for lithium to neon. Angular configurations of the electrons in the outer unfilled shell have the same sequence, and the progression of ionization energies is quite similar. You can see why the chemical properties repeat with increasing atomic number. Magnesium acts chemically much like beryllium, silicon like carbon, and chlorine like fluorine. Argon is inert like neon. You may have noticed that there is a slight peculiarity in the sequence of ionization energies between lithium and neon, and a similar one between sodium and argon. The last electron is bound to the oxygen atom somewhat less than we might expect. And sulfur is similar. Why should that be? We can understand it if we put in just a little bit of the effects of the interactions between individual electrons. Think of what happens when we put the first 2p electron onto the boron atom. It has six possibilities\u2014three possible p -states, each with two spins. Imagine that the electron goes with spin up into the m=0 state, which we have also called the \u201c z \u201d state because it hugs the z -axis. Now what will happen in carbon? There are now two 2p electrons. If one of them goes into the \u201c z \u201d state, where will the second one go? It will have lower energy if it stays away from the first electron, which it can do by going into, say, the \u201c x \u201d state of the 2p shell. (This state is, remember, just a linear combination of the m=+1 and m=\u22121 states.) Next, when we go to nitrogen, the three 2p electrons will have the lowest energy of mutual repulsion if they go one each into the \u201c x ,\u201d \u201c y ,\u201d and \u201c z \u201d configurations. For oxygen, however, the jig is up. The fourth electron must go into one of the filled states\u2014with opposite spin. It is strongly repelled by the electron already in that state, so its energy will not be as low as it might otherwise be, and it is more easily removed. That explains the break in the sequence of binding energies which appears between nitrogen and oxygen, and between phosphorus and sulfur. After argon, you would, at first, think that the new electrons would start to fill up the 3d states. But they don\u2019t. As we described earlier\u2014and illustrated in Fig. 19\u20138\u2014the higher angular momentum states get pushed up in energy. By the time we get to the 3d states they are pushed to an energy a little bit above the energy of the 4s state. So in potassium the last electron goes into the 4s state. After this shell is filled (with two electrons) at calcium, the 3d states begin to be filled for scandium, titanium, and vanadium. The energies of the 3d and 4s states are so close together that small effects can shift the balance either way. By the time we get to put four electrons into the 3d states, their repulsion raises the energy of the 4s state just enough that its energy is slightly above the 3d energy, so one electron shifts over. For chromium we don\u2019t get a 4 , 2 combination as we would have expected, but instead a 5 , 1 combination. The new electron added to get manganese fills up the 4s shell again, and the states of the 3d shell are then occupied one by one until we reach copper. Since the outermost shell of manganese, iron, cobalt, and nickel have the same configurations, however, they all tend to have similar chemical properties. (This effect is much more pronounced in the rare-earth elements which all have the same outer shell but a progressively filling inner shell which has much less influence on their chemical properties.) In copper an electron is robbed from the 4s shell, finally completing the 3d shell. The energy of the 10 , 1 combination is, however, so close to the 9 , 2 configuration for copper that just the presence of another atom nearby can shift the balance. For this reason the two last electrons of copper are nearly equivalent, and copper can have a valence of either 1 or 2 . (It sometimes acts as though its electrons were in the 9 , 2 combination.) Similar things happen at other places and account for the fact that other metals, such as iron, combine chemically with either of two valences. By zinc, both the 3d and 4s shells are filled once and for all. From gallium to krypton the sequence proceeds normally again, filling the 4p shell. The outer shells, the energies, and the chemical properties repeat the pattern of boron to neon and aluminum to argon. Krypton, like argon and neon, is known as \u201cnoble\u201d gas. All three are chemically \u201cinert.\u201d This means only that, having filled shells of relatively low energy, there are few situations in which there is an energy advantage for them to join in a simple combination with other elements. Having a filled shell is not enough. Beryllium and magnesium have filled s -shells, but the energy of these shells is too high to lead to stability. Similarly, one would have expected another \u201cnoble\u201d element at nickel, if the energy of the 3d shell had been lower (or the 4s higher). On the other hand, krypton is not completely inert; it will form a weakly-bound compound with chlorine. Since our sample has turned up most of the main features of the periodic table, we stop our examination at element number 36 \u2014there are still seventy or so more! We would like to bring up only one more point\u2014that we not only can understand the valences to some extent but also can say something about the directional properties of the chemical bonds. Take an atom like oxygen which has four 2p electrons. The first three go into \u201c x ,\u201d \u201c y ,\u201d and \u201c z \u201d states and the fourth will double one of these states, leaving two\u2014say \u201c x \u201d and \u201c y \u201d\u2014vacant. Consider then what happens in H 2 O. Each of the two hydrogens are willing to share an electron with the oxygen, helping the oxygen to fill a shell. These electrons will tend to go into the \u201c x \u201d and \u201c y \u201d vacancies. So the water molecule should have the two hydrogen atoms making a right angle with respect to the center of the oxygen. The angle is actually 105 \u2218 . We can even understand why the angle is larger than 90 \u2218 . In sharing their electrons the hydrogens end up with a net positive charge. The electric repulsion \u201cstrains\u201d the wave functions and pushes the angle out to 105 \u2218 . The same situation occurs in H 2 S. But because the sulfur atom is larger, the two hydrogen atoms are farther apart, there is less repulsion, and the angle is only pushed out to about 93 \u2218 . Selenium is even larger, so in H 2 Se the angle is very nearly 90 \u2218 . We can use the same arguments to understand the geometry of ammonia, H 3 N. Nitrogen has room for three more 2p electrons, one each for the \u201c x ,\u201d \u201c y ,\u201d and \u201c z \u201d type states. The three hydrogens should join on at right angles to each other. The angles come out a little larger than 90 \u2218 \u2014again from the electric repulsion\u2014but at least we see why the molecule of H 3 N is not flat. The angles in phosphene, H 3 P, are close to 90 \u2218 , and in H 3 As are still closer. We assumed that NH 3 was not flat when we described it as a two-state system. And the nonflatness is what makes the ammonia maser possible. Now we see that also that shape can be understood from our quantum mechanics. The Schr\u00f6dinger equation has been one of the great triumphs of physics. By providing the key to the underlying machinery of atomic structure it has given an explanation for atomic spectra, for chemistry, and for the nature of matter."
    },
    {
        "input": "Characteristics of Force",
        "output": "Although it is interesting and worthwhile to study the physical laws simply because they help us to understand and to use nature, one ought to stop every once in a while and think, \u201cWhat do they really mean?\u201d The meaning of any statement is a subject that has interested and troubled philosophers from time immemorial, and the meaning of physical laws is even more interesting, because it is generally believed that these laws represent some kind of real knowledge. The meaning of knowledge is a deep problem in philosophy, and it is always important to ask, \u201cWhat does it mean?\u201d Let us ask, \u201cWhat is the meaning of the physical laws of Newton, which we write as F=ma ? What is the meaning of force, mass, and acceleration?\u201d Well, we can intuitively sense the meaning of mass, and we can define acceleration if we know the meaning of position and time. We shall not discuss those meanings, but shall concentrate on the new concept of force. The answer is equally simple: \u201cIf a body is accelerating, then there is a force on it.\u201d That is what Newton\u2019s laws say, so the most precise and beautiful definition of force imaginable might simply be to say that force is the mass of an object times the acceleration. Suppose we have a law which says that the conservation of momentum is valid if the sum of all the external forces is zero; then the question arises, \u201cWhat does it mean, that the sum of all the external forces is zero?\u201d A pleasant way to define that statement would be: \u201cWhen the total momentum is a constant, then the sum of the external forces is zero.\u201d There must be something wrong with that, because it is just not saying anything new. If we have discovered a fundamental law, which asserts that the force is equal to the mass times the acceleration, and then define the force to be the mass times the acceleration, we have found out nothing. We could also define force to mean that a moving object with no force acting on it continues to move with constant velocity in a straight line. If we then observe an object not moving in a straight line with a constant velocity, we might say that there is a force on it. Now such things certainly cannot be the content of physics, because they are definitions going in a circle. The Newtonian statement above, however, seems to be a most precise definition of force, and one that appeals to the mathematician; nevertheless, it is completely useless, because no prediction whatsoever can be made from a definition. One might sit in an armchair all day long and define words at will, but to find out what happens when two balls push against each other, or when a weight is hung on a spring, is another matter altogether, because the way the bodies behave is something completely outside any choice of definitions. For example, if we were to choose to say that an object left to itself keeps its position and does not move, then when we see something drifting, we could say that must be due to a \u201cgorce\u201d\u2014a gorce is the rate of change of position. Now we have a wonderful new law, everything stands still except when a gorce is acting. You see, that would be analogous to the above definition of force, and it would contain no information. The real content of Newton\u2019s laws is this: that the force is supposed to have some independent properties, in addition to the law F=ma ; but the specific independent properties that the force has were not completely described by Newton or by anybody else, and therefore the physical law F=ma is an incomplete law. It implies that if we study the mass times the acceleration and call the product the force, i.e., if we study the characteristics of force as a program of interest, then we shall find that forces have some simplicity; the law is a good program for analyzing nature, it is a suggestion that the forces will be simple. Now the first example of such forces was the complete law of gravitation, which was given by Newton, and in stating the law he answered the question, \u201cWhat is the force?\u201d If there were nothing but gravitation, then the combination of this law and the force law (second law of motion) would be a complete theory, but there is much more than gravitation, and we want to use Newton\u2019s laws in many different situations. Therefore in order to proceed we have to tell something about the properties of force. For example, in dealing with force the tacit assumption is always made that the force is equal to zero unless some physical body is present, that if we find a force that is not equal to zero we also find something in the neighborhood that is a source of the force. This assumption is entirely different from the case of the \u201cgorce\u201d that we introduced above. One of the most important characteristics of force is that it has a material origin, and this is not just a definition. Newton also gave one rule about the force: that the forces between interacting bodies are equal and opposite\u2014action equals reaction; that rule, it turns out, is not exactly true. In fact, the law F=ma is not exactly true; if it were a definition we should have to say that it is always exactly true; but it is not. The student may object, \u201cI do not like this imprecision, I should like to have everything defined exactly; in fact, it says in some books that any science is an exact subject, in which everything is defined.\u201d If you insist upon a precise definition of force, you will never get it! First, because Newton\u2019s Second Law is not exact, and second, because in order to understand physical laws you must understand that they are all some kind of approximation. Any simple idea is approximate; as an illustration, consider an object, \u2026 what is an object? Philosophers are always saying, \u201cWell, just take a chair for example.\u201d The moment they say that, you know that they do not know what they are talking about any more. What is a chair? Well, a chair is a certain thing over there \u2026 certain?, how certain? The atoms are evaporating from it from time to time\u2014not many atoms, but a few\u2014dirt falls on it and gets dissolved in the paint; so to define a chair precisely, to say exactly which atoms are chair, and which atoms are air, or which atoms are dirt, or which atoms are paint that belongs to the chair is impossible. So the mass of a chair can be defined only approximately. In the same way, to define the mass of a single object is impossible, because there are not any single, left-alone objects in the world\u2014every object is a mixture of a lot of things, so we can deal with it only as a series of approximations and idealizations. The trick is the idealizations. To an excellent approximation of perhaps one part in 1010 , the number of atoms in the chair does not change in a minute, and if we are not too precise we may idealize the chair as a definite thing; in the same way we shall learn about the characteristics of force, in an ideal fashion, if we are not too precise. One may be dissatisfied with the approximate view of nature that physics tries to obtain (the attempt is always to increase the accuracy of the approximation), and may prefer a mathematical definition; but mathematical definitions can never work in the real world. A mathematical definition will be good for mathematics, in which all the logic can be followed out completely, but the physical world is complex, as we have indicated in a number of examples, such as those of the ocean waves and a glass of wine. When we try to isolate pieces of it, to talk about one mass, the wine and the glass, how can we know which is which, when one dissolves in the other? The forces on a single thing already involve approximation, and if we have a system of discourse about the real world, then that system, at least for the present day, must involve approximations of some kind. This system is quite unlike the case of mathematics, in which everything can be defined, and then we do not know what we are talking about. In fact, the glory of mathematics is that we do not have to say what we are talking about. The glory is that the laws, the arguments, and the logic are independent of what \u201cit\u201d is. If we have any other set of objects that obey the same system of axioms as Euclid\u2019s geometry, then if we make new definitions and follow them out with correct logic, all the consequences will be correct, and it makes no difference what the subject was. In nature, however, when we draw a line or establish a line by using a light beam and a theodolite, as we do in surveying, are we measuring a line in the sense of Euclid? No, we are making an approximation; the cross hair has some width, but a geometrical line has no width, and so, whether Euclidean geometry can be used for surveying or not is a physical question, not a mathematical question. However, from an experimental standpoint, not a mathematical standpoint, we need to know whether the laws of Euclid apply to the kind of geometry that we use in measuring land; so we make a hypothesis that it does, and it works pretty well; but it is not precise, because our surveying lines are not really geometrical lines. Whether or not those lines of Euclid, which are really abstract, apply to the lines of experience is a question for experience; it is not a question that can be answered by sheer reason. In the same way, we cannot just call F=ma a definition, deduce everything purely mathematically, and make mechanics a mathematical theory, when mechanics is a description of nature. By establishing suitable postulates it is always possible to make a system of mathematics, just as Euclid did, but we cannot make a mathematics of the world, because sooner or later we have to find out whether the axioms are valid for the objects of nature. Thus we immediately get involved with these complicated and \u201cdirty\u201d objects of nature, but with approximations ever increasing in accuracy. The foregoing considerations show that a true understanding of Newton\u2019s laws requires a discussion of forces, and it is the purpose of this chapter to introduce such a discussion, as a kind of completion of Newton\u2019s laws. We have already studied the definitions of acceleration and related ideas, but now we have to study the properties of force, and this chapter, unlike the previous chapters, will not be very precise, because forces are quite complicated. To begin with a particular force, let us consider the drag on an airplane flying through the air. What is the law for that force? (Surely there is a law for every force, we must have a law!) One can hardly think that the law for that force will be simple. Try to imagine what makes a drag on an airplane flying through the air\u2014the air rushing over the wings, the swirling in the back, the changes going on around the fuselage, and many other complications, and you see that there is not going to be a simple law. On the other hand, it is a remarkable fact that the drag force on an airplane is approximately a constant times the square of the velocity, or F\u2248cv2 . Now what is the status of such a law, is it analogous to F=ma ? Not at all, because in the first place this law is an empirical thing that is obtained roughly by tests in a wind tunnel. You say, \u201cWell F=ma might be empirical too.\u201d That is not the reason that there is a difference. The difference is not that it is empirical, but that, as we understand nature, this law is the result of an enormous complexity of events and is not, fundamentally, a simple thing. If we continue to study it more and more, measuring more and more accurately, the law will continue to become more complicated, not less. In other words, as we study this law of the drag on an airplane more and more closely, we find out that it is \u201cfalser\u201d and \u201cfalser,\u201d and the more deeply we study it, and the more accurately we measure, the more complicated the truth becomes; so in that sense we consider it not to result from a simple, fundamental process, which agrees with our original surmise. For example, if the velocity is extremely low, so low that an ordinary airplane is not flying, as when the airplane is dragged slowly through the air, then the law changes, and the drag friction depends more nearly linearly on the velocity. To take another example, the frictional drag on a ball or a bubble or anything that is moving slowly through a viscous liquid like honey, is proportional to the velocity, but for motion so fast that the fluid swirls around (honey does not but water and air do) then the drag becomes more nearly proportional to the square of the velocity (F=cv2 ), and if the velocity continues to increase, then even this law begins to fail. People who say, \u201cWell the coefficient changes slightly,\u201d are dodging the issue. Second, there are other great complications: can this force on the airplane be divided or analyzed as a force on the wings, a force on the front, and so on? Indeed, this can be done, if we are concerned about the torques here and there, but then we have to get special laws for the force on the wings, and so on. It is an amazing fact that the force on a wing depends upon the other wing: in other words, if we take the airplane apart and put just one wing in the air, then the force is not the same as if the rest of the plane were there. The reason, of course, is that some of the wind that hits the front goes around to the wings and changes the force on the wings. It seems a miracle that there is such a simple, rough, empirical law that can be used in the design of airplanes, but this law is not in the same class as the basic laws of physics, and further study of it will only make it more and more complicated. A study of how the coefficient c depends on the shape of the front of the airplane is, to put it mildly, frustrating. There just is no simple law for determining the coefficient in terms of the shape of the airplane. In contrast, the law of gravitation is simple, and further study only indicates its greater simplicity. We have just discussed two cases of friction, resulting from fast movement in air and slow movement in honey. There is another kind of friction, called dry friction or sliding friction, which occurs when one solid body slides on another. In this case a force is needed to maintain motion. This is called a frictional force, and its origin, also, is a very complicated matter. Both surfaces of contact are irregular, on an atomic level. There are many points of contact where the atoms seem to cling together, and then, as the sliding body is pulled along, the atoms snap apart and vibration ensues; something like that has to happen. Formerly the mechanism of this friction was thought to be very simple, that the surfaces were merely full of irregularities and the friction originated in lifting the slider over the bumps; but this cannot be, for there is no loss of energy in that process, whereas power is in fact consumed. The mechanism of power loss is that as the slider snaps over the bumps, the bumps deform and then generate waves and atomic motions and, after a while, heat, in the two bodies. Now it is very remarkable that again, empirically, this friction can be described approximately by a simple law. This law is that the force needed to overcome friction and to drag one object over another depends upon the normal force (i.e., perpendicular to the surface) between the two surfaces that are in contact. Actually, to a fairly good approximation, the frictional force is proportional to this normal force, and has a more or less constant coefficient; that is, F=\u03bcN, where \u03bc is called the coefficient of friction (Fig. 12\u20131). Although this coefficient is not exactly constant, the formula is a good empirical rule for judging approximately the amount of force that will be needed in certain practical or engineering circumstances. If the normal force or the speed of motion gets too big, the law fails because of the excessive heat generated. It is important to realize that each of these empirical laws has its limitations, beyond which it does not really work. That the formula F=\u03bcN is approximately correct can be demonstrated by a simple experiment. We set up a plane, inclined at a small angle \u03b8 , and place a block of weight W on the plane. We then tilt the plane at a steeper angle, until the block just begins to slide from its own weight. The component of the weight downward along the plane is Wsin\u03b8 , and this must equal the frictional force F when the block is sliding uniformly. The component of the weight normal to the plane is Wcos\u03b8 , and this is the normal force N . With these values, the formula becomes Wsin\u03b8=\u03bcWcos\u03b8 , from which we get \u03bc= sin\u03b8/cos\u03b8= tan\u03b8 . If this law were exactly true, an object would start to slide at some definite inclination. If the same block is loaded by putting extra weight on it, then, although W is increased, all the forces in the formula are increased in the same proportion, and W cancels out. If \u03bc stays constant, the loaded block will slide again at the same slope. When the angle \u03b8 is determined by trial with the original weight, it is found that with the greater weight the block will slide at about the same angle. This will be true even when one weight is many times as great as the other, and so we conclude that the coefficient of friction is independent of the weight. In performing this experiment it is noticeable that when the plane is tilted at about the correct angle \u03b8 , the block does not slide steadily but in a halting fashion. At one place it may stop, at another it may move with acceleration. This behavior indicates that the coefficient of friction is only roughly a constant, and varies from place to place along the plane. The same erratic behavior is observed whether the block is loaded or not. Such variations are caused by different degrees of smoothness or hardness of the plane, and perhaps dirt, oxides, or other foreign matter. The tables that list purported values of \u03bc for \u201csteel on steel,\u201d \u201ccopper on copper,\u201d and the like, are all false, because they ignore the factors mentioned above, which really determine \u03bc . The friction is never due to \u201ccopper on copper,\u201d etc., but to the impurities clinging to the copper. In experiments of the type described above, the friction is nearly independent of the velocity. Many people believe that the friction to be overcome to get something started (static friction) exceeds the force required to keep it sliding (sliding friction), but with dry metals it is very hard to show any difference. The opinion probably arises from experiences where small bits of oil or lubricant are present, or where blocks, for example, are supported by springs or other flexible supports so that they appear to bind. It is quite difficult to do accurate quantitative experiments in friction, and the laws of friction are still not analyzed very well, in spite of the enormous engineering value of an accurate analysis. Although the law F=\u03bcN is fairly accurate once the surfaces are standardized, the reason for this form of the law is not really understood. To show that the coefficient \u03bc is nearly independent of velocity requires some delicate experimentation, because the apparent friction is much reduced if the lower surface vibrates very fast. When the experiment is done at very high speed, care must be taken that the objects do not vibrate relative to one another, since apparent decreases of the friction at high speed are often due to vibrations. At any rate, this friction law is another of those semiempirical laws that are not thoroughly understood, and in view of all the work that has been done it is surprising that more understanding of this phenomenon has not come about. At the present time, in fact, it is impossible even to estimate the coefficient of friction between two substances. It was pointed out above that attempts to measure \u03bc by sliding pure substances such as copper on copper will lead to spurious results, because the surfaces in contact are not pure copper, but are mixtures of oxides and other impurities. If we try to get absolutely pure copper, if we clean and polish the surfaces, outgas the materials in a vacuum, and take every conceivable precaution, we still do not get \u03bc . For if we tilt the apparatus even to a vertical position, the slider will not fall off\u2014the two pieces of copper stick together! The coefficient \u03bc , which is ordinarily less than unity for reasonably hard surfaces, becomes several times unity! The reason for this unexpected behavior is that when the atoms in contact are all of the same kind, there is no way for the atoms to \u201cknow\u201d that they are in different pieces of copper. When there are other atoms, in the oxides and greases and more complicated thin surface layers of contaminants in between, the atoms \u201cknow\u201d when they are not on the same part. When we consider that it is forces between atoms that hold the copper together as a solid, it should become clear that it is impossible to get the right coefficient of friction for pure metals. The same phenomenon can be observed in a simple home-made experiment with a flat glass plate and a glass tumbler. If the tumbler is placed on the plate and pulled along with a loop of string, it slides fairly well and one can feel the coefficient of friction; it is a little irregular, but it is a coefficient. If we now wet the glass plate and the bottom of the tumbler and pull again, we find that it binds, and if we look closely we shall find scratches, because the water is able to lift the grease and the other contaminants off the surface, and then we really have a glass-to-glass contact; this contact is so good that it holds tight and resists separation so much that the glass is torn apart; that is, it makes scratches. We shall next discuss the characteristics of molecular forces. These are forces between the atoms, and are the ultimate origin of friction. Molecular forces have never been satisfactorily explained on a basis of classical physics; it takes quantum mechanics to understand them fully. Empirically, however, the force between atoms is illustrated schematically in Fig. 12\u20132, where the force F between two atoms is plotted as a function of the distance r between them. There are different cases: in the water molecule, for example, the negative charges sit more on the oxygen, and the mean positions of the negative charges and of the positive charges are not at the same point; consequently, another molecule nearby feels a relatively large force, which is called a dipole-dipole force. However, for many systems the charges are very much better balanced, in particular for oxygen gas, which is perfectly symmetrical. In this case, although the minus charges and the plus charges are dispersed over the molecule, the distribution is such that the center of the minus charges and the center of the plus charges coincide. A molecule where the centers do not coincide is called a polar molecule, and charge times the separation between centers is called the dipole moment. A nonpolar molecule is one in which the centers of the charges coincide. For all nonpolar molecules, in which all the electrical forces are neutralized, it nevertheless turns out that the force at very large distances is an attraction and varies inversely as the seventh power of the distance, or F=k/ r 7 , where k is a constant that depends on the molecules. Why this is we shall learn only when we learn quantum mechanics. When there are dipoles the forces are greater. When atoms or molecules get too close they repel with a very large repulsion; that is what keeps us from falling through the floor! These molecular forces can be demonstrated in a fairly direct way: one of these is the friction experiment with a sliding glass tumbler; another is to take two very carefully ground and lapped surfaces which are very accurately flat, so that the surfaces can be brought very close together. An example of such surfaces is the Johansson blocks that are used in machine shops as standards for making accurate length measurements. If one such block is slid over another very carefully and the upper one is lifted, the other one will adhere and also be lifted by the molecular forces, exemplifying the direct attraction between the atoms on one block for the atoms on the other block. Nevertheless these molecular forces of attraction are still not fundamental in the sense that gravitation is fundamental; they are due to the vastly complex interactions of all the electrons and nuclei in one molecule with all the electrons and nuclei in another. Any simple-looking formula we get represents a summation of complications, so we still have not got the fundamental phenomena. Since the molecular forces attract at large distances and repel at short distances, as shown in Fig. 12\u20132, we can make up solids in which all the atoms are held together by their attractions and held apart by the repulsion that sets in when they are too close together. At a certain distance d (where the graph in Fig. 12\u20132 crosses the axis) the forces are zero, which means that they are all balanced, so that the molecules stay that distance apart from one another. If the molecules are pushed closer together than the distance d they all show a repulsion, represented by the portion of the graph above the r -axis. To push the molecules only slightly closer together requires a great force, because the molecular repulsion rapidly becomes very great at distances less than d . If the molecules are pulled slightly apart there is a slight attraction, which increases as the separation increases. If they are pulled sufficiently hard, they will separate permanently\u2014the bond is broken. If the molecules are pushed only a very small distance closer, or pulled only a very small distance farther than d , the corresponding distance along the curve of Fig. 12\u20132 is also very small, and can then be approximated by a straight line. Therefore, in many circumstances, if the displacement is not too great the force is proportional to the displacement. This principle is known as Hooke\u2019s law, or the law of elasticity, which says that the force in a body which tries to restore the body to its original condition when it is distorted is proportional to the distortion. This law, of course, holds true only if the distortion is relatively small; when it gets too large the body will be torn apart or crushed, depending on the kind of distortion. The amount of force for which Hooke\u2019s law is valid depends upon the material; for instance, for dough or putty the force is very small, but for steel it is relatively large. Hooke\u2019s law can be nicely demonstrated with a long coil spring, made of steel and suspended vertically. A suitable weight hung on the lower end of the spring produces a tiny twist throughout the length of the wire, which results in a small vertical deflection in each turn and adds up to a large displacement if there are many turns. If the total elongation produced, say, by a 100 -gram weight, is measured, it is found that additional weights of 100 grams will each produce an additional elongation that is very nearly equal to the stretch that was measured for the first 100 grams. This constant ratio of force to displacement begins to change when the spring is overloaded, i.e., Hooke\u2019s law no longer holds. We shall now discuss the only remaining forces that are fundamental. We call them fundamental in the sense that their laws are fundamentally simple. We shall first discuss electrical force. Objects carry electrical charges which consist simply of electrons or protons. If any two bodies are electrically charged, there is an electrical force between them, and if the magnitudes of the charges are q 1 and q 2 , respectively, the force varies inversely as the square of the distance between the charges, or F=(const) q 1 q 2 / r 2 . For unlike charges, this law is like the law of gravitation, but for like charges the force is repulsive and the sign (direction) is reversed. The charges q 1 and q 2 can be intrinsically either positive or negative, and in any specific application of the formula the direction of the force will come out right if the q \u2019s are given the proper plus or minus sign; the force is directed along the line between the two charges. The constant in the formula depends, of course, upon what units are used for the force, the charge, and the distance. In current practice the charge is measured in coulombs, the distance in meters, and the force in newtons. Then, in order to get the force to come out properly in newtons, the constant (which for historical reasons is written 1/4\u03c0 \u03f5 0 ) takes the numerical value \u03f5 0 =8.854\u00d7 10 \u221212 coul 2 /newton\u22c5 m 2 2 or 1/4\u03c0 \u03f5 0 =8.99\u00d7 10 9 N\u22c5 m 2 / coul 2 . 2 Thus the force law for static charges is F= q 1 q 2 r/4\u03c0 \u03f5 0 r 3 . (12.2) In nature, the most important charge of all is the charge on a single electron, which is 1.60\u00d7 10 \u221219 coulomb. In working with electrical forces between fundamental particles rather than with large charges, many people prefer the combination ( q el ) 2 /4\u03c0 \u03f5 0 , in which q el is defined as the charge on an electron. This combination occurs frequently, and to simplify calculations it has been defined by the symbol e 2 ; its numerical value in the mks system of units turns out to be (1.52\u00d7 10 \u221214 ) 2 . The advantage of using the constant in this form is that the force between two electrons in newtons can then be written simply as e 2 / r 2 , with r in meters, without all the individual constants. Electrical forces are much more complicated than this simple formula indicates, since the formula gives the force between two objects only when the objects are standing still. We shall consider the more general case shortly. In the analysis of forces of the more fundamental kinds (not such forces as friction, but the electrical force or the gravitational force), an interesting and very important concept has been developed. Since at first sight the forces are very much more complicated than is indicated by the inverse-square laws and these laws hold true only when the interacting bodies are standing still, an improved method is needed to deal with the very complex forces that ensue when the bodies start to move in a complicated way. Experience has shown that an approach known as the concept of a \u201cfield\u201d is of great utility for the analysis of forces of this type. To illustrate the idea for, say, electrical force, suppose we have two electrical charges, q 1 and q 2 , located at points P and R respectively. Then the force between the charges is given by F= q 1 q 2 r/4\u03c0 \u03f5 0 r 3 . (12.3) To analyze this force by means of the field concept, we say that the charge q 1 at P produces a \u201ccondition\u201d at R , such that when the charge q 2 is placed at R it \u201cfeels\u201d the force. This is one way, strange perhaps, of describing it; we say that the force F on q 2 at R can be written in two parts. It is q 2 multiplied by a quantity E that would be there whether q 2 were there or not (provided we keep all the other charges in their right places). E is the \u201ccondition\u201d produced by q 1 , we say, and F is the response of q 2 to E . E is called an electric field, and it is a vector. The formula for the electric field E that is produced at R by a charge q 1 at P is the charge q 1 times the constant 1/4\u03c0 \u03f5 0 divided by r 2 ( r is the distance from P to R ), and it is acting in the direction of the radius vector (the radius vector r divided by its own length). The expression for E is thus E= q 1 r/4\u03c0 \u03f5 0 r 3 . (12.4) We then write F= q 2 E, (12.5) which expresses the force, the field, and the charge in the field. What is the point of all this? The point is to divide the analysis into two parts. One part says that something produces a field. The other part says that something is acted on by the field. By allowing us to look at the two parts independently, this separation of the analysis simplifies the calculation of a problem in many situations. If many charges are present, we first work out the total electric field produced at R by all the charges, and then, knowing the charge that is placed at R , we find the force on it. In the case of gravitation, we can do exactly the same thing. In this case, where the force F=\u2212G m 1 m 2 r/ r 3 , we can make an analogous analysis, as follows: the force on a body in a gravitational field is the mass of that body times the field C . The force on m 2 is the mass m 2 times the field C produced by m 1 ; that is, F= m 2 C . Then the field C produced by a body of mass m 1 is C=\u2212G m 1 r/ r 3 and it is directed radially, as in the electrical case. In spite of how it might at first seem, this separation of one part from another is not a triviality. It would be trivial, just another way of writing the same thing, if the laws of force were simple, but the laws of force are so complicated that it turns out that the fields have a reality that is almost independent of the objects which create them. One can do something like shake a charge and produce an effect, a field, at a distance; if one then stops moving the charge, the field keeps track of all the past, because the interaction between two particles is not instantaneous. It is desirable to have some way to remember what happened previously. If the force upon some charge depends upon where another charge was yesterday, which it does, then we need machinery to keep track of what went on yesterday, and that is the character of a field. So when the forces get more complicated, the field becomes more and more real, and this technique becomes less and less of an artificial separation. In analyzing forces by the use of fields, we need two kinds of laws pertaining to fields. The first is the response to a field, and that gives the equations of motion. For example, the law of response of a mass to a gravitational field is that the force is equal to the mass times the gravitational field; or, if there is also a charge on the body, the response of the charge to the electric field equals the charge times the electric field. The second part of the analysis of nature in these situations is to formulate the laws which determine the strength of the field and how it is produced. These laws are sometimes called the field equations. We shall learn more about them in due time, but shall write down a few things about them now. First, the most remarkable fact of all, which is true exactly and which can be easily understood, is that the total electric field produced by a number of sources is the vector sum of the electric fields produced by the first source, the second source, and so on. In other words, if we have numerous charges making a field, and if all by itself one of them would make the field E 1 , another would make the field E 2 , and so on, then we merely add the vectors to get the total field. This principle can be expressed as E= E 1 + E 2 + E 3 +\u22ef (12.6) or, in view of the definition given above, E= \u2211 i q i r i 4\u03c0 \u03f5 0 r 3 i . (12.7) Can the same methods be applied to gravitation? The force between two masses m 1 and m 2 was expressed by Newton as F=\u2212G m 1 m 2 r/ r 3 . But according to the field concept, we may say that m 1 creates a field C in all the surrounding space, such that the force on m 2 is given by F= m 2 C. (12.8) By complete analogy with the electrical case, C i =\u2212G m i r i / r 3 i (12.9) and the gravitational field produced by several masses is C= C 1 + C 2 + C 3 +\u22ef (12.10) In Chapter 9, in working out a case of planetary motion, we used this principle in essence. We simply added all the force vectors to get the resultant force on a planet. If we divide out the mass of the planet in question, we get Eq. (12.10). Equations (12.6) and (12.10) express what is known as the principle of superposition of fields. This principle states that the total field due to all the sources is the sum of the fields due to each source. So far as we know today, for electricity this is an absolutely guaranteed law, which is true even when the force law is complicated because of the motions of the charges. There are apparent violations, but more careful analysis has always shown these to be due to the overlooking of certain moving charges. However, although the principle of superposition applies exactly for electrical forces, it is not exact for gravity if the field is too strong, and Newton\u2019s equation (12.10) is only approximate, according to Einstein\u2019s gravitational theory. Closely related to electrical force is another kind, called magnetic force, and this too is analyzed in terms of a field. Some of the qualitative relations between electrical and magnetic forces can be illustrated by an experiment with an electron-ray tube (Fig. 12\u20133). At one end of such a tube is a source that emits a stream of electrons. Within the tube are arrangements for accelerating the electrons to a high speed and sending some of them in a narrow beam to a fluorescent screen at the other end of the tube. A spot of light glows in the center of the screen where the electrons strike, and this enables us to trace the electron path. On the way to the screen the electron beam passes through a narrow space between a pair of parallel metal plates, which are arranged, say, horizontally. A voltage can be applied across the plates, so that either plate can be made negative at will. When such a voltage is present, there is an electric field between the plates. The first part of the experiment is to apply a negative voltage to the lower plate, which means that extra electrons have been placed on the lower plate. Since like charges repel, the light spot on the screen instantly shifts upward. (We could also say this in another way\u2014that the electrons \u201cfelt\u201d the field, and responded by deflecting upward.) We next reverse the voltage, making the upper plate negative. The light spot on the screen now jumps below the center, showing that the electrons in the beam were repelled by those in the plate above them. (Or we could say again that the electrons had \u201cresponded\u201d to the field, which is now in the reverse direction.) The second part of the experiment is to disconnect the voltage from the plates and test the effect of a magnetic field on the electron beam. This is done by means of a horseshoe magnet, whose poles are far enough apart to more or less straddle the tube. Suppose we hold the magnet below the tube in the same orientation as the letter U, with its poles up and part of the tube in between. We note that the light spot is deflected, say, upward, as the magnet approaches the tube from below. So it appears that the magnet repels the electron beam. However, it is not that simple, for if we invert the magnet without reversing the poles side-for-side, and now approach the tube from above, the spot still moves upward, so the electron beam is not repelled; instead, it appears to be attracted this time. Now we start again, restoring the magnet to its original U orientation and holding it below the tube, as before. Yes, the spot is still deflected upward; but now turn the magnet 180 degrees around a vertical axis, so that it is still in the U position but the poles are reversed side-for-side. Behold, the spot now jumps downward, and stays down, even if we invert the magnet and approach from above, as before. To understand this peculiar behavior, we have to have a new combination of forces. We explain it thus: Across the magnet from one pole to the other there is a magnetic field. This field has a direction which is always away from one particular pole (which we could mark) and toward the other. Inverting the magnet did not change the direction of the field, but reversing the poles side-for-side did reverse its direction. For example, if the electron velocity were horizontal in the x -direction and the magnetic field were also horizontal but in the y -direction, the magnetic force on the moving electrons would be in the z -direction, i.e., up or down, depending on whether the field was in the positive or negative y -direction. Although we shall not at the present time give the correct law of force between charges moving in an arbitrary manner, one relative to the other, because it is too complicated, we shall give one aspect of it: the complete law of the forces if the fields are known. The force on a charged object depends upon its motion; if, when the object is standing still at a given place, there is some force, this is taken to be proportional to the charge, the coefficient being what we call the electric field. When the object moves the force may be different, and the correction, the new \u201cpiece\u201d of force, turns out to be dependent exactly linearly on the velocity, but at right angles to v and to another vector quantity which we call the magnetic induction B . If the components of the electric field E and the magnetic induction B are, respectively, ( E x , E y , E z ) and ( B x , B y , B z ) , and if the velocity v has the components ( v x , v y , v z ) , then the total electric and magnetic force on a moving charge q has the components F x F y F z =q( E x =q( E y =q( E z + v y + v z + v x B z B x B y \u2212 v z \u2212 v x \u2212 v y B y B z B x ), ), ). (12.11) If, for instance, the only component of the magnetic field were B y and the only component of the velocity were v x , then the only term left in the magnetic force would be a force in the z -direction, at right angles to both B and v . The next kind of force we shall discuss might be called a pseudo force. In Chapter 11 we discussed the relationship between two people, Joe and Moe, who use different coordinate systems. Let us suppose that the positions of a particle as measured by Joe are x and by Moe are x \u2032 ; then the laws are as follows: x= x \u2032 +s,y= y \u2032 ,z= z \u2032 , \u2032 \u2032 \u2032 where s is the displacement of Moe\u2019s system relative to Joe\u2019s. If we suppose that the laws of motion are correct for Joe, how do they look for Moe? We find first, that dx/dt=d x \u2032 /dt+ds/dt. \u2032 Previously, we considered the case where s was constant, and we found that s made no difference in the laws of motion, since ds/dt=0 ; ultimately, therefore, the laws of physics were the same in both systems. But another case we can take is that s=ut , where u is a uniform velocity in a straight line. Then s is not constant, and ds/dt is not zero, but is u , a constant. However, the acceleration d 2 x/d t 2 is still the same as d 2 x \u2032 /d t 2 , because du/dt=0 . This proves the law that we used in Chapter 10, namely, that if we move in a straight line with uniform velocity the laws of physics will look the same to us as when we are standing still. That is the Galilean transformation. But we wish to discuss the interesting case where s is still more complicated, say s=a t 2 /2 . Then ds/dt=at and d 2 s/d t 2 =a , a uniform acceleration; or in a still more complicated case, the acceleration might be a function of time. This means that although the laws of motion from the point of view of Joe would look like m d 2 x d t 2 = F x , 2 the laws of motion as looked upon by Moe would appear as m d 2 x \u2032 d t 2 = F x \u2032 = F x \u2212ma. 2 That is, since Moe\u2019s coordinate system is accelerating with respect to Joe\u2019s, the extra term ma comes in, and Moe will have to correct his forces by that amount in order to get Newton\u2019s laws to work. In other words, here is an apparent, mysterious new force of unknown origin which arises, of course, because Moe has the wrong coordinate system. This is an example of a pseudo force; other examples occur in coordinate systems that are rotating. Another example of pseudo force is what is often called \u201ccentrifugal force.\u201d An observer in a rotating coordinate system, e.g., in a rotating box, will find mysterious forces, not accounted for by any known origin of force, throwing things outward toward the walls. These forces are due merely to the fact that the observer does not have Newton\u2019s coordinate system, which is the simplest coordinate system. Pseudo force can be illustrated by an interesting experiment in which we push a jar of water along a table, with acceleration. Gravity, of course, acts downward on the water, but because of the horizontal acceleration there is also a pseudo force acting horizontally and in a direction opposite to the acceleration. The resultant of gravity and pseudo force makes an angle with the vertical, and during the acceleration the surface of the water will be perpendicular to the resultant force, i.e., inclined at an angle with the table, with the water standing higher in the rearward side of the jar. When the push on the jar stops and the jar decelerates because of friction, the pseudo force is reversed, and the water stands higher in the forward side of the jar (Fig. 12\u20134). One very important feature of pseudo forces is that they are always proportional to the masses; the same is true of gravity. The possibility exists, therefore, that gravity itself is a pseudo force. Is it not possible that perhaps gravitation is due simply to the fact that we do not have the right coordinate system? After all, we can always get a force proportional to the mass if we imagine that a body is accelerating. For instance, a man shut up in a box that is standing still on the earth finds himself held to the floor of the box with a certain force that is proportional to his mass. But if there were no earth at all and the box were standing still, the man inside would float in space. On the other hand, if there were no earth at all and something were pulling the box along with an acceleration g , then the man in the box, analyzing physics, would find a pseudo force which would pull him to the floor, just as gravity does. Einstein put forward the famous hypothesis that accelerations give an imitation of gravitation, that the forces of acceleration (the pseudo forces) cannot be distinguished from those of gravity; it is not possible to tell how much of a given force is gravity and how much is pseudo force. It might seem all right to consider gravity to be a pseudo force, to say that we are all held down because we are accelerating upward, but how about the people in Madagascar, on the other side of the earth\u2014are they accelerating too? Einstein found that gravity could be considered a pseudo force only at one point at a time, and was led by his considerations to suggest that the geometry of the world is more complicated than ordinary Euclidean geometry. The present discussion is only qualitative, and does not pretend to convey anything more than the general idea. To give a rough idea of how gravitation could be the result of pseudo forces, we present an illustration which is purely geometrical and does not represent the real situation. Suppose that we all lived in two dimensions, and knew nothing of a third. We think we are on a plane, but suppose we are really on the surface of a sphere. And suppose that we shoot an object along the ground, with no forces on it. Where will it go? It will appear to go in a straight line, but it has to remain on the surface of a sphere, where the shortest distance between two points is along a great circle; so it goes along a great circle. If we shoot another object similarly, but in another direction, it goes along another great circle. Because we think we are on a plane, we expect that these two bodies will continue to diverge linearly with time, but careful observation will show that if they go far enough they move closer together again, as though they were attracting each other. But they are not attracting each other\u2014there is just something \u201cweird\u201d about this geometry. This particular illustration does not describe correctly the way in which Einstein\u2019s geometry is \u201cweird,\u201d but it illustrates that if we distort the geometry sufficiently it is possible that all gravitation is related in some way to pseudo forces; that is the general idea of the Einsteinian theory of gravitation. We conclude this chapter with a brief discussion of the only other known forces, which are called nuclear forces. These forces are within the nuclei of atoms, and although they are much discussed, no one has ever calculated the force between two nuclei, and indeed at present there is no known law for nuclear forces. These forces have a very tiny range which is just about the same as the size of the nucleus, perhaps 10 \u221213 centimeter. With particles so small and at such a tiny distance, only the quantum-mechanical laws are valid, not the Newtonian laws. In nuclear analysis we no longer think in terms of forces, and in fact we can replace the force concept with a concept of the energy of interaction of two particles, a subject that will be discussed later. Any formula that can be written for nuclear forces is a rather crude approximation which omits many complications; one might be somewhat as follows: forces within a nucleus do not vary inversely as the square of the distance, but die off exponentially over a certain distance r , as expressed by F=(1/ r 2 )exp(\u2212r/ r 0 ) , where the distance r 0 is of the order of 10 \u221213 centimeter. In other words, the forces disappear as soon as the particles are any great distance apart, although they are very strong within the 10 \u221213 centimeter range. So far as they are understood today, the laws of nuclear force are very complex; we do not understand them in any simple way, and the whole problem of analyzing the fundamental machinery behind nuclear forces is unsolved. Attempts at a solution have led to the discovery of numerous strange particles, the \u03c0 -mesons, for example, but the origin of these forces remains obscure."
    },
    {
        "input": "Probability Amplitudes",
        "output": "When Schr\u00f6dinger first discovered the correct laws of quantum mechanics, he wrote an equation which described the amplitude to find a particle in various places. This equation was very similar to the equations that were already known to classical physicists\u2014equations that they had used in describing the motion of air in a sound wave, the transmission of light, and so on. So most of the time at the beginning of quantum mechanics was spent in solving this equation. But at the same time an understanding was being developed, particularly by Born and Dirac, of the basically new physical ideas behind quantum mechanics. As quantum mechanics developed further, it turned out that there were a large number of things which were not directly encompassed in the Schr\u00f6dinger equation\u2014such as the spin of the electron, and various relativistic phenomena. Traditionally, all courses in quantum mechanics have begun in the same way, retracing the path followed in the historical development of the subject. One first learns a great deal about classical mechanics so that he will be able to understand how to solve the Schr\u00f6dinger equation. Then he spends a long time working out various solutions. Only after a detailed study of this equation does he get to the \u201cadvanced\u201d subject of the electron\u2019s spin. We had also originally considered that the right way to conclude these lectures on physics was to show how to solve the equations of classical physics in complicated situations\u2014such as the description of sound waves in enclosed regions, modes of electromagnetic radiation in cylindrical cavities, and so on. That was the original plan for this course. However, we have decided to abandon that plan and to give instead an introduction to the quantum mechanics. We have come to the conclusion that what are usually called the advanced parts of quantum mechanics are, in fact, quite simple. The mathematics that is involved is particularly simple, involving simple algebraic operations and no differential equations or at most only very simple ones. The only problem is that we must jump the gap of no longer being able to describe the behavior in detail of particles in space. So this is what we are going to try to do: to tell you about what conventionally would be called the \u201cadvanced\u201d parts of quantum mechanics. But they are, we assure you, by all odds the simplest parts\u2014in a deep sense of the word\u2014as well as the most basic parts. This is frankly a pedagogical experiment; it has never been done before, as far as we know. In this subject we have, of course, the difficulty that the quantum mechanical behavior of things is quite strange. Nobody has an everyday experience to lean on to get a rough, intuitive idea of what will happen. So there are two ways of presenting the subject: We could either describe what can happen in a rather rough physical way, telling you more or less what happens without giving the precise laws of everything; or we could, on the other hand, give the precise laws in their abstract form. But, then because of the abstractions, you wouldn\u2019t know what they were all about, physically. The latter method is unsatisfactory because it is completely abstract, and the first way leaves an uncomfortable feeling because one doesn\u2019t know exactly what is true and what is false. We are not sure how to overcome this difficulty. You will notice, in fact, that Chapters 1 and 2 showed this problem. The first chapter was relatively precise; but the second chapter was a rough description of the characteristics of different phenomena. Here, we will try to find a happy medium between the two extremes. We will begin in this chapter by dealing with some general quantum mechanical ideas. Some of the statements will be quite precise, others only partially precise. It will be hard to tell you as we go along which is which, but by the time you have finished the rest of the book, you will understand in looking back which parts hold up and which parts were only explained roughly. The chapters which follow this one will not be so imprecise. In fact, one of the reasons we have tried carefully to be precise in the succeeding chapters is so that we can show you one of the most beautiful things about quantum mechanics\u2014how much can be deduced from so little. We begin by discussing again the superposition of probability amplitudes. As an example we will refer to the experiment described in Chapter 1, and shown again here in Fig. 3\u20131. There is a source s of particles, say electrons; then there is a wall with two slits in it; after the wall, there is a detector located at some position x . We ask for the probability that a particle will be found at x . Our first general principle in quantum mechanics is that the probability that a particle will arrive at x , when let out at the source s , can be represented quantitatively by the absolute square of a complex number called a probability amplitude\u2014in this case, the \u201camplitude that a particle from s will arrive at x .\u201d We will use such amplitudes so frequently that we will use a shorthand notation\u2014invented by Dirac and generally used in quantum mechanics\u2014to represent this idea. We write the probability amplitude this way: \u27e8Particle arrives at x|particle leaves s\u27e9. In other words, the two brackets \u27e8\u27e9 are a sign equivalent to \u201cthe amplitude that\u201d; the expression at the right of the vertical line always gives the starting condition, and the one at the left, the final condition. Sometimes it will also be convenient to abbreviate still more and describe the initial and final conditions by single letters. For example, we may on occasion write the amplitude (3.1) as \u27e8x|s\u27e9. We want to emphasize that such an amplitude is, of course, just a single number\u2014a complex number. We have already seen in the discussion of Chapter 1 that when there are two ways for the particle to reach the detector, the resulting probability is not the sum of the two probabilities, but must be written as the absolute square of the sum of two amplitudes. We had that the probability that an electron arrives at the detector when both paths are open is P12=|\u03d51+\u03d52|2. We wish now to put this result in terms of our new notation. First, however, we want to state our second general principle of quantum mechanics: When a particle can reach a given state by two possible routes, the total amplitude for the process is the sum of the amplitudes for the two routes considered separately. In our new notation we write that \u27e8x|s\u27e9both holes open=\u27e8x|s\u27e9through 1+\u27e8x|s\u27e9through 2. Incidentally, we are going to suppose that the holes 1 and 2 are small enough that when we say an electron goes through the hole, we don\u2019t have to discuss which part of the hole. We could, of course, split each hole into pieces with a certain amplitude that the electron goes to the top of the hole and the bottom of the hole and so on. We will suppose that the hole is small enough so that we don\u2019t have to worry about this detail. That is part of the roughness involved; the matter can be made more precise, but we don\u2019t want to do so at this stage. Now we want to write out in more detail what we can say about the amplitude for the process in which the electron reaches the detector at x by way of hole 1 . We can do that by using our third general principle: When a particle goes by some particular route the amplitude for that route can be written as the product of the amplitude to go part way with the amplitude to go the rest of the way. For the setup of Fig. 3\u20131 the amplitude to go from s to x by way of hole 1 is equal to the amplitude to go from s to 1 , multiplied by the amplitude to go from 1 to x . \u27e8x|s \u27e9 via 1 =\u27e8x|1\u27e9\u27e81|s\u27e9. (3.5) Again this result is not completely precise. We should also include a factor for the amplitude that the electron will get through the hole at 1 ; but in the present case it is a simple hole, and we will take this factor to be unity. You will note that Eq. (3.5) appears to be written in reverse order. It is to be read from right to left: The electron goes from s to 1 and then from 1 to x . In summary, if events occur in succession\u2014that is, if you can analyze one of the routes of the particle by saying it does this, then it does this, then it does that\u2014the resultant amplitude for that route is calculated by multiplying in succession the amplitude for each of the successive events. Using this law we can rewrite Eq. (3.4) as \u27e8x|s \u27e9 both =\u27e8x|1\u27e9\u27e81|s\u27e9+\u27e8x|2\u27e9\u27e82|s\u27e9. \u27e8 | \u27e9 \u27e8 | \u27e9 \u27e8 | \u27e9 \u27e8 | \u27e9 \u27e8 | \u27e9 Now we wish to show that just using these principles we can calculate a much more complicated problem like the one shown in Fig. 3\u20132. Here we have two walls, one with two holes, 1 and 2 , and another which has three holes, a , b , and c . Behind the second wall there is a detector at x , and we want to know the amplitude for a particle to arrive there. Well, one way you can find this is by calculating the superposition, or interference, of the waves that go through; but you can also do it by saying that there are six possible routes and superposing an amplitude for each. The electron can go through hole 1 , then through hole a , and then to x ; or it could go through hole 1 , then through hole b , and then to x ; and so on. According to our second principle, the amplitudes for alternative routes add, so we should be able to write the amplitude from s to x as a sum of six separate amplitudes. On the other hand, using the third principle, each of these separate amplitudes can be written as a product of three amplitudes. For example, one of them is the amplitude for s to 1 , times the amplitude for 1 to a , times the amplitude for a to x . Using our shorthand notation, we can write the complete amplitude to go from s to x as \u27e8x|s\u27e9 =\u27e8x|a\u27e9\u27e8a|1\u27e9\u27e81|s\u27e9+\u27e8x|b\u27e9\u27e8b|1\u27e9\u27e81|s\u27e9+ \u22ef+\u27e8x|c\u27e9\u27e8c|2\u27e9\u27e82|s\u27e9. We can save writing by using the summation notation \u27e8x|s\u27e9= \u2211 i=1,2 \u03b1=a,b,c \u27e8x|\u03b1\u27e9\u27e8\u03b1|i\u27e9\u27e8i|s\u27e9. (3.6) In order to make any calculations using these methods, it is, naturally, necessary to know the amplitude to get from one place to another. We will give a rough idea of a typical amplitude. It leaves out certain things like the polarization of light or the spin of the electron, but aside from such features it is quite accurate. We give it so that you can solve problems involving various combinations of slits. Suppose a particle with a definite energy is going in empty space from a location r 1 to a location r 2 . In other words, it is a free particle with no forces on it. Except for a numerical factor in front, the amplitude to go from r 1 to r 2 is \u27e8 r 2 | r 1 \u27e9= e ip r 12 /\u210f r 12 , (3.7) where r 12 =| r 2 \u2212 r 1 | , and p is the momentum which is related to the energy E by the relativistic equation p 2 c 2 = E 2 \u2212( m 0 c 2 ) 2 , 2 or the nonrelativistic equation p 2 2m =Kinetic energy. 2 Equation (3.7) says in effect that the particle has wavelike properties, the amplitude propagating as a wave with a wave number equal to the momentum divided by \u210f . In the most general case, the amplitude and the corresponding probability will also involve the time. For most of these initial discussions we will suppose that the source always emits the particles with a given energy so we will not need to worry about the time. But we could, in the general case, be interested in some other questions. Suppose that a particle is liberated at a certain place P at a certain time, and you would like to know the amplitude for it to arrive at some location, say r , at some later time. This could be represented symbolically as the amplitude \u27e8r,t= t 1 |P,t=0\u27e9 . Clearly, this will depend upon both r and t . You will get different results if you put the detector in different places and measure at different times. This function of r and t , in general, satisfies a differential equation which is a wave equation. For example, in a nonrelativistic case it is the Schr\u00f6dinger equation. One has then a wave equation analogous to the equation for electromagnetic waves or waves of sound in a gas. However, it must be emphasized that the wave function that satisfies the equation is not like a real wave in space; one cannot picture any kind of reality to this wave as one does for a sound wave. Although one may be tempted to think in terms of \u201cparticle waves\u201d when dealing with one particle, it is not a good idea, for if there are, say, two particles, the amplitude to find one at r 1 and the other at r 2 is not a simple wave in three-dimensional space, but depends on the six space variables r 1 and r 2 . If we are, for example, dealing with two (or more) particles, we will need the following additional principle: Provided that the two particles do not interact, the amplitude that one particle will do one thing and the other one something else is the product of the two amplitudes that the two particles would do the two things separately. For example, if \u27e8a| s 1 \u27e9 is the amplitude for particle 1 to go from s 1 to a , and \u27e8b| s 2 \u27e9 is the amplitude for particle 2 to go from s 2 to b , the amplitude that both things will happen together is \u27e8a| s 1 \u27e9\u27e8b| s 2 \u27e9. \u27e8 | \u27e9 \u27e8 b | \u27e9 There is one more point to emphasize. Suppose that we didn\u2019t know where the particles in Fig. 3\u20132 come from before arriving at holes 1 and 2 of the first wall. We can still make a prediction of what will happen beyond the wall (for example, the amplitude to arrive at x ) provided that we are given two numbers: the amplitude to have arrived at 1 and the amplitude to have arrived at 2 . In other words, because of the fact that the amplitude for successive events multiplies, as shown in Eq. (3.6), all you need to know to continue the analysis is two numbers\u2014in this particular case \u27e81|s\u27e9 and \u27e82|s\u27e9 . These two complex numbers are enough to predict all the future. That is what really makes quantum mechanics easy. It turns out that in later chapters we are going to do just such a thing when we specify a starting condition in terms of two (or a few) numbers. Of course, these numbers depend upon where the source is located and possibly other details about the apparatus, but given the two numbers, we do not need to know any more about such details. Now we would like to consider a matter which was discussed in some detail in Chapter 1. This time we will do it with the full glory of the amplitude idea to show you how it works out. We take the same experiment shown in Fig. 3\u20131, but now with the addition of a light source behind the two holes, as shown in Fig. 3\u20133. In Chapter 1, we discovered the following interesting result. If we looked behind slit 1 and saw a photon scattered from there, then the distribution obtained for the electrons at x in coincidence with these photons was the same as though slit 2 were closed. The total distribution for electrons that had been \u201cseen\u201d at either slit 1 or slit 2 was the sum of the separate distributions and was completely different from the distribution with the light turned off. This was true at least if we used light of short enough wavelength. If the wavelength was made longer so we could not be sure at which hole the scattering had occurred, the distribution became more like the one with the light turned off. Let\u2019s examine what is happening by using our new notation and the principles of combining amplitudes. To simplify the writing, we can again let \u03d5 1 stand for the amplitude that the electron will arrive at x by way of hole 1 , that is, \u03d5 1 =\u27e8x|1\u27e9\u27e81|s\u27e9. \u03d5 \u27e8 | \u27e9 \u27e8 | \u27e9 Similarly, we\u2019ll let \u03d5 2 stand for the amplitude that the electron gets to the detector by way of hole 2 : \u03d5 2 =\u27e8x|2\u27e9\u27e82|s\u27e9. \u03d5 \u27e8 | \u27e9 \u27e8 | \u27e9 These are the amplitudes to go through the two holes and arrive at x if there is no light. Now if there is light, we ask ourselves the question: What is the amplitude for the process in which the electron starts at s and a photon is liberated by the light source L , ending with the electron at x and a photon seen behind slit 1 ? Suppose that we observe the photon behind slit 1 by means of a detector D 1 , as shown in Fig. 3\u20133, and use a similar detector D 2 to count photons scattered behind hole 2 . There will be an amplitude for a photon to arrive at D 1 and an electron at x , and also an amplitude for a photon to arrive at D 2 and an electron at x . Let\u2019s try to calculate them. Although we don\u2019t have the correct mathematical formula for all the factors that go into this calculation, you will see the spirit of it in the following discussion. First, there is the amplitude \u27e81|s\u27e9 that an electron goes from the source to hole 1 . Then we can suppose that there is a certain amplitude that while the electron is at hole 1 it scatters a photon into the detector D 1 . Let us represent this amplitude by a . Then there is the amplitude \u27e8x|1\u27e9 that the electron goes from slit 1 to the electron detector at x . The amplitude that the electron goes from s to x via slit 1 and scatters a photon into D 1 is then \u27e8x|1\u27e9a\u27e81|s\u27e9. \u27e8 | \u27e9 \u27e8 | \u27e9 Or, in our previous notation, it is just a \u03d5 1 . There is also some amplitude that an electron going through slit 2 will scatter a photon into counter D 1 . You say, \u201cThat\u2019s impossible; how can it scatter into counter D 1 if it is only looking at hole 1 ?\u201d If the wavelength is long enough, there are diffraction effects, and it is certainly possible. If the apparatus is built well and if we use photons of short wavelength, then the amplitude that a photon will be scattered into detector 1 , from an electron at 2 is very small. But to keep the discussion general we want to take into account that there is always some such amplitude, which we will call b . Then the amplitude that an electron goes via slit 2 and scatters a photon into D 1 is \u27e8x|2\u27e9b\u27e82|s\u27e9=b \u03d5 2 . \u27e8 | \u27e9 b \u27e8 | \u27e9 b \u03d5 The amplitude to find the electron at x and the photon in D 1 is the sum of two terms, one for each possible path for the electron. Each term is in turn made up of two factors: first, that the electron went through a hole, and second, that the photon is scattered by such an electron into detector 1 ; we have \u27e8 electron at x photon at D 1 \u2223 \u2223 \u2223 electron from s photon from L \u27e9=a \u03d5 1 +b \u03d5 2 . (3.8) We can get a similar expression when the photon is found in the other detector D 2 . If we assume for simplicity that the system is symmetrical, then a is also the amplitude for a photon in D 2 when an electron passes through hole 2 , and b is the amplitude for a photon in D 2 when the electron passes through hole 1 . The corresponding total amplitude for a photon at D 2 and an electron at x is \u27e8 electron at x photon at D 2 \u2223 \u2223 \u2223 electron from s photon from L \u27e9=a \u03d5 2 +b \u03d5 1 . (3.9) Now we are finished. We can easily calculate the probability for various situations. Suppose that we want to know with what probability we get a count in D 1 and an electron at x . That will be the absolute square of the amplitude given in Eq. (3.8), namely, just |a \u03d5 1 +b \u03d5 2 | 2 . Let\u2019s look more carefully at this expression. First of all, if b is zero\u2014which is the way we would like to design the apparatus\u2014then the answer is simply | \u03d5 1 | 2 diminished in total amplitude by the factor |a | 2 . This is the probability distribution that you would get if there were only one hole\u2014as shown in the graph of Fig. 3\u20134(a). On the other hand, if the wavelength is very long, the scattering behind hole 2 into D 1 may be just about the same as for hole 1 . Although there may be some phases involved in a and b , we can ask about a simple case in which the two phases are equal. If a is practically equal to b , then the total probability becomes | \u03d5 1 + \u03d5 2 | 2 multiplied by |a | 2 , since the common factor a can be taken out. This, however, is just the probability distribution we would have gotten without the photons at all. Therefore, in the case that the wavelength is very long\u2014and the photon detection ineffective\u2014you return to the original distribution curve which shows interference effects, as shown in Fig. 3\u20134(b). In the case that the detection is partially effective, there is an interference between a lot of \u03d5 1 and a little of \u03d5 2 , and you will get an intermediate distribution such as is sketched in Fig. 3\u20134(c). Needless to say, if we look for coincidence counts of photons at D 2 and electrons at x , we will get the same kinds of results. If you remember the discussion in Chapter 1, you will see that these results give a quantitative description of what was described there. Now we would like to emphasize an important point so that you will avoid a common error. Suppose that you only want the amplitude that the electron arrives at x , regardless of whether the photon was counted at D 1 or D 2 . Should you add the amplitudes given in Eqs. (3.8) and (3.9)? No! You must never add amplitudes for different and distinct final states. Once the photon is accepted by one of the photon counters, we can always determine which alternative occurred if we want, without any further disturbance to the system. Each alternative has a probability completely independent of the other. To repeat, do not add amplitudes for different final conditions, where by \u201cfinal\u201d we mean at that moment the probability is desired\u2014that is, when the experiment is \u201cfinished.\u201d You do add the amplitudes for the different indistinguishable alternatives inside the experiment, before the complete process is finished. At the end of the process you may say that you \u201cdon\u2019t want to look at the photon.\u201d That\u2019s your business, but you still do not add the amplitudes. Nature does not know what you are looking at, and she behaves the way she is going to behave whether you bother to take down the data or not. So here we must not add the amplitudes. We first square the amplitudes for all possible different final events and then sum. The correct result for an electron at x and a photon at either D 1 or D 2 is \u2223 \u2223 \u2223 \u27e8 e at x ph at D 1 \u2223 \u2223 \u2223 e from s ph from L \u27e9 \u2223 \u2223 \u2223 2 + \u2223 \u2223 \u2223 \u27e8 e at x ph at D 2 \u2223 \u2223 \u2223 e from s ph from L \u27e9 \u2223 \u2223 \u2223 2 =|a \u03d5 1 +b \u03d5 2 | 2 +|a \u03d5 2 +b \u03d5 1 | 2 . (3.10) Our next example is a phenomenon in which we have to analyze the interference of probability amplitudes somewhat carefully. We look at the process of the scattering of neutrons from a crystal. Suppose we have a crystal which has a lot of atoms with nuclei at their centers, arranged in a periodic array, and a neutron beam that comes from far away. We can label the various nuclei in the crystal by an index i , where i runs over the integers 1 , 2 , 3 , \u2026, N , with N equal to the total number of atoms. The problem is to calculate the probability of getting a neutron into a counter with the arrangement shown in Fig. 3\u20135. For any particular atom i , the amplitude that the neutron arrives at the counter C is the amplitude that the neutron gets from the source S to nucleus i , multiplied by the amplitude a that it gets scattered there, multiplied by the amplitude that it gets from i to the counter C . Let\u2019s write that down: \u27e8neutron at C|neutron from S \u27e9 via i =\u27e8C|i\u27e9a\u27e8i|S\u27e9. (3.11) In writing this equation we have assumed that the scattering amplitude a is the same for all atoms. We have here a large number of apparently indistinguishable routes. They are indistinguishable because a low-energy neutron is scattered from a nucleus without knocking the atom out of its place in the crystal\u2014no \u201crecord\u201d is left of the scattering. According to the earlier discussion, the total amplitude for a neutron at C involves a sum of Eq. (3.11) over all the atoms: \u27e8neutron at C|neutron from S\u27e9 = \u2211 i=1 N \u27e8C|i\u27e9a\u27e8i|S\u27e9. (3.12) Because we are adding amplitudes of scattering from atoms with different space positions, the amplitudes will have different phases giving the characteristic interference pattern that we have already analyzed in the case of the scattering of light from a grating. The neutron intensity as a function of angle in such an experiment is indeed often found to show tremendous variations, with very sharp interference peaks and almost nothing in between\u2014as shown in Fig. 3\u20136(a). However, for certain kinds of crystals it does not work this way, and there is\u2014along with the interference peaks discussed above\u2014a general background of scattering in all directions. We must try to understand the apparently mysterious reasons for this. Well, we have not considered one important property of the neutron. It has a spin of one-half, and so there are two conditions in which it can be: either spin \u201cup\u201d (say perpendicular to the page in Fig. 3\u20135) or spin \u201cdown.\u201d If the nuclei of the crystal have no spin, the neutron spin doesn\u2019t have any effect. But when the nuclei of the crystal also have a spin, say a spin of one-half, you will observe the background of smeared-out scattering described above. The explanation is as follows. If the neutron has one direction of spin and the atomic nucleus has the same spin, then no change of spin can occur in the scattering process. If the neutron and atomic nucleus have opposite spin, then scattering can occur by two processes, one in which the spins are unchanged and another in which the spin directions are exchanged. This rule for no net change of the sum of the spins is analogous to our classical law of conservation of angular momentum. We can begin to understand the phenomenon if we assume that all the scattering nuclei are set up with spins in one direction. A neutron with the same spin will scatter with the expected sharp interference distribution. What about one with opposite spin? If it scatters without spin flip, then nothing is changed from the above; but if the two spins flip over in the scattering, we could, in principle, find out which nucleus had done the scattering, since it would be the only one with spin turned over. Well, if we can tell which atom did the scattering, what have the other atoms got to do with it? Nothing, of course. The scattering is exactly the same as that from a single atom. To include this effect, the mathematical formulation of Eq. (3.12) must be modified since we haven\u2019t described the states completely in that analysis. Let\u2019s start with all neutrons from the source having spin up and all the nuclei of the crystal having spin down. First, we would like the amplitude that at the counter the spin of the neutron is up and all spins of the crystal are still down. This is not different from our previous discussion. We will let a be the amplitude to scatter with no spin flip. The amplitude for scattering from the i th atom is, of course, \u27e8 C up , crystal all down| S up , crystal all down\u27e9 =\u27e8C|i\u27e9a\u27e8i|S\u27e9. Since all the atomic spins are still down, the various alternatives (different values of i ) cannot be distinguished. There is clearly no way to tell which atom did the scattering. For this process, all the amplitudes interfere. We have another case, however, where the spin of the detected neutron is down although it started from S with spin up. In the crystal, one of the spins must be changed to the up direction\u2014let\u2019s say that of the k th atom. We will assume that there is the same scattering amplitude with spin flip for every atom, namely b . (In a real crystal there is the disagreeable possibility that the reversed spin moves to some other atom, but let\u2019s take the case of a crystal for which this probability is very low.) The scattering amplitude is then \u27e8 C down , nucleus k up| S up , crystal all down\u27e9 =\u27e8C|k\u27e9b\u27e8k|S\u27e9. (3.13) If we ask for the probability of finding the neutron spin down and the k th nucleus spin up, it is equal to the absolute square of this amplitude, which is simply |b | 2 times |\u27e8C|k\u27e9\u27e8k|S\u27e9 | 2 . The second factor is almost independent of location in the crystal, and all phases have disappeared in taking the absolute square. The probability of scattering from any nucleus in the crystal with spin flip is now |b | 2 \u2211 k=1 N |\u27e8C|k\u27e9\u27e8k|S\u27e9 | 2 , N which will show a smooth distribution as in Fig. 3\u20136(b). You may argue, \u201cI don\u2019t care which atom is up.\u201d Perhaps you don\u2019t, but nature knows; and the probability is, in fact, what we gave above\u2014there isn\u2019t any interference. On the other hand, if we ask for the probability that the spin is up at the detector and all the atoms still have spin down, then we must take the absolute square of \u2211 i=1 N \u27e8C|i\u27e9a\u27e8i|S\u27e9. N Since the terms in this sum have phases, they do interfere, and we get a sharp interference pattern. If we do an experiment in which we don\u2019t observe the spin of the detected neutron, then both kinds of events can occur; and the separate probabilities add. The total probability (or counting rate) as a function of angle then looks like the graph in Fig. 3\u20136(c). Let\u2019s review the physics of this experiment. If you could, in principle, distinguish the alternative final states (even though you do not bother to do so), the total, final probability is obtained by calculating the probability for each state (not the amplitude) and then adding them together. If you cannot distinguish the final states even in principle, then the probability amplitudes must be summed before taking the absolute square to find the actual probability. The thing you should notice particularly is that if you were to try to represent the neutron by a wave alone, you would get the same kind of distribution for the scattering of a down-spinning neutron as for an up-spinning neutron. You would have to say that the \u201cwave\u201d would come from all the different atoms and interfere just as for the up-spinning one with the same wavelength. But we know that is not the way it works. So as we stated earlier, we must be careful not to attribute too much reality to the waves in space. They are useful for certain problems but not for all. The next experiment we will describe is one which shows one of the beautiful consequences of quantum mechanics. It again involves a physical situation in which a thing can happen in two indistinguishable ways, so that there is an interference of amplitudes\u2014as is always true in such circumstances. We are going to discuss the scattering, at relatively low energy, of nuclei on other nuclei. We start by thinking of \u03b1 -particles (which, as you know, are helium nuclei) bombarding, say, oxygen. To make it easier for us to analyze the reaction, we will look at it in the center-of-mass system, in which the oxygen nucleus and the \u03b1 -particle have their velocities in opposite directions before the collision and again in exactly opposite directions after the collision. See Fig. 3\u20137(a). (The magnitudes of the velocities are, of course, different, since the masses are different.) We will also suppose that there is conservation of energy and that the collision energy is low enough that neither particle is broken up or left in an excited state. The reason that the two particles deflect each other is, of course, that each particle carries a positive charge and, classically speaking, there is an electrical repulsion as they go by. The scattering will happen at different angles with different probabilities, and we would like to discuss something about the angle dependence of such scatterings. (It is possible, of course, to calculate this thing classically, and it is one of the most remarkable accidents of quantum mechanics that the answer to this problem comes out the same as it does classically. This is a curious point because it happens for no other force except the inverse square law\u2014so it is indeed an accident.) The probability of scattering in different directions can be measured by an experiment as shown in Fig. 3\u20137(a). The counter at position 1 could be designed to detect only \u03b1 -particles; the counter at position 2 could be designed to detect only oxygen\u2014just as a check. (In the laboratory system the detectors would not be opposite; but in the CM system they are.) Our experiment consists in measuring the probability of scattering in various directions. Let\u2019s call f(\u03b8) the amplitude to scatter into the counters when they are at the angle \u03b8 ; then |f(\u03b8) | 2 will be our experimentally determined probability. Now we could set up another experiment in which our counters would respond to either the \u03b1 -particle or the oxygen nucleus. Then we have to work out what happens when we do not bother to distinguish which particles are counted. Of course, if we are to get an oxygen in the position \u03b8 , there must be an \u03b1 -particle on the opposite side at the angle (\u03c0\u2212\u03b8) , as shown in Fig. 3\u20137(b). So if f(\u03b8) is the amplitude for \u03b1 -scattering through the angle \u03b8 , then f(\u03c0\u2212\u03b8) is the amplitude for oxygen scattering through the angle \u03b8 .1 Thus, the probability for having some particle in the detector at position 1 is: Probability of some particle in D 1 =|f(\u03b8) | 2 +|f(\u03c0\u2212\u03b8) | 2 . (3.14) Note that the two states are distinguishable in principle. Even though in this experiment we do not distinguish them, we could. According to the earlier discussion, then, we must add the probabilities, not the amplitudes. The result given above is correct for a variety of target nuclei\u2014for \u03b1 -particles on oxygen, on carbon, on beryllium, on hydrogen. But it is wrong for \u03b1 -particles on \u03b1 -particles. For the one case in which both particles are exactly the same, the experimental data disagree with the prediction of (3.14). For example, the scattering probability at 90 \u2218 is exactly twice what the above theory predicts and has nothing to do with the particles being \u201chelium\u201d nuclei. If the target is He 3 , but the projectiles are \u03b1 -particles (He 4 ), then there is agreement. Only when the target is He 4 \u2014so its nuclei are identical with the incoming \u03b1 -particle\u2014does the scattering vary in a peculiar way with angle. Perhaps you can already see the explanation. There are two ways to get an \u03b1 -particle into the counter: by scattering the bombarding \u03b1 -particle at an angle \u03b8 , or by scattering it at an angle of (\u03c0\u2212\u03b8) . How can we tell whether the bombarding particle or the target particle entered the counter? The answer is that we cannot. In the case of \u03b1 -particles with \u03b1 -particles there are two alternatives that cannot be distinguished. Here, we must let the probability amplitudes interfere by addition, and the probability of finding an \u03b1 -particle in the counter is the square of their sum: Probability of an \u03b1-particle at D 1 =|f(\u03b8)+f(\u03c0\u2212\u03b8) | 2 . (3.15) This is quite a different result than that in Eq. (3.14). We can take an angle of \u03c0/2 as an example, because it is easy to figure out. For \u03b8=\u03c0/2 , we obviously have f(\u03b8)=f(\u03c0\u2212\u03b8) , so the probability in Eq. (3.15) becomes |f(\u03c0/2)+f(\u03c0/2) | 2 =4|f(\u03c0/2) | 2 . On the other hand, if they did not interfere, the result of Eq. (3.14) gives only 2|f(\u03c0/2) | 2 . So there is twice as much scattering at 90 \u2218 as we might have expected. Of course, at other angles the results will also be different. And so you have the unusual result that when particles are identical, a certain new thing happens that doesn\u2019t happen when particles can be distinguished. In the mathematical description you must add the amplitudes for alternative process in which the two particles simply exchange roles and there is an interference. An even more perplexing thing happens when we do the same kind of experiment by scattering electrons on electrons, or protons on protons. Neither of the above results is then correct! For these particles, we must invoke still a new rule, a most peculiar rule, which is the following: When you have a situation in which the identity of the electron which is arriving at a point is exchanged with another one, the new amplitude interferes with the old one with an opposite phase. It is interference all right, but with a minus sign. In the case of \u03b1 -particles, when you exchange the \u03b1 -particle entering the detector, the interfering amplitudes interfere with the positive sign. In the case of electrons, the interfering amplitudes for exchange interfere with a negative sign. Except for another detail to be discussed below, the proper equation for electrons in an experiment like the one shown in Fig. 3\u20138 is Probability of e at D 1 =|f(\u03b8)\u2212f(\u03c0\u2212\u03b8) | 2 . (3.16) The above statement must be qualified, because we have not considered the spin of the electron ( \u03b1 -particles have no spin). The electron spin may be considered to be either \u201cup\u201d or \u201cdown\u201d with respect to the plane of the scattering. If the energy of the experiment is low enough, the magnetic forces due to the currents will be small and the spin will not be affected. We will assume that this is the case for the present analysis, so that there is no chance that the spins are changed during the collision. Whatever spin the electron has, it carries along with it. Now you see there are many possibilities. The bombarding and target particles can have both spins up, both down, or opposite spins. If both spins are up, as in Fig. 3\u20138 (or if both spins are down), the same will be true of the recoil particles and the amplitude for the process is the difference of the amplitudes for the two possibilities shown in Fig. 3\u20138(a) and (b). The probability of detecting an electron in D 1 is then given by Eq. (3.16). Suppose, however, the \u201cbombarding\u201d spin is up and the \u201ctarget\u201d spin is down. The electron entering counter 1 can have spin up or spin down, and by measuring this spin we can tell whether it came from the bombarding beam or from the target. The two possibilities are shown in Fig. 3\u20139(a) and (b); they are distinguishable in principle, and hence there will be no interference\u2014merely an addition of the two probabilities. The same argument holds if both of the original spins are reversed\u2014that is, if the left-hand spin is down and the right-hand spin is up. Now if we take our electrons at random\u2014as from a tungsten filament in which the electrons are completely unpolarized\u2014then the odds are fifty-fifty that any particular electron comes out with spin up or spin down. If we don\u2019t bother to measure the spin of the electrons at any point in the experiment, we have what we call an unpolarized experiment. The results for this experiment are best calculated by listing all of the various possibilities as we have done in Table 3\u20131. A separate probability is computed for each distinguishable alternative. The total probability is then the sum of all the separate probabilities. Note that for unpolarized beams the result for \u03b8=\u03c0/2 is one-half that of the classical result with independent particles. The behavior of identical particles has many interesting consequences; we will discuss them in greater detail in the next chapter."
    },
    {
        "input": "Diffusion",
        "output": "We have considered so far only the molecular motions in a gas which is in thermal equilibrium. We want now to discuss what happens when things are near, but not exactly in, equilibrium. In a situation far from equilibrium, things are extremely complicated, but in a situation very close to equilibrium we can easily work out what happens. To see what happens, we must, however, return to the kinetic theory. Statistical mechanics and thermodynamics deal with the equilibrium situation, but away from equilibrium we can only analyze what occurs atom by atom, so to speak. As a simple example of a nonequilibrium circumstance, we shall consider the diffusion of ions in a gas. Suppose that in a gas there is a relatively small concentration of ions\u2014electrically charged molecules. If we put an electric field on the gas, then each ion will have a force on it which is different from the forces on the neutral molecules of the gas. If there were no other molecules present, an ion would have a constant acceleration until it reached the wall of the container. But because of the presence of the other molecules, it cannot do that; its velocity increases only until it collides with a molecule and loses its momentum. It starts again to pick up more speed, but then it loses its momentum again. The net effect is that an ion works its way along an erratic path, but with a net motion in the direction of the electric force. We shall see that the ion has an average \u201cdrift\u201d with a mean speed which is proportional to the electric field\u2014the stronger the field, the faster it goes. While the field is on, and while the ion is moving along, it is, of course, not in thermal equilibrium, it is trying to get to equilibrium, which is to be sitting at the end of the container. By means of the kinetic theory we can compute the drift velocity. It turns out that with our present mathematical abilities we cannot really compute precisely what will happen, but we can obtain approximate results which exhibit all the essential features. We can find out how things will vary with pressure, with temperature, and so on, but it will not be possible to get precisely the correct numerical factors in front of all the terms. We shall, therefore, in our derivations, not worry about the precise value of numerical factors. They can be obtained only by a very much more sophisticated mathematical treatment. Before we consider what happens in nonequilibrium situations, we shall need to look a little closer at what goes on in a gas in thermal equilibrium. We shall need to know, for example, what the average time between successive collisions of a molecule is. Any molecule experiences a sequence of collisions with other molecules\u2014in a random way, of course. A particular molecule will, in a long period of time T , have a certain number, N , of hits. If we double the length of time, there will be twice as many hits. So the number of collisions is proportional to the time T . We would like to write it this way: N=T/\u03c4. (43.1) We have written the constant of proportionality as 1/\u03c4 , where \u03c4 will have the dimensions of a time. The constant \u03c4 is the average time between collisions. Suppose, for example, that in an hour there are 60 collisions; then \u03c4 is one minute. We would say that \u03c4 (one minute) is the average time between the collisions. We may often wish to ask the following question: \u201cWhat is the chance that a molecule will experience a collision during the next small interval of time dt ?\u201d The answer, we may intuitively understand, is dt/\u03c4 . But let us try to make a more convincing argument. Suppose that there were a very large number N of molecules. How many will have collisions in the next interval of time dt ? If there is equilibrium, nothing is changing on the average with time. So N molecules waiting the time dt will have the same number of collisions as one molecule waiting for the time Ndt . That number we know is Ndt/\u03c4 . So the number of hits of N molecules is Ndt/\u03c4 in a time dt , and the chance, or probability, of a hit for any one molecule is just 1/N as large, or (1/N)(Ndt/\u03c4)=dt/\u03c4 , as we guessed above. That is to say, the fraction of the molecules which will suffer a collision in the time dt is dt/\u03c4 . To take an example, if \u03c4 is one minute, then in one second the fraction of particles which will suffer collisions is 1/60 . What this means, of course, is that 1/60 of the molecules happen to be close enough to what they are going to hit next that their collisions will occur in the next second. When we say that \u03c4 , the mean time between collisions, is one minute, we do not mean that all the collisions will occur at times separated by exactly one minute. A particular particle does not have a collision, wait one minute, and then have another collision. The times between successive collisions are quite variable. We will not need it for our later work here, but we may make a small diversion to answer the question: \u201cWhat are the times between collisions?\u201d We know that for the case above, the average time is one minute, but we might like to know, for example, what is the chance that we get no collision for two minutes? We shall find the answer to the general question: \u201cWhat is the probability that a molecule will go for a time t without having a collision?\u201d At some arbitrary instant\u2014that we call t=0 \u2014we begin to watch a particular molecule. What is the chance that it gets by until t without colliding with another molecule? To compute the probability, we observe what is happening to all N 0 molecules in a container. After we have waited a time t , some of them will have had collisions. We let N(t) be the number that have not had collisions up to the time t . N(t) is, of course, less than N 0 . We can find N(t) because we know how it changes with time. If we know that N(t) molecules have got by until t , then N(t+dt) , the number which get by until t+dt , is less than N(t) by the number that have collisions in dt . The number that collide in dt we have written above in terms of the mean time \u03c4 as dN=N(t)dt/\u03c4 . We have the equation N(t+dt)=N(t)\u2212N(t) dt \u03c4 . (43.2) The quantity on the left-hand side, N(t+dt) , can be written, according to the definitions of calculus, as N(t)+(dN/dt)dt . Making this substitution, Eq. (43.2) yields dN(t) dt =\u2212 N(t) \u03c4 . (43.3) The number that are being lost in the interval dt is proportional to the number that are present, and inversely proportional to the mean life \u03c4 . Equation (43.3) is easily integrated if we rewrite it as dN(t) N(t) =\u2212 dt \u03c4 . (43.4) Each side is a perfect differential, so the integral is lnN(t)=\u2212t/\u03c4+(a constant), (43.5) which says the same thing as N(t)=(constant) e \u2212t/\u03c4 . (43.6) We know that the constant must be just N 0 , the total number of molecules present, since all of them start at t=0 to wait for their \u201cnext\u201d collision. We can write our result as N(t)= N 0 e \u2212t/\u03c4 . (43.7) If we wish the probability of no collision, P(t) , we can get it by dividing N(t) by N 0 , so P(t)= e \u2212t/\u03c4 . (43.8) Our result is: the probability that a particular molecule survives a time t without a collision is e \u2212t/\u03c4 , where \u03c4 is the mean time between collisions. The probability starts out at 1 (or certainty) for t=0 , and gets less as t gets bigger and bigger. The probability that the molecule avoids a collision for a time equal to \u03c4 is e \u22121 \u22480.37 . The chance is less than one-half that it will have a greater than average time between collisions. That is all right, because there are enough molecules which go collision-free for times much longer than the mean time before colliding, so that the average time can still be \u03c4 . We originally defined \u03c4 as the average time between collisions. The result we have obtained in Eq. (43.7) also says that the mean time from an arbitrary starting instant to the next collision is also \u03c4 . We can demonstrate this somewhat surprising fact in the following way. The number of molecules which experience their next collision in the interval dt at the time t after an arbitrarily chosen starting time is N(t)dt/\u03c4 . Their \u201ctime until the next collision\u201d is, of course, just t . The \u201caverage time until the next collision\u201d is obtained in the usual way: Average time until the next collision= 1 N 0 \u222b \u221e 0 t N(t)dt \u03c4 . \u221e Using N(t) obtained in (43.7) and evaluating the integral, we find indeed that \u03c4 is the average time from any instant until the next collision. Another way of describing the molecular collisions is to talk not about the time between collisions, but about how far the particle moves between collisions. If we say that the average time between collisions is \u03c4 , and that the molecules have a mean velocity v , we can expect that the average distance between collisions, which we shall call l , is just the product of \u03c4 and v . This distance between collisions is usually called the mean free path: Mean free path l=\u03c4v. (43.9) In this chapter we shall be a little careless about what kind of average we mean in any particular case. The various possible averages\u2014the mean, the root-mean-square, etc.\u2014are all nearly equal and differ by factors which are near to one. Since a detailed analysis is required to obtain the correct numerical factors anyway, we need not worry about which average is required at any particular point. We may also warn the reader that the algebraic symbols we are using for some of the physical quantities (e.g., l for the mean free path) do not follow a generally accepted convention, mainly because there is no general agreement. Just as the chance that a molecule will have a collision in a short time dt is equal to dt/\u03c4 , the chance that it will have a collision in going a distance dx is dx/l . Following the same line of argument used above, the reader can show that the probability that a molecule will go at least the distance x before having its next collision is e \u2212x/l . The average distance a molecule goes before colliding with another molecule\u2014the mean free path l \u2014will depend on how many molecules there are around and on the \u201csize\u201d of the molecules, i.e., how big a target they represent. The effective \u201csize\u201d of a target in a collision we usually describe by a \u201ccollision cross section,\u201d the same idea that is used in nuclear physics, or in light-scattering problems. Consider a moving particle which travels a distance dx through a gas which has n 0 scatterers (molecules) per unit volume (Fig. 43\u20131). If we look at each unit of area perpendicular to the direction of motion of our selected particle, we will find there n 0 dx molecules. If each one presents an effective collision area or, as it is usually called, \u201ccollision cross section,\u201d \u03c3 c , then the total area covered by the scatterers is \u03c3 c n 0 dx . By \u201ccollision cross section\u201d we mean the area within which the center of our particle must be located if it is to collide with a particular molecule. If molecules were little spheres (a classical picture) we would expect that \u03c3 c =\u03c0( r 1 + r 2 ) 2 , where r 1 and r 2 are the radii of the two colliding objects. The chance that our particle will have a collision is the ratio of the area covered by scattering molecules to the total area, which we have taken to be one. So the probability of a collision in going a distance dx is just \u03c3 c n 0 dx : Chance of a collision in dx= \u03c3 c n 0 dx. (43.10) We have seen above that the chance of a collision in dx can also be written in terms of the mean free path l as dx/l . Comparing this with (43.10), we can relate the mean free path to the collision cross section: 1 l = \u03c3 c n 0 , (43.11) which is easier to remember if we write it as \u03c3 c n 0 l=1. (43.12) This formula can be thought of as saying that there should be one collision, on the average, when the particle goes through a distance l in which the scattering molecules could just cover the total area. In a cylindrical volume of length l and a base of unit area, there are n 0 l scatterers; if each one has an area \u03c3 c the total area covered is n 0 l \u03c3 c , which is just one unit of area. The whole area is not covered, of course, because some molecules are partly hidden behind others. That is why some molecules go farther than l before having a collision. It is only on the average that the molecules have a collision by the time they go the distance l . From measurements of the mean free path l we can determine the scattering cross section \u03c3 c , and compare the result with calculations based on a detailed theory of atomic structure. But that is a different subject! So we return to the problem of nonequilibrium states. We want to describe what happens to a molecule, or several molecules, which are different in some way from the large majority of the molecules in a gas. We shall refer to the \u201cmajority\u201d molecules as the \u201cbackground\u201d molecules, and we shall call the molecules which are different from the background molecules \u201cspecial\u201d molecules or, for short, the S -molecules. A molecule could be special for any number of reasons: It might be heavier than the background molecules. It might be a different chemical. It might have an electric charge\u2014i.e., be an ion in a background of uncharged molecules. Because of their different masses or charges the S -molecules may have forces on them which are different from the forces on the background molecules. By considering what happens to these S -molecules we can understand the basic effects which come into play in a similar way in many different phenomena. To list a few: the diffusion of gases, electric currents in batteries, sedimentation, centrifugal separation, etc. We begin by concentrating on the basic process: an S -molecule in a background gas is acted on by some specific force F (which might be, e.g., gravitational or electrical) and in addition by the not-so-specific forces due to collisions with the background molecules. We would like to describe the general behavior of the S -molecule. What happens to it, in detail, is that it darts around hither and yon as it collides over and over again with other molecules. But if we watch it carefully we see that it does make some net progress in the direction of the force F . We say that there is a drift, superposed on its random motion. We would like to know what the speed of its drift is\u2014its drift velocity\u2014due to the force F . If we start to observe an S -molecule at some instant we may expect that it is somewhere between two collisions. In addition to the velocity it was left with after its last collision it is picking up some velocity component due to the force F . In a short time (on the average, in a time \u03c4 ) it will experience a collision and start out on a new piece of its trajectory. It will have a new starting velocity, but the same acceleration from F . To keep things simple for the moment, we shall suppose that after each collision our S -molecule gets a completely \u201cfresh\u201d start. That is, that it keeps no remembrance of its past acceleration by F . This might be a reasonable assumption if our S -molecule were much lighter than the background molecules, but it is certainly not valid in general. We shall discuss later an improved assumption. For the moment, then, our assumption is that the S -molecule leaves each collision with a velocity which may be in any direction with equal likelihood. The starting velocity will take it equally in all directions and will not contribute to any net motion, so we shall not worry further about its initial velocity after a collision. In addition to its random motion, each S -molecule will have, at any moment, an additional velocity in the direction of the force F , which it has picked up since its last collision. What is the average value of this part of the velocity? It is just the acceleration F/m (where m is the mass of the S -molecule) times the average time since the last collision. Now the average time since the last collision must be the same as the average time until the next collision, which we have called \u03c4 , above. The average velocity from F , of course, is just what is called the drift velocity, so we have the relation v drift = F\u03c4 m . (43.13) This basic relation is the heart of our subject. There may be some complication in determining what \u03c4 is, but the basic process is defined by Eq. (43.13). You will notice that the drift velocity is proportional to the force. There is, unfortunately, no generally used name for the constant of proportionality. Different names have been used for each different kind of force. If in an electrical problem the force is written as the charge times the electric field, F=qE , then the constant of proportionality between the velocity and the electric field E is usually called the \u201cmobility.\u201d In spite of the possibility of some confusion, we shall use the term mobility for the ratio of the drift velocity to the force for any force. We write v drift =\u03bcF (43.14) in general, and we shall call \u03bc the mobility. We have from Eq. (43.13) that \u03bc=\u03c4/m. (43.15) The mobility is proportional to the mean time between collisions (there are fewer collisions to slow it down) and inversely proportional to the mass (more inertia means less speed picked up between collisions). To get the correct numerical coefficient in Eq. (43.13), which is correct as given, takes some care. Without intending to confuse, we should still point out that the arguments have a subtlety which can be appreciated only by a careful and detailed study. To illustrate that there are difficulties, in spite of appearances, we shall make over again the argument which led to Eq. (43.13) in a reasonable but erroneous way (and the way one will find in many textbooks!). We might have said: The mean time between collisions is \u03c4 . After a collision the particle starts out with a random velocity, but it picks up an additional velocity between collisions, which is equal to the acceleration times the time. Since it takes the time \u03c4 to arrive at the next collision it gets there with the velocity (F/m)\u03c4 . At the beginning of the collision it had zero velocity. So between the two collisions it has, on the average, a velocity one-half of the final velocity, so the mean drift velocity is 1 2 F\u03c4/m . (Wrong!) This result is wrong and the result in Eq. (43.13) is right, although the arguments may sound equally satisfactory. The reason the second result is wrong is somewhat subtle, and has to do with the following: The argument is made as though all collisions were separated by the mean time \u03c4 . The fact is that some times are shorter and others are longer than the mean. Short times occur more often but make less contribution to the drift velocity because they have less chance \u201cto really get going.\u201d If one takes proper account of the distribution of free times between collisions, one can show that there should not be the factor 1 2 that was obtained from the second argument. The error was made in trying to relate by a simple argument the average final velocity to the average velocity itself. This relationship is not simple, so it is best to concentrate on what is wanted: the average velocity itself. The first argument we gave determines the average velocity directly\u2014and correctly! But we can perhaps see now why we shall not in general try to get all of the correct numerical coefficients in our elementary derivations! We return now to our simplifying assumption that each collision knocks out all memory of the past motion\u2014that a fresh start is made after each collision. Suppose our S -molecule is a heavy object in a background of lighter molecules. Then our S -molecule will not lose its \u201cforward\u201d momentum in each collision. It would take several collisions before its motion was \u201crandomized\u201d again. We should assume, instead, that at each collision\u2014in each time \u03c4 on the average\u2014it loses a certain fraction of its momentum. We shall not work out the details, but just state that the result is equivalent to replacing \u03c4 , the average collision time, by a new\u2014and longer\u2014 \u03c4 which corresponds to the average \u201cforgetting time,\u201d i.e., the average time to forget its forward momentum. With such an interpretation of \u03c4 we can use our formula (43.15) for situations which are not quite as simple as we first assumed. We now apply our results to a special case. Suppose we have a gas in a vessel in which there are also some ions\u2014atoms or molecules with a net electric charge. We show the situation schematically in Fig. 43\u20132. If two opposite walls of the container are metallic plates, we can connect them to the terminals of a battery and thereby produce an electric field in the gas. The electric field will result in a force on the ions, so they will begin to drift toward one or the other of the plates. An electric current will be induced, and the gas with its ions will behave like a resistor. By computing the ion flow from the drift velocity we can compute the resistance. We ask, specifically: How does the flow of electric current depend on the voltage difference V that we apply across the two plates? We consider the case that our container is a rectangular box of length b and cross-sectional area A (Fig. 43\u20132). If the potential difference, or voltage, from one plate to the other is V , the electric field E between the plates is V/b . (The electric potential is the work done in carrying a unit charge from one plate to the other. The force on a unit charge is E . If E is the same everywhere between the plates, which is a good enough approximation for now, the work done on a unit charge is just Eb , so V=Eb .) The special force on an ion of the gas is qE , where q is the charge on the ion. The drift velocity of the ion is then \u03bc times this force, or v drift =\u03bcF=\u03bcqE=\u03bcq V b . (43.16) An electric current I is the flow of charge in a unit time. The electric current to one of the plates is given by the total charge of the ions which arrive at the plate in a unit of time. If the ions drift toward the plate with the velocity v drift , then those which are within a distance ( v drift \u22c5T ) will arrive at the plate in the time T . If there are n i ions per unit volume, the number which reach the plate in the time T is ( n i \u22c5A\u22c5 v drift \u22c5T ). Each ion carries the charge q , so we have that Charge collected in T=q n i A v drift T. (43.17) The current I is the charge collected in T divided by T , so I=q n i A v drift . (43.18) Substituting v drift from (43.16), we have I=\u03bc q 2 n i A b V. (43.19) We find that the current is proportional to the voltage, which is just the form of Ohm\u2019s law, and the resistance R is the inverse of the proportionality constant: 1 R =\u03bc q 2 n i A b . (43.20) We have a relation between the resistance and the molecular properties n i , q , and \u03bc , which depends in turn on m and \u03c4 . If we know n i and q from atomic measurements, a measurement of R could be used to determine \u03bc , and from \u03bc also \u03c4 . We turn now to a different kind of problem, and a different kind of analysis: the theory of diffusion. Suppose that we have a container of gas in thermal equilibrium, and that we introduce a small amount of a different kind of gas at some place in the container. We shall call the original gas the \u201cbackground\u201d gas and the new one the \u201cspecial\u201d gas. The special gas will start to spread out through the whole container, but it will spread slowly because of the presence of the background gas. This slow spreading-out process is called diffusion. The diffusion is controlled mainly by the molecules of the special gas getting knocked about by the molecules of the background gas. After a large number of collisions, the special molecules end up spread out more or less evenly throughout the whole volume. We must be careful not to confuse diffusion of a gas with the gross transport that may occur due to convection currents. Most commonly, the mixing of two gases occurs by a combination of convection and diffusion. We are interested now only in the case that there are no \u201cwind\u201d currents. The gas is spreading only by molecular motions, by diffusion. We wish to compute how fast diffusion takes place. We now compute the net flow of molecules of the \u201cspecial\u201d gas due to the molecular motions. There will be a net flow only when there is some nonuniform distribution of the molecules, otherwise all of the molecular motions would average to give no net flow. Let us consider first the flow in the x -direction. To find the flow, we consider an imaginary plane surface perpendicular to the x -axis and count the number of special molecules that cross this plane. To obtain the net flow, we must count as positive those molecules which cross in the direction of positive x and subtract from this number the number which cross in the negative x -direction. As we have seen many times, the number which cross a surface area in a time \u0394T is given by the number which start the interval \u0394T in a volume which extends the distance v\u0394T from the plane. (Note that v , here, is the actual molecular velocity, not the drift velocity.) We shall simplify our algebra by giving our surface one unit of area. Then the number of special molecules which pass from left to right (taking the +x -direction to the right) is n \u2212 v\u0394T , where n \u2212 is the number of special molecules per unit volume to the left (within a factor of 2 or so, but we are ignoring such factors!). The number which cross from right to left is, similarly, n + v\u0394T , where n + is the number density of special molecules on the right-hand side of the plane. If we call the molecular current J , by which we mean the net flow of molecules per unit area per unit time, we have J= n \u2212 v\u0394T\u2212 n + v\u0394T \u0394T , (43.21) or J=( n \u2212 \u2212 n + )v. (43.22) What shall we use for n \u2212 and n + ? When we say \u201cthe density on the left,\u201d how far to the left do we mean? We should choose the density at the place from which the molecules started their \u201cflight,\u201d because the number which start such trips is determined by the number present at that place. So by n \u2212 we should mean the density a distance to the left equal to the mean free path l , and by n + , the density at the distance l to the right of our imaginary surface. It is convenient to consider that the distribution of our special molecules in space is described by a continuous function of x , y , and z which we shall call n a . By n a (x,y,z) we mean the number density of special molecules in a small volume element centered on (x,y,z) . In terms of n a we can express the difference ( n + \u2212 n \u2212 ) as ( n + \u2212 n \u2212 )= d n a dx \u0394x= d n a dx \u22c52l. (43.23) Substituting this result in Eq. (43.22) and neglecting the factor of 2 , we get J x =\u2212lv d n a dx . (43.24) We have found that the flow of special molecules is proportional to the derivative of the density, or to what is sometimes called the \u201cgradient\u201d of the density. It is clear that we have made several rough approximations. Besides various factors of two we have left out, we have used v where we should have used v x , and we have assumed that n + and n \u2212 refer to places at the perpendicular distance l from our surface, whereas for those molecules which do not travel perpendicular to the surface element, l should correspond to the slant distance from the surface. All of these refinements can be made; the result of a more careful analysis shows that the right-hand side of Eq. (43.24) should be multiplied by 1/3 . So a better answer is J x =\u2212 lv 3 d n a dx . (43.25) Similar equations can be written for the currents in the y - and z -directions. The current J x and the density gradient d n a /dx can be measured by macroscopic observations. Their experimentally determined ratio is called the \u201cdiffusion coefficient,\u201d D . That is, J x =\u2212D d n a dx . (43.26) We have been able to show that for a gas we expect D= 1 3 lv. (43.27) So far in this chapter we have considered two distinct processes: mobility, the drift of molecules due to \u201coutside\u201d forces; and diffusion, the spreading determined only by the internal forces, the random collisions. There is, however, a relation between them, since they both depend basically on the thermal motions, and the mean free path l appears in both calculations. If, in Eq. (43.25), we substitute l=v\u03c4 and \u03c4=\u03bcm , we have J x =\u2212 1 3 m v 2 \u03bc d n a dx . (43.28) But m v 2 depends only on the temperature. We recall that 1 2 m v 2 = 3 2 kT, (43.29) so J x =\u2212\u03bckT d n a dx . (43.30) We find that D , the diffusion coefficient, is just kT times \u03bc , the mobility coefficient: D=\u03bckT. (43.31) And it turns out that the numerical coefficient in (43.31) is exactly right\u2014no extra factors have to be thrown in to adjust for our rough assumptions. We can show, in fact, that (43.31) must always be correct\u2014even in complicated situations (for example, the case of a suspension in a liquid) where the details of our simple calculations would not apply at all. To show that (43.31) must be correct in general, we shall derive it in a different way, using only our basic principles of statistical mechanics. Imagine a situation in which there is a gradient of \u201cspecial\u201d molecules, and we have a diffusion current proportional to the density gradient, according to Eq. (43.26). We now apply a force field in the x -direction, so that each special molecule feels the force F . According to the definition of the mobility \u03bc there will be a drift velocity given by v drift =\u03bcF. (43.32) By our usual arguments, the drift current (the net number of molecules which pass a unit of area in a unit of time) will be J drift = n a v drift , (43.33) or J drift = n a \u03bcF. (43.34) We now adjust the force F so that the drift current due to F just balances the diffusion, so that there is no net flow of our special molecules. We have J x + J drift =0 , or D d n a dx = n a \u03bcF. (43.35) Under the \u201cbalance\u201d conditions we find a steady (with time) gradient of density given by d n a dx = n a \u03bcF D . (43.36) But notice! We are describing an equilibrium condition, so our equilibrium laws of statistical mechanics apply. According to these laws the probability of finding a molecule at the coordinate x is proportional to e \u2212U/kT , where U is the potential energy. In terms of the number density n a , this means that n a = n 0 e \u2212U/kT . (43.37) If we differentiate (43.37) with respect to x , we find d n a dx =\u2212 n 0 e \u2212U/kT \u22c5 1 kT dU dx , (43.38) or d n a dx =\u2212 n a kT dU dx . (43.39) In our situation, since the force F is in the x -direction, the potential energy U is just \u2212Fx , and \u2212dU/dx=F . Equation (43.39) then gives d n a dx = n a F kT . (43.40) [This is just exactly Eq. (40.2), from which we deduced e \u2212U/kT in the first place, so we have come in a circle]. Comparing (43.40) with (43.36), we get exactly Eq. (43.31). We have shown that Eq. (43.31), which gives the diffusion current in terms of the mobility, has the correct coefficient and is very generally true. Mobility and diffusion are intimately connected. This relation was first deduced by Einstein. The methods of the kinetic theory that we have been using above can be used also to compute the thermal conductivity of a gas. If the gas at the top of a container is hotter than the gas at the bottom, heat will flow from the top to the bottom. (We think of the top being hotter because otherwise convection currents would be set up and the problem would no longer be one of heat conduction.) The transfer of heat from the hotter gas to the colder gas is by the diffusion of the \u201chot\u201d molecules\u2014those with more energy\u2014downward and the diffusion of the \u201ccold\u201d molecules upward. To compute the flow of thermal energy we can ask about the energy carried downward across an element of area by the downward-moving molecules, and about the energy carried upward across the surface by the upward-moving molecules. The difference will give us the net downward flow of energy. The thermal conductivity \u03ba is defined as the ratio of the rate at which thermal energy is carried across a unit surface area, to the temperature gradient: 1 A dQ dt =\u2212\u03ba dT dz . (43.41) Since the details of the calculations are quite similar to those we have done above in considering molecular diffusion, we shall leave it as an exercise for the reader to show that \u03ba= knlv \u03b3\u22121 , (43.42) where kT/(\u03b3\u22121) is the average energy of a molecule at the temperature T . If we use our relation nl \u03c3 c =1 , the heat conductivity can be written as \u03ba= 1 \u03b3\u22121 kv \u03c3 c . (43.43) We have a rather surprising result. We know that the average velocity of gas molecules depends on the temperature but not on the density. We expect \u03c3 c to depend only on the size of the molecules. So our simple result says that the thermal conductivity \u03ba (and therefore the rate of flow of heat in any particular circumstance) is independent of the density of the gas! The change in the number of \u201ccarriers\u201d of energy with a change in density is just compensated by the larger distance the \u201ccarriers\u201d can go between collisions. One may ask: \u201cIs the heat flow independent of the gas density in the limit as the density goes to zero? When there is no gas at all?\u201d Certainly not! The formula (43.43) was derived, as were all the others in this chapter, under the assumption that the mean free path between collisions is much smaller than any of the dimensions of the container. Whenever the gas density is so low that a molecule has a fair chance of crossing from one wall of its container to the other without having a collision, none of the calculations of this chapter apply. We must in such cases go back to kinetic theory and calculate again the details of what will occur."
    },
    {
        "input": "Radiation Damping. Light Scattering",
        "output": "In the last chapter we learned that when a system is oscillating, energy is carried away, and we deduced a formula for the energy which is radiated by an oscillating system. If we know the electric field, then the average of the square of the field times \u03f50c is the amount of energy that passes per square meter per second through a surface normal to the direction in which the radiation is going: S=\u03f50c\u27e8E2\u27e9. Any oscillating charge radiates energy; for instance, a driven antenna radiates energy. If the system radiates energy, then in order to account for the conservation of energy we must find that power is being delivered along the wires which lead into the antenna. That is, to the driving circuit the antenna acts like a resistance, or a place where energy can be \u201clost\u201d (the energy is not really lost, it is really radiated out, but so far as the circuit is concerned, the energy is lost). In an ordinary resistance, the energy which is \u201clost\u201d passes into heat; in this case the energy which is \u201clost\u201d goes out into space. But from the standpoint of circuit theory, without considering where the energy goes, the net effect on the circuit is the same\u2014energy is \u201clost\u201d from that circuit. Therefore the antenna appears to the generator as having a resistance, even though it may be made with perfectly good copper. In fact, if it is well built it will appear as almost a pure resistance, with very little inductance or capacitance, because we would like to radiate as much energy as possible out of the antenna. This resistance that an antenna shows is called the radiation resistance. If a current I is going to the antenna, then the average rate at which power is delivered to the antenna is the average of the square of the current times the resistance. The rate at which power is radiated by the antenna is proportional to the square of the current in the antenna, of course, because all the fields are proportional to the currents, and the energy liberated is proportional to the square of the field. The coefficient of proportionality between radiated power and \u27e8I2\u27e9 is the radiation resistance. An interesting question is, what is this radiation resistance due to? Let us take a simple example: let us say that currents are driven up and down in an antenna. We find that we have to put work in, if the antenna is to radiate energy. If we take a charged body and accelerate it up and down it radiates energy; if it were not charged it would not radiate energy. It is one thing to calculate from the conservation of energy that energy is lost, but another thing to answer the question, against what force are we doing the work? That is an interesting and very difficult question which has never been completely and satisfactorily answered for electrons, although it has been for antennas. What happens is this: in an antenna, the fields produced by the moving charges in one part of the antenna react on the moving charges in another part of the antenna. We can calculate these forces and find out how much work they do, and so find the right rule for the radiation resistance. When we say \u201cWe can calculate\u2014\u201d that is not quite right\u2014we cannot, because we have not yet studied the laws of electricity at short distances; only at large distances do we know what the electric field is. We saw the formula (28.3), but at present it is too complicated for us to calculate the fields inside the wave zone. Of course, since conservation of energy is valid, we can calculate the result all right without knowing the fields at short distances. (As a matter of fact, by using this argument backwards it turns out that one can find the formula for the forces at short distances only by knowing the field at very large distances, by using the laws of conservation of energy, but we shall not go into that here.) The problem in the case of a single electron is this: if there is only one charge, what can the force act on? It has been proposed, in the old classical theory, that the charge was a little ball, and that one part of the charge acted on the other part. Because of the delay in the action across the tiny electron, the force is not exactly in phase with the motion. That is, if we have the electron standing still, we know that \u201caction equals reaction.\u201d So the various internal forces are equal, and there is no net force. But if the electron is accelerating, then because of the time delay across it, the force which is acting on the front from the back is not exactly the same as the force on the back from the front, because of the delay in the effect. This delay in the timing makes for a lack of balance, so, as a net effect, the thing holds itself back by its bootstraps! This model of the origin of the resistance to acceleration, the radiation resistance of a moving charge, has run into many difficulties, because our present view of the electron is that it is not a \u201clittle ball\u201d; this problem has never been solved. Nevertheless we can calculate exactly, of course, what the net radiation resistance force must be, i.e., how much loss there must be when we accelerate a charge, in spite of not knowing directly the mechanism of how that force works. Now we shall calculate the total energy radiated by an accelerating charge. To keep the discussion general, we shall take the case of a charge accelerating any which way, but nonrelativistically. At a moment when the acceleration is, say, vertical, we know that the electric field that is generated is the charge multiplied by the projection of the retarded acceleration, divided by the distance. So we know the electric field at any point, and we therefore know the square of the electric field and thus the energy \u03f50cE2 leaving through a unit area per second. The quantity \u03f50c appears quite often in expressions involving radiowave propagation. Its reciprocal is called the impedance of a vacuum, and it is an easy number to remember: it has the value 1/\u03f50c=377 ohms. So the power in watts per square meter is equal to the average of the field squared, divided by 377 . Using our expression (29.1) for the electric field, we find that S= q2a\u20322sin2\u03b8 16\u03c02\u03f50r2c3 is the power per square meter radiated in the direction \u03b8 . We notice that it goes inversely as the square of the distance, as we said before. Now suppose we wanted the total energy radiated in all directions: then we must integrate (32.2) over all directions. First we multiply by the area, to find the amount that flows within a little angle d\u03b8 (Fig. 32\u20131). We need the area of a spherical section. The way to think of it is this: if r is the radius, then the width of the annular segment is rd\u03b8 , and the circumference is 2\u03c0rsin\u03b8 , because rsin\u03b8 is the radius of the circle. So the area of the little piece of the sphere is 2\u03c0rsin\u03b8 times rd\u03b8 : dA=2\u03c0r2sin\u03b8d\u03b8. By multiplying the flux [(32.2), the power per square meter] by the area in square meters included in the small angle d\u03b8 , we find the amount of energy that is liberated in this direction between \u03b8 and \u03b8+d\u03b8 ; then we integrate that over all the angles \u03b8 from 0 to 180\u2218 : P=\u222bSdA= q2a\u20322 8\u03c0\u03f50c3 \u222b \u03c0 0 sin3\u03b8d\u03b8. By writing sin3\u03b8=(1\u2212cos2\u03b8)sin\u03b8 it is not hard to show that \u222b \u03c0 0 sin3\u03b8d\u03b8=4/3 . Using that fact, we finally get P= q2a\u20322 6\u03c0\u03f50c3 . This expression deserves some remarks. First of all, since the vector a\u2032 had a certain direction, the a\u20322 in (32.5) would be the square of the vector a\u2032 , that is, a\u2032\u22c5a\u2032 , the length of the vector, squared. Secondly, the flux (32.2) was calculated using the retarded acceleration; that is, the acceleration at the time at which the energy now passing through the sphere was radiated. We might like to say that this energy was in fact liberated at this earlier time. This is not exactly true; it is only an approximate idea. The exact time when the energy is liberated cannot be defined precisely. All we can really calculate precisely is what happens in a complete motion, like an oscillation or something, where the acceleration finally ceases. Then what we find is that the total energy flux per cycle is the average of acceleration squared, for a complete cycle. This is what should really appear in (32.5). Or, if it is a motion with an acceleration that is initially and finally zero, then the total energy that has flown out is the time integral of (32.5). To illustrate the consequences of formula (32.5) when we have an oscillating system, let us see what happens if the displacement x of the charge is oscillating so that the acceleration a is \u2212\u03c92x0ei\u03c9t . The average of the acceleration squared over a cycle (remember that we have to be very careful when we square things that are written in complex notation\u2014it really is the cosine, and the average of cos2\u03c9t is one-half) thus is \u27e8a\u20322\u27e9= 1 2 \u03c94x 2 0 . Therefore P= q2\u03c94x 2 0 12\u03c0\u03f50c3 . The formulas we are now discussing are relatively advanced and more or less modern; they date from the beginning of the twentieth century, and they are very famous. Because of their historical value, it is important for us to be able to read about them in older books. In fact, the older books also used a system of units different from our present mks system. However, all these complications can be straightened out in the final formulas dealing with electrons by the following rule: The quantity q 2 e /4\u03c0\u03f50 , where qe is the electronic charge (in coulombs), has, historically, been written as e2 . It is very easy to calculate that e in the mks system is numerically equal to 1.5188\u00d710\u221214 , because we know that, numerically, qe=1.60206\u00d710\u221219 and 1/4\u03c0\u03f50=8.98748\u00d7109 . Therefore we shall often use the convenient abbreviation e2= q 2 e 4\u03c0\u03f50 . If we use the above numerical value of e in the older formulas and treat them as though they were written in mks units, we will get the right numerical results. For example, the older form of (32.5) is P= 2 3 e2a\u20322/c3 . Again, the potential energy of a proton and an electron at distance r is q 2 e /4\u03c0\u03f50r or e2/r , with e=1.5188\u00d710\u221214 (mks). Now the fact that an oscillator loses a certain energy would mean that if we had a charge on the end of a spring (or an electron in an atom) which has a natural frequency \u03c90 , and we start it oscillating and let it go, it will not oscillate forever, even if it is in empty space millions of miles from anything. There is no oil, no resistance, in an ordinary sense; no \u201cviscosity.\u201d But nevertheless it will not oscillate, as we might once have said, \u201cforever,\u201d because if it is charged it is radiating energy, and therefore the oscillation will slowly die out. How slowly? What is the Q of such an oscillator, caused by the electromagnetic effects, the so-called radiation resistance or radiation damping of the oscillator? The Q of any oscillating system is the total energy content of the oscillator at any time divided by the energy loss per radian: Q=\u2212 W dW/d\u03d5 . Or (another way to write it), since dW/d\u03d5= (dW/dt)/(d\u03d5/dt)= (dW/dt)/\u03c9 , Q=\u2212 \u03c9W dW/dt . If for a given Q this tells us how the energy of the oscillation dies out, dW/dt=\u2212(\u03c9/Q)W , which has the solution W=W0e\u2212\u03c9t/Q if W0 is the initial energy (at t=0 ). To find the Q for a radiator, we go back to (32.8) and use (32.6) for dW/dt . Now what do we use for the energy W of the oscillator? The kinetic energy of the oscillator is 1 2 mv2 , and the mean kinetic energy is m\u03c92x 2 0 /4 . But we remember that for the total energy of an oscillator, on the average half is kinetic and half is potential energy, and so we double our result, and find for the total energy of the oscillator W= 1 2 m\u03c92x 2 0 . What do we use for the frequency in our formulas? We use the natural frequency \u03c90 because, for all practical purposes, that is the frequency at which our atom is radiating, and for m we use the electron mass me . Then, making the necessary divisions and cancellations, the formula comes down to 1 Q = 4\u03c0e2 3\u03bbmec2 . (In order to see it better and in a more historical form we write it using our abbreviation q 2 e /4\u03c0\u03f50=e2 , and the factor \u03c90/c which was left over has been written as 2\u03c0/\u03bb .) Since Q is dimensionless, the combination e2/mec2 must be a property only of the electron charge and mass, an intrinsic property of the electron, and it must be a length. It has been given a name, the classical electron radius, because the early atomic models, which were invented to explain the radiation resistance on the basis of the force of one part of the electron acting on the other parts, all needed to have an electron whose dimensions were of this general order of magnitude. However, this quantity no longer has the significance that we believe that the electron really has such a radius. Numerically, the magnitude of the radius is r0= e2 mec2 =2.82\u00d710\u221215 m. Now let us actually calculate the Q of an atom that is emitting light\u2014let us say a sodium atom. For a sodium atom, the wavelength is roughly 6000 angstroms, in the yellow part of the visible spectrum, and this is a typical wavelength. Thus Q= 3\u03bb 4\u03c0r0 \u22485\u00d7107, so the Q of an atom is of the order 108 . This means that an atomic oscillator will oscillate for 108 radians or about 107 oscillations, before its energy falls by a factor 1/e . The frequency of oscillation of light corresponding to 6000 angstroms, \u03bd=c/\u03bb , is on the order of 1015 cycles/sec, and therefore the lifetime, the time it takes for the energy of a radiating atom to die out by a factor 1/e , is on the order of 10\u22128 sec. In ordinary circumstances, freely emitting atoms usually take about this long to radiate. This is valid only for atoms which are in empty space, not being disturbed in any way. If the electron is in a solid and it has to hit other atoms or other electrons, then there are additional resistances and different damping. The effective resistance term \u03b3 in the resistance law for the oscillator can be found from the relation 1/Q=\u03b3/\u03c90 , and we remember that the size of \u03b3 determines how wide the resonance curve is (Fig. 23\u20132). Thus we have just computed the widths of spectral lines for freely radiating atoms! Since \u03bb=2\u03c0c/\u03c9 , we find that \u0394\u03bb =2\u03c0c\u0394\u03c9/\u03c92=2\u03c0c\u03b3/\u03c9 2 0 =2\u03c0c/Q\u03c90 =\u03bb/Q=4\u03c0r0/3=1.18\u00d710\u221214 m. In preparation for our second topic, the scattering of light, we must now discuss a certain feature of the phenomenon of interference that we neglected to discuss previously. This is the question of when interference does not occur. If we have two sources S1 and S2 , with amplitudes A1 and A2 , and we make an observation in a certain direction in which the phases of arrival of the two signals are \u03d51 and \u03d52 (a combination of the actual time of oscillation and the delayed time, depending on the position of observation), then the energy that we receive can be found by compounding the two complex number vectors A1 and A2 , one at angle \u03d51 and the other at angle \u03d52 (as we did in Chapter 29) and we find that the resultant energy is proportional to A 2 R =A 2 1 +A 2 2 +2A1A2cos(\u03d51\u2212\u03d52). Now if the cross term 2A1A2cos(\u03d51\u2212\u03d52) were not there, then the total energy that would be received in a given direction would simply be the sum of the energies, A 2 1 +A 2 2 , that would be liberated by each source separately, which is what we usually expect. That is, the combined intensity of light shining on something from two sources is the sum of the intensities of the two lights. On the other hand, if we have things set just right and we have a cross term, it is not such a sum, because there is also some interference. If there are circumstances in which this term is of no importance, then we would say the interference is apparently lost. Of course, in nature it is always there, but we may not be able to detect it. Let us consider some examples. Suppose, first, that the two sources are 7,000,000,000 wavelengths apart, not an impossible arrangement. Then in a given direction it is true that there is a very definite value of these phase differences. But, on the other hand, if we move just a hair in one direction, a few wavelengths, which is no distance at all (our eye already has a hole in it that is so large that we are averaging the effects over a range very wide compared with one wavelength) then we change the relative phase, and the cosine changes very rapidly. If we take the average of the intensity over a little region, then the cosine, which goes plus, minus, plus, minus, as we move around, averages to zero. So if we average over regions where the phase varies very rapidly with position, we get no interference. Another example. Suppose that the two sources are two independent radio oscillators\u2014not a single oscillator being fed by two wires, which guarantees that the phases are kept together, but two independent sources\u2014and that they are not precisely tuned at the same frequency (it is very hard to make them at exactly the same frequency without actually wiring them together). In this case we have what we call two independent sources. Of course, since the frequencies are not exactly equal, although they started in phase, one of them begins to get a little ahead of the other, and pretty soon they are out of phase, and then it gets still further ahead, and pretty soon they are in phase again. So the phase difference between the two is gradually drifting with time, but if our observation is so crude that we cannot see that little time, if we average over a much longer time, then although the intensity swells and falls like what we call \u201cbeats\u201d in sound, if these swellings and fallings are too rapid for our equipment to follow, then again this term averages out. In other words, in any circumstance in which the phase shift averages out, we get no interference! One finds many books which say that two distinct light sources never interfere. This is not a statement of physics, but is merely a statement of the degree of sensitivity of the technique of the experiments at the time the book was written. What happens in a light source is that first one atom radiates, then another atom radiates, and so forth, and we have just seen that atoms radiate a train of waves only for about 10\u22128 sec; after 10\u22128 sec, some atom has probably taken over, then another atom takes over, and so on. So the phases can really only stay the same for about 10\u22128 sec. Therefore, if we average for very much more than 10\u22128 sec, we do not see an interference from two different sources, because they cannot hold their phases steady for longer than 10\u22128 sec. With photocells, very high-speed detection is possible, and one can show that there is an interference which varies with time, up and down, in about 10\u22128 sec. But most detection equipment, of course, does not look at such fine time intervals, and thus sees no interference. Certainly with the eye, which has a tenth-of-a-second averaging time, there is no chance whatever of seeing an interference between two different ordinary sources. Recently it has become possible to make light sources which get around this effect by making all the atoms emit together in time. The device which does this is a very complicated thing, and has to be understood in a quantum-mechanical way. It is called a laser, and it is possible to produce from a laser a source in which the time during which the phase is kept constant, is very much longer than 10 \u22128 sec. It can be of the order of a hundredth, a tenth, or even one second, and so, with ordinary photocells, one can pick up the frequency between two different lasers. One can easily detect the pulsing of the beats between two laser sources. Soon, no doubt, someone will be able to demonstrate two sources shining on a wall, in which the beats are so slow that one can see the wall get bright and dark! Another case in which the interference averages out is that in which, instead of having only two sources, we have many. In this case, we would write the expression for A 2 R as the sum of a whole lot of amplitudes, complex numbers, squared, and we would get the square of each one, all added together, plus cross terms between every pair, and if the circumstances are such that the latter average out, then there will be no effects of interference. It may be that the various sources are located in such random positions that, although the phase difference between A 2 and A 3 is also definite, it is very different from that between A 1 and A 2 , etc. So we would get a whole lot of cosines, many plus, many minus, all averaging out. So it is that in many circumstances we do not see the effects of interference, but see only a collective, total intensity equal to the sum of all the intensities. The above leads us to an effect which occurs in air as a consequence of the irregular positions of the atoms. When we were discussing the index of refraction, we saw that an incoming beam of light will make the atoms radiate again. The electric field of the incoming beam drives the electrons up and down, and they radiate because of their acceleration. This scattered radiation combines to give a beam in the same direction as the incoming beam, but of somewhat different phase, and this is the origin of the index of refraction. But what can we say about the amount of re-radiated light in some other direction? Ordinarily, if the atoms are very beautifully located in a nice pattern, it is easy to show that we get nothing in other directions, because we are adding a lot of vectors with their phases always changing, and the result comes to zero. But if the objects are randomly located, then the total intensity in any direction is the sum of the intensities that are scattered by each atom, as we have just discussed. Furthermore, the atoms in a gas are in actual motion, so that although the relative phase of two atoms is a definite amount now, later the phase would be quite different, and therefore each cosine term will average out. Therefore, to find out how much light is scattered in a given direction by a gas, we merely study the effects of one atom and multiply the intensity it radiates by the number of atoms. Earlier, we remarked that the phenomenon of scattering of light of this nature is the origin of the blue of the sky. The sunlight goes through the air, and when we look to one side of the sun\u2014say at 90 \u2218 to the beam\u2014we see blue light; what we now have to calculate is how much light we see and why it is blue. If the incident beam has the electric field1 E= E ^ 0 e i\u03c9t at the point where the atom is located, we know that an electron in the atom will vibrate up and down in response to this E (Fig. 32\u20132). From Eq. (23.8), the response will be x ^ = q e E ^ 0 m( \u03c9 2 0 \u2212 \u03c9 2 +i\u03b3\u03c9) . (32.15) We could include the damping and the possibility that the atom acts like several oscillators of different frequency and sum over the various frequencies, but for simplicity let us just take one oscillator and neglect the damping. Then the response to the external electric field, which we have already used in the calculation of the index of refraction, is simply x ^ = q e E ^ 0 m( \u03c9 2 0 \u2212 \u03c9 2 ) . (32.16) We could now easily calculate the intensity of light that is emitted in various directions, using formula (32.2) and the acceleration corresponding to the above x ^ . Rather than do this, however, we shall simply calculate the total amount of light scattered in all directions, just to save time. The total amount of light energy per second, scattered in all directions by the single atom, is of course given by Eq. (32.6). So, putting together the various pieces and regrouping them, we get P =[( q 2 e \u03c9 4 /12\u03c0 \u03f5 0 c 3 ) q 2 e E 2 0 / m 2 e ( \u03c9 2 \u2212 \u03c9 2 0 ) 2 ] =( 1 2 \u03f5 0 c E 2 0 )(8\u03c0/3)( q 4 e /16 \u03c0 2 \u03f5 2 0 m 2 e c 4 )[ \u03c9 4 /( \u03c9 2 \u2212 \u03c9 2 0 ) 2 ] =( 1 2 \u03f5 0 c E 2 0 )(8\u03c0 r 2 0 /3)[ \u03c9 4 /( \u03c9 2 \u2212 \u03c9 2 0 ) 2 ] (32.17) for the total scattered power, radiated in all directions. We have written the result in the above form because it is then easy to remember: First, the total energy that is scattered is proportional to the square of the incident field. What does that mean? Obviously, the square of the incident field is proportional to the energy which is coming in per second. In fact, the energy incident per square meter per second is \u03f5 0 c times the average \u27e8 E 2 \u27e9 of the square of the electric field, and if E 0 is the maximum value of E , then \u27e8 E 2 \u27e9= 1 2 E 2 0 . In other words, the total energy scattered is proportional to the energy per square meter that comes in; the brighter the sunlight that is shining in the sky, the brighter the sky is going to look. Next, what fraction of the incoming light is scattered? Let us imagine a \u201ctarget\u201d with a certain area, let us say \u03c3 , in the beam (not a real, material target, because this would diffract light, and so on; we mean an imaginary area drawn in space). The total amount of energy that would pass through this surface \u03c3 in a given circumstance is proportional both to the incoming intensity and to \u03c3 , and the total power would be P=( 1 2 \u03f5 0 c E 2 0 )\u03c3. (32.18) Now we invent an idea: we say that the atom scatters a total amount of intensity which is the amount which would fall on a certain geometrical area, and we give the answer by giving that area. That answer, then, is independent of the incident intensity; it gives the ratio of the energy scattered to the energy incident per square meter. In other words, the ratio total energy scattered per second energy incident per square meter per second is an area. total energy scattered per second The significance of this area is that, if all the energy that impinged on that area were to be spewed in all directions, then that is the amount of energy that would be scattered by the atom. This area is called a cross section for scattering; the idea of cross section is used constantly, whenever some phenomenon occurs in proportion to the intensity of a beam. In such cases one always describes the amount of the phenomenon by saying what the effective area would have to be to pick up that much of the beam. It does not mean in any way that this oscillator actually has such an area. If there were nothing present but a free electron shaking up and down there would be no area directly associated with it, physically. It is merely a way of expressing the answer to a certain kind of problem; it tells us what area the incident beam would have to hit in order to account for that much energy coming off. Thus, for our case, \u03c3 s = 8\u03c0 r 2 0 3 \u22c5 \u03c9 4 ( \u03c9 2 \u2212 \u03c9 2 0 ) 2 (32.19) (the subscript s is for \u201cscattering\u201d). Let us look at some examples. First, if we go to a very low natural frequency \u03c9 0 , or to completely unbound electrons, for which \u03c9 0 =0 , then the frequency \u03c9 cancels out and the cross section is a constant. This low-frequency limit, or the free electron cross section, is known as the Thomson scattering cross section. It is an area whose dimensions are approximately 10 \u221215 meter, more or less, on a side, i.e., 10 \u221230 square meter, which is rather small! On the other hand, if we take the case of light in the air, we remember that for air the natural frequencies of the oscillators are higher than the frequency of the light that we use. This means that, to a first approximation, we can disregard \u03c9 2 in the denominator, and we find that the scattering is proportional to the fourth power of the frequency. That is to say, light which is of higher frequency by, say, a factor of two, is sixteen times more intensely scattered, which is a quite sizable difference. This means that blue light, which has about twice the frequency of the reddish end of the spectrum, is scattered to a far greater extent than red light. Thus when we look at the sky it looks that glorious blue that we see all the time! There are several points to be made about the above results. One interesting question is, why do we ever see the clouds? Where do the clouds come from? Everybody knows it is the condensation of water vapor. But, of course, the water vapor is already in the atmosphere before it condenses, so why don\u2019t we see it then? After it condenses it is perfectly obvious. It wasn\u2019t there, now it is there. So the mystery of where the clouds come from is not really such a childish mystery as \u201cWhere does the water come from, Daddy?,\u201d but has to be explained. We have just explained that every atom scatters light, and of course the water vapor will scatter light, too. The mystery is why, when the water is condensed into clouds, does it scatter such a tremendously greater amount of light? Consider what would happen if, instead of a single atom, we had an agglomerate of atoms, say two, very close together compared with the wavelength of the light. Remember, atoms are only an angstrom or so across, while the wavelength of light is some 5000 angstroms, so when they form a clump, a few atoms together, they can be very close together compared with the wavelength of light. Then when the electric field acts, both of the atoms will move together. The electric field that is scattered will then be the sum of the two electric fields in phase, i.e., double the amplitude that there was with a single atom, and the energy which is scattered is therefore four times what it is with a single atom, not twice! So lumps of atoms radiate or scatter more energy than they do as single atoms. Our argument that the phases are independent is based on the assumption that there is a real and large difference in phase between any two atoms, which is true only if they are several wavelengths apart and randomly spaced, or moving. But if they are right next to each other, they necessarily scatter in phase, and they have a coherent interference which produces an increase in the scattering. If we have N atoms in a lump, which is a tiny droplet of water, then each one will be driven by the electric field in about the same way as before (the effect of one atom on the other is not important; it is just to get the idea anyway) and the amplitude of scattering from each one is the same, so the total field which is scattered is N -fold increased. The intensity of the light which is scattered is then the square, or N 2 -fold, increased. We would have expected, if the atoms were spread out in space, only N times as much as 1 , whereas we get N 2 times as much as 1 ! That is to say, the scattering of water in lumps of N molecules each is N times more intense than the scattering of the single atoms. So as the water agglomerates the scattering increases. Does it increase ad infinitum? No! When does this analysis begin to fail? How many atoms can we put together before we cannot drive this argument any further? Answer: If the water drop gets so big that from one end to the other is a wavelength or so, then the atoms are no longer all in phase because they are too far apart. So as we keep increasing the size of the droplets we get more and more scattering, until such a time that a drop gets about the size of a wavelength, and then the scattering does not increase anywhere nearly as rapidly as the drop gets bigger. Furthermore, the blue disappears, because for long wavelengths the drops can be bigger, before this limit is reached, than they can be for short wavelengths. Although the short waves scatter more per atom than the long waves, there is a bigger enhancement for the red end of the spectrum than for the blue end when all the drops are bigger than the wavelength, so the color is shifted from the blue toward the red. Now we can make an experiment that demonstrates this. We can make particles that are very small at first, and then gradually grow in size. We use a solution of sodium thiosulfate (hypo) with sulfuric acid, which precipitates very fine grains of sulfur. As the sulfur precipitates, the grains first start very small, and the scattering is a little bluish. As it precipitates more it gets more intense, and then it will get whitish as the particles get bigger. In addition, the light which goes straight through will have the blue taken out. That is why the sunset is red, of course, because the light that comes through a lot of air, to the eye has had a lot of blue light scattered out, so it is yellow-red. Finally, there is one other important feature which really belongs in the next chapter, on polarization, but it is so interesting that we point it out now. This is that the electric field of the scattered light tends to vibrate in a particular direction. The electric field in the incoming light is oscillating in some way, and the driven oscillator goes in this same direction, and if we are situated about at right angles to the beam, we will see polarized light, that is to say, light in which the electric field is going only one way. In general, the atoms can vibrate in any direction at right angles to the beam, but if they are driven directly toward or away from us, we do not see it. So if the incoming light has an electric field which changes and oscillates in any direction, which we call unpolarized light, then the light which is coming out at 90 \u2218 to the beam vibrates in only one direction! (See Fig. 32\u20133.) There is a substance called polaroid which has the property that when light goes through it, only the piece of the electric field which is along one particular axis can get through. We can use this to test for polarization, and indeed we find the light scattered by the hypo solution to be strongly polarized."
    },
    {
        "input": "Magnetic Materials",
        "output": "In this chapter we will discuss the behavior and peculiarities of ferromagnetic materials and of other strange magnetic materials. Before proceeding to study magnetic materials, however, we will review very quickly some of the things about the general theory of magnets that we learned in the last chapter. First, we imagine the atomic currents inside the material that are responsible for the magnetism, and then describe them in terms of a volume current density jmag=\u2207\u00d7M . We emphasize that this is not supposed to represent the actual currents. When the magnetization is uniform the currents do not really cancel out precisely; that is, the whirling currents of one electron in one atom and the whirling currents of an electron in another atom do not overlap in such a way that the sum is exactly zero. Even within a single atom the distribution of magnetism is not smooth. For instance, in an iron atom the magnetization is distributed in a more or less spherical shell, not too close to the nucleus and not too far away. Thus, magnetism in matter is quite a complicated thing in its details; it is very irregular. However, we are obliged now to ignore this detailed complexity and discuss phenomena from a gross, average point of view. Then it is true that the average current in the interior region, over any finite area that is big compared with an atom, is zero when M is uniform. So, what we mean by magnetization per unit volume and jmag and so on, at the level we are now considering, is an average over regions that are large compared with the space occupied by a single atom. In the last chapter, we also discovered that a ferromagnetic material has the following interesting property: above a certain temperature it is not strongly magnetic, whereas below this temperature it becomes magnetic. This fact is easily demonstrated. A piece of nickel wire at room temperature is attracted by a magnet. However, if we heat it above its Curie temperature with a gas flame, it becomes nonmagnetic and is not attracted toward the magnet\u2014even when brought quite close to the magnet. If we let it lie near the magnet while it cools off, at the instant its temperature falls below the critical temperature it is suddenly attracted again by the magnet! The general theory of ferromagnetism that we will use supposes that the spin of the electron is responsible for the magnetization. The electron has spin one-half and carries one Bohr magneton of magnetic moment \u03bc= \u03bcB= qe\u210f/2m . The electron spin can be pointed either \u201cup\u201d or \u201cdown.\u201d Because the electron has a negative charge, when its spin is \u201cup\u201d it has a negative moment, and when its spin is \u201cdown\u201d it has a positive moment. With our usual conventions, the moment \u03bc of the electron is opposite its spin. We have found that the energy of orientation of a magnetic dipole in a given applied field B is \u2212\u03bc\u22c5B , but the energy of the spinning electrons depends on the neighboring spin alignments as well. In iron, if the moment of a nearby atom is \u201cup,\u201d there is a very strong tendency that the moment of the one next to it will also be \u201cup.\u201d That is what makes iron, cobalt, and nickel so strongly magnetic\u2014the moments all want to be parallel. The first question we have to discuss is why. Soon after the development of quantum mechanics, it was noticed that there is a very strong apparent force\u2014not a magnetic force or any other kind of actual force, but only an apparent force\u2014trying to line the spins of nearby electrons opposite to one another. These forces are closely related to chemical valence forces. There is a principle in quantum mechanics\u2014called the exclusion principle\u2014that two electrons cannot occupy exactly the same state, that they cannot be in exactly the same condition as to location and spin orientation.1 For example, if they are at the same point, the only alternative is to have their spins opposite. So, if there is a region of space between atoms where electrons like to congregate (as in a chemical bond) and we want to put another electron on top of one already there, the only way to do it is to have the spin of the second one pointed opposite to the spin of the first one. To have the spins parallel is against the law, unless the electrons stay away from each other. This has the effect that a pair of parallel-spin electrons near to each other have much more energy than a pair of opposite-spin electrons; the net effect is as though there were a force trying to turn the spin over. Sometimes this spin-turning force is called the exchange force, but that only makes it more mysterious\u2014it is not a very good term. It is just because of the exclusion principle that electrons have a tendency to make their spins opposite. In fact, that is the explanation of the lack of magnetism in almost all substances! The spins of the free electrons on the outside of the atoms have tremendous tendency to balance in opposite directions. The problem is to explain why for materials like iron it is just the reverse of what we should expect. We have summarized the supposed alignment effect by adding a suitable term in the energy equation, by saying that if the electron magnets in the neighborhood have a mean magnetization M , then the moment of an electron has a strong tendency to be in the same direction as the average magnetization of the atoms in the neighborhood. Thus, we may write for the two possible spin orientations,2 Spin \u201cup\u201d energy =+\u03bc(H+ \u03bbM \u03f50c2 ), Spin \u201cdown\u201d energy =\u2212\u03bc(H+ \u03bbM \u03f50c2 ). When it was clear that quantum mechanics could supply a tremendous spin-orientating force\u2014even if, apparently, of the wrong sign\u2014it was suggested that ferromagnetism might have its origin in this same force, that due to the complexities of iron and the large number of electrons involved, the sign of the interaction energy would come out the other way around. Since the time this was thought of\u2014in about 1927 when quantum mechanics was first being understood\u2014many people have been making various estimates and semicalculations, trying to get a theoretical prediction for \u03bb . The most recent calculations of the energy between the two electron spins in iron\u2014assuming that the interaction is a direct one between the two electrons in neighboring atoms\u2014still give the wrong sign. The present understanding of this is again to assume that the complexity of the situation is somehow responsible and to hope that the next man who makes the calculation with a more complicated situation will get the right answer! It is believed that the up-spin of one of the electrons in the inside shell, which is making the magnetism, tends to make the conduction electrons which fly around the outside have the opposite spin. One might expect this to happen because the conduction electrons come into the same region as the \u201cmagnetic\u201d electrons. Since they move around, they can carry their prejudice for being upside down over to the next atom; that is, one \u201cmagnetic\u201d electron tries to force the conduction electrons to be opposite, and the conduction electron then makes the next \u201cmagnetic\u201d electron opposite to it. The double interaction is equivalent to an interaction which tries to line up the two \u201cmagnetic\u201d electrons. In other words, the tendency to make parallel spins is the result of an intermediary that tends to some extent to be opposite to both. This mechanism does not require that the conduction electrons be completely \u201cupside down.\u201d They could just have a slight prejudice to be down, just enough to load the \u201cmagnetic\u201d odds the other way. This is the mechanism that the people who have calculated such things now believe is responsible for ferromagnetism. But we must emphasize that to this day nobody can calculate the magnitude of \u03bb simply by knowing that the material is number 26 in the periodic table. In short, we don\u2019t thoroughly understand it. Now let us continue with the theory, and then come back later to discuss a certain error involved in the way we have set it up. If the magnetic moment of a certain electron is \u201cup,\u201d energy comes both from the external field and also from the tendency of the spins to be parallel. Since the energy is lower when the spins are parallel, the effect is sometimes thought of as due to an \u201ceffective internal field.\u201d But remember, it is not due to a true magnetic force; it is an interaction that is more complicated. In any case, we take Eqs. (37.1) as the formulas for the energies of the two spin states of a \u201cmagnetic\u201d electron. At a temperature T , the relative probability of these two states is proportional to e\u2212energy/kT , which we can write as e\u00b1x , with x=\u03bc(H+\u03bbM/\u03f50c2)/kT . Then, if we calculate the mean value of the magnetic moment, we find (as in the last chapter) that it is M=N\u03bctanhx. Now we would like to calculate the internal energy of the material. We note that the energy of an electron is exactly proportional to the magnetic moment, so that the calculation of the mean moment and the calculation of the mean energy are the same\u2014except that in place of \u03bc in Eq. (37.2) we would write \u2212\u03bcB , which is \u2212\u03bc(H+\u03bbM/\u03f50c2) . The mean energy is then \u27e8U\u27e9av=\u2212N\u03bc(H+ \u03bbM \u03f50c2 )tanhx. Now this is not quite correct. The term \u03bbM/\u03f50c2 represents interactions of all possible pairs of atoms, and we must remember to count each pair only once. (When we consider the energy of one electron in the field of the rest and then the energy of a second electron in the field of the rest, we have counted part of the first energy once more.) Thus, we must divide the mutual interaction term by two, and our formula for the energy then turns out to be \u27e8U\u27e9av=\u2212N\u03bc(H+ \u03bbM 2\u03f50c2 )tanhx. In the last chapter we discovered an interesting thing\u2014that below a certain temperature the material finds a solution to the equations in which the magnetic moment is not zero, even with no external magnetizing field. When we set H=0 in Eq. (37.2), we found that M Msat =tanh( Tc T M Msat ), where Msat=N\u03bc , and Tc=\u03bc\u03bbMsat/k\u03f50c2 . When we solve this equation (graphically or otherwise), we find that the ratio M/Msat as a function of T/Tc is a curve like that labeled \u201cquantum theory\u201d in Fig. 37\u20131. The dashed curve marked \u201ccobalt, nickel\u201d shows the experimental results for crystals of these elements. The theory and experiment are in reasonably good agreement. The figure also shows the result of the classical theory in which the calculation is carried out assuming that the atomic magnets can have all possible orientations in space. You can see that this assumption gives a prediction that is not even close to the experimental facts. Even the quantum theory deviates from the observed behavior at both high and low temperatures. The reason for the deviations is that we have made a rather sloppy approximation in the theory: We have assumed that the energy of an atom depends upon the mean magnetization of its neighboring atoms. In other words, for each one that is \u201cup\u201d in the neighborhood of a given atom, there will be a contribution of energy due to that quantum mechanical alignment effect. But how many are there pointed \u201cup\u201d? On the average, that is measured by the magnetization M \u2014but only on the average. A particular atom somewhere might find all its neighbors \u201cup.\u201d Then its energy will be larger than the average. Another one might find some up and some down, perhaps averaging to zero, and it would have no energy from that term, and so on. What we ought to do is to use some more complicated kind of average, because the atoms in different places have different environments, and the numbers up and down are different for different ones. Instead of just taking one atom subjected to the average influence, we should take each one in its actual situation, compute its energy, and find the average energy. But how do we find out how many are \u201cup\u201d and how many are \u201cdown\u201d in the neighborhood? That is, of course, just what we are trying to calculate\u2014the number \u201cup\u201d and \u201cdown\u201d\u2014so we have a very complicated interconnected problem of correlations, a problem which has never been solved. It is an intriguing and exciting one which has existed for years and on which some of the greatest names in physics have written papers, but even they have not completely solved it. It turns out that at low temperatures, when almost all the atomic magnets are \u201cup\u201d and only a few are \u201cdown,\u201d it is easy to solve; and at high temperatures, far above the Curie temperature Tc when they are almost all random, it is again easy. It is often easy to calculate small departures from some simple, idealized situation, so it is fairly well understood why there are deviations from the simple theory at low temperature. It is also understood physically that for statistical reasons the magnetization should deviate at high temperatures. But the exact behavior near the Curie point has never been thoroughly figured out. That\u2019s an interesting problem to work out some day if you want a problem that has never been solved. In the last chapter we laid the groundwork necessary for calculating the thermodynamic properties of ferromagnetic materials. These are, naturally, related to the internal energy of the crystal, which includes interactions of the various spins, given by Eq. (37.3). For the energy of the spontaneous magnetization below the Curie point, we can set H=0 in Eq. (37.3), and\u2014noticing that tanhx=M/Msat \u2014we find a mean energy proportional to M2 : \u27e8U\u27e9av=\u2212 N\u03bc\u03bbM2 2\u03f50c2Msat . If we now plot the energy due to the magnetism as a function of temperature, we get a curve which is the negative of the square of the curve of Fig. 37\u20131, as drawn in Fig. 37\u20132(a). If we were to measure then the specific heat of such a material we would obtain a curve which is the derivative of 37\u20132(a). It is shown in Fig. 37\u20132(b). It rises slowly with increasing temperature, but falls suddenly to zero at T=Tc . The sharp drop is due to the change in slope of the magnetic energy and is reached right at the Curie point. So without any magnetic measurements at all we could have discovered that something was going on inside of iron or nickel by measuring this thermodynamic property. However, both experiment and improved theory (with fluctuations included) suggest that this simple curve is wrong and that the true situation is really more complicated. The curve goes higher at the peak and falls to zero somewhat slowly. Even if the temperature is high enough to randomize the spins on the average, there are still local regions where there is a certain amount of polarization, and in these regions the spins still have a little extra energy of interaction\u2014which only dies out slowly as things get more and more random with further increases in temperature. So the actual curve looks like Fig. 37\u20132(c). One of the challenges of theoretical physics today is to find an exact theoretical description of the character of the specific heat near the Curie transition\u2014an intriguing problem which has not yet been solved. Naturally, this problem is very closely related to the shape of the magnetization curve in the same region. Now we want to describe some experiments, other than thermodynamic ones, which show that there is something right about our interpretation of magnetism. When the material is magnetized to saturation at low enough temperatures, M is very nearly equal to Msat \u2014nearly all the spins are parallel, as well as their magnetic moments. We can check this by an experiment. Suppose we suspend a bar magnet by a thin fiber and then surround it by a coil so that we can reverse the magnetic field without touching the magnet or putting any torque on it. This is a very difficult experiment because the magnetic forces are so enormous that any irregularities, any lopsidedness, or any lack of perfection in the iron will produce accidental torques. However, the experiment has been done under careful conditions in which such accidental torques are minimized. By means of the magnetic field from a coil that surrounds the bar, we turn all the atomic magnets over at once. When we do this we also change the angular momenta of all the spins from \u201cup\u201d to \u201cdown\u201d (see Fig. 37\u20133). If angular momentum is to be conserved when the spins all turn over, the rest of the bar must have an opposite change in angular momentum. The whole magnet will start to spin. And sure enough, when we do the experiment, we find a slight turning of the magnet. We can measure the total angular momentum given to the whole magnet, and this is simply N times \u210f , the change in the angular momentum of each spin. The ratio of angular momentum to magnetic moment measured this way comes out to within about 10 percent of what we calculate. Actually, our calculations assume that the atomic magnets are due purely to the electron spin, but there is, in addition, some orbital motion also in most materials. The orbital motion is not completely free of the lattice and does not contribute much more than a few percent to the magnetism. As a matter of fact, the saturation magnetic field that one gets taking Msat=N\u03bc and using the density of iron of 7.9 and the moment \u03bc of the spinning electron is about 20,000 gauss. But according to experiment, it is actually in the neighborhood of 21,500 gauss. This is a typical magnitude of error\u20145 or 10 percent\u2014due to neglecting the contributions of the orbital moments that have not been included in making the analysis. Thus, a slight discrepancy with the gyromagnetic measurements is quite understandable. We have concluded from our theoretical analysis that a ferromagnetic material should spontaneously become magnetized below a certain temperature so that all the magnetism would be in the same direction. But we know that this is not true for an ordinary piece of unmagnetized iron. Why isn\u2019t all iron magnetized? We can explain it with the help of Fig. 37\u20134. Suppose the iron were all a big single crystal of the shape shown in Fig. 37\u20134(a) and spontaneously magnetized all in one direction. Then there would be a considerable external magnetic field, which would have a lot of energy. We can reduce that field energy if we arrange that one side of the block is magnetized \u201cup\u201d and the other side magnetized \u201cdown,\u201d as in Fig. 37\u20134(b). Then, of course, the fields outside the iron would extend over less volume, so there would be less energy there. Ah, but wait! In the layer between the two regions we have up-spinning electrons adjacent to down-spinning electrons. But ferromagnetism appears only in those materials for which the energy is reduced if the electrons are parallel rather than opposite. So, we have added some extra energy along the dotted line in Fig. 37\u20134(b); this energy is sometimes called wall energy. A region having only one direction of magnetization is called a domain. At the interface\u2014the \u201cwall\u201d\u2014between two domains, where we have atoms on opposite sides which are spinning in different directions, there is an energy per unit area of the wall. We have described it as though two adjacent atoms were spinning exactly opposite, but it turns out that nature adjusts things so that the transition is more gradual. But we don\u2019t need to worry about such fine details at this point. Now the question is: When is it better or worse to make a wall? The answer is that it depends on the size of the domains. Suppose that we were to scale up a block so that the whole thing was twice as big. The volume in the space outside filled with a given magnetic field strength would be eight times bigger, and the energy in the magnetic field, which is proportional to the volume, would also be eight times greater. But the surface area between two domains, which will give the wall energy, would be only four times as big. Therefore, if the piece of iron is big enough, it will pay to split it into more domains. This is why only the very tiny crystals can have but a single domain. Any large object\u2014one more than about a hundredth of a millimeter in size\u2014will have at least one domain wall; and any ordinary, \u201ccentimeter-size\u201d object will be split into many domains, as shown in the figure. Splitting into domains goes on until the energy needed to put in one extra wall is as large as the energy decrease in the magnetic field outside the crystal. Actually nature has discovered still another way to lower the energy: It is not necessary to have the field go outside at all, if a little triangular region is magnetized sideways, as in Fig. 37\u20134(d).3 Then with the arrangement of Fig. 37\u20134(d) we see that there is no external field, but instead only a little more domain wall. But that introduces a new kind of problem. It turns out that when a single crystal of iron is magnetized, it changes its length in the direction of magnetization, so an \u201cideal\u201d cube with its magnetization, say, \u201cup,\u201d is no longer a perfect cube. The \u201cvertical\u201d dimension will be different from the \u201chorizontal\u201d dimension. This effect is called magnetostriction. Because of such geometric changes, the little triangular pieces of Fig. 37\u20134(d) do not, so to speak, \u201cfit\u201d into the available space anymore\u2014the crystal has got too long one way and too short the other way. Of course, it does fit, really, but only by being squashed in; and this involves some mechanical stresses. So, this arrangement also introduces an extra energy. It is the balance of all these various energies which determines how the domains finally arrange themselves in their complicated fashion in a piece of unmagnetized iron. Now, what happens when we put on an external magnetic field? To take a simple case, consider a crystal whose domains are as shown in Fig. 37\u20134(d). If we apply an external magnetic field in the upward direction, in what manner does the crystal become magnetized? First, the middle domain wall can move over sideways (to the right) and reduce the energy. It moves over so that the region which is \u201cup\u201d becomes bigger than the region which is \u201cdown.\u201d There are more elementary magnets lined up with the field, and this gives a lower energy. So, for a piece of iron in weak fields\u2014at the very beginning of magnetization\u2014the domain walls begin to move and eat into the regions which are magnetized opposite to the field. As the field continues to increase, a whole crystal shifts gradually into a single large domain which the external field helps to keep lined up. In a strong field the crystal \u201clikes\u201d to be all one way just because its energy in the applied field is reduced\u2014it is no longer merely the crystal\u2019s own external field which matters. What if the geometry is not so simple? What if the axes of the crystal and its spontaneous magnetization are in one direction, but we apply the magnetic field in some other direction\u2014say at 45 \u2218 ? We might think that domains would reform themselves with their magnetization parallel to the field, and then as before, they could all grow into one domain. But this is not easy for the iron to do, for the energy needed to magnetize a crystal depends on the direction of magnetization relative to the crystal axis. It is relatively easy to magnetize iron in a direction parallel to the crystal axes, but it takes more energy to magnetize it in some other direction\u2014like 45 \u2218 with respect to one of the axes. Therefore, if we apply a magnetic field in such a direction, what happens first is that the domains which point along one of the preferred directions which is near to the applied field grow until the magnetization is all along one of these directions. Then with much stronger fields, the magnetization is gradually pulled around parallel to the field, as sketched in Fig. 37\u20135. In Fig. 37\u20136 are shown some observations of the magnetization curves of single crystals of iron. To understand them, we must first explain something about the notation that is used in describing directions in a crystal. There are many ways in which a crystal can be sliced so as to produce a face which is a plane of atoms. Everyone who has driven past an orchard or vineyard knows this\u2014it is fascinating to watch. If you look one way, you see lines of trees\u2014if you look another way, you see different lines of trees, and so on. In a similar way, a crystal has definite families of planes that hold many atoms, and the planes have this important characteristic (we consider a cubic crystal to make it easier): If we observe where the planes intersect the three coordinate axes\u2014we find that the reciprocals of the three distances from the origin are in the ratio of simple whole numbers. These three whole numbers are taken as the definition of the planes. For example, in Fig. 37\u20137(a), a plane parallel to the yz -plane is shown. This is called a [100] plane; the reciprocals of its intersection of the y - and z -axes are both zero. The direction perpendicular to such a plane (in a cubic crystal) is given the same set of numbers. It is easy to understand the idea in a cubic crystal, for then the indices [100] mean a vector which has a unit component in the x -direction and none in the y - or z -directions. The [110] direction is in a direction 45 \u2218 from the x - and y -axes, as in Fig. 37\u20137(b); and the [111] direction is in the direction of the cube diagonal, as in Fig. 37\u20137(c). Returning now to Fig. 37\u20136, we see the magnetization curves of a single crystal of iron for various directions. First, note that for very tiny fields\u2014so weak that it is hard to see them on the scale at all\u2014the magnetization increases extremely rapidly to quite large values. If the field is in the [100] direction\u2014namely along one of those nice, easy directions of magnetization\u2014the curve goes up to a high value, curves around a little, and then is saturated. What happened is that the domains which were already there are very easily removed. Only a small field is required to make the domain walls move and eat up all of the \u201cwrong-way\u201d domains. Single crystals of iron are enormously permeable (magnetic sense), much more so than ordinary polycrystalline iron. A perfect crystal magnetizes extremely easily. Why is it curved at all? Why doesn\u2019t it just go right up to saturation? We are not sure. You might study that some day. We do understand why it is flat for high fields. When the whole block is a single domain, the extra magnetic field cannot make any more magnetization\u2014it is already at M sat , with all the electrons lined up. Now, if we try to do the same thing in the [110] direction\u2014which is at 45 \u2218 to the crystal axes\u2014what will happen? We turn on a little bit of field and the magnetization leaps up as the domains grow. Then as we increase the field some more, we find that it takes quite a lot of field to get up to saturation, because now the magnetization is turning away from an \u201ceasy\u201d direction. If this explanation is correct, the point at which the [110] curve extrapolates back to the vertical axis should be at 1/ 2 \u2013 \u221a of the saturation value. It turns out, in fact, to be very, very close to 1/ 2 \u2013 \u221a . Similarly, in the [111] direction\u2014which is along the cube diagonal\u2014we find, as we would expect, that the curve extrapolates back to nearly 1/ 3 \u2013 \u221a of saturation. Figure 37\u20138 shows the corresponding situation for two other materials, nickel and cobalt. Nickel is different from iron. In nickel, it turns out that the [111] direction is the easy direction of magnetization. Cobalt has a hexagonal crystal form, and people have botched up the system of nomenclature for this case. They want to have three axes on the bottom of the hexagon and one perpendicular to these, so they have used four indices. The [0001] direction is the direction of the axis of the hexagon, and [1010] is perpendicular to that axis. We see that crystals of different metals behave in different ways. Now we must discuss a polycrystalline material, such as an ordinary piece of iron. Inside such materials there are many, many little crystals with their crystalline axes pointing every which way. These are not the same as domains. Remember that the domains were all part of a single crystal, but in a piece of iron there are many different crystals with axes at different orientations, as shown in Fig. 37\u20139. Within each of these crystals, there will also generally be some domains. When we apply a small magnetic field to a piece of polycrystalline material, what happens is that the domain walls begin to move, and the domains which have a favorable direction of easy magnetization grow larger. This growth is reversible so long as the field stays very small\u2014if we turn the field off, the magnetization will return to zero. This part of the magnetization curve is marked a in Fig. 37\u201310. For larger fields\u2014in the region b of the magnetization curve shown\u2014things get much more complicated. In every small crystal of the material, there are strains and dislocations; there are impurities, dirt, and imperfections. And at all but the smallest fields, the domain wall, in moving, gets stuck on these. There is an interaction energy between the domain wall and a dislocation, or a grain boundary, or an impurity. So when the wall gets to one of them, it gets stuck; it sticks there at a certain field. But then if the field is raised some more, the wall suddenly snaps past. So the motion of the domain wall is not smooth the way it is in a perfect crystal\u2014it gets hung up every once in a while and moves in jerks. If we were to look at the magnetization on a microscopic scale, we would see something like the insert of Fig. 37\u201310. Now the important thing is that these jerks in the magnetization can cause an energy loss. In the first place, when a boundary finally slips past an impediment, it moves very quickly to the next one, since the field is already above what would be required for the unimpeded motion. The rapid motion means that there are rapidly changing magnetic fields which produce eddy currents in the crystal. These currents lose energy in heating the metal. A second effect is that when a domain suddenly changes, part of the crystal changes its dimensions from the magnetostriction. Each sudden shift of a domain wall sets up a little sound wave that carries away energy. Because of such effects, the second part of magnetization curve is irreversible, and there is energy being lost. This is the origin of the hysteresis effect, because to move a boundary wall forward\u2014snap\u2014and then to move it backward\u2014snap\u2014produces a different result. It\u2019s like \u201cjerky\u201d friction, and it takes energy. Eventually, for high enough fields, when we have moved all the domain walls and magnetized each crystal in its best direction, there are still some crystallites which happen to have their easy directions of magnetization not in the direction of our external magnetic field. Then it takes a lot of extra field to turn those magnetic moments around. So the magnetization increases slowly, but smoothly, for high fields\u2014namely in the region marked c in the figure. The magnetization does not come sharply to its saturation value, because in the last part of the curve the atomic magnets are turning in the strong field. So we see why the magnetization curve of ordinary polycrystalline materials, such as the one shown in Fig. 37\u201310, rises a little bit and reversibly at first, then rises irreversibly, and then curves over slowly. Of course, there is no sharp break-point between the three regions\u2014they blend smoothly, one into the other. It is not hard to show that the magnetization process in the middle part of the magnetization curve is jerky\u2014that the domain walls jerk and snap as they shift. All you need is a coil of wire\u2014with many thousands of turns\u2014connected to an amplifier and a loudspeaker, as shown in Fig. 37\u201311. If you put a few silicon steel sheets (of the type used in transformers) at the center of the coil and bring a bar magnet slowly near the stack, the sudden changes in magnetization will produce impulses of emf in the coil, which are heard as distinct clicks in the loudspeaker. As you move the magnet nearer to the iron you will hear a whole rush of clicks that sound something like the noise of sand grains falling over each other as a can of sand is tilted. The domain walls are jumping, snapping, and jiggling as the field is increased. This phenomenon is called the Barkhausen effect. As you move the magnet even closer to the iron sheets, the noise grows louder and louder for a while but then there is relatively little noise when the magnet gets very close. Why? Because nearly all the domain walls have moved as far as they can go. Any greater field is merely turning the magnetization in each domain, which is a smooth process. If you now withdraw the magnet, so as to come back on the downward branch of the hysteresis loop, the domains all try to get back to low energy again, and you hear another rush of backward-going jerks. You can also note that if you bring the magnet to a given place and move it back and forth a little bit, there is relatively little noise. It is again like tilting a can of sand\u2014once the grains shift into place, small movements of the can don\u2019t disturb them. In the iron the small variations in the magnetic field aren\u2019t enough to move any boundaries over any of the \u201chumps.\u201d Now we would like to talk about the various kinds of magnetic materials that there are in the technical world and to consider some of the problems involved in designing magnetic materials for different purposes. First, the term \u201cthe magnetic properties of iron,\u201d which one often hears, is a misnomer\u2014there is no such thing. \u201cIron\u201d is not a well-defined material\u2014the properties of iron depend critically on the amount of impurities and also on how the iron is formed. You can appreciate that the magnetic properties will depend on how easily the domain walls move and that this is a gross property, not a property of the individual atoms. So practical ferromagnetism is not really a property of an iron atom\u2014it is a property of solid iron in a certain form. For example, iron can take on two different crystalline forms. The common form has a body-centered cubic lattice, but it can also have a face-centered cubic lattice, which is, however, stable only at temperatures above 900 \u2218 C. Of course, at that temperature the body-centered cubic structure is already past the Curie point. However, by alloying chromium and nickel with the iron (one possible mixture is 18 percent chromium and 8 percent nickel) we can get what is called stainless steel, which, although it is mainly iron, retains the face-centered lattice even at low temperatures. Because its crystal structure is different, it has completely different magnetic properties. Most kinds of stainless steel are not magnetic to any appreciable degree, although there are some kinds which are somewhat magnetic\u2014it depends on the composition of the alloy. Even when such an alloy is magnetic, it is not ferromagnetic like ordinary iron\u2014even though it is mostly just iron. We would like now to describe a few of the special materials which have been developed for their particular magnetic properties. First, if we want to make a permanent magnet, we would like material with an enormously wide hysteresis loop so that, when we turn the current off and come down to zero magnetizing field, the magnetization will remain large. For such materials the domain boundaries should be \u201cfrozen\u201d in place as much as possible. One such material is the remarkable alloy \u201cAlnico V\u201d ( 51% Fe, 8% Al, 14% Ni, 24% Co, 3% Cu). (The rather complex composition of this alloy is indicative of the kind of detailed effort that has gone into making good magnets. What patience it takes to mix five things together and test them until you find the most ideal substance!) When Alnico solidifies, there is a \u201csecond phase\u201d which precipitates out, making many tiny grains and very high internal strains. In this material, the domain boundaries have a hard time moving at all. In addition to having a precise composition, Alnico is mechanically \u201cworked\u201d in a way that makes the crystals appear in the form of long grains along the direction in which the magnetization is going to be. Then the magnetization will have a natural tendency to be lined up in these directions and will be held there from the anisotropic effects. Furthermore, the material is even cooled in an external magnetic field when it is manufactured, so that the grains will grow with the right crystal orientation. The hysteresis loop of Alnico V is shown in Fig. 37\u201312. You see that it is about 700 times wider than the hysteresis curve for soft iron that we showed in the last chapter in Fig. 36\u20138. Let\u2019s turn now to a different kind of material. For building transformers and motors, we want a material which is magnetically \u201csoft\u201d\u2014one in which the magnetism is easily changed so that an enormous amount of magnetization results from a very small applied field. To arrange this, we need pure, well-annealed material which will have very few dislocations and impurities so that the domain walls can move easily. It would also be nice if we could make the anisotropy small. Then, even if a grain of the material sits at the wrong angle with respect to the field, it will still magnetize easily. Now we have said that iron prefers to magnetize along the [100] direction, whereas nickel prefers the [111] direction; so if we mix iron and nickel in various proportions, we might hope to find that with just the right proportions the alloy wouldn\u2019t prefer any direction\u2014the [100] and [111] directions would be equivalent. It turns out that this happens with a mixture of 70 percent nickel and 30 percent iron. In addition\u2014possibly by luck or maybe because of some physical relationship between the anisotropy and the magnetostriction effects\u2014it turns out that the magnetostriction of iron and nickel has the opposite sign. And in an alloy of the two metals, this property goes through zero at about 80 percent nickel. So somewhere between 70 and 80 percent nickel we get very \u201csoft\u201d magnetic materials\u2014alloys that are very easy to magnetize. They are called the permalloys. Permalloys are useful for high-quality transformers (at low signal levels), but they would be no good at all for permanent magnets. Permalloys must be very carefully made and handled. The magnetic properties of a piece of permalloy are drastically changed if it is stressed beyond its elastic limit\u2014it mustn\u2019t be bent. Then, its permeability is reduced because of the dislocations, slip bands, and so on, which are produced by the mechanical deformations. The domain boundaries are no longer easy to move. The high permeability can, however, be restored by annealing at high temperatures. It is often convenient to have some numbers to characterize the various magnetic materials. Two useful numbers are the intercepts of the hysteresis loop with the B - and H -axes, as indicated in Fig. 37\u201312. These intercepts are called the remanent magnetic field B r and the coercive force H c . In Table 37\u20131 we list these numbers for a few magnetic materials. We would now like to discuss some of the more exotic magnetic materials. There are many elements in the periodic table which have incomplete inner electron shells and hence have atomic magnetic moments. For instance, right next to the ferromagnetic elements iron, nickel, and cobalt you will find chromium and manganese. Why aren\u2019t they ferromagnetic? The answer is that the \u03bb term in Eq. (37.1) has the opposite sign for these elements. In the chromium lattice, for example, the spins of the chromium atoms alternate atom by atom, as shown in Fig. 37\u201313(b). So chromium is \u201cmagnetic\u201d from its own point of view, but it is not technically interesting because there are no external magnetic effects. Chromium, then, is an example of a material in which quantum mechanical effects make the spins alternate. Such a material is called antiferromagnetic. The alignment in antiferromagnetic materials is also temperature dependent. Below a critical temperature, all the spins are lined up in the alternating array, but when the material is heated above a certain temperature\u2014which is again called the Curie temperature\u2014the spins suddenly become random. There is, internally, a sudden transition. This transition can be seen in the specific heat curve. Also it shows up in some special \u201cmagnetic\u201d effects. For instance, the existence of the alternating spins can be verified by scattering neutrons from a crystal of chromium. Because a neutron itself has a spin (and a magnetic moment), it has a different amplitude to be scattered, depending on whether its spin is parallel or opposite to the spin of the scatterer. Thus, we get a different interference pattern when the spins in a crystal are alternating than we do when they have a random distribution. There is another kind of substance in which quantum mechanical effects make the electron spins alternate, but which is nevertheless ferromagnetic\u2014that is, the crystal has a permanent net magnetization. The idea behind such materials is shown in Fig. 37\u201314. The figure shows the crystal structure of spinel, a magnesium-aluminum oxide, which\u2014as it is shown\u2014is not magnetic. The oxide has two kinds of metal atoms: magnesium and aluminum. Now if we replace the magnesium and the aluminum by two magnetic elements like iron and zinc, or by zinc and manganese\u2014in other words, if we put in magnetic atoms instead of the nonmagnetic ones\u2014an interesting thing happens. Let\u2019s call one kind of metal atom a and the other kind of metal atom b ; then the following combination of forces must be considered. There is an a - b interaction which tries to make the a atoms and the b atoms have opposite spins\u2014because quantum mechanics always gives the opposite sign (except for the mysterious crystals of iron, nickel, and cobalt). Then, there is a direct a - a interaction which tries to make the a \u2019s opposite, and also a b - b interaction which tries to make the b \u2019s opposite. Now, of course we cannot have everything opposite everything else\u2014 a opposite b , a opposite a , and b opposite b . Presumably because of the distances between the a \u2019s and the presence of the oxygen (although we really don\u2019t know why), it turns out that the a - b interaction is stronger than the a - a or the b - b . So the solution that nature uses in this case is to make all the a \u2019s parallel to each other, and all the b \u2019s parallel to each other, but the two systems opposite. That gives the lowest energy because of the stronger a - b interaction. The result: all the a \u2019s are spinning up and all the b \u2019s are spinning down\u2014or vice versa, of course. But if the magnetic moments of the a -type atom and the b -type atom are not equal, we can get the situation shown in Fig. 37\u201313(c), and there can be a net magnetization in the material. The material will then be ferromagnetic\u2014although somewhat weak. Such materials are called ferrites. They do not have as high a saturation magnetization as iron\u2014for obvious reasons\u2014so they are only useful for smaller fields. But they have a very important difference\u2014they are insulators; the ferrites are ferromagnetic insulators. In high-frequency fields, they will have very small eddy currents and so can be used, for example, in microwave systems. The microwave fields will be able to get inside such an insulating material, whereas they would be kept out by the eddy currents in a conductor like iron. There is another class of magnetic materials which has only recently been discovered\u2014members of the family of the orthosilicates called garnets. They are again crystals in which the lattice contains two kinds of metallic atoms, and we have again a situation in which two kinds of atoms can be substituted almost at will. Among the many compounds of interest there is one which is completely ferromagnetic. It has yttrium and iron in the garnet structure, and the reason it is ferromagnetic is very curious. Here again quantum mechanics is making the neighboring spins opposite, so that there is a locked-in system of spins with the electron spins of the iron one way and the electron spins of the yttrium the opposite way. But the yttrium atom is complicated. It is a rare-earth element and gets a large contribution to its magnetic moment from orbital motion of the electrons. For yttrium, the orbital motion contribution is opposite that of the spin and also is bigger. Thus, although quantum mechanics, working through the exclusion principle, makes the spins of the yttrium opposite those of the iron, it makes the total magnetic moment of the yttrium atom parallel to the iron because of the orbital effect\u2014as sketched in Fig. 37\u201313(d). The compound is therefore a regular ferromagnet. Another interesting example of ferromagnetism occurs in some of the rare-earth elements. It has to do with a still more peculiar arrangement of the spins. The material is not ferromagnetic in the sense that the spins are all parallel, nor is it antiferromagnetic in the sense that every atom is opposite. In these crystals all of the spins in one layer are parallel and lie in the plane of the layer. In the next layer all spins are again parallel to each other, but point in a somewhat different direction. In the following layer they are in still another direction, and so on. The result is that the local magnetization vector varies in the form of a spiral\u2014the magnetic moments of the successive layers rotate as we proceed along a line perpendicular to the layers. It is interesting to try to analyze what happens when a field is applied to such a spiral\u2014all the twistings and turnings that must go on in all those atomic magnets. (Some people like to amuse themselves with the theory of these things!) Not only are there cases of \u201cflat\u201d spirals, but there are also cases in which the directions the magnetic moments of successive layers map out a cone, so that it has a spiral component and also a uniform ferromagnetic component in one direction! The magnetic properties of materials, worked out on a more advanced level than we have been able to do here, have fascinated physicists of all kinds. In the first place, there are those practical people who love to work out ways of making things in a better way\u2014they love to design better and more interesting magnetic materials. The discovery of things like ferrites, or their application, immediately delights people who like to see clever new ways of doing things. Besides this, there are those who find a fascination in the terrible complexity that nature can produce using a few basic laws. Starting with one and the same general idea, nature goes from the ferromagnetism of iron and its domains, to the antiferromagnetism of chromium, to the magnetism of ferrites and garnets, to the spiral structure of the rare earth elements, and on, and on. It is fascinating to discover experimentally all the strange things that go on in these special substances. Then, to the theoretical physicists, ferromagnetism presents a number of very interesting, unsolved, and beautiful challenges. One challenge is to understand why it exists at all. Another is to predict the statistics of the interacting spins in an ideal lattice. Even neglecting any possible extraneous complications, this problem has, so far, defied full understanding. The reason that it is so interesting is that it is such an easily stated problem: Given a lot of electron spins in a regular lattice, interacting with such-and-such a law, what do they do? It is simply stated, but it has defied complete analysis for years. Although it has been analyzed rather carefully for temperatures not too close to the Curie point, the theory of the sudden transition at the Curie point still needs to be completed. Finally, the whole subject of the system of spinning atomic magnets\u2014in ferromagnetic, or in paramagnetic materials and in nuclear magnetism, has also been a fascinating thing to advanced students in physics. The system of spins can be pushed on and pulled on with external magnetic fields, so one can do many tricks with resonances, with relaxation effects, with spin-echoes, and with other effects. It serves as a prototype of many complicated thermodynamic systems. But in paramagnetic materials the situation is often fairly simple, and people have been delighted both to do experiments and to explain the phenomena theoretically. We now close our study of electricity and magnetism. In the first chapter, we spoke of the great strides that have been made since the early Greek observation of the strange behaviors of amber and of lodestone. Yet in all our long and involved discussion we have never explained why it is that when we rub a piece of amber we get a charge on it, nor have we explained why a lodestone is magnetized! You may say, \u201cOh, we just didn\u2019t get the right sign.\u201d No, it is worse than that. Even if we did get the right sign, we would still have the question: Why is the piece of lodestone in the ground magnetized? There is the earth\u2019s magnetic field, of course, but where does the earth\u2019s field come from? Nobody really knows\u2014there have only been some good guesses. So you see, this physics of ours is a lot of fakery\u2014we start out with the phenomena of lodestone and amber, and we end up not understanding either of them very well. But we have learned a tremendous amount of very exciting and very practical information in the process!"
    },
    {
        "input": "Atoms in Motion",
        "output": "This two-year course in physics is presented from the point of view that you, the reader, are going to be a physicist. This is not necessarily the case of course, but that is what every professor in every subject assumes! If you are going to be a physicist, you will have a lot to study: two hundred years of the most rapidly developing field of knowledge that there is. So much knowledge, in fact, that you might think that you cannot learn all of it in four years, and truly you cannot; you will have to go to graduate school too! Surprisingly enough, in spite of the tremendous amount of work that has been done for all this time it is possible to condense the enormous mass of results to a large extent\u2014that is, to find laws which summarize all our knowledge. Even so, the laws are so hard to grasp that it is unfair to you to start exploring this tremendous subject without some kind of map or outline of the relationship of one part of the subject of science to another. Following these preliminary remarks, the first three chapters will therefore outline the relation of physics to the rest of the sciences, the relations of the sciences to each other, and the meaning of science, to help us develop a \u201cfeel\u201d for the subject. You might ask why we cannot teach physics by just giving the basic laws on page one and then showing how they work in all possible circumstances, as we do in Euclidean geometry, where we state the axioms and then make all sorts of deductions. (So, not satisfied to learn physics in four years, you want to learn it in four minutes?) We cannot do it in this way for two reasons. First, we do not yet know all the basic laws: there is an expanding frontier of ignorance. Second, the correct statement of the laws of physics involves some very unfamiliar ideas which require advanced mathematics for their description. Therefore, one needs a considerable amount of preparatory training even to learn what the words mean. No, it is not possible to do it that way. We can only do it piece by piece. Each piece, or part, of the whole of nature is always merely an approximation to the complete truth, or the complete truth so far as we know it. In fact, everything we know is only some kind of approximation, because we know that we do not know all the laws as yet. Therefore, things must be learned only to be unlearned again or, more likely, to be corrected. The principle of science, the definition, almost, is the following: The test of all knowledge is experiment. Experiment is the sole judge of scientific \u201ctruth.\u201d But what is the source of knowledge? Where do the laws that are to be tested come from? Experiment, itself, helps to produce these laws, in the sense that it gives us hints. But also needed is imagination to create from these hints the great generalizations\u2014to guess at the wonderful, simple, but very strange patterns beneath them all, and then to experiment to check again whether we have made the right guess. This imagining process is so difficult that there is a division of labor in physics: there are theoretical physicists who imagine, deduce, and guess at new laws, but do not experiment; and then there are experimental physicists who experiment, imagine, deduce, and guess. We said that the laws of nature are approximate: that we first find the \u201cwrong\u201d ones, and then we find the \u201cright\u201d ones. Now, how can an experiment be \u201cwrong\u201d? First, in a trivial way: if something is wrong with the apparatus that you did not notice. But these things are easily fixed, and checked back and forth. So without snatching at such minor things, how can the results of an experiment be wrong? Only by being inaccurate. For example, the mass of an object never seems to change: a spinning top has the same weight as a still one. So a \u201claw\u201d was invented: mass is constant, independent of speed. That \u201claw\u201d is now found to be incorrect. Mass is found to increase with velocity, but appreciable increases require velocities near that of light. A true law is: if an object moves with a speed of less than one hundred miles a second the mass is constant to within one part in a million. In some such approximate form this is a correct law. So in practice one might think that the new law makes no significant difference. Well, yes and no. For ordinary speeds we can certainly forget it and use the simple constant-mass law as a good approximation. But for high speeds we are wrong, and the higher the speed, the more wrong we are. Finally, and most interesting, philosophically we are completely wrong with the approximate law. Our entire picture of the world has to be altered even though the mass changes only by a little bit. This is a very peculiar thing about the philosophy, or the ideas, behind the laws. Even a very small effect sometimes requires profound changes in our ideas. Now, what should we teach first? Should we teach the correct but unfamiliar law with its strange and difficult conceptual ideas, for example the theory of relativity, four-dimensional space-time, and so on? Or should we first teach the simple \u201cconstant-mass\u201d law, which is only approximate, but does not involve such difficult ideas? The first is more exciting, more wonderful, and more fun, but the second is easier to get at first, and is a first step to a real understanding of the first idea. This point arises again and again in teaching physics. At different times we shall have to resolve it in different ways, but at each stage it is worth learning what is now known, how accurate it is, how it fits into everything else, and how it may be changed when we learn more. Let us now proceed with our outline, or general map, of our understanding of science today (in particular, physics, but also of other sciences on the periphery), so that when we later concentrate on some particular point we will have some idea of the background, why that particular point is interesting, and how it fits into the big structure. So, what is our overall picture of the world? If, in some cataclysm, all of scientific knowledge were to be destroyed, and only one sentence passed on to the next generations of creatures, what statement would contain the most information in the fewest words? I believe it is the atomic hypothesis (or the atomic fact, or whatever you wish to call it) that all things are made of atoms\u2014little particles that move around in perpetual motion, attracting each other when they are a little distance apart, but repelling upon being squeezed into one another. In that one sentence, you will see, there is an enormous amount of information about the world, if just a little imagination and thinking are applied. To illustrate the power of the atomic idea, suppose that we have a drop of water a quarter of an inch on the side. If we look at it very closely we see nothing but water\u2014smooth, continuous water. Even if we magnify it with the best optical microscope available\u2014roughly two thousand times\u2014then the water drop will be roughly forty feet across, about as big as a large room, and if we looked rather closely, we would still see relatively smooth water\u2014but here and there small football-shaped things swimming back and forth. Very interesting. These are paramecia. You may stop at this point and get so curious about the paramecia with their wiggling cilia and twisting bodies that you go no further, except perhaps to magnify the paramecia still more and see inside. This, of course, is a subject for biology, but for the present we pass on and look still more closely at the water material itself, magnifying it two thousand times again. Now the drop of water extends about fifteen miles across, and if we look very closely at it we see a kind of teeming, something which no longer has a smooth appearance\u2014it looks something like a crowd at a football game as seen from a very great distance. In order to see what this teeming is about, we will magnify it another two hundred and fifty times and we will see something similar to what is shown in Fig. 1\u20131. This is a picture of water magnified a billion times, but idealized in several ways. In the first place, the particles are drawn in a simple manner with sharp edges, which is inaccurate. Secondly, for simplicity, they are sketched almost schematically in a two-dimensional arrangement, but of course they are moving around in three dimensions. Notice that there are two kinds of \u201cblobs\u201d or circles to represent the atoms of oxygen (black) and hydrogen (white), and that each oxygen has two hydrogens tied to it. (Each little group of an oxygen with its two hydrogens is called a molecule.) The picture is idealized further in that the real particles in nature are continually jiggling and bouncing, turning and twisting around one another. You will have to imagine this as a dynamic rather than a static picture. Another thing that cannot be illustrated in a drawing is the fact that the particles are \u201cstuck together\u201d\u2014that they attract each other, this one pulled by that one, etc. The whole group is \u201cglued together,\u201d so to speak. On the other hand, the particles do not squeeze through each other. If you try to squeeze two of them too close together, they repel. The atoms are 1 or 2\u00d710\u22128 cm in radius. Now 10\u22128 cm is called an angstrom (just as another name), so we say they are 1 or 2 angstroms (\u00c5) in radius. Another way to remember their size is this: if an apple is magnified to the size of the earth, then the atoms in the apple are approximately the size of the original apple. Now imagine this great drop of water with all of these jiggling particles stuck together and tagging along with each other. The water keeps its volume; it does not fall apart, because of the attraction of the molecules for each other. If the drop is on a slope, where it can move from one place to another, the water will flow, but it does not just disappear\u2014things do not just fly apart\u2014because of the molecular attraction. Now the jiggling motion is what we represent as heat: when we increase the temperature, we increase the motion. If we heat the water, the jiggling increases and the volume between the atoms increases, and if the heating continues there comes a time when the pull between the molecules is not enough to hold them together and they do fly apart and become separated from one another. Of course, this is how we manufacture steam out of water\u2014by increasing the temperature; the particles fly apart because of the increased motion. In Fig. 1\u20132 we have a picture of steam. This picture of steam fails in one respect: at ordinary atmospheric pressure there certainly would not be as many as three water molecules in this figure. Most squares this size would contain none\u2014but we accidentally have two and a half or three in the picture (just so it would not be completely blank). Now in the case of steam we see the characteristic molecules more clearly than in the case of water. For simplicity, the molecules are drawn so that there is a 120\u2218 angle between the hydrogen atoms. In actual fact the angle is 105\u22183\u2032 , and the distance between the center of a hydrogen and the center of the oxygen is 0.957 \u00c5, so we know this molecule very well. Let us see what some of the properties of steam vapor or any other gas are. The molecules, being separated from one another, will bounce against the walls. Imagine a room with a number of tennis balls (a hundred or so) bouncing around in perpetual motion. When they bombard the wall, this pushes the wall away. (Of course we would have to push the wall back.) This means that the gas exerts a jittery force which our coarse senses (not being ourselves magnified a billion times) feel only as an average push. In order to confine a gas we must apply a pressure. Figure 1\u20133 shows a standard vessel for holding gases (used in all textbooks), a cylinder with a piston in it. Now, it makes no difference what the shapes of water molecules are, so for simplicity we shall draw them as tennis balls or little dots. These things are in perpetual motion in all directions. So many of them are hitting the top piston all the time that to keep it from being patiently knocked out of the tank by this continuous banging, we shall have to hold the piston down by a certain force, which we call the pressure (really, the pressure times the area is the force). Clearly, the force is proportional to the area, for if we increase the area but keep the number of molecules per cubic centimeter the same, we increase the number of collisions with the piston in the same proportion as the area was increased. Now let us put twice as many molecules in this tank, so as to double the density, and let them have the same speed, i.e., the same temperature. Then, to a close approximation, the number of collisions will be doubled, and since each will be just as \u201cenergetic\u201d as before, the pressure is proportional to the density. If we consider the true nature of the forces between the atoms, we would expect a slight decrease in pressure because of the attraction between the atoms, and a slight increase because of the finite volume they occupy. Nevertheless, to an excellent approximation, if the density is low enough that there are not many atoms, the pressure is proportional to the density. We can also see something else: If we increase the temperature without changing the density of the gas, i.e., if we increase the speed of the atoms, what is going to happen to the pressure? Well, the atoms hit harder because they are moving faster, and in addition they hit more often, so the pressure increases. You see how simple the ideas of atomic theory are. Let us consider another situation. Suppose that the piston moves inward, so that the atoms are slowly compressed into a smaller space. What happens when an atom hits the moving piston? Evidently it picks up speed from the collision. You can try it by bouncing a ping-pong ball from a forward-moving paddle, for example, and you will find that it comes off with more speed than that with which it struck. (Special example: if an atom happens to be standing still and the piston hits it, it will certainly move.) So the atoms are \u201chotter\u201d when they come away from the piston than they were before they struck it. Therefore all the atoms which are in the vessel will have picked up speed. This means that when we compress a gas slowly, the temperature of the gas increases. So, under slow compression, a gas will increase in temperature, and under slow expansion it will decrease in temperature. We now return to our drop of water and look in another direction. Suppose that we decrease the temperature of our drop of water. Suppose that the jiggling of the molecules of the atoms in the water is steadily decreasing. We know that there are forces of attraction between the atoms, so that after a while they will not be able to jiggle so well. What will happen at very low temperatures is indicated in Fig. 1\u20134: the molecules lock into a new pattern which is ice. This particular schematic diagram of ice is wrong because it is in two dimensions, but it is right qualitatively. The interesting point is that the material has a definite place for every atom, and you can easily appreciate that if somehow or other we were to hold all the atoms at one end of the drop in a certain arrangement, each atom in a certain place, then because of the structure of interconnections, which is rigid, the other end miles away (at our magnified scale) will have a definite location. So if we hold a needle of ice at one end, the other end resists our pushing it aside, unlike the case of water, in which the structure is broken down because of the increased jiggling so that the atoms all move around in different ways. The difference between solids and liquids is, then, that in a solid the atoms are arranged in some kind of an array, called a crystalline array, and they do not have a random position at long distances; the position of the atoms on one side of the crystal is determined by that of other atoms millions of atoms away on the other side of the crystal. Figure 1\u20134 is an invented arrangement for ice, and although it contains many of the correct features of ice, it is not the true arrangement. One of the correct features is that there is a part of the symmetry that is hexagonal. You can see that if we turn the picture around an axis by 60\u2218 , the picture returns to itself. So there is a symmetry in the ice which accounts for the six-sided appearance of snowflakes. Another thing we can see from Fig. 1\u20134 is why ice shrinks when it melts. The particular crystal pattern of ice shown here has many \u201choles\u201d in it, as does the true ice structure. When the organization breaks down, these holes can be occupied by molecules. Most simple substances, with the exception of water and type metal, expand upon melting, because the atoms are closely packed in the solid crystal and upon melting need more room to jiggle around, but an open structure collapses, as in the case of water. Now although ice has a \u201crigid\u201d crystalline form, its temperature can change\u2014ice has heat. If we wish, we can change the amount of heat. What is the heat in the case of ice? The atoms are not standing still. They are jiggling and vibrating. So even though there is a definite order to the crystal\u2014a definite structure\u2014all of the atoms are vibrating \u201cin place.\u201d As we increase the temperature, they vibrate with greater and greater amplitude, until they shake themselves out of place. We call this melting. As we decrease the temperature, the vibration decreases and decreases until, at absolute zero, there is a minimum amount of vibration that the atoms can have, but not zero. This minimum amount of motion that atoms can have is not enough to melt a substance, with one exception: helium. Helium merely decreases the atomic motions as much as it can, but even at absolute zero there is still enough motion to keep it from freezing. Helium, even at absolute zero, does not freeze, unless the pressure is made so great as to make the atoms squash together. If we increase the pressure, we can make it solidify. So much for the description of solids, liquids, and gases from the atomic point of view. However, the atomic hypothesis also describes processes, and so we shall now look at a number of processes from an atomic standpoint. The first process that we shall look at is associated with the surface of the water. What happens at the surface of the water? We shall now make the picture more complicated\u2014and more realistic\u2014by imagining that the surface is in air. Figure 1\u20135 shows the surface of water in air. We see the water molecules as before, forming a body of liquid water, but now we also see the surface of the water. Above the surface we find a number of things: First of all there are water molecules, as in steam. This is water vapor, which is always found above liquid water. (There is an equilibrium between the steam vapor and the water which will be described later.) In addition we find some other molecules\u2014here two oxygen atoms stuck together by themselves, forming an oxygen molecule, there two nitrogen atoms also stuck together to make a nitrogen molecule. Air consists almost entirely of nitrogen, oxygen, some water vapor, and lesser amounts of carbon dioxide, argon, and other things. So above the water surface is the air, a gas, containing some water vapor. Now what is happening in this picture? The molecules in the water are always jiggling around. From time to time, one on the surface happens to be hit a little harder than usual, and gets knocked away. It is hard to see that happening in the picture because it is a still picture. But we can imagine that one molecule near the surface has just been hit and is flying out, or perhaps another one has been hit and is flying out. Thus, molecule by molecule, the water disappears\u2014it evaporates. But if we close the vessel above, after a while we shall find a large number of molecules of water amongst the air molecules. From time to time, one of these vapor molecules comes flying down to the water and gets stuck again. So we see that what looks like a dead, uninteresting thing\u2014a glass of water with a cover, that has been sitting there for perhaps twenty years\u2014really contains a dynamic and interesting phenomenon which is going on all the time. To our eyes, our crude eyes, nothing is changing, but if we could see it a billion times magnified, we would see that from its own point of view it is always changing: molecules are leaving the surface, molecules are coming back. Why do we see no change? Because just as many molecules are leaving as are coming back! In the long run \u201cnothing happens.\u201d If we then take the top of the vessel off and blow the moist air away, replacing it with dry air, then the number of molecules leaving is just the same as it was before, because this depends on the jiggling of the water, but the number coming back is greatly reduced because there are so many fewer water molecules above the water. Therefore there are more going out than coming in, and the water evaporates. Hence, if you wish to evaporate water turn on the fan! Here is something else: Which molecules leave? When a molecule leaves it is due to an accidental, extra accumulation of a little bit more than ordinary energy, which it needs if it is to break away from the attractions of its neighbors. Therefore, since those that leave have more energy than the average, the ones that are left have less average motion than they had before. So the liquid gradually cools if it evaporates. Of course, when a molecule of vapor comes from the air to the water below there is a sudden great attraction as the molecule approaches the surface. This speeds up the incoming molecule and results in generation of heat. So when they leave they take away heat; when they come back they generate heat. Of course when there is no net evaporation the result is nothing\u2014the water is not changing temperature. If we blow on the water so as to maintain a continuous preponderance in the number evaporating, then the water is cooled. Hence, blow on soup to cool it! Of course you should realize that the processes just described are more complicated than we have indicated. Not only does the water go into the air, but also, from time to time, one of the oxygen or nitrogen molecules will come in and \u201cget lost\u201d in the mass of water molecules, and work its way into the water. Thus the air dissolves in the water; oxygen and nitrogen molecules will work their way into the water and the water will contain air. If we suddenly take the air away from the vessel, then the air molecules will leave more rapidly than they come in, and in doing so will make bubbles. This is very bad for divers, as you may know. Now we go on to another process. In Fig. 1\u20136 we see, from an atomic point of view, a solid dissolving in water. If we put a crystal of salt in the water, what will happen? Salt is a solid, a crystal, an organized arrangement of \u201csalt atoms.\u201d Figure 1\u20137 is an illustration of the three-dimensional structure of common salt, sodium chloride. Strictly speaking, the crystal is not made of atoms, but of what we call ions. An ion is an atom which either has a few extra electrons or has lost a few electrons. In a salt crystal we find chlorine ions (chlorine atoms with an extra electron) and sodium ions (sodium atoms with one electron missing). The ions all stick together by electrical attraction in the solid salt, but when we put them in the water we find, because of the attractions of the negative oxygen and positive hydrogen for the ions, that some of the ions jiggle loose. In Fig. 1\u20136 we see a chlorine ion getting loose, and other atoms floating in the water in the form of ions. This picture was made with some care. Notice, for example, that the hydrogen ends of the water molecules are more likely to be near the chlorine ion, while near the sodium ion we are more likely to find the oxygen end, because the sodium is positive and the oxygen end of the water is negative, and they attract electrically. Can we tell from this picture whether the salt is dissolving in water or crystallizing out of water? Of course we cannot tell, because while some of the atoms are leaving the crystal other atoms are rejoining it. The process is a dynamic one, just as in the case of evaporation, and it depends on whether there is more or less salt in the water than the amount needed for equilibrium. By equilibrium we mean that situation in which the rate at which atoms are leaving just matches the rate at which they are coming back. If there is almost no salt in the water, more atoms leave than return, and the salt dissolves. If, on the other hand, there are too many \u201csalt atoms,\u201d more return than leave, and the salt is crystallizing. In passing, we mention that the concept of a molecule of a substance is only approximate and exists only for a certain class of substances. It is clear in the case of water that the three atoms are actually stuck together. It is not so clear in the case of sodium chloride in the solid. There is just an arrangement of sodium and chlorine ions in a cubic pattern. There is no natural way to group them as \u201cmolecules of salt.\u201d Returning to our discussion of solution and precipitation, if we increase the temperature of the salt solution, then the rate at which atoms are taken away is increased, and so is the rate at which atoms are brought back. It turns out to be very difficult, in general, to predict which way it is going to go, whether more or less of the solid will dissolve. Most substances dissolve more, but some substances dissolve less, as the temperature increases. In all of the processes which have been described so far, the atoms and the ions have not changed partners, but of course there are circumstances in which the atoms do change combinations, forming new molecules. This is illustrated in Fig. 1\u20138. A process in which the rearrangement of the atomic partners occurs is what we call a chemical reaction. The other processes so far described are called physical processes, but there is no sharp distinction between the two. (Nature does not care what we call it, she just keeps on doing it.) This figure is supposed to represent carbon burning in oxygen. In the case of oxygen, two oxygen atoms stick together very strongly. (Why do not three or even four stick together? That is one of the very peculiar characteristics of such atomic processes. Atoms are very special: they like certain particular partners, certain particular directions, and so on. It is the job of physics to analyze why each one wants what it wants. At any rate, two oxygen atoms form, saturated and happy, a molecule.) The carbon atoms are supposed to be in a solid crystal (which could be graphite or diamond2). Now, for example, one of the oxygen molecules can come over to the carbon, and each atom can pick up a carbon atom and go flying off in a new combination\u2014\u201ccarbon-oxygen\u201d\u2014which is a molecule of the gas called carbon monoxide. It is given the chemical name CO. It is very simple: the letters \u201cCO\u201d are practically a picture of that molecule. But carbon attracts oxygen much more than oxygen attracts oxygen or carbon attracts carbon. Therefore in this process the oxygen may arrive with only a little energy, but the oxygen and carbon will snap together with a tremendous vengeance and commotion, and everything near them will pick up the energy. A large amount of motion energy, kinetic energy, is thus generated. This of course is burning; we are getting heat from the combination of oxygen and carbon. The heat is ordinarily in the form of the molecular motion of the hot gas, but in certain circumstances it can be so enormous that it generates light. That is how one gets flames. In addition, the carbon monoxide is not quite satisfied. It is possible for it to attach another oxygen, so that we might have a much more complicated reaction in which the oxygen is combining with the carbon, while at the same time there happens to be a collision with a carbon monoxide molecule. One oxygen atom could attach itself to the CO and ultimately form a molecule, composed of one carbon and two oxygens, which is designated CO2 and called carbon dioxide. If we burn the carbon with very little oxygen in a very rapid reaction (for example, in an automobile engine, where the explosion is so fast that there is not time for it to make carbon dioxide) a considerable amount of carbon monoxide is formed. In many such rearrangements, a very large amount of energy is released, forming explosions, flames, etc., depending on the reactions. Chemists have studied these arrangements of the atoms, and found that every substance is some type of arrangement of atoms. To illustrate this idea, let us consider another example. If we go into a field of small violets, we know what \u201cthat smell\u201d is. It is some kind of molecule, or arrangement of atoms, that has worked its way into our noses. First of all, how did it work its way in? That is rather easy. If the smell is some kind of molecule in the air, jiggling around and being knocked every which way, it might have accidentally worked its way into the nose. Certainly it has no particular desire to get into our nose. It is merely one helpless part of a jostling crowd of molecules, and in its aimless wanderings this particular chunk of matter happens to find itself in the nose. Now chemists can take special molecules like the odor of violets, and analyze them and tell us the exact arrangement of the atoms in space. We know that the carbon dioxide molecule is straight and symmetrical: O\u2014C\u2014O. (That can be determined easily, too, by physical methods.) However, even for the vastly more complicated arrangements of atoms that there are in chemistry, one can, by a long, remarkable process of detective work, find the arrangements of the atoms. Figure 1\u20139 is a picture of the air in the neighborhood of a violet; again we find nitrogen and oxygen in the air, and water vapor. (Why is there water vapor? Because the violet is wet. All plants transpire.) However, we also see a \u201cmonster\u201d composed of carbon atoms, hydrogen atoms, and oxygen atoms, which have picked a certain particular pattern in which to be arranged. It is a much more complicated arrangement than that of carbon dioxide; in fact, it is an enormously complicated arrangement. Unfortunately, we cannot picture all that is really known about it chemically, because the precise arrangement of all the atoms is actually known in three dimensions, while our picture is in only two dimensions. The six carbons which form a ring do not form a flat ring, but a kind of \u201cpuckered\u201d ring. All of the angles and distances are known. So a chemical formula is merely a picture of such a molecule. When the chemist writes such a thing on the blackboard, he is trying to \u201cdraw,\u201d roughly speaking, in two dimensions. For example, we see a \u201cring\u201d of six carbons, and a \u201cchain\u201d of carbons hanging on the end, with an oxygen second from the end, three hydrogens tied to that carbon, two carbons and three hydrogens sticking up here, etc. How does the chemist find what the arrangement is? He mixes bottles full of stuff together, and if it turns red, it tells him that it consists of one hydrogen and two carbons tied on here; if it turns blue, on the other hand, that is not the way it is at all. This is one of the most fantastic pieces of detective work that has ever been done\u2014organic chemistry. To discover the arrangement of the atoms in these enormously complicated arrays the chemist looks at what happens when he mixes two different substances together. The physicist could never quite believe that the chemist knew what he was talking about when he described the arrangement of the atoms. For about twenty years it has been possible, in some cases, to look at such molecules (not quite as complicated as this one, but some which contain parts of it) by a physical method, and it has been possible to locate every atom, not by looking at colors, but by measuring where they are. And lo and behold!, the chemists are almost always correct. It turns out, in fact, that in the odor of violets there are three slightly different molecules, which differ only in the arrangement of the hydrogen atoms. One problem of chemistry is to name a substance, so that we will know what it is. Find a name for this shape! Not only must the name tell the shape, but it must also tell that here is an oxygen atom, there a hydrogen\u2014exactly what and where each atom is. So we can appreciate that the chemical names must be complex in order to be complete. You see that the name of this thing in the more complete form that will tell you the structure of it is 4-(2, 2, 3, 6 tetramethyl-5-cyclohexenyl)-3-buten-2-one, and that tells you that this is the arrangement. We can appreciate the difficulties that the chemists have, and also appreciate the reason for such long names. It is not that they wish to be obscure, but they have an extremely difficult problem in trying to describe the molecules in words! How do we know that there are atoms? By one of the tricks mentioned earlier: we make the hypothesis that there are atoms, and one after the other results come out the way we predict, as they ought to if things are made of atoms. There is also somewhat more direct evidence, a good example of which is the following: The atoms are so small that you cannot see them with a light microscope\u2014in fact, not even with an electron microscope. (With a light microscope you can only see things which are much bigger.) Now if the atoms are always in motion, say in water, and we put a big ball of something in the water, a ball much bigger than the atoms, the ball will jiggle around\u2014much as in a push ball game, where a great big ball is pushed around by a lot of people. The people are pushing in various directions, and the ball moves around the field in an irregular fashion. So, in the same way, the \u201clarge ball\u201d will move because of the inequalities of the collisions on one side to the other, from one moment to the next. Therefore, if we look at very tiny particles (colloids) in water through an excellent microscope, we see a perpetual jiggling of the particles, which is the result of the bombardment of the atoms. This is called the Brownian motion. We can see further evidence for atoms in the structure of crystals. In many cases the structures deduced by x-ray analysis agree in their spatial \u201cshapes\u201d with the forms actually exhibited by crystals as they occur in nature. The angles between the various \u201cfaces\u201d of a crystal agree, within seconds of arc, with angles deduced on the assumption that a crystal is made of many \u201clayers\u201d of atoms. Everything is made of atoms. That is the key hypothesis. The most important hypothesis in all of biology, for example, is that everything that animals do, atoms do. In other words, there is nothing that living things do that cannot be understood from the point of view that they are made of atoms acting according to the laws of physics. This was not known from the beginning: it took some experimenting and theorizing to suggest this hypothesis, but now it is accepted, and it is the most useful theory for producing new ideas in the field of biology. If a piece of steel or a piece of salt, consisting of atoms one next to the other, can have such interesting properties; if water\u2014which is nothing but these little blobs, mile upon mile of the same thing over the earth\u2014can form waves and foam, and make rushing noises and strange patterns as it runs over cement; if all of this, all the life of a stream of water, can be nothing but a pile of atoms, how much more is possible? If instead of arranging the atoms in some definite pattern, again and again repeated, on and on, or even forming little lumps of complexity like the odor of violets, we make an arrangement which is always different from place to place, with different kinds of atoms arranged in many ways, continually changing, not repeating, how much more marvelously is it possible that this thing might behave? Is it possible that that \u201cthing\u201d walking back and forth in front of you, talking to you, is a great glob of these atoms in a very complex arrangement, such that the sheer complexity of it staggers the imagination as to what it can do? When we say we are a pile of atoms, we do not mean we are merely a pile of atoms, because a pile of atoms which is not repeated from one to the other might well have the possibilities which you see before you in the mirror."
    },
    {
        "input": "Identical Particles",
        "output": "In the last chapter we began to consider the special rules for the interference that occurs in processes with two identical particles. By identical particles we mean things like electrons which can in no way be distinguished one from another. If a process involves two particles that are identical, reversing which one arrives at a counter is an alternative which cannot be distinguished and\u2014like all cases of alternatives which cannot be distinguished\u2014interferes with the original, unexchanged case. The amplitude for an event is then the sum of the two interfering amplitudes; but, interestingly enough, the interference is in some cases with the same phase and, in others, with the opposite phase. Suppose we have a collision of two particles a and b in which particle a scatters in the direction 1 and particle b scatters in the direction 2 , as sketched in Fig. 4\u20131(a). Let\u2019s call f(\u03b8) the amplitude for this process; then the probability P1 of observing such an event is proportional to |f(\u03b8)|2 . Of course, it could also happen that particle b scattered into counter 1 and particle a went into counter 2 , as shown in Fig. 4\u20131(b). Assuming that there are no special directions defined by spins or such, the probability P2 for this process is just |f(\u03c0\u2212\u03b8)|2 , because it is just equivalent to the first process with counter 1 moved over to the angle \u03c0\u2212\u03b8 . You might also think that the amplitude for the second process is just f(\u03c0\u2212\u03b8) . But that is not necessarily so, because there could be an arbitrary phase factor. That is, the amplitude could be ei\u03b4f(\u03c0\u2212\u03b8). Such an amplitude still gives a probability P2 equal to |f(\u03c0\u2212\u03b8)|2 . Now let\u2019s see what happens if a and b are identical particles. Then the two different processes shown in the two diagrams of Fig. 4\u20131 cannot be distinguished. There is an amplitude that either a or b goes into counter 1 , while the other goes into counter 2 . This amplitude is the sum of the amplitudes for the two processes shown in Fig. 4\u20131. If we call the first one f(\u03b8) , then the second one is ei\u03b4f(\u03c0\u2212\u03b8) , where now the phase factor is very important because we are going to be adding two amplitudes. Suppose we have to multiply the amplitude by a certain phase factor when we exchange the roles of the two particles. If we exchange them again we should get the same factor again. But we are then back to the first process. The phase factor taken twice must bring us back where we started\u2014its square must be equal to 1 . There are only two possibilities: ei\u03b4 is equal to +1 , or is equal to \u22121 . Either the exchanged case contributes with the same sign, or it contributes with the opposite sign. Both cases exist in nature, each for a different class of particles. Particles which interfere with a positive sign are called Bose particles and those which interfere with a negative sign are called Fermi particles. The Bose particles are the photon, the mesons, and the graviton. The Fermi particles are the electron, the muon, the neutrinos, the nucleons, and the baryons. We have, then, that the amplitude for the scattering of identical particles is: Bose particles: (Amplitude direct)+(Amplitude exchanged). Fermi particles: (Amplitude direct)\u2212(Amplitude exchanged). For particles with spin\u2014like electrons\u2014there is an additional complication. We must specify not only the location of the particles but the direction of their spins. It is only for identical particles with identical spin states that the amplitudes interfere when the particles are exchanged. If you think of the scattering of unpolarized beams\u2014which are a mixture of different spin states\u2014there is some extra arithmetic. Now an interesting problem arises when there are two or more particles bound tightly together. For example, an \u03b1 -particle has four particles in it\u2014two neutrons and two protons. When two \u03b1 -particles scatter, there are several possibilities. It may be that during the scattering there is a certain amplitude that one of the neutrons will leap across from one \u03b1 -particle to the other, while a neutron from the other \u03b1 -particle leaps the other way so that the two alphas which come out of the scattering are not the original ones\u2014there has been an exchange of a pair of neutrons. See Fig. 4\u20132. The amplitude for scattering with an exchange of a pair of neutrons will interfere with the amplitude for scattering with no such exchange, and the interference must be with a minus sign because there has been an exchange of one pair of Fermi particles. On the other hand, if the relative energy of the two \u03b1 -particles is so low that they stay fairly far apart\u2014say, due to the Coulomb repulsion\u2014and there is never any appreciable probability of exchanging any of the internal particles, we can consider the \u03b1 -particle as a simple object, and we do not need to worry about its internal details. In such circumstances, there are only two contributions to the scattering amplitude. Either there is no exchange, or all four of the nucleons are exchanged in the scattering. Since the protons and the neutrons in the \u03b1 -particle are all Fermi particles, an exchange of any pair reverses the sign of the scattering amplitude. So long as there are no internal changes in the \u03b1 -particles, interchanging the two \u03b1 -particles is the same as interchanging four pairs of Fermi particles. There is a change in sign for each pair, so the net result is that the amplitudes combine with a positive sign. The \u03b1 -particle behaves like a Bose particle. So the rule is that composite objects, in circumstances in which the composite object can be considered as a single object, behave like Fermi particles or Bose particles, depending on whether they contain an odd number or an even number of Fermi particles. All the elementary Fermi particles we have mentioned\u2014such as the electron, the proton, the neutron, and so on\u2014have a spin j=1/2 . If several such Fermi particles are put together to form a composite object, the resulting spin may be either integral or half-integral. For example, the common isotope of helium, He4 , which has two neutrons and two protons, has a spin of zero, whereas Li7 , which has three protons and four neutrons, has a spin of 3/2 . We will learn later the rules for compounding angular momentum, and will just mention now that every composite object which has a half-integral spin imitates a Fermi particle, whereas every composite object with an integral spin imitates a Bose particle. This brings up an interesting question: Why is it that particles with half-integral spin are Fermi particles whose amplitudes add with the minus sign, whereas particles with integral spin are Bose particles whose amplitudes add with the positive sign? We apologize for the fact that we cannot give you an elementary explanation. An explanation has been worked out by Pauli from complicated arguments of quantum field theory and relativity. He has shown that the two must necessarily go together, but we have not been able to find a way of reproducing his arguments on an elementary level. It appears to be one of the few places in physics where there is a rule which can be stated very simply, but for which no one has found a simple and easy explanation. The explanation is deep down in relativistic quantum mechanics. This probably means that we do not have a complete understanding of the fundamental principle involved. For the moment, you will just have to take it as one of the rules of the world. Now we would like to discuss an interesting consequence of the addition rule for Bose particles. It has to do with their behavior when there are several particles present. We begin by considering a situation in which two Bose particles are scattered from two different scatterers. We won\u2019t worry about the details of the scattering mechanism. We are interested only in what happens to the scattered particles. Suppose we have the situation shown in Fig. 4\u20133. The particle a is scattered into the state 1 . By a state we mean a given direction and energy, or some other given condition. The particle b is scattered into the state 2 . We want to assume that the two states 1 and 2 are nearly the same. (What we really want to find out eventually is the amplitude that the two particles are scattered into identical directions, or states; but it is best if we think first about what happens if the states are almost the same and then work out what happens when they become identical.) Suppose that we had only particle a ; then it would have a certain amplitude for scattering in direction 1 , say \u27e81|a\u27e9 . And particle b alone would have the amplitude \u27e82|b\u27e9 for landing in direction 2 . If the two particles are not identical, the amplitude for the two scatterings to occur at the same time is just the product \u27e81|a\u27e9\u27e82|b\u27e9. The probability for such an event is then |\u27e81|a\u27e9\u27e82|b\u27e9|2, which is also equal to |\u27e81|a\u27e9|2|\u27e82|b\u27e9|2. To save writing for the present arguments, we will sometimes set \u27e81|a\u27e9=a1,\u27e82|b\u27e9=b2. Then the probability of the double scattering is |a1|2|b2|2. It could also happen that particle b is scattered into direction 1 , while particle a goes into direction 2 . The amplitude for this process is \u27e82|a\u27e9\u27e81|b\u27e9, and the probability of such an event is |\u27e82|a\u27e9\u27e81|b\u27e9 | 2 =| a 2 | 2 | b 1 | 2 . Imagine now that we have a pair of tiny counters that pick up the two scattered particles. The probability P 2 that they will pick up two particles together is just the sum P 2 =| a 1 | 2 | b 2 | 2 +| a 2 | 2 | b 1 | 2 . (4.3) Now let\u2019s suppose that the directions 1 and 2 are very close together. We expect that a should vary smoothly with direction, so a 1 and a 2 must approach each other as 1 and 2 get close together. If they are close enough, the amplitudes a 1 and a 2 will be equal. We can set a 1 = a 2 and call them both just a ; similarly, we set b 1 = b 2 =b . Then we get that P 2 =2|a | 2 |b | 2 . (4.4) Now suppose, however, that a and b are identical Bose particles. Then the process of a going into 1 and b going into 2 cannot be distinguished from the exchanged process in which a goes into 2 and b goes into 1 . In this case the amplitudes for the two different processes can interfere. The total amplitude to obtain a particle in each of the two counters is \u27e81|a\u27e9\u27e82|b\u27e9+\u27e82|a\u27e9\u27e81|b\u27e9. (4.5) And the probability that we get a pair is the absolute square of this amplitude, P 2 =| a 1 b 2 + a 2 b 1 | 2 =4|a | 2 |b | 2 . (4.6) We have the result that it is twice as likely to find two identical Bose particles scattered into the same state as you would calculate assuming the particles were different. Although we have been considering that the two particles are observed in separate counters, this is not essential\u2014as we can see in the following way. Let\u2019s imagine that both the directions 1 and 2 would bring the particles into a single small counter which is some distance away. We will let the direction 1 be defined by saying that it heads toward the element of area d S 1 of the counter. Direction 2 heads toward the surface element d S 2 of the counter. (We imagine that the counter presents a surface at right angles to the line from the scatterings.) Now we cannot give a probability that a particle will go into a precise direction or to a particular point in space. Such a thing is impossible\u2014the chance for any exact direction is zero. When we want to be so specific, we shall have to define our amplitudes so that they give the probability of arriving per unit area of a counter. Suppose that we had only particle a ; it would have a certain amplitude for scattering in direction 1 . Let\u2019s define \u27e81|a\u27e9= a 1 to be the amplitude that a will scatter into a unit area of the counter in the direction 1 . In other words, the scale of a 1 is chosen\u2014we say it is \u201cnormalized\u201d so that the probability that it will scatter into an element of area d S 1 is |\u27e81|a\u27e9 | 2 d S 1 =| a 1 | 2 d S 1 . (4.7) If our counter has the total area \u0394S , and we let d S 1 range over this area, the total probability that the particle a will be scattered into the counter is \u222b \u0394S | a 1 | 2 d S 1 . (4.8) As before, we want to assume that the counter is sufficiently small so that the amplitude a 1 doesn\u2019t vary significantly over the surface of the counter; a 1 is then a constant amplitude which we can call a . Then the probability that particle a is scattered somewhere into the counter is p a =|a | 2 \u0394S. (4.9) In the same way, we will have that the probability that particle b \u2014when it is alone\u2014scatters into some element of area, say d S 2 , is | b 2 | 2 d S 2 . 2 (We use d S 2 instead of d S 1 because we will later want a and b to go into different directions.) Again we set b 2 equal to the constant amplitude b ; then the probability that particle b is counted in the detector is p b =|b | 2 \u0394S. (4.10) Now when both particles are present, the probability that a is scattered into d S 1 and b is scattered into d S 2 is | a 1 b 2 | 2 d S 1 d S 2 =|a | 2 |b | 2 d S 1 d S 2 . (4.11) If we want the probability that both a and b get into the counter, we integrate both d S 1 and d S 2 over \u0394S and find that P 2 =|a | 2 |b | 2 (\u0394S ) 2 . (4.12) We notice, incidentally, that this is just equal to p a \u22c5 p b , just as you would suppose assuming that the particles a and b act independently of each other. When the two particles are identical, however, there are two indistinguishable possibilities for each pair of surface elements d S 1 and d S 2 . Particle a going into d S 2 and particle b going into d S 1 is indistinguishable from a into d S 1 and b into d S 2 , so the amplitudes for these processes will interfere. (When we had two different particles above\u2014although we did not in fact care which particle went where in the counter\u2014we could, in principle, have found out; so there was no interference. For identical particles we cannot tell, even in principle.) We must write, then, that the probability that the two particles arrive at d S 1 and d S 2 is | a 1 b 2 + a 2 b 1 | 2 d S 1 d S 2 . (4.13) Now, however, when we integrate over the area of the counter, we must be careful. If we let d S 1 and d S 2 range over the whole area \u0394S , we would count each part of the area twice since (4.13) contains everything that can happen with any pair of surface elements d S 1 and d S 2 .1 We can still do the integral that way, if we correct for the double counting by dividing the result by 2 . We get then that P 2 for identical Bose particles is P 2 (Bose) = 1 2 {4|a | 2 |b | 2 (\u0394S ) 2 } =2|a | 2 |b | 2 (\u0394S ) 2 . (4.14) Again, this is just twice what we got in Eq. (4.12) for distinguishable particles. If we imagine for a moment that we knew that the b channel had already sent its particle into the particular direction, we can say that the probability that a second particle will go into the same direction is twice as great as we would have expected if we had calculated it as an independent event. It is a property of Bose particles that if there is already one particle in a condition of some kind, the probability of getting a second one in the same condition is twice as great as it would be if the first one were not already there. This fact is often stated in the following way: If there is already one Bose particle in a given state, the amplitude for putting an identical one on top of it is 2 \u2013 \u221a greater than if it weren\u2019t there. (This is not a proper way of stating the result from the physical point of view we have taken, but if it is used consistently as a rule, it will, of course, give the correct result.) Let\u2019s extend our result to a situation in which there are n particles present. We imagine the circumstance shown in Fig. 4\u20134. We have n particles a , b , c , \u2026, which are scattered and end up in the directions 1 , 2 , 3 , \u2026, n . All n directions are headed toward a small counter a long distance away. As in the last section, we choose to normalize all the amplitudes so that the probability that each particle acting alone would go into an element of surface dS of the counter is |\u27e8\u27e9 | 2 dS. 2 First, let\u2019s assume that the particles are all distinguishable; then the probability that n particles will be counted together in n different surface elements is | a 1 b 2 c 3 \u22ef | 2 d S 1 d S 2 d S 3 \u22ef (4.15) Again we take that the amplitudes don\u2019t depend on where dS is located in the counter (assumed small) and call them simply a , b , c , \u2026 The probability (4.15) becomes |a | 2 |b | 2 |c | 2 \u22efd S 1 d S 2 d S 3 \u22ef (4.16) Integrating each dS over the surface \u0394S of the counter, we have that P n (different) , the probability of counting n different particles at once, is P n (different)=|a | 2 |b | 2 |c | 2 \u22ef(\u0394S ) n . (4.17) This is just the product of the probabilities for each particle to enter the counter separately. They all act independently\u2014the probability for one to enter does not depend on how many others are also entering. Now suppose that all the particles are identical Bose particles. For each set of directions 1 , 2 , 3 , \u2026 there are many indistinguishable possibilities. If there were, for instance, just three particles, we would have the following possibilities: a b c a b c \u21921 \u21922 \u21923 \u21922 \u21923 \u21921 a b c a b c \u21921 \u21923 \u21922 \u21923 \u21921 \u21922 a b c a b c \u21922 \u21921 \u21923 \u21923 \u21922 \u21921 There are six different combinations. With n particles, there are n! different, but indistinguishable, possibilities for which we must add amplitudes. The probability that n particles will be counted in n surface elements is then | a 1 b 2 c 3 \u22ef+ a 1 b 3 c 2 \u22ef+ a 2 b 1 c 3 \u22ef + a 2 b 3 c 1 \u22ef+etc.+etc. | 2 d S 1 d S 2 d S 3 \u22efd S n . (4.18) Once more we assume that all the directions are so close that we can set a 1 = a 2 = \u22ef= a n = a , and similarly for b , c , \u2026; the probability of (4.18) becomes |n!abc\u22ef | 2 d S 1 d S 2 \u22efd S n . (4.19) When we integrate each dS over the area \u0394S of the counter, each possible product of surface elements is counted n! times; we correct for this by dividing by n! and get P n (Bose)= 1 n! |n!abc\u22ef | 2 (\u0394S ) n 1 or P n (Bose)=n!|abc\u22ef | 2 (\u0394S ) n . (4.20) Comparing this result with Eq. (4.17), we see that the probability of counting n Bose particles together is n! greater than we would calculate assuming that the particles were all distinguishable. We can summarize our result this way: P n (Bose)=n! P n (different). (4.21) Thus, the probability in the Bose case is larger by n! than you would calculate assuming that the particles acted independently. We can see better what this means if we ask the following question: What is the probability that a Bose particle will go into a particular state when there are already n others present? Let\u2019s call the newly added particle w . If we have (n+1) particles, including w , Eq. (4.20) becomes P n+1 (Bose)=(n+1)!|abc\u22efw | 2 (\u0394S ) n+1 . (4.22) We can write this as P n+1 (Bose)={(n+1)|w | 2 \u0394S}n!|abc\u22ef | 2 (\u0394S ) n 2 2 or P n+1 (Bose)=(n+1)|w | 2 \u0394S P n (Bose). (4.23) We can look at this result in the following way: The number |w | 2 \u0394S is the probability for getting particle w into the detector if no other particles were present; P n (Bose) is the chance that there are already n other Bose particles present. So Eq. (4.23) says that when there are n other identical Bose particles present, the probability that one more particle will enter the same state is enhanced by the factor (n+1) . The probability of getting a boson, where there are already n , is (n+1) times stronger than it would be if there were none before. The presence of the other particles increases the probability of getting one more. Throughout our discussion we have talked about a process like the scattering of \u03b1 -particles. But that is not essential; we could have been speaking of the creation of particles, as for instance the emission of light. When the light is emitted, a photon is \u201ccreated.\u201d In such a case, we don\u2019t need the incoming lines in Fig. 4\u20134; we can consider merely that there are some atoms emitting n photons, as in Fig. 4\u20135. So our result can also be stated: The probability that an atom will emit a photon into a particular final state is increased by the factor (n+1) if there are already n photons in that state. People like to summarize this result by saying that the amplitude to emit a photon is increased by the factor n+1 \u2212 \u2212 \u2212 \u2212 \u2212 \u221a when there are already n photons present. It is, of course, another way of saying the same thing if it is understood to mean that this amplitude is just to be squared to get the probability. It is generally true in quantum mechanics that the amplitude to get from any condition \u03d5 to any other condition \u03c7 is the complex conjugate of the amplitude to get from \u03c7 to \u03d5 : \u27e8\u03c7|\u03d5\u27e9=\u27e8\u03d5|\u03c7 \u27e9 \u2217 . (4.24) We will learn about this law a little later, but for the moment we will just assume it is true. We can use it to find out how photons are scattered or absorbed out of a given state. We have that the amplitude that a photon will be added to some state, say i , when there are already n photons present is, say, \u27e8n+1|n\u27e9= n+1 \u2212 \u2212 \u2212 \u2212 \u2212 \u221a a, (4.25) where a=\u27e8i|a\u27e9 is the amplitude when there are no others present. Using Eq. (4.24), the amplitude to go the other way\u2014from (n+1) photons to n \u2014is \u27e8n|n+1\u27e9= n+1 \u2212 \u2212 \u2212 \u2212 \u2212 \u221a a \u2217 . (4.26) This isn\u2019t the way people usually say it; they don\u2019t like to think of going from (n+1) to n , but prefer always to start with n photons present. Then they say that the amplitude to absorb a photon when there are n present\u2014in other words, to go from n to (n\u22121) \u2014is \u27e8n\u22121|n\u27e9= n \u2212 \u2212 \u221a a \u2217 . (4.27) which is, of course, just the same as Eq. (4.26). Then they have trouble trying to remember when to use n \u2212 \u2212 \u221a or n+1 \u2212 \u2212 \u2212 \u2212 \u2212 \u221a . Here\u2019s the way to remember: The factor is always the square root of the largest number of photons present, whether it is before or after the reaction. Equations (4.25) and (4.26) show that the law is really symmetric\u2014it only appears unsymmetric if you write it as Eq. (4.27). There are many physical consequences of these new rules; we want to describe one of them having to do with the emission of light. Suppose we imagine a situation in which photons are contained in a box\u2014you can imagine a box with mirrors for walls. Now say that in the box we have n photons, all of the same state\u2014the same frequency, direction, and polarization\u2014so they can\u2019t be distinguished, and that also there is an atom in the box that can emit another photon into the same state. Then the probability that it will emit a photon is (n+1)|a | 2 , (4.28) and the probability that it will absorb a photon is n|a | 2 , (4.29) where |a | 2 is the probability it would emit if no photons were present. We have already discussed these rules in a somewhat different way in Chapter 42 of Vol. I. Equation (4.29) says that the probability that an atom will absorb a photon and make a transition to a higher energy state is proportional to the intensity of the light shining on it. But, as Einstein first pointed out, the rate at which an atom will make a transition downward has two parts. There is the probability that it will make a spontaneous transition |a | 2 , plus the probability of an induced transition n|a | 2 , which is proportional to the intensity of the light\u2014that is, to the number of photons present. Furthermore, as Einstein said, the coefficients of absorption and of induced emission are equal and are related to the probability of spontaneous emission. What we learn here is that if the light intensity is measured in terms of the number of photons present (instead of as the energy per unit area, and per sec), the coefficients of absorption, of induced emission, and of spontaneous emission are all equal. This is the content of the relation between the Einstein coefficients A and B of Chapter 42, Vol. I, Eq. (42.18). We would like to use our rules for Bose particles to discuss once more the spectrum of blackbody radiation (see Chapter 42, Vol. I). We will do it by finding out how many photons there are in a box if the radiation is in thermal equilibrium with some atoms in the box. Suppose that for each light frequency \u03c9 , there are a certain number N of atoms which have two energy states separated by the energy \u0394E=\u210f\u03c9 . See Fig. 4\u20136. We\u2019ll call the lower-energy state the \u201cground\u201d state and the upper state the \u201cexcited\u201d state. Let N g and N e be the average numbers of atoms in the ground and excited states; then in thermal equilibrium at the temperature T , we have from statistical mechanics that N e N g = e \u2212\u0394E/\u03baT = e \u2212\u210f\u03c9/\u03baT . (4.30) Each atom in the ground state can absorb a photon and go into the excited state, and each atom in the excited state can emit a photon and go to the ground state. In equilibrium, the rates for these two processes must be equal. The rates are proportional to the probability for the event and to the number of atoms present. Let\u2019s let n \u00af \u00af \u00af be the average number of photons present in a given state with the frequency \u03c9 . Then the absorption rate from that state is N g n \u00af \u00af \u00af |a | 2 , and the emission rate into that state is N e ( n \u00af \u00af \u00af +1)|a | 2 . Setting the two rates equal, we have that N g n \u00af \u00af \u00af = N e ( n \u00af \u00af \u00af +1). (4.31) Combining this with Eq. (4.30), we have n \u00af \u00af \u00af n \u00af \u00af \u00af +1 = e \u2212\u210f\u03c9/\u03baT . Solving for n \u00af \u00af \u00af , we have n \u00af \u00af \u00af = 1 e \u210f\u03c9/\u03baT \u22121 , (4.32) which is the mean number of photons in any state with frequency \u03c9 , for a cavity in thermal equilibrium. Since each photon has the energy \u210f\u03c9 , the energy in the photons of a given state is n \u00af \u00af \u00af \u210f\u03c9 , or \u210f\u03c9 e \u210f\u03c9/\u03baT \u22121 . (4.33) Incidentally, we once found a similar equation in another context [Chapter 41, Vol. I, Eq. (41.15)]. You remember that for any harmonic oscillator\u2014such as a weight on a spring\u2014the quantum mechanical energy levels are equally spaced with a separation \u210f\u03c9 , as drawn in Fig. 4\u20137. If we call the energy of the n th level n\u210f\u03c9 , we find that the mean energy of such an oscillator is also given by Eq. (4.33). Yet this equation was derived here for photons, by counting particles, and it gives the same results. That is one of the marvelous miracles of quantum mechanics. If one begins by considering a kind of state or condition for Bose particles which do not interact with each other (we have assumed that the photons do not interact with each other), and then considers that into this state there can be put either zero, or one, or two, \u2026 up to any number n of particles, one finds that this system behaves for all quantum mechanical purposes exactly like a harmonic oscillator. By such an oscillator we mean a dynamic system like a weight on a spring or a standing wave in a resonant cavity. And that is why it is possible to represent the electromagnetic field by photon particles. From one point of view, we can analyze the electromagnetic field in a box or cavity in terms of a lot of harmonic oscillators, treating each mode of oscillation according to quantum mechanics as a harmonic oscillator. From a different point of view, we can analyze the same physics in terms of identical Bose particles. And the results of both ways of working are always in exact agreement. There is no way to make up your mind whether the electromagnetic field is really to be described as a quantized harmonic oscillator or by giving how many photons there are in each condition. The two views turn out to be mathematically identical. So in the future we can speak either about the number of photons in a particular state in a box or the number of the energy level associated with a particular mode of oscillation of the electromagnetic field. They are two ways of saying the same thing. The same is true of photons in free space. They are equivalent to oscillations of a cavity whose walls have receded to infinity. We have computed the mean energy in any particular mode in a box at the temperature T ; we need only one more thing to get the blackbody radiation law: We need to know how many modes there are at each energy. (We assume that for every mode there are some atoms in the box\u2014or in the walls\u2014which have energy levels that can radiate into that mode, so that each mode can get into thermal equilibrium.) The blackbody radiation law is usually stated by giving the energy per unit volume carried by the light in a small frequency interval from \u03c9 to \u03c9+\u0394\u03c9 . So we need to know how many modes there are in a box with frequencies in the interval \u0394\u03c9 . Although this question continually comes up in quantum mechanics, it is purely a classical question about standing waves. We will get the answer only for a rectangular box. It comes out the same for a box of any shape, but it\u2019s very complicated to compute for the arbitrary case. Also, we are only interested in a box whose dimensions are very large compared with a wavelength of the light. Then there are billions and billions of modes; there will be many in any small frequency interval \u0394\u03c9 , so we can speak of the \u201caverage number\u201d in any \u0394\u03c9 at the frequency \u03c9 . Let\u2019s start by asking how many modes there are in a one-dimensional case\u2014as for waves on a stretched string. You know that each mode is a sine wave that has to go to zero at both ends; in other words, there must be an integral number of half-wavelengths in the length of the line, as shown in Fig. 4\u20138. We prefer to use the wave number k=2\u03c0/\u03bb ; calling k j the wave number of the j th mode, we have that k j = j\u03c0 L , (4.34) where j is any integer. The separation \u03b4k between successive modes is \u03b4k= k j+1 \u2212 k j = \u03c0 L . \u03c0 We want to assume that kL is so large that in a small interval \u0394k , there are many modes. Calling \u0394N the number of modes in the interval \u0394k , we have \u0394N= \u0394k \u03b4k = L \u03c0 \u0394k. (4.35) Now theoretical physicists working in quantum mechanics usually prefer to say that there are one-half as many modes; they write \u0394N= L 2\u03c0 \u0394k. (4.36) We would like to explain why. They usually like to think in terms of travelling waves\u2014some going to the right (with a positive k ) and some going to the left (with a negative k ). But a \u201cmode\u201d is a standing wave which is the sum of two waves, one going in each direction. In other words, they consider each standing wave as containing two distinct photon \u201cstates.\u201d So if by \u0394N , one prefers to mean the number of photon states of a given k (where now k ranges over positive and negative values), one should then take \u0394N half as big. (All integrals must now go from k=\u2212\u221e to k=+\u221e , and the total number of states up to any given absolute value of k will come out O.K.) Of course, we are not then describing standing waves very well, but we are counting modes in a consistent way. Now we want to extend the results to three dimensions. A standing wave in a rectangular box must have an integral number of half-waves along each axis. The situation for two of the dimensions is shown in Fig. 4\u20139. Each wave direction and frequency is described by a vector wave number k , whose x , y , and z components must satisfy equations like Eq. (4.34). So we have that k x k y k z = j x \u03c0 L x , = j y \u03c0 L y , = j z \u03c0 L z . The number of modes with k x in an interval \u0394 k x is, as before, L x 2\u03c0 \u0394 k x , L and similarly for \u0394 k y and \u0394 k z . If we call \u0394N(k) the number of modes for a vector wave number k whose x -component is between k x and k x +\u0394 k x , whose y -component is between k y and k y +\u0394 k y , and whose z -component is between k z and k z +\u0394 k z , then \u0394N(k)= L x L y L z (2\u03c0 ) 3 \u0394 k x \u0394 k y \u0394 k z . (4.37) The product L x L y L z is equal to the volume V of the box. So we have the important result that for high frequencies (wavelengths small compared with the dimensions), the number of modes in a cavity is proportional to the volume V of the box and to the \u201cvolume in k -space\u201d \u0394 k x \u0394 k y \u0394 k z . This result comes up again and again in many problems and should be memorized: dN(k)=V d 3 k (2\u03c0 ) 3 . (4.38) Although we have not proved it, the result is independent of the shape of the box. We will now apply this result to find the number of photon modes for photons with frequencies in the range \u0394\u03c9 . We are just interested in the energy in various modes\u2014but not interested in the directions of the waves. We would like to know the number of modes in a given range of frequencies. In a vacuum the magnitude of k is related to the frequency by |k|= \u03c9 c . (4.39) So in a frequency interval \u0394\u03c9 , these are all the modes which correspond to k \u2019s with a magnitude between k and k+\u0394k , independent of the direction. The \u201cvolume in k -space\u201d between k and k+\u0394k is a spherical shell of volume 4\u03c0 k 2 \u0394k. 2 The number of modes is then \u0394N(\u03c9)= V4\u03c0 k 2 \u0394k (2\u03c0 ) 3 . (4.40) However, since we are now interested in frequencies, we should substitute k=\u03c9/c , so we get \u0394N(\u03c9)= V4\u03c0 \u03c9 2 \u0394\u03c9 (2\u03c0 ) 3 c 3 . (4.41) There is one more complication. If we are talking about modes of an electromagnetic wave, for any given wave vector k there can be either of two polarizations (at right angles to each other). Since these modes are independent, we must\u2014for light\u2014double the number of modes. So we have \u0394N(\u03c9)= V \u03c9 2 \u0394\u03c9 \u03c0 2 c 3 (for light). (4.42) We have shown, Eq. (4.33), that each mode (or each \u201cstate\u201d) has on the average the energy n \u00af \u00af \u00af \u210f\u03c9= \u210f\u03c9 e \u210f\u03c9/\u03baT \u22121 . \u210f Multiplying this by the number of modes, we get the energy \u0394E in the modes that lie in the interval \u0394\u03c9 : \u0394E= \u210f\u03c9 e \u210f\u03c9/\u03baT \u22121 V \u03c9 2 \u0394\u03c9 \u03c0 2 c 3 . (4.43) This is the law for the frequency spectrum of blackbody radiation, which we have already found in Chapter 41 of Vol. I. The spectrum is plotted in Fig. 4\u201310. You see now that the answer depends on the fact that photons are Bose particles, which have a tendency to try to get all into the same state (because the amplitude for doing so is large). You will remember, it was Planck\u2019s study of the blackbody spectrum (which was a mystery to classical physics), and his discovery of the formula in Eq. (4.43) that started the whole subject of quantum mechanics. Liquid helium has at low temperatures many odd properties which we cannot unfortunately take the time to describe in detail right now, but many of them arise from the fact that a helium atom is a Bose particle. One of the things is that liquid helium flows without any viscous resistance. It is, in fact, the ideal \u201cdry\u201d water we have been talking about in one of the earlier chapters\u2014provided that the velocities are low enough. The reason is the following. In order for a liquid to have viscosity, there must be internal energy losses; there must be some way for one part of the liquid to have a motion that is different from that of the rest of the liquid. This means that it must be possible to knock some of the atoms into states that are different from the states occupied by other atoms. But at sufficiently low temperatures, when the thermal motions get very small, all the atoms try to get into the same condition. So, if some of them are moving along, then all the atoms try to move together in the same state. There is a kind of rigidity to the motion, and it is hard to break the motion up into irregular patterns of turbulence, as would happen, for example, with independent particles. So in a liquid of Bose particles, there is a strong tendency for all the atoms to go into the same state\u2014which is represented by the n+1 \u2212 \u2212 \u2212 \u2212 \u2212 \u221a factor we found earlier. (For a bottle of liquid helium n is, of course, a very large number!) This cooperative motion does not happen at high temperatures, because then there is sufficient thermal energy to put the various atoms into various different higher states. But at a sufficiently low temperature there suddenly comes a moment in which all the helium atoms try to go into the same state. The helium becomes a superfluid. Incidentally, this phenomenon only appears with the isotope of helium which has atomic weight 4 . For the helium isotope of atomic weight 3 , the individual atoms are Fermi particles, and the liquid is a normal fluid. Since superfluidity occurs only with He 4 , it is evidently a quantum mechanical effect\u2014due to the Bose nature of the \u03b1 -particle. Fermi particles act in a completely different way. Let\u2019s see what happens if we try to put two Fermi particles into the same state. We will go back to our original example and ask for the amplitude that two identical Fermi particles will be scattered into almost exactly the same direction. The amplitude that particle a will go in direction 1 and particle b will go in direction 2 is \u27e81|a\u27e9\u27e82|b\u27e9, \u27e8 | \u27e9 \u27e8 | b \u27e9 whereas the amplitude that the outgoing directions will be interchanged is \u27e82|a\u27e9\u27e81|b\u27e9. \u27e8 | \u27e9 \u27e8 | b \u27e9 Since we have Fermi particles, the amplitude for the process is the difference of these two amplitudes: \u27e81|a\u27e9\u27e82|b\u27e9\u2212\u27e82|a\u27e9\u27e81|b\u27e9. (4.44) Let\u2019s say that by \u201cdirection 1 \u201d we mean that the particle has not only a certain direction but also a given direction of its spin, and that \u201cdirection 2 \u201d is almost exactly the same as direction 1 and corresponds to the same spin direction. Then \u27e81|a\u27e9 and \u27e82|a\u27e9 are nearly equal. (This would not necessarily be true if the outgoing states 1 and 2 did not have the same spin, because there might be some reason why the amplitude would depend on the spin direction.) Now if we let directions 1 and 2 approach each other, the total amplitude in Eq. (4.44) becomes zero. The result for Fermi particles is much simpler than for Bose particles. It just isn\u2019t possible at all for two Fermi particles\u2014such as two electrons\u2014to get into exactly the same state. You will never find two electrons in the same position with their two spins in the same direction. It is not possible for two electrons to have the same momentum and the same spin directions. If they are at the same location or with the same state of motion, the only possibility is that they must be spinning opposite to each other. What are the consequences of this? There are a number of most remarkable effects which are a consequence of the fact that two Fermi particles cannot get into the same state. In fact, almost all the peculiarities of the material world hinge on this wonderful fact. The variety that is represented in the periodic table is basically a consequence of this one rule. Of course, we cannot say what the world would be like if this one rule were changed, because it is just a part of the whole structure of quantum mechanics, and it is impossible to say what else would change if the rule about Fermi particles were different. Anyway, let\u2019s just try to see what would happen if only this one rule were changed. First, we can show that every atom would be more or less the same. Let\u2019s start with the hydrogen atom. It would not be noticeably affected. The proton of the nucleus would be surrounded by a spherically symmetric electron cloud, as shown in Fig. 4\u201311(a). As we have described in Chapter 2, the electron is attracted to the center, but the uncertainty principle requires that there be a balance between the concentration in space and in momentum. The balance means that there must be a certain energy and a certain spread in the electron distribution which determines the characteristic dimension of the hydrogen atom. Now suppose that we have a nucleus with two units of charge, such as the helium nucleus. This nucleus would attract two electrons, and if they were Bose particles, they would\u2014except for their electric repulsion\u2014both crowd in as close as possible to the nucleus. A helium atom might look as shown in part (b) of the figure. Similarly, a lithium atom which has a triply charged nucleus would have an electron distribution like that shown in part (c) of Fig. 4\u201311. Every atom would look more or less the same\u2014a little round ball with all the electrons sitting near the nucleus, nothing directional and nothing complicated. Because electrons are Fermi particles, however, the actual situation is quite different. For the hydrogen atom the situation is essentially unchanged. The only difference is that the electron has a spin which we indicate by the little arrow in Fig. 4\u201312(a). In the case of a helium atom, however, we cannot put two electrons on top of each other. But wait, that is only true if their spins are the same. Two electrons can occupy the same state if their spins are opposite. So the helium atom does not look much different either. It would appear as shown in part (b) of Fig. 4\u201312. For lithium, however, the situation becomes quite different. Where can we put the third electron? The third electron cannot go on top of the other two because both spin directions are occupied. (You remember that for an electron or any particle with spin 1/2 there are only two possible directions for the spin.) The third electron can\u2019t go near the place occupied by the other two, so it must take up a special condition in a different kind of state farther away from the nucleus in part (c) of the figure. (We are speaking only in a rather rough way here, because in reality all three electrons are identical; since we cannot really distinguish which one is which, our picture is only an approximate one.) Now we can begin to see why different atoms will have different chemical properties. Because the third electron in lithium is farther out, it is relatively more loosely bound. It is much easier to remove an electron from lithium than from helium. (Experimentally, it takes 25 electron volts to ionize helium but only 5 electron volts to ionize lithium.) This accounts for the valence of the lithium atom. The directional properties of the valence have to do with the pattern of the waves of the outer electron, which we will not go into at the moment. But we can already see the importance of the so-called exclusion principle\u2014which states that no two electrons can be found in exactly the same state (including spin). The exclusion principle is also responsible for the stability of matter on a large scale. We explained earlier that the individual atoms in matter did not collapse because of the uncertainty principle; but this does not explain why it is that two hydrogen atoms can\u2019t be squeezed together as close as you want\u2014why it is that all the protons don\u2019t get close together with one big smear of electrons around them. The answer is, of course, that since no more than two electrons\u2014with opposite spins\u2014can be in roughly the same place, the hydrogen atoms must keep away from each other. So the stability of matter on a large scale is really a consequence of the Fermi particle nature of the electrons. Of course, if the outer electrons on two atoms have spins in opposite directions, they can get close to each other. This is, in fact, just the way that the chemical bond comes about. It turns out that two atoms together will generally have the lowest energy if there is an electron between them. It is a kind of an electrical attraction for the two positive nuclei toward the electron in the middle. It is possible to put two electrons more or less between the two nuclei so long as their spins are opposite, and the strongest chemical binding comes about this way. There is no stronger binding, because the exclusion principle does not allow there to be more than two electrons in the space between the atoms. We expect the hydrogen molecule to look more or less as shown in Fig. 4\u201313. We want to mention one more consequence of the exclusion principle. You remember that if both electrons in the helium atom are to be close to the nucleus, their spins are necessarily opposite. Now suppose that we would like to try to arrange to have both electrons with the same spin\u2014as we might consider doing by putting on a fantastically strong magnetic field that would try to line up the spins in the same direction. But then the two electrons could not occupy the same state in space. One of them would have to take on a different geometrical position, as indicated in Fig. 4\u201314. The electron which is located farther from the nucleus has less binding energy. The energy of the whole atom is therefore quite a bit higher. In other words, when the two spins are opposite, there is a much stronger total attraction. So, there is an apparent, enormous force trying to line up spins opposite to each other when two electrons are close together. If two electrons are trying to go in the same place, there is a very strong tendency for the spins to become lined opposite. This apparent force trying to orient the two spins opposite to each other is much more powerful than the tiny force between the two magnetic moments of the electrons. You remember when we were speaking of ferromagnetism there was the mystery of why the electrons in different atoms had a strong tendency to line up parallel. Although there is still no quantitative explanation, it is believed that what happens is that the electrons around the core of one atom interact through the exclusion principle with the outer electrons which have become free to wander throughout the crystal. This interaction causes the spins of the free electrons and the inner electrons to take on opposite directions. But the free electrons and the inner atomic electrons can only be opposite provided all the inner electrons have the same spin direction, as indicated in Fig. 4\u201315. It seems probable that it is the effect of the exclusion principle acting indirectly through the free electrons that gives rise to the strong aligning forces responsible for ferromagnetism. We will mention one further example of the influence of the exclusion principle. We have said earlier that the nuclear forces are the same between the neutron and the proton, between the proton and the proton, and between the neutron and the neutron. Why is it then that a proton and a neutron can stick together to make a deuterium nucleus, whereas there is no nucleus with just two protons or with just two neutrons? The deuteron is, as a matter of fact, bound by an energy of about 2.2 million electron volts, yet, there is no corresponding binding between a pair of protons to make an isotope of helium with the atomic weight 2 . Such nuclei do not exist. The combination of two protons does not make a bound state. The answer is a result of two effects: first, the exclusion principle; and second, the fact that the nuclear forces are somewhat sensitive to the direction of spin. The force between a neutron and a proton is attractive and somewhat stronger when the spins are parallel than when they are opposite. It happens that these forces are just different enough that a deuteron can only be made if the neutron and proton have their spins parallel; when their spins are opposite, the attraction is not quite strong enough to bind them together. Since the spins of the neutron and proton are each one-half and are in the same direction, the deuteron has a spin of one. We know, however, that two protons are not allowed to sit on top of each other if their spins are parallel. If it were not for the exclusion principle, two protons would be bound, but since they cannot exist at the same place and with the same spin directions, the He 2 nucleus does not exist. The protons could come together with their spins opposite, but then there is not enough binding to make a stable nucleus, because the nuclear force for opposite spins is too weak to bind a pair of nucleons. The attractive force between neutrons and protons of opposite spins can be seen by scattering experiments. Similar scattering experiments with two protons with parallel spins show that there is the corresponding attraction. So it is the exclusion principle that helps explain why deuterium can exist when He 2 cannot."
    },
    {
        "input": "Symmetry and Conservation Laws",
        "output": "In classical physics there are a number of quantities which are conserved\u2014such as momentum, energy, and angular momentum. Conservation theorems about corresponding quantities also exist in quantum mechanics. The most beautiful thing of quantum mechanics is that the conservation theorems can, in a sense, be derived from something else, whereas in classical mechanics they are practically the starting points of the laws. (There are ways in classical mechanics to do an analogous thing to what we will do in quantum mechanics, but it can be done only at a very advanced level.) In quantum mechanics, however, the conservation laws are very deeply related to the principle of superposition of amplitudes, and to the symmetry of physical systems under various changes. This is the subject of the present chapter. Although we will apply these ideas mostly to the conservation of angular momentum, the essential point is that the theorems about the conservation of all kinds of quantities are\u2014in the quantum mechanics\u2014related to the symmetries of the system. We begin, therefore, by studying the question of symmetries of systems. A very simple example is the hydrogen molecular ion\u2014we could equally well take the ammonia molecule\u2014in which there are two states. For the hydrogen molecular ion we took as our base states one in which the electron was located near proton number 1 , and another in which the electron was located near proton number 2 . The two states\u2014which we called |1\u27e9 and |2\u27e9 \u2014are shown again in Fig. 17\u20131(a). Now, so long as the two nuclei are both exactly the same, then there is a certain symmetry in this physical system. That is to say, if we were to reflect the system in the plane halfway between the two protons\u2014by which we mean that everything on one side of the plane gets moved to the symmetric position on the other side\u2014we would get the situations in Fig. 17\u20131(b). Since the protons are identical, the operation of reflection changes |1\u27e9 into |2\u27e9 and |2\u27e9 into |1\u27e9 . We\u2019ll call this reflection operation \u02c6 P and write \u02c6 P |1\u27e9=|2\u27e9, \u02c6 P |2\u27e9=|1\u27e9. So our \u02c6 P is an operator in the sense that it \u201cdoes something\u201d to a state to make a new state. The interesting thing is that \u02c6 P operating on any state produces some other state of the system. Now \u02c6 P , like any of the other operators we have described, has matrix elements which can be defined by the usual obvious notation. Namely, P11=\u27e81| \u02c6 P |1\u27e9andP12=\u27e81| \u02c6 P |2\u27e9 are the matrix elements we get if we multiply \u02c6 P |1\u27e9 and \u02c6 P |2\u27e9 on the left by \u27e81| . From Eq. (17.1) they are \u27e81| \u02c6 P |1\u27e9 =P11=\u27e81|2\u27e9=0, \u27e81| \u02c6 P |2\u27e9 =P12=\u27e81|1\u27e9=1. In the same way we can get P21 and P22 . The matrix of \u02c6 P \u2014with respect to the base system |1\u27e9 and |2\u27e9 \u2014is P=( 0 1 1 0 ). We see once again that the words operator and matrix in quantum mechanics are practically interchangeable. There are slight technical differences\u2014like the difference between a \u201cnumeral\u201d and a \u201cnumber\u201d\u2014but the distinction is something pedantic that we don\u2019t have to worry about. So whether \u02c6 P defines an operation, or is actually used to define a matrix of numbers, we will call it interchangeably an operator or a matrix. Now we would like to point out something. We will suppose that the physics of the whole hydrogen molecular ion system is symmetrical. It doesn\u2019t have to be\u2014it depends, for instance, on what else is near it. But if the system is symmetrical, the following idea should certainly be true. Suppose we start at t=0 with the system in the state |1\u27e9 and find after an interval of time t that the system turns out to be in a more complicated situation\u2014in some linear combination of the two base states. Remember that in Chapter 8 we used to represent \u201cgoing for a period of time\u201d by multiplying by the operator \u02c6 U . That means that the system would after a while\u2014say 15 seconds to be definite\u2014be in some other state. For example, it might be \u221a 2/3 parts of the state |1\u27e9 and i \u221a 1/3 parts of the state |2\u27e9 , and we would write |\u03c8 at 15 sec\u27e9 = \u02c6 U (15,0)|1\u27e9 = \u221a 2/3 |1\u27e9+i \u221a 1/3 |2\u27e9. Now we ask what happens if we start the system in the symmetric state |2\u27e9 and wait for 15 seconds under the same conditions? It is clear that if the world is symmetric\u2014as we are supposing\u2014we should get the state symmetric to (17.4): |\u03c8 at 15 sec\u27e9 = \u02c6 U (15,0)|2\u27e9 = \u221a 2/3 |2\u27e9+i \u221a 1/3 |1\u27e9. The same ideas are sketched diagrammatically in Fig. 17\u20132. So if the physics of a system is symmetrical with respect to some plane, and we work out the behavior of a particular state, we also know the behavior of the state we would get by reflecting the original state in the symmetry plane. We would like to say the same things a little bit more generally\u2014which means a little more abstractly. Let \u02c6 Q be any one of a number of operations that you could perform on a system without changing the physics. For instance, for \u02c6 Q we might be thinking of \u02c6 P , the operation of a reflection in the plane between the two atoms in the hydrogen molecule. Or, in a system with two electrons, we might be thinking of the operation of interchanging the two electrons. Another possibility would be, in a spherically symmetric system, the operation of a rotation of the whole system through a finite angle around some axis\u2014which wouldn\u2019t change the physics. Of course, we would normally want to give each special case some special notation for \u02c6 Q . Specifically, we will normally define the \u02c6 R y(\u03b8) to be the operation \u201crotate the system about the y -axis by the angle \u03b8 \u201d. By \u02c6 Q we mean just any one of the operators we have described or any other one\u2014which leaves the basic physical situation unchanged. Let\u2019s think of some more examples. If we have an atom with no external magnetic field and no external electric field, and if we were to turn the coordinates around any axis, it would be the same physical system. Again, the ammonia molecule is symmetrical with respect to a reflection in a plane parallel to that of the three hydrogens\u2014so long as there is no electric field. When there is an electric field, when we make a reflection we would have to change the electric field also, and that changes the physical problem. But if we have no external field, the molecule is symmetrical. Now we consider a general situation. Suppose we start with the state |\u03c81\u27e9 and after some time or other under given physical conditions it has become the state |\u03c82\u27e9 . We can write |\u03c82\u27e9= \u02c6 U |\u03c81\u27e9. [You can be thinking of Eq. (17.4).] Now imagine we perform the operation \u02c6 Q on the whole system. The state |\u03c81\u27e9 will be transformed to a state |\u03c8 \u2032 1 \u27e9 , which we can also write as \u02c6 Q |\u03c81\u27e9 . Also the state |\u03c82\u27e9 is changed into |\u03c8 \u2032 2 \u27e9= \u02c6 Q |\u03c82\u27e9 . Now if the physics is symmetrical under \u02c6 Q (don\u2019t forget the if; it is not a general property of systems), then, waiting for the same time under the same conditions, we should have |\u03c8 \u2032 2 \u27e9= \u02c6 U |\u03c8 \u2032 1 \u27e9. [Like Eq. (17.5).] But we can write \u02c6 Q |\u03c81\u27e9 for |\u03c8 \u2032 1 \u27e9 and \u02c6 Q |\u03c82\u27e9 for |\u03c8 \u2032 2 \u27e9 so (17.7) can also be written \u02c6 Q |\u03c82\u27e9= \u02c6 U \u02c6 Q |\u03c81\u27e9. If we now replace |\u03c82\u27e9 by \u02c6 U |\u03c81\u27e9 \u2014Eq. (17.6)\u2014we get \u02c6 Q \u02c6 U |\u03c81\u27e9= \u02c6 U \u02c6 Q |\u03c81\u27e9. It\u2019s not hard to understand what this means. Thinking of the hydrogen ion it says that: \u201cmaking a reflection and waiting a while\u201d\u2014the expression on the right of Eq. (17.9)\u2014is the same as \u201cwaiting a while and then making a reflection\u201d\u2014the expression on the left of (17.9). These should be the same so long as U doesn\u2019t change under the reflection. Since (17.9) is true for any starting state |\u03c81\u27e9 , it is really an equation about the operators: \u02c6 Q \u02c6 U = \u02c6 U \u02c6 Q . This is what we wanted to get\u2014it is a mathematical statement of symmetry. When Eq. (17.10) is true, we say that the operators \u02c6 U and \u02c6 Q commute. We can then define \u201csymmetry\u201d in the following way: A physical system is symmetric with respect to the operation \u02c6 Q when \u02c6 Q commutes with \u02c6 U , the operation of the passage of time. [In terms of matrices, the product of two operators is equivalent to the matrix product, so Eq. (17.10) also holds for the matrices Q and U for a system which is symmetric under the transformation Q .] Incidentally, since for infinitesimal times \u03f5 we have \u02c6 U =1\u2212i \u02c6 H \u03f5/\u210f \u2014where \u02c6 H is the usual Hamiltonian (see Chapter 8)\u2014you can see that if (17.10) is true, it is also true that \u02c6 Q \u02c6 H = \u02c6 H \u02c6 Q . So (17.11) is the mathematical statement of the condition for the symmetry of a physical situation under the operator \u02c6 Q . It defines a symmetry. Before applying the result we have just found, we would like to discuss the idea of symmetry a little more. Suppose that we have a very special situation: after we operate on a state with \u02c6 Q , we get the same state. This is a very special case, but let\u2019s suppose it happens to be true for a state |\u03c80\u27e9 that |\u03c8\u2032\u27e9= \u02c6 Q |\u03c80\u27e9 is physically the same state as |\u03c80\u27e9 . That means that |\u03c8\u2032\u27e9 is equal to |\u03c80\u27e9 except for some phase factor.1 How can that happen? For instance, suppose that we have an H + 2 ion in the state which we once called |I\u27e9 .2 For this state there is equal amplitude to be in the base states |1\u27e9 and |2\u27e9 . The probabilities are shown as a bar graph in Fig. 17\u20133(a). If we operate on |I\u27e9 with the reflection operator \u02c6 P , it flips the state over changing |1\u27e9 to |2\u27e9 and |2\u27e9 to |1\u27e9 \u2014we get the probabilities shown in Fig. 17\u20133(b). But that\u2019s just the state |I\u27e9 all over again. If we start with state |II\u27e9 the probabilities before and after reflection look just the same. However, there is a difference if we look at the amplitudes. For the state |I\u27e9 the amplitudes are the same after the reflection, but for the state |II\u27e9 the amplitudes have the opposite sign. In other words, \u02c6 P |I\u27e9 = \u02c6 P { |1\u27e9+|2\u27e9 \u221a 2 } = |2\u27e9+|1\u27e9 \u221a 2 =|I\u27e9, \u02c6 P |II\u27e9 = \u02c6 P { |1\u27e9\u2212|2\u27e9 \u221a 2 } = |2\u27e9\u2212|1\u27e9 \u221a 2 =\u2212|II\u27e9. If we write \u02c6 P |\u03c80\u27e9=ei\u03b4|\u03c80\u27e9 , we have that ei\u03b4=1 for the state |I\u27e9 and ei\u03b4=\u22121 for the state |II\u27e9 . Let\u2019s look at another example. Suppose we have a RHC polarized photon propagating in the z -direction. If we do the operation of a rotation around the z -axis, we know that this just multiplies the amplitude by ei\u03d5 when \u03d5 is the angle of the rotation. So for the rotation operation in this case, \u03b4 is just equal to the angle of rotation. Now it is clear that if it happens to be true that an operator \u02c6 Q just changes the phase of a state at some time, say t=0 , it is true forever. In other words, if the state |\u03c81\u27e9 goes over into the state |\u03c82\u27e9 after a time t , or \u02c6 U (t,0)|\u03c81\u27e9=|\u03c82\u27e9 and if the symmetry of the situation makes it so that \u02c6 Q |\u03c81\u27e9=ei\u03b4|\u03c81\u27e9, then it is also true that \u02c6 Q |\u03c82\u27e9=ei\u03b4|\u03c82\u27e9. This is clear, since \u02c6 Q |\u03c82\u27e9= \u02c6 Q \u02c6 U |\u03c81\u27e9= \u02c6 U \u02c6 Q |\u03c81\u27e9, and if \u02c6 Q |\u03c81\u27e9=ei\u03b4|\u03c81\u27e9 , then \u02c6 Q |\u03c82\u27e9= \u02c6 U ei\u03b4|\u03c81\u27e9=ei\u03b4 \u02c6 U |\u03c81\u27e9=ei\u03b4|\u03c82\u27e9. [The sequence of equalities follows from (17.13) and (17.10) for a symmetrical system, from (17.14), and from the fact that a number like ei\u03b4 commutes with an operator.] So with certain symmetries something which is true initially is true for all times. But isn\u2019t that just a conservation law? Yes! It says that if you look at the original state and by making a little computation on the side discover that an operation which is a symmetry operation of the system produces only a multiplication by a certain phase, then you know that the same property will be true of the final state\u2014the same operation multiplies the final state by the same phase factor. This is always true even though we may not know anything else about the inner mechanism of the universe which changes a system from the initial to the final state. Even if we do not care to look at the details of the machinery by which the system gets from one state to another, we can still say that if a thing is in a state with a certain symmetry character originally, and if the Hamiltonian for this thing is symmetrical under that symmetry operation, then the state will have the same symmetry character for all times. That\u2019s the basis of all the conservation laws of quantum mechanics. Let\u2019s look at a special example. Let\u2019s go back to the \u02c6 P operator. We would like first to modify a little our definition of \u02c6 P . We want to take for \u02c6 P not just a mirror reflection, because that requires defining the plane in which we put the mirror. There is a special kind of a reflection that doesn\u2019t require the specification of a plane. Suppose we redefine the operation \u02c6 P this way: First you reflect in a mirror in the z -plane so that z goes to \u2212z , x stays x , and y stays y ; then you turn the system 180\u2218 about the z -axis so that x is made to go to \u2212x and y to \u2212y . The whole thing is called an inversion. Every point is projected through the origin to the diametrically opposite position. All the coordinates of everything are reversed. We will still use the symbol \u02c6 P for this operation. It is shown in Fig. 17\u20134. It is a little more convenient than a simple reflection because it doesn\u2019t require that you specify which coordinate plane you used for the reflection\u2014you need specify only the point which is at the center of symmetry. Now let\u2019s suppose that we have a state | \u03c8 0 \u27e9 which under the inversion operation goes into e i\u03b4 | \u03c8 0 \u27e9 \u2014that is, | \u03c8 \u2032 0 \u27e9= P ^ | \u03c8 0 \u27e9= e i\u03b4 | \u03c8 0 \u27e9. (17.16) Then suppose that we invert again. After two inversions we are right back where we started from\u2014nothing is changed at all. We must have that P ^ | \u03c8 \u2032 0 \u27e9= P ^ \u22c5 P ^ | \u03c8 0 \u27e9=| \u03c8 0 \u27e9. But P ^ \u22c5 P ^ | \u03c8 0 \u27e9= P ^ e i\u03b4 | \u03c8 0 \u27e9= e i\u03b4 P ^ | \u03c8 0 \u27e9=( e i\u03b4 ) 2 | \u03c8 0 \u27e9. It follows that ( e i\u03b4 ) 2 =1. 2 So if the inversion operator is a symmetry operation of a state, there are only two possibilities for e i\u03b4 : e i\u03b4 =\u00b11, i \u03b4 which means that P ^ | \u03c8 0 \u27e9=| \u03c8 0 \u27e9or P ^ | \u03c8 0 \u27e9=\u2212| \u03c8 0 \u27e9. (17.17) Classically, if a state is symmetric under an inversion, the operation gives back the same state. In quantum mechanics, however, there are the two possibilities: we get the same state or minus the same state. When we get the same state, P ^ | \u03c8 0 \u27e9=| \u03c8 0 \u27e9 , we say that the state | \u03c8 0 \u27e9 has even parity. When the sign is reversed so that P ^ | \u03c8 0 \u27e9=\u2212| \u03c8 0 \u27e9 , we say that the state has odd parity. (The inversion operator P ^ is also known as the parity operator.) The state |I\u27e9 of the H + 2 ion has even parity; and the state |II\u27e9 has odd parity\u2014see Eq. (17.12). There are, of course, states which are not symmetric under the operation P ^ ; these are states with no definite parity. For instance, in the H + 2 system the state |I\u27e9 has even parity, the state |II\u27e9 has odd parity, and the state |1\u27e9 has no definite parity. When we speak of an operation like inversion being performed \u201con a physical system\u201d we can think about it in two ways. We can think of physically moving whatever is at r to the inverse point at \u2212r , or we can think of looking at the same system from a new frame of reference x \u2032 , y \u2032 , z \u2032 related to the old by x \u2032 =\u2212x , y \u2032 =\u2212y , and z \u2032 =\u2212z . Similarly, when we think of rotations, we can think of rotating bodily a physical system, or of rotating the coordinate frame with respect to which we measure the system, keeping the \u201csystem\u201d fixed in space. Generally, the two points of view are essentially equivalent. For rotation they are equivalent except that rotating a system by the angle \u03b8 is like rotating the reference frame by the negative of \u03b8 . In these lectures we have usually considered what happens when a projection is made into a new set of axes. What you get that way is the same as what you get if you leave the axes fixed and rotate the system backwards by the same amount. When you do that, the signs of the angles are reversed.3 Many of the laws of physics\u2014but not all\u2014are unchanged by a reflection or an inversion of the coordinates. They are symmetric with respect to an inversion. The laws of electrodynamics, for instance, are unchanged if we change x to \u2212x , y to \u2212y , and z to \u2212z in all the equations. The same is true for the laws of gravity, and for the strong interactions of nuclear physics. Only the weak interactions\u2014responsible for \u03b2 -decay\u2014do not have this symmetry. (We discussed this in some detail in Chapter 52, Vol. I.) We will for now leave out any consideration of the \u03b2 -decays. Then in any physical system where \u03b2 -decays are not expected to produce any appreciable effect\u2014an example would be the emission of light by an atom\u2014the Hamiltonian H ^ and the operator P ^ will commute. Under these circumstances we have the following proposition. If a state originally has even parity, and if you look at the physical situation at some later time, it will again have even parity. For instance, suppose an atom about to emit a photon is in a state known to have even parity. You look at the whole thing\u2014including the photon\u2014after the emission; it will again have even parity (likewise if you start with odd parity). This principle is called the conservation of parity. You can see why the words \u201cconservation of parity\u201d and \u201creflection symmetry\u201d are closely intertwined in the quantum mechanics. Although until a few years ago it was thought that nature always conserved parity, it is now known that this is not true. It has been discovered to be false because the \u03b2 -decay reaction does not have the inversion symmetry which is found in the other laws of physics. Now we can prove an interesting theorem (which is true so long as we can disregard weak interactions): Any state of definite energy which is not degenerate must have a definite parity. It must have either even parity or odd parity. (Remember that we have sometimes seen systems in which several states have the same energy\u2014we say that such states are degenerate. Our theorem will not apply to them.) For a state | \u03c8 0 \u27e9 of definite energy, we know that H ^ | \u03c8 0 \u27e9=E| \u03c8 0 \u27e9, (17.18) where E is just a number\u2014the energy of the state. If we have any operator Q ^ which is a symmetry operator of the system we can prove that Q ^ | \u03c8 0 \u27e9= e i\u03b4 | \u03c8 0 \u27e9 (17.19) so long as | \u03c8 0 \u27e9 is a unique state of definite energy. Consider the new state | \u03c8 \u2032 0 \u27e9 that you get from operating with Q ^ . If the physics is symmetric, then | \u03c8 \u2032 0 \u27e9 must have the same energy as | \u03c8 0 \u27e9 . But we have taken a situation in which there is only one state of that energy, namely | \u03c8 0 \u27e9 , so | \u03c8 \u2032 0 \u27e9 must be the same state\u2014it can only differ by a phase. That\u2019s the physical argument. The same thing comes out of our mathematics. Our definition of symmetry is Eq. (17.10) or Eq. (17.11) (good for any state \u03c8 ), H ^ Q ^ |\u03c8\u27e9= Q ^ H ^ |\u03c8\u27e9. (17.20) But we are considering only a state | \u03c8 0 \u27e9 which is a definite energy state, so that H ^ | \u03c8 0 \u27e9=E| \u03c8 0 \u27e9 . Since E is just a number that floats through Q ^ if we want, we have Q ^ H ^ | \u03c8 0 \u27e9= Q ^ E| \u03c8 0 \u27e9=E Q ^ | \u03c8 0 \u27e9. So H ^ { Q ^ | \u03c8 0 \u27e9}=E{ Q ^ | \u03c8 0 \u27e9}. (17.21) So | \u03c8 \u2032 0 \u27e9= Q ^ | \u03c8 0 \u27e9 is also a definite energy state of H ^ \u2014and with the same E . But by our hypothesis, there is only one such state; it must be that | \u03c8 \u2032 0 \u27e9= e i\u03b4 | \u03c8 0 \u27e9 . What we have just proved is true for any operator Q ^ that is a symmetry operator of the physical system. Therefore, in a situation in which we consider only electrical forces and strong interactions\u2014and no \u03b2 -decay\u2014so that inversion symmetry is an allowed approximation, we have that P ^ |\u03c8\u27e9= e i\u03b4 |\u03c8\u27e9 . But we have also seen that e i\u03b4 must be either +1 or \u22121 . So any state of a definite energy (which is not degenerate) has got either an even parity or an odd parity. We turn now to another interesting example of an operation: a rotation. We consider the special case of an operator that rotates an atomic system by angle \u03d5 around the z -axis. We will call this operator4 R ^ z (\u03d5) . We are going to suppose that we have a physical situation where we have no influences lined up along the x - and y -axes. Any electric field or magnetic field is taken to be parallel to the z -axis5 so that there will be no change in the external conditions if we rotate the whole physical system about the z -axis. For example, if we have an atom in empty space and we turn the atom around the z -axis by an angle \u03d5 , we have the same physical system. Now then, there are special states which have the property that such an operation produces a new state which is the original state multiplied by some phase factor. Let us make a quick side remark to show you that when this is true the phase change must always be proportional to the angle \u03d5 . Suppose that you would rotate twice by the angle \u03d5 . That\u2019s the same thing as rotating by the angle 2\u03d5 . If a rotation by \u03d5 has the effect of multiplying the state | \u03c8 0 \u27e9 by a phase e i\u03b4 so that R ^ z (\u03d5)| \u03c8 0 \u27e9= e i\u03b4 | \u03c8 0 \u27e9, two such rotations in succession would multiply the state by the factor ( e i\u03b4 ) 2 = e i2\u03b4 , since R ^ z (\u03d5) R ^ z (\u03d5)| \u03c8 0 \u27e9 = = = R ^ z (\u03d5) e i\u03b4 | \u03c8 0 \u27e9 e i\u03b4 R ^ z (\u03d5)| \u03c8 0 \u27e9 e i\u03b4 e i\u03b4 | \u03c8 0 \u27e9 . The phase change \u03b4 must be proportional to \u03d5 .6 We are considering then those special states | \u03c8 0 \u27e9 for which R ^ z (\u03d5)| \u03c8 0 \u27e9= e im\u03d5 | \u03c8 0 \u27e9, (17.22) where m is some real number. We also know the remarkable fact that if the system is symmetrical for a rotation around z and if the original state happens to have the property that (17.22) is true, then it will also have the same property later on. So this number m is a very important one. If we know its value initially, we know its value at the end of the game. It is a number which is conserved\u2014 m is a constant of the motion. The reason that we pull out m is because it hasn\u2019t anything to do with any special angle \u03d5 , and also because it corresponds to something in classical mechanics. In quantum mechanics we choose to call m\u210f \u2014for such states as | \u03c8 0 \u27e9 \u2014the angular momentum about the z -axis. If we do that we find that in the limit of large systems the same quantity is equal to the z -component of the angular momentum of classical mechanics. So if we have a state for which a rotation about the z -axis just produces a phase factor e im\u03d5 , then we have a state of definite angular momentum about that axis\u2014and the angular momentum is conserved. It is m\u210f now and forever. Of course, you can rotate about any axis, and you get the conservation of angular momentum for the various axes. You see that the conservation of angular momentum is related to the fact that when you turn a system you get the same state with only a new phase factor. We would like to show you how general this idea is. We will apply it to two other conservation laws which have exact correspondence in the physical ideas to the conservation of angular momentum. In classical physics we also have conservation of momentum and conservation of energy, and it is interesting to see that both of these are related in the same way to some physical symmetry. Suppose that we have a physical system\u2014an atom, some complicated nucleus, or a molecule, or something\u2014and it doesn\u2019t make any difference if we take the whole system and move it over to a different place. So we have a Hamiltonian which has the property that it depends only on the internal coordinates in some sense, and does not depend on the absolute position in space. Under those circumstances there is a special symmetry operation we can perform which is a translation in space. Let\u2019s define D ^ x (a) as the operation of a displacement by the distance a along the x -axis. Then for any state we can make this operation and get a new state. But again there can be very special states which have the property that when you displace them by a along the x -axis you get the same state except for a phase factor. It\u2019s also possible to prove, just as we did above, that when this happens, the phase must be proportional to a . So we can write for these special states | \u03c8 0 \u27e9 D ^ x (a)| \u03c8 0 \u27e9= e ika | \u03c8 0 \u27e9. (17.23) The coefficient k , when multiplied by \u210f , is called the x -component of the momentum. And the reason it is called that is that this number is numerically equal to the classical momentum p x when we have a large system. The general statement is this: If the Hamiltonian is unchanged when the system is displaced, and if the state starts with a definite momentum in the x -direction, then the momentum in the x -direction will remain the same as time goes on. The total momentum of a system before and after collisions\u2014or after explosions or what not\u2014will be the same. There is another operation that is quite analogous to the displacement in space: a delay in time. Suppose that we have a physical situation where there is nothing external that depends on time, and we start something off at a certain moment in a given state and let it roll. Now if we were to start the same thing off again (in another experiment) two seconds later\u2014or/say, delayed by a time \u03c4 \u2014and if nothing in the external conditions depends on the absolute time, the development would be the same and the final state would be the same as the other final state, except that it will get there later by the time \u03c4 . Under those circumstances we can also find special states which have the property that the development in time has the special characteristic that the delayed state is just the old, multiplied by a phase factor. Once more it is clear that for these special states the phase change must be proportional to \u03c4 . We can write D ^ t (\u03c4)| \u03c8 0 \u27e9= e \u2212i\u03c9\u03c4 | \u03c8 0 \u27e9. (17.24) It is conventional to use the negative sign in defining \u03c9 ; with this convention \u03c9\u210f is the energy of the system, and it is conserved. So a system of definite energy is one which when displaced \u03c4 in time reproduces itself multiplied by e \u2212i\u03c9\u03c4 . (That\u2019s what we have said before when we defined a quantum state of definite energy, so we\u2019re consistent with ourselves.) It means that if a system is in a state of definite energy, and if the Hamiltonian doesn\u2019t depend on t , then no matter what goes on, the system will have the same energy at all later times. You see, therefore, the relation between the conservation laws and the symmetry of the world. Symmetry with respect to displacements in time implies the conservation of energy; symmetry with respect to position in x , y , or z implies the conservation of that component of momentum. Symmetry with respect to rotations around the x -, y -, and z -axes implies the conservation of the x -, y -, and z -components of angular momentum. Symmetry with respect to reflection implies the conservation of parity. Symmetry with respect to the interchange of two electrons implies the conservation of something we don\u2019t have a name for, and so on. Some of these principles have classical analogs and others do not. There are more conservation laws in quantum mechanics than are useful in classical mechanics\u2014or, at least, than are usually made use of. In order that you will be able to read other books on quantum mechanics, we must make a small technical aside\u2014to describe the notation that people use. The operation of a displacement with respect to time is, of course, just the operation U ^ that we talked about before: D ^ t (\u03c4)= U ^ (t+\u03c4,t). (17.25) Most people like to discuss everything in terms of infinitesimal displacements in time, or in terms of infinitesimal displacements in space, or in terms of rotations through infinitesimal angles. Since any finite displacement or angle can be accumulated by a succession of infinitesimal displacements or angles, it is often easier to analyze first the infinitesimal case. The operator of an infinitesimal displacement \u0394t in time is\u2014as we have defined it in Chapter 8\u2014 D ^ t (\u0394t)=1\u2212 i \u210f \u0394t H ^ . (17.26) Then H ^ is analogous to the classical quantity we call energy, because if H ^ |\u03c8\u27e9 happens to be a constant times |\u03c8\u27e9 namely, H ^ |\u03c8\u27e9=E|\u03c8\u27e9 then that constant is the energy of the system. The same thing is done for the other operations. If we make a small displacement in x , say by the amount \u0394x , a state |\u03c8\u27e9 will, in general, go over into some other state | \u03c8 \u2032 \u27e9 . We can write | \u03c8 \u2032 \u27e9= D ^ x (\u0394x)|\u03c8\u27e9=(1+ i \u210f p ^ x \u0394x)|\u03c8\u27e9, (17.27) since as \u0394x goes to zero, the | \u03c8 \u2032 \u27e9 should become just |\u03c8\u27e9 or D ^ x (0)=1 , and for small \u0394x the change of D ^ x (\u0394x) from 1 should be proportional to \u0394x . Defined this way, the operator p ^ x is called the momentum operator\u2014for the x -component, of course. For identical reasons, people usually write for small rotations R ^ z (\u0394\u03d5)|\u03c8\u27e9=(1+ i \u210f J ^ z \u0394\u03d5)|\u03c8\u27e9 (17.28) and call J ^ z the operator of the z -component of angular momentum. For those special states for which R ^ z (\u03d5)| \u03c8 0 \u27e9= e im\u03d5 | \u03c8 0 \u27e9 , we can for any small angle\u2014say \u0394\u03d5 \u2014expand the right-hand side to first order in \u0394\u03d5 and get R ^ z (\u0394\u03d5)| \u03c8 0 \u27e9= e im\u0394\u03d5 | \u03c8 0 \u27e9=(1+im\u0394\u03d5)| \u03c8 0 \u27e9. Comparing this with the definition of J ^ z in Eq. (17.28), we get that J ^ z | \u03c8 0 \u27e9=m\u210f| \u03c8 0 \u27e9. (17.29) In other words, if you operate with J ^ z on a state with a definite angular momentum about the z -axis, you get m\u210f times the same state, where m\u210f is the amount of z -component of angular momentum. It is quite analogous to operating on a definite energy state with H ^ to get E|\u03c8\u27e9 . We would now like to make some applications of the ideas of the conservation of angular momentum\u2014to show you how they work. The point is that they are really very simple. You knew before that angular momentum is conserved. The only thing you really have to remember from this chapter is that if a state | \u03c8 0 \u27e9 has the property that upon a rotation through an angle \u03d5 about the z -axis, it becomes e im\u03d5 | \u03c8 0 \u27e9 ; it has a z -component of angular momentum equal to m\u210f . That\u2019s all we will need to do a number of interesting things. First of all we would like to check on one idea. In Section 11-4 we showed that when RHC polarized light is viewed in a frame rotated by the angle \u03d5 about the z -axis7 it gets multiplied by e i\u03d5 . Does that mean then that the photons of light that are right circularly polarized carry an angular momentum of one unit8 along the z -axis? Indeed it does. It also means that if we have a beam of light containing a large number of photons all circularly polarized the same way\u2014as we would have in a classical beam\u2014it will carry angular momentum. If the total energy carried by the beam in a certain time is W , then there are N=W/\u210f\u03c9 photons. Each one carries the angular momentum \u210f , so there is a total angular momentum of J z =N\u210f= W \u03c9 . (17.30) Can we prove classically that light which is right circularly polarized carries an energy and angular momentum in proportion to W/\u03c9 ? That should be a classical proposition if everything is right. Here we have a case where we can go from the quantum thing to the classical thing. We should see if the classical physics checks. It will give us an idea whether we have a right to call m the angular momentum. Remember what right circularly polarized light is, classically. It\u2019s described by an electric field with an oscillating x -component and an oscillating y -component 90 \u2218 out of phase so that the resultant electric vector E goes in a circle\u2014as drawn in Fig. 17\u20135(a). Now suppose that such light shines on a wall which is going to absorb it\u2014or at least some of it\u2014and consider an atom in the wall according to the classical physics. We have often described the motion of the electron in the atom as a harmonic oscillator which can be driven into oscillation by an external electric field. We\u2019ll suppose that the atom is isotropic, so that it can oscillate equally well in the x - or y -directions. Then in the circularly polarized light, the x -displacement and the y -displacement are the same, but one is 90 \u2218 behind the other. The net result is that the electron moves in a circle, as shown in Fig. 17\u20135(b). The electron is displaced at some displacement r from its equilibrium position at the origin and goes around with some phase lag with respect to the vector E . The relation between E and r might be as shown in Fig. 17\u20135(b). As time goes on, the electric field rotates and the displacement rotates with the same frequency, so their relative orientation stays the same. Now let\u2019s look at the work being done on this electron. The rate that energy is being put into this electron is v , its velocity, times the component of qE parallel to the velocity: dW dt =q E t v. (17.31) But look, there is angular momentum being poured into this electron, because there is always a torque about the origin. The torque is q E t r , which must be equal to the rate of change of angular momentum d J z /dt : d J z dt =q E t r. (17.32) Remembering that v=\u03c9r , we have that d J z dW = 1 \u03c9 . d J Therefore, if we integrate the total angular momentum which is absorbed, it is proportional to the total energy\u2014the constant of proportionality being 1/\u03c9 , which agrees with Eq. (17.30). Light does carry angular momentum\u2014 1 unit (times \u210f ) if it is right circularly polarized along the z -axis, and \u22121 unit along the z -axis if it is left circularly polarized. Now let\u2019s ask the following question: If light is linearly polarized in the x -direction, what is its angular momentum? Light polarized in the x -direction can be represented as the superposition of RHC and LHC polarized light. Therefore, there is a certain amplitude that the angular momentum is +\u210f and another amplitude that the angular momentum is \u2212\u210f , so it doesn\u2019t have a definite angular momentum. It has an amplitude to appear with +\u210f and an equal amplitude to appear with \u2212\u210f . The interference of these two amplitudes produces the linear polarization, but it has equal probabilities to appear with plus or minus one unit of angular momentum. Macroscopic measurements made on a beam of linearly polarized light will show that it carries zero angular momentum, because in a large number of photons there are nearly equal numbers of RHC and LHC photons contributing opposite amounts of angular momentum\u2014the average angular momentum is zero. And in the classical theory you don\u2019t find the angular momentum unless there is some circular polarization. We have said that any spin-one particle can have three values of J z , namely +1,0,\u22121 (the three states we saw in the Stern-Gerlach experiment). But light is screwy; it has only two states. It does not have the zero case. This strange lack is related to the fact that light cannot stand still. For a particle of spin j which is standing still, there must be the 2j+1 possible states with values of j z going in steps of 1 from \u2212j to +j . But it turns out that for something of spin j with zero mass only the states with the components +j and \u2212j along the direction of motion exist. For example, light does not have three states, but only two\u2014although a photon is still an object of spin one. How is this consistent with our earlier proofs\u2014based on what happens under rotations in space\u2014that for spin-one particles three states are necessary? For a particle at rest, rotations can be made about any axis without changing the momentum state. Particles with zero rest mass (like photons and neutrinos) cannot be at rest; only rotations about the axis along the direction of motion do not change the momentum state. Arguments about rotations around one axis only are insufficient to prove that three states are required, given that one of them varies as e i\u03d5 under rotations by the angle \u03d5 .9 One further side remark. For a zero rest mass particle, in general, only one of the two spin states with respect to the line of motion ( +j , \u2212j ) is really necessary. For neutrinos\u2014which are spin one-half particles\u2014only the states with the component of angular momentum opposite to the direction of motion (\u2212\u210f/2) exist in nature [and only along the motion (+\u210f/2) for antineutrinos]. When a system has inversion symmetry (so that parity is conserved, as it is for light) both components ( +j , and \u2212j ) are required. Now we want to give an example of how we use the theorem of conservation of angular momentum in a specifically quantum physical problem. We look at break-up of the lambda particle ( \u039b 0 ), which disintegrates into a proton and a \u03c0 \u2212 meson by a \u201cweak\u201d interaction: \u039b 0 \u2192p+ \u03c0 \u2212 . 0 Assume we know that the pion has spin zero, that the proton has spin one-half, and that the \u039b 0 has spin one-half. We would like to solve the following problem: Suppose that a \u039b 0 were to be produced in a way that caused it to be completely polarized\u2014by which we mean that its spin is, say \u201cup,\u201d with respect to some suitably chosen z -axis\u2014see Fig. 17\u20136(a). The question is, with what probability will it disintegrate so that the proton goes off at an angle \u03b8 with respect to the z -axis\u2014as in Fig. 17\u20136(b)? In other words, what is the angular distribution of the disintegrations? We will look at the disintegration in the coordinate system in which the \u039b 0 is at rest\u2014we will measure the angles in this rest frame; then they can always be transformed to another frame if we want. We begin by looking at the special circumstance in which the proton is emitted into a small solid angle \u0394\u03a9 along the z -axis (Fig. 17\u20137). Before the disintegration we have a \u039b 0 with its spin \u201cup,\u201d as in part (a) of the figure. After a short time\u2014for reasons unknown to this day, except that they are connected with the weak decays\u2014the \u039b 0 explodes into a proton and a pion. Suppose the proton goes up along the +z -axis. Then, from the conservation of momentum, the pion must go down. Since the proton is a spin one-half particle, its spin must be either \u201cup\u201d or \u201cdown\u201d\u2014there are, in principle, the two possibilities shown in parts (b) and (c) of the figure. The conservation of angular momentum, however, requires that the proton have spin \u201cup.\u201d This is most easily seen from the following argument. A particle moving along the z -axis cannot contribute any angular momentum about this axis by virtue of its motion; therefore, only the spins can contribute to J z . The spin angular momentum about the z -axis is +\u210f/2 before the disintegration, so it must also be +\u210f/2 afterward. We can say that since the pion has no spin, the proton spin must be \u201cup.\u201d If you are worried that arguments of this kind may not be valid in quantum mechanics, we can take a moment to show you that they are. The initial state (before the disintegration), which we can call | \u039b 0 ,spin +z\u27e9 has the property that if it is rotated about the z -axis by the angle \u03d5 , the state vector gets multiplied by the phase factor e i\u03d5/2 . (In the rotated system the state vector is e i\u03d5/2 | \u039b 0 ,spin +z\u27e9 .) That\u2019s what we mean by spin \u201cup\u201d for a spin one-half particle. Since nature\u2019s behavior doesn\u2019t depend on our choice of axes, the final state (the proton plus pion) must have the same property. We could write the final state as, say, |proton going +z, spin +z; pion going \u2212z\u27e9. | \u27e9 But we really do not need to specify the pion motion, since in the frame we have chosen the pion always moves opposite the proton; we can simplify our description of the final state to |proton going +z, spin +z\u27e9. | \u27e9 Now what happens to this state vector if we rotate the coordinates about the z -axis by the angle \u03d5 ? Since the proton and pion are moving along the z -axis, their motion isn\u2019t changed by the rotation. (That\u2019s why we picked this special case; we couldn\u2019t make the argument otherwise.) Also, nothing happens to the pion, because it is spin zero. The proton, however, has spin one-half. If its spin is \u201cup\u201d it will contribute a phase change of e i\u03d5/2 in response to the rotation. (If its spin were \u201cdown\u201d the phase change due to the proton would be e \u2212i\u03d5/2 .) But the phase change with rotation before and after the excitement must be the same if angular momentum is to be conserved. (And it will be, since there are no outside influences in the Hamiltonian.) So the only possibility is that the proton spin will be \u201cup.\u201d If the proton goes up, its spin must also be \u201cup.\u201d We conclude, then, that the conservation of angular momentum permits the process shown in part (b) of Fig. 17\u20137, but does not permit the process shown in part (c). Since we know that the disintegration occurs, there is some amplitude for process (b)\u2014proton going up with spin \u201cup.\u201d We\u2019ll let a stand for the amplitude that the disintegration occurs in this way in any infinitesimal interval of time.10 Now let\u2019s see what would happen if the \u039b 0 spin were initially \u201cdown.\u201d Again we ask about the decays in which the proton goes up along the z -axis, as shown in Fig. 17\u20138. You will appreciate that in this case the proton must have spin \u201cdown\u201d if angular momentum is conserved. Let\u2019s say that the amplitude for such a disintegration is b . We can\u2019t say anything more about the two amplitudes a and b . They depend on the inner machinery of \u039b 0 , and the weak decays, and nobody yet knows how to calculate them. We\u2019ll have to get them from experiment. But with just these two amplitudes we can find out all we want to know about the angular distribution of the disintegration. We only have to be careful always to define completely the states we are talking about. We want to know the probability that the proton will go off at the angle \u03b8 with respect to the z -axis (into a small solid angle \u0394\u03a9 ) as drawn in Fig. 17\u20136. Let\u2019s put a new z -axis in this direction and call it the z \u2032 -axis. We know how to analyze what happens along this axis. With respect to this new axis, the \u039b 0 no longer has its spin \u201cup,\u201d but has a certain amplitude to have its spin \u201cup\u201d and another amplitude to have its spin \u201cdown.\u201d We have already worked these out in Chapter 6, and again in Chapter 10, Eq. (10.30). The amplitude to be spin \u201cup\u201d is cos\u03b8/2 , and the amplitude to be spin \u201cdown\u201d is11 \u2212sin\u03b8/2 . When the \u039b 0 spin is \u201cup\u201d along the z \u2032 -axis it will emit a proton in the + z \u2032 -direction with the amplitude a . So the amplitude to find an \u201cup\u201d-spinning proton coming out along the z \u2032 -direction is acos \u03b8 2 . (17.33) Similarly, the amplitude to find a \u201cdown\u201d-spinning proton coming along the positive z \u2032 -axis is \u2212bsin \u03b8 2 . (17.34) The two processes that these amplitudes refer to are shown in Fig. 17\u20139. Let\u2019s now ask the following easy question. If the \u039b 0 has spin up along the z -axis, what is the probability that the decay proton will go off at the angle \u03b8 ? The two spin states (\u201cup\u201d or \u201cdown\u201d along z \u2032 ) are distinguishable even though we are not going to look at them. So to get the probability we square the amplitudes and add. The probability f(\u03b8) of finding a proton in a small solid angle \u0394\u03a9 at \u03b8 is f(\u03b8)=|a | 2 cos 2 \u03b8 2 +|b | 2 sin 2 \u03b8 2 . (17.35) Remembering that sin 2 \u03b8/2= 1 2 (1\u2212cos\u03b8) and that cos 2 \u03b8/2= 1 2 (1+cos\u03b8) , we can write f(\u03b8) as f(\u03b8)=( |a | 2 +|b | 2 2 )+( |a | 2 \u2212|b | 2 2 )cos\u03b8. (17.36) The angular distribution has the form f(\u03b8)=\u03b2(1+\u03b1cos\u03b8). (17.37) The probability has one part that is independent of \u03b8 and one part that varies linearly with cos\u03b8 . From measuring the angular distribution we can get \u03b1 and \u03b2 , and therefore, |a| and |b| . Now there are many other questions we can answer. Are we interested only in protons with spin \u201cup\u201d along the old z -axis? Each of the terms in (17.33) and (17.34) will give an amplitude to find a proton with spin \u201cup\u201d and with spin \u201cdown\u201d with respect to the z \u2032 -axis ( + z \u2032 and \u2212 z \u2032 ). Spin \u201cup\u201d with respect to the old axis |+z\u27e9 can be expressed in terms of the base states |+ z \u2032 \u27e9 and |\u2212 z \u2032 \u27e9 . We can then combine the two amplitudes (17.33) and (17.34) with the proper coefficients ( cos\u03b8/2 and \u2212sin\u03b8/2 ) to get the total amplitude (a cos 2 \u03b8 2 +b sin 2 \u03b8 2 ). \u03b8 \u03b8 Its square is the probability that the proton comes out at the angle \u03b8 with its spin the same as the \u039b 0 (\u201cup\u201d along the z -axis). If parity were conserved, we could say one more thing. The disintegration of Fig. 17\u20138 is just the reflection\u2014in the xy -plane of the disintegration\u2014of Fig. 17\u20137.12 If parity were conserved, b would have to be equal to a or to \u2212a . Then the coefficient \u03b1 of (17.37) would be zero, and the disintegration would be equally likely to occur in all directions. The experimental results show, however, that there is an asymmetry in the disintegration. The measured angular distribution does go as cos\u03b8 as we predict\u2014and not as cos 2 \u03b8 or any other power. In fact, since the angular distribution has this form, we can deduce from these measurements that the spin of the \u039b 0 is 1/2 . Also, we see that parity is not conserved. In fact, the coefficient \u03b1 is found experimentally to be \u22120.62\u00b10.05 , so b is about twice as large as a . The lack of symmetry under a reflection is quite clear. You see how much we can get from the conservation of angular momentum. We will give some more examples in the next chapter. Parenthetical note. By the amplitude a in this section we mean the amplitude that the state |proton going +z, spin +z\u27e9 is generated in an infinitesimal time dt from the state |\u039b, spin +z\u27e9 , or, in other words, that \u27e8proton going +z, spin +z|H|\u039b, spin +z\u27e9=i\u210fa, (17.38) where H is the Hamiltonian of the world\u2014or, at least, of whatever is responsible for the \u039b -decay. The conservation of angular momentum means that the Hamiltonian must have the property that \u27e8proton going +z, spin \u2212z|H|\u039b, spin +z\u27e9=0. (17.39) By the amplitude b we mean that \u27e8proton going +z, spin \u2212z|H|\u039b, spin \u2212z\u27e9=i\u210fb. (17.40) Conservation of angular momentum implies that \u27e8proton going +z, spin +z|H|\u039b, spin \u2212z\u27e9=0. (17.41) If the amplitudes written in (17.33) and (17.34) are not clear, we can express them more mathematically as follows. By (17.33) we intend the amplitude that the \u039b with spin along +z will disintegrate into a proton moving along the + z \u2032 -direction with its spin also in the + z \u2032 -direction, namely the amplitude \u27e8proton going + z \u2032 , spin + z \u2032 |H|\u039b, spin +z\u27e9. (17.42) By the general theorems of quantum mechanics, this amplitude can be written as \u2211 i \u27e8proton going + z \u2032 , spin + z \u2032 |H|\u039b,i\u27e9\u27e8\u039b,i|\u039b, spin +z\u27e9, (17.43) where the sum is to be taken over the base states |\u039b,i\u27e9 of the \u039b -particle at rest. Since the \u039b -particle is spin one-half, there are two such base states which can be in any reference base we wish. If we use for base states spin \u201cup\u201d and spin \u201cdown\u201d with respect to z \u2032 ( + z \u2032 , \u2212 z \u2032 ), the amplitude of (17.43) is equal to the sum + \u27e8proton going + z \u2032 , spin + z \u2032 |H|\u039b,+ z \u2032 \u27e9\u27e8\u039b,+ z \u2032 |\u039b,+z\u27e9 \u27e8proton going + z \u2032 , spin + z \u2032 |H|\u039b,\u2212 z \u2032 \u27e9\u27e8\u039b,\u2212 z \u2032 |\u039b,+z\u27e9. (17.44) The first factor of the first term is a , and the first factor of the second term is zero\u2014from the definition of (17.38), and from (17.41), which in turn follows from angular momentum conservation. The remaining factor \u27e8\u039b,+ z \u2032 |\u039b,+z\u27e9 of the first term is just the amplitude that a spin one-half particle which has spin \u201cup\u201d along one axis will also have spin \u201cup\u201d along an axis tilted at the angle \u03b8 , which is cos\u03b8/2 \u2014see Table 6\u20132. So (17.44) is just acos\u03b8/2 , as we wrote in (17.33). The amplitude of (17.34) follows from the same kind of arguments for a spin \u201cdown\u201d \u039b -particle. We would like now to bring together in one place the various things we have learned about the rotations for particles of spin one-half and spin one\u2014so they will be convenient for future reference. On the next page you will find tables of the two rotation matrices R z (\u03d5) and R y (\u03b8) for spin one-half particles, for spin-one particles, and for photons (spin-one particles with zero rest mass). For each spin we will give the terms of the matrix \u27e8j|R|i\u27e9 for rotations about the z -axis or the y -axis. They are, of course, exactly equivalent to the amplitudes like \u27e8+T|0S\u27e9 we have used in earlier chapters. We mean by R z (\u03d5) that the state is projected into a new coordinate system which is rotated through the angle \u03d5 about the z -axis\u2014using always the right-hand rule to define the positive sense of the rotation. By R y (\u03b8) we mean that the reference axes are rotated by the angle \u03b8 about the y -axis. Knowing these two rotations, you can, of course, work out any arbitrary rotation. As usual, we write the matrix elements so that the state on the left is a base state of the new (rotated) frame and the state on the right is a base state of the old (unrotated) frame. You can interpret the entries in the tables in many ways. For instance, the entry e \u2212i\u03d5/2 in Table 17\u20131 means that the matrix element \u27e8\u2212|R|\u2212\u27e9= e \u2212i\u03d5/2 . It also means that R ^ |\u2212\u27e9= e \u2212i\u03d5/2 |\u2212\u27e9 , or that \u27e8\u2212| R ^ =\u27e8\u2212| e \u2212i\u03d5/2 . It\u2019s all the same thing."
    },
    {
        "input": "Inside Dielectrics",
        "output": "The force on an electric charge depends not only on where it is, but also on how fast it is moving. Every point in space is characterized by two vector quantities which determine the force on any charge. First, there is the electric force, which gives a force component independent of the motion of the charge. We describe it by the electric field, E . Second, there is an additional force component, called the magnetic force, which depends on the velocity of the charge. This magnetic force has a strange directional character: At any particular point in space, both the direction of the force and its magnitude depend on the direction of motion of the particle: at every instant the force is always at right angles to the velocity vector; also, at any particular point, the force is always at right angles to a fixed direction in space (see Fig. 13\u20131); and finally, the magnitude of the force is proportional to the component of the velocity at right angles to this unique direction. It is possible to describe all of this behavior by defining the magnetic field vector B , which specifies both the unique direction in space and the constant of proportionality with the velocity, and to write the magnetic force as qv\u00d7B . The total electromagnetic force on a charge can, then, be written as F=q(E+v\u00d7B). This is called the Lorentz force. The magnetic force is easily demonstrated by bringing a bar magnet close to a cathode-ray tube. The deflection of the electron beam shows that the presence of the magnet results in forces on the electrons transverse to their direction of motion, as we described in Chapter 12 of Vol. I. The unit of magnetic field B is evidently one newton\u22c5 second per coulomb-meter. The same unit is also one volt\u22c5 second per meter2 . It is also called one weber per square meter. We consider first how we can understand the magnetic forces on wires carrying electric currents. In order to do this, we define what is meant by the current density. Electric currents are electrons or other charges in motion with a net drift or flow. We can represent the charge flow by a vector which gives the amount of charge passing per unit area and per unit time through a surface element at right angles to the flow (just as we did for the case of heat flow). We call this the current density and represent it by the vector j . It is directed along the motion of the charges. If we take a small area \u0394S at a given place in the material, the amount of charge flowing across that area in a unit time is j\u22c5n\u0394S, where n is the unit vector normal to \u0394S . The current density is related to the average flow velocity of the charges. Suppose that we have a distribution of charges whose average motion is a drift with the velocity v . As this distribution passes over a surface element \u0394S , the charge \u0394q passing through the surface element in a time \u0394t is equal to the charge contained in a parallelepiped whose base is \u0394S and whose height is v\u0394t , as shown in Fig. 13\u20132. The volume of the parallelepiped is the projection of \u0394S at right angles to v times v\u0394t , which when multiplied by the charge density \u03c1 will give \u0394q . Thus \u0394q=\u03c1v\u22c5n\u0394S\u0394t. The charge per unit time is then \u03c1v\u22c5n\u0394S , from which we get j=\u03c1v. If the charge distribution consists of individual charges, say electrons, each with the charge q and moving with the mean velocity v , then the current density is j=Nqv. where N is the number of charges per unit volume. The total charge passing per unit time through any surface S is called the electric current, I . It is equal to the integral of the normal component of the flow through all of the elements of the surface: I=\u222bSj\u22c5ndS (see Fig. 13\u20133). The current I out of a closed surface S represents the rate at which charge leaves the volume V enclosed by S . One of the basic laws of physics is that electric charge is indestructible; it is never lost or created. Electric charges can move from place to place but never appear from nowhere. We say that charge is conserved. If there is a net current out of a closed surface, the amount of charge inside must decrease by the corresponding amount (Fig. 13\u20134). We can, therefore, write the law of the conservation of charge as \u222b any closed surface j\u22c5ndS=\u2212 d dt (Qinside). The charge inside can be written as a volume integral of the charge density: Qinside=\u222b V inside S \u03c1dV. If we apply (13.6) to a small volume \u0394V , we know that the left-hand integral is \u2207\u22c5j\u0394V . The charge inside is \u03c1\u0394V , so the conservation of charge can also be written as \u2207\u22c5j=\u2212 \u2202\u03c1 \u2202t (Gauss\u2019 mathematics once again!). Now we are ready to find the force on a current-carrying wire in a magnetic field. The current consists of charged particles moving with the velocity v along the wire. Each charge feels a transverse force F=qv\u00d7B (Fig. 13\u20135a). If there are N such charges per unit volume, the number in a small volume \u0394V of the wire is N\u0394V . The total magnetic force \u0394F on the volume \u0394V is the sum of the forces on the individual charges, that is, \u0394F=(N\u0394V)(qv\u00d7B). But Nqv is just j , so \u0394F=j\u00d7B\u0394V (13.9) (Fig. 13\u20135b). The force per unit volume is j\u00d7B . If the current is uniform across a wire whose cross-sectional area is A , we may take as the volume element a cylinder with the base area A and the length \u0394L . Then \u0394F=j\u00d7BA\u0394L. (13.10) Now we can call jA the vector current I in the wire. (Its magnitude is the electric current in the wire, and its direction is along the wire.) Then \u0394F=I\u00d7B\u0394L. (13.11) The force per unit length on a wire is I\u00d7B . This equation gives the important result that the magnetic force on a wire, due to the movement of charges in it, depends only on the total current, and not on the amount of charge carried by each particle\u2014or even its sign! The magnetic force on a wire near a magnet is easily shown by observing its deflection when a current is turned on, as was described in Chapter 1 (see Fig. 1\u20136). We have seen that there is a force on a wire in the presence of a magnetic field, produced, say, by a magnet. From the principle that action equals reaction we might expect that there should be a force on the source of the magnetic field, i.e., on the magnet, when there is a current through the wire.1 There are indeed such forces, as is seen by the deflection of a compass needle near a current-carrying wire. Now we know that magnets feel forces from other magnets, so that means that when there is a current in a wire, the wire itself generates a magnetic field. Moving charges, then, produce a magnetic field. We would like now to try to discover the laws that determine how such magnetic fields are created. The question is: Given a current, what magnetic field does it make? The answer to this question was determined experimentally by three critical experiments and a brilliant theoretical argument given by Amp\u00e8re. We will pass over this interesting historical development and simply say that a large number of experiments have demonstrated the validity of Maxwell\u2019s equations. We take them as our starting point. If we drop the terms involving time derivatives in these equations we get the equations of magnetostatics: \u2207\u22c5B=0 (13.12) and c 2 \u2207\u00d7B= j \u03f5 0 . (13.13) These equations are valid only if all electric charge densities are constant and all currents are steady, so that the electric and magnetic fields are not changing with time\u2014all of the fields are \u201cstatic.\u201d We may remark that it is rather dangerous to think that there is such a thing as a static magnetic situation, because there must be currents in order to get a magnetic field at all\u2014and currents can come only from moving charges. \u201cMagnetostatics\u201d is, therefore, an approximation. It refers to a special kind of dynamic situation with large numbers of charges in motion, which we can approximate by a steady flow of charge. Only then can we speak of a current density j which does not change with time. The subject should more accurately be called the study of steady currents. Assuming that all fields are steady, we drop all terms in \u2202E/\u2202t and \u2202B/\u2202t from the complete Maxwell equations, Eqs. (2.41), and obtain the two equations (13.12) and (13.13) above. Also notice that since the divergence of the curl of any vector is necessarily zero, Eq. (13.13) requires that \u2207\u22c5j=0 . This is true, by Eq. (13.8), only if \u2202\u03c1/\u2202t is zero. But that must be so if E is not changing with time, so our assumptions are consistent. The requirement that \u2207\u22c5j=0 means that we may only have charges which flow in paths that close back on themselves. They may, for instance, flow in wires that form complete loops\u2014called circuits. The circuits may, of course, contain generators or batteries that keep the charges flowing. But they may not include condensers which are charging or discharging. (We will, of course, extend the theory later to include dynamic fields, but we want first to take the simpler case of steady currents.) Now let us look at Eqs. (13.12) and (13.13) to see what they mean. The first one says that the divergence of B is zero. Comparing it to the analogous equation in electrostatics, which says that \u2207\u22c5E=\u03c1/ \u03f5 0 , we can conclude that there is no magnetic analog of an electric charge. There are no magnetic charges from which lines of B can emerge. If we think in terms of \u201clines\u201d of the vector field B , they can never start and they never stop. Then where do they come from? Magnetic fields \u201cappear\u201d in the presence of currents; they have a curl proportional to the current density. Wherever there are currents, there are lines of magnetic field making loops around the currents. Since lines of B do not begin or end, they will often close back on themselves, making closed loops. But there can also be complicated situations in which the lines are not simple closed loops. But whatever they do, they never diverge from points. No magnetic charges have ever been discovered, so \u2207\u22c5B=0 . This much is true not only for magnetostatics, it is always true\u2014even for dynamic fields. The connection between the B field and currents is contained in Eq. (13.13). Here we have a new kind of situation which is quite different from electrostatics, where we had \u2207\u00d7E=0 . That equation meant that the line integral of E around any closed path is zero: \u222e loop E\u22c5ds=0. \u222e We got that result from Stokes\u2019 theorem, which says that the integral around any closed path of any vector field is equal to the surface integral of the normal component of the curl of the vector (taken over any surface which has the closed loop as its periphery). Applying the same theorem to the magnetic field vector and using the symbols shown in Fig. 13\u20136, we get \u222e \u0393 B\u22c5ds= \u222b S (\u2207\u00d7B)\u22c5ndS. (13.14) Taking the curl of B from Eq. (13.13), we have \u222e \u0393 B\u22c5ds= 1 \u03f5 0 c 2 \u222b S j\u22c5ndS. (13.15) The integral over S , according to (13.5), is the total current I through the surface S . Since for steady currents the current through S is independent of the shape of S , so long as it is bounded by the curve \u0393 , one usually speaks of \u201cthe current through the loop \u0393 .\u201d We have, then, a general law: the circulation of B around any closed curve is equal to the current I through the loop, divided by \u03f5 0 c 2 : \u222e \u0393 B\u22c5ds= I through \u0393 \u03f5 0 c 2 . (13.16) This law\u2014called Amp\u00e8re\u2019s law\u2014plays the same role in magnetostatics that Gauss\u2019 law played in electrostatics. Amp\u00e8re\u2019s law alone does not determine B from currents; we must, in general, also use \u2207\u22c5B=0 . But, as we will see in the next section, it can be used to find the field in special circumstances which have certain simple symmetries. We can illustrate the use of Amp\u00e8re\u2019s law by finding the magnetic field near a wire. We ask: What is the field outside a long straight wire with a cylindrical cross section? We will assume something which may not be at all evident, but which is nevertheless true: that the field lines of B go around the wire in closed circles. If we make this assumption, then Amp\u00e8re\u2019s law, Eq. (13.16), tells us how strong the field is. From the symmetry of the problem, B has the same magnitude at all points on a circle concentric with the wire (see Fig. 13\u20137). We can then do the line integral of B\u22c5ds quite easily; it is just the magnitude of B times the circumference. If r is the radius of the circle, then \u222eB\u22c5ds=B\u22c52\u03c0r. \u222e The total current through the loop is merely the current I in the wire, so B\u22c52\u03c0r= I \u03f5 0 c 2 , I or B= 1 4\u03c0 \u03f5 0 c 2 2I r . (13.17) The strength of the magnetic field drops off inversely as r , the distance from the axis of the wire. We can, if we wish, write Eq. (13.17) in vector form. Remembering that B is at right angles both to I and to r , we have B= 1 4\u03c0 \u03f5 0 c 2 2I\u00d7 e r r . (13.18) We have separated out the factor 1/4\u03c0 \u03f5 0 c 2 , because it appears often. It is worth remembering that it is exactly 10 \u22127 (in the mks system), since an equation like (13.17) is used to define the unit of current, the ampere. At one meter from a current of one ampere the magnetic field is 2\u00d7 10 \u22127 webers per square meter. Since a current produces a magnetic field, it will exert a force on a nearby wire which is also carrying a current. In Chapter 1 we described a simple demonstration of the forces between two current-carrying wires. If the wires are parallel, each is at right angles to the B field of the other; the wires should then be pushed either toward or away from each other. When currents are in the same direction, the wires attract; when the currents are moving in opposite directions, the wires repel. Let\u2019s take another example that can be analyzed by Amp\u00e8re\u2019s law if we add some knowledge about the field. Suppose we have a long coil of wire wound in a tight spiral, as shown by the cross sections in Fig. 13\u20138. Such a coil is called a solenoid. We observe experimentally that when a solenoid is very long compared with its diameter, the field outside is very small compared with the field inside. Using just that fact, together with Amp\u00e8re\u2019s law, we can find the size of the field inside. Since the field stays inside (and has zero divergence), its lines must go along parallel to the axis, as shown in Fig. 13\u20138. That being the case, we can use Amp\u00e8re\u2019s law with the rectangular \u201ccurve\u201d \u0393 shown in the figure. This loop goes the distance L inside the solenoid, where the field is, say, B 0 , then goes at right angles to the field, and returns along the outside, where the field is negligible. The line integral of B for this curve is just B 0 L , and it must be 1/ \u03f5 0 c 2 times the total current through \u0393 , which is NI if there are N turns of the solenoid in the length L . We have B 0 L= NI \u03f5 0 c 2 . N I Or, letting n be the number of turns per unit length of the solenoid (that is, n=N/L ), we get B 0 = nI \u03f5 0 c 2 . (13.19) What happens to the lines of B when they get to the end of the solenoid? Presumably, they spread out in some way and return to enter the solenoid at the other end, as sketched in Fig. 13\u20139. Such a field is just what is observed outside of a bar magnet. But what is a magnet anyway? Our equations say that B comes from the presence of currents. Yet we know that ordinary bars of iron (no batteries or generators) also produce magnetic fields. You might expect that there should be some other terms on the right-hand side of (13.12) or (13.13) to represent \u201cthe density of magnetic iron\u201d or some such quantity. But there is no such term. Our theory says that the magnetic effects of iron come from some internal currents which are already taken care of by the j term. Matter is very complex when looked at from a fundamental point of view\u2014as we saw when we tried to understand dielectrics. In order not to interrupt our present discussion, we will wait until later to deal in detail with the interior mechanisms of magnetic materials like iron: You will have to accept, for the moment, that all magnetism is produced from currents, and that in a permanent magnet there are permanent internal currents. In the case of iron, these currents come from electrons spinning around their own axes. Every electron has such a spin, which corresponds to a tiny circulating current. Of course, one electron doesn\u2019t produce much magnetic field, but in an ordinary piece of matter there are billions and billions of electrons. Normally these spin and point every which way, so that there is no net effect. The miracle is that in a very few substances, like iron, a large fraction of the electrons spin with their axes in the same direction\u2014for iron, two electrons of each atom take part in this cooperative motion. In a bar magnet there are large numbers of electrons all spinning in the same direction and, as we will see, their total effect is equivalent to a current circulating on the surface of the bar. (This is quite analogous to what we found for dielectrics\u2014that a uniformly polarized dielectric is equivalent to a distribution of charges on its surface.) It is, therefore, no accident that a bar magnet is equivalent to a solenoid. When we said that the magnetic force on a charge was proportional to its velocity, you may have wondered: \u201cWhat velocity? With respect to which reference frame?\u201d It is, in fact, clear from the definition of B given at the beginning of this chapter that what this vector is will depend on what we choose as a reference frame for our specification of the velocity of charges. But we have said nothing about which is the proper frame for specifying the magnetic field. It turns out that any inertial frame will do. We will also see that magnetism and electricity are not independent things\u2014that they should always be taken together as one complete electromagnetic field. Although in the static case Maxwell\u2019s equations separate into two distinct pairs, one pair for electricity and one pair for magnetism, with no apparent connection between the two fields, nevertheless, in nature itself there is a very intimate relationship between them that arises from the principle of relativity. Historically, the principle of relativity was discovered after Maxwell\u2019s equations. It was, in fact, the study of electricity and magnetism which led ultimately to Einstein\u2019s discovery of his principle of relativity. But let\u2019s see what our knowledge of relativity would tell us about magnetic forces if we assume that the relativity principle is applicable\u2014as it is\u2014to electromagnetism. Suppose we think about what happens when a negative charge moves with velocity v 0 parallel to a current-carrying wire, as in Fig. 13\u201310. We will try to understand what goes on in two reference frames: one fixed with respect to the wire, as in part (a) of the figure, and one fixed with respect to the particle, as in part (b). We will call the first frame S and the second S \u2032 . In the S -frame, there is clearly a magnetic force on the particle. The force is directed toward the wire, so if the charge were moving freely we would see it curve in toward the wire. But in the S \u2032 -frame there can be no magnetic force on the particle, because its velocity is zero. Does it, therefore, stay where it is? Would we see different things happening in the two systems? The principle of relativity would say that in S \u2032 we should also see the particle move closer to the wire. We must try to understand why that would happen. We return to our atomic description of a wire carrying a current. In a normal conductor, like copper, the electric currents come from the motion of some of the negative electrons\u2014called the conduction electrons\u2014while the positive nuclear charges and the remainder of the electrons stay fixed in the body of the material. We let the charge density of the conduction electrons be \u03c1 \u2212 and their velocity in S be v . The density of the charges at rest in S is \u03c1 + , which must be equal to the negative of \u03c1 \u2212 , since we are considering an uncharged wire. There is thus no electric field outside the wire, and the force on the moving particle is just F=q v 0 \u00d7B. F B Using the result we found in Eq. (13.18) for the magnetic field at the distance r from the axis of a wire, we conclude that the force on the particle is directed toward the wire and has the magnitude F= 1 4\u03c0 \u03f5 0 c 2 \u22c5 2Iq v 0 r . 1 2 I Using Eqs. (13.3) and (13.5), the current I can be written as \u03c1 \u2212 vA , where A is the area of a cross section of the wire. Then F= 1 4\u03c0 \u03f5 0 c 2 \u22c5 2q \u03c1 \u2212 Av v 0 r . (13.20) We could continue to treat the general case of arbitrary velocities for v and v 0 , but it will be just as good to look at the special case in which the velocity v 0 of the particle is the same as the velocity v of the conduction electrons. So we write v 0 =v , and Eq. (13.20) becomes F= q 2\u03c0 \u03f5 0 \u03c1 \u2212 A r v 2 c 2 . (13.21) Now we turn our attention to what happens in S \u2032 , in which the particle is at rest and the wire is running past (toward the left in the figure) with the speed v . The positive charges moving with the wire will make some magnetic field B \u2032 at the particle. But the particle is now at rest, so there is no magnetic force on it! If there is any force on the particle, it must come from an electric field. It must be that the moving wire has produced an electric field. But it can do that only if it appears charged\u2014it must be that a neutral wire with a current appears to be charged when set in motion. We must look into this. We must try to compute the charge density in the wire in S \u2032 from what we know about it in S . One might, at first, think they are the same; but we know that lengths are changed between S and S \u2032 (see Chapter 15, Vol. I), so volumes will change also. Since the charge densities depend on the volume occupied by charges, the densities will change, too. Before we can decide about the charge densities in S \u2032 , we must know what happens to the electric charge of a bunch of electrons when the charges are moving. We know that the apparent mass of a particle changes by 1/ 1\u2212 v 2 / c 2 \u2212 \u2212 \u2212 \u2212 \u2212 \u2212 \u2212 \u2212 \u221a . Does its charge do something similar? No! Charges are always the same, moving or not. Otherwise we would not always observe that the total charge is conserved. Suppose that we take a block of material, say a conductor, which is initially uncharged. Now we heat it up. Because the electrons have a different mass than the protons, the velocities of the electrons and of the protons will change by different amounts. If the charge of a particle depended on the speed of the particle carrying it, in the heated block the charge of the electrons and protons would no longer balance. A block would become charged when heated. As we have seen earlier, a very small fractional change in the charge of all the electrons in a block would give rise to enormous electric fields. No such effect has ever been observed. Also, we can point out that the mean speed of the electrons in matter depends on its chemical composition. If the charge on an electron changed with speed, the net charge in a piece of material would be changed in a chemical reaction. Again, a straightforward calculation shows that even a very small dependence of charge on speed would give enormous fields from the simplest chemical reactions. No such effect is observed, and we conclude that the electric charge of a single particle is independent of its state of motion. So the charge q on a particle is an invariant scalar quantity, independent of the frame of reference. That means that in any frame the charge density of a distribution of electrons is just proportional to the number of electrons per unit volume. We need only worry about the fact that the volume can change because of the relativistic contraction of distances. We now apply these ideas to our moving wire. If we take a length L 0 of the wire, in which there is a charge density \u03c1 0 of stationary charges, it will contain the total charge Q= \u03c1 0 L 0 A 0 . If the same charges are observed in a different frame to be moving with velocity v , they will all be found in a piece of the material with the shorter length L= L 0 1\u2212 v 2 / c 2 \u2212 \u2212 \u2212 \u2212 \u2212 \u2212 \u2212 \u2212 \u221a , (13.22) but with the same area A 0 (since dimensions transverse to the motion are unchanged). See Fig. 13\u201311. If we call \u03c1 the density of charges in the frame in which they are moving, the total charge Q will be \u03c1L A 0 . This must also be equal to \u03c1 0 L 0 A 0 , because charge is the same in any system, so that \u03c1L= \u03c1 0 L 0 or, from (13.22), \u03c1= \u03c1 0 1\u2212 v 2 / c 2 \u2212 \u2212 \u2212 \u2212 \u2212 \u2212 \u2212 \u2212 \u221a . (13.23) The charge density of a moving distribution of charges varies in the same way as the relativistic mass of a particle. We now use this general result for the positive charge density \u03c1 + of our wire. These charges are at rest in frame S . In S \u2032 , however, where the wire moves with the speed v , the positive charge density becomes \u03c1 \u2032 + = \u03c1 + 1\u2212 v 2 / c 2 \u2212 \u2212 \u2212 \u2212 \u2212 \u2212 \u2212 \u2212 \u221a . (13.24) The negative charges are at rest in S \u2032 . So they have their \u201crest density\u201d \u03c1 0 in this frame. In Eq. (13.23) \u03c1 0 = \u03c1 \u2032 \u2212 , because they have the density \u03c1 \u2212 when the wire is at rest, i.e., in frame S , where the speed of the negative charges is v . For the conduction electrons, we then have that \u03c1 \u2212 = \u03c1 \u2032 \u2212 1\u2212 v 2 / c 2 \u2212 \u2212 \u2212 \u2212 \u2212 \u2212 \u2212 \u2212 \u221a , (13.25) or \u03c1 \u2032 \u2212 = \u03c1 \u2212 1\u2212 v 2 / c 2 \u2212 \u2212 \u2212 \u2212 \u2212 \u2212 \u2212 \u2212 \u221a . (13.26) Now we can see why there are electric fields in S \u2032 \u2014because in this frame the wire has the net charge density \u03c1 \u2032 given by \u03c1 \u2032 = \u03c1 \u2032 + + \u03c1 \u2032 \u2212 . \u2032 \u2032 \u2032 Using (13.24) and (13.26), we have \u03c1 \u2032 = \u03c1 + 1\u2212 v 2 / c 2 \u2212 \u2212 \u2212 \u2212 \u2212 \u2212 \u2212 \u2212 \u221a + \u03c1 \u2212 1\u2212 v 2 / c 2 \u2212 \u2212 \u2212 \u2212 \u2212 \u2212 \u2212 \u2212 \u221a . \u03c1 Since the stationary wire is neutral, \u03c1 \u2212 =\u2212 \u03c1 + , and we have \u03c1 \u2032 = \u03c1 + v 2 / c 2 1\u2212 v 2 / c 2 \u2212 \u2212 \u2212 \u2212 \u2212 \u2212 \u2212 \u2212 \u221a . (13.27) Our moving wire is positively charged and will produce an electric field E \u2032 at the external stationary particle. We have already solved the electrostatic problem of a uniformly charged cylinder. The electric field at the distance r from the axis of the cylinder is E \u2032 = \u03c1 \u2032 A 2\u03c0 \u03f5 0 r = \u03c1 + A v 2 / c 2 2\u03c0 \u03f5 0 r 1\u2212 v 2 / c 2 \u2212 \u2212 \u2212 \u2212 \u2212 \u2212 \u2212 \u2212 \u221a . (13.28) The force on the negatively charged particle is toward the wire. We have, at least, a force in the same direction from the two points of view; the electric force in S \u2032 has the same direction as the magnetic force in S . The magnitude of the force in S \u2032 is F \u2032 = q 2\u03c0 \u03f5 0 \u03c1 + A r v 2 / c 2 1\u2212 v 2 / c 2 \u2212 \u2212 \u2212 \u2212 \u2212 \u2212 \u2212 \u2212 \u221a . (13.29) Comparing this result for F \u2032 with our result for F in Eq. (13.21), we see that the magnitudes of the forces are almost identical from the two points of view. In fact, F \u2032 = F 1\u2212 v 2 / c 2 \u2212 \u2212 \u2212 \u2212 \u2212 \u2212 \u2212 \u2212 \u221a , (13.30) so for the small velocities we have been considering, the two forces are equal. We can say that for low velocities, at least, we understand that magnetism and electricity are just \u201ctwo ways of looking at the same thing.\u201d But things are even better than that. If we take into account the fact that forces also transform when we go from one system to the other, we find that the two ways of looking at what happens do indeed give the same physical result for any velocity. One way of seeing this is to ask a question like: What transverse momentum will the particle have after the force has acted for a little while? We know from Chapter 16 of Vol. I that the transverse momentum of a particle should be the same in both the S - and S \u2032 -frames. Calling the transverse coordinate y , we want to compare \u0394 p y and \u0394 p \u2032 y . Using the relativistically correct equation of motion, F=dp/dt , we expect that after the time \u0394t our particle will have a transverse momentum \u0394 p y in the S -system given by \u0394 p y =F\u0394t. (13.31) In the S \u2032 -system, the transverse momentum will be \u0394 p \u2032 y = F \u2032 \u0394 t \u2032 . (13.32) We must, of course, compare \u0394 p y and \u0394 p \u2032 y for corresponding time intervals \u0394t and \u0394 t \u2032 . We have seen in Chapter 15 of Vol. I that the time intervals referred to a moving particle appear to be longer than those in the rest system of the particle. Since our particle is initially at rest in S \u2032 , we expect, for small \u0394t , that \u0394t= \u0394 t \u2032 1\u2212 v 2 / c 2 \u2212 \u2212 \u2212 \u2212 \u2212 \u2212 \u2212 \u2212 \u221a , (13.33) and everything comes out O.K. From (13.31) and (13.32), \u0394 p \u2032 y \u0394 p y = F \u2032 \u0394 t \u2032 F\u0394t , \u2032 which is just =1 if we combine (13.30) and (13.33). We have found that we get the same physical result whether we analyze the motion of a particle moving along a wire in a coordinate system at rest with respect to the wire, or in a system at rest with respect to the particle. In the first instance, the force was purely \u201cmagnetic,\u201d in the second, it was purely \u201celectric.\u201d The two points of view are illustrated in Fig. 13\u201312 (although there is still a magnetic field B \u2032 in the second frame, it produces no forces on the stationary particle). If we had chosen still another coordinate system, we would have found a different mixture of E and B fields. Electric and magnetic forces are part of one physical phenomenon\u2014the electromagnetic interactions of particles. The separation of this interaction into electric and magnetic parts depends very much on the reference frame chosen for the description. But a complete electromagnetic description is invariant; electricity and magnetism taken together are consistent with Einstein\u2019s relativity. Since electric and magnetic fields appear in different mixtures if we change our frame of reference, we must be careful about how we look at the fields E and B . For instance, if we think of \u201clines\u201d of E or B , we must not attach too much reality to them. The lines may disappear if we try to observe them from a different coordinate system. For example, in system S \u2032 there are electric field lines, which we do not find \u201cmoving past us with velocity v in system S .\u201d In system S there are no electric field lines at all! Therefore it makes no sense to say something like: When I move a magnet, it takes its field with it, so the lines of B are also moved. There is no way to make sense, in general, out of the idea of \u201cthe speed of a moving field line.\u201d The fields are our way of describing what goes on at a point in space. In particular, E and B tell us about the forces that will act on a moving particle. The question \u201cWhat is the force on a charge from a moving magnetic field?\u201d doesn\u2019t mean anything precise. The force is given by the values of E and B at the charge, and the formula (13.1) is not to be altered if the source of E or B is moving (it is the values of E and B that will be altered by the motion). Our mathematical description deals only with the fields as a function of x , y , z , and t with respect to some inertial frame. We will later be speaking of \u201ca wave of electric and magnetic fields travelling through space,\u201d as, for instance, a light wave. But that is like speaking of a wave travelling on a string. We don\u2019t then mean that some part of the string is moving in the direction of the wave, we mean that the displacement of the string appears first at one place and later at another. Similarly, in an electromagnetic wave, the wave travels; but the magnitude of the fields change. So in the future when we\u2014or someone else\u2014speaks of a \u201cmoving\u201d field, you should think of it as just a handy, short way of describing a changing field in some circumstances. You may have worried about the simplification we made above when we took the same velocity v for the particle and for the conduction electrons in the wire. We could go back and carry through the analysis again for two different velocities, but it is easier to simply notice that charge and current density are the components of a four-vector (see Chapter 17, Vol. I). We have seen that if \u03c1 0 is the density of the charges in their rest frame, then in a frame in which they have the velocity v , the density is \u03c1= \u03c1 0 1\u2212 v 2 / c 2 \u2212 \u2212 \u2212 \u2212 \u2212 \u2212 \u2212 \u2212 \u221a . \u03c1 In that frame their current density is j=\u03c1v= \u03c1 0 v 1\u2212 v 2 / c 2 \u2212 \u2212 \u2212 \u2212 \u2212 \u2212 \u2212 \u2212 \u221a . (13.34) Now we know that the energy U and momentum p of a particle moving with velocity v are given by U= m 0 c 2 1\u2212 v 2 / c 2 \u2212 \u2212 \u2212 \u2212 \u2212 \u2212 \u2212 \u2212 \u221a ,p= m 0 v 1\u2212 v 2 / c 2 \u2212 \u2212 \u2212 \u2212 \u2212 \u2212 \u2212 \u2212 \u221a , 2 where m 0 is its rest mass. We also know that U/c= m 0 c/ 1\u2212 v 2 / c 2 \u2212 \u2212 \u2212 \u2212 \u2212 \u2212 \u2212 \u2212 \u221a and p form a relativistic four-vector. Since c\u03c1=c \u03c1 0 / 1\u2212 v 2 / c 2 \u2212 \u2212 \u2212 \u2212 \u2212 \u2212 \u2212 \u2212 \u221a and j depend on the velocity v exactly as do U/c and p , we can conclude that c\u03c1 and j are also the components of a relativistic four-vector. This property is the key to a general analysis of the field of a wire moving with any velocity, which we would need if we want to do the problem again with the velocity v 0 of the particle different from the velocity of the conduction electrons. If we wish to transform \u03c1 and j to a coordinate system moving with a velocity u in the x -direction, we know that they transform just like t and (x,y,z) , so that we have (see Chapter 15, Vol. I) x \u2032 y \u2032 z \u2032 t \u2032 = x\u2212ut 1\u2212 u 2 / c 2 \u2212 \u2212 \u2212 \u2212 \u2212 \u2212 \u2212 \u2212 \u221a , =y, =z, = t\u2212ux/ c 2 1\u2212 u 2 / c 2 \u2212 \u2212 \u2212 \u2212 \u2212 \u2212 \u2212 \u2212 \u221a , j \u2032 x j \u2032 y j \u2032 z \u03c1 \u2032 = j x \u2212u\u03c1 1\u2212 u 2 / c 2 \u2212 \u2212 \u2212 \u2212 \u2212 \u2212 \u2212 \u2212 \u221a = j y , = j z , = \u03c1\u2212u j x / c 2 1\u2212 u 2 / c 2 \u2212 \u2212 \u2212 \u2212 \u2212 \u2212 \u2212 \u2212 \u221a . (13.35) With these equations we can relate charges and currents in one frame to those in another. Taking the charges and currents in either frame, we can solve the electromagnetic problem in that frame by using our Maxwell equations. The result we obtain for the motions of particles will be the same no matter which frame we choose. We will return at a later time to the relativistic transformations of the electromagnetic fields. We will conclude this chapter by making two further points regarding the subject of magnetostatics. First, our basic equations for the magnetic field, \u2207\u22c5B=0,\u2207\u00d7B=j/ c 2 \u03f5 0 , 2 are linear in B and j . That means that the principle of superposition also applies to magnetic fields. The field produced by two different steady currents is the sum of the individual fields from each current acting alone. Our second remark concerns the right-hand rules which we have encountered (such as the right-hand rule for the magnetic field produced by a current). We have also observed that the magnetization of an iron magnet is to be understood from the spin of the electrons in the material. The direction of the magnetic field of a spinning electron is related to its spin axis by the same right-hand rule. Because B is determined by a \u201chanded\u201d rule\u2014involving either a cross product or a curl\u2014it is called an axial vector. (Vectors whose direction in space does not depend on a reference to a right or left hand are called polar vectors. Displacement, velocity, force, and E , for example, are polar vectors.) Physically observable quantities in electromagnetism are not, however, right- (or left-) handed. Electromagnetic interactions are symmetrical under reflection (see Chapter 52, Vol. I). Whenever magnetic forces between two sets of currents are computed, the result is invariant with respect to a change in the hand convention. Our equations lead, independently of the right-hand convention, to the end result that parallel currents attract, or that currents in opposite directions repel. (Try working out the force using \u201cleft-hand rules.\u201d) An attraction or repulsion is a polar vector. This happens because in describing any complete interaction, we use the right-hand rule twice\u2014once to find B from currents, again to find the force this B produces on a second current. Using the right-hand rule twice is the same as using the left-hand rule twice. If we were to change our conventions to a left-hand system all our B fields would be reversed, but all forces\u2014or, what is perhaps more relevant, the observed accelerations of objects\u2014would be unchanged. Although physicists have recently found to their surprise that all the laws of nature are not always invariant for mirror reflections, the laws of electromagnetism do have such a basic symmetry."
    },
    {
        "input": "The Brownian Movement",
        "output": "The Brownian movement was discovered in 1827 by Robert Brown, a botanist. While he was studying microscopic life, he noticed little particles of plant pollens jiggling around in the liquid he was looking at in the microscope, and he was wise enough to realize that these were not living, but were just little pieces of dirt moving around in the water. In fact he helped to demonstrate that this had nothing to do with life by getting from the ground an old piece of quartz in which there was some water trapped. It must have been trapped for millions and millions of years, but inside he could see the same motion. What one sees is that very tiny particles are jiggling all the time. This was later proved to be one of the effects of molecular motion, and we can understand it qualitatively by thinking of a great push ball on a playing field, seen from a great distance, with a lot of people underneath, all pushing the ball in various directions. We cannot see the people because we imagine that we are too far away, but we can see the ball, and we notice that it moves around rather irregularly. We also know, from the theorems that we have discussed in previous chapters, that the mean kinetic energy of a small particle suspended in a liquid or a gas will be 3 2 kT even though it is very heavy compared with a molecule. If it is very heavy, that means that the speeds are relatively slow, but it turns out, actually, that the speed is not really so slow. In fact, we cannot see the speed of such a particle very easily because although the mean kinetic energy is 3 2 kT , which represents a speed of a millimeter or so per second for an object a micron or two in diameter, this is very hard to see even in a microscope, because the particle continuously reverses its direction and does not get anywhere. How far it does get we will discuss at the end of the present chapter. This problem was first solved by Einstein at the beginning of the 20th century. Incidentally, when we say that the mean kinetic energy of this particle is 3 2 kT , we claim to have derived this result from the kinetic theory, that is, from Newton\u2019s laws. We shall find that we can derive all kinds of things\u2014marvelous things\u2014from the kinetic theory, and it is most interesting that we can apparently get so much from so little. Of course we do not mean that Newton\u2019s laws are \u201clittle\u201d\u2014they are enough to do it, really\u2014what we mean is that we did not do very much. How do we get so much out? The answer is that we have been perpetually making a certain important assumption, which is that if a given system is in thermal equilibrium at some temperature, it will also be in thermal equilibrium with anything else at the same temperature. For instance, if we wanted to see how a particle would move if it was really colliding with water, we could imagine that there was a gas present, composed of another kind of particle, little fine pellets that (we suppose) do not interact with water, but only hit the particle with \u201chard\u201d collisions. Suppose the particle has a prong sticking out of it; all our pellets have to do is hit the prong. We know all about this imaginary gas of pellets at temperature T \u2014it is an ideal gas. Water is complicated, but an ideal gas is simple. Now, our particle has to be in equilibrium with the gas of pellets. Therefore, the mean motion of the particle must be what we get for gaseous collisions, because if it were not moving at the right speed relative to the water but, say, was moving faster, that would mean that the pellets would pick up energy from it and get hotter than the water. But we had started them at the same temperature, and we assume that if a thing is once in equilibrium, it stays in equilibrium\u2014parts of it do not get hotter and other parts colder, spontaneously. This proposition is true and can be proved from the laws of mechanics, but the proof is very complicated and can be established only by using advanced mechanics. It is much easier to prove in quantum mechanics than it is in classical mechanics. It was proved first by Boltzmann, but for now we simply take it to be true, and then we can argue that our particle has to have 3 2 kT of energy if it is hit with artificial pellets, so it also must have 3 2 kT when it is being hit with water at the same temperature and we take away the pellets; so it is 3 2 kT . It is a strange line of argument, but perfectly valid. In addition to the motion of colloidal particles for which the Brownian movement was first discovered, there are a number of other phenomena, both in the laboratory and in other situations, where one can see Brownian movement. If we are trying to build the most delicate possible equipment, say a very small mirror on a thin quartz fiber for a very sensitive ballistic galvanometer (Fig. 41\u20131), the mirror does not stay put, but jiggles all the time\u2014all the time\u2014so that when we shine a light on it and look at the position of the spot, we do not have a perfect instrument because the mirror is always jiggling. Why? Because the average kinetic energy of rotation of this mirror has to be, on the average, 1 2 kT . What is the mean-square angle over which the mirror will wobble? Suppose we find the natural vibration period of the mirror by tapping on one side and seeing how long it takes to oscillate back and forth, and we also know the moment of inertia, I . We know the formula for the kinetic energy of rotation\u2014it is given by Eq. (19.8): T= 1 2 I \u03c9 2 . That is the kinetic energy, and the potential energy that goes with it will be proportional to the square of the angle\u2014it is V= 1 2 \u03b1 \u03b8 2 . But, if we know the period t 0 and calculate from that the natural frequency \u03c9 0 =2\u03c0/ t 0 , then the potential energy is V= 1 2 I \u03c9 2 0 \u03b8 2 . Now we know that the average kinetic energy is 1 2 kT , but since it is a harmonic oscillator the average potential energy is also 1 2 kT . Thus 1 2 I \u03c9 2 0 \u27e8 \u03b8 2 \u27e9= 1 2 kT, 1 1 or \u27e8 \u03b8 2 \u27e9=kT/I \u03c9 2 0 . (41.1) In this way we can calculate the oscillations of a galvanometer mirror, and thereby find what the limitations of our instrument will be. If we want to have smaller oscillations, we have to cool the mirror. An interesting question is, where to cool it. This depends upon where it is getting its \u201ckicks\u201d from. If it is through the fiber, we cool it at the top\u2014if the mirror is surrounded by a gas and is getting hit mostly by collisions in the gas, it is better to cool the gas. As a matter of fact, if we know where the damping of the oscillations comes from, it turns out that that is always the source of the fluctuations also, a point which we will come back to. The same thing works, amazingly enough, in electrical circuits. Suppose that we are building a very sensitive, accurate amplifier for a definite frequency and have a resonant circuit (Fig. 41\u20132) in the input so as to make it very sensitive to this certain frequency, like a radio receiver, but a really good one. Suppose we wish to go down to the very lowest limit of things, so we take the voltage, say off the inductance, and send it into the rest of the amplifier. Of course, in any circuit like this, there is a certain amount of loss. It is not a perfect resonant circuit, but it is a very good one and there is a little resistance, say (we put the resistor in so we can see it, but it is supposed to be small). Now we would like to find out: How much does the voltage across the inductance fluctuate? Answer: We know that 1 2 L I 2 is the \u201ckinetic energy\u201d\u2014the energy associated with a coil in a resonant circuit (Chapter 25). Therefore the mean value of 1 2 L I 2 is equal to 1 2 kT \u2014that tells us what the rms current is and we can find out what the rms voltage is from the rms current. For if we want the voltage across the inductance the formula is V ^ L =i\u03c9L I ^ , and the mean absolute square voltage on the inductance is \u27e8 V 2 L \u27e9= L 2 \u03c9 2 0 \u27e8 I 2 \u27e9 , and putting in 1 2 L\u27e8 I 2 \u27e9= 1 2 kT , we obtain \u27e8 V 2 L \u27e9=L \u03c9 2 0 kT. (41.2) So now we can design circuits and tell when we are going to get what is called Johnson noise, the noise associated with thermal fluctuations! Where do the fluctuations come from this time? They come again from the resistor\u2014they come from the fact that the electrons in the resistor are jiggling around because they are in thermal equilibrium with the matter in the resistor, and they make fluctuations in the density of electrons. They thus make tiny electric fields which drive the resonant circuit. Electrical engineers represent the answer in another way. Physically, the resistor is effectively the source of noise. However, we may replace the real circuit having an honest, true physical resistor which is making noise, by an artificial circuit which contains a little generator that is going to represent the noise, and now the resistor is otherwise ideal\u2014no noise comes from it. All the noise is in the artificial generator. And so if we knew the characteristics of the noise generated by a resistor, if we had the formula for that, then we could calculate what the circuit is going to do in response to that noise. So, we need a formula for the noise fluctuations. Now the noise that is generated by the resistor is at all frequencies, since the resistor by itself is not resonant. Of course the resonant circuit only \u201clistens\u201d to the part that is near the right frequency, but the resistor has many different frequencies in it. We may describe how strong the generator is, as follows: The mean power that the resistor would absorb if it were connected directly across the noise generator would be \u27e8 E 2 \u27e9/R , if E were the voltage from the generator. But we would like to know in more detail how much power there is at every frequency. There is very little power in any one frequency; it is a distribution. Let P(\u03c9)d\u03c9 be the power that the generator would deliver in the frequency range d\u03c9 into the very same resistor. Then we can prove (we shall prove it for another case, but the mathematics is exactly the same) that the power comes out P(\u03c9)d\u03c9=(2/\u03c0)kTd\u03c9, (41.3) and is independent of the resistance when put this way. Now we go on to consider a still more advanced and interesting proposition that is as follows. Suppose we have a charged oscillator like those we were talking about when we were discussing light, let us say an electron oscillating up and down in an atom. If it oscillates up and down, it radiates light. Now suppose that this oscillator is in a very thin gas of other atoms, and that from time to time the atoms collide with it. Then in equilibrium, after a long time, this oscillator will pick up energy such that its kinetic energy of oscillation is 1 2 kT , and since it is a harmonic oscillator, its entire energy will become kT . That is, of course, a wrong description so far, because the oscillator carries electric charge, and if it has an energy kT it is shaking up and down and radiating light. Therefore it is impossible to have equilibrium of real matter alone without the charges in it emitting light, and as light is emitted, energy flows away, the oscillator loses its kT as time goes on, and thus the whole gas which is colliding with the oscillator gradually cools off. And that is, of course, the way a warm stove cools, by radiating the light into the sky, because the atoms are jiggling their charge and they continually radiate, and slowly, because of this radiation, the jiggling motion slows down. On the other hand, if we enclose the whole thing in a box so that the light does not go away to infinity, then we can eventually get thermal equilibrium. We may either put the gas in a box where we can say that there are other radiators in the box walls sending light back or, to take a nicer example, we may suppose the box has mirror walls. It is easier to think about that case. Thus we assume that all the radiation that goes out from the oscillator keeps running around in the box. Then, of course, it is true that the oscillator starts to radiate, but pretty soon it can maintain its kT of energy in spite of the fact that it is radiating, because it is being illuminated, we may say, by its own light reflected from the walls of the box. That is, after a while there is a great deal of light rushing around in the box, and although the oscillator is radiating some, the light comes back and returns some of the energy that was radiated. We shall now determine how much light there must be in such a box at temperature T in order that the shining of the light on this oscillator will generate just enough energy to account for the light it radiated. Let the gas atoms be very few and far between, so that we have an ideal oscillator with no resistance except radiation resistance. Then we consider that at thermal equilibrium the oscillator is doing two things at the same time. First, it has a mean energy kT , and we calculate how much radiation it emits. Second, this radiation should be exactly the amount that would result because of the fact that the light shining on the oscillator is scattered. Since there is nowhere else the energy can go, this effective radiation is really just scattered light from the light that is in there. Thus we first calculate the energy that is radiated by the oscillator per second, if the oscillator has a certain energy. (We borrow from Chapter 32 on radiation resistance a number of equations without going back over their derivation.) The energy radiated per radian divided by the energy of the oscillator is called 1/Q (Eq. 32.8): 1/Q=(dW/dt)/ \u03c9 0 W . Using the quantity \u03b3 , the damping constant, this can also be written as 1/Q=\u03b3/ \u03c9 0 , where \u03c9 0 is the natural frequency of the oscillator\u2014if gamma is very small, Q is very large. The energy radiated per second is then dW dt = \u03c9 0 W Q = \u03c9 0 W\u03b3 \u03c9 0 =\u03b3W. (41.4) The energy radiated per second is thus simply gamma times the energy of the oscillator. Now the oscillator should have an average energy kT , so we see that gamma kT is the average amount of energy radiated per second: \u27e8dW/dt\u27e9=\u03b3kT. (41.5) Now we only have to know what gamma is. Gamma is easily found from Eq. (32.12). It is \u03b3= \u03c9 0 Q = 2 3 r 0 \u03c9 2 0 c , (41.6) where r 0 = e 2 /m c 2 is the classical electron radius, and we have set \u03bb=2\u03c0c/ \u03c9 0 . Our final result for the average rate of radiation of light near the frequency \u03c9 0 is therefore \u27e8dW/dt\u27e9= 2 3 r 0 \u03c9 2 0 kT c . (41.7) Next we ask how much light must be shining on the oscillator. It must be enough that the energy absorbed from the light (and thereupon scattered) is just exactly this much. In other words, the emitted light is accounted for as scattered light from the light that is shining on the oscillator in the cavity. So we must now calculate how much light is scattered from the oscillator if there is a certain amount\u2014unknown\u2014of radiation incident on it. Let I(\u03c9)d\u03c9 be the amount of light energy there is at the frequency \u03c9 , within a certain range d\u03c9 (because there is no light at exactly a certain frequency; it is spread all over the spectrum). So I(\u03c9) is a certain spectral distribution which we are now going to find\u2014it is the color of a furnace at temperature T that we see when we open the door and look in the hole. Now how much light is absorbed? We worked out the amount of radiation absorbed from a given incident light beam, and we calculated it in terms of a cross section. It is just as though we said that all of the light that falls on a certain cross section is absorbed. So the total amount that is re-radiated (scattered) is the incident intensity I(\u03c9)d\u03c9 multiplied by the cross section \u03c3 . The formula for the cross section that we derived (Eq. 32.19) did not have the damping included. It is not hard to go through the derivation again and put in the resistance term, which we neglected. If we do that, and calculate the cross section the same way, we get \u03c3 s = 8\u03c0 r 2 0 3 ( \u03c9 4 ( \u03c9 2 \u2212 \u03c9 2 0 ) 2 + \u03b3 2 \u03c9 2 ). (41.8) Now, as a function of frequency, \u03c3 s is of significant size only for \u03c9 very near to the natural frequency \u03c9 0 . (Remember that the Q for a radiating oscillator is about 10 8 .) The oscillator scatters very strongly when \u03c9 is equal to \u03c9 0 , and very weakly for other values of \u03c9 . Therefore we can replace \u03c9 by \u03c9 0 and \u03c9 2 \u2212 \u03c9 2 0 by 2 \u03c9 0 (\u03c9\u2212 \u03c9 0 ) , and we get \u03c3 s = 2\u03c0 r 2 0 \u03c9 2 0 3[(\u03c9\u2212 \u03c9 0 ) 2 + \u03b3 2 /4] . (41.9) Now the whole curve is localized near \u03c9= \u03c9 0 . (We do not really have to make any approximations, but it is much easier to do the integrals if we simplify the equation a bit.) Now we multiply the intensity in a given frequency range by the cross section of scattering, to get the amount of energy scattered in the range d\u03c9 . The total energy scattered is then the integral of this for all \u03c9 . Thus d W s dt = \u222b \u221e 0 I(\u03c9) \u03c3 s (\u03c9)d\u03c9 = \u222b \u221e 0 2\u03c0 r 2 0 \u03c9 2 0 I(\u03c9)d\u03c9 3[(\u03c9\u2212 \u03c9 0 ) 2 + \u03b3 2 /4] . (41.10) Now we set d W s /dt=3\u03b3kT . Why three? Because when we made our analysis of the cross section in Chapter 32, we assumed that the polarization was such that the light could drive the oscillator. If we had used an oscillator which could move only in one direction, and the light, say, was polarized in the wrong way, it would not give any scattering. So we must either average the cross section of an oscillator which can go only in one direction, over all directions of incidence and polarization of the light or, more easily, we can imagine an oscillator which will follow the field no matter which way the field is pointing. Such an oscillator, which can oscillate equally in three directions, would have 3kT average energy because there are 3 degrees of freedom in that oscillator. So we should use 3\u03b3kT because of the 3 degrees of freedom. Now we have to do the integral. Let us suppose that the unknown spectral distribution I(\u03c9) of the light is a smooth curve and does not vary very much across the very narrow frequency region where \u03c3 s is peaked (Fig. 41\u20133). Then the only significant contribution comes when \u03c9 is very close to \u03c9 0 , within an amount gamma, which is very small. So therefore, although I(\u03c9) may be an unknown and complicated function, the only place where it is important is near \u03c9= \u03c9 0 , and there we may replace the smooth curve by a flat one\u2014a \u201cconstant\u201d\u2014at the same height. In other words, we simply take I(\u03c9) outside the integral sign and call it I( \u03c9 0 ) . We may also take the rest of the constants out in front of the integral, and what we have left is 2 3 \u03c0 r 2 0 \u03c9 2 0 I( \u03c9 0 ) \u222b \u221e 0 d\u03c9 (\u03c9\u2212 \u03c9 0 ) 2 + \u03b3 2 /4 =3\u03b3kT. (41.11) Now, the integral should go from 0 to \u221e , but 0 is so far from \u03c9 0 that the curve is all finished by that time, so we go instead to minus \u221e \u2014it makes no difference and it is much easier to do the integral. The integral is an inverse tangent function of the form \u222bdx/( x 2 + a 2 ) . If we look it up in a book we see that it is equal to \u03c0/a . So what it comes to for our case is 2\u03c0/\u03b3 . Therefore we get, with some rearranging, I( \u03c9 0 )= 9 \u03b3 2 kT 4 \u03c0 2 r 2 0 \u03c9 2 0 . (41.12) Then we substitute the formula (41.6) for gamma (do not worry about writing \u03c9 0 ; since it is true of any \u03c9 0 , we may just call it \u03c9 ) and the formula for I(\u03c9) then comes out I(\u03c9)= \u03c9 2 kT \u03c0 2 c 2 . (41.13) And that gives us the distribution of light in a hot furnace. It is called the blackbody radiation. Black, because the hole in the furnace that we look at is black when the temperature is zero. Inside a closed box at temperature T , (41.13) is the distribution of energy of the radiation, according to classical theory. First, let us notice a remarkable feature of that expression. The charge of the oscillator, the mass of the oscillator, all properties specific to the oscillator, cancel out, because once we have reached equilibrium with one oscillator, we must be at equilibrium with any other oscillator of a different mass, or we will be in trouble. So this is an important kind of check on the proposition that equilibrium does not depend on what we are in equilibrium with, but only on the temperature. Now let us draw a picture of the I(\u03c9) curve (Fig. 41\u20134). It tells us how much light we have at different frequencies. The amount of intensity that there is in our box, per unit frequency range, goes, as we see, as the square of the frequency, which means that if we have a box at any temperature at all, and if we look at the x-rays that are coming out, there will be a lot of them! Of course we know this is false. When we open the furnace and take a look at it, we do not burn our eyes out from x-rays at all. It is completely false. Furthermore, the total energy in the box, the total of all this intensity summed over all frequencies, would be the area under this infinite curve. Therefore, something is fundamentally, powerfully, and absolutely wrong. Thus was the classical theory absolutely incapable of correctly describing the distribution of light from a blackbody, just as it was incapable of correctly describing the specific heats of gases. Physicists went back and forth over this derivation from many different points of view, and there is no escape. This is the prediction of classical physics. Equation (41.13) is called Rayleigh\u2019s law, and it is the prediction of classical physics, and is obviously absurd. The difficulty above was another part of the continual problem of classical physics, which started with the difficulty of the specific heat of gases, and now has been focused on the distribution of light in a blackbody. Now, of course, at the time that theoreticians studied this thing, there were also many measurements of the actual curve. And it turned out that the correct curve looked like the dashed curves in Fig. 41\u20134. That is, the x-rays were not there. If we lower the temperature, the whole curve goes down in proportion to T , according to the classical theory, but the observed curve also cuts off sooner at a lower temperature. Thus the low-frequency end of the curve is right, but the high-frequency end is wrong. Why? When Sir James Jeans was worrying about the specific heats of gases, he noted that motions which have high frequency are \u201cfrozen out\u201d as the temperature goes too low. That is, if the temperature is too low, if the frequency is too high, the oscillators do not have kT of energy on the average. Now recall how our derivation of (41.13) worked: It all depends on the energy of an oscillator at thermal equilibrium. What the kT of (41.5) was, and what the same kT in (41.13) is, is the mean energy of a harmonic oscillator of frequency \u03c9 at temperature T . Classically, this is kT , but experimentally, no!\u2014not when the temperature is too low or the oscillator frequency is too high. And so the reason that the curve falls off is the same reason that the specific heats of gases fail. It is easier to study the blackbody curve than it is the specific heats of gases, which are so complicated, therefore our attention is focused on determining the true blackbody curve, because this curve is a curve which correctly tells us, at every frequency, what the average energy of harmonic oscillators actually is as a function of temperature. Planck studied this curve. He first determined the answer empirically, by fitting the observed curve with a nice function that fitted very well. Thus he had an empirical formula for the average energy of a harmonic oscillator as a function of frequency. In other words, he had the right formula instead of kT , and then by fiddling around he found a simple derivation for it which involved a very peculiar assumption. That assumption was that the harmonic oscillator can take up energies only \u210f\u03c9 at a time. The idea that they can have any energy at all is false. Of course, that was the beginning of the end of classical mechanics. The very first correctly determined quantum-mechanical formula will now be derived. Suppose that the permitted energy levels of a harmonic oscillator were equally spaced at \u210f \u03c9 0 apart, so that the oscillator could take on only these different energies (Fig. 41\u20135). Planck made a somewhat more complicated argument than the one that is being given here, because that was the very beginning of quantum mechanics and he had to prove some things. But we are going to take it as a fact (which he demonstrated in this case) that the probability of occupying a level of energy E is P(E)=\u03b1 e \u2212E/kT . If we go along with that, we will obtain the right result. Suppose now that we have a lot of oscillators, and each is a vibrator of frequency \u03c9 0 . Some of these vibrators will be in the bottom quantum state, some will be in the next one, and so forth. What we would like to know is the average energy of all these oscillators. To find out, let us calculate the total energy of all the oscillators and divide by the number of oscillators. That will be the average energy per oscillator in thermal equilibrium, and will also be the energy that is in equilibrium with the blackbody radiation and that should go in Eq. (41.13) in place of kT . Thus we let N 0 be the number of oscillators that are in the ground state (the lowest energy state); N 1 the number of oscillators in the state E 1 ; N 2 the number that are in state E 2 ; and so on. According to the hypothesis (which we have not proved) that in quantum mechanics the law that replaced the probability e \u2212P.E./kT or e \u2212K.E./kT in classical mechanics is that the probability goes down as e \u2212\u0394E/kT , where \u0394E is the excess energy, we shall assume that the number N 1 that are in the first state will be the number N 0 that are in the ground state, times e \u2212\u210f\u03c9/kT . Similarly, N 2 , the number of oscillators in the second state, is N 2 = N 0 e \u22122\u210f\u03c9/kT . To simplify the algebra, let us call e \u2212\u210f\u03c9/kT =x . Then we simply have N 1 = N 0 x , N 2 = N 0 x 2 , \u2026, N n = N 0 x n . The total energy of all the oscillators must first be worked out. If an oscillator is in the ground state, there is no energy. If it is in the first state, the energy is \u210f\u03c9 , and there are N 1 of them. So N 1 \u210f\u03c9 , or \u210f\u03c9 N 0 x is how much energy we get from those. Those that are in the second state have 2\u210f\u03c9 , and there are N 2 of them, so N 2 \u22c52\u210f\u03c9=2\u210f\u03c9 N 0 x 2 is how much energy we get, and so on. Then we add it all together to get E tot = N 0 \u210f\u03c9(0+x+2 x 2 +3 x 3 +\u22ef) . And now, how many oscillators are there? Of course, N 0 is the number that are in the ground state, N 1 in the first state, and so on, and we add them together: N tot = N 0 (1+x+ x 2 + x 3 +\u22ef) . Thus the average energy is \u27e8E\u27e9= E tot N tot = N 0 \u210f\u03c9(0+x+2 x 2 +3 x 3 +\u22ef) N 0 (1+x+ x 2 + x 3 +\u22ef) . (41.14) Now the two sums which appear here we shall leave for the reader to play with and have some fun with. When we are all finished summing and substituting for x in the sum, we should get\u2014if we make no mistakes in the sum\u2014 \u27e8E\u27e9= \u210f\u03c9 e \u210f\u03c9/kT \u22121 . (41.15) This, then, was the first quantum-mechanical formula ever known, or ever discussed, and it was the beautiful culmination of decades of puzzlement. Maxwell knew that there was something wrong, and the problem was, what was right? Here is the quantitative answer of what is right instead of kT . This expression should, of course, approach kT as \u03c9\u21920 or as T\u2192\u221e . See if you can prove that it does\u2014learn how to do the mathematics. This is the famous cutoff factor that Jeans was looking for, and if we use it instead of kT in (41.13), we obtain for the distribution of light in a black box I(\u03c9)d\u03c9= \u210f \u03c9 3 d\u03c9 \u03c0 2 c 2 ( e \u210f\u03c9/kT \u22121) . (41.16) We see that for a large \u03c9 , even though we have \u03c9 3 in the numerator, there is an e raised to a tremendous power in the denominator, so the curve comes down again and does not \u201cblow up\u201d\u2014we do not get ultraviolet light and x-rays where we do not expect them! One might complain that in our derivation of (41.16) we used the quantum theory for the energy levels of the harmonic oscillator, but the classical theory in determining the cross section \u03c3 s . But the quantum theory of light interacting with a harmonic oscillator gives exactly the same result as that given by the classical theory. That, in fact, is why we were justified in spending so much time on our analysis of the index of refraction and the scattering of light, using a model of atoms like little oscillators\u2014the quantum formulas are substantially the same. Now let us return to the Johnson noise in a resistor. We have already remarked that the theory of this noise power is really the same theory as that of the classical blackbody distribution. In fact, rather amusingly, we have already said that if the resistance in a circuit were not a real resistance, but were an antenna (an antenna acts like a resistance because it radiates energy), a radiation resistance, it would be easy for us to calculate what the power would be. It would be just the power that runs into the antenna from the light that is all around, and we would get the same distribution, changed by only one or two factors. We can suppose that the resistor is a generator with an unknown power spectrum P(\u03c9) . The spectrum is determined by the fact that this same generator, connected to a resonant circuit of any frequency, as in Fig. 41\u20132(b), generates in the inductance a voltage of the magnitude given in Eq. (41.2). One is thus led to the same integral as in (41.10), and the same method works to give Eq. (41.3). For low temperatures the kT in (41.3) must of course be replaced by (41.15). The two theories (blackbody radiation and Johnson noise) are also closely related physically, for we may of course connect a resonant circuit to an antenna, so the resistance R is a pure radiation resistance. Since (41.2) does not depend on the physical origin of the resistance, we know the generator G for a real resistance and for radiation resistance is the same. What is the origin of the generated power P(\u03c9) if the resistance R is only an ideal antenna in equilibrium with its environment at temperature T ? It is the radiation I(\u03c9) in the space at temperature T which impinges on the antenna and, as \u201creceived signals,\u201d makes an effective generator. Therefore one can deduce a direct relation of P(\u03c9) and I(\u03c9) , leading then from (41.13) to (41.3). All the things we have been talking about\u2014the so-called Johnson noise and Planck\u2019s distribution, and the correct theory of the Brownian movement which we are about to describe\u2014are developments of the first decade or so of the 20th century. Now with those points and that history in mind, we return to the Brownian movement. Let us consider how the position of a jiggling particle should change with time, for very long times compared with the time between \u201ckicks.\u201d Consider a little Brownian movement particle which is jiggling about because it is bombarded on all sides by irregularly jiggling water molecules. Query: After a given length of time, how far away is it likely to be from where it began? This problem was solved by Einstein and Smoluchowski. If we imagine that we divide the time into little intervals, let us say a hundredth of a second or so, then after the first hundredth of a second it moves here, and in the next hundredth it moves some more, in the next hundredth of a second it moves somewhere else, and so on. In terms of the rate of bombardment, a hundredth of a second is a very long time. The reader may easily verify that the number of collisions a single molecule of water receives in a second is about 10 14 , so in a hundredth of a second it has 10 12 collisions, which is a lot! Therefore, after a hundredth of a second it is not going to remember what happened before. In other words, the collisions are all random, so that one \u201cstep\u201d is not related to the previous \u201cstep.\u201d It is like the famous drunken sailor problem: the sailor comes out of the bar and takes a sequence of steps, but each step is chosen at an arbitrary angle, at random (Fig. 41\u20136). The question is: After a long time, where is the sailor? Of course we do not know! It is impossible to say. What do we mean\u2014he is just somewhere more or less random. Well then, on the average, where is he? On the average, how far away from the bar has he gone? We have already answered this question, because once we were discussing the superposition of light from a whole lot of different sources at different phases, and that meant adding a lot of arrows at different angles (Chapter 30). There we discovered that the mean square of the distance from one end to the other of the chain of random steps, which was the intensity of the light, is the sum of the intensities of the separate pieces. And so, by the same kind of mathematics, we can prove immediately that if R N is the vector distance from the origin after N steps, the mean square of the distance from the origin is proportional to the number N of steps. That is, \u27e8 R 2 N \u27e9=N L 2 , where L is the length of each step. Since the number of steps is proportional to the time in our present problem, the mean square distance is proportional to the time: \u27e8 R 2 \u27e9=\u03b1t. (41.17) This does not mean that the mean distance is proportional to the time. If the mean distance were proportional to the time it would mean that the drifting is at a nice uniform velocity. The sailor is making some relatively sensible headway, but only such that his mean square distance is proportional to time. That is the characteristic of a random walk. We may show very easily that in each successive step the square of the distance increases, on the average, by L 2 . For if we write R N = R N\u22121 +L , we find that R 2 N is R N \u22c5 R N = R 2 N = R 2 N\u22121 +2 R N\u22121 \u22c5L+ L 2 , 2 2 2 and averaging over many trials, we have \u27e8 R 2 N \u27e9=\u27e8 R 2 N\u22121 \u27e9+ L 2 , since \u27e8 R N\u22121 \u22c5L\u27e9=0 . Thus, by induction, \u27e8 R 2 N \u27e9=N L 2 . (41.18) Now we would like to calculate the coefficient \u03b1 in Eq. (41.17), and to do so we must add a feature. We are going to suppose that if we were to put a force on this particle (having nothing to do with the Brownian movement\u2014we are taking a side issue for the moment), then it would react in the following way against the force. First, there would be inertia. Let m be the coefficient of inertia, the effective mass of the object (not necessarily the same as the real mass of the real particle, because the water has to move around the particle if we pull on it). Thus if we talk about motion in one direction, there is a term like m( d 2 x/d t 2 ) on one side. And next, we want also to assume that if we kept a steady pull on the object, there would be a drag on it from the fluid, proportional to its velocity. Besides the inertia of the fluid, there is a resistance to flow due to the viscosity and the complexity of the fluid. It is absolutely essential that there be some irreversible losses, something like resistance, in order that there be fluctuations. There is no way to produce the kT unless there are also losses. The source of the fluctuations is very closely related to these losses. What the mechanism of this drag is, we will discuss soon\u2014we shall talk about forces that are proportional to the velocity and where they come from. But let us suppose for now that there is such a resistance. Then the formula for the motion under an external force, when we are pulling on it in a normal manner, is m d 2 x d t 2 +\u03bc dx dt = F ext . (41.19) The quantity \u03bc can be determined directly from experiment. For example, we can watch the drop fall under gravity. Then we know that the force is mg , and \u03bc is mg divided by the speed of fall the drop ultimately acquires. Or we could put the drop in a centrifuge and see how fast it sediments. Or if it is charged, we can put an electric field on it. So \u03bc is a measurable thing, not an artificial thing, and it is known for many types of colloidal particles, etc. Now let us use the same formula in the case where the force is not external, but is equal to the irregular forces of the Brownian movement. We shall then try to determine the mean square distance that the object goes. Instead of taking the distances in three dimensions, let us take just one dimension, and find the mean of x 2 , just to prepare ourselves. (Obviously the mean of x 2 is the same as the mean of y 2 is the same as the mean of z 2 , and therefore the mean square of the distance is just 3 times what we are going to calculate.) The x -component of the irregular forces is, of course, just as irregular as any other component. What is the rate of change of x 2 ? It is d( x 2 )/dt=2x(dx/dt) , so what we have to find is the average of the position times the velocity. We shall show that this is a constant, and that therefore the mean square radius will increase proportionally to the time, and at what rate. Now if we multiply Eq. (41.19) by x , mx( d 2 x/d t 2 )+\u03bcx(dx/dt)=x F x . We want the time average of x(dx/dt) , so let us take the average of the whole equation, and study the three terms. Now what about x times the force? If the particle happens to have gone a certain distance x , then, since the irregular force is completely irregular and does not know where the particle started from, the next impulse can be in any direction relative to x . If x is positive, there is no reason why the average force should also be in that direction. It is just as likely to be one way as the other. The bombardment forces are not driving it in a definite direction. So the average value of x times F is zero. On the other hand, for the term mx( d 2 x/d t 2 ) we will have to be a little fancy, and write this as mx d 2 x d t 2 =m d[x(dx/dt)] dt \u2212m( dx dt ) 2 . 2 Thus we put in these two terms and take the average of both. So let us see how much the first term should be. Now x times the velocity has a mean that does not change with time, because when it gets to some position it has no remembrance of where it was before, so things are no longer changing with time. So this quantity, on the average, is zero. We have left the quantity m v 2 , and that is the only thing we know: m v 2 /2 has a mean value 1 2 kT . Therefore we find that \u27e8mx d 2 x d t 2 \u27e9+\u03bc\u27e8x dx dt \u27e9=\u27e8x F x \u27e9 2 implies \u2212\u27e8m v 2 \u27e9+ \u03bc 2 d dt \u27e8 x 2 \u27e9=0, d or d\u27e8 x 2 \u27e9 dt =2 kT \u03bc . (41.20) Therefore the object has a mean square distance \u27e8 R 2 \u27e9 , at the end of a certain amount of t , equal to \u27e8 R 2 \u27e9=6kT t \u03bc . (41.21) And so we can actually determine how far the particles go! We first must determine how they react to a steady force, how fast they drift under a known force (to find \u03bc ), and then we can determine how far they go in their random motions. This equation was of considerable importance historically, because it was one of the first ways by which the constant k was determined. After all, we can measure \u03bc , the time, how far the particles go, and we can take an average. The reason that the determination of k was important is that in the law PV=RT for a mole, we know that R , which can also be measured, is equal to the number of atoms in a mole times k . A mole was originally defined as so and so many grams of oxygen-16 (now carbon is used), so the number of atoms in a mole was not known, originally. It is, of course, a very interesting and important problem. How big are atoms? How many are there? So one of the earliest determinations of the number of atoms was by the determination of how far a dirty little particle would move if we watched it patiently under a microscope for a certain length of time. And thus Boltzmann\u2019s constant k and the Avogadro number N 0 were determined because R had already been measured."
    },
    {
        "input": "The Relation of Wave and Particle Viewpoints",
        "output": "In this chapter we shall discuss the relationship of the wave and particle viewpoints. We already know, from the last chapter, that neither the wave viewpoint nor the particle viewpoint is correct. We would always like to present things accurately, or at least precisely enough that they will not have to be changed when we learn more\u2014it may be extended, but it will not be changed! But when we try to talk about the wave picture or the particle picture, both are approximate, and both will change. Therefore what we learn in this chapter will not be accurate in a certain sense; we will deal with some half-intuitive arguments which will be made more precise later. But certain things will be changed a little bit when we interpret them correctly in quantum mechanics. We are doing this so that you can have some qualitative feeling for some quantum phenomena before we get into the mathematical details of quantum mechanics. Furthermore, all our experiences are with waves and with particles, and so it is rather handy to use the wave and particle ideas to get some understanding of what happens in given circumstances before we know the complete mathematics of the quantum-mechanical amplitudes. We shall try to indicate the weakest places as we go along, but most of it is very nearly correct\u2014it is just a matter of interpretation. First of all, we know that the new way of representing the world in quantum mechanics\u2014the new framework\u2014is to give an amplitude for every event that can occur, and if the event involves the reception of one particle, then we can give the amplitude to find that one particle at different places and at different times. The probability of finding the particle is then proportional to the absolute square of the amplitude. In general, the amplitude to find a particle in different places at different times varies with position and time. In some special case it can be that the amplitude varies sinusoidally in space and time like ei(\u03c9t\u2212k\u22c5r) , where r is the vector position from some origin. (Do not forget that these amplitudes are complex numbers, not real numbers.) Such an amplitude varies according to a definite frequency \u03c9 and wave number k . Then it turns out that this corresponds to a classical limiting situation where we would have believed that we have a particle whose energy E was known and is related to the frequency by E=\u210f\u03c9, and whose momentum p is also known and is related to the wave number by p=\u210fk. (The symbol \u210f represents the number h divided by 2\u03c0 ; \u210f=h/2\u03c0 .) This means that the idea of a particle is limited. The idea of a particle\u2014its location, its momentum, etc.\u2014which we use so much, is in certain ways unsatisfactory. For instance, if an amplitude to find a particle at different places is given by ei(\u03c9t\u2212k\u22c5r) , whose absolute square is a constant, that would mean that the probability of finding a particle is the same at all points. That means we do not know where it is\u2014it can be anywhere\u2014there is a great uncertainty in its location. On the other hand, if the position of a particle is more or less well known and we can predict it fairly accurately, then the probability of finding it in different places must be confined to a certain region, whose length we call \u0394x . Outside this region, the probability is zero. Now this probability is the absolute square of an amplitude, and if the absolute square is zero, the amplitude is also zero, so that we have a wave train whose length is \u0394x (Fig. 2\u20131), and the wavelength (the distance between nodes of the waves in the train) of that wave train is what corresponds to the particle momentum. Here we encounter a strange thing about waves; a very simple thing which has nothing to do with quantum mechanics strictly. It is something that anybody who works with waves, even if he knows no quantum mechanics, knows: namely, we cannot define a unique wavelength for a short wave train. Such a wave train does not have a definite wavelength; there is an indefiniteness in the wave number that is related to the finite length of the train, and thus there is an indefiniteness in the momentum. Let us consider two examples of this idea\u2014to see the reason that there is an uncertainty in the position and/or the momentum, if quantum mechanics is right. We have also seen before that if there were not such a thing\u2014if it were possible to measure the position and the momentum of anything simultaneously\u2014we would have a paradox; it is fortunate that we do not have such a paradox, and the fact that such an uncertainty comes naturally from the wave picture shows that everything is mutually consistent. Here is one example which shows the relationship between the position and the momentum in a circumstance that is easy to understand. Suppose we have a single slit, and particles are coming from very far away with a certain energy\u2014so that they are all coming essentially horizontally (Fig. 2\u20132). We are going to concentrate on the vertical components of momentum. All of these particles have a certain horizontal momentum p 0 , say, in a classical sense. So, in the classical sense, the vertical momentum p y , before the particle goes through the hole, is definitely known. The particle is moving neither up nor down, because it came from a source that is far away\u2014and so the vertical momentum is of course zero. But now let us suppose that it goes through a hole whose width is B . Then after it has come out through the hole, we know the position vertically\u2014the y -position\u2014with considerable accuracy\u2014namely \u00b1B .1 That is, the uncertainty in position, \u0394y , is of order B . Now we might also want to say, since we know the momentum is absolutely horizontal, that \u0394 p y is zero; but that is wrong. We once knew the momentum was horizontal, but we do not know it any more. Before the particles passed through the hole, we did not know their vertical positions. Now that we have found the vertical position by having the particle come through the hole, we have lost our information on the vertical momentum! Why? According to the wave theory, there is a spreading out, or diffraction, of the waves after they go through the slit, just as for light. Therefore there is a certain probability that particles coming out of the slit are not coming exactly straight. The pattern is spread out by the diffraction effect, and the angle of spread, which we can define as the angle of the first minimum, is a measure of the uncertainty in the final angle. How does the pattern become spread? To say it is spread means that there is some chance for the particle to be moving up or down, that is, to have a component of momentum up or down. We say chance and particle because we can detect this diffraction pattern with a particle counter, and when the counter receives the particle, say at C in Fig. 2\u20132, it receives the entire particle, so that, in a classical sense, the particle has a vertical momentum, in order to get from the slit up to C . To get a rough idea of the spread of the momentum, the vertical momentum p y has a spread which is equal to p 0 \u0394\u03b8 , where p 0 is the horizontal momentum. And how big is \u0394\u03b8 in the spread-out pattern? We know that the first minimum occurs at an angle \u0394\u03b8 such that the waves from one edge of the slit have to travel one wavelength farther than the waves from the other side\u2014we worked that out before (Chapter 30 of Vol. I). Therefore \u0394\u03b8 is \u03bb/B , and so \u0394 p y in this experiment is p 0 \u03bb/B . Note that if we make B smaller and make a more accurate measurement of the position of the particle, the diffraction pattern gets wider. So the narrower we make the slit, the wider the pattern gets, and the more is the likelihood that we would find that the particle has sidewise momentum. Thus the uncertainty in the vertical momentum is inversely proportional to the uncertainty of y . In fact, we see that the product of the two is equal to p 0 \u03bb . But \u03bb is the wavelength and p 0 is the momentum, and in accordance with quantum mechanics, the wavelength times the momentum is Planck\u2019s constant h . So we obtain the rule that the uncertainties in the vertical momentum and in the vertical position have a product of the order h : \u0394y\u0394 p y \u2265\u210f/2. (2.3) We cannot prepare a system in which we know the vertical position of a particle and can predict how it will move vertically with greater certainty than given by (2.3). That is, the uncertainty in the vertical momentum must exceed \u210f/2\u0394y , where \u0394y is the uncertainty in our knowledge of the position. Sometimes people say quantum mechanics is all wrong. When the particle arrived from the left, its vertical momentum was zero. And now that it has gone through the slit, its position is known. Both position and momentum seem to be known with arbitrary accuracy. It is quite true that we can receive a particle, and on reception determine what its position is and what its momentum would have had to have been to have gotten there. That is true, but that is not what the uncertainty relation (2.3) refers to. Equation (2.3) refers to the predictability of a situation, not remarks about the past. It does no good to say \u201cI knew what the momentum was before it went through the slit, and now I know the position,\u201d because now the momentum knowledge is lost. The fact that it went through the slit no longer permits us to predict the vertical momentum. We are talking about a predictive theory, not just measurements after the fact. So we must talk about what we can predict. Now let us take the thing the other way around. Let us take another example of the same phenomenon, a little more quantitatively. In the previous example we measured the momentum by a classical method. Namely, we considered the direction and the velocity and the angles, etc., so we got the momentum by classical analysis. But since momentum is related to wave number, there exists in nature still another way to measure the momentum of a particle\u2014photon or otherwise\u2014which has no classical analog, because it uses Eq. (2.2). We measure the wavelengths of the waves. Let us try to measure momentum in this way. Suppose we have a grating with a large number of lines (Fig. 2\u20133), and send a beam of particles at the grating. We have often discussed this problem: if the particles have a definite momentum, then we get a very sharp pattern in a certain direction, because of the interference. And we have also talked about how accurately we can determine that momentum, that is to say, what the resolving power of such a grating is. Rather than derive it again, we refer to Chapter 30 of Volume I, where we found that the relative uncertainty in the wavelength that can be measured with a given grating is 1/Nm , where N is the number of lines on the grating and m is the order of the diffraction pattern. That is, \u0394\u03bb/\u03bb=1/Nm. (2.4) Now formula (2.4) can be rewritten as \u0394\u03bb/ \u03bb 2 =1/Nm\u03bb=1/L, (2.5) where L is the distance shown in Fig. 2\u20133. This distance is the difference between the total distance that the particle or wave or whatever it is has to travel if it is reflected from the bottom of the grating, and the distance that it has to travel if it is reflected from the top of the grating. That is, the waves which form the diffraction pattern are waves which come from different parts of the grating. The first ones that arrive come from the bottom end of the grating, from the beginning of the wave train, and the rest of them come from later parts of the wave train, coming from different parts of the grating, until the last one finally arrives, and that involves a point in the wave train a distance L behind the first point. So in order that we shall have a sharp line in our spectrum corresponding to a definite momentum, with an uncertainty given by (2.4), we have to have a wave train of at least length L . If the wave train is too short, we are not using the entire grating. The waves which form the spectrum are being reflected from only a very short sector of the grating if the wave train is too short, and the grating will not work right\u2014we will find a big angular spread. In order to get a narrower one, we need to use the whole grating, so that at least at some moment the whole wave train is scattering simultaneously from all parts of the grating. Thus the wave train must be of length L in order to have an uncertainty in the wavelength less than that given by (2.5). Incidentally, \u0394\u03bb/ \u03bb 2 =\u0394(1/\u03bb)=\u0394k/2\u03c0. (2.6) Therefore \u0394k=2\u03c0/L, (2.7) where L is the length of the wave train. This means that if we have a wave train whose length is less than L , the uncertainty in the wave number must exceed 2\u03c0/L . Or the uncertainty in a wave number times the length of the wave train\u2014we will call that for a moment \u0394x \u2014exceeds 2\u03c0 . We call it \u0394x because that is the uncertainty in the location of the particle. If the wave train exists only in a finite length, then that is where we could find the particle, within an uncertainty \u0394x . Now this property of waves, that the length of the wave train times the uncertainty of the wave number associated with it is at least 2\u03c0 , is a property that is known to everyone who studies them. It has nothing to do with quantum mechanics. It is simply that if we have a finite train, we cannot count the waves in it very precisely. Let us try another way to see the reason for that. Suppose that we have a finite train of length L ; then because of the way it has to decrease at the ends, as in Fig. 2\u20131, the number of waves in the length L is uncertain by something like \u00b11 . But the number of waves in L is kL/2\u03c0 . Thus k is uncertain, and we again get the result (2.7), a property merely of waves. The same thing works whether the waves are in space and k is the number of radians per centimeter and L is the length of the train, or the waves are in time and \u03c9 is the number of radians per second and T is the \u201clength\u201d in time that the wave train comes in. That is, if we have a wave train lasting only for a certain finite time T , then the uncertainty in the frequency is given by \u0394\u03c9=2\u03c0/T. (2.8) We have tried to emphasize that these are properties of waves alone, and they are well known, for example, in the theory of sound. The point is that in quantum mechanics we interpret the wave number as being a measure of the momentum of a particle, with the rule that p=\u210fk , so that relation (2.7) tells us that \u0394p\u2248h/\u0394x . This, then, is a limitation of the classical idea of momentum. (Naturally, it has to be limited in some ways if we are going to represent particles by waves!) It is nice that we have found a rule that gives us some idea of when there is a failure of classical ideas. Next let us consider the reflection of particle waves from a crystal. A crystal is a thick thing which has a whole lot of similar atoms\u2014we will include some complications later\u2014in a nice array. The question is how to set the array so that we get a strong reflected maximum in a given direction for a given beam of, say, light (x-rays), electrons, neutrons, or anything else. In order to obtain a strong reflection, the scattering from all of the atoms must be in phase. There cannot be equal numbers in phase and out of phase, or the waves will cancel out. The way to arrange things is to find the regions of constant phase, as we have already explained; they are planes which make equal angles with the initial and final directions (Fig. 2\u20134). If we consider two parallel planes, as in Fig. 2\u20134, the waves scattered from the two planes will be in phase, provided the difference in distance traveled by a wave front is an integral number of wavelengths. This difference can be seen to be 2dsin\u03b8 , where d is the perpendicular distance between the planes. Thus the condition for coherent reflection is 2dsin\u03b8=n\u03bb(n=1,2,\u2026). (2.9) If, for example, the crystal is such that the atoms happen to lie on planes obeying condition (2.9) with n=1 , then there will be a strong reflection. If, on the other hand, there are other atoms of the same nature (equal in density) halfway between, then the intermediate planes will also scatter equally strongly and will interfere with the others and produce no effect. So d in (2.9) must refer to adjacent planes; we cannot take a plane five layers farther back and use this formula! As a matter of interest, actual crystals are not usually as simple as a single kind of atom repeated in a certain way. Instead, if we make a two-dimensional analog, they are much like wallpaper, in which there is some kind of figure which repeats all over the wallpaper. By \u201cfigure\u201d we mean, in the case of atoms, some arrangement\u2014calcium and a carbon and three oxygens, etc., for calcium carbonate, and so on\u2014which may involve a relatively large number of atoms. But whatever it is, the figure is repeated in a pattern. This basic figure is called a unit cell. The basic pattern of repetition defines what we call the lattice type; the lattice type can be immediately determined by looking at the reflections and seeing what their symmetry is. In other words, where we find any reflections at all determines the lattice type, but in order to determine what is in each of the elements of the lattice one must take into account the intensity of the scattering at the various directions. Which directions scatter depends on the type of lattice, but how strongly each scatters is determined by what is inside each unit cell, and in that way the structure of crystals is worked out. Two photographs of x-ray diffraction patterns are shown in Figs. 2\u20135 and 2\u20136; they illustrate scattering from rock salt and myoglobin, respectively. Incidentally, an interesting thing happens if the spacings of the nearest planes are less than \u03bb/2 . In this case (2.9) has no solution for n . Thus if \u03bb is bigger than twice the distance between adjacent planes, then there is no side diffraction pattern, and the light\u2014or whatever it is\u2014will go right through the material without bouncing off or getting lost. So in the case of light, where \u03bb is much bigger than the spacing, of course it does go through and there is no pattern of reflection from the planes of the crystal. This fact also has an interesting consequence in the case of piles which make neutrons (these are obviously particles, for anybody\u2019s money!). If we take these neutrons and let them into a long block of graphite, the neutrons diffuse and work their way along (Fig. 2\u20137). They diffuse because they are bounced by the atoms, but strictly, in the wave theory, they are bounced by the atoms because of diffraction from the crystal planes. It turns out that if we take a very long piece of graphite, the neutrons that come out the far end are all of long wavelength! In fact, if one plots the intensity as a function of wavelength, we get nothing except for wavelengths longer than a certain minimum (Fig. 2\u20138). In other words, we can get very slow neutrons that way. Only the slowest neutrons come through; they are not diffracted or scattered by the crystal planes of the graphite, but keep going right through like light through glass, and are not scattered out the sides. There are many other demonstrations of the reality of neutron waves and waves of other particles. We now consider another application of the uncertainty relation, Eq. (2.3). It must not be taken too seriously; the idea is right but the analysis is not very accurate. The idea has to do with the determination of the size of atoms, and the fact that, classically, the electrons would radiate light and spiral in until they settle down right on top of the nucleus. But that cannot be right quantum-mechanically because then we would know where each electron was and how fast it was moving. Suppose we have a hydrogen atom, and measure the position of the electron; we must not be able to predict exactly where the electron will be, or the momentum spread will then turn out to be infinite. Every time we look at the electron, it is somewhere, but it has an amplitude to be in different places so there is a probability of it being found in different places. These places cannot all be at the nucleus; we shall suppose there is a spread in position of order a . That is, the distance of the electron from the nucleus is usually about a . We shall determine a by minimizing the total energy of the atom. The spread in momentum is roughly \u210f/a because of the uncertainty relation, so that if we try to measure the momentum of the electron in some manner, such as by scattering x-rays off it and looking for the Doppler effect from a moving scatterer, we would expect not to get zero every time\u2014the electron is not standing still\u2014but the momenta must be of the order p\u2248\u210f/a . Then the kinetic energy is roughly 1 2 m v 2 = p 2 /2m= \u210f 2 /2m a 2 . (In a sense, this is a kind of dimensional analysis to find out in what way the kinetic energy depends upon the reduced Planck constant, upon m , and upon the size of the atom. We need not trust our answer to within factors like 2 , \u03c0 , etc. We have not even defined a very precisely.) Now the potential energy is minus e 2 over the distance from the center, say \u2212 e 2 /a , where, as defined in Volume I, e 2 is the charge of an electron squared, divided by 4\u03c0 \u03f5 0 . Now the point is that the potential energy is reduced if a gets smaller, but the smaller a is, the higher the momentum required, because of the uncertainty principle, and therefore the higher the kinetic energy. The total energy is E= \u210f 2 /2m a 2 \u2212 e 2 /a. (2.10) We do not know what a is, but we know that the atom is going to arrange itself to make some kind of compromise so that the energy is as little as possible. In order to minimize E , we differentiate with respect to a , set the derivative equal to zero, and solve for a . The derivative of E is dE/da=\u2212 \u210f 2 /m a 3 + e 2 / a 2 , (2.11) and setting dE/da=0 gives for a the value a 0 = \u210f 2 /m e 2 =0.528 angstrom, =0.528\u00d7 10 \u221210 meter. (2.12) This particular distance is called the Bohr radius, and we have thus learned that atomic dimensions are of the order of angstroms, which is right. This is pretty good\u2014in fact, it is amazing, since until now we have had no basis for understanding the size of atoms! Atoms are completely impossible from the classical point of view, since the electrons would spiral into the nucleus. Now if we put the value (2.12) for a 0 into (2.10) to find the energy, it comes out E 0 =\u2212 e 2 /2 a 0 =\u2212m e 4 /2 \u210f 2 =\u221213.6 eV. (2.13) What does a negative energy mean? It means that the electron has less energy when it is in the atom than when it is free. It means it is bound. It means it takes energy to kick the electron out; it takes energy of the order of 13.6 eV to ionize a hydrogen atom. We have no reason to think that it is not two or three times this\u2014or half of this\u2014or (1/\u03c0) times this, because we have used such a sloppy argument. However, we have cheated, we have used all the constants in such a way that it happens to come out the right number! This number, 13.6 electron volts, is called a Rydberg of energy; it is the ionization energy of hydrogen. So we now understand why we do not fall through the floor. As we walk, our shoes with their masses of atoms push against the floor with its mass of atoms. In order to squash the atoms closer together, the electrons would be confined to a smaller space and, by the uncertainty principle, their momenta would have to be higher on the average, and that means high energy; the resistance to atomic compression is a quantum-mechanical effect and not a classical effect. Classically, we would expect that if we were to draw all the electrons and protons closer together, the energy would be reduced still further, and the best arrangement of positive and negative charges in classical physics is all on top of each other. This was well known in classical physics and was a puzzle because of the existence of the atom. Of course, the early scientists invented some ways out of the trouble\u2014but never mind, we have the right way out, now! Incidentally, although we have no reason to understand it at the moment, in a situation where there are many electrons it turns out that they try to keep away from each other. If one electron is occupying a certain space, then another does not occupy the same space. More precisely, there are two spin cases, so that two can sit on top of each other, one spinning one way and one the other way. But after that we cannot put any more there. We have to put others in another place, and that is the real reason that matter has strength. If we could put all the electrons in the same place, it would condense even more than it does. It is the fact that the electrons cannot all get on top of each other that makes tables and everything else solid. Obviously, in order to understand the properties of matter, we will have to use quantum mechanics and not be satisfied with classical mechanics. We have talked about the atom in its lowest possible energy condition, but it turns out that the electron can do other things. It can jiggle and wiggle in a more energetic manner, and so there are many different possible motions for the atom. According to quantum mechanics, in a stationary condition there can only be definite energies for an atom. We make a diagram (Fig. 2\u20139) in which we plot the energy vertically, and we make a horizontal line for each allowed value of the energy. When the electron is free, i.e., when its energy is positive, it can have any energy; it can be moving at any speed. But bound energies are not arbitrary. The atom must have one or another out of a set of allowed values, such as those in Fig. 2\u20139. Now let us call the allowed values of the energy E 0 , E 1 , E 2 , E 3 . If an atom is initially in one of these \u201cexcited states,\u201d E 1 , E 2 , etc., it does not remain in that state forever. Sooner or later it drops to a lower state and radiates energy in the form of light. The frequency of the light that is emitted is determined by conservation of energy plus the quantum-mechanical understanding that the frequency of the light is related to the energy of the light by (2.1). Therefore the frequency of the light which is liberated in a transition from energy E 3 to energy E 1 (for example) is \u03c9 31 =( E 3 \u2212 E 1 )/\u210f. (2.14) This, then, is a characteristic frequency of the atom and defines a spectral emission line. Another possible transition would be from E 3 to E 0 . That would have a different frequency \u03c9 30 =( E 3 \u2212 E 0 )/\u210f. (2.15) Another possibility is that if the atom were excited to the state E 1 it could drop to the ground state E 0 , emitting a photon of frequency \u03c9 10 =( E 1 \u2212 E 0 )/\u210f. (2.16) The reason we bring up three transitions is to point out an interesting relationship. It is easy to see from (2.14), (2.15), and (2.16) that \u03c9 30 = \u03c9 31 + \u03c9 10 . (2.17) In general, if we find two spectral lines, we shall expect to find another line at the sum of the frequencies (or the difference in the frequencies), and that all the lines can be understood by finding a series of levels such that every line corresponds to the difference in energy of some pair of levels. This remarkable coincidence in spectral frequencies was noted before quantum mechanics was discovered, and it is called the Ritz combination principle. This is again a mystery from the point of view of classical mechanics. Let us not belabor the point that classical mechanics is a failure in the atomic domain; we seem to have demonstrated that pretty well. We have already talked about quantum mechanics as being represented by amplitudes which behave like waves, with certain frequencies and wave numbers. Let us observe how it comes about from the point of view of amplitudes that the atom has definite energy states. This is something we cannot understand from what has been said so far, but we are all familiar with the fact that confined waves have definite frequencies. For instance, if sound is confined to an organ pipe, or anything like that, then there is more than one way that the sound can vibrate, but for each such way there is a definite frequency. Thus an object in which the waves are confined has certain resonance frequencies. It is therefore a property of waves in a confined space\u2014a subject which we will discuss in detail with formulas later on\u2014that they exist only at definite frequencies. And since the general relation exists between frequencies of the amplitude and energy, we are not surprised to find definite energies associated with electrons bound in atoms. Let us consider briefly some philosophical implications of quantum mechanics. As always, there are two aspects of the problem: one is the philosophical implication for physics, and the other is the extrapolation of philosophical matters to other fields. When philosophical ideas associated with science are dragged into another field, they are usually completely distorted. Therefore we shall confine our remarks as much as possible to physics itself. First of all, the most interesting aspect is the idea of the uncertainty principle; making an observation affects the phenomenon. It has always been known that making observations affects a phenomenon, but the point is that the effect cannot be disregarded or minimized or decreased arbitrarily by rearranging the apparatus. When we look for a certain phenomenon we cannot help but disturb it in a certain minimum way, and the disturbance is necessary for the consistency of the viewpoint. The observer was sometimes important in prequantum physics, but only in a trivial sense. The problem has been raised: if a tree falls in a forest and there is nobody there to hear it, does it make a noise? A real tree falling in a real forest makes a sound, of course, even if nobody is there. Even if no one is present to hear it, there are other traces left. The sound will shake some leaves, and if we were careful enough we might find somewhere that some thorn had rubbed against a leaf and made a tiny scratch that could not be explained unless we assumed the leaf were vibrating. So in a certain sense we would have to admit that there is a sound made. We might ask: was there a sensation of sound? No, sensations have to do, presumably, with consciousness. And whether ants are conscious and whether there were ants in the forest, or whether the tree was conscious, we do not know. Let us leave the problem in that form. Another thing that people have emphasized since quantum mechanics was developed is the idea that we should not speak about those things which we cannot measure. (Actually relativity theory also said this.) Unless a thing can be defined by measurement, it has no place in a theory. And since an accurate value of the momentum of a localized particle cannot be defined by measurement it therefore has no place in the theory. The idea that this is what was the matter with classical theory is a false position. It is a careless analysis of the situation. Just because we cannot measure position and momentum precisely does not a priori mean that we cannot talk about them. It only means that we need not talk about them. The situation in the sciences is this: A concept or an idea which cannot be measured or cannot be referred directly to experiment may or may not be useful. It need not exist in a theory. In other words, suppose we compare the classical theory of the world with the quantum theory of the world, and suppose that it is true experimentally that we can measure position and momentum only imprecisely. The question is whether the ideas of the exact position of a particle and the exact momentum of a particle are valid or not. The classical theory admits the ideas; the quantum theory does not. This does not in itself mean that classical physics is wrong. When the new quantum mechanics was discovered, the classical people\u2014which included everybody except Heisenberg, Schr\u00f6dinger, and Born\u2014said: \u201cLook, your theory is not any good because you cannot answer certain questions like: what is the exact position of a particle?, which hole does it go through?, and some others.\u201d Heisenberg\u2019s answer was: \u201cI do not need to answer such questions because you cannot ask such a question experimentally.\u201d It is that we do not have to. Consider two theories (a) and (b); (a) contains an idea that cannot be checked directly but which is used in the analysis, and the other, (b), does not contain the idea. If they disagree in their predictions, one could not claim that (b) is false because it cannot explain this idea that is in (a), because that idea is one of the things that cannot be checked directly. It is always good to know which ideas cannot be checked directly, but it is not necessary to remove them all. It is not true that we can pursue science completely by using only those concepts which are directly subject to experiment. In quantum mechanics itself there is a probability amplitude, there is a potential, and there are many constructs that we cannot measure directly. The basis of a science is its ability to predict. To predict means to tell what will happen in an experiment that has never been done. How can we do that? By assuming that we know what is there, independent of the experiment. We must extrapolate the experiments to a region where they have not been done. We must take our concepts and extend them to places where they have not yet been checked. If we do not do that, we have no prediction. So it was perfectly sensible for the classical physicists to go happily along and suppose that the position\u2014which obviously means something for a baseball\u2014meant something also for an electron. It was not stupidity. It was a sensible procedure. Today we say that the law of relativity is supposed to be true at all energies, but someday somebody may come along and say how stupid we were. We do not know where we are \u201cstupid\u201d until we \u201cstick our neck out,\u201d and so the whole idea is to put our neck out. And the only way to find out that we are wrong is to find out what our predictions are. It is absolutely necessary to make constructs. We have already made a few remarks about the indeterminacy of quantum mechanics. That is, that we are unable now to predict what will happen in physics in a given physical circumstance which is arranged as carefully as possible. If we have an atom that is in an excited state and so is going to emit a photon, we cannot say when it will emit the photon. It has a certain amplitude to emit the photon at any time, and we can predict only a probability for emission; we cannot predict the future exactly. This has given rise to all kinds of nonsense and questions on the meaning of freedom of will, and of the idea that the world is uncertain. Of course we must emphasize that classical physics is also indeterminate, in a sense. It is usually thought that this indeterminacy, that we cannot predict the future, is an important quantum-mechanical thing, and this is said to explain the behavior of the mind, feelings of free will, etc. But if the world were classical\u2014if the laws of mechanics were classical\u2014it is not quite obvious that the mind would not feel more or less the same. It is true classically that if we knew the position and the velocity of every particle in the world, or in a box of gas, we could predict exactly what would happen. And therefore the classical world is deterministic. Suppose, however, that we have a finite accuracy and do not know exactly where just one atom is, say to one part in a billion. Then as it goes along it hits another atom, and because we did not know the position better than to one part in a billion, we find an even larger error in the position after the collision. And that is amplified, of course, in the next collision, so that if we start with only a tiny error it rapidly magnifies to a very great uncertainty. To give an example: if water falls over a dam, it splashes. If we stand nearby, every now and then a drop will land on our nose. This appears to be completely random, yet such a behavior would be predicted by purely classical laws. The exact position of all the drops depends upon the precise wigglings of the water before it goes over the dam. How? The tiniest irregularities are magnified in falling, so that we get complete randomness. Obviously, we cannot really predict the position of the drops unless we know the motion of the water absolutely exactly. Speaking more precisely, given an arbitrary accuracy, no matter how precise, one can find a time long enough that we cannot make predictions valid for that long a time. Now the point is that this length of time is not very large. It is not that the time is millions of years if the accuracy is one part in a billion. The time goes, in fact, only logarithmically with the error, and it turns out that in only a very, very tiny time we lose all our information. If the accuracy is taken to be one part in billions and billions and billions\u2014no matter how many billions we wish, provided we do stop somewhere\u2014then we can find a time less than the time it took to state the accuracy\u2014after which we can no longer predict what is going to happen! It is therefore not fair to say that from the apparent freedom and indeterminacy of the human mind, we should have realized that classical \u201cdeterministic\u201d physics could not ever hope to understand it, and to welcome quantum mechanics as a release from a \u201ccompletely mechanistic\u201d universe. For already in classical mechanics there was indeterminability from a practical point of view."
    },
    {
        "input": "Differential Calculus of Vector Fields",
        "output": "The physicist needs a facility in looking at problems from several points of view. The exact analysis of real physical problems is usually quite complicated, and any particular physical situation may be too complicated to analyze directly by solving the differential equation. But one can still get a very good idea of the behavior of a system if one has some feel for the character of the solution in different circumstances. Ideas such as the field lines, capacitance, resistance, and inductance are, for such purposes, very useful. So we will spend much of our time analyzing them. In this way we will get a feel as to what should happen in different electromagnetic situations. On the other hand, none of the heuristic models, such as field lines, is really adequate and accurate for all situations. There is only one precise way of presenting the laws, and that is by means of differential equations. They have the advantage of being fundamental and, so far as we know, precise. If you have learned the differential equations you can always go back to them. There is nothing to unlearn. It will take you some time to understand what should happen in different circumstances. You will have to solve the equations. Each time you solve the equations, you will learn something about the character of the solutions. To keep these solutions in mind, it will be useful also to study their meaning in terms of field lines and of other concepts. This is the way you will really \u201cunderstand\u201d the equations. That is the difference between mathematics and physics. Mathematicians, or people who have very mathematical minds, are often led astray when \u201cstudying\u201d physics because they lose sight of the physics. They say: \u201cLook, these differential equations\u2014the Maxwell equations\u2014are all there is to electrodynamics; it is admitted by the physicists that there is nothing which is not contained in the equations. The equations are complicated, but after all they are only mathematical equations and if I understand them mathematically inside out, I will understand the physics inside out.\u201d Only it doesn\u2019t work that way. Mathematicians who study physics with that point of view\u2014and there have been many of them\u2014usually make little contribution to physics and, in fact, little to mathematics. They fail because the actual physical situations in the real world are so complicated that it is necessary to have a much broader understanding of the equations. What it means really to understand an equation\u2014that is, in more than a strictly mathematical sense\u2014was described by Dirac. He said: \u201cI understand what an equation means if I have a way of figuring out the characteristics of its solution without actually solving it.\u201d So if we have a way of knowing what should happen in given circumstances without actually solving the equations, then we \u201cunderstand\u201d the equations, as applied to these circumstances. A physical understanding is a completely unmathematical, imprecise, and inexact thing, but absolutely necessary for a physicist. Ordinarily, a course like this is given by developing gradually the physical ideas\u2014by starting with simple situations and going on to more and more complicated situations. This requires that you continuously forget things you previously learned\u2014things that are true in certain situations, but which are not true in general. For example, the \u201claw\u201d that the electrical force depends on the square of the distance is not always true. We prefer the opposite approach. We prefer to take first the complete laws, and then to step back and apply them to simple situations, developing the physical ideas as we go along. And that is what we are going to do. Our approach is completely opposite to the historical approach in which one develops the subject in terms of the experiments by which the information was obtained. But the subject of physics has been developed over the past 200 years by some very ingenious people, and as we have only a limited time to acquire our knowledge, we cannot possibly cover everything they did. Unfortunately one of the things that we shall have a tendency to lose in these lectures is the historical, experimental development. It is hoped that in the laboratory some of this lack can be corrected. You can also fill in what we must leave out by reading the Encyclopedia Britannica, which has excellent historical articles on electricity and on other parts of physics. You will also find historical information in many textbooks on electricity and magnetism. We begin now with the abstract, mathematical view of the theory of electricity and magnetism. The ultimate idea is to explain the meaning of the laws given in Chapter 1. But to do this we must first explain a new and peculiar notation that we want to use. So let us forget electromagnetism for the moment and discuss the mathematics of vector fields. It is of very great importance, not only for electromagnetism, but for all kinds of physical circumstances. Just as ordinary differential and integral calculus is so important to all branches of physics, so also is the differential calculus of vectors. We turn to that subject. Listed below are a few facts from the algebra of vectors. It is assumed that you already know them. A\u22c5B=scalar=AxBx+AyBy+AzBz A\u00d7B=vector (A\u00d7B)z =Ax By \u2212Ay Bx (A\u00d7B)x =Ay Bz \u2212Az By (A\u00d7B)y =Az Bx \u2212Ax Bz A\u00d7A=0 A\u22c5(A\u00d7B)=0 A\u22c5(B\u00d7C)=(A\u00d7B)\u22c5C A\u00d7(B\u00d7C)=B(A\u22c5C)\u2212C(A\u22c5B) Also we will want to use the two following equalities from the calculus: \u0394f(x,y,z)= \u2202f \u2202x \u0394x+ \u2202f \u2202y \u0394y+ \u2202f \u2202z \u0394z, \u2202 2 f \u2202x\u2202y = \u2202 2 f \u2202y\u2202x . (2.7) (2.8) The first equation (2.7) is, of course, true only in the limit that \u0394x , \u0394y , and \u0394z go toward zero. The simplest possible physical field is a scalar field. By a field, you remember, we mean a quantity which depends upon position in space. By a scalar field we merely mean a field which is characterized at each point by a single number\u2014a scalar. Of course the number may change in time, but we need not worry about that for the moment. We will talk about what the field looks like at a given instant. As an example of a scalar field, consider a solid block of material which has been heated at some places and cooled at others, so that the temperature of the body varies from point to point in a complicated way. Then the temperature will be a function of x , y , and z , the position in space measured in a rectangular coordinate system. Temperature is a scalar field. One way of thinking about scalar fields is to imagine \u201ccontours\u201d which are imaginary surfaces drawn through all points for which the field has the same value, just as contour lines on a map connect points with the same height. For a temperature field the contours are called \u201cisothermal surfaces\u201d or isotherms. Figure 2\u20131 illustrates a temperature field and shows the dependence of T on x and y when z=0 . Several isotherms are drawn. There are also vector fields. The idea is very simple. A vector is given for each point in space. The vector varies from point to point. As an example, consider a rotating body. The velocity of the material of the body at any point is a vector which is a function of position (Fig. 2\u20132). As a second example, consider the flow of heat in a block of material. If the temperature in the block is high at one place and low at another, there will be a flow of heat from the hotter places to the colder. The heat will be flowing in different directions in different parts of the block. The heat flow is a directional quantity which we call h . Its magnitude is a measure of how much heat is flowing. Examples of the heat flow vector are also shown in Fig. 2\u20131. Let\u2019s make a more precise definition of h : The magnitude of the vector heat flow at a point is the amount of thermal energy that passes, per unit time and per unit area, through an infinitesimal surface element at right angles to the direction of flow. The vector points in the direction of flow (see Fig. 2\u20133). In symbols: If \u0394J is the thermal energy that passes per unit time through the surface element \u0394a , then h= \u0394J \u0394a e f , (2.9) where e f is a unit vector in the direction of flow. The vector h can be defined in another way\u2014in terms of its components. We ask how much heat flows through a small surface at any angle with respect to the flow. In Fig. 2\u20134 we show a small surface \u0394 a 2 inclined with respect to \u0394 a 1 , which is perpendicular to the flow. The unit vector n is normal to the surface \u0394 a 2 . The angle \u03b8 between n and h is the same as the angle between the surfaces (since h is normal to \u0394 a 1 ). Now what is the heat flow per unit area through \u0394 a 2 ? The flow through \u0394 a 2 is the same as through \u0394 a 1 ; only the areas are different. In fact, \u0394 a 1 =\u0394 a 2 cos\u03b8 . The heat flow through \u0394 a 2 is \u0394J \u0394 a 2 = \u0394J \u0394 a 1 cos\u03b8=h\u22c5n. (2.10) We interpret this equation: the heat flow (per unit time and per unit area) through any surface element whose unit normal is n , is given by h\u22c5n . Equally, we could say: the component of the heat flow perpendicular to the surface element \u0394 a 2 is h\u22c5n . We can, if we wish, consider that these statements define h . We will be applying the same ideas to other vector fields. When fields vary in time, we can describe the variation by giving their derivatives with respect to t . We want to describe the variations with position in a similar way, because we are interested in the relationship between, say, the temperature in one place and the temperature at a nearby place. How shall we take the derivative of the temperature with respect to position? Do we differentiate the temperature with respect to x ? Or with respect to y , or z ? Useful physical laws do not depend upon the orientation of the coordinate system. They should, therefore, be written in a form in which either both sides are scalars or both sides are vectors. What is the derivative of a scalar field, say \u2202T/\u2202x ? Is it a scalar, or a vector, or what? It is neither a scalar nor a vector, as you can easily appreciate, because if we took a different x -axis, \u2202T/\u2202x would certainly be different. But notice: We have three possible derivatives: \u2202T/\u2202x , \u2202T/\u2202y , and \u2202T/\u2202z . Since there are three kinds of derivatives and we know that it takes three numbers to form a vector, perhaps these three derivatives are the components of a vector: ( \u2202T \u2202x , \u2202T \u2202y , \u2202T \u2202z ) = ? a vector. (2.11) Of course it is not generally true that any three numbers form a vector. It is true only if, when we rotate the coordinate system, the components of the vector transform among themselves in the correct way. So it is necessary to analyze how these derivatives are changed by a rotation of the coordinate system. We shall show that (2.11) is indeed a vector. The derivatives do transform in the correct way when the coordinate system is rotated. We can see this in several ways. One way is to ask a question whose answer is independent of the coordinate system, and try to express the answer in an \u201cinvariant\u201d form. For instance, if S=A\u22c5B , and if A and B are vectors, we know\u2014because we proved it in Chapter 11 of Vol. I\u2014that S is a scalar. We know that S is a scalar without investigating whether it changes with changes in coordinate systems. It can\u2019t, because it\u2019s a dot product of two vectors. Similarly, if we have three numbers B 1 , B 2 , and B 3 and we find out that for every vector A A x B 1 + A y B 2 + A z B 3 =S, (2.12) where S is the same for any coordinate system, then it must be that the three numbers B 1 , B 2 , B 3 are the components B x , B y , B z of some vector B . Now let\u2019s think of the temperature field. Suppose we take two points P 1 and P 2 , separated by the small interval \u0394R . The temperature at P 1 is T 1 and at P 2 is T 2 , and the difference \u0394T= T 2 \u2212 T 1 . The temperatures at these real, physical points certainly do not depend on what axis we choose for measuring the coordinates. In particular, \u0394T is a number independent of the coordinate system. It is a scalar. If we choose some convenient set of axes, we could write T 1 =T(x,y,z) and T 2 =T(x+\u0394x,y+\u0394y,z+\u0394z) , where \u0394x , \u0394y , and \u0394z are the components of the vector \u0394R (Fig. 2\u20135). Remembering Eq. (2.7), we can write \u0394T= \u2202T \u2202x \u0394x+ \u2202T \u2202y \u0394y+ \u2202T \u2202z \u0394z. (2.13) The left side of Eq. (2.13) is a scalar. The right side is the sum of three products with \u0394x , \u0394y , and \u0394z , which are the components of a vector. It follows that the three numbers \u2202T \u2202x , \u2202T \u2202y , \u2202T \u2202z \u2202 T \u2202 T \u2202 T are also the x -, y -, and z -components of a vector. We write this new vector with the symbol \u2207T . The symbol \u2207 (called \u201cdel\u201d) is an upside-down \u0394 , and is supposed to remind us of differentiation. People read \u2207T in various ways: \u201cdel- T ,\u201d or \u201cgradient of T ,\u201d or \u201c grad T ;\u201d1 grad T=\u2207T=( \u2202T \u2202x , \u2202T \u2202y , \u2202T \u2202z ). (2.14) Using this notation, we can rewrite Eq. (2.13) in the more compact form \u0394T=\u2207T\u22c5\u0394R. (2.15) In words, this equation says that the difference in temperature between two nearby points is the dot product of the gradient of T and the vector displacement between the points. The form of Eq. (2.15) also illustrates clearly our proof above that \u2207T is indeed a vector. Perhaps you are still not convinced? Let\u2019s prove it in a different way. (Although if you look carefully, you may be able to see that it\u2019s really the same proof in a longer-winded form!) We shall show that the components of \u2207T transform in just the same way that components of R do. If they do, \u2207T is a vector according to our original definition of a vector in Chapter 11 of Vol. I. We take a new coordinate system x \u2032 , y \u2032 , z \u2032 , and in this new system we calculate \u2202T/\u2202 x \u2032 , \u2202T/\u2202 y \u2032 , and \u2202T/\u2202 z \u2032 . To make things a little simpler, we let z= z \u2032 , so that we can forget about the z -coordinate. (You can check out the more general case for yourself.) We take an x \u2032 y \u2032 -system rotated an angle \u03b8 with respect to the xy -system, as in Fig. 2\u20136(a). For a point (x,y) the coordinates in the prime system are x \u2032 y \u2032 =xcos\u03b8 =\u2212xsin\u03b8 +ysin\u03b8, +ycos\u03b8. (2.16) (2.17) Or, solving for x and y , x y = x \u2032 cos\u03b8 = x \u2032 sin\u03b8 \u2212 y \u2032 sin\u03b8, + y \u2032 cos\u03b8. (2.18) (2.19) If any pair of numbers transforms with these equations in the same way that x and y do, they are the components of a vector. Now let\u2019s look at the difference in temperature between the two nearby points P 1 and P 2 , chosen as in Fig. 2\u20136(b). If we calculate with the x - and y -coordinates, we would write \u0394T= \u2202T \u2202x \u0394x (2.20) \u2014since \u0394y is zero. What would a computation in the prime system give? We would have written \u0394T= \u2202T \u2202 x \u2032 \u0394 x \u2032 + \u2202T \u2202 y \u2032 \u0394 y \u2032 . (2.21) Looking at Fig. 2\u20136(b), we see that \u0394 x \u2032 =\u0394xcos\u03b8 (2.22) and \u0394 y \u2032 =\u2212\u0394xsin\u03b8, (2.23) since \u0394 y \u2032 is negative when \u0394x is positive. Substituting these in Eq. (2.21), we find that \u0394T = \u2202T \u2202 x \u2032 \u0394xcos\u03b8\u2212 \u2202T \u2202 y \u2032 \u0394xsin\u03b8 =( \u2202T \u2202 x \u2032 cos\u03b8\u2212 \u2202T \u2202 y \u2032 sin\u03b8)\u0394x. (2.24) (2.25) Comparing Eq. (2.25) with (2.20), we see that \u2202T \u2202x = \u2202T \u2202 x \u2032 cos\u03b8\u2212 \u2202T \u2202 y \u2032 sin\u03b8. (2.26) This equation says that \u2202T/\u2202x is obtained from \u2202T/\u2202 x \u2032 and \u2202T/\u2202 y \u2032 , just as x is obtained from x \u2032 and y \u2032 in Eq. (2.18). So \u2202T/\u2202x is the x -component of a vector. The same kind of arguments would show that \u2202T/\u2202y and \u2202T/\u2202z are y - and z -components. So \u2207T is definitely a vector. It is a vector field derived from the scalar field T . Now we can do something that is extremely amusing and ingenious\u2014and characteristic of the things that make mathematics beautiful. The argument that grad T , or \u2207T , is a vector did not depend upon what scalar field we were differentiating. All the arguments would go the same if T were replaced by any scalar field. Since the transformation equations are the same no matter what we differentiate, we could just as well omit the T and replace Eq. (2.26) by the operator equation \u2202 \u2202x = \u2202 \u2202 x \u2032 cos\u03b8\u2212 \u2202 \u2202 y \u2032 sin\u03b8. (2.27) We leave the operators, as Jeans said, \u201chungry for something to differentiate.\u201d Since the differential operators themselves transform as the components of a vector should, we can call them components of a vector operator. We can write \u2207=( \u2202 \u2202x , \u2202 \u2202y , \u2202 \u2202z ), (2.28) which means, of course, \u2207 x = \u2202 \u2202x , \u2207 y = \u2202 \u2202y , \u2207 z = \u2202 \u2202z . (2.29) We have abstracted the gradient away from the T \u2014that is the wonderful idea. You must always remember, of course, that \u2207 is an operator. Alone, it means nothing. If \u2207 by itself means nothing, what does it mean if we multiply it by a scalar\u2014say T \u2014to get the product T\u2207 ? (One can always multiply a vector by a scalar.) It still does not mean anything. Its x -component is T \u2202 \u2202x , (2.30) which is not a number, but is still some kind of operator. However, according to the algebra of vectors we would still call T\u2207 a vector. Now let\u2019s multiply \u2207 by a scalar on the other side, so that we have the product (\u2207T) . In ordinary algebra TA=AT, (2.31) but we have to remember that operator algebra is a little different from ordinary vector algebra. With operators we must always keep the sequence right, so that the operations make proper sense. You will have no difficulty if you just remember that the operator \u2207 obeys the same convention as the derivative notation. What is to be differentiated must be placed on the right of the \u2207 . The order is important. Keeping in mind this problem of order, we understand that T\u2207 is an operator, but the product \u2207T is no longer a hungry operator; the operator is completely satisfied. It is indeed a physical vector having a meaning. It represents the spatial rate of change of T . The x -component of \u2207T is how fast T changes in the x -direction. What is the direction of the vector \u2207T ? We know that the rate of change of T in any direction is the component of \u2207T in that direction (see Eq. (2.15)). It follows that the direction of \u2207T is that in which it has the largest possible component\u2014in other words, the direction in which T changes the fastest. The gradient of T has the direction of the steepest uphill slope (in T ). Can we do any other algebra with the vector operator \u2207 ? Let us try combining it with a vector. We can combine two vectors by making a dot product. We could make the products (a vector)\u22c5\u2207,or\u2207\u22c5(a vector). ( ) \u2207 \u2207 ( ) The first one doesn\u2019t mean anything yet, because it is still an operator. What it might ultimately mean would depend on what it is made to operate on. The second product is some scalar field. ( A\u22c5B is always a scalar.) Let\u2019s try the dot product of \u2207 with a vector field we know, say h . We write out the components: \u2207\u22c5h= \u2207 x h x + \u2207 y h y + \u2207 z h z (2.32) or \u2207\u22c5h= \u2202 h x \u2202x + \u2202 h y \u2202y + \u2202 h z \u2202z . (2.33) The sum is invariant under a coordinate transformation. If we were to choose a different system (indicated by primes), we would have2 \u2207 \u2032 \u22c5h= \u2202 h x \u2032 \u2202 x \u2032 + \u2202 h y \u2032 \u2202 y \u2032 + \u2202 h z \u2032 \u2202 z \u2032 , (2.34) which is the same number as would be gotten from Eq. (2.33), even though it looks different. That is, \u2207 \u2032 \u22c5h=\u2207\u22c5h (2.35) for every point in space. So \u2207\u22c5h is a scalar field, which must represent some physical quantity. You should realize that the combination of derivatives in \u2207\u22c5h is rather special. There are all sorts of other combinations like \u2202 h y /\u2202x , which are neither scalars nor components of vectors. The scalar quantity \u2207\u22c5(a vector) is extremely useful in physics. It has been given the name the divergence. For example, \u2207\u22c5h=div h=\u201cdivergence of h.\u201d (2.36) As we did for \u2207T , we can ascribe a physical significance to \u2207\u22c5h . We shall, however, postpone that until later. First, we wish to see what else we can cook up with the vector operator \u2207 . What about a cross product? We must expect that \u2207\u00d7h=a vector. (2.37) It is a vector whose components we can write by the usual rule for cross products (see Eq. (2.2)): (\u2207\u00d7h ) z = \u2207 x h y \u2212 \u2207 y h x = \u2202 h y \u2202x \u2212 \u2202 h x \u2202y . (2.38) Similarly, (\u2207\u00d7h ) x = \u2207 y h z \u2212 \u2207 z h y = \u2202 h z \u2202y \u2212 \u2202 h y \u2202z (2.39) and (\u2207\u00d7h ) y = \u2207 z h x \u2212 \u2207 x h z = \u2202 h x \u2202z \u2212 \u2202 h z \u2202x . (2.40) The combination \u2207\u00d7h is called \u201cthe curl of h .\u201d The reason for the name and the physical meaning of the combination will be discussed later. Summarizing, we have three kinds of combinations with \u2207 : \u2207T \u2207\u22c5h \u2207\u00d7h =grad T =div h =curl h =a vector, =a scalar, =a vector. Using these combinations, we can write about the spatial variations of fields in a convenient way\u2014in a way that is general, in that it doesn\u2019t depend on any particular set of axes. As an example of the use of our vector differential operator \u2207 , we write a set of vector equations which contain the same laws of electromagnetism that we gave in words in Chapter 1. They are called Maxwell\u2019s equations. Maxwell\u2019s Equations (1) (2) (3) (4) \u2207\u22c5E \u2207\u00d7E \u2207\u22c5B c 2 \u2207\u00d7B = \u03c1 \u03f5 0 =\u2212 \u2202B \u2202t =0 = \u2202E \u2202t + j \u03f5 0 (2.41) where \u03c1 (rho), the \u201celectric charge density,\u201d is the amount of charge per unit volume, and j , the \u201celectric current density,\u201d is the rate at which charge flows through a unit area per second. These four equations contain the complete classical theory of the electromagnetic field. You see what an elegantly simple form we can get with our new notation! Let us give another example of a law of physics written in vector notation. The law is not a precise one, but for many metals and a number of other substances that conduct heat it is quite accurate. You know that if you take a slab of material and heat one face to temperature T 2 and cool the other to a different temperature T 1 the heat will flow through the material from T 2 to T 1 [Fig. 2\u20137(a)]. The heat flow is proportional to the area A of the faces, and to the temperature difference. It is also inversely proportional to d , the distance between the plates. (For a given temperature difference, the thinner the slab the greater the heat flow.) Letting J be the thermal energy that passes per unit time through the slab, we write J=\u03ba( T 2 \u2212 T 1 ) A d . (2.42) The constant of proportionality \u03ba (kappa) is called the thermal conductivity. What will happen in a more complicated case? Say in an odd-shaped block of material in which the temperature varies in peculiar ways? Suppose we look at a tiny piece of the block and imagine a slab like that of Fig. 2\u20137(a) on a miniature scale. We orient the faces parallel to the isothermal surfaces, as in Fig. 2\u20137(b), so that Eq. (2.42) is correct for the small slab. If the area of the small slab is \u0394A , the heat flow per unit time is \u0394J=\u03ba\u0394T \u0394A \u0394s , (2.43) where \u0394s is the thickness of the slab. Now \u0394J/\u0394A we have defined earlier as the magnitude of h , whose direction is the heat flow. The heat flow will be from T 1 +\u0394T toward T 1 and so it will be perpendicular to the isotherms, as drawn in Fig. 2\u20137(b). Also, \u0394T/\u0394s is just the rate of change of T with position. And since the position change is perpendicular to the isotherms, our \u0394T/\u0394s is the maximum rate of change. It is, therefore, just the magnitude of \u2207T . Now since the direction of \u2207T is opposite to that of h , we can write (2.43) as a vector equation: h=\u2212\u03ba\u2207T. (2.44) (The minus sign is necessary because heat flows \u201cdownhill\u201d in temperature.) Equation (2.44) is the differential equation of heat conduction in bulk materials. You see that it is a proper vector equation. Each side is a vector if \u03ba is just a number. It is the generalization to arbitrary cases of the special relation (2.42) for rectangular slabs. Later we should learn to write all sorts of elementary physics relations like (2.42) in the more sophisticated vector notation. This notation is useful not only because it makes the equations look simpler. It also shows most clearly the physical content of the equations without reference to any arbitrarily chosen coordinate system. So far we have had only first derivatives. Why not second derivatives? We could have several combinations: (a) (b) (c) (d) (e) \u2207\u22c5(\u2207T) \u2207\u00d7(\u2207T) \u2207(\u2207\u22c5h) \u2207\u22c5(\u2207\u00d7h) \u2207\u00d7(\u2207\u00d7h) (2.45) You can check that these are all the possible combinations. Let\u2019s look first at the second one, (b). It has the same form as A\u00d7(AT)=(A\u00d7A)T=0, ( ) ( ) since A\u00d7A is always zero. So we should have curl (grad T)=\u2207\u00d7(\u2207T)=0. (2.46) We can see how this equation comes about if we go through once with the components: [\u2207\u00d7(\u2207T) ] z = \u2207 x (\u2207T ) y \u2212 \u2207 y (\u2207T ) x = \u2202 \u2202x ( \u2202T \u2202y )\u2212 \u2202 \u2202y ( \u2202T \u2202x ), (2.47) which is zero (by Eq. (2.8)). It goes the same for the other components. So \u2207\u00d7(\u2207T)=0 , for any temperature distribution\u2014in fact, for any scalar function. Now let us take another example. Let us see whether we can find another zero. The dot product of a vector with a cross product which contains that vector is zero: A\u22c5(A\u00d7B)=0, (2.48) because A\u00d7B is perpendicular to A , and so has no components in the direction A . The same combination appears in (d) of (2.45), so we have \u2207\u22c5(\u2207\u00d7h)=div (curl h)=0. (2.49) Again, it is easy to show that it is zero by carrying through the operations with components. Now we are going to state two mathematical theorems that we will not prove. They are very interesting and useful theorems for physicists to know. In a physical problem we frequently find that the curl of some quantity\u2014say of the vector field A \u2014is zero. Now we have seen (Eq. (2.46)) that the curl of a gradient is zero, which is easy to remember because of the way the vectors work. It could certainly be, then, that A is the gradient of some quantity, because then its curl would necessarily be zero. The interesting theorem is that if the curl A is zero, then A is always the gradient of something\u2014there is some scalar field \u03c8 (psi) such that A is equal to grad \u03c8 . In other words, we have the Theorem: If there is a such that \u2207\u00d7A \u03c8 A=\u2207\u03c8 =0 . (2.50) There is a similar theorem if the divergence of A is zero. We have seen in Eq. (2.49) that the divergence of a curl of something is always zero. If you come across a vector field D for which div D is zero, then you can conclude that D is the curl of some vector field C . Theorem: If there is a such that \u2207\u22c5D C D=\u2207 =0 \u00d7C. (2.51) In looking at the possible combinations of two \u2207 operators, we have found that two of them always give zero. Now we look at the ones that are not zero. Take the combination \u2207\u22c5(\u2207T) , which was first on our list. It is not, in general, zero. We write out the components: \u2207T=i \u2207 x T+j \u2207 y T+k \u2207 z T. \u2207 T i \u2207 T j \u2207 T k \u2207 T Then \u2207\u22c5(\u2207T) = \u2207 x ( \u2207 x T)+ \u2207 y ( \u2207 y T)+ \u2207 z ( \u2207 z T) = \u2202 2 T \u2202 x 2 + \u2202 2 T \u2202 y 2 + \u2202 2 T \u2202 z 2 , (2.52) which would, in general, come out to be some number. It is a scalar field. You see that we do not need to keep the parentheses, but can write, without any chance of confusion, \u2207\u22c5(\u2207T)=\u2207\u22c5\u2207T=(\u2207\u22c5\u2207)T= \u2207 2 T. (2.53) We look at \u2207 2 as a new operator. It is a scalar operator. Because it appears often in physics, it has been given a special name\u2014the Laplacian. Laplacian= \u2207 2 = \u2202 2 \u2202 x 2 + \u2202 2 \u2202 y 2 + \u2202 2 \u2202 z 2 . (2.54) Since the Laplacian is a scalar operator, we may operate with it on a vector\u2014by which we mean the same operation on each component in rectangular coordinates: \u2207 2 h=( \u2207 2 h x , \u2207 2 h y , \u2207 2 h z ). 2 2 2 2 Let\u2019s look at one more possibility: \u2207\u00d7(\u2207\u00d7h) , which was (e) in the list (2.45). Now the curl of the curl can be written differently if we use the vector equality (2.6): A\u00d7(B\u00d7C)=B(A\u22c5C)\u2212C(A\u22c5B). (2.55) In order to use this formula, we should replace A and B by the operator \u2207 and put C=h . If we do that, we get \u2207\u00d7(\u2207\u00d7h)=\u2207(\u2207\u22c5h)\u2212h(\u2207\u22c5\u2207)\u2026??? \u2207 ( \u2207 h ) \u2207 ( \u2207 h ) h ( \u2207 \u2207 ) Wait a minute! Something is wrong. The first two terms are vectors all right (the operators are satisfied), but the last term doesn\u2019t come out to anything. It\u2019s still an operator. The trouble is that we haven\u2019t been careful enough about keeping the order of our terms straight. If you look again at Eq. (2.55), however, you see that we could equally well have written it as A\u00d7(B\u00d7C)=B(A\u22c5C)\u2212(A\u22c5B)C. (2.56) The order of terms looks better. Now let\u2019s make our substitution in (2.56). We get \u2207\u00d7(\u2207\u00d7h)=\u2207(\u2207\u22c5h)\u2212(\u2207\u22c5\u2207)h. (2.57) This form looks all right. It is, in fact, correct, as you can verify by computing the components. The last term is the Laplacian, so we can equally well write \u2207\u00d7(\u2207\u00d7h)=\u2207(\u2207\u22c5h)\u2212 \u2207 2 h. (2.58) We have had something to say about all of the combinations in our list of double \u2207 's, except for (c), \u2207(\u2207\u22c5h) . It is a possible vector field, but there is nothing special to say about it. It\u2019s just some vector field which may occasionally come up. It will be convenient to have a table of our conclusions: (a) (b) (c) (d) (e) (f) ( \u2207\u22c5(\u2207T)= \u2207 2 T=a scalar field \u2207\u00d7(\u2207T)=0 \u2207(\u2207\u22c5h)=a vector field \u2207\u22c5(\u2207\u00d7h)=0 \u2207\u00d7(\u2207\u00d7h)=\u2207(\u2207\u22c5h)\u2212 \u2207 2 h \u2207\u22c5\u2207)h= \u2207 2 h=a vector field (2.59) You may notice that we haven\u2019t tried to invent a new vector operator (\u2207\u00d7\u2207) . Do you see why? We have been applying our knowledge of ordinary vector algebra to the algebra of the operator \u2207 . We have to be careful, though, because it is possible to go astray. There are two pitfalls which we will mention, although they will not come up in this course. What would you say about the following expression, that involves the two scalar functions \u03c8 and \u03d5 (phi): (\u2207\u03c8)\u00d7(\u2207\u03d5)? ( \u2207 \u03c8 ) ( \u2207 \u03d5 ) You might want to say: it must be zero because it\u2019s just like (Aa)\u00d7(Ab), ( ) ( b ) which is zero because the cross product of two equal vectors A\u00d7A is always zero. But in our example the two operators \u2207 are not equal! The first one operates on one function, \u03c8 ; the other operates on a different function, \u03d5 . So although we represent them by the same symbol \u2207 , they must be considered as different operators. Clearly, the direction of \u2207\u03c8 depends on the function \u03c8 , so it is not likely to be parallel to \u2207\u03d5 : (\u2207\u03c8)\u00d7(\u2207\u03d5)\u22600(generally). ( \u2207 \u03c8 ) ( \u2207 \u03d5 ) \u2260 ( generally ) Fortunately, we won\u2019t have to use such expressions. (What we have said doesn\u2019t change the fact that \u2207\u00d7\u2207\u03c8=0 for any scalar field, because here both \u2207 \u2019s operate on the same function.) Pitfall number two (which, again, we need not get into in our course) is the following: The rules that we have outlined here are simple and nice when we use rectangular coordinates. For example, if we have \u2207 2 h and we want the x -component, it is ( \u2207 2 h ) x =( \u2202 2 \u2202 x 2 + \u2202 2 \u2202 y 2 + \u2202 2 \u2202 z 2 ) h x = \u2207 2 h x . (2.60) The same expression would not work if we were to ask for the radial component of \u2207 2 h . The radial component of \u2207 2 h is not equal to \u2207 2 h r . The reason is that when we are dealing with the algebra of vectors, the directions of the vectors are all quite definite. But when we are dealing with vector fields, their directions are different at different places. If we try to describe a vector field in, say, polar coordinates, what we call the \u201cradial\u201d direction varies from point to point. So we can get into a lot of trouble when we start to differentiate the components. For example, even for a constant vector field, the radial component changes from point to point. It is usually safest and simplest just to stick to rectangular coordinates and avoid trouble, but there is one exception worth mentioning: Since the Laplacian \u2207 2 , is a scalar, we can write it in any coordinate system we want to (for example, in polar coordinates). But since it is a differential operator, we should use it only on vectors whose components are in a fixed direction\u2014that means rectangular coordinates. So we shall express all of our vector fields in terms of their x -, y -, and z -components when we write our vector differential equations out in components."
    }
]