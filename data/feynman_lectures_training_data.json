[
    {
        "input": "Illustrations of Thermodynamics",
        "output": "Thermodynamics is a rather difficult and complex subject when we come to apply it, and it is not appropriate for us to go very far into the applications in this course. The subject is of very great importance, of course, to engineers and chemists, and those who are interested in the subject can learn about the applications in physical chemistry or in engineering thermodynamics. There are also good equation reference books, such as Zemansky\u2019s Heat and Thermodynamics, where one can learn more about the subject. In the Encyclopedia Britannica, fourteenth edition, one can find excellent articles on thermodynamics and thermochemistry, and in the article on chemistry, the sections on physical chemistry, vaporization, liquefication of gases, and so on. The subject of thermodynamics is complicated because there are so many different ways of describing the same thing. If we wish to describe the behavior of a gas, we can say that the pressure depends on the temperature and on the volume, or we can say that the volume depends on the temperature and the pressure. Or with respect to the internal energy U , we might say that it depends on the temperature and volume, if those are the variables we have chosen\u2014but we might also say that it depends on the temperature and the pressure, or the pressure and the volume, and so on. In the last chapter we discussed another function of temperature and volume, called the entropy S , and we can of course construct as many other functions of these variables as we like: U\u2212TS is a function of temperature and volume. So we have a large number of different quantities which can be functions of many different combinations of variables. To keep the subject simple in this chapter, we shall decide at the start to use temperature and volume as the independent variables. Chemists use temperature and pressure, because they are easier to measure and control in chemical experiments, but we shall use temperature and volume throughout this chapter, except in one place where we shall see how to make the transformation into the chemists\u2019 system of variables. We shall first, then, consider only one system of independent variables: temperature and volume. Secondly, we shall discuss only two dependent functions: the internal energy and the pressure. All the other functions can be derived from these, so it is not necessary to discuss them. With these limitations, thermodynamics is still a fairly difficult subject, but it is not quite so impossible! First we shall review some mathematics. If a quantity is a function of two variables, the idea of the derivative of the quantity requires a little more careful thought than for the case where there is only one variable. What do we mean by the derivative of the pressure with respect to the temperature? The pressure change accompanying a change in the temperature depends partly, of course, on what happens to the volume while T is changing. We must specify the change in V before the concept of a derivative with respect to T has a precise meaning. We might ask, for example, for the rate of change of P with respect to T if V is held constant. This ratio is just the ordinary derivative that we usually write as dP/dT . We customarily use a special symbol, \u2202P/\u2202T , to remind us that P depends on another variable V as well as on T , and that this other variable is held constant. We shall not only use the symbol \u2202 to call attention to the fact that the other variable is held constant, but we shall also write the variable that is held constant as a subscript, (\u2202P/\u2202T)V . Since we have only two independent variables, this notation is redundant, but it will help us keep our wits about us in the thermodynamic jungle of partial derivatives. Let us suppose that the function f(x,y) depends on the two independent variables x and y . By (\u2202f/\u2202x)y we mean simply the ordinary derivative, obtained in the usual way, if we treat y as a constant: ( \u2202f \u2202x )y= limit \u0394x\u21920 f(x+\u0394x,y)\u2212f(x,y) \u0394x . Similarly, we define ( \u2202f \u2202y )x= limit \u0394y\u21920 f(x,y+\u0394y)\u2212f(x,y) \u0394y . For example, if f(x,y)=x2+yx , then (\u2202f/\u2202x)y=2x+y , and (\u2202f/\u2202y)x=x . We can extend this idea to higher derivatives: \u22022f/\u2202y2 or \u22022f/\u2202y\u2202x . The latter symbol indicates that we first differentiate f with respect to x , treating y as a constant, then differentiate the result with respect to y , treating x as a constant. The actual order of differentiation is immaterial: \u22022f/\u2202x\u2202y=\u22022f/\u2202y\u2202x . We will need to compute the change \u0394f in f(x,y) when x changes to x+\u0394x and y changes to y+\u0394y . We assume throughout the following that \u0394x and \u0394y are infinitesimally small: \u0394f =f(x+\u0394x,y+\u0394y) =f(x+\u0394x,y+\u0394y) +f(x,y+\u0394y) =\u0394x( \u2202f \u2202x ) y +\u0394y( \u2202f \u2202y \u2212 \u2212 \u2212 ) x f(x,y) f(x,y+\u0394y) f(x,y) (45.1) The last equation is the fundamental relation that expresses \u0394f in terms of \u0394x and \u0394y . As an example of the use of this relation, let us calculate the change in the internal energy U(T,V) when the temperature changes from T to T+\u0394T and the volume changes from V to V+\u0394V . Using Eq. (45.1), we write \u0394U=\u0394T( \u2202U \u2202T ) V +\u0394V( \u2202U \u2202V ) T . (45.2) In our last chapter we found another expression for the change \u0394U in the internal energy when a quantity of heat \u0394Q was added to the gas: \u0394U=\u0394Q\u2212P\u0394V. (45.3) In comparing Eqs. (45.2) and (45.3) one might at first be inclined to think that P=\u2212(\u2202U/\u2202V ) T , but this is not correct. To obtain the correct relation, let us first suppose that we add a quantity of heat \u0394Q to the gas while keeping the volume constant, so that \u0394V=0 . With \u0394V=0 , Eq. (45.3) tells us that \u0394U=\u0394Q , and Eq. (45.2) tells us that \u0394U=(\u2202U/\u2202T ) V \u0394T , so that (\u2202U/\u2202T ) V =\u0394Q/\u0394T . The ratio \u0394Q/\u0394T , the amount of heat one must put into a substance in order to change its temperature by one degree with the volume held constant, is called the specific heat at constant volume and is designated by the symbol C V . By this argument we have shown that ( \u2202U \u2202T ) V = C V . (45.4) Now let us again add a quantity of heat \u0394Q to the gas, but this time we will hold T constant and allow the volume to change by \u0394V . The analysis in this case is more complex, but we can calculate \u0394U by the argument of Carnot, making use of the Carnot cycle we introduced in the last chapter. The pressure-volume diagram for the Carnot cycle is shown in Fig. 45\u20131. As we have already shown, the total amount of work done by the gas in a reversible cycle is \u0394Q(\u0394T/T) , where \u0394Q is the amount of heat energy added to the gas as it expands isothermally at temperature T from volume V to V+\u0394V , and T\u2212\u0394T is the final temperature reached by the gas as it expands adiabatically on the second leg of the cycle. Now we will show that this work done is also given by the shaded area in Fig. 45\u20131. In any circumstances, the work done by the gas is \u222bPdV , and is positive when the gas expands and negative when the gas is compressed. If we plot P vs. V , the variation of P and V is represented by a curve which gives the value of P corresponding to a particular value of V . As the volume changes from one value to another, the work done by the gas, the integral \u222bPdV , is the area under the curve connecting the initial and final values of V . When we apply this idea to the Carnot cycle, we see that as we go around the cycle, paying attention to the sign of the work done by the gas, the net work done by the gas is just the shaded area in Fig. 45\u20131. Now we want to evaluate the shaded area geometrically. The cycle we have used in Fig. 45\u20131 differs from that used in the previous chapter in that we now suppose that \u0394T and \u0394Q are infinitesimally small. We are working between adiabatic lines and isothermal lines that are very close together, and the figure described by the heavy lines in Fig. 45\u20131 will approach a parallelogram as the increments \u0394T and \u0394Q approach zero. The area of this parallelogram is just \u0394V\u0394P , where \u0394V is the change in volume as energy \u0394Q is added to the gas at constant temperature, and \u0394P is the change in pressure as the temperature changes by \u0394T at constant volume. One can easily show that the shaded area in Fig. 45\u20131 is given by \u0394V\u0394P by recognizing that the shaded area is equal to the area enclosed by the dotted lines in Fig. 45\u20132, which in turn differs from the rectangle bounded by \u0394P and \u0394V only by the addition and subtraction of the equal triangular areas in Fig. 45\u20132. Now let us summarize the results of the arguments we have developed so far: Work done by the gas=shaded area =\u0394V\u0394P=\u0394Q( \u0394T T ) or \u0394T T \u22c5 \u239b \u239d heat needed to change V by \u0394V \u239e \u23a0 constant T =\u0394V\u22c5 \u239b \u239d change in P when T changes by \u0394T \u239e \u23a0 constant V or 1 \u0394V \u22c5 \u239b \u239d heat needed to change V by \u0394V \u239e \u23a0 T =T( \u2202P \u2202T ) V . \u23ab \u23ad \u23ac \u23aa \u23aa \u23aa \u23aa \u23aa \u23aa \u23aa \u23aa \u23aa \u23aa \u23aa \u23aa \u23aa \u23aa \u23aa \u23aa \u23aa \u23aa \u23aa \u23aa \u23aa \u23aa \u23aa \u23aa \u23aa \u23aa \u23aa \u23aa \u23aa \u23aa \u23aa \u23aa \u23aa \u23aa \u23aa \u23aa \u23aa \u23aa \u23aa \u23aa \u23aa \u23aa \u23aa \u23aa \u23aa \u23aa \u23aa \u23aa \u23aa \u23aa \u23aa \u23aa \u23aa \u23aa \u23aa \u23aa \u23aa \u23aa \u23aa \u23aa (45.5) Equation (45.5) expresses the essential result of Carnot\u2019s argument. The whole of thermodynamics can be deduced from Eq. (45.5) and the First Law, which is stated in Eq. (45.3). Equation (45.5) is essentially the Second Law, although it was originally deduced by Carnot in a slightly different form, since he did not use our definition of temperature. Now we can proceed to calculate (\u2202U/\u2202V ) T . By how much would the internal energy U change if we changed the volume by \u0394V ? First, U changes because heat is put in, and second, U changes because work is done. The heat put in is \u0394Q=T( \u2202P \u2202T ) V \u0394V, \u2202 P according to Eq. (45.5), and the work done on the substance is \u2212P\u0394V . Therefore the change \u0394U in internal energy has two pieces: \u0394U=T( \u2202P \u2202T ) V \u0394V\u2212P\u0394V. (45.6) Dividing both sides by \u0394V , we find for the rate of change of U with V at constant T ( \u2202U \u2202V ) T =T( \u2202P \u2202T ) V \u2212P. (45.7) In our thermodynamics, in which T and V are the only variables and P and U are the only functions, Eqs. (45.3) and (45.7) are the basic equations from which all the results of the subject can be deduced. Now let us discuss the meaning of Eq. (45.7) and see why it answers the questions which we proposed in our last chapter. We considered the following problem: in kinetic theory it is obvious that an increase in temperature leads to an increase in pressure, because of the bombardments of the atoms on a piston. For the same physical reason, when we let the piston move back, heat is taken out of the gas and, in order to keep the temperature constant, heat will have to be put back in. The gas cools when it expands, and the pressure rises when it is heated. There must be some connection between these two phenomena, and this connection is given explicitly in Eq. (45.7). If we hold the volume fixed and increase the temperature, the pressure rises at a rate (\u2202P/\u2202T ) V . Related to that fact is this: if we increase the volume, the gas will cool unless we pour some heat in to maintain the temperature constant, and (\u2202U/\u2202V ) T tells us the amount of heat needed to maintain the temperature. Equation (45.7) expresses the fundamental interrelationship between these two effects. That is what we promised we would find when we came to the laws of thermodynamics. Without knowing the internal mechanism of the gas, and knowing only that we cannot make perpetual motion of the second type, we can deduce the relationship between the amount of heat needed to maintain a constant temperature when the gas expands, and the pressure change when the gas is heated at constant volume! Now that we have the result we wanted for a gas, let us consider the rubber band. When we stretch a rubber band, we find that its temperature rises, and when we heat a rubber band, we find that it pulls itself in. What is the equation that gives the same relation for a rubber band as Eq. (45.3) gives for gas? For a rubber band the situation will be something like this: when heat \u0394Q is put in, the internal energy is changed by \u0394U and some work is done. The only difference will be that the work done by the rubber band is \u2212F\u0394L instead of P\u0394V , where F is the force on the band, and L is the length of the band. The force F is a function of temperature and of length of the band. Replacing P\u0394V in Eq. (45.3) by \u2212F\u0394L , we get \u0394U=\u0394Q+F\u0394L. (45.8) Comparing Eqs. (45.3) and (45.8), we see that the rubber band equation is obtained by a mere substitution of one letter for another. Furthermore, if we substitute L for V , and \u2212F for P , all of our discussion of the Carnot cycle applies to the rubber band. We can immediately deduce, for instance, that the heat \u0394Q needed to change the length by \u0394L is given by the analog to Eq. (45.5): \u0394Q=\u2212T(\u2202F/\u2202T ) L \u0394L . This equation tells us that if we keep the length of a rubber band fixed and heat the band, we can calculate how much the force will increase in terms of the heat needed to keep the temperature constant when the band is relaxed a little bit. So we see that the same equation applies to both gas and a rubber band. In fact, if one can write \u0394U=\u0394Q+A\u0394B , where A and B represent different quantities, force and length, pressure and volume, etc., one can apply the results obtained for a gas by substituting A and B for \u2212P and V . For example, consider the electric potential difference, or \u201cvoltage,\u201d E in a battery and the charge \u0394Z that moves through the battery. We know that the work done in a reversible electric cell, like a storage battery, is E\u0394Z . (Since we include no P\u0394V term in the work, we require that our battery maintain a constant volume.) Let us see what thermodynamics can tell us about the performance of a battery. If we substitute E for P and Z for V in Eq. (45.6), we obtain \u0394U \u0394Z =T( \u2202E \u2202T ) Z \u2212E. (45.9) Equation (45.9) says that the internal energy U is changed when a charge \u0394Z moves through the cell. Why is \u0394U/\u0394Z not simply the voltage E of the battery? (The answer is that a real battery gets warm when charge moves through the cell. The internal energy of the battery is changed, first, because the battery did some work on the outside circuit, and second, because the battery is heated.) The remarkable thing is that the second part can again be expressed in terms of the way in which the battery voltage changes with temperature. Incidentally, when the charge moves through the cell, chemical reactions occur, and Eq. (45.9) suggests a nifty way of measuring the amount of energy required to produce a chemical reaction. All we need to do is construct a cell that works on the reaction, measure the voltage, and measure how much the voltage changes with temperature when we draw no charge from the battery! Now we have assumed that the volume of the battery can be maintained constant, since we have omitted the P\u0394V term when we set the work done by the battery equal to E\u0394Z . It turns out that it is technically quite difficult to keep the volume constant. It is much easier to keep the cell at constant atmospheric pressure. For that reason, the chemists do not like any of the equations we have written above: they prefer equations which describe performance under constant pressure. We chose at the beginning of this chapter to use V and T as independent variables. The chemists prefer P and T , and we will now consider how the results we have obtained so far can be transformed into the chemists\u2019 system of variables. Remember that in the following treatment confusion can easily set in because we are shifting gears from T and V to T and P . We started in Eq. (45.3) with \u0394U=\u0394Q\u2212P\u0394V ; P\u0394V may be replaced by E\u0394Z or A\u0394B . If we could somehow replace the last term, P\u0394V , by V\u0394P , then we would have interchanged V and P , and the chemists would be happy. Well, a clever man noticed that the differential of the product PV is d(PV)=PdV+VdP , and if he added this equality to Eq. (45.3), he obtained \u0394(PV) \u0394U \u0394(U+PV) =P\u0394V =\u0394Q =\u0394Q +V\u0394P \u2212P\u0394V +V\u0394P In order that the result look like Eq. (45.3), we define U+PV to be something new, called the enthalpy, H , and we write \u0394H=\u0394Q+V\u0394P . Now we are ready to transform our results into chemists\u2019 language with the following rules: U\u2192H , P\u2192\u2212V , V\u2192P . For example, the fundamental relationship that chemists would use instead of Eq. (45.7) is ( \u2202H \u2202P ) T =\u2212T( \u2202V \u2202T ) P +V. \u2202 H \u2202 V It should now be clear how one transforms to the chemists\u2019 variables T and P . We now go back to our original variables: for the remainder of this chapter, T and V are the independent variables. Now let us apply the results we have obtained to a number of physical situations. Consider first the ideal gas. From kinetic theory we know that the internal energy of a gas depends only on the motion of the molecules and the number of molecules. The internal energy depends on T , but not on V . If we change V , but keep T constant, U is not changed. Therefore (\u2202U/\u2202V ) T =0 , and Eq. (45.7) tells us that for an ideal gas T( \u2202P \u2202T ) V \u2212P=0. (45.10) Equation (45.10) is a differential equation that can tell us something about P . We take account of the partial derivatives in the following way: Since the partial derivative is at constant V , we will replace the partial derivative by an ordinary derivative and write explicitly, to remind us, \u201cconstant V .\u201d Equation (45.10) then becomes T \u0394P \u0394T \u2212P=0;const V, (45.11) which we can integrate to get lnP P =lnT+const; =const\u00d7T; const V, const V. (45.12) We know that for an ideal gas the pressure per mole is equal to P= RT V , (45.13) which is consistent with (45.12), since V and R are constants. Why did we bother to go through this calculation if we already knew the results? Because we have been using two independent definitions of temperature! At one stage we assumed that the kinetic energy of the molecules was proportional to the temperature, an assumption that defines one scale of temperature which we will call the ideal gas scale. The T in Eq. (45.13) is based on the gas scale. We also call temperatures measured on the gas scale kinetic temperatures. Later, we defined the temperature in a second way which was completely independent of any substance. From arguments based on the Second Law we defined what we might call the \u201cgrand thermodynamic absolute temperature\u201d T , the T that appears in Eq. (45.12). What we proved here is that the pressure of an ideal gas (defined as one for which the internal energy does not depend on the volume) is proportional to the grand thermodynamic absolute temperature. We also know that the pressure is proportional to the temperature measured on the gas scale. Therefore we can deduce that the kinetic temperature is proportional to the \u201cgrand thermodynamic absolute temperature.\u201d That means, of course, that if we were sensible we could make two scales agree. In this instance, at least, the two scales have been chosen so that they coincide; the proportionality constant has been chosen to be 1 . Most of the time man chooses trouble for himself, but in this case he made them equal! The vaporization of a liquid is another application of the results we have derived. Suppose we have some liquid in a cylinder, such that we can compress it by pushing on the piston, and we ask ourselves, \u201cIf we keep the temperature constant, how does the pressure vary with volume?\u201d In other words, we want to draw an isothermal line on the P - V diagram. The substance in the cylinder is not the ideal gas that we considered earlier; now it may be in the liquid or the vapor phase, or both may be present. If we apply sufficient pressure, the substance will condense to a liquid. Now if we squeeze still harder, the volume changes very little, and our isothermal line rises rapidly with decreasing volume, as shown at the left in Fig. 45\u20133. If we increase the volume by pulling the piston out, the pressure drops until we reach the point at which the liquid starts to boil, and then vapor starts to form. If we pull the piston out farther, all that happens is that more liquid vaporizes. When there is part liquid and part vapor in the cylinder, the two phases are in equilibrium\u2014liquid is evaporating and vapor is condensing at the same rate. If we make more room for the vapor, more vapor is needed to maintain the pressure, so a little more liquid evaporates, but the pressure remains constant. On the flat part of the curve in Fig. 45\u20133 the pressure does not change, and the value of the pressure here is called the vapor pressure at temperature T . As we continue to increase the volume, there comes a time when there is no more liquid to evaporate. At this juncture, if we expand the volume further, the pressure will fall as for an ordinary gas, as shown at the right of the P - V diagram. The lower curve in Fig. 45\u20133 is the isothermal line at a slightly lower temperature T\u2212\u0394T . The pressure in the liquid phase is slightly reduced because liquid expands with an increase in temperature (for most substances, but not for water near the freezing point) and, of course, the vapor pressure is lower at the lower temperature. We will now make a cycle out of the two isothermal lines by connecting them (say by adiabatic lines) at both ends of the upper flat section, as shown in Fig. 45\u20134. We are going to use the argument of Carnot, which tells us that the heat added to the substance in changing it from a liquid to a vapor is related to the work done by the substance as it goes around the cycle. Let us call L the heat needed to vaporize the substance in the cylinder. As in the argument immediately preceding Eq. (45.5), we know that L(\u0394T/T)= work done by the substance. As before, the work done by the substance is the shaded area, which is approximately \u0394P( V G \u2212 V L ) , where \u0394P is the difference in vapor pressure at the two temperatures T and T\u2212\u0394T , V G is the volume of the gas, and V L is the volume of the liquid, both volumes measured at the vapor pressure at temperature T . Setting these two expressions for the area equal, we get L\u0394T/T=\u0394P( V G \u2212 V L ) , or L T( V G \u2212 V L ) =(\u2202 P vap /\u2202T). (45.14) Equation (45.14) gives the relationship between the rate of change of vapor pressure with temperature and the amount of heat required to evaporate the liquid. This relationship was deduced by Carnot, but it is called the Clausius-Clapeyron equation. Now let us compare Eq. (45.14) with the results deduced from kinetic theory. Usually V G is very much larger than V L . So V G \u2212 V L \u2248 V G =RT/P per mole. If we further assume that L is a constant, independent of temperature\u2014not a very good approximation\u2014then we would have \u2202P/\u2202T=L/(R T 2 /P) . The solution of this differential equation is P=const e \u2212L/RT . (45.15) Let us compare this with the pressure variation with temperature that we deduced earlier from kinetic theory. Kinetic theory indicated the possibility, at least roughly, that the number of molecules per unit volume of vapor above a liquid would be n=( 1 V a ) e \u2212( U G \u2212 U L )/RT , (45.16) where U G \u2212 U L is the internal energy per mole in the gas minus the internal energy per mole in the liquid, i.e., the energy needed to vaporize a mole of liquid. Equation (45.15) from thermodynamics and Eq. (45.16) from kinetic theory are very closely related because the pressure is nkT , but they are not exactly the same. However, they will turn out to be exactly the same if we assume U G \u2212 U L =const , instead of L=const . If we assume U G \u2212 U L =const , independent of temperature, then the argument leading to Eq. (45.15) will produce Eq. (45.16). Since the pressure is constant while the volume is changing, the change in internal energy U G \u2212 U L is equal to the heat L put in minus the work done P( V G \u2212 V L ) , so L=( U G +P V G )\u2212( U L +P V L ) . This comparison shows the advantages and disadvantages of thermodynamics over kinetic theory: First of all, Eq. (45.14) obtained by thermodynamics is exact, while Eq. (45.16) can only be approximated, for instance, if U is nearly constant, and if the model is right. Second, we may not understand correctly how the gas goes into the liquid; nevertheless, Eq. (45.14) is right, while (45.16) is only approximate. Third, although our treatment applies to a gas condensing into a liquid, the argument is true for any other change of state. For instance, the solid-to-liquid transition has the same kind of curve as that shown in Figs. 45\u20133 and 45\u20134. Introducing the latent heat for melting, M /mole, the formula analogous to Eq. (45.14) then is (\u2202 P melt /\u2202T ) V =M/[T( V liq \u2212 V solid )] . Although we may not understand the kinetic theory of the melting process, we nevertheless have a correct equation. However, when we can understand the kinetic theory, we have another advantage. Equation (45.14) is only a differential relationship, and we have no way of obtaining the constants of integration. In the kinetic theory we can obtain the constants also if we have a good model that describes the phenomenon completely. So there are advantages and disadvantages to each. When knowledge is weak and the situation is complicated, thermodynamic relations are really the most powerful. When the situation is very simple and a theoretical analysis can be made, then it is better to try to get more information from theoretical analysis. One more example: blackbody radiation. We have discussed a box containing radiation and nothing else. We have talked about the equilibrium between the oscillator and the radiation. We also found that the photons hitting the wall of the box would exert the pressure P , and we found PV=U/3 , where U is the total energy of all the photons and V is the volume of the box. If we substitute U=3PV in the basic Eq. (45.7), we find1 ( \u2202U \u2202V ) T =3P=T( \u2202P \u2202T ) V \u2212P. (45.17) Since the volume of our box is constant, we can replace (\u2202P/\u2202T ) V by dP/dT to obtain an ordinary differential equation we can integrate: lnP=4lnT+const , or P=const\u00d7 T 4 . The pressure of radiation varies as the fourth power of the temperature, and the total energy density of the radiation, U/V=3P , also varies as T 4 . It is usual to write U/V=(4\u03c3/c) T 4 , where c is the speed of light and \u03c3 is called the Stefan-Boltzmann constant. It is not possible to get \u03c3 from thermodynamics alone. Here is a good example of its power, and its limitations. To know that U/V goes as T 4 is a great deal, but to know how big U/V actually is at any temperature requires that we go into the kind of detail that only a complete theory can supply. For blackbody radiation we have such a theory and we can derive an expression for the constant \u03c3 in the following manner. Let I(\u03c9)d\u03c9 be the intensity distribution, the energy flow through 1 m\u00b2 in one second with frequency between \u03c9 and \u03c9+d\u03c9 . The energy density distribution = energy/volume =I(\u03c9)d\u03c9/c is U V =total energy density = \u222b \u221e \u03c9=0 energy density between \u03c9 and \u03c9+d\u03c9 = \u222b \u221e 0 I(\u03c9)d\u03c9 c . From our earlier discussions, we know that I(\u03c9)= \u210f \u03c9 3 \u03c0 2 c 2 ( e \u210f\u03c9/kT \u22121) . 3 Substituting this expression for I(\u03c9) in our equation for U/V , we get U V = 1 \u03c0 2 c 3 \u222b \u221e 0 \u210f \u03c9 3 d\u03c9 e \u210f\u03c9/kT \u22121 . \u221e 3 If we substitute x=\u210f\u03c9/kT , the expression becomes U V = (kT ) 4 \u210f 3 \u03c0 2 c 3 \u222b \u221e 0 x 3 dx e x \u22121 . 4 This integral is just some number that we can get, approximately, by drawing a curve and taking the area by counting squares. It is roughly 6.5 . The mathematicians among us can show that the integral is exactly \u03c0 4 /15 .2 Comparing this expression with U/V=(4\u03c3/c) T 4 , we find \u03c3= k 4 \u03c0 2 60 \u210f 3 c 2 =5.67\u00d7 10 \u22128 watts (meter ) 2 (degree ) 4 . 4 If we make a small hole in our box, how much energy will flow per second through the hole of unit area? To go from energy density to energy flow, we multiply the energy density U/V by c . We also multiply by 1 4 , which arises as follows: first, a factor of 1 2 , because only the energy which is flowing out escapes; and second, another factor 1 2 , because energy which approaches the hole at an angle to the normal is less effective in getting through the hole by a cosine factor. The average value of the cosine factor is 1 2 . It is clear now why we write U/V=(4\u03c3/c) T 4 : so that we can ultimately say that the flux from a small hole is \u03c3 T 4 per unit area."
    },
    {
        "input": "Work and Potential Energy (A)",
        "output": "In Chapter 4 we discussed the conservation of energy. In that discussion, we did not use Newton\u2019s laws, but it is, of course, of great interest to see how it comes about that energy is in fact conserved in accordance with these laws. For clarity we shall start with the simplest possible example, and then develop harder and harder examples. The simplest example of the conservation of energy is a vertically falling object, one that moves only in a vertical direction. An object which changes its height under the influence of gravity alone has a kinetic energy T (or K.E.) due to its motion during the fall, and a potential energy mgh , abbreviated U (or P.E.), whose sum is constant: 1 2 m v 2 K.E. + mgh P.E. =const, 1 or T+U=const. (13.1) Now we would like to show that this statement is true. What do we mean, show it is true? From Newton\u2019s Second Law we can easily tell how the object moves, and it is easy to find out how the velocity varies with time, namely, that it increases proportionally with the time, and that the height varies as the square of the time. So if we measure the height from a zero point where the object is stationary, it is no miracle that the height turns out to be equal to the square of the velocity times a number of constants. However, let us look at it a little more closely. Let us find out directly from Newton\u2019s Second Law how the kinetic energy should change, by taking the derivative of the kinetic energy with respect to time and then using Newton\u2019s laws. When we differentiate 1 2 m v 2 with respect to time, we obtain dT dt = d dt ( 1 2 m v 2 )= 1 2 m2v dv dt =mv dv dt , (13.2) since m is assumed constant. But from Newton\u2019s Second Law, m(dv/dt)=F , so that dT/dt=Fv. (13.3) In general, it will come out to be F\u22c5v , but in our one-dimensional case let us leave it as the force times the velocity. Now in our simple example the force is constant, equal to \u2212mg , a vertical force (the minus sign means that it acts downward), and the velocity, of course, is the rate of change of the vertical position, or height h , with time. Thus the rate of change of the kinetic energy is \u2212mg(dh/dt) , which quantity, miracle of miracles, is minus the rate of change of something else! It is minus the time rate of change of mgh ! Therefore, as time goes on, the changes in kinetic energy and in the quantity mgh are equal and opposite, so that the sum of the two quantities remains constant. Q.E.D. We have shown, from Newton\u2019s second law of motion, that energy is conserved for constant forces when we add the potential energy mgh to the kinetic energy 1 2 m v 2 . Now let us look into this further and see whether it can be generalized, and thus advance our understanding. Does it work only for a freely falling body, or is it more general? We expect from our discussion of the conservation of energy that it would work for an object moving from one point to another in some kind of frictionless curve, under the influence of gravity (Fig. 13\u20131). If the object reaches a certain height h from the original height H , then the same formula should again be right, even though the velocity is now in some direction other than the vertical. We would like to understand why the law is still correct. Let us follow the same analysis, finding the time rate of change of the kinetic energy. This will again be mv(dv/dt) , but m(dv/dt) is the rate of change of the magnitude of the momentum, i.e., the force in the direction of motion\u2014the tangential force F t . Thus dT dt =mv dv dt = F t v. d T d Now the speed is the rate of change of distance along the curve, ds/dt , and the tangential force F t is not \u2212mg but is weaker by the ratio of the vertical distance dh to the distance ds along the path. In other words, F t =\u2212mgsin\u03b8=\u2212mg dh ds , d h so that F t ds dt =\u2212mg( dh ds )( ds dt )=\u2212mg dh dt , d d h d d h since the ds \u2019s cancel. Thus we get \u2212mg(dh/dt) , which is equal to the rate of change of \u2212mgh , as before. In order to understand exactly how the conservation of energy works in general in mechanics, we shall now discuss a number of concepts which will help us to analyze it. First, we discuss the rate of change of kinetic energy in general in three dimensions. The kinetic energy in three dimensions is T= 1 2 m( v 2 x + v 2 y + v 2 z ). 1 When we differentiate this with respect to time, we get three terrifying terms: dT dt =m( v x d v x dt + v y d v y dt + v z d v z dt ). (13.4) But m(d v x /dt) is the force F x acting on the object in the x -direction. Thus the right side of Eq. (13.4) is F x v x + F y v y + F z v z . We recall our vector analysis and recognize this as F\u22c5v ; therefore dT/dt=F\u22c5v. (13.5) This result can be derived more quickly as follows: if a and b are two vectors, both of which may depend upon the time, the derivative of a\u22c5b is, in general, d(a\u22c5b)/dt=a\u22c5(db/dt)+(da/dt)\u22c5b. (13.6) We then use this in the form a= b= v : d( 1 2 m v 2 ) dt = d( 1 2 mv\u22c5v) dt =m dv dt \u22c5v =F\u22c5v=F\u22c5 ds dt . (13.7) Because the concepts of kinetic energy, and energy in general, are so important, various names have been given to the important terms in equations such as these. 1 2 m v 2 is, as we know, called kinetic energy. F\u22c5v is called power: the force acting on an object times the velocity of the object (vector \u201cdot\u201d product) is the power being delivered to the object by that force. We thus have a marvelous theorem: the rate of change of kinetic energy of an object is equal to the power expended by the forces acting on it. However, to study the conservation of energy, we want to analyze this still more closely. Let us evaluate the change in kinetic energy in a very short time dt . If we multiply both sides of Eq. (13.7) by dt , we find that the differential change in the kinetic energy is the force \u201cdot\u201d the differential distance moved: dT=F\u22c5ds. (13.8) If we now integrate, we get \u0394T= \u222b 2 1 F\u22c5ds. (13.9) What does this mean? It means that if an object is moving in any way under the influence of a force, moving in some kind of curved path, then the change in K.E. when it goes from one point to another along the curve is equal to the integral of the component of the force along the curve times the differential displacement ds , the integral being carried out from one point to the other. This integral also has a name; it is called the work done by the force on the object. We see immediately that power equals work done per second. We also see that it is only a component of force in the direction of motion that contributes to the work done. In our simple example the forces were only vertical, and had only a single component, say F z , equal to \u2212mg . No matter how the object moves in those circumstances, falling in a parabola for example, F\u22c5s , which can be written as F x dx+ F y dy+ F z dz , has nothing left of it but F z dz=\u2212mgdz , because the other components of force are zero. Therefore, in our simple case, \u222b 2 1 F\u22c5ds= \u222b z 2 z 1 \u2212mgdz=\u2212mg( z 2 \u2212 z 1 ), (13.10) so again we find that it is only the vertical height from which the object falls that counts toward the potential energy. A word about units. Since forces are measured in newtons, and we multiply by a distance in order to obtain work, work is measured in newton \u22c5 meters (N \u22c5 m), but people do not like to say newton-meters, they prefer to say joules (J). A newton-meter is called a joule; work is measured in joules. Power, then, is joules per second, and that is also called a watt (W). If we multiply watts by time, the result is the work done. The work done by the electrical company in our houses, technically, is equal to the watts times the time. That is where we get things like kilowatt hours, 1000 watts times 3600 seconds, or 3.6\u00d7 10 6 joules. Now we take another example of the law of conservation of energy. Consider an object which initially has kinetic energy and is moving very fast, and which slides against the floor with friction. It stops. At the start the kinetic energy is not zero, but at the end it is zero; there is work done by the forces, because whenever there is friction there is always a component of force in a direction opposite to that of the motion, and so energy is steadily lost. But now let us take a mass on the end of a pivot swinging in a vertical plane in a gravitational field with no friction. What happens here is different, because when the mass is going up the force is downward, and when it is coming down, the force is also downward. Thus F\u22c5ds has one sign going up and another sign coming down. At each corresponding point of the downward and upward paths the values of F\u22c5ds are exactly equal in size but of opposite sign, so the net result of the integral will be zero for this case. Thus the kinetic energy with which the mass comes back to the bottom is the same as it had when it left; that is the principle of the conservation of energy. (Note that when there are friction forces the conservation of energy seems at first sight to be invalid. We have to find another form of energy. It turns out, in fact, that heat is generated in an object when it rubs another with friction, but at the moment we supposedly do not know that.) The next problem to be discussed is much more difficult than the above; it has to do with the case when the forces are not constant, or simply vertical, as they were in the cases we have worked out. We want to consider a planet, for example, moving around the sun, or a satellite in the space around the earth. We shall first consider the motion of an object which starts at some point 1 and falls, say, directly toward the sun or toward the earth (Fig. 13\u20132). Will there be a law of conservation of energy in these circumstances? The only difference is that in this case, the force is changing as we go along, it is not just a constant. As we know, the force is \u2212GM/ r 2 times the mass m , where m is the mass that moves. Now certainly when a body falls toward the earth, the kinetic energy increases as the distance fallen increases, just as it does when we do not worry about the variation of force with height. The question is whether it is possible to find another formula for potential energy different from mgh , a different function of distance away from the earth, so that conservation of energy will still be true. This one-dimensional case is easy to treat because we know that the change in the kinetic energy is equal to the integral, from one end of the motion to the other, of \u2212GMm/ r 2 times the displacement dr : T 2 \u2212 T 1 =\u2212 \u222b 2 1 GMm dr r 2 . (13.11) There are no cosines needed for this case because the force and the displacement are in the same direction. It is easy to integrate dr/ r 2 ; the result is \u22121/r , so Eq. (13.11) becomes T 2 \u2212 T 1 =+GMm( 1 r 2 \u2212 1 r 1 ). (13.12) Thus we have a different formula for potential energy. Equation (13.12) tells us that the quantity ( 1 2 m v 2 \u2212GMm/r) calculated at point 1 , at point 2 , or at any other place, has a constant value. We now have the formula for the potential energy in a gravitational field for vertical motion. Now we have an interesting problem. Can we make perpetual motion in a gravitational field? The gravitational field varies; in different places it is in different directions and has different strengths. Could we do something like this, using a fixed, frictionless track: start at some point and lift an object out to some other point, then move it around an arc to a third point, then lower it a certain distance, then move it in at a certain slope and pull it out some other way, so that when we bring it back to the starting point, a certain amount of work has been done by the gravitational force, and the kinetic energy of the object is increased? Can we design the curve so that it comes back moving a little bit faster than it did before, so that it goes around and around and around, and gives us perpetual motion? Since perpetual motion is impossible, we ought to find out that this is also impossible. We ought to discover the following proposition: since there is no friction the object should come back with neither higher nor lower velocity\u2014it should be able to keep going around and around any closed path. Stated in another way, the total work done in going around a complete cycle should be zero for gravity forces, because if it is not zero we can get energy out by going around. (If the work turns out to be less than zero, so that we get less speed when we go around one way, then we merely go around the other way, because the forces, of course, depend only upon the position, not upon the direction; if one way is plus, the other way would be minus, so unless it is zero we will get perpetual motion by going around either way.) Is the work really zero? Let us try to demonstrate that it is. First we shall explain more or less why it is zero, and then we shall examine it a little better mathematically. Suppose that we use a simple path such as that shown in Fig. 13\u20133, in which a small mass is carried from point 1 to point 2 , and then is made to go around a circle to 3 , back to 4 , then to 5 , 6 , 7 , and 8 , and finally back to 1 . All of the lines are either purely radial or circular, with M as the center. How much work is done in carrying m around this path? Between points 1 and 2 , it is GMm times the difference of 1/r between these two points: W 12 = \u222b 2 1 F\u22c5ds= \u222b 2 1 \u2212GMm dr r 2 =GMm( 1 r 2 \u2212 1 r 1 ). 2 2 From 2 to 3 the force is exactly at right angles to the curve, so that W 23 \u22610 . The work from 3 to 4 is W 34 = \u222b 4 3 F\u22c5ds=GMm( 1 r 4 \u2212 1 r 3 ). 4 In the same fashion, we find that W 45 =0 , W 56 =GMm(1/ r 6 \u22121/ r 5 ) , W 67 =0 , W 78 =GMm(1/ r 8 \u22121/ r 7 ) , and W 81 =0 . Thus W=GMm( 1 r 2 \u2212 1 r 1 + 1 r 4 \u2212 1 r 3 + 1 r 6 \u2212 1 r 5 + 1 r 8 \u2212 1 r 7 ). 1 1 1 1 1 1 1 1 But we note that r 2 = r 3 , r 4 = r 5 , r 6 = r 7 , and r 8 = r 1 . Therefore W=0 . Of course we may wonder whether this is too trivial a curve. What if we use a real curve? Let us try it on a real curve. First of all, we might like to assert that a real curve could always be imitated sufficiently well by a series of sawtooth jiggles like those of Fig. 13\u20134, and that therefore, etc., Q.E.D., but without a little analysis, it is not obvious at first that the work done going around even a small triangle is zero. Let us magnify one of the triangles, as shown in Fig. 13\u20134. Is the work done in going from a to b and b to c on a triangle the same as the work done in going directly from a to c ? Suppose that the force is acting in a certain direction; let us take the triangle such that the side bc is in this direction, just as an example. We also suppose that the triangle is so small that the force is essentially constant over the entire triangle. What is the work done in going from a to c ? It is W ac = \u222b c a F\u22c5ds=Fscos\u03b8, c since the force is constant. Now let us calculate the work done in going around the other two sides of the triangle. On the vertical side ab the force is perpendicular to ds , so that here the work is zero. On the horizontal side bc , W bc = \u222b c b F\u22c5ds=Fx. c Thus we see that the work done in going along the sides of a small triangle is the same as that done going on a slant, because scos\u03b8 is equal to x . We have proved previously that the answer is zero for any path composed of a series of notches like those of Fig. 13\u20133, and also that we do the same work if we cut across the corners instead of going along the notches (so long as the notches are fine enough, and we can always make them very fine); therefore, the work done in going around any path in a gravitational field is zero. This is a very remarkable result. It tells us something we did not previously know about planetary motion. It tells us that when a planet moves around the sun (without any other objects around, no other forces) it moves in such a manner that the square of the speed at any point minus some constants divided by the radius at that point is always the same at every point on the orbit. For example, the closer the planet is to the sun, the faster it is going, but by how much? By the following amount: if instead of letting the planet go around the sun, we were to change the direction (but not the magnitude) of its velocity and make it move radially, and then we let it fall from some special radius to the radius of interest, the new speed would be the same as the speed it had in the actual orbit, because this is just another example of a complicated path. So long as we come back to the same distance, the kinetic energy will be the same. So, whether the motion is the real, undisturbed one, or is changed in direction by channels, by frictionless constraints, the kinetic energy with which the planet arrives at a point will be the same. Thus, when we make a numerical analysis of the motion of the planet in its orbit, as we did earlier, we can check whether or not we are making appreciable errors by calculating this constant quantity, the energy, at every step, and it should not change. For the orbit of Table 9\u20132 the energy does change,1 it changes by some 1.5 percent from the beginning to the end. Why? Either because for the numerical method we use finite intervals, or else because we made a slight mistake somewhere in arithmetic. Let us consider the energy in another case: the problem of a mass on a spring. When we displace the mass from its balanced position, the restoring force is proportional to the displacement. In those circumstances, can we work out a law for conservation of energy? Yes, because the work done by such a force is W= \u222b x 0 Fdx= \u222b x 0 \u2212kxdx=\u2212 1 2 k x 2 . (13.13) Therefore, for a mass on a spring we have that the kinetic energy of the oscillating mass plus 1 2 k x 2 is a constant. Let us see how this works. We pull the mass down; it is standing still and so its speed is zero. But x is not zero, x is at its maximum, so there is some energy, the potential energy, of course. Now we release the mass and things begin to happen (the details not to be discussed), but at any instant the kinetic plus potential energy must be a constant. For example, after the mass is on its way past the original equilibrium point, the position x equals zero, but that is when it has its biggest v 2 , and as it gets more x 2 it gets less v 2 , and so on. So the balance of x 2 and v 2 is maintained as the mass goes up and down. Thus we have another rule now, that the potential energy for a spring is 1 2 k x 2 , if the force is \u2212kx . Now we go on to the more general consideration of what happens when there are large numbers of objects. Suppose we have the complicated problem of many objects, which we label i=1 , 2 , 3 , \u2026, all exerting gravitational pulls on each other. What happens then? We shall prove that if we add the kinetic energies of all the particles, and add to this the sum, over all pairs of particles, of their mutual gravitational potential energy, \u2212GMm/ r ij , the total is a constant: \u2211 i 1 2 m i v 2 i + \u2211 (pairs ij) \u2212 G m i m j r ij =const. (13.14) How do we prove it? We differentiate each side with respect to time and get zero. When we differentiate 1 2 m i v 2 i , we find derivatives of the velocity that are the forces, just as in Eq. (13.5). We replace these forces by the law of force that we know from Newton\u2019s law of gravity and then we notice that what is left is minus the time derivative of \u2211 pairs \u2212 G m i m j r ij . G The time derivative of the kinetic energy is d dt \u2211 i 1 2 m i v 2 i = \u2211 i m i d v i dt \u22c5 v i = \u2211 i F i \u22c5 v i = \u2211 i ( \u2211 j \u2212 G m i m j r ij r 3 ij )\u22c5 v i . (13.15) The time derivative of the potential energy is d dt \u2211 pairs \u2212 G m i m j r ij = \u2211 pairs (+ G m i m j r 2 ij )( d r ij dt ). G G d But r ij = ( x i \u2212 x j ) 2 +( y i \u2212 y j ) 2 +( z i \u2212 z j ) 2 \u2212 \u2212 \u2212 \u2212 \u2212 \u2212 \u2212 \u2212 \u2212 \u2212 \u2212 \u2212 \u2212 \u2212 \u2212 \u2212 \u2212 \u2212 \u2212 \u2212 \u2212 \u2212 \u2212 \u2212 \u2212 \u2212 \u2212 \u221a , so that d r ij dt = 1 2 r ij [ + + 2( x i 2( y i 2( z i \u2212 x j \u2212 y j \u2212 z j )( d x i dt )( d y i dt )( d z i dt \u2212 d x j dt \u2212 d y j dt \u2212 d z j dt ) ) )] = r ij \u22c5 v i \u2212 v j r ij = r ij \u22c5 v i r ij + r ji \u22c5 v j r ji , since r ij =\u2212 r ji , while r ij = r ji . Thus d dt \u2211 pairs \u2212 G m i m j r ij = \u2211 pairs [ G m i m j r ij r 3 ij \u22c5 v i + G m j m i r ji r 3 ji \u22c5 v j ]. (13.16) Now we must note carefully what \u2211 i { \u2211 j } and \u2211 pairs mean. In Eq. (13.15), \u2211 i { \u2211 j } means that i takes on all values i=1 , 2 , 3 , \u2026 in turn, and for each value of i , the index j takes on all values except i . Thus if i=3 , j takes on the values 1 , 2 , 4 , \u2026 In Eq. (13.16), on the other hand, \u2211 pairs means that given values of i and j occur only once. Thus the particle pair 1 and 3 contributes only one term to the sum. To keep track of this, we might agree to let i range over all values 1 , 2 , 3 , \u2026, and for each i let j range only over values greater than i . Thus if i=3 , j could only have values 4 , 5 , 6 , \u2026 But we notice that for each i,j value there are two contributions to the sum, one involving v i , and the other v j , and that these terms have the same appearance as those of Eq. (13.15), where all values of i and j (except i=j ) are included in the sum. Therefore, by matching the terms one by one, we see that Eqs. (13.16) and (13.15) are precisely the same, but of opposite sign, so that the time derivative of the kinetic plus potential energy is indeed zero. Thus we see that, for many objects, the kinetic energy is the sum of the contributions from each individual object, and that the potential energy is also simple, it being also just a sum of contributions, the energies between all the pairs. We can understand why it should be the energy of every pair this way: Suppose that we want to find the total amount of work that must be done to bring the objects to certain distances from each other. We may do this in several steps, bringing them in from infinity where there is no force, one by one. First we bring in number one, which requires no work, since no other objects are yet present to exert force on it. Next we bring in number two, which does take some work, namely W 12 =\u2212G m 1 m 2 / r 12 . Now, and this is an important point, suppose we bring in the next object to position three. At any moment the force on number 3 can be written as the sum of two forces\u2014the force exerted by number 1 and that exerted by number 2 . Therefore the work done is the sum of the works done by each, because if F 3 can be resolved into the sum of two forces, F 3 = F 13 + F 23 , F F F then the work is \u222b F 3 \u22c5ds=\u222b F 13 \u22c5ds+\u222b F 23 \u22c5ds= W 13 + W 23 . \u222b \u222b \u222b That is, the work done is the sum of the work done against the first force and the second force, as if each acted independently. Proceeding in this way, we see that the total work required to assemble the given configuration of objects is precisely the value given in Eq. (13.14) as the potential energy. It is because gravity obeys the principle of superposition of forces that we can write the potential energy as a sum over each pair of particles. Now we shall calculate the fields which are met in a few physical circumstances involving distributions of mass. We have not so far considered distributions of mass, only particles, so it is interesting to calculate the forces when they are produced by more than just one particle. First we shall find the gravitational force on a mass that is produced by a plane sheet of material, infinite in extent. The force on a unit mass at a given point P , produced by this sheet of material (Fig. 13\u20135), will of course be directed toward the sheet. Let the distance of the point from the sheet be a , and let the amount of mass per unit area of this huge sheet be \u03bc . We shall suppose \u03bc to be constant; it is a uniform sheet of material. Now, what small field dC is produced by the mass dm lying between \u03c1 and \u03c1+d\u03c1 from the point O of the sheet nearest point P ? Answer: dC=\u2212G(dmr/ r 3 ) . But this field is directed along r , and we know that only the x -component of it will remain when we add all the little vector dC \u2019s to produce C . The x -component of dC is d C x =\u2212G dm r x r 3 =\u2212G dma r 3 . d d Now all masses dm which are at the same distance r from P will yield the same d C x , so we may at once write for dm the total mass in the ring between \u03c1 and \u03c1+d\u03c1 , namely dm=\u03bc2\u03c0\u03c1d\u03c1 ( 2\u03c0\u03c1d\u03c1 is the area of a ring of radius \u03c1 and width d\u03c1 , if d\u03c1\u226a\u03c1 ). Thus d C x =\u2212G\u03bc2\u03c0\u03c1 d\u03c1a r 3 . d Then, since r 2 = \u03c1 2 + a 2 , \u03c1d\u03c1=rdr . Therefore, C x =\u22122\u03c0G\u03bca \u222b \u221e a dr r 2 =\u22122\u03c0G\u03bca( 1 a \u2212 1 \u221e )=\u22122\u03c0G\u03bc. (13.17) Thus the force is independent of distance a ! Why? Have we made a mistake? One might think that the farther away we go, the weaker the force would be. But no! If we are close, most of the matter is pulling at an unfavorable angle; if we are far away, more of the matter is situated more favorably to exert a pull toward the plane. At any distance, the matter which is most effective lies in a certain cone. When we are farther away the force is smaller by the inverse square, but in the same cone, in the same angle, there is much more matter, larger by just the square of the distance! This analysis can be made rigorous by just noticing that the differential contribution in any given cone is in fact independent of the distance, because of the reciprocal variation of the strength of the force from a given mass, and the amount of mass included in the cone, with changing distance. The force is not really constant of course, because when we go on the other side of the sheet it is reversed in sign. We have also, in effect, solved an electrical problem: if we have an electrically charged plate, with an amount \u03c3 of charge per unit area, then the electric field at a point outside the sheet is equal to \u03c3/2 \u03f5 0 , and is in the outward direction if the sheet is positively charged, and inward if the sheet is negatively charged. To prove this, we merely note that \u2212G , for gravity, plays the same role as 1/4\u03c0 \u03f5 0 for electricity. Now suppose that we have two plates, with a positive charge +\u03c3 on one and a negative charge \u2212\u03c3 on another at a distance D from the first. What is the field? Outside the two plates it is zero. Why? Because one attracts and the other repels, the force being independent of distance, so that the two balance out! Also, the field between the two plates is clearly twice as great as that from one plate, namely E=\u03c3/ \u03f5 0 , and is directed from the positive plate to the negative one. Now we come to a most interesting and important problem, whose solution we have been assuming all the time, namely, that the force produced by the earth at a point on the surface or outside it is the same as if all the mass of the earth were located at its center. The validity of this assumption is not obvious, because when we are close, some of the mass is very close to us, and some is farther away, and so on. When we add the effects all together, it seems a miracle that the net force is exactly the same as we would get if we put all the mass in the middle! We now demonstrate the correctness of this miracle. In order to do so, however, we shall consider a thin uniform hollow shell instead of the whole earth. Let the total mass of the shell be m , and let us calculate the potential energy of a particle of mass m \u2032 a distance R away from the center of the sphere (Fig. 13\u20136) and show that the potential energy is the same as it would be if the mass m were a point at the center. (The potential energy is easier to work with than is the field because we do not have to worry about angles, we merely add the potential energies of all the pieces of mass.) If we call x the distance of a certain plane section from the center, then all the mass that is in a slice dx is at the same distance r from P , and the potential energy due to this ring is \u2212G m \u2032 dm/r . How much mass is in the small slice dx ? An amount dm=2\u03c0y\u03bcds= 2\u03c0y\u03bcdx sin\u03b8 = 2\u03c0y\u03bcdxa y =2\u03c0a\u03bcdx, 2 d 2 d where \u03bc=m/4\u03c0 a 2 is the surface density of mass on the spherical shell. (It is a general rule that the area of a zone of a sphere is proportional to its axial width.) Therefore the potential energy due to dm is dW=\u2212 G m \u2032 dm r =\u2212 G m \u2032 2\u03c0a\u03bcdx r . \u2032 \u2032 But we see that r 2 = y 2 +(R\u2212x ) 2 = y 2 + x 2 + R 2 \u22122Rx = a 2 + R 2 \u22122Rx. Thus 2rdr=\u22122Rdx 2 d 2 R d or dx r =\u2212 dr R . d d Therefore, dW= G m \u2032 2\u03c0a\u03bcdr R , \u2032 and so W = G m \u2032 2\u03c0a\u03bc R \u222b R\u2212a R+a dr =\u2212 G m \u2032 2\u03c0a\u03bc R 2a=\u2212 G m \u2032 (4\u03c0 a 2 \u03bc) R =\u2212 G m \u2032 m R . (13.18) Thus, for a thin spherical shell, the potential energy of a mass m \u2032 , external to the shell, is the same as though the mass of the shell were concentrated at its center. The earth can be imagined as a series of spherical shells, each one of which contributes an energy which depends only on its mass and the distance from its center to the particle; adding them all together we get the total mass, and therefore the earth acts as though all the material were at the center! But notice what happens if our point is on the inside of the shell. Making the same calculation, but with P on the inside, we still get the difference of the two r \u2019s, but now in the form a\u2212R\u2212(a+R)=\u22122R , or minus twice the distance from the center. In other words, W comes out to be W=\u2212G m \u2032 m/a , which is independent of R and independent of position, i.e., the same energy no matter where we are inside. Therefore no force; no work is done when we move about inside. If the potential energy is the same no matter where an object is placed inside the sphere, there can be no force on it. So there is no force inside, there is only a force outside, and the force outside is the same as though the mass were all at the center."
    },
    {
        "input": "Relativistic Energy and Momentum",
        "output": "In this chapter we shall continue to discuss the principle of relativity of Einstein and Poincar\u00e9, as it affects our ideas of physics and other branches of human thought. Poincar\u00e9 made the following statement of the principle of relativity: \u201cAccording to the principle of relativity, the laws of physical phenomena must be the same for a fixed observer as for an observer who has a uniform motion of translation relative to him, so that we have not, nor can we possibly have, any means of discerning whether or not we are carried along in such a motion.\u201d When this idea descended upon the world, it caused a great stir among philosophers, particularly the \u201ccocktail-party philosophers,\u201d who say, \u201cOh, it is very simple: Einstein\u2019s theory says all is relative!\u201d In fact, a surprisingly large number of philosophers, not only those found at cocktail parties (but rather than embarrass them, we shall just call them \u201ccocktail-party philosophers\u201d), will say, \u201cThat all is relative is a consequence of Einstein, and it has profound influences on our ideas.\u201d In addition, they say \u201cIt has been demonstrated in physics that phenomena depend upon your frame of reference.\u201d We hear that a great deal, but it is difficult to find out what it means. Probably the frames of reference that were originally referred to were the coordinate systems which we use in the analysis of the theory of relativity. So the fact that \u201cthings depend upon your frame of reference\u201d is supposed to have had a profound effect on modern thought. One might well wonder why, because, after all, that things depend upon one\u2019s point of view is so simple an idea that it certainly cannot have been necessary to go to all the trouble of the physical relativity theory in order to discover it. That what one sees depends upon his frame of reference is certainly known to anybody who walks around, because he sees an approaching pedestrian first from the front and then from the back; there is nothing deeper in most of the philosophy which is said to have come from the theory of relativity than the remark that \u201cA person looks different from the front than from the back.\u201d The old story about the elephant that several blind men describe in different ways is another example, perhaps, of the theory of relativity from the philosopher\u2019s point of view. But certainly there must be deeper things in the theory of relativity than just this simple remark that \u201cA person looks different from the front than from the back.\u201d Of course relativity is deeper than this, because we can make definite predictions with it. It certainly would be rather remarkable if we could predict the behavior of nature from such a simple observation alone. There is another school of philosophers who feel very uncomfortable about the theory of relativity, which asserts that we cannot determine our absolute velocity without looking at something outside, and who would say, \u201cIt is obvious that one cannot measure his velocity without looking outside. It is self-evident that it is meaningless to talk about the velocity of a thing without looking outside; the physicists are rather stupid for having thought otherwise, but it has just dawned on them that this is the case. If only we philosophers had realized what the problems were that the physicists had, we could have decided immediately by brainwork that it is impossible to tell how fast one is moving without looking outside, and we could have made an enormous contribution to physics.\u201d These philosophers are always with us, struggling in the periphery to try to tell us something, but they never really understand the subtleties and depths of the problem. Our inability to detect absolute motion is a result of experiment and not a result of plain thought, as we can easily illustrate. In the first place, Newton believed that it was true that one could not tell how fast he is going if he is moving with uniform velocity in a straight line. In fact, Newton first stated the principle of relativity, and one quotation made in the last chapter was a statement of Newton\u2019s. Why then did the philosophers not make all this fuss about \u201call is relative,\u201d or whatever, in Newton\u2019s time? Because it was not until Maxwell\u2019s theory of electrodynamics was developed that there were physical laws that suggested that one could measure his velocity without looking outside; soon it was found experimentally that one could not. Now, is it absolutely, definitely, philosophically necessary that one should not be able to tell how fast he is moving without looking outside? One of the consequences of relativity was the development of a philosophy which said, \u201cYou can only define what you can measure! Since it is self-evident that one cannot measure a velocity without seeing what he is measuring it relative to, therefore it is clear that there is no meaning to absolute velocity. The physicists should have realized that they can talk only about what they can measure.\u201d But that is the whole problem: whether or not one can define absolute velocity is the same as the problem of whether or not one can detect in an experiment, without looking outside, whether he is moving. In other words, whether or not a thing is measurable is not something to be decided a priori by thought alone, but something that can be decided only by experiment. Given the fact that the velocity of light is 186,000 mi/sec, one will find few philosophers who will calmly state that it is self-evident that if light goes 186,000 mi/sec inside a car, and the car is going 100,000 mi/sec, that the light also goes 186,000 mi/sec past an observer on the ground. That is a shocking fact to them; the very ones who claim it is obvious find, when you give them a specific fact, that it is not obvious. Finally, there is even a philosophy which says that one cannot detect any motion except by looking outside. It is simply not true in physics. True, one cannot perceive a uniform motion in a straight line, but if the whole room were rotating we would certainly know it, for everybody would be thrown to the wall\u2014there would be all kinds of \u201ccentrifugal\u201d effects. That the earth is turning on its axis can be determined without looking at the stars, by means of the so-called Foucault pendulum, for example. Therefore it is not true that \u201call is relative\u201d; it is only uniform velocity that cannot be detected without looking outside. Uniform rotation about a fixed axis can be. When this is told to a philosopher, he is very upset that he did not really understand it, because to him it seems impossible that one should be able to determine rotation about an axis without looking outside. If the philosopher is good enough, after some time he may come back and say, \u201cI understand. We really do not have such a thing as absolute rotation; we are really rotating relative to the stars, you see. And so some influence exerted by the stars on the object must cause the centrifugal force.\u201d Now, for all we know, that is true; we have no way, at the present time, of telling whether there would have been centrifugal force if there were no stars and nebulae around. We have not been able to do the experiment of removing all the nebulae and then measuring our rotation, so we simply do not know. We must admit that the philosopher may be right. He comes back, therefore, in delight and says, \u201cIt is absolutely necessary that the world ultimately turn out to be this way: absolute rotation means nothing; it is only relative to the nebulae.\u201d Then we say to him, \u201cNow, my friend, is it or is it not obvious that uniform velocity in a straight line, relative to the nebulae should produce no effects inside a car?\u201d Now that the motion is no longer absolute, but is a motion relative to the nebulae, it becomes a mysterious question, and a question that can be answered only by experiment. What, then, are the philosophic influences of the theory of relativity? If we limit ourselves to influences in the sense of what kind of new ideas and suggestions are made to the physicist by the principle of relativity, we could describe some of them as follows. The first discovery is, essentially, that even those ideas which have been held for a very long time and which have been very accurately verified might be wrong. It was a shocking discovery, of course, that Newton\u2019s laws are wrong, after all the years in which they seemed to be accurate. Of course it is clear, not that the experiments were wrong, but that they were done over only a limited range of velocities, so small that the relativistic effects would not have been evident. But nevertheless, we now have a much more humble point of view of our physical laws\u2014everything can be wrong! Secondly, if we have a set of \u201cstrange\u201d ideas, such as that time goes slower when one moves, and so forth, whether we like them or do not like them is an irrelevant question. The only relevant question is whether the ideas are consistent with what is found experimentally. In other words, the \u201cstrange ideas\u201d need only agree with experiment, and the only reason that we have to discuss the behavior of clocks and so forth is to demonstrate that although the notion of the time dilation is strange, it is consistent with the way we measure time. Finally, there is a third suggestion which is a little more technical but which has turned out to be of enormous utility in our study of other physical laws, and that is to look at the symmetry of the laws or, more specifically, to look for the ways in which the laws can be transformed and leave their form the same. When we discussed the theory of vectors, we noted that the fundamental laws of motion are not changed when we rotate the coordinate system, and now we learn that they are not changed when we change the space and time variables in a particular way, given by the Lorentz transformation. So this idea of studying the patterns or operations under which the fundamental laws are not changed has proved to be a very useful one. To continue our discussion of the Lorentz transformation and relativistic effects, we consider a famous so-called \u201cparadox\u201d of Peter and Paul, who are supposed to be twins, born at the same time. When they are old enough to drive a space ship, Paul flies away at very high speed. Because Peter, who is left on the ground, sees Paul going so fast, all of Paul\u2019s clocks appear to go slower, his heart beats go slower, his thoughts go slower, everything goes slower, from Peter\u2019s point of view. Of course, Paul notices nothing unusual, but if he travels around and about for a while and then comes back, he will be younger than Peter, the man on the ground! That is actually right; it is one of the consequences of the theory of relativity which has been clearly demonstrated. Just as the muons last longer when they are moving, so also will Paul last longer when he is moving. This is called a \u201cparadox\u201d only by the people who believe that the principle of relativity means that all motion is relative; they say, \u201cHeh, heh, heh, from the point of view of Paul, can\u2019t we say that Peter was moving and should therefore appear to age more slowly? By symmetry, the only possible result is that both should be the same age when they meet.\u201d But in order for them to come back together and make the comparison, Paul must either stop at the end of the trip and make a comparison of clocks or, more simply, he has to come back, and the one who comes back must be the man who was moving, and he knows this, because he had to turn around. When he turned around, all kinds of unusual things happened in his space ship\u2014the rockets went off, things jammed up against one wall, and so on\u2014while Peter felt nothing. So the way to state the rule is to say that the man who has felt the accelerations, who has seen things fall against the walls, and so on, is the one who would be the younger; that is the difference between them in an \u201cabsolute\u201d sense, and it is certainly correct. When we discussed the fact that moving muons live longer, we used as an example their straight-line motion in the atmosphere. But we can also make muons in a laboratory and cause them to go in a curve with a magnet, and even under this accelerated motion, they last exactly as much longer as they do when they are moving in a straight line. Although no one has arranged an experiment explicitly so that we can get rid of the paradox, one could compare a muon which is left standing with one that had gone around a complete circle, and it would surely be found that the one that went around the circle lasted longer. Although we have not actually carried out an experiment using a complete circle, it is really not necessary, of course, because everything fits together all right. This may not satisfy those who insist that every single fact be demonstrated directly, but we confidently predict the result of the experiment in which Paul goes in a complete circle. The main difference between the relativity of Einstein and the relativity of Newton is that the laws of transformation connecting the coordinates and times between relatively moving systems are different. The correct transformation law, that of Lorentz, is x \u2032 y \u2032 z \u2032 t \u2032 = x\u2212ut 1\u2212 u 2 / c 2 \u2212 \u2212 \u2212 \u2212 \u2212 \u2212 \u2212 \u2212 \u221a , =y, =z, = t\u2212ux/ c 2 1\u2212 u 2 / c 2 \u2212 \u2212 \u2212 \u2212 \u2212 \u2212 \u2212 \u2212 \u221a . (16.1) These equations correspond to the relatively simple case in which the relative motion of the two observers is along their common x -axes. Of course other directions of motion are possible, but the most general Lorentz transformation is rather complicated, with all four quantities mixed up together. We shall continue to use this simpler form, since it contains all the essential features of relativity. Let us now discuss more of the consequences of this transformation. First, it is interesting to solve these equations in reverse. That is, here is a set of linear equations, four equations with four unknowns, and they can be solved in reverse, for x,y,z,t in terms of x \u2032 , y \u2032 , z \u2032 , t \u2032 . The result is very interesting, since it tells us how a system of coordinates \u201cat rest\u201d looks from the point of view of one that is \u201cmoving.\u201d Of course, since the motions are relative and of uniform velocity, the man who is \u201cmoving\u201d can say, if he wishes, that it is really the other fellow who is moving and he himself who is at rest. And since he is moving in the opposite direction, he should get the same transformation, but with the opposite sign of velocity. That is precisely what we find by manipulation, so that is consistent. If it did not come out that way, we would have real cause to worry! x y z t = x \u2032 +u t \u2032 1\u2212 u 2 / c 2 \u2212 \u2212 \u2212 \u2212 \u2212 \u2212 \u2212 \u2212 \u221a , = y \u2032 , = z \u2032 , = t \u2032 +u x \u2032 / c 2 1\u2212 u 2 / c 2 \u2212 \u2212 \u2212 \u2212 \u2212 \u2212 \u2212 \u2212 \u221a . (16.2) Next we discuss the interesting problem of the addition of velocities in relativity. We recall that one of the original puzzles was that light travels at 186,000 mi/sec in all systems, even when they are in relative motion. This is a special case of the more general problem exemplified by the following. Suppose that an object inside a space ship is going at 100,000 mi/sec and the space ship itself is going at 100,000 mi/sec; how fast is the object inside the space ship moving from the point of view of an observer outside? We might want to say 200,000 mi/sec, which is faster than the speed of light. This is very unnerving, because it is not supposed to be going faster than the speed of light! The general problem is as follows. Let us suppose that the object inside the ship, from the point of view of the man inside, is moving with velocity v , and that the space ship itself has a velocity u with respect to the ground. We want to know with what velocity v x this object is moving from the point of view of the man on the ground. This is, of course, still but a special case in which the motion is in the x -direction. There will also be a transformation for velocities in the y -direction, or for any angle; these can be worked out as needed. Inside the space ship the velocity is v x \u2032 , which means that the displacement x \u2032 is equal to the velocity times the time: x \u2032 = v x \u2032 t \u2032 . (16.3) Now we have only to calculate what the position and time are from the point of view of the outside observer for an object which has the relation (16.2) between x \u2032 and t \u2032 . So we simply substitute (16.3) into (16.2), and obtain x= v x \u2032 t \u2032 +u t \u2032 1\u2212 u 2 / c 2 \u2212 \u2212 \u2212 \u2212 \u2212 \u2212 \u2212 \u2212 \u221a . (16.4) But here we find x expressed in terms of t \u2032 . In order to get the velocity as seen by the man on the outside, we must divide his distance by his time, not by the other man\u2019s time! So we must also calculate the time as seen from the outside, which is t= t \u2032 +u( v x \u2032 t \u2032 )/ c 2 1\u2212 u 2 / c 2 \u2212 \u2212 \u2212 \u2212 \u2212 \u2212 \u2212 \u2212 \u221a . (16.5) Now we must find the ratio of x to t , which is v x = x t = u+ v x \u2032 1+u v x \u2032 / c 2 , (16.6) the square roots having cancelled. This is the law that we seek: the resultant velocity, the \u201csumming\u201d of two velocities, is not just the algebraic sum of two velocities (we know that it cannot be or we get in trouble), but is \u201ccorrected\u201d by 1+uv/ c 2 . Now let us see what happens. Suppose that you are moving inside the space ship at half the speed of light, and that the space ship itself is going at half the speed of light. Thus u is 1 2 c and v is 1 2 c , but in the denominator uv/ c 2 is one-fourth, so that v= 1 2 c+ 1 2 c 1+ 1 4 = 4c 5 . 1 1 So, in relativity, \u201chalf\u201d and \u201chalf\u201d does not make \u201cone,\u201d it makes only \u201c 4/5 .\u201d Of course low velocities can be added quite easily in the familiar way, because so long as the velocities are small compared with the speed of light we can forget about the (1+uv/ c 2 ) factor; but things are quite different and quite interesting at high velocity. Let us take a limiting case. Just for fun, suppose that inside the space ship the man was observing light itself. In other words, v=c , and yet the space ship is moving. How will it look to the man on the ground? The answer will be v= u+c 1+uc/ c 2 =c u+c u+c =c. + + Therefore, if something is moving at the speed of light inside the ship, it will appear to be moving at the speed of light from the point of view of the man on the ground too! This is good, for it is, in fact, what the Einstein theory of relativity was designed to do in the first place\u2014so it had better work! Of course, there are cases in which the motion is not in the direction of the uniform translation. For example, there may be an object inside the ship which is just moving \u201cupward\u201d with the velocity v y \u2032 with respect to the ship, and the ship is moving \u201chorizontally.\u201d Now, we simply go through the same thing, only using y \u2019s instead of x \u2019s, with the result y= y \u2032 = v y \u2032 t \u2032 , \u2032 \u2032 so that if v x \u2032 =0 , v y = y t = v y \u2032 1\u2212 u 2 / c 2 \u2212 \u2212 \u2212 \u2212 \u2212 \u2212 \u2212 \u2212 \u221a . (16.7) Thus a sidewise velocity is no longer v y \u2032 , but v y \u2032 1\u2212 u 2 / c 2 \u2212 \u2212 \u2212 \u2212 \u2212 \u2212 \u2212 \u2212 \u221a . We found this result by substituting and combining the transformation equations, but we can also see the result directly from the principle of relativity for the following reason (it is always good to look again to see whether we can see the reason). We have already (Fig. 15\u20133) seen how a possible clock might work when it is moving; the light appears to travel at an angle at the speed c in the fixed system, while it simply goes vertically with the same speed in the moving system. We found that the vertical component of the velocity in the fixed system is less than that of light by the factor 1\u2212 u 2 / c 2 \u2212 \u2212 \u2212 \u2212 \u2212 \u2212 \u2212 \u2212 \u221a (see Eq. 15.3). But now suppose that we let a material particle go back and forth in this same \u201cclock,\u201d but at some integral fraction 1/n of the speed of light (Fig. 16\u20131). Then when the particle has gone back and forth once, the light will have gone exactly n times. That is, each \u201cclick\u201d of the \u201cparticle\u201d clock will coincide with each n th \u201cclick\u201d of the light clock. This fact must still be true when the whole system is moving, because the physical phenomenon of coincidence will be a coincidence in any frame. Therefore, since the speed c y is less than the speed of light, the speed v y of the particle must be slower than the corresponding speed by the same square-root ratio! That is why the square root appears in any vertical velocity. We learned in the last chapter that the mass of an object increases with velocity, but no demonstration of this was given, in the sense that we made no arguments analogous to those about the way clocks have to behave. However, we can show that, as a consequence of relativity plus a few other reasonable assumptions, the mass must vary in this way. (We have to say \u201ca few other assumptions\u201d because we cannot prove anything unless we have some laws which we assume to be true, if we expect to make meaningful deductions.) To avoid the need to study the transformation laws of force, we shall analyze a collision, where we need know nothing about the laws of force, except that we shall assume the conservation of momentum and energy. Also, we shall assume that the momentum of a particle which is moving is a vector and is always directed in the direction of the velocity. However, we shall not assume that the momentum is a constant times the velocity, as Newton did, but only that it is some function of velocity. We thus write the momentum vector as a certain coefficient times the vector velocity: p= m v v. (16.8) We put a subscript v on the coefficient to remind us that it is a function of velocity, and we shall agree to call this coefficient m v the \u201cmass.\u201d Of course, when the velocity is small, it is the same mass that we would measure in the slow-moving experiments that we are used to. Now we shall try to demonstrate that the formula for m v must be m 0 / 1\u2212 v 2 / c 2 \u2212 \u2212 \u2212 \u2212 \u2212 \u2212 \u2212 \u2212 \u221a , by arguing from the principle of relativity that the laws of physics must be the same in every coordinate system. Suppose that we have two particles, like two protons, that are absolutely equal, and they are moving toward each other with exactly equal velocities. Their total momentum is zero. Now what can happen? After the collision, their directions of motion must be exactly opposite to each other, because if they are not exactly opposite, there will be a nonzero total vector momentum, and momentum would not have been conserved. Also they must have the same speeds, since they are exactly similar objects; in fact, they must have the same speed they started with, since we suppose that the energy is conserved in these collisions. So the diagram of an elastic collision, a reversible collision, will look like Fig. 16\u20132(a): all the arrows are the same length, all the speeds are equal. We shall suppose that such collisions can always be arranged, that any angle \u03b8 can occur, and that any speed could be used in such a collision. Next, we notice that this same collision can be viewed differently by turning the axes, and just for convenience we shall turn the axes, so that the horizontal splits it evenly, as in Fig. 16\u20132(b). It is the same collision redrawn, only with the axes turned. Now here is the real trick: let us look at this collision from the point of view of someone riding along in a car that is moving with a speed equal to the horizontal component of the velocity of one particle. Then how does the collision look? It looks as though particle 1 is just going straight up, because it has lost its horizontal component, and it comes straight down again, also because it does not have that component. That is, the collision appears as shown in Fig. 16\u20133(a). Particle 2 , however, was going the other way, and as we ride past it appears to fly by at some terrific speed and at a smaller angle, but we can appreciate that the angles before and after the collision are the same. Let us denote by u the horizontal component of the velocity of particle 2 , and by w the vertical velocity of particle 1 . Now the question is, what is the vertical velocity utan\u03b1 ? If we knew that, we could get the correct expression for the momentum, using the law of conservation of momentum in the vertical direction. Clearly, the horizontal component of the momentum is conserved: it is the same before and after the collision for both particles, and is zero for particle 1 . So we need to use the conservation law only for the upward velocity utan\u03b1 . But we can get the upward velocity, simply by looking at the same collision going the other way! If we look at the collision of Fig. 16\u20133(a) from a car moving to the left with speed u , we see the same collision, except \u201cturned over,\u201d as shown in Fig. 16\u20133(b). Now particle 2 is the one that goes up and down with speed w , and particle 1 has picked up the horizontal speed u . Of course, now we know what the velocity utan\u03b1 is: it is w 1\u2212 u 2 / c 2 \u2212 \u2212 \u2212 \u2212 \u2212 \u2212 \u2212 \u2212 \u221a (see Eq. 16.7). We know that the change in the vertical momentum of the vertically moving particle is \u0394p=2 m w w \u0394 2 ( 2 , because it moves up and back down). The obliquely moving particle has a certain velocity v whose components we have found to be u and w 1\u2212 u 2 / c 2 \u2212 \u2212 \u2212 \u2212 \u2212 \u2212 \u2212 \u2212 \u221a , and whose mass is m v . The change in vertical momentum of this particle is therefore \u0394 p \u2032 =2 m v w 1\u2212 u 2 / c 2 \u2212 \u2212 \u2212 \u2212 \u2212 \u2212 \u2212 \u2212 \u221a because, in accordance with our assumed law (16.8), the momentum component is always the mass corresponding to the magnitude of the velocity times the component of the velocity in the direction of interest. Thus in order for the total momentum to be zero the vertical momenta must cancel and the ratio of the mass moving with speed v and the mass moving with speed w must therefore be m w m v = 1\u2212 u 2 / c 2 \u2212 \u2212 \u2212 \u2212 \u2212 \u2212 \u2212 \u2212 \u221a . (16.9) Let us take the limiting case that w is infinitesimal. If w is very tiny indeed, it is clear that v and u are practically equal. In this case, m w \u2192 m 0 and m v \u2192 m u . The grand result is m u = m 0 1\u2212 u 2 / c 2 \u2212 \u2212 \u2212 \u2212 \u2212 \u2212 \u2212 \u2212 \u221a . (16.10) It is an interesting exercise now to check whether or not Eq. (16.9) is indeed true for arbitrary values of w , assuming that Eq. (16.10) is the right formula for the mass. Note that the velocity v needed in Eq. (16.9) can be calculated from the right-angle triangle: v 2 = u 2 + w 2 (1\u2212 u 2 / c 2 ). 2 2 2 2 2 It will be found to check out automatically, although we used it only in the limit of small w . Now, let us accept that momentum is conserved and that the mass depends upon the velocity according to (16.10) and go on to find what else we can conclude. Let us consider what is commonly called an inelastic collision. For simplicity, we shall suppose that two objects of the same kind, moving oppositely with equal speeds w , hit each other and stick together, to become some new, stationary object, as shown in Fig. 16\u20134(a). The mass m of each corresponds to w , which, as we know, is m 0 / 1\u2212 w 2 / c 2 \u2212 \u2212 \u2212 \u2212 \u2212 \u2212 \u2212 \u2212 \u221a . If we assume the conservation of momentum and the principle of relativity, we can demonstrate an interesting fact about the mass of the new object which has been formed. We imagine an infinitesimal velocity u at right angles to w (we can do the same with finite values of u , but it is easier to understand with an infinitesimal velocity), then look at this same collision as we ride by in an elevator at the velocity \u2212u . What we see is shown in Fig. 16\u20134(b). The composite object has an unknown mass M . Now object 1 moves with an upward component of velocity u and a horizontal component which is practically equal to w , and so also does object 2 . After the collision we have the mass M moving upward with velocity u , considered very small compared with the speed of light, and also small compared with w . Momentum must be conserved, so let us estimate the momentum in the upward direction before and after the collision. Before the collision we have p\u22482 m w u , and after the collision the momentum is evidently p \u2032 = M u u , but M u is essentially the same as M 0 because u is so small. These momenta must be equal because of the conservation of momentum, and therefore M 0 =2 m w . (16.11) The mass of the object which is formed when two equal objects collide must be twice the mass of the objects which come together. You might say, \u201cYes, of course, that is the conservation of mass.\u201d But not \u201cYes, of course,\u201d so easily, because these masses have been enhanced over the masses that they would be if they were standing still, yet they still contribute, to the total M , not the mass they have when standing still, but more. Astonishing as that may seem, in order for the conservation of momentum to work when two objects come together, the mass that they form must be greater than the rest masses of the objects, even though the objects are at rest after the collision! In the last chapter we demonstrated that as a result of the dependence of the mass on velocity and Newton\u2019s laws, the changes in the kinetic energy of an object resulting from the total work done by the forces on it always comes out to be \u0394T=( m u \u2212 m 0 ) c 2 = m 0 c 2 1\u2212 u 2 / c 2 \u2212 \u2212 \u2212 \u2212 \u2212 \u2212 \u2212 \u2212 \u221a \u2212 m 0 c 2 . (16.12) We even went further, and guessed that the total energy is the total mass times c 2 . Now we continue this discussion. Suppose that our two equally massive objects that collide can still be \u201cseen\u201d inside M . For instance, a proton and a neutron are \u201cstuck together,\u201d but are still moving about inside of M . Then, although we might at first expect the mass M to be 2 m 0 , we have found that it is not 2 m 0 , but 2 m w . Since 2 m w is what is put in, but 2 m 0 are the rest masses of the things inside, the excess mass of the composite object is equal to the kinetic energy brought in. This means, of course, that energy has inertia. In the last chapter we discussed the heating of a gas, and showed that because the gas molecules are moving and moving things are heavier, when we put energy into the gas its molecules move faster and so the gas gets heavier. But in fact the argument is completely general, and our discussion of the inelastic collision shows that the mass is there whether or not it is kinetic energy. In other words, if two particles come together and produce potential or any other form of energy; if the pieces are slowed down by climbing hills, doing work against internal forces, or whatever; then it is still true that the mass is the total energy that has been put in. So we see that the conservation of mass which we have deduced above is equivalent to the conservation of energy, and therefore there is no place in the theory of relativity for strictly inelastic collisions, as there was in Newtonian mechanics. According to Newtonian mechanics it is all right for two things to collide and so form an object of mass 2 m 0 which is in no way distinct from the one that would result from putting them together slowly. Of course we know from the law of conservation of energy that there is more kinetic energy inside, but that does not affect the mass, according to Newton\u2019s laws. But now we see that this is impossible; because of the kinetic energy involved in the collision, the resulting object will be heavier; therefore, it will be a different object. When we put the objects together gently they make something whose mass is 2 m 0 ; when we put them together forcefully, they make something whose mass is greater. When the mass is different, we can tell that it is different. So, necessarily, the conservation of energy must go along with the conservation of momentum in the theory of relativity. This has interesting consequences. For example, suppose that we have an object whose mass M is measured, and suppose something happens so that it flies into two equal pieces moving with speed w , so that they each have a mass m w . Now suppose that these pieces encounter enough material to slow them up until they stop; then they will have mass m 0 . How much energy will they have given to the material when they have stopped? Each will give an amount ( m w \u2212 m 0 ) c 2 , by the theorem that we proved before. This much energy is left in the material in some form, as heat, potential energy, or whatever. Now 2 m w =M , so the liberated energy is E=(M\u22122 m 0 ) c 2 . This equation was used to estimate how much energy would be liberated under fission in the atomic bomb, for example. (Although the fragments are not exactly equal, they are nearly equal.) The mass of the uranium atom was known\u2014it had been measured ahead of time\u2014and the atoms into which it split, iodine, xenon, and so on, all were of known mass. By masses, we do not mean the masses while the atoms are moving, we mean the masses when the atoms are at rest. In other words, both M and m 0 are known. So by subtracting the two numbers one can calculate how much energy will be released if M can be made to split in \u201chalf.\u201d For this reason poor old Einstein was called the \u201cfather\u201d of the atomic bomb in all the newspapers. Of course, all that meant was that he could tell us ahead of time how much energy would be released if we told him what process would occur. The energy that should be liberated when an atom of uranium undergoes fission was estimated about six months before the first direct test, and as soon as the energy was in fact liberated, someone measured it directly (and if Einstein\u2019s formula had not worked, they would have measured it anyway), and the moment they measured it they no longer needed the formula. Of course, we should not belittle Einstein, but rather should criticize the newspapers and many popular descriptions of what causes what in the history of physics and technology. The problem of how to get the thing to occur in an effective and rapid manner is a completely different matter. The result is just as significant in chemistry. For instance, if we were to weigh the carbon dioxide molecule and compare its mass with that of the carbon and the oxygen, we could find out how much energy would be liberated when carbon and oxygen form carbon dioxide. The only trouble here is that the differences in masses are so small that it is technically very difficult to do. Now let us turn to the question of whether we should add m 0 c 2 to the kinetic energy and say from now on that the total energy of an object is m c 2 . First, if we can still see the component pieces of rest mass m 0 inside M , then we could say that some of the mass M of the compound object is the mechanical rest mass of the parts, part of it is kinetic energy of the parts, and part of it is potential energy of the parts. But we have discovered, in nature, particles of various kinds which undergo reactions just like the one we have treated above, in which with all the study in the world, we cannot see the parts inside. For instance, when a K-meson disintegrates into two pions it does so according to the law (16.11), but the idea that a K is made out of 2 \u03c0 \u2019s is a useless idea, because it also disintegrates into 3 \u03c0 \u2019s! Therefore we have a new idea: we do not have to know what things are made of inside; we cannot and need not identify, inside a particle, which of the energy is rest energy of the parts into which it is going to disintegrate. It is not convenient and often not possible to separate the total m c 2 energy of an object into rest energy of the inside pieces, kinetic energy of the pieces, and potential energy of the pieces; instead, we simply speak of the total energy of the particle. We \u201cshift the origin\u201d of energy by adding a constant m 0 c 2 to everything, and say that the total energy of a particle is the mass in motion times c 2 , and when the object is standing still, the energy is the mass at rest times c 2 . Finally, we find that the velocity v , momentum P , and total energy E are related in a rather simple way. That the mass in motion at speed v is the mass m 0 at rest divided by 1\u2212 v 2 / c 2 \u2212 \u2212 \u2212 \u2212 \u2212 \u2212 \u2212 \u2212 \u221a , surprisingly enough, is rarely used. Instead, the following relations are easily proved, and turn out to be very useful: E 2 \u2212 P 2 c 2 = m 2 0 c 4 (16.13) and Pc=Ev/c. (16.14)"
    },
    {
        "input": "The Principle of Least Action",
        "output": "\u201cWhen I was in high school, my physics teacher\u2014whose name was Mr. Bader\u2014called me down one day after physics class and said, \u2018You look bored; I want to tell you something interesting.\u2019 Then he told me something which I found absolutely fascinating, and have, since then, always found fascinating. Every time the subject comes up, I work on it. In fact, when I began to prepare this lecture I found myself making more analyses on the thing. Instead of worrying about the lecture, I got involved in a new problem. The subject is this\u2014the principle of least action. \u201cMr. Bader told me the following: Suppose you have a particle (in a gravitational field, for instance) which starts somewhere and moves to some other point by free motion\u2014you throw it, and it goes up and comes down (Fig. 19\u20131). It goes from the original place to the final place in a certain amount of time. Now, you try a different motion. Suppose that to get from here to there, it went as shown in Fig. 19\u20132 but got there in just the same amount of time. Then he said this: If you calculate the kinetic energy at every moment on the path, take away the potential energy, and integrate it over the time during the whole path, you\u2019ll find that the number you\u2019ll get is bigger than that for the actual motion. \u201cIn other words, the laws of Newton could be stated not in the form F=ma but in the form: the average kinetic energy less the average potential energy is as little as possible for the path of an object going from one point to another. \u201cLet me illustrate a little bit better what it means. If you take the case of the gravitational field, then if the particle has the path x(t) (let\u2019s just take one dimension for a moment; we take a trajectory that goes up and down and not sideways), where x is the height above the ground, the kinetic energy is 1 2 m(dx/dt)2 , and the potential energy at any time is mgx . Now I take the kinetic energy minus the potential energy at every moment along the path and integrate that with respect to time from the initial time to the final time. Let\u2019s suppose that at the original time t1 we started at some height and at the end of the time t2 we are definitely ending at some other place (Fig. 19\u20133). \u201cThen the integral is \u222b t2 t1 [ 1 2 m( dx dt )2\u2212mgx]dt. The actual motion is some kind of a curve\u2014it\u2019s a parabola if we plot against the time\u2014and gives a certain value for the integral. But we could imagine some other motion that went very high and came up and down in some peculiar way (Fig. 19\u20134). We can calculate the kinetic energy minus the potential energy and integrate for such a path \u2026 or for any other path we want. The miracle is that the true path is the one for which that integral is least. \u201cLet\u2019s try it out. First, suppose we take the case of a free particle for which there is no potential energy at all. Then the rule says that in going from one point to another in a given amount of time, the kinetic energy integral is least, so it must go at a uniform speed. (We know that\u2019s the right answer\u2014to go at a uniform speed.) Why is that? Because if the particle were to go any other way, the velocities would be sometimes higher and sometimes lower than the average. The average velocity is the same for every case because it has to get from \u2018here\u2019 to \u2018there\u2019 in a given amount of time. \u201cAs an example, say your job is to start from home and get to school in a given length of time with the car. You can do it several ways: You can accelerate like mad at the beginning and slow down with the brakes near the end, or you can go at a uniform speed, or you can go backwards for a while and then go forward, and so on. The thing is that the average speed has got to be, of course, the total distance that you have gone over the time. But if you do anything but go at a uniform speed, then sometimes you are going too fast and sometimes you are going too slow. Now the mean square of something that deviates around an average, as you know, is always greater than the square of the mean; so the kinetic energy integral would always be higher if you wobbled your velocity than if you went at a uniform velocity. So we see that the integral is a minimum if the velocity is a constant (when there are no forces). The correct path is shown in Fig. 19\u20135. \u201cNow, an object thrown up in a gravitational field does rise faster first and then slow down. That is because there is also the potential energy, and we must have the least difference of kinetic and potential energy on the average. Because the potential energy rises as we go up in space, we will get a lower difference if we can get as soon as possible up to where there is a high potential energy. Then we can take that potential away from the kinetic energy and get a lower average. So it is better to take a path which goes up and gets a lot of negative stuff from the potential energy (Fig. 19\u20136). \u201cOn the other hand, you can\u2019t go up too fast, or too far, because you will then have too much kinetic energy involved\u2014you have to go very fast to get way up and come down again in the fixed amount of time available. So you don\u2019t want to go too far up, but you want to go up some. So it turns out that the solution is some kind of balance between trying to get more potential energy with the least amount of extra kinetic energy\u2014trying to get the difference, kinetic minus the potential, as small as possible. \u201cThat is all my teacher told me, because he was a very good teacher and knew when to stop talking. But I don\u2019t know when to stop talking. So instead of leaving it as an interesting remark, I am going to horrify and disgust you with the complexities of life by proving that it is so. The kind of mathematical problem we will have is very difficult and a new kind. We have a certain quantity which is called the action, S . It is the kinetic energy, minus the potential energy, integrated over time. Action=S=\u222b t2 t1 (KE\u2212PE)dt. Remember that the PE and KE are both functions of time. For each different possible path you get a different number for this action. Our mathematical problem is to find out for what curve that number is the least. \u201cYou say\u2014Oh, that\u2019s just the ordinary calculus of maxima and minima. You calculate the action and just differentiate to find the minimum. \u201cBut watch out. Ordinarily we just have a function of some variable, and we have to find the value of that variable where the function is least or most. For instance, we have a rod which has been heated in the middle and the heat is spread around. For each point on the rod we have a temperature, and we must find the point at which that temperature is largest. But now for each path in space we have a number\u2014quite a different thing\u2014and we have to find the path in space for which the number is the minimum. That is a completely different branch of mathematics. It is not the ordinary calculus. In fact, it is called the calculus of variations. \u201cThere are many problems in this kind of mathematics. For example, the circle is usually defined as the locus of all points at a constant distance from a fixed point, but another way of defining a circle is this: a circle is that curve of given length which encloses the biggest area. Any other curve encloses less area for a given perimeter than the circle does. So if we give the problem: find that curve which encloses the greatest area for a given perimeter, we would have a problem of the calculus of variations\u2014a different kind of calculus than you\u2019re used to. \u201cSo we make the calculation for the path of an object. Here is the way we are going to do it. The idea is that we imagine that there is a true path and that any other curve we draw is a false path, so that if we calculate the action for the false path we will get a value that is bigger than if we calculate the action for the true path (Fig. 19\u20137). \u201cProblem: Find the true path. Where is it? One way, of course, is to calculate the action for millions and millions of paths and look at which one is lowest. When you find the lowest one, that\u2019s the true path. \u201cThat\u2019s a possible way. But we can do it better than that. When we have a quantity which has a minimum\u2014for instance, in an ordinary function like the temperature\u2014one of the properties of the minimum is that if we go away from the minimum in the first order, the deviation of the function from its minimum value is only second order. At any place else on the curve, if we move a small distance the value of the function changes also in the first order. But at a minimum, a tiny motion away makes, in the first approximation, no difference (Fig. 19\u20138). \u201cThat is what we are going to use to calculate the true path. If we have the true path, a curve which differs only a little bit from it will, in the first approximation, make no difference in the action. Any difference will be in the second approximation, if we really have a minimum. \u201cThat is easy to prove. If there is a change in the first order when I deviate the curve a certain way, there is a change in the action that is proportional to the deviation. The change presumably makes the action greater; otherwise we haven\u2019t got a minimum. But then if the change is proportional to the deviation, reversing the sign of the deviation will make the action less. We would get the action to increase one way and to decrease the other way. The only way that it could really be a minimum is that in the first approximation it doesn\u2019t make any change, that the changes are proportional to the square of the deviations from the true path. \u201cSo we work it this way: We call x(t) \u2212 \u2212 \u2212 (with an underline) the true path\u2014the one we are trying to find. We take some trial path x(t) that differs from the true path by a small amount which we will call \u03b7(t) (eta of t ; Fig. 19\u20139). \u201cNow the idea is that if we calculate the action S for the path x(t) , then the difference between that S and the action that we calculated for the path x(t) \u2212 \u2212 \u2212 \u2014to simplify the writing we can call it S \u2212 \u2212 \u2014the difference of S \u2212 \u2212 and S must be zero in the first-order approximation of small \u03b7 . It can differ in the second order, but in the first order the difference must be zero. \u201cAnd that must be true for any \u03b7 at all. Well, not quite. The method doesn\u2019t mean anything unless you consider paths which all begin and end at the same two points\u2014each path begins at a certain point at t 1 and ends at a certain other point at t 2 , and those points and times are kept fixed. So the deviations in our \u03b7 have to be zero at each end, \u03b7( t 1 )=0 and \u03b7( t 2 )=0 . With that condition, we have specified our mathematical problem. \u201cIf you didn\u2019t know any calculus, you might do the same kind of thing to find the minimum of an ordinary function f(x) . You could discuss what happens if you take f(x) and add a small amount h to x and argue that the correction to f(x) in the first order in h must be zero at the minimum. You would substitute x+h for x and expand out to the first order in h \u2026 just as we are going to do with \u03b7 . \u201cThe idea is then that we substitute x(t)= x(t) \u2212 \u2212 \u2212 +\u03b7(t) in the formula for the action: S=\u222b[ m 2 ( dx dt ) 2 \u2212V(x)]dt, \u222b where I call the potential energy V(x) . The derivative dx/dt is, of course, the derivative of x(t) \u2212 \u2212 \u2212 plus the derivative of \u03b7(t) , so for the action I get this expression: S= \u222b t 2 t 1 [ m 2 ( d x \u2212 \u2212 dt + d\u03b7 dt ) 2 \u2212V( x \u2212 \u2212 +\u03b7)]dt. t \u201cNow I must write this out in more detail. For the squared term I get ( d x \u2212 \u2212 dt ) 2 +2 d x \u2212 \u2212 dt d\u03b7 dt +( d\u03b7 dt ) 2 . d d d d But wait. I\u2019m not worrying about higher than the first order, so I will take all the terms which involve \u03b7 2 and higher powers and put them in a little box called \u2018second and higher order.\u2019 From this term I get only second order, but there will be more from something else. So the kinetic energy part is m 2 ( d x \u2212 \u2212 dt ) 2 +m d x \u2212 \u2212 dt d\u03b7 dt +(second and higher order). d d d \u201cNow we need the potential V at x \u2212 \u2212 +\u03b7 . I consider \u03b7 small, so I can write V(x) as a Taylor series. It is approximately V( x \u2212 \u2212 ) ; in the next approximation (from the ordinary nature of derivatives) the correction is \u03b7 times the rate of change of V with respect to x , and so on: V( x \u2212 \u2212 +\u03b7)=V( x \u2212 \u2212 )+\u03b7 V \u2032 ( x \u2212 \u2212 )+ \u03b7 2 2 V \u2032\u2032 ( x \u2212 \u2212 )+\u22ef 2 I have written V \u2032 for the derivative of V with respect to x in order to save writing. The term in \u03b7 2 and the ones beyond fall into the \u2018second and higher order\u2019 category and we don\u2019t have to worry about them. Putting it all together, S= \u222b t 2 t 1 [ m 2 ( d x \u2212 \u2212 dt ) 2 \u2212V( x \u2212 \u2212 )+m d x \u2212 \u2212 dt d\u03b7 dt \u2212\u03b7 V \u2032 ( x \u2212 \u2212 )+(second and higher order)]dt. Now if we look carefully at the thing, we see that the first two terms which I have arranged here correspond to the action S \u2212 \u2212 that I would have calculated with the true path x \u2212 \u2212 . The thing I want to concentrate on is the change in S \u2014the difference between the S and the S \u2212 \u2212 that we would get for the right path. This difference we will write as \u03b4S , called the variation in S . Leaving out the \u2018second and higher order\u2019 terms, I have for \u03b4S \u03b4S= \u222b t 2 t 1 [m d x \u2212 \u2212 dt d\u03b7 dt \u2212\u03b7 V \u2032 ( x \u2212 \u2212 )]dt. t \u201cNow the problem is this: Here is a certain integral. I don\u2019t know what the x \u2212 \u2212 is yet, but I do know that no matter what \u03b7 is, this integral must be zero. Well, you think, the only way that that can happen is that what multiplies \u03b7 must be zero. But what about the first term with d\u03b7/dt ? Well, after all, if \u03b7 can be anything at all, its derivative is anything also, so you conclude that the coefficient of d\u03b7/dt must also be zero. That isn\u2019t quite right. It isn\u2019t quite right because there is a connection between \u03b7 and its derivative; they are not absolutely independent, because \u03b7(t) must be zero at both t 1 and t 2 . \u201cThe method of solving all problems in the calculus of variations always uses the same general principle. You make the shift in the thing you want to vary (as we did by adding \u03b7 ); you look at the first-order terms; then you always arrange things in such a form that you get an integral of the form \u2018some kind of stuff times the shift (\u03b7) ,\u2019 but with no other derivatives (no d\u03b7/dt ). It must be rearranged so it is always \u2018something\u2019 times \u03b7 . You will see the great value of that in a minute. (There are formulas that tell you how to do this in some cases without actually calculating, but they are not general enough to be worth bothering about; the best way is to calculate it out this way.) \u201cHow can I rearrange the term in d\u03b7/dt to make it have an \u03b7 ? I can do that by integrating by parts. It turns out that the whole trick of the calculus of variations consists of writing down the variation of S and then integrating by parts so that the derivatives of \u03b7 disappear. It is always the same in every problem in which derivatives appear. \u201cYou remember the general principle for integrating by parts. If you have any function f times d\u03b7/dt integrated with respect to t , you write down the derivative of \u03b7f : d dt (\u03b7f)=\u03b7 df dt +f d\u03b7 dt . d d f d The integral you want is over the last term, so \u222bf d\u03b7 dt dt=\u03b7f\u2212\u222b\u03b7 df dt dt. \u222b \u222b \u201cIn our formula for \u03b4S , the function f is m times d x \u2212 \u2212 /dt ; therefore, I have the following formula for \u03b4S . \u03b4S= m d x \u2212 \u2212 dt \u03b7(t) \u2223 \u2223 \u2223 t 2 t 1 \u2212 \u222b t 2 t 1 d dt (m d x \u2212 \u2212 dt )\u03b7(t) \u2212 \u222b t 2 t 1 V \u2032 ( x \u2212 \u2212 )\u03b7(t) dt dt. The first term must be evaluated at the two limits t 1 and t 2 . Then I must have the integral from the rest of the integration by parts. The last term is brought down without change. \u201cNow comes something which always happens\u2014the integrated part disappears. (In fact, if the integrated part does not disappear, you restate the principle, adding conditions to make sure it does!) We have already said that \u03b7 must be zero at both ends of the path, because the principle is that the action is a minimum provided that the varied curve begins and ends at the chosen points. The condition is that \u03b7( t 1 )=0 , and \u03b7( t 2 )=0 . So the integrated term is zero. We collect the other terms together and obtain this: \u03b4S= \u222b t 2 t 1 [\u2212m d 2 x \u2212 \u2212 d t 2 \u2212 V \u2032 ( x \u2212 \u2212 )]\u03b7(t)dt. t 2 The variation in S is now the way we wanted it\u2014there is the stuff in brackets, say F , all multiplied by \u03b7(t) and integrated from t 1 to t 2 . \u201cWe have that an integral of something or other times \u03b7(t) is always zero: \u222bF(t)\u03b7(t)dt=0. \u222b I have some function of t ; I multiply it by \u03b7(t) ; and I integrate it from one end to the other. And no matter what the \u03b7 is, I get zero. That means that the function F(t) is zero. That\u2019s obvious, but anyway I\u2019ll show you one kind of proof. \u201cSuppose that for \u03b7(t) I took something which was zero for all t except right near one particular value. It stays zero until it gets to this t , then it blips up for a moment and blips right back down (Fig. 19\u201310). When we do the integral of this \u03b7 times any function F , the only place that you get anything other than zero was where \u03b7(t) was blipping, and then you get the value of F at that place times the integral over the blip. The integral over the blip alone isn\u2019t zero, but when multiplied by F it has to be; so the function F has to be zero where the blip was. But the blip was anywhere I wanted to put it, so F must be zero everywhere. \u201cWe see that if our integral is zero for any \u03b7 , then the coefficient of \u03b7 must be zero. The action integral will be a minimum for the path that satisfies this complicated differential equation: [\u2212m d 2 x \u2212 \u2212 d t 2 \u2212 V \u2032 ( x \u2212 \u2212 )]=0. 2 It\u2019s not really so complicated; you have seen it before. It is just F=ma . The first term is the mass times acceleration, and the second is the derivative of the potential energy, which is the force. \u201cSo, for a conservative system at least, we have demonstrated that the principle of least action gives the right answer; it says that the path that has the minimum action is the one satisfying Newton\u2019s law. \u201cOne remark: I did not prove it was a minimum\u2014maybe it\u2019s a maximum. In fact, it doesn\u2019t really have to be a minimum. It is quite analogous to what we found for the \u2018principle of least time\u2019 which we discussed in optics. There also, we said at first it was \u2018least\u2019 time. It turned out, however, that there were situations in which it wasn\u2019t the least time. The fundamental principle was that for any first-order variation away from the optical path, the change in time was zero; it is the same story. What we really mean by \u2018least\u2019 is that the first-order change in the value of S , when you change the path, is zero. It is not necessarily a \u2018minimum.\u2019 \u201cNext, I remark on some generalizations. In the first place, the thing can be done in three dimensions. Instead of just x , I would have x , y , and z as functions of t ; the action is more complicated. For three-dimensional motion, you have to use the complete kinetic energy\u2014 (m/2) times the whole velocity squared. That is, KE= m 2 [( dx dt ) 2 +( dy dt ) 2 +( dz dt ) 2 ]. d d d Also, the potential energy is a function of x , y , and z . And what about the path? The path is some general curve in space, which is not so easily drawn, but the idea is the same. And what about the \u03b7 ? Well, \u03b7 can have three components. You could shift the paths in x , or in y , or in z \u2014or you could shift in all three directions simultaneously. So \u03b7 would be a vector. This doesn\u2019t really complicate things too much, though. Since only the first-order variation has to be zero, we can do the calculation by three successive shifts. We can shift \u03b7 only in the x -direction and say that coefficient must be zero. We get one equation. Then we shift it in the y -direction and get another. And in the z -direction and get another. Or, of course, in any order that you want. Anyway, you get three equations. And, of course, Newton\u2019s law is really three equations in the three dimensions\u2014one for each component. I think that you can practically see that it is bound to work, but we will leave you to show for yourself that it will work for three dimensions. Incidentally, you could use any coordinate system you want, polar or otherwise, and get Newton\u2019s laws appropriate to that system right off by seeing what happens if you have the shift \u03b7 in radius, or in angle, etc. \u201cSimilarly, the method can be generalized to any number of particles. If you have, say, two particles with a force between them, so that there is a mutual potential energy, then you just add the kinetic energy of both particles and take the potential energy of the mutual interaction. And what do you vary? You vary the paths of both particles. Then, for two particles moving in three dimensions, there are six equations. You can vary the position of particle 1 in the x -direction, in the y -direction, and in the z -direction, and similarly for particle 2 ; so there are six equations. And that\u2019s as it should be. There are the three equations that determine the acceleration of particle 1 in terms of the force on it and three for the acceleration of particle 2 , from the force on it. You follow the same game through, and you get Newton\u2019s law in three dimensions for any number of particles. \u201cI have been saying that we get Newton\u2019s law. That is not quite true, because Newton\u2019s law includes nonconservative forces like friction. Newton said that ma is equal to any F . But the principle of least action only works for conservative systems\u2014where all forces can be gotten from a potential function. You know, however, that on a microscopic level\u2014on the deepest level of physics\u2014there are no nonconservative forces. Nonconservative forces, like friction, appear only because we neglect microscopic complications\u2014there are just too many particles to analyze. But the fundamental laws can be put in the form of a principle of least action. \u201cLet me generalize still further. Suppose we ask what happens if the particle moves relativistically. We did not get the right relativistic equation of motion; F=ma is only right nonrelativistically. The question is: Is there a corresponding principle of least action for the relativistic case? There is. The formula in the case of relativity is the following: S=\u2212 m 0 c 2 \u2212q \u222b t 2 t 1 1\u2212 v 2 / c 2 \u2212 \u2212 \u2212 \u2212 \u2212 \u2212 \u2212 \u2212 \u221a dt \u222b t 2 t 1 [\u03d5(x,y,z,t)\u2212v\u22c5A(x,y,z,t)]dt. The first part of the action integral is the rest mass m 0 times c 2 times the integral of a function of velocity, 1\u2212 v 2 / c 2 \u2212 \u2212 \u2212 \u2212 \u2212 \u2212 \u2212 \u2212 \u221a . Then instead of just the potential energy, we have an integral over the scalar potential \u03d5 and over v times the vector potential A . Of course, we are then including only electromagnetic forces. All electric and magnetic fields are given in terms of \u03d5 and A . This action function gives the complete theory of relativistic motion of a single particle in an electromagnetic field. \u201cOf course, wherever I have written v , you understand that before you try to figure anything out, you must substitute dx/dt for v x and so on for the other components. Also, you put the point along the path at time t , x(t) , y(t) , z(t) where I wrote simply x , y , z . Properly, it is only after you have made those replacements for the v \u2019s that you have the formula for the action for a relativistic particle. I will leave to the more ingenious of you the problem to demonstrate that this action formula does, in fact, give the correct equations of motion for relativity. May I suggest you do it first without the A , that is, for no magnetic field? Then you should get the components of the equation of motion, dp/dt=\u2212q\u2207\u03d5 , where, you remember, p= m 0 v/ 1\u2212 v 2 / c 2 \u2212 \u2212 \u2212 \u2212 \u2212 \u2212 \u2212 \u2212 \u221a . \u201cIt is much more difficult to include also the case with a vector potential. The variations get much more complicated. But in the end, the force term does come out equal to q(E+v\u00d7B) , as it should. But I will leave that for you to play with. \u201cI would like to emphasize that in the general case, for instance in the relativistic formula, the action integrand no longer has the form of the kinetic energy minus the potential energy. That\u2019s only true in the nonrelativistic approximation. For example, the term m 0 c 2 1\u2212 v 2 / c 2 \u2212 \u2212 \u2212 \u2212 \u2212 \u2212 \u2212 \u2212 \u221a is not what we have called the kinetic energy. The question of what the action should be for any particular case must be determined by some kind of trial and error. It is just the same problem as determining what are the laws of motion in the first place. You just have to fiddle around with the equations that you know and see if you can get them into the form of the principle of least action. \u201cOne other point on terminology. The function that is integrated over time to get the action S is called the Lagrangian, L , which is a function only of the velocities and positions of particles. So the principle of least action is also written S= \u222b t 2 t 1 L( x i , v i )dt, t where by x i and v i are meant all the components of the positions and velocities. So if you hear someone talking about the \u2018Lagrangian,\u2019 you know they are talking about the function that is used to find S . For relativistic motion in an electromagnetic field L=\u2212 m 0 c 2 1\u2212 v 2 / c 2 \u2212 \u2212 \u2212 \u2212 \u2212 \u2212 \u2212 \u2212 \u221a \u2212q(\u03d5\u2212v\u22c5A). \u201cAlso, I should say that S is not really called the \u2018action\u2019 by the most precise and pedantic people. It is called \u2018Hamilton\u2019s first principal function.\u2019 Now I hate to give a lecture on \u2018the-principle-of-least-Hamilton\u2019s-first-principal-function.\u2019 So I call it \u2018the action.\u2019 Also, more and more people are calling it the action. You see, historically something else which is not quite as useful was called the action, but I think it\u2019s more sensible to change to a newer definition. So now you too will call the new function the action, and pretty soon everybody will call it by that simple name. \u201cNow I want to say some things on this subject which are similar to the discussions I gave about the principle of least time. There is quite a difference in the characteristic of a law which says a certain integral from one place to another is a minimum\u2014which tells something about the whole path\u2014and of a law which says that as you go along, there is a force that makes it accelerate. The second way tells how you inch your way along the path, and the other is a grand statement about the whole path. In the case of light, we talked about the connection of these two. Now, I would like to explain why it is true that there are differential laws when there is a least action principle of this kind. The reason is the following: Consider the actual path in space and time. As before, let\u2019s take only one dimension, so we can plot the graph of x as a function of t . Along the true path, S is a minimum. Let\u2019s suppose that we have the true path and that it goes through some point a in space and time, and also through another nearby point b (Fig. 19\u201311). Now if the entire integral from t 1 to t 2 is a minimum, it is also necessary that the integral along the little section from a to b is also a minimum. It can\u2019t be that the part from a to b is a little bit more. Otherwise you could just fiddle with just that piece of the path and make the whole integral a little lower. \u201cSo every subsection of the path must also be a minimum. And this is true no matter how short the subsection. Therefore, the principle that the whole path gives a minimum can be stated also by saying that an infinitesimal section of path also has a curve such that it has a minimum action. Now if we take a short enough section of path\u2014between two points a and b very close together\u2014how the potential varies from one place to another far away is not the important thing, because you are staying almost in the same place over the whole little piece of the path. The only thing that you have to discuss is the first-order change in the potential. The answer can only depend on the derivative of the potential and not on the potential everywhere. So the statement about the gross property of the whole path becomes a statement of what happens for a short section of the path\u2014a differential statement. And this differential statement only involves the derivatives of the potential, that is, the force at a point. That\u2019s the qualitative explanation of the relation between the gross law and the differential law. \u201cIn the case of light we also discussed the question: How does the particle find the right path? From the differential point of view, it is easy to understand. Every moment it gets an acceleration and knows only what to do at that instant. But all your instincts on cause and effect go haywire when you say that the particle decides to take the path that is going to give the minimum action. Does it \u2018smell\u2019 the neighboring paths to find out whether or not they have more action? In the case of light, when we put blocks in the way so that the photons could not test all the paths, we found that they couldn\u2019t figure out which way to go, and we had the phenomenon of diffraction. \u201cIs the same thing true in mechanics? Is it true that the particle doesn\u2019t just \u2018take the right path\u2019 but that it looks at all the other possible trajectories? And if by having things in the way, we don\u2019t let it look, that we will get an analog of diffraction? The miracle of it all is, of course, that it does just that. That\u2019s what the laws of quantum mechanics say. So our principle of least action is incompletely stated. It isn\u2019t that a particle takes the path of least action but that it smells all the paths in the neighborhood and chooses the one that has the least action by a method analogous to the one by which light chose the shortest time. You remember that the way light chose the shortest time was this: If it went on a path that took a different amount of time, it would arrive at a different phase. And the total amplitude at some point is the sum of contributions of amplitude for all the different ways the light can arrive. All the paths that give wildly different phases don\u2019t add up to anything. But if you can find a whole sequence of paths which have phases almost all the same, then the little contributions will add up and you get a reasonable total amplitude to arrive. The important path becomes the one for which there are many nearby paths which give the same phase. \u201cIt is just exactly the same thing for quantum mechanics. The complete quantum mechanics (for the nonrelativistic case and neglecting electron spin) works as follows: The probability that a particle starting at point 1 at the time t 1 will arrive at point 2 at the time t 2 is the square of a probability amplitude. The total amplitude can be written as the sum of the amplitudes for each possible path\u2014for each way of arrival. For every x(t) that we could have\u2014for every possible imaginary trajectory\u2014we have to calculate an amplitude. Then we add them all together. What do we take for the amplitude for each path? Our action integral tells us what the amplitude for a single path ought to be. The amplitude is proportional to some constant times e iS/\u210f , where S is the action for that path. That is, if we represent the phase of the amplitude by a complex number, the phase angle is S/\u210f . The action S has dimensions of energy times time, and Planck\u2019s constant \u210f has the same dimensions. It is the constant that determines when quantum mechanics is important. \u201cHere is how it works: Suppose that for all paths, S is very large compared to \u210f . One path contributes a certain amplitude. For a nearby path, the phase is quite different, because with an enormous S even a small change in S means a completely different phase\u2014because \u210f is so tiny. So nearby paths will normally cancel their effects out in taking the sum\u2014except for one region, and that is when a path and a nearby path all give the same phase in the first approximation (more precisely, the same action within \u210f ). Only those paths will be the important ones. So in the limiting case in which Planck\u2019s constant \u210f goes to zero, the correct quantum-mechanical laws can be summarized by simply saying: \u2018Forget about all these probability amplitudes. The particle does go on a special path, namely, that one for which S does not vary in the first approximation.\u2019 That\u2019s the relation between the principle of least action and quantum mechanics. The fact that quantum mechanics can be formulated in this way was discovered in 1942 by a student of that same teacher, Bader, I spoke of at the beginning of this lecture. [Quantum mechanics was originally formulated by giving a differential equation for the amplitude (Schr\u00f6dinger) and also by some other matrix mathematics (Heisenberg).] \u201cNow I want to talk about other minimum principles in physics. There are many very interesting ones. I will not try to list them all now but will only describe one more. Later on, when we come to a physical phenomenon which has a nice minimum principle, I will tell about it then. I want now to show that we can describe electrostatics, not by giving a differential equation for the field, but by saying that a certain integral is a maximum or a minimum. First, let\u2019s take the case where the charge density is known everywhere, and the problem is to find the potential \u03d5 everywhere in space. You know that the answer should be \u2207 2 \u03d5=\u2212\u03c1/ \u03f5 0 . 2 But another way of stating the same thing is this: Calculate the integral U \u2217 , where U \u2217 = \u03f5 0 2 \u222b(\u2207\u03d5 ) 2 dV\u2212\u222b\u03c1\u03d5dV, \u222b \u222b which is a volume integral to be taken over all space. This thing is a minimum for the correct potential distribution \u03d5(x,y,z) . \u201cWe can show that the two statements about electrostatics are equivalent. Let\u2019s suppose that we pick any function \u03d5 . We want to show that when we take for \u03d5 the correct potential \u03d5 \u2212 \u2212 , plus a small deviation f , then in the first order, the change in U \u2217 is zero. So we write \u03d5= \u03d5 \u2212 \u2212 +f. \u03d5 \u03d5 f The \u03d5 \u2212 \u2212 is what we are looking for, but we are making a variation of it to find what it has to be so that the variation of U \u2217 is zero to first order. For the first part of U \u2217 , we need (\u2207\u03d5 ) 2 =(\u2207 \u03d5 \u2212 \u2212 ) 2 +2\u2207 \u03d5 \u2212 \u2212 \u22c5\u2207f+(\u2207f ) 2 . 2 2 2 The only first-order term that will vary is 2\u2207 \u03d5 \u2212 \u2212 \u22c5\u2207f. \u2207 \u03d5 \u2207 f In the second term of the quantity U \u2217 , the integrand is \u03c1\u03d5=\u03c1 \u03d5 \u2212 \u2212 +\u03c1f, \u03d5 \u03d5 f whose variable part is \u03c1f . So, keeping only the variable parts, we need the integral \u0394 U \u2217 =\u222b( \u03f5 0 \u2207 \u03d5 \u2212 \u2212 \u22c5\u2207f\u2212\u03c1f)dV. \u222b \u201cNow, following the old general rule, we have to get the darn thing all clear of derivatives of f . Let\u2019s look at what the derivatives are. The dot product is \u2202 \u03d5 \u2212 \u2212 \u2202x \u2202f \u2202x + \u2202 \u03d5 \u2212 \u2212 \u2202y \u2202f \u2202y + \u2202 \u03d5 \u2212 \u2212 \u2202z \u2202f \u2202z , \u2202 \u03d5 \u2202 \u03d5 \u2202 \u03d5 which we have to integrate with respect to x , to y , and to z . Now here is the trick: to get rid of \u2202f/\u2202x we integrate by parts with respect to x . That will carry the derivative over onto the \u03d5 \u2212 \u2212 . It\u2019s the same general idea we used to get rid of derivatives with respect to t . We use the equality \u222b \u2202 \u03d5 \u2212 \u2212 \u2202x \u2202f \u2202x dx=f \u2202 \u03d5 \u2212 \u2212 \u2202x \u2212\u222bf \u2202 2 \u03d5 \u2212 \u2212 \u2202 x 2 dx. 2 The integrated term is zero, since we have to make f zero at infinity. (That corresponds to making \u03b7 zero at t 1 and t 2 . So our principle should be more accurately stated: U \u2217 is less for the true \u03d5 than for any other \u03d5(x,y,z) having the same values at infinity.) Then we do the same thing for y and z . So our integral \u0394 U \u2217 is \u0394 U \u2217 =\u222b(\u2212 \u03f5 0 \u2207 2 \u03d5 \u2212 \u2212 \u2212\u03c1)fdV. \u222b In order for this variation to be zero for any f , no matter what, the coefficient of f must be zero and, therefore, \u2207 2 \u03d5 \u2212 \u2212 =\u2212\u03c1/ \u03f5 0 . 2 We get back our old equation. So our \u2018minimum\u2019 proposition is correct. \u201cWe can generalize our proposition if we do our algebra in a little different way. Let\u2019s go back and do our integration by parts without taking components. We start by looking at the following equality: \u2207\u22c5(f\u2207 \u03d5 \u2212 \u2212 )=\u2207f\u22c5\u2207 \u03d5 \u2212 \u2212 +f \u2207 2 \u03d5 \u2212 \u2212 . 2 If I differentiate out the left-hand side, I can show that it is just equal to the right-hand side. Now we can use this equation to integrate by parts. In our integral \u0394 U \u2217 , we replace \u2207 \u03d5 \u2212 \u2212 \u22c5\u2207f by \u2207\u22c5(f\u2207 \u03d5 \u2212 \u2212 )\u2212f \u2207 2 \u03d5 \u2212 \u2212 , which gets integrated over volume. The divergence term integrated over volume can be replaced by a surface integral: \u222b\u2207\u22c5(f\u2207 \u03d5 \u2212 \u2212 )dV=\u222bf\u2207 \u03d5 \u2212 \u2212 \u22c5nda. \u222b \u222b Since we are integrating over all space, the surface over which we are integrating is at infinity. There, f is zero and we get the same answer as before. \u201cOnly now we see how to solve a problem when we don\u2019t know where all the charges are. Suppose that we have conductors with charges spread out on them in some way. We can still use our minimum principle if the potentials of all the conductors are fixed. We carry out the integral for U \u2217 only in the space outside of all conductors. Then, since we can\u2019t vary \u03d5 \u2212 \u2212 on the conductor, f is zero on all those surfaces, and the surface integral \u222bf\u2207 \u03d5 \u2212 \u2212 \u22c5nda \u222b is still zero. The remaining volume integral \u0394 U \u2217 =\u222b(\u2212 \u03f5 0 \u2207 2 \u03d5 \u2212 \u2212 \u2212\u03c1)fdV \u222b is only to be carried out in the spaces between conductors. Of course, we get Poisson\u2019s equation again, \u2207 2 \u03d5 \u2212 \u2212 =\u2212\u03c1/ \u03f5 0 . 2 So we have shown that our original integral U \u2217 is also a minimum if we evaluate it over the space outside of conductors all at fixed potentials (that is, such that any trial \u03d5(x,y,z) must equal the given potential of the conductors when (x,y,z) is a point on the surface of a conductor). \u201cThere is an interesting case when the only charges are on conductors. Then U \u2217 = \u03f5 0 2 \u222b(\u2207\u03d5 ) 2 dV. \u222b Our minimum principle says that in the case where there are conductors set at certain given potentials, the potential between them adjusts itself so that integral U \u2217 is least. What is this integral? The term \u2207\u03d5 is the electric field, so the integral is the electrostatic energy. The true field is the one, of all those coming from the gradient of a potential, with the minimum total energy. \u201cI would like to use this result to calculate something particular to show you that these things are really quite practical. Suppose I take two conductors in the form of a cylindrical condenser (Fig. 19\u201312). The inside conductor has the potential V , and the outside is at the potential zero. Let the radius of the inside conductor be a and that of the outside, b . Now we can suppose any distribution of potential between the two. If we use the correct \u03d5 \u2212 \u2212 , and calculate \u03f5 0 /2\u222b(\u2207 \u03d5 \u2212 \u2212 ) 2 dV , it should be the energy of the system, 1 2 C V 2 . So we can also calculate C by our principle. But if we use a wrong distribution of potential and try to calculate the capacity C by this method, we will get a capacity that is too big, since V is specified. Any assumed potential \u03d5 that is not the exactly correct one will give a fake C that is larger than the correct value. But if my false \u03d5 is any rough approximation, the C will be a good approximation, because the error in C is second order in the error in \u03d5 . \u201cSuppose I don\u2019t know the capacity of a cylindrical condenser. I can use this principle to find it. I just guess at the potential function \u03d5 until I get the lowest C . Suppose, for instance, I pick a potential that corresponds to a constant field. (You know, of course, that the field isn\u2019t really constant here; it varies as 1/r .) A field which is constant means a potential which goes linearly with distance. To fit the conditions at the two conductors, it must be \u03d5=V(1\u2212 r\u2212a b\u2212a ). ( ) This function is V at r=a , zero at r=b , and in between has a constant slope equal to \u2212V/(b\u2212a) . So what one does to find the integral U \u2217 is multiply the square of this gradient by \u03f5 0 /2 and integrate over all volume. Let\u2019s do this calculation for a cylinder of unit length. A volume element at the radius r is 2\u03c0rdr . Doing the integral, I find that my first try at the capacity gives 1 2 C V 2 (first try)= \u03f5 0 2 \u222b b a V 2 (b\u2212a ) 2 2\u03c0rdr. b The integral is easy; it is just \u03c0 V 2 ( b+a b\u2212a ). b So I have a formula for the capacity which is not the true one but is an approximate job: C 2\u03c0 \u03f5 0 = b+a 2(b\u2212a) . C b It is, naturally, different from the correct answer C=2\u03c0 \u03f5 0 /ln(b/a) , but it\u2019s not too bad. Let\u2019s compare it with the right answer for several values of b/a . I have computed out the answers in Table 19\u20131. Even when b/a is as big as 2 \u2014which gives a pretty big variation in the field compared with a linearly varying field\u2014I get a pretty fair approximation. The answer is, of course, a little too high, as expected. The thing gets much worse if you have a tiny wire inside a big cylinder. Then the field has enormous variations and if you represent it by a constant, you\u2019re not doing very well. With b/a=100 , we\u2019re off by nearly a factor of two. Things are much better for small b/a . To take the opposite extreme, when the conductors are not very far apart\u2014say b/a=1.1 \u2014then the constant field is a pretty good approximation, and we get the correct value for C to within a tenth of a percent. \u201cNow I would like to tell you how to improve such a calculation. (Of course, you know the right answer for the cylinder, but the method is the same for some other odd shapes, where you may not know the right answer.) The next step is to try a better approximation to the unknown true \u03d5 . For example, we might try a constant plus an exponential \u03d5 , etc. But how do you know when you have a better approximation unless you know the true \u03d5 ? Answer: You calculate C ; the lowest C is the value nearest the truth. Let us try this idea out. Suppose that the potential is not linear but say quadratic in r \u2014that the electric field is not constant but linear. The most general quadratic form that fits \u03d5=0 at r=b and \u03d5=V at r=a is \u03d5=V[1+\u03b1( r\u2212a b\u2212a )\u2212(1+\u03b1)( r\u2212a b\u2212a ) 2 ], [ ( ) ( ] where \u03b1 is any constant number. This formula is a little more complicated. It involves a quadratic term in the potential as well as a linear term. It is very easy to get the field out of it. The field is just E=\u2212 d\u03d5 dr =\u2212 \u03b1V b\u2212a +2(1+\u03b1) (r\u2212a)V (b\u2212a ) 2 . d \u03d5 ( ) Now we have to square this and integrate over volume. But wait a moment. What should I take for \u03b1 ? I can take a parabola for the \u03d5 ; but what parabola? Here\u2019s what I do: Calculate the capacity with an arbitrary \u03b1 . What I get is C 2\u03c0 \u03f5 0 = a b\u2212a [ b a ( \u03b1 2 6 + 2\u03b1 3 +1)+ 1 6 \u03b1 2 + 1 3 ]. 2 It looks a little complicated, but it comes out of integrating the square of the field. Now I can pick my \u03b1 . I know that the truth lies lower than anything that I am going to calculate, so whatever I put in for \u03b1 is going to give me an answer too big. But if I keep playing with \u03b1 and get the lowest possible value I can, that lowest value is nearer to the truth than any other value. So what I do next is to pick the \u03b1 that gives the minimum value for C . Working it out by ordinary calculus, I get that the minimum C occurs for \u03b1=\u22122b/(b+a) . Substituting that value into the formula, I obtain for the minimum capacity C 2\u03c0 \u03f5 0 = b 2 +4ab+ a 2 3( b 2 \u2212 a 2 ) . 2 \u201cI\u2019ve worked out what this formula gives for C for various values of b/a . I call these numbers C(quadratic) . Table 19\u20132 compares C(quadratic) with the true C . \u201cFor example, when the ratio of the radii is 2 to 1 , I have 1.444 , which is a very good approximation to the true answer, 1.4427 . Even for larger b/a , it stays pretty good\u2014it is much, much better than the first approximation. It is even fairly good\u2014only off by 10 percent\u2014when b/a is 10 to 1 . But when it gets to be 100 to 1 \u2014well, things begin to go wild. I get that C is 0.347 instead of 0.217 . On the other hand, for a ratio of radii of 1.5 , the answer is excellent; and for a b/a of 1.1 , the answer comes out 10.492063 instead of 10.492059 . Where the answer should be good, it is very, very good. \u201cI have given these examples, first, to show the theoretical value of the principles of minimum action and minimum principles in general and, second, to show their practical utility\u2014not just to calculate a capacity when we already know the answer. For any other shape, you can guess an approximate field with some unknown parameters like \u03b1 and adjust them to get a minimum. You will get excellent numerical results for otherwise intractable problems.\u201d \u201cI should like to add something that I didn\u2019t have time for in the lecture. (I always seem to prepare more than I have time to tell about.) As I mentioned earlier, I got interested in a problem while working on this lecture. I want to tell you what that problem is. Among the minimum principles that I could mention, I noticed that most of them sprang in one way or another from the least action principle of mechanics and electrodynamics. But there is also a class that does not. As an example, if currents are made to go through a piece of material obeying Ohm\u2019s law, the currents distribute themselves inside the piece so that the rate at which heat is generated is as little as possible. Also we can say (if things are kept isothermal) that the rate at which energy is generated is a minimum. Now, this principle also holds, according to classical theory, in determining even the distribution of velocities of the electrons inside a metal which is carrying a current. The distribution of velocities is not exactly the equilibrium distribution [Chapter 40, Vol. I, Eq. (40.6)] because they are drifting sideways. The new distribution can be found from the principle that it is the distribution for a given current for which the entropy developed per second by collisions is as small as possible. The true description of the electrons\u2019 behavior ought to be by quantum mechanics, however. The question is: Does the same principle of minimum entropy generation also hold when the situation is described quantum-mechanically? I haven\u2019t found out yet. \u201cThe question is interesting academically, of course. Such principles are fascinating, and it is always worthwhile to try to see how general they are. But also from a more practical point of view, I want to know. I, with some colleagues, have published a paper in which we calculated by quantum mechanics approximately the electrical resistance felt by an electron moving through an ionic crystal like NaCl. [Feynman, Hellwarth, Iddings, and Platzman, \u201cMobility of Slow Electrons in a Polar Crystal,\u201d Phys. Rev. 127, 1004 (1962).] But if a minimum principle existed, we could use it to make the results much more accurate, just as the minimum principle for the capacity of a condenser permitted us to get such accuracy for that capacity even though we had only a rough knowledge of the electric field.\u201d"
    },
    {
        "input": "The Independent Particle Approximation",
        "output": "In Chapter 13 we worked out the theory for the propagation of an electron or of some other \u201cparticle,\u201d such as an atomic excitation, through a crystal lattice. In the last chapter we applied the theory to semiconductors. But when we talked about situations in which there are many electrons we disregarded any interactions between them. To do this is of course only an approximation. In this chapter we will discuss further the idea that you can disregard the interaction between the electrons. We will also use the opportunity to show you some more applications of the theory of the propagation of particles. Since we will generally continue to disregard the interactions between particles, there is very little really new in this chapter except for the new applications. The first example to be considered is, however, one in which it is possible to write down quite exactly the correct equations when there is more than one \u201cparticle\u201d present. From them we will be able to see how the approximation of disregarding the interactions is made. We will not, though, analyze the problem very carefully. As our first example we will consider a \u201cspin wave\u201d in a ferromagnetic crystal. We have discussed the theory of ferromagnetism in Chapter 36 of Volume II. At zero temperature all the electron spins that contribute to the magnetism in the body of a ferromagnetic crystal are parallel. There is an interaction energy between the spins, which is lowest when all the spins are down. At any nonzero temperature, however, there is some chance that some of the spins are turned over. We calculated the probability in an approximate manner in Chapter 36. This time we will describe the quantum mechanical theory\u2014so you will see what you would have to do if you wanted to solve the problem more exactly. (We will still make some idealizations by assuming that the electrons are localized at the atoms and that the spins interact only with neighboring spins.) We consider a model in which the electrons at each atom are all paired except one, so that all of the magnetic effects come from one spin- 1 2 electron per atom. Further, we imagine that these electrons are localized at the atomic sites in the lattice. The model corresponds roughly to metallic nickel. We also assume that there is an interaction between any two adjacent spinning electrons which gives a term in the energy of the system E=\u2212 \u2211 i,j K\u03c3i\u22c5\u03c3j, where \u03c3 \u2019s represent the spins and the summation is over all adjacent pairs of electrons. We have already discussed this kind of interaction energy when we considered the hyperfine splitting of hydrogen due to the interaction of the magnetic moments of the electron and proton in a hydrogen atom. We expressed it then as A\u03c3e\u22c5\u03c3p . Now, for a given pair, say the electrons at atom 4 and at atom 5 , the Hamiltonian would be \u2212K\u03c34\u22c5\u03c35 . We have a term for each such pair, and the Hamiltonian is (as you would expect for classical energies) the sum of these terms for each interacting pair. The energy is written with the factor \u2212K so that a positive K will correspond to ferromagnetism\u2014that is, the lowest energy results when adjacent spins are parallel. In a real crystal, there may be other terms which are the interactions of next nearest neighbors, and so on, but we don\u2019t need to consider such complications at this stage. With the Hamiltonian of Eq. (15.1) we have a complete description of the ferromagnet\u2014within our approximation\u2014and the properties of the magnetization should come out. We should also be able to calculate the thermodynamic properties due to the magnetization. If we can find all the energy levels, the properties of the crystal at a temperature T can be found from the principle that the probability that a system will be found in a given state of energy E is proportional to e\u2212E/\u03baT . This problem has never been completely solved. We will show some of the problems by taking a simple example in which all the atoms are in a line\u2014a one-dimensional lattice. You can easily extend the ideas to three dimensions. At each atomic location there is an electron which has two possible states, either spin up or spin down, and the whole system is described by telling how all of the spins are arranged. We take the Hamiltonian of the system to be the operator of the interaction energy. Interpreting the spin vectors of Eq. (15.1) as the sigma-operators\u2014or the sigma-matrices\u2014we write for the linear lattice \u02c6 H = \u2211 n \u2212 A 2 \u02c6 \u03c3 n\u22c5 \u02c6 \u03c3 n+1. In this equation we have written the constant as A/2 for convenience (so that some of the later equations will be exactly the same as the ones in Chapter 13). Now what is the lowest state of this system? The state of lowest energy is the one in which all the spins are parallel\u2014let\u2019s say, all up.1 We can write this state as |\u22ef++++\u22ef\u27e9 , or |gnd\u27e9 for the \u201cground,\u201d or lowest, state. It\u2019s easy to figure out the energy for this state. One way is to write out all the vector sigmas in terms of \u02c6 \u03c3 x , \u02c6 \u03c3 y , and \u02c6 \u03c3 z , and work through carefully what each term of the Hamiltonian does to the ground state, and then add the results. We can, however, also use a good short cut. We saw in Section 12\u20132, that \u02c6 \u03c3 i\u22c5 \u02c6 \u03c3 j could be written in terms of the Pauli spin exchange operator like this: \u02c6 \u03c3 i\u22c5 \u02c6 \u03c3 j=(2 \u02c6 P spin ex ij \u22121), where the operator \u02c6 P spin ex ij interchanges the spins of the i th and j th electrons. With this substitution the Hamiltonian becomes \u02c6 H =\u2212A \u2211 n ( \u02c6 P spin ex n,n+1 \u2212 1 2 ). It is now easy to work out what happens to different states. For instance if i and j are both up, then exchanging the spins leaves everything unchanged, so \u02c6 P ij acting on the state just gives the same state back, and is equivalent to multiplying by +1 . The expression ( \u02c6 P ij\u2212 1 2 ) is just equal to one-half. (From now on we will leave off the descriptive superscript on the \u02c6 P .) For the ground state all spins are up; so if you exchange a particular pair of spins, you get back the original state. The ground state is a stationary state. If you operate on it with the Hamiltonian you get the same state again multiplied by a sum of terms, \u2212(A/2) for each pair of spins. That is, the energy of the system in the ground state is \u2212A/2 per atom. Next we would like to look at the energies of some of the excited states. It will be convenient to measure the energies with respect to the ground state\u2014that is, to choose the ground state as our zero of energy. We can do that by adding the energy A/2 to each term in the Hamiltonian. That just changes the \u201c 1 2 \u201d in Eq. (15.4) to \u201c 1 .\u201d Our new Hamiltonian is H ^ =\u2212A \u2211 n ( P ^ n,n+1 \u22121). (15.5) With this Hamiltonian the energy of the lowest state is zero; the spin exchange operator is equivalent to multiplying by unity (for the ground state) which is cancelled by the \u201c 1 \u201d in each term. For describing states other than the ground state we will need a suitable set of base states. One convenient approach is to group the states according to whether one electron has spin down, or two electrons have spin down, and so on. There are, of course, many states with one spin down. The down spin could be at atom \u201c4,\u201d or at atom \u201c5,\u201d or at atom \u201c6,\u201d \u2026 We can, in fact, choose just such states for our base states. We could write them this way: |4\u27e9 , |5\u27e9 , |6\u27e9 , \u2026 It will, however, be more convenient later if we label the \u201codd atom\u201d\u2014the one with the down-spinning electron\u2014by its coordinate x . That is, we\u2019ll define the state | x 5 \u27e9 to be one with all the electrons spinning up except for the one on the atom at x 5 , which has a down-spinning electron (see Fig. 15\u20131). In general, | x n \u27e9 is the state with one down spin that is located at the coordinate x n of the n th atom. What is the action of the Hamiltonian (15.5) on the state | x 5 \u27e9 ? One term of the Hamiltonian is say \u2212A( P ^ 7,8 \u22121) . The operator P ^ 7,8 exchanges the two spins of the adjacent atoms 7 , 8 . But in the state | x 5 \u27e9 these are both up, and nothing happens; P ^ 7,8 is equivalent to multiplying by 1 : P ^ 7,8 | x 5 \u27e9=| x 5 \u27e9. It follows that ( P ^ 7,8 \u22121)| x 5 \u27e9=0. Thus all the terms of the Hamiltonian give zero\u2014except those involving atom 5 , of course. On the state | x 5 \u27e9 , the operation P ^ 4,5 exchanges the spin of atom 4 (up) and atom 5 (down). The result is the state with all spins up except the atom at 4 . That is P ^ 4,5 | x 5 \u27e9=| x 4 \u27e9. In the same way P ^ 5,6 | x 5 \u27e9=| x 6 \u27e9. Hence, the only terms of the Hamiltonian which survive are \u2212A( P ^ 4,5 \u22121) and \u2212A( P ^ 5,6 \u22121) . Acting on | x 5 \u27e9 they produce \u2212A| x 4 \u27e9+A| x 5 \u27e9 and \u2212A| x 6 \u27e9+A| x 5 \u27e9 , respectively. The result is H ^ | x 5 \u27e9 =\u2212A \u2211 n ( P ^ n,n+1 \u22121)| x 5 \u27e9 =\u2212A{| x 6 \u27e9+| x 4 \u27e9\u22122| x 5 \u27e9}. (15.6) When the Hamiltonian acts on state | x 5 \u27e9 it gives rise to some amplitude to be in states | x 4 \u27e9 and | x 6 \u27e9 . That just means that there is a certain amplitude to have the down spin jump over to the next atom. So because of the interaction between the spins, if we begin with one spin down, then there is some probability that at a later time another one will be down instead. Operating on the general state | x n \u27e9 , the Hamiltonian gives H ^ | x n \u27e9=\u2212A{| x n+1 \u27e9+| x n\u22121 \u27e9\u22122| x n \u27e9}. (15.7) Notice particularly that if we take a complete set of states with only one spin down, they will only be mixed among themselves. The Hamiltonian will never mix these states with others that have more spins down. So long as you only exchange spins you never change the total number of down spins. It will be convenient to use the matrix notation for the Hamiltonian, say H n,m \u2261\u27e8 x n | H ^ | x m \u27e9 ; Eq. (15.7) is equivalent to H n,n H n,n+1 H n,m =2A; = H n,n\u22121 =\u2212A; =0, for |n\u2212m|>1. (15.8) Now what are the energy levels for states with one spin down? As usual we let C n be the amplitude that some state |\u03c8\u27e9 is in the state | x n \u27e9 . If |\u03c8\u27e9 is to be a definite energy state, all the C n \u2019s must vary with time in the same way, namely, C n = a n e \u2212iEt/\u210f . (15.9) We can put this trial solution into our usual Hamiltonian equation i\u210f d C n dt = \u2211 m H nm C m , (15.10) using Eq. (15.8) for the matrix elements. Of course we get an infinite number of equations, but they can all be written as E a n =2A a n \u2212A a n\u22121 \u2212A a n+1 . (15.11) We have again exactly the same problem we worked out in Chapter 13, except that where we had E 0 we now have 2A . The solutions correspond to amplitudes C n (the down-spin amplitude) which propagate along the lattice with a propagation constant k and an energy E=2A(1\u2212coskb), (15.12) where b is the lattice constant. The definite energy solutions correspond to \u201cwaves\u201d of down spin\u2014called \u201cspin waves.\u201d And for each wavelength there is a corresponding energy. For large wavelengths (small k ) this energy varies as E=A b 2 k 2 . (15.13) Just as before, we can consider a localized wave packet (containing, however, only long wavelengths) which corresponds to a spin-down electron in one part of the lattice. This down spin will behave like a \u201cparticle.\u201d Because its energy is related to k by (15.13) the \u201cparticle\u201d will have an effective mass: m eff = \u210f 2 2A b 2 . (15.14) These \u201cparticles\u201d are sometimes called \u201cmagnons.\u201d Now we would like to discuss what happens if there are two down spins. Again we pick a set of base states. We\u2019ll choose states in which there are down spins at two atomic locations, such as the state shown in Fig. 15\u20132. We can label such a state by the x -coordinates of the two sites with down spins. The one shown can be called | x 2 , x 5 \u27e9 . In general the base states are | x n , x m \u27e9 \u2014a doubly infinite set! In this system of description, the state | x 4 , x 9 \u27e9 and the state | x 9 , x 4 \u27e9 are exactly the same state, because each simply says that there is a down spin at 4 and one at 9 ; there is no meaning to the order. Furthermore, the state | x 4 , x 4 \u27e9 has no meaning, there isn\u2019t such a thing. We can describe any state |\u03c8\u27e9 by giving the amplitudes to be in each of the base states. Thus C m,n =\u27e8 x m , x n |\u03c8\u27e9 now means the amplitude for a system in the state |\u03c8\u27e9 to be in a state in which both the m th and n th atoms have a down spin. The complications which now arise are not complications of ideas\u2014they are merely complexities in bookkeeping. (One of the complexities of quantum mechanics is just the bookkeeping. With more and more down spins, the notation becomes more and more elaborate with lots of indices and the equations always look very horrifying; but the ideas are not necessarily more complicated than in the simplest case.) The equations of motion of the spin system are the differential equations for the C n,m . They are i\u210f d C n,m dt = \u2211 i,j ( H nm,ij ) C ij . (15.15) Suppose we want to find the stationary states. As usual, the derivatives with respect to time become E times the amplitudes and the C m,n can be replaced by the coefficients a m,n . Next we have to work out carefully the effect of H on a state with spins m and n down. It is not hard to figure out. Suppose for a moment that m and n are far enough apart so that we don\u2019t have to worry about the obvious trouble. The operation of exchange at the location x n will move the down spin either to the (n+1) or (n\u22121) atom, and so there\u2019s an amplitude that the present state has come from the state | x m , x n+1 \u27e9 and also an amplitude that it has come from the state | x m , x n\u22121 \u27e9 . Or it may have been the other spin that moved; so there\u2019s a certain amplitude that C m,n is fed from C m+1,n or from C m\u22121,n . These effects should all be equal. The final result for the Hamiltonian equation on C m,n is E a m,n = \u2212A( a m+1,n + a m\u22121,n + a m,n+1 + a m,n\u22121 )+4A a m,n . (15.16) This equation is correct except in two situations. If m=n there is no equation at all, and if m=n\u00b11 , then two of the terms in Eq. (15.16) should be missing. We are going to disregard these exceptions. We simply ignore the fact that some few of these equations are slightly altered. After all, the crystal is supposed to be infinite, and we have an infinite number of terms; neglecting a few might not matter much. So for a first rough approximation let\u2019s forget about the altered equations. In other words, we assume that Eq. (15.16) is true for all m and n , even for m and n next to each other. This is the essential part of our approximation. Then the solution is not hard to find. We get immediately C m,n = a m,n e \u2212iEt/\u210f , (15.17) with a m,n =(const.) e i k 1 x m e i k 2 x n , (15.18) where E=4A\u22122Acos k 1 b\u22122Acos k 2 b. (15.19) Think for a moment what would happen if we had two independent, single spin waves (as in the previous section) corresponding to k= k 1 and k= k 2 ; they would have energies, from Eq. (15.12), of E 1 =(2A\u22122Acos k 1 b) ( k b ) and E 2 =(2A\u22122Acos k 2 b). ( k b ) Notice that the energy E in Eq. (15.19) is just their sum, E= E 1 + E 2 . (15.20) In other words we can think of our solution in this way. There are two particles\u2014that is, two spin waves. One of them has a momentum described by k 1 , the other by k 2 , and the energy of the system is the sum of the energies of the two objects. The two particles act completely independently. That\u2019s all there is to it. Of course we have made some approximations, but we do not wish to discuss the precision of our answer at this point. However, you might guess that in a reasonable size crystal with billions of atoms\u2014and, therefore, billions of terms in the Hamiltonian\u2014leaving out a few terms wouldn\u2019t make much of an error. If we had so many down spins that there was an appreciable density, then we would certainly have to worry about the corrections. [Interestingly enough, an exact solution can be written down if there are just the two down spins. The result is not particularly important. But it is interesting that the equations can be solved exactly for this case. The solution is: a m,n =exp[i k c ( x m + x n )]sin(k| x m \u2212 x n |), (15.21) with the energy E=4A\u22122Acos k 1 b\u22122Acos k 2 b, E 4 A 2 A k b 2 A k b and with the wave numbers k c and k related to k 1 and k 2 by k 1 = k c \u2212k, k 2 = k c +k. (15.22) This solution includes the \u201cinteraction\u201d of the two spins. It describes the fact that when the spins come together there is a certain chance of scattering. The spins act very much like particles with an interaction. But the detailed theory of their scattering goes beyond what we want to talk about here.] In the last section we wrote down a Hamiltonian, Eq. (15.15), for a two-particle system. Then using an approximation which is equivalent to neglecting any \u201cinteraction\u201d of the two particles, we found the stationary states described by Eqs. (15.17) and (15.18). This state is just the product of two single-particle states. The solution we have given for a m,n in Eq. (15.18) is, however, really not satisfactory. We have very carefully pointed out earlier that the state | x 9 , x 4 \u27e9 is not a different state from | x 4 , x 9 \u27e9 \u2014the order of x m and x n has no significance. In general, the algebraic expression for the amplitude C m,n must be unchanged if we interchange the values of x m and x n , since that doesn\u2019t change the state. Either way, it should represent the amplitude to find a down spin at x m and a down spin at x n . But notice that (15.18) is not symmetric in x m and x n \u2014since k 1 and k 2 can in general be different. The trouble is that we have not forced our solution of Eq. (15.15) to satisfy this additional condition. Fortunately it is easy to fix things up. Notice first that a solution of the Hamiltonian equation just as good as (15.18) is a m,n =K e i k 2 x m e i k 1 x n . (15.23) It even has the same energy we got for (15.18). Any linear combination of (15.18) and (15.23) is also a good solution, and has an energy still given by Eq. (15.19). The solution we should have chosen\u2014because of our symmetry requirement\u2014is just the sum of (15.18) and (15.23): a m,n =K[ e i k 1 x m e i k 2 x n + e i k 2 x m e i k 1 x n ]. (15.24) Now, given any k 1 and k 2 the amplitude C m,n is independent of which way we put x m and x n \u2014if we should happen to define x m and x n reversed we get the same amplitude. Our interpretation of Eq. (15.24) in terms of \u201cmagnons\u201d must also be different. We can no longer say that the equation represents one particle with wave number k 1 and a second particle with wave number k 2 . The amplitude (15.24) represents one state with two particles (magnons). The state is characterized by the two wave numbers k 1 and k 2 . Our solution looks like a compound state of one particle with the momentum p 1 =\u210f k 1 and another particle with the momentum p 2 =\u210f k 2 , but in our state we can\u2019t say which particle is which. By now, this discussion should remind you of Chapter 4 and our story of identical particles. We have just been showing that the particles of the spin waves\u2014the magnons\u2014behave like identical Bose particles. All amplitudes must be symmetric in the coordinates of the two particles\u2014which is the same as saying that if we \u201cinterchange the two particles,\u201d we get back the same amplitude and with the same sign. But, you may be thinking, why did we choose to add the two terms in making Eq. (15.24). Why not subtract? With a minus sign, interchanging x m and x n would just change the sign of a m,n which doesn\u2019t matter. But interchanging x m and x n doesn\u2019t change anything\u2014all the electrons of the crystal are exactly where they were before, so there is no reason for even the sign of the amplitude to change. The magnons will behave like Bose particles.2 The main points of this discussion have been twofold: First, to show you something about spin waves, and, second, to demonstrate a state whose amplitude is a product of two amplitudes, and whose energy is the sum of the energies corresponding to the two amplitudes. For independent particles the amplitude is the product and the energy is the sum. You can easily see why the energy is the sum. The energy is the coefficient of t in an imaginary exponential\u2014it is proportional to the frequency. If two objects are doing something, one of them with the amplitude e \u2212i E 1 t/\u210f and the other with the amplitude e \u2212i E 2 t/\u210f , and if the amplitude for the two things to happen together is the product of the amplitudes for each, then there is a single frequency in the product which is the sum of the two frequencies. The energy corresponding to the amplitude product is the sum of the two energies. We have gone through a rather long-winded argument to tell you a simple thing. When you don\u2019t take into account any interaction between particles, you can think of each particle independently. They can individually exist in the various different states they would have alone, and they will each contribute the energy they would have had if they were alone. However, you must remember that if they are identical particles, they may behave either as Bose or as Fermi particles depending upon the problem. Two extra electrons added to a crystal, for instance, would have to behave like Fermi particles. When the positions of two electrons are interchanged, the amplitude must reverse sign. In the equation corresponding to Eq. (15.24) there would have to be a minus sign between the two terms on the right. As a consequence, two Fermi particles cannot be in exactly the same condition\u2014with equal spins and equal k \u2019s. The amplitude for this state is zero. Although quantum mechanics provides the basic laws that determine the structures of molecules, these laws can be applied exactly only to the most simple compounds. The chemists have, therefore, worked out various approximate methods for calculating some of the properties of complicated molecules. We would now like to show you how the independent particle approximation is used by the organic chemists. We begin with the benzene molecule. We discussed the benzene molecule from another point of view in Chapter 10. There we took an approximate picture of the molecule as a two-state system, with the two base states shown in Fig. 15\u20133. There is a ring of six carbons with a hydrogen bonded to the carbon at each location. With the conventional picture of valence bonds it is necessary to assume double bonds between half of the carbon atoms, and in the lowest energy condition there are the two possibilities shown in the figure. There are also other, higher-energy states. When we discussed benzene in Chapter 10, we just took the two states and forgot all the rest. We found that the ground-state energy of the molecule was not the energy of one of the states in the figure, but was lower than that by an amount proportional to the amplitude to flip from one of these states to the other. Now we\u2019re going to look at the same molecule from a completely different point of view\u2014using a different kind of approximation. The two points of view will give us different answers, but if we improve either approximation it should lead to the truth, a valid description of benzene. However, if we don\u2019t bother to improve them, which is of course the usual situation, then you should not be surprised if the two descriptions do not agree exactly. We shall at least show that also with the new point-of-view the lowest energy of the benzene molecule is lower than either of the three-bond structures of Fig. 15\u20133. Now we want to use the following picture. Suppose we imagine the six carbon atoms of a benzene molecule connected only by single bonds as in Fig. 15\u20134. We have removed six electrons\u2014since a bond stands for a pair of electrons\u2014so we have a six-times ionized benzene molecule. Now we will consider what happens when we put back the six electrons one at a time, imagining that each one can run freely around the ring. We assume also that all the bonds shown in Fig. 15\u20134 are satisfied, and don\u2019t need to be considered further. What happens when we put one electron back into the molecular ion? It might, of course, be located in any one of the six positions around the ring\u2014corresponding to six base states. It would also have a certain amplitude, say A , to go from one position to the next. If we analyze the stationary states, there would be certain possible energy levels. That\u2019s only for one electron. Next put a second electron in. And now we make the most ridiculous approximation that you can think of\u2014that what one electron does is not affected by what the other is doing. Of course they really will interact; they repel each other through the Coulomb force, and furthermore when they are both at the same site, they must have considerably different energy than twice the energy for one being there. Certainly the approximation of independent particles is not legitimate when there are only six sites\u2014particularly when we want to put in six electrons. Nevertheless the organic chemists have been able to learn a lot by making this kind of an approximation. Before we work out the benzene molecule in detail, let\u2019s consider a simpler example\u2014the ethylene molecule which contains just two carbon atoms with two hydrogen atoms on either side as shown in Fig. 15\u20135. This molecule has one \u201cextra\u201d bond involving two electrons between the two carbon atoms. Now remove one of these electrons; what do we have? We can look at it as a two-state system\u2014the remaining electron can be at one carbon or the other. We can analyze it as a two-state system. The possible energies for the single electron are either ( E 0 \u2212A) or ( E 0 +A) , as shown in Fig. 15\u20136. Now add the second electron. Good, if we have two electrons, we can put the first one in the lower state and the second one in the upper. Not quite; we forgot something. Each one of the states is really double. When we say there\u2019s a possible state with the energy ( E 0 \u2212A) , there are really two. Two electrons can go into the same state if one has its spin up and the other, its spin down. (No more can be put in because of the exclusion principle.) So there really are two possible states of energy ( E 0 \u2212A) . We can draw a diagram, as in Fig. 15\u20137, which indicates both the energy levels and their occupancy. In the condition of lowest energy both electrons will be in the lowest state with their spins opposite. The energy of the extra bond in the ethylene molecule therefore is 2( E 0 \u2212A) if we neglect the interaction between the two electrons. Let\u2019s go back to the benzene. Each of the two states of Fig. 15\u20133 has three double bonds. Each of these is just like the bond in ethylene, and contributes 2( E 0 \u2212A) to the energy if E 0 is now the energy to put an electron on a site in benzene and A is the amplitude to flip to the next site. So the energy should be roughly 6( E 0 \u2212A) . But when we studied benzene before, we got that the energy was lower than the energy of the structure with three extra bonds. Let\u2019s see if the energy for benzene comes out lower than three bonds from our new point of view. We start with the six-times ionized benzene ring and add one electron. Now we have a six-state system. We haven\u2019t solved such a system yet, but we know what to do. We can write six equations in the six amplitudes, and so on. But let\u2019s save some work\u2014by noticing that we\u2019ve already solved the problem, when we worked out the problem of an electron on an infinite line of atoms. Of course, the benzene is not an infinite line, it has 6 atomic sites in a circle. But imagine that we open out the circle to a line, and number the atoms along the line from 1 to 6 . In an infinite line the next location would be 7 , but if we insist that this location be identical with number 1 and so on, the situation will be just like the benzene ring. In other words we can take the solution for an infinite line with an added requirement that the solution must be periodic with a cycle six atoms long. From Chapter 13 the electron on a line has states of definite energy when the amplitude at each site is e ik x n = e ikbn . For each k the energy is E= E 0 \u22122Acoskb. (15.25) We want to use now only those solutions which repeat every 6 atoms. Let\u2019s do first the general case for a ring of N atoms. If the solution is to have a period of N atomic spacing, e ikbN must be unity; or kbN must be a multiple of 2\u03c0 . Taking s to represent any integer, our condition is that kbN=2\u03c0s. (15.26) We have seen before that there is no meaning to taking k \u2019s outside the range \u00b1\u03c0/b . This means that we get all possible states by taking values of s in the range \u00b1N/2 . We find then that for an N -atom ring there are N definite energy states3 and they have wave numbers k s given by k s = 2\u03c0 Nb s. (15.27) Each state has the energy (15.25). We have a line spectrum of possible energy levels. The spectrum for benzene ( N=6 ) is shown in Fig. 15\u20138(b). (The numbers in parentheses indicate the number of different states with the same energy.) There\u2019s a nice way to visualize the six energy levels, as we have shown in part (a) of the figure. Imagine a circle centered on a level with E 0 , and with a radius of 2A . If we start at the bottom and mark off six equal arcs (at angles from the bottom point of k s b=2\u03c0s/N , or 2\u03c0s/6 for benzene), then the vertical heights of the points on the circle are the solutions of Eq. (15.25). The six points represent the six possible states. The lowest energy level is at ( E 0 \u22122A) ; there are two states with the same energy ( E 0 \u2212A) , and so on.4 These are possible states for one electron. If we have more than one electron, two\u2014with opposite spins\u2014can go into each state. For the benzene molecule we have to put in six electrons. For the ground state they will go into the lowest possible energy states\u2014two at s=0 , two at s=+1 , and two at s=\u22121 . According to the independent particle approximation the energy of the ground state is E ground =2( E 0 \u22122A)+4( E 0 \u2212A) =6 E 0 \u22128A. (15.28) The energy is indeed less than that of three separate double bonds\u2014by the amount 2A . By comparing the energy of benzene to the energy of ethylene it is possible to determine A . It comes out to be 0.8 electron volt, or, in the units the chemists like, 18 kilocalories per mole. We can use this description to calculate or understand other properties of benzene. For example, using Fig. 15\u20138 we can discuss the excitation of benzene by light. What would happen if we tried to excite one of the electrons? It could move up to one of the empty higher states. The lowest energy of excitation would be a transition from the highest filled level to the lowest empty level. That takes the energy 2A . Benzene will absorb light of frequency \u03bd when h\u03bd=2A . There will also be absorption of photons with the energies 3A and 4A . Needless to say, the absorption spectrum of benzene has been measured and the pattern of spectral lines is more or less correct except that the lowest transition occurs in the ultraviolet; and to fit the data one would have to choose a value of A between 1.4 and 2.4 electron volts. That is, the numerical value of A is two or three times larger than is predicted from the chemical binding energy. What the chemist does in situations like this is to analyze many molecules of a similar kind and get some empirical rules. He learns, for example: For calculating binding energy use such and such a value of A , but for getting the absorption spectrum approximately right use another value of A . You may feel that this sounds a little absurd. It is not very satisfactory from the point of view of a physicist who is trying to understand nature from first principles. But the problem of the chemist is different. He must try to guess ahead of time what is going to happen with molecules that haven\u2019t been made yet, or which aren\u2019t understood completely. What he needs is a series of empirical rules; it doesn\u2019t make much difference where they come from. So he uses the theory in quite a different way than the physicist. He takes equations that have some shadow of the truth in them, but then he must alter the constants in them\u2014making empirical corrections. In the case of benzene, the principal reason for the inconsistency is our assumption that the electrons are independent\u2014the theory we started with is really not legitimate. Nevertheless, it has some shadow of the truth because its results seem to be going in the right direction. With such equations plus some empirical rules\u2014including various exceptions\u2014the organic chemist makes his way through the morass of complicated things he chooses to study. (Don\u2019t forget that the reason a physicist can really calculate from first principles is that he chooses only simple problems. He never solves a problem with 42 or even 6 electrons in it. So far, he has been able to calculate reasonably accurately only the hydrogen atom and the helium atom.) Let\u2019s see how the same ideas can be used to study other molecules. Consider a molecule like butadiene (1,3) \u2014it is drawn in Fig. 15\u20139 according to the usual valence bond picture. We can play the same game with the extra four electrons corresponding to the two double bonds. If we remove four electrons, we have four carbon atoms in a line. You already know how to solve a line. You say, \u201cOh no, I only know how to solve an infinite line.\u201d But the solutions for the infinite line also include the ones for a finite line. Watch. Let N be the number of atoms on the line and number them from 1 to N as shown in Fig. 15\u201310. In writing the equations for the amplitude at position 1 you would not have a term feeding from position 0 . Similarly, the equation for position N would differ from the one that we used for an infinite line because there would be nothing feeding from position N+1 . But suppose that we can obtain a solution for the infinite line which has the following property: the amplitude to be at atom 0 is zero and the amplitude to be at atom (N+1) is also zero. Then the set of equations for all the locations from 1 to N on the finite line are also satisfied. You might think no such solution exists for the infinite line because our solutions all looked like e ik x n which has the same absolute value of the amplitude everywhere. But you will remember that the energy depends only on the absolute value of k , so that another solution, which is equally legitimate for the same energy, would be e \u2212ik x n . And the same is true of any superposition of these two solutions. By subtracting them we can get the solution sink x n , which satisfies the requirement that the amplitude be zero at x=0 . It still corresponds to the energy ( E 0 \u22122Acoskb) . Now by a suitable choice for the value of k we can also make the amplitude zero at x N+1 . This requires that (N+1)kb be a multiple of \u03c0 , or that kb= \u03c0 (N+1) s, (15.29) where s is an integer from 1 to N . (We take only positive k \u2019s because each solution contains +k and \u2212k ; changing the sign of k gives the same state all over again.) For the butadiene molecule, N=4 , so there are four states with kb=\u03c0/5,2\u03c0/5,3\u03c0/5,and4\u03c0/5. (15.30) We can represent the energy levels using a circle diagram similar to the one for benzene. This time we use a semicircle divided into five equal parts as shown in Fig. 15\u201311. The point at the bottom corresponds to s=0 , which gives no state at all. The same is true of the point at the top, which corresponds to s=N+1 . The remaining 4 points give us four allowed energies. There are four stationary states, which is what we expect having started with four base states. In the circle diagram, the angular intervals are \u03c0/5 or 36 degrees. The lowest energy comes out ( E 0 \u22121.618A) . (Ah, what wonders mathematics holds; the golden mean of the Greeks5 gives us the lowest energy state of the butadiene molecule according to this theory!) Now we can calculate the energy of the butadiene molecule when we put in four electrons. With four electrons, we fill up the lowest two levels, each with two electrons of opposite spin. The total energy is E =2( E 0 \u22121.618A)+2( E 0 \u22120.618A) =4( E 0 \u2212A)\u22120.472A. (15.31) This result seems reasonable. The energy is a little lower than for two simple double bonds, but the binding is not so strong as in benzene. Anyway this is the way the chemist analyzes some organic molecules. The chemist can use not only the energies but the probability amplitudes as well. Knowing the amplitudes for each state, and which states are occupied, he can tell the probability of finding an electron anywhere in the molecule. Those places where the electrons are more likely to be are apt to be reactive in chemical substitutions which require that an electron be shared with some other group of atoms. The other sites are more likely to be reactive in those substitutions which have a tendency to yield an extra electron to the system. The same ideas we have been using can give us some understanding of a molecule even as complicated as chlorophyll, one version of which is shown in Fig. 15\u201312. Notice that the double and single bonds we have drawn with heavy lines form a long closed ring with twenty intervals. The extra electrons of the double bonds can run around this ring. Using the independent particle method we can get a whole set of energy levels. There are strong absorption lines from transitions between these levels which lie in the visible part of the spectrum, and give this molecule its strong color. Similar complicated molecules such as the xanthophylls, which make leaves turn red, can be studied in the same way. There is one more idea which emerges from the application of this kind of theory in organic chemistry. It is probably the most successful or, at least in a certain sense, the most accurate. This idea has to do with the question: In what situations does one get a particularly strong chemical binding? The answer is very interesting. Take the example, first, of benzene, and imagine the sequence of events that occurs as we start with the six-times ionized molecule and add more and more electrons. We would then be thinking of various benzene ions\u2014negative or positive. Suppose we plot the energy of the ion (or neutral molecule) as a function of the number of electrons. If we take E 0 =0 (since we don\u2019t know what it is), we get the curve shown in Fig. 15\u201313. For the first two electrons the slope of the function is a straight line. For each successive group the slope increases, and there is a discontinuity in slope between the groups of electrons. The slope changes when one has just finished filling a set of levels which all have the same energy and must move up to the next higher set of levels for the next electron. The actual energy of the benzene ion is really quite different from the curve of Fig. 15\u201313 because of the interactions of the electrons and because of electrostatic energies we have been neglecting. These corrections will, however, vary with n in a rather smooth way. Even if we were to make all these corrections, the resulting energy curve would still have kinks at those values of n which just fill up a particular energy level. Now consider a very smooth curve that fits the points on the average like the one drawn in Fig. 15\u201314. We can say that the points above this curve have \u201chigher-than-normal\u201d energies, and the points below the curve have \u201clower-than-normal\u201d energies. We would, in general, expect that those configurations with a lower-than-normal energy would have an above average stability\u2014chemically speaking. Notice that the configurations farther below the curve always occur at the end of one of the straight line segments\u2014namely when there are enough electrons to fill up an \u201cenergy shell,\u201d as it is called. This is the very accurate prediction of the theory. Molecules\u2014or ions\u2014are particularly stable (in comparison with other similar configurations) when the available electrons just fill up an energy shell. This theory has explained and predicted some very peculiar chemical facts. To take a very simple example, consider a ring of three. It\u2019s almost unbelievable that the chemist can make a ring of three and have it stable, but it has been done. The energy circle for three electrons is shown in Fig. 15\u201315. Now if you put two electrons in the lower state, you have only two of the three electrons that you require. The third electron must be put in at a much higher level. By our argument this molecule should not be particularly stable, whereas the two-electron structure should be stable. It does turn out, in fact, that the neutral molecule of triphenyl cyclopropenyl is very hard to make, but that the positive ion shown in Fig. 15\u201316 is relatively easy to make. The ring of three is never really easy because there is always a large stress when the bonds in an organic molecule make an equilateral triangle. To make a stable compound at all, the structure must be stabilized in some way. Anyway if you add three benzene rings on the corners, the positive ion can be made. (The reason for this requirement of added benzene rings is not really understood.) In a similar way the five-sided ring can also be analyzed. If you draw the energy diagram, you can see in a qualitative way that the six-electron structure should be an especially stable structure, so that such a molecule should be most stable as a negative ion. Now the five-ring is well known and easy to make and always acts as a negative ion. Similarly, you can easily verify that a ring of 4 or 8 is not very interesting, but that a ring of 14 or 10 \u2014like a ring of 6 \u2014should be especially stable as a neutral object. There are two other similar situations which we will describe only briefly. In considering the structure of an atom, we can consider that the electrons fill successive shells. The Schr\u00f6dinger theory of electron motion can be worked out easily only for a single electron moving in a \u201ccentral\u201d field\u2014one which varies only with the distance from a point. How can we then understand what goes on in an atom which has 22 electrons?! One way is to use a kind of independent particle approximation. First you calculate what happens with one electron. You get a number of energy levels. You put an electron into the lowest energy state. You can, for a rough model, continue to ignore the electron interactions and go on filling successive shells, but there is a way to get better answers by taking into account\u2014in an approximate way at least\u2014the effect of the electric charge carried by the electron. Each time you add an electron you compute its amplitude to be at various places, and then use this amplitude to estimate a kind of spherically symmetric charge distribution. You use the field of this distribution\u2014together with the field of the positive nucleus and all the previous electrons\u2014to calculate the states available for the next electron. In this way you can get reasonably correct estimates for the energies for the neutral atom and for various ionized states. You find that there are energy shells, just as we saw for the electrons in a ring molecule. With a partially filled shell, the atom will show a preference for taking on one or more extra electrons, or for losing some electrons so as to get into the most stable state of a filled shell. This theory explains the machinery behind the fundamental chemical properties which show up in the periodic table of the elements. The inert gases are those elements in which a shell has just been completed, and it is especially difficult to make them react. (Some of them do react of course\u2014with fluorine and oxygen, for example; but such compounds are very weakly bound; the so-called inert gases are nearly inert.) An atom which has one electron more or one electron less than an inert gas will easily lose or gain an electron to get into the especially stable (low-energy) condition which comes from having a completely filled shell\u2014they are the very active chemical elements of valence +1 or \u22121 . The other situation is found in nuclear physics. In atomic nuclei the protons and neutrons interact with each other quite strongly. Even so, the independent particle model can again be used to analyze nuclear structure. It was first discovered experimentally that nuclei were especially stable if they contained certain particular numbers of neutrons\u2014namely 2 , 8 , 20 , 28 , 50 , 82 . Nuclei containing protons in these numbers are also especially stable. Since there was initially no explanation for these numbers they were called the \u201cmagic numbers\u201d of nuclear physics. It is well known that neutrons and protons interact strongly with each other; people were, therefore, quite surprised when it was discovered that an independent particle model predicted a shell structure which came out with the first few magic numbers. The model assumed that each nucleon (proton or neutron) moved in a central potential which was created by the average effects of all the other nucleons. This model failed, however, to give the correct values for the higher magic numbers. Then it was discovered by Maria Mayer, and independently by Jensen and his collaborators, that by taking the independent particle model and adding only a correction for what is called the \u201cspin-orbit interaction,\u201d one could make an improved model which gave all of the magic numbers. (The spin-orbit interaction causes the energy of a nucleon to be lower if its spin has the same direction as its orbital angular momentum from motion in the nucleus.) The theory gives even more\u2014its picture of the so-called \u201cshell structure\u201d of the nuclei enables us to predict certain characteristics of nuclei and of nuclear reactions. The independent particle approximation has been found useful in a wide range of subjects\u2014from solid-state physics, to chemistry, to biology, to nuclear physics. It is often only a crude approximation, but is able to give an understanding of why there are especially stable conditions\u2014in shells. Since it omits all of the complexity of the interactions between the individual particles, we should not be surprised that it often fails completely to give correctly many important details."
    },
    {
        "input": "Linear Systems and Review",
        "output": "In this chapter we shall discuss certain aspects of oscillating systems that are found somewhat more generally than just in the particular systems we have been discussing. For our particular system, the differential equation that we have been solving is m d 2 x d t 2 +\u03b3m dx dt +m \u03c9 2 0 x=F(t). (25.1) Now this particular combination of \u201coperations\u201d on the variable x has the interesting property that if we substitute (x+y) for x , then we get the sum of the same operations on x and y ; or, if we multiply x by a , then we get just a times the same combination. This is easy to prove. Just as a \u201cshorthand\u201d notation, because we get tired of writing down all those letters in (25.1), we shall use the symbol L \u2212 \u2212 (x) instead. When we see this, it means the left-hand side of (25.1), with x substituted in. With this system of writing, L \u2212 \u2212 (x+y) would mean the following: L \u2212 \u2212 (x+y)=m d 2 (x+y) d t 2 +\u03b3m d(x+y) dt +m \u03c9 2 0 (x+y). (25.2) (We underline the L \u2212 \u2212 so as to remind ourselves that it is not an ordinary function.) We sometimes call this an operator notation, but it makes no difference what we call it, it is just \u201cshorthand.\u201d Our first statement was that L \u2212 \u2212 (x+y)= L \u2212 \u2212 (x)+ L \u2212 \u2212 (y), (25.3) which of course follows from the fact that a(x+y)=ax+ay , d(x+y)/dt=dx/dt+dy/dt , etc. Our second statement was, for constant a , L \u2212 \u2212 (ax)=a L \u2212 \u2212 (x). (25.4) [Actually, (25.3) and (25.4) are very closely related, because if we put x+x into (25.3), this is the same as setting a=2 in (25.4), and so on.] In more complicated problems, there may be more derivatives, and more terms in L \u2212 \u2212 ; the question of interest is whether the two equations (25.3) and (25.4) are maintained or not. If they are, we call such a problem a linear problem. In this chapter we shall discuss some of the properties that exist because the system is linear, to appreciate the generality of some of the results that we have obtained in our special analysis of a special equation. Now let us study some of the properties of linear differential equations, having illustrated them already with the specific equation (25.1) that we have studied so closely. The first property of interest is this: suppose that we have to solve the differential equation for a transient, the free oscillation with no driving force. That is, we want to solve L \u2212 \u2212 (x)=0. (25.5) Suppose that, by some hook or crook, we have found a particular solution, which we shall call x 1 . That is, we have an x 1 for which L \u2212 \u2212 ( x 1 )=0 . Now we notice that a x 1 is also a solution to the same equation; we can multiply this special solution by any constant whatever, and get a new solution. In other words, if we had a motion of a certain \u201csize,\u201d then a motion twice as \u201cbig\u201d is again a solution. Proof: L \u2212 \u2212 (a x 1 )= a L \u2212 \u2212 ( x 1 )= a\u22c50=0 . Next, suppose that, by hook or by crook, we have not only found one solution x 1 , but also another solution, x 2 . (Remember that when we substituted x= e i\u03b1t for finding the transients, we found two values for \u03b1 , that is, two solutions, x 1 and x 2 .) Now let us show that the combination ( x 1 + x 2 ) is also a solution. In other words, if we put x= x 1 + x 2 , x is again a solution of the equation. Why? Because, if L \u2212 \u2212 ( x 1 )=0 and L \u2212 \u2212 ( x 2 )=0 , then L \u2212 \u2212 ( x 1 + x 2 )= L \u2212 \u2212 ( x 1 )+ L \u2212 \u2212 ( x 2 )=0+0=0 . So if we have found a number of solutions for the motion of a linear system we can add them together. Combining these two ideas, we see, of course, that we can also add six of one and two of the other: if x 1 is a solution, so is \u03b1 x 1 . Therefore any sum of these two solutions, such as (\u03b1 x 1 +\u03b2 x 2 ) , is also a solution. If we happen to be able to find three solutions, then we find that any combination of the three solutions is again a solution, and so on. It turns out that the number of what we call independent solutions1 that we have obtained for our oscillator problem is only two. The number of independent solutions that one finds in the general case depends upon what is called the number of degrees of freedom. We shall not discuss this in detail now, but if we have a second-order differential equation, there are only two independent solutions, and we have found both of them; so we have the most general solution. Now let us go on to another proposition, which applies to the situation in which the system is subjected to an outside force. Suppose the equation is L \u2212 \u2212 (x)=F(t), (25.6) and suppose that we have found a special solution of it. Let us say that Joe\u2019s solution is x J , and that L \u2212 \u2212 ( x J )=F(t) . Suppose we want to find yet another solution; suppose we add to Joe\u2019s solution one of those that was a solution of the free equation (25.5), say x 1 . Then we see by (25.3) that L \u2212 \u2212 ( x J + x 1 ) = L \u2212 \u2212 ( x J )+ L \u2212 \u2212 ( x 1 ) =F(t)+0 =F(t). (25.7) Therefore, to the \u201cforced\u201d solution we can add any \u201cfree\u201d solution, and we still have a solution. The free solution is called a transient solution. When we have no force acting, and suddenly turn one on, we do not immediately get the steady solution that we solved for with the sine wave solution, but for a while there is a transient which sooner or later dies out, if we wait long enough. The \u201cforced\u201d solution does not die out, since it keeps on being driven by the force. Ultimately, for long periods of time, the solution is unique, but initially the motions are different for different circumstances, depending on how the system was started. Now we come to another interesting proposition. Suppose that we have a certain particular driving force F a (let us say an oscillatory one with a certain \u03c9= \u03c9 a , but our conclusions will be true for any functional form of F a ) and we have solved for the forced motion (with or without the transients; it makes no difference). Now suppose some other force is acting, let us say F b , and we solve the same problem, but for this different force. Then suppose someone comes along and says, \u201cI have a new problem for you to solve; I have the force F a + F b .\u201d Can we do it? Of course we can do it, because the solution is the sum of the two solutions x a and x b for the forces taken separately\u2014a most remarkable circumstance indeed. If we use (25.3), we see that L \u2212 \u2212 ( x a + x b ) = L \u2212 \u2212 ( x a )+ L \u2212 \u2212 ( x b ) = F a (t)+ F b (t). (25.8) This is an example of what is called the principle of superposition for linear systems, and it is very important. It means the following: if we have a complicated force which can be broken up in any convenient manner into a sum of separate pieces, each of which is in some way simple, in the sense that for each special piece into which we have divided the force we can solve the equation, then the answer is available for the whole force, because we may simply add the pieces of the solution back together, in the same manner as the total force is compounded out of pieces (Fig. 25\u20131). Let us give another example of the principle of superposition. In Chapter 12 we said that it was one of the great facts of the laws of electricity that if we have a certain distribution of charges q a and calculate the electric field E a arising from these charges at a certain place P , and if, on the other hand, we have another set of charges q b and we calculate the field E b due to these at the corresponding place, then if both charge distributions are present at the same time, the field E at P is the sum of E a due to one set plus E b due to the other. In other words, if we know the field due to a certain charge, then the field due to many charges is merely the vector sum of the fields of these charges taken individually. This is exactly analogous to the above proposition that if we know the result of two given forces taken at one time, then if the force is considered as a sum of them, the response is a sum of the corresponding individual responses. The reason why this is true in electricity is that the great laws of electricity, Maxwell\u2019s equations, which determine the electric field, turn out to be differential equations which are linear, i.e., which have the property (25.3). What corresponds to the force is the charge generating the electric field, and the equation which determines the electric field in terms of the charge is linear. As another interesting example of this proposition, let us ask how it is possible to \u201ctune in\u201d to a particular radio station at the same time as all the radio stations are broadcasting. The radio station transmits, fundamentally, an oscillating electric field of very high frequency which acts on our radio antenna. It is true that the amplitude of the oscillation of the field is changed, modulated, to carry the signal of the voice, but that is very slow, and we are not going to worry about it. When one hears \u201cThis station is broadcasting at a frequency of 780 kilocycles,\u201d this indicates that 780,000 oscillations per second is the frequency of the electric field of the station antenna, and this drives the electrons up and down at that frequency in our antenna. Now at the same time we may have another radio station in the same town radiating at a different frequency, say 550 kilocycles per second; then the electrons in our antenna are also being driven by that frequency. Now the question is, how is it that we can separate the signals coming into the one radio at 780 kilocycles from those coming in at 550 kilocycles? We certainly do not hear both stations at the same time. By the principle of superposition, the response of the electric circuit in the radio, the first part of which is a linear circuit, to the forces that are acting due to the electric field F a + F b , is x a + x b . It therefore looks as though we will never disentangle them. In fact, the very proposition of superposition seems to insist that we cannot avoid having both of them in our system. But remember, for a resonant circuit, the response curve, the amount of x per unit F , as a function of the frequency, looks like Fig. 25\u20133. If it were a very high Q circuit, the response would show a very sharp maximum. Now suppose that the two stations are comparable in strength, that is, the two forces are of the same magnitude. The response that we get is the sum of x a and x b . But, in Fig. 25\u20133, x a is tremendous, while x b is small. So, in spite of the fact that the two signals are equal in strength, when they go through the sharp resonant circuit of the radio tuned for \u03c9 a , the frequency of the transmission of one station, then the response to this station is much greater than to the other. Therefore the complete response, with both signals acting, is almost all made up of \u03c9 a , and we have selected the station we want. Now what about the tuning? How do we tune it? We change \u03c9 0 by changing the L or the C of the circuit, because the frequency of the circuit has to do with the combination of L and C . In particular, most radios are built so that one can change the capacitance. When we retune the radio, we can make a new setting of the dial, so that the natural frequency of the circuit is shifted, say, to \u03c9 c . In those circumstances we hear neither one station nor the other; we get silence, provided there is no other station at frequency \u03c9 c . If we keep on changing the capacitance until the resonance curve is at \u03c9 b , then of course we hear the other station. That is how radio tuning works; it is again the principle of superposition, combined with a resonant response.2 To conclude this discussion, let us describe qualitatively what happens if we proceed further in analyzing a linear problem with a given force, when the force is quite complicated. Out of the many possible procedures, there are two especially useful general ways that we can solve the problem. One is this: suppose that we can solve it for special known forces, such as sine waves of different frequencies. We know it is child\u2019s play to solve it for sine waves. So we have the so-called \u201cchild\u2019s play\u201d cases. Now the question is whether our very complicated force can be represented as the sum of two or more \u201cchild\u2019s play\u201d forces. In Fig. 25\u20131 we already had a fairly complicated curve, and of course we can make it more complicated still if we add in more sine waves. So it is certainly possible to obtain very complicated curves. And, in fact, the reverse is also true: practically every curve can be obtained by adding together infinite numbers of sine waves of different wavelengths (or frequencies) for each one of which we know the answer. We just have to know how much of each sine wave to put in to make the given F , and then our answer, x , is the corresponding sum of the F sine waves, each multiplied by its effective ratio of x to F . This method of solution is called the method of Fourier transforms or Fourier analysis. We are not going to actually carry out such an analysis just now; we only wish to describe the idea involved. Another way in which our complicated problem can be solved is the following very interesting one. Suppose that, by some tremendous mental effort, it were possible to solve our problem for a special force, namely an impulse. The force is quickly turned on and then off; it is all over. Actually we need only solve for an impulse of some unit strength, any other strength can be gotten by multiplication by an appropriate factor. We know that the response x for an impulse is a damped oscillation. Now what can we say about some other force, for instance a force like that of Fig. 25\u20134? Such a force can be likened to a succession of blows with a hammer. First there is no force, and all of a sudden there is a steady force\u2014impulse, impulse, impulse, impulse, \u2026 and then it stops. In other words, we imagine the continuous force to be a series of impulses, very close together. Now, we know the result for an impulse, so the result for a whole series of impulses will be a whole series of damped oscillations: it will be the curve for the first impulse, and then (slightly later) we add to that the curve for the second impulse, and the curve for the third impulse, and so on. Thus we can represent, mathematically, the complete solution for arbitrary functions if we know the answer for an impulse. We get the answer for any other force simply by integrating. This method is called the Green\u2019s function method. A Green\u2019s function is a response to an impulse, and the method of analyzing any force by putting together the response of impulses is called the Green\u2019s function method. The physical principles involved in both of these schemes are so simple, involving just the linear equation, that they can be readily understood, but the mathematical problems that are involved, the complicated integrations and so on, are a little too advanced for us to attack right now. You will most likely return to this some day when you have had more practice in mathematics. But the idea is very simple indeed. Finally, we make some remarks on why linear systems are so important. The answer is simple: because we can solve them! So most of the time we solve linear problems. Second (and most important), it turns out that the fundamental laws of physics are often linear. The Maxwell equations for the laws of electricity are linear, for example. The great laws of quantum mechanics turn out, so far as we know, to be linear equations. That is why we spend so much time on linear equations: because if we understand linear equations, we are ready, in principle, to understand a lot of things. We mention another situation where linear equations are found. When displacements are small, many functions can be approximated linearly. For example, if we have a simple pendulum, the correct equation for its motion is d 2 \u03b8/d t 2 =\u2212(g/L)sin\u03b8. (25.9) This equation can be solved by elliptic functions, but the easiest way to solve it is numerically, as was shown in Chapter 9 on Newton\u2019s Laws of Motion. A nonlinear equation cannot be solved, ordinarily, any other way but numerically. Now for small \u03b8 , sin\u03b8 is practically equal to \u03b8 , and we have a linear equation. It turns out that there are many circumstances where small effects are linear: for the example here the swing of a pendulum through small arcs. As another example, if we pull a little bit on a spring, the force is proportional to the extension. If we pull hard, we break the spring, and the force is a completely different function of the distance! Linear equations are important. In fact they are so important that perhaps fifty percent of the time we are solving linear equations in physics and in engineering. Let us now review the things we have been talking about in the past few chapters. It is very easy for the physics of oscillators to become obscured by the mathematics. The physics is actually very simple, and if we may forget the mathematics for a moment we shall see that we can understand almost everything that happens in an oscillating system. First, if we have only the spring and the weight, it is easy to understand why the system oscillates\u2014it is a consequence of inertia. We pull the mass down and the force pulls it back up; as it passes zero, which is the place it likes to be, it cannot just suddenly stop; because of its momentum it keeps on going and swings to the other side, and back and forth. So, if there were no friction, we would surely expect an oscillatory motion, and indeed we get one. But if there is even a little bit of friction, then on the return cycle, the swing will not be quite as high as it was the first time. Now what happens, cycle by cycle? That depends on the kind and amount of friction. Suppose that we could concoct a kind of friction force that always remains in the same proportion to the other forces, of inertia and in the spring, as the amplitude of oscillation varies. In other words, for smaller oscillations the friction should be weaker than for big oscillations. Ordinary friction does not have this property, so a special kind of friction must be carefully invented for the very purpose of creating a friction that is directly proportional to the velocity\u2014so that for big oscillations it is stronger and for small oscillations it is weaker. If we happen to have that kind of friction, then at the end of each successive cycle the system is in the same condition as it was at the start, except a little bit smaller. All the forces are smaller in the same proportion: the spring force is reduced, the inertial effects are lower because the accelerations are now weaker, and the friction is less too, by our careful design. When we actually have that kind of friction, we find that each oscillation is exactly the same as the first one, except reduced in amplitude. If the first cycle dropped the amplitude, say, to 90 percent of what it was at the start, the next will drop it to 90 percent of 90 percent, and so on: the sizes of the oscillations are reduced by the same fraction of themselves in every cycle. An exponential function is a curve which does just that. It changes by the same factor in each equal interval of time. That is to say, if the amplitude of one cycle, relative to the preceding one, is called a , then the amplitude of the next is a 2 , and of the next, a 3 . So the amplitude is some constant raised to a power equal to the number of cycles traversed: A= A 0 a n . (25.10) But of course n\u221dt , so it is perfectly clear that the general solution will be some kind of an oscillation, sine or cosine \u03c9t , times an amplitude which goes as b t more or less. But b can be written as e \u2212c , if b is positive and less than 1 . So this is why the solution looks like e \u2212ct cos \u03c9 0 t . It is very simple. What happens if the friction is not so artificial; for example, ordinary rubbing on a table, so that the friction force is a certain constant amount, and is independent of the size of the oscillation that reverses its direction each half-cycle? Then the equation is no longer linear, it becomes hard to solve, and must be solved by the numerical method given in Chapter 9, or by considering each half-cycle separately. The numerical method is the most powerful method of all, and can solve any equation. It is only when we have a simple problem that we can use mathematical analysis. Mathematical analysis is not the grand thing it is said to be; it solves only the simplest possible equations. As soon as the equations get a little more complicated, just a shade\u2014they cannot be solved analytically. But the numerical method, which was advertised at the beginning of the course, can take care of any equation of physical interest. Next, what about the resonance curve? Why is there a resonance? First, imagine for a moment that there is no friction, and we have something which could oscillate by itself. If we tapped the pendulum just right each time it went by, of course we could make it go like mad. But if we close our eyes and do not watch it, and tap at arbitrary equal intervals, what is going to happen? Sometimes we will find ourselves tapping when it is going the wrong way. When we happen to have the timing just right, of course, each tap is given at just the right time, and so it goes higher and higher and higher. So without friction we get a curve which looks like the solid curve in Fig. 25\u20135 for different frequencies. Qualitatively, we understand the resonance curve; in order to get the exact shape of the curve it is probably just as well to do the mathematics. The curve goes toward infinity as \u03c9\u2192 \u03c9 0 , where \u03c9 0 is the natural frequency of the oscillator. Now suppose there is a little bit of friction; then when the displacement of the oscillator is small, the friction does not affect it much; the resonance curve is the same, except when we are near resonance. Instead of becoming infinite near resonance, the curve is only going to get so high that the work done by our tapping each time is enough to compensate for the loss of energy by friction during the cycle. So the top of the curve is rounded off\u2014it does not go to infinity. If there is more friction, the top of the curve is rounded off still more. Now someone might say, \u201cI thought the widths of the curves depended on the friction.\u201d That is because the curve is usually plotted so that the top of the curve is called one unit. However, the mathematical expression is even simpler to understand if we just plot all the curves on the same scale; then all that happens is that the friction cuts down the top! If there is less friction, we can go farther up into that little pinnacle before the friction cuts it off, so it looks relatively narrow. That is, the higher the peak of the curve, the narrower the width at half the maximum height. Finally, we take the case where there is an enormous amount of friction. It turns out that if there is too much friction, the system does not oscillate at all. The energy in the spring is barely able to move it against the frictional force, and so it slowly oozes down to the equilibrium point. The next aspect of this review is to note that masses and springs are not the only linear systems; there are others. In particular, there are electrical systems called linear circuits, in which we find a complete analog to mechanical systems. We did not learn exactly why each of the objects in an electrical circuit works in the way it does\u2014that is not to be understood at the present moment; we may assert it as an experimentally verifiable fact that they behave as stated. For example, let us take the simplest possible circumstance. We have a piece of wire, which is just a resistance, and we have applied to it a difference in potential, V . Now the V means this: if we carry a charge q through the wire from one terminal to another terminal, the work done is qV . The higher the voltage difference, the more work was done when the charge, as we say, \u201cfalls\u201d from the high potential end of the terminal to the low potential end. So charges release energy in going from one end to the other. Now the charges do not simply fly from one end straight to the other end; the atoms in the wire offer some resistance to the current, and this resistance obeys the following law for almost all ordinary substances: if there is a current I , that is, so and so many charges per second tumbling down, the number per second that comes tumbling through the wire is proportional to how hard we push them\u2014in other words, proportional to how much voltage there is: V=IR=R(dq/dt). (25.11) The coefficient R is called the resistance, and the equation is called Ohm\u2019s Law. The unit of resistance is the ohm; it is equal to one volt per ampere. In mechanical situations, to get such a frictional force in proportion to the velocity is difficult; in an electrical system it is very easy, and this law is extremely accurate for most metals. We are often interested in how much work is done per second, the power loss, or the energy liberated by the charges as they tumble down the wire. When we carry a charge q through a voltage V , the work is qV , so the work done per second would be V(dq/dt) , which is the same as VI , or also IR\u22c5I= I 2 R . This is called the heating loss\u2014this is how much heat is generated in the resistance per second, by the conservation of energy. It is this heat that makes an ordinary incandescent light bulb work. Of course, there are other interesting properties of mechanical systems, such as the mass (inertia), and it turns out that there is an electrical analog to inertia also. It is possible to make something called an inductor, having a property called inductance, such that a current, once started through the inductance, does not want to stop. It requires a voltage in order to change the current! If the current is constant, there is no voltage across an inductance. dc circuits do not know anything about inductance; it is only when we change the current that the effects of inductance show up. The equation is V=L(dI/dt)=L( d 2 q/d t 2 ), (25.12) and the unit of inductance, called the henry, is such that one volt applied to an inductance of one henry produces a change of one ampere per second in the current. Equation (25.12) is the analog of Newton\u2019s law for electricity, if we wish: V corresponds to F , L corresponds to m , and I corresponds to velocity! All of the consequent equations for the two kinds of systems will have the same derivations because, in all the equations, we can change any letter to its corresponding analog letter and we get the same equation; everything we deduce will have a correspondence in the two systems. Now what electrical thing corresponds to the mechanical spring, in which there was a force proportional to the stretch? If we start with F=kx and replace F\u2192V and x\u2192q , we get V=\u03b1q . It turns out that there is such a thing, in fact it is the only one of the three circuit elements we can really understand, because we did study a pair of parallel plates, and we found that if there were a charge of certain equal, opposite amounts on each plate, the electric field between them would be proportional to the size of the charge. So the work done in moving a unit charge across the gap from one plate to the other is precisely proportional to the charge. This work is the definition of the voltage difference, and it is the line integral of the electric field from one plate to another. It turns out, for historical reasons, that the constant of proportionality is not called C , but 1/C . It could have been called C , but it was not. So we have V=q/C. (25.13) The unit of capacitance, C , is the farad; a charge of one coulomb on each plate of a one-farad capacitor yields a voltage difference of one volt. There are our analogies, and the equation corresponding to the oscillating circuit becomes the following, by direct substitution of L for m , q for x , etc: m( d 2 x/d t 2 ) L( d 2 q/d t 2 ) +\u03b3m(dx/dt)+kx +R(dq/dt)+q/C =F, =V. (25.14) (25.15) Now everything we learned about (25.14) can be transformed to apply to (25.15). Every consequence is the same; so much the same that there is a brilliant thing we can do. Suppose we have a mechanical system which is quite complicated, not just one mass on a spring, but several masses on several springs, all hooked together. What do we do? Solve it? Perhaps; but look, we can make an electrical circuit which will have the same equations as the thing we are trying to analyze! For instance, if we wanted to analyze a mass on a spring, why can we not build an electrical circuit in which we use an inductance proportional to the mass, a resistance proportional to the corresponding m\u03b3 , 1/C proportional to k , all in the same ratio? Then, of course, this electrical circuit will be the exact analog of our mechanical one, in the sense that whatever q does, in response to V ( V also is made to correspond to the forces that are acting), so the x would do in response to the force! So if we have a complicated thing with a whole lot of interconnecting elements, we can interconnect a whole lot of resistances, inductances, and capacitances, to imitate the mechanically complicated system. What is the advantage to that? One problem is just as hard (or as easy) as the other, because they are exactly equivalent. The advantage is not that it is any easier to solve the mathematical equations after we discover that we have an electrical circuit (although that is the method used by electrical engineers!), but instead, the real reason for looking at the analog is that it is easier to make the electrical circuit, and to change something in the system. Suppose we have designed an automobile, and want to know how much it is going to shake when it goes over a certain kind of bumpy road. We build an electrical circuit with inductances to represent the inertia of the wheels, spring constants as capacitances to represent the springs of the wheels, and resistors to represent the shock absorbers, and so on for the other parts of the automobile. Then we need a bumpy road. All right, we apply a voltage from a generator, which represents such and such a kind of bump, and then look at how the left wheel jiggles by measuring the charge on some capacitor. Having measured it (it is easy to do), we find that it is bumping too much. Do we need more shock absorber, or less shock absorber? With a complicated thing like an automobile, do we actually change the shock absorber, and solve it all over again? No!, we simply turn a dial; dial number ten is shock absorber number three, so we put in more shock absorber. The bumps are worse\u2014all right, we try less. The bumps are still worse; we change the stiffness of the spring (dial 17 ), and we adjust all these things electrically, with merely the turn of a knob. This is called an analog computer. It is a device which imitates the problem that we want to solve by making another problem, which has the same equation, but in another circumstance of nature, and which is easier to build, to measure, to adjust, and to destroy! Finally, there is an important item which is not quite in the nature of review. This has to do with an electrical circuit in which there is more than one circuit element. For example, when we have an inductor, a resistor, and a capacitor connected as in Fig. 24\u20132, we note that all the charge went through every one of the three, so that the current in such a singly connected thing is the same at all points along the wire. Since the current is the same in each one, the voltage across R is IR , the voltage across L is L(dI/dt) , and so on. So, the total voltage drop is the sum of these, and this leads to Eq. (25.15). Using complex numbers, we found that we could solve the equation for the steady-state motion in response to a sinusoidal force. We thus found that V ^ = Z ^ I ^ . Now Z ^ is called the impedance of this particular circuit. It tells us that if we apply a sinusoidal voltage, V ^ , we get a current I ^ . Now suppose we have a more complicated circuit which has two pieces, which by themselves have certain impedances, Z ^ 1 and Z ^ 2 and we put them in series (Fig. 25\u20136a) and apply a voltage. What happens? It is now a little more complicated, but if I ^ is the current through Z ^ 1 , the voltage difference across Z ^ 1 , is V ^ 1 = I ^ Z ^ 1 ; similarly, the voltage across Z ^ 2 is V ^ 2 = I ^ Z ^ 2 . The same current goes through both. Therefore the total voltage is the sum of the voltages across the two sections and is equal to V ^ = V ^ 1 + V ^ 2 =( Z ^ 1 + Z ^ 2 ) I ^ . This means that the voltage on the complete circuit can be written V ^ = I ^ Z ^ s , where the Z ^ s of the combined system in series is the sum of the two Z ^ \u2019s of the separate pieces: Z ^ s = Z ^ 1 + Z ^ 2 . (25.16) This is not the only way things may be connected. We may also connect them in another way, called a parallel connection (Fig. 25\u20136b). Now we see that a given voltage across the terminals, if the connecting wires are perfect conductors, is effectively applied to both of the impedances, and will cause currents in each independently. Therefore the current through Z ^ 1 is equal to I ^ 1 = V ^ / Z ^ 1 . The current in Z ^ 2 is I ^ 2 = V ^ / Z ^ 2 . It is the same voltage. Now the total current which is supplied to the terminals is the sum of the currents in the two sections: I ^ = V ^ / Z ^ 1 + V ^ / Z ^ 2 . This can be written as V ^ = I ^ (1/ Z ^ 1 )+(1/ Z ^ 2 ) = I ^ Z ^ p . Thus 1/ Z ^ p =1/ Z ^ 1 +1/ Z ^ 2 . (25.17) More complicated circuits can sometimes be simplified by taking pieces of them, working out the succession of impedances of the pieces, and combining the circuit together step by step, using the above rules. If we have any kind of circuit with many impedances connected in all kinds of ways, and if we include the voltages in the form of little generators having no impedance (when we pass charge through it, the generator adds a voltage V ), then the following principles apply: (1) At any junction, the sum of the currents into a junction is zero. That is, all the current which comes in must come back out. (2) If we carry a charge around any loop, and back to where it started, the net work done is zero. These rules are called Kirchhoff\u2019s laws for electrical circuits. Their systematic application to complicated circuits often simplifies the analysis of such circuits. We mention them here in conjunction with Eqs. (25.16) and (25.17), in case you have already come across such circuits that you need to analyze in laboratory work. They will be discussed again in more detail next year."
    },
    {
        "input": "The Vector Potential",
        "output": "In the last chapter we studied the magnetic field produced by a small rectangular current loop. We found that it is a dipole field, with the dipole moment given by \u03bc=IA, where I is the current and A is the area of the loop. The direction of the moment is normal to the plane of the loop, so we can also write \u03bc=IAn, where n is the unit normal to the area A . A current loop\u2014or magnetic dipole\u2014not only produces magnetic fields, but will also experience forces when placed in the magnetic field of other currents. We will look first at the forces on a rectangular loop in a uniform magnetic field. Let the z -axis be along the direction of the field, and the plane of the loop be placed through the y -axis, making the angle \u03b8 with the xy -plane as in Fig. 15\u20131. Then the magnetic moment of the loop\u2014which is normal to its plane\u2014will make the angle \u03b8 with the magnetic field. Since the currents are opposite on opposite sides of the loop, the forces are also opposite, so there is no net force on the loop (when the field is uniform). Because of forces on the two sides marked 1 and 2 in the figure, however, there is a torque which tends to rotate the loop about the y -axis. The magnitude of these forces F1 and F2 is F1=F2=IBb. Their moment arm is asin\u03b8, so the torque is \u03c4=IabBsin\u03b8. or, since Iab is the magnetic moment of the loop, \u03c4=\u03bcBsin\u03b8. The torque can be written in vector notation: \u03c4=\u03bc\u00d7B. Although we have only shown that the torque is given by Eq. (15.2) in one rather special case, the result is right for a small loop of any shape, as we will see. The same kind of relationship holds for the torque of an electric dipole in an electric field: \u03c4=p\u00d7E. We now ask about the mechanical energy of our current loop. Since there is a torque, the energy evidently depends on the orientation. The principle of virtual work says that the torque is the rate of change of energy with angle, so we can write dU=\u03c4d\u03b8. Setting \u03c4=\u03bcBsin\u03b8 , and integrating, we can write for the energy U=\u2212\u03bcBcos\u03b8+a constant. (The sign is negative because the torque tries to line up the moment with the field; the energy is lowest when \u03bc and B are parallel.) For reasons which we will discuss later, this energy is not the total energy of a current loop. (We have, for one thing, not taken into account the energy required to maintain the current in the loop.) We will, therefore, call this energy Umech , to remind us that it is only part of the energy. Also, since we are leaving out some of the energy anyway, we can set the constant of integration equal to zero in Eq. (15.3). So we rewrite the equation: Umech=\u2212\u03bc\u22c5B. Again, this corresponds to the result for an electric dipole: U=\u2212p\u22c5E. Now the electrostatic energy U in Eq. (15.5) is the true energy, but Umech in (15.4) is not the real energy. It can, however, be used in computing forces, by the principle of virtual work, supposing that the current in the loop\u2014or at least \u03bc \u2014is kept constant. We can show for our rectangular loop that Umech also corresponds to the mechanical work done in bringing the loop into the field. The total force on the loop is zero only in a uniform field; in a nonuniform field there are net forces on a current loop. In putting the loop into a region with a field, we must have gone through places where the field was not uniform, and so work was done. To make the calculation simple, we shall imagine that the loop is brought into the field with its moment pointing along the field. (It can be rotated to its final position after it is in place.) Imagine that we want to move the loop in the x -direction\u2014toward a region of stronger field\u2014and that the loop is oriented as shown in Fig. 15\u20132. We start somewhere where the field is zero and integrate the force times the distance as we bring the loop into the field. First, let\u2019s compute the work done on each side separately and then take the sum (rather than adding the forces before integrating). The forces on sides 3 and 4 are at right angles to the direction of motion, so no work is done on them. The force on side 2 is IbB(x) in the x -direction, and to get the work done against the magnetic forces we must integrate this from some x where the field is zero, say at x=\u2212\u221e , to x2 , its present position: W2=\u2212\u222b x2 \u2212\u221e F2dx=\u2212Ib\u222b x2 \u2212\u221e B(x)dx. Similarly, the work done against the forces on side 1 is W1=\u2212\u222b x1 \u2212\u221e F1dx=Ib\u222b x1 \u2212\u221e B(x)dx. To find each integral, we need to know how B(x) depends on x . But notice that side 1 follows along right behind side 2 , so that its integral includes most of the work done on side 2 . In fact, the sum of (15.6) and (15.7) is just W=\u2212Ib\u222b x2 x1 B(x)dx. But if we are in a region where B is nearly the same on both sides 1 and 2 , we can write the integral as \u222b x2 x1 B(x)dx=(x2\u2212x1)B=aB, where B is the field at the center of the loop. The total mechanical energy we have put in is Umech=W=\u2212IabB=\u2212\u03bcB. The result agrees with the energy we took for Eq. (15.4). We would, of course, have gotten the same result if we had added the forces on the loop before integrating to find the work. If we let B 1 be the field at side 1 and B 2 be the field at side 2 , then the total force in the x -direction is F x =Ib( B 2 \u2212 B 1 ). If the loop is \u201csmall,\u201d that is, if B 2 and B 1 are not too different, we can write B 2 = B 1 + \u2202B \u2202x \u0394x= B 1 + \u2202B \u2202x a. So the force is F x =Iab \u2202B \u2202x . (15.10) The total work done on the loop by external forces is \u2212 \u222b x \u2212\u221e F x dx=\u2212Iab\u222b \u2202B \u2202x dx=\u2212IabB, which is again just \u2212\u03bcB . Only now we see why it is that the force on a small current loop is proportional to the derivative of the magnetic field, as we would expect from F x \u0394x=\u2212\u0394 U mech =\u2212\u0394(\u2212\u03bc\u22c5B). (15.11) Our result, then, is that even though U mech =\u2212\u03bc\u22c5B may not include all the energy of a system\u2014it is a fake kind of energy\u2014it can still be used with the principle of virtual work to find the forces on steady current loops. We want now to show why the energy U mech discussed in the previous section is not the correct energy associated with steady currents\u2014that it does not keep track of the total energy in the world. We have, indeed, emphasized that it can be used like the energy, for computing forces from the principle of virtual work, provided that the current in the loop (and all other currents) do not change. Let\u2019s see why all this works. Imagine that the loop in Fig. 15\u20132 is moving in the +x -direction and take the z -axis in the direction of B . The conduction electrons in side 2 will experience a force along the wire, in the y -direction. But because of their flow\u2014as an electric current\u2014there is a component of their motion in the same direction as the force. Each electron is, therefore, having work done on it at the rate F y v y , where v y , is the component of the electron velocity along the wire. We will call this work done on the electrons electrical work. Now it turns out that if the loop is moving in a uniform field, the total electrical work is zero, since positive work is done on some parts of the loop and an equal amount of negative work is done on other parts. But this is not true if the circuit is moving in a nonuniform field\u2014then there will be a net amount of work done on the electrons. In general, this work would tend to change the flow of the electrons, but if the current is being held constant, energy must be absorbed or delivered by the battery or other source that is keeping the current steady. This energy was not included when we computed U mech in Eq. (15.9), because our computations included only the mechanical forces on the body of the wire. You may be thinking: But the force on the electrons depends on how fast the wire is moved; perhaps if the wire is moved slowly enough this electrical energy can be neglected. It is true that the rate at which the electrical energy is delivered is proportional to the speed of the wire, but the total energy delivered is proportional also to the time that this rate goes on. So the total electrical energy is proportional to the velocity times the time, which is just the distance moved. For a given distance moved in a field the same amount of electrical work is done. Let\u2019s consider a segment of wire of unit length carrying the current I and moving in a direction perpendicular to itself and to a magnetic field B with the speed v wire . Because of the current the electrons will have a drift velocity v drift along the wire. The component of the magnetic force on each electron in the direction of the drift is q e v wire B . So the rate at which electrical work is being done is F v drift =( q e v wire B) v drift . If there are N conduction electrons in the unit length of the wire, the total rate at which electrical work is being done is d U elect dt =N q e v wire B v drift . d U But N q e v drift =I , the current in the wire, so d U elect dt =I v wire B. d U Now since the current is held constant, the forces on the conduction electrons do not cause them to accelerate; the electrical energy is not going into the electrons but into the source that is keeping the current constant. But notice that the force on the wire is IB , so IB v wire is also the rate of mechanical work done on the wire, d U mech /dt=IB v wire . We conclude that the mechanical work done on the wire is just equal to the electrical work done on the current source, so the energy of the loop is a constant! This is not a coincidence, but a consequence of the law we already know. The total force on each charge in the wire is F=q(E+v\u00d7B). ( ) The rate at which work is done is v\u22c5F=q[v\u22c5E+v\u22c5(v\u00d7B)]. (15.12) If there are no electric fields we have only the second term, which is always zero. We shall see later that changing magnetic fields produce electric fields, so our reasoning applies only to moving wires in steady magnetic fields. How is it then that the principle of virtual work gives the right answer? Because we still have not taken into account the total energy of the world. We have not included the energy of the currents that are producing the magnetic field we start out with. Suppose we imagine a complete system such as that drawn in Fig. 15\u20133(a), in which we are moving our loop with the current I 1 into the magnetic field B 1 produced by the current I 2 in a coil. Now the current I 1 in the loop will also be producing some magnetic field B 2 at the coil. If the loop is moving, the field B 2 will be changing. As we shall see in the next chapter, a changing magnetic field generates an E -field; and this E -field will do work on the charges in the coil. This energy must also be included in our balance sheet of the total energy. We could wait until the next chapter to find out about this new energy term, but we can also see what it will be if we use the principle of relativity in the following way. When we are moving the loop toward the stationary coil we know that its electrical energy is just equal and opposite to the mechanical work done. So U mech + U elect (loop)=0. ( loop ) Suppose now we look at what is happening from a different point of view, in which the loop is at rest, and the coil is moved toward it. The coil is then moving into the field produced by the loop. The same arguments would give that U mech + U elect (coil)=0. ( coil ) The mechanical energy is the same in the two cases because it comes from the force between the two circuits. The sum of the two equations gives 2 U mech + U elect (loop)+ U elect (coil)=0. ( loop ) ( coil ) The total energy of the whole system is, of course, the sum of the two electrical energies plus the mechanical energy taken only once. So we have U total = U elect (loop)+ U elect (coil)+ U mech =\u2212 U mech . (15.13) The total energy of the world is really the negative of U mech . If we want the true energy of a magnetic dipole, for example, we should write U total =+\u03bc\u22c5B. U B It is only if we make the condition that all currents are constant that we can use only a part of the energy, U mech (which is always the negative of the true energy), to find the mechanical forces. In a more general problem, we must be careful to include all energies. We have seen an analogous situation in electrostatics. We showed that the energy of a capacitor is equal to Q 2 /2C . When we use the principle of virtual work to find the force between the plates of the capacitor, the change in energy is equal to Q 2 /2 times the change in 1/C . That is, \u0394U= Q 2 2 \u0394( 1 C )=\u2212 Q 2 2 \u0394C C 2 . (15.14) Now suppose that we were to calculate the work done in moving two conductors subject to the different condition that the voltage between them is held constant. Then we can get the right answers for force from the principle of virtual work if we do something artificial. Since Q=CV , the real energy is 1 2 C V 2 . But if we define an artificial energy equal to \u2212 1 2 C V 2 , then the principle of virtual work can be used to get forces by setting the change in the artificial energy equal to the mechanical work, provided that we insist that the voltage V be held constant. Then \u0394 U mech =\u0394(\u2212 C V 2 2 )=\u2212 V 2 2 \u0394C, (15.15) which is the same as Eq. (15.14). We get the correct result even though we are neglecting the work done by the electrical system to keep the voltage constant. Again, this electrical energy is just twice as big as the mechanical energy and of the opposite sign. Thus if we calculate artificially, disregarding the fact that the source of the potential has to do work to maintain the voltages constant, we get the right answer. It is exactly analogous to the situation in magnetostatics. We can now use our knowledge that U total =\u2212 U mech to find the true energy of steady currents in magnetic fields. We can begin with the true energy of a small current loop. Calling U total just U , we write U=\u03bc\u22c5B. (15.16) Although we calculated this energy for a plane rectangular loop, the same result holds for a small plane loop of any shape. We can find the energy of a circuit of any shape by imagining that it is made up of small current loops. Say we have a wire in the shape of the loop \u0393 of Fig. 15\u20134. We fill in this curve with the surface S , and on the surface mark out a large number of small loops, each of which can be considered plane. If we let the current I circulate around each of the little loops, the net result will be the same as a current around \u0393 , since the currents will cancel on all lines internal to \u0393 . Physically, the system of little currents is indistinguishable from the original circuit. The energy must also be the same, and so is just the sum of the energies of the little loops. If the area of each little loop is \u0394a , its energy is I\u0394a B n , where B n is the component normal to \u0394a . The total energy is U=\u2211I B n \u0394a. \u2211 Going to the limit of infinitesimal loops, the sum becomes an integral, and U=I\u222b B n da=I\u222bB\u22c5nda, (15.17) where n is the unit normal to da . If we set B=\u2207\u00d7A , we can connect the surface integral to a line integral, using Stokes\u2019 theorem, I \u222b S (\u2207\u00d7A)\u22c5nda=I \u222e \u0393 A\u22c5ds, (15.18) where ds is the line element along \u0393 . So we have the energy for a circuit of any shape: U=I \u222e circuit A\u22c5ds, (15.19) In this expression A refers, of course, to the vector potential due to those currents (other than the I in the wire) which produce the field B at the wire. Now any distribution of steady currents can be imagined to be made up of filaments that run parallel to the lines of current flow. For each pair of such circuits, the energy is given by (15.19), where the integral is taken around one circuit, using the vector potential A from the other circuit. For the total energy we want the sum of all such pairs. If, instead of keeping track of the pairs, we take the complete sum over all the filaments, we would be counting the energy twice (we saw a similar effect in electrostatics), so the total energy can be written U= 1 2 \u222bj\u22c5AdV. (15.20) This formula corresponds to the result we found for the electrostatic energy: U= 1 2 \u222b\u03c1\u03d5dV. (15.21) So we may if we wish think of A as a kind of potential for currents in magnetostatics. Unfortunately, this idea is not too useful, because it is true only for static fields. In fact, neither of the equations (15.20) and (15.21) gives the correct energy when the fields change with time. In this section we would like to discuss the following questions: Is the vector potential merely a device which is useful in making calculations\u2014as the scalar potential is useful in electrostatics\u2014or is the vector potential a \u201creal\u201d field? Isn\u2019t the magnetic field the \u201creal\u201d field, because it is responsible for the force on a moving particle? First we should say that the phrase \u201ca real field\u201d is not very meaningful. For one thing, you probably don\u2019t feel that the magnetic field is very \u201creal\u201d anyway, because even the whole idea of a field is a rather abstract thing. You cannot put out your hand and feel the magnetic field. Furthermore, the value of the magnetic field is not very definite; by choosing a suitable moving coordinate system, for instance, you can make a magnetic field at a given point disappear. What we mean here by a \u201creal\u201d field is this: a real field is a mathematical function we use for avoiding the idea of action at a distance. If we have a charged particle at the position P , it is affected by other charges located at some distance from P . One way to describe the interaction is to say that the other charges make some \u201ccondition\u201d\u2014whatever it may be\u2014in the environment at P . If we know that condition, which we describe by giving the electric and magnetic fields, then we can determine completely the behavior of the particle\u2014with no further reference to how those conditions came about. In other words, if those other charges were altered in some way, but the conditions at P that are described by the electric and magnetic field at P remain the same, then the motion of the charge will also be the same. A \u201creal\u201d field is then a set of numbers we specify in such a way that what happens at a point depends only on the numbers at that point. We do not need to know any more about what\u2019s going on at other places. It is in this sense that we will discuss whether the vector potential is a \u201creal\u201d field. You may be wondering about the fact that the vector potential is not unique\u2014that it can be changed by adding the gradient of any scalar with no change at all in the forces on particles. That has not, however, anything to do with the question of reality in the sense that we are talking about. For instance, the magnetic field is in a sense altered by a relativity change (as are also E and A ). But we are not worried about what happens if the field can be changed in this way. That doesn\u2019t really make any difference; that has nothing to do with the question of whether the vector potential is a proper \u201creal\u201d field for describing magnetic effects, or whether it is just a useful mathematical tool. We should also make some remarks on the usefulness of the vector potential A . We have seen that it can be used in a formal procedure for calculating the magnetic fields of known currents, just as \u03d5 can be used to find electric fields. In electrostatics we saw that \u03d5 was given by the scalar integral \u03d5(1)= 1 4\u03c0 \u03f5 0 \u222b \u03c1(2) r 12 d V 2 . (15.22) From this \u03d5 , we get the three components of E by three differential operations. This procedure is usually easier to handle than evaluating the three integrals in the vector formula E(1)= 1 4\u03c0 \u03f5 0 \u222b \u03c1(2) e 12 r 2 12 d V 2 . (15.23) First, there are three integrals; and second, each integral is in general somewhat more difficult. The advantages are much less clear for magnetostatics. The integral for A is already a vector integral: A(1)= 1 4\u03c0 \u03f5 0 c 2 \u222b j(2)d V 2 r 12 , (15.24) which is, of course, three integrals. Also, when we take the curl of A to get B , we have six derivatives to do and combine by pairs. It is not immediately obvious whether in most problems this procedure is really any easier than computing B directly from B(1)= 1 4\u03c0 \u03f5 0 c 2 \u222b j(2)\u00d7 e 12 r 2 12 d V 2 . (15.25) Using the vector potential is often more difficult for simple problems for the following reason. Suppose we are interested only in the magnetic field B at one point, and that the problem has some nice symmetry\u2014say we want the field at a point on the axis of a ring of current. Because of the symmetry, we can easily get B by doing the integral of Eq. (15.25). If, however, we were to find A first, we would have to compute B from derivatives of A , so we must know what A is at all points in the neighborhood of the point of interest. And most of these points are off the axis of symmetry, so the integral for A gets complicated. In the ring problem, for example, we would need to use elliptic integrals. In such problems, A is clearly not very useful. It is true that in many complex problems it is easier to work with A , but it would be hard to argue that this ease of technique would justify making you learn about one more vector field. We have introduced A because it does have an important physical significance. Not only is it related to the energies of currents, as we saw in the last section, but it is also a \u201creal\u201d physical field in the sense that we described above. In classical mechanics it is clear that we can write the force on a particle as F=q(E+v\u00d7B), (15.26) so that, given the forces, everything about the motion is determined. In any region where B=0 even if A is not zero, such as outside a solenoid, there is no discernible effect of A . Therefore for a long time it was believed that A was not a \u201creal\u201d field. It turns out, however, that there are phenomena involving quantum mechanics which show that the field A is in fact a \u201creal\u201d field in the sense we have defined it. In the next section we will show you how that works. There are many changes in what concepts are important when we go from classical to quantum mechanics. We have already discussed some of them in Vol. I. In particular, the force concept gradually fades away, while the concepts of energy and momentum become of paramount importance. You remember that instead of particle motions, one deals with probability amplitudes which vary in space and time. In these amplitudes there are wavelengths related to momenta, and frequencies related to energies. The momenta and energies, which determine the phases of wave functions, are therefore the important quantities in quantum mechanics. Instead of forces, we deal with the way interactions change the wavelength of the waves. The idea of a force becomes quite secondary\u2014if it is there at all. When people talk about nuclear forces, for example, what they usually analyze and work with are the energies of interaction of two nucleons, and not the force between them. Nobody ever differentiates the energy to find out what the force looks like. In this section we want to describe how the vector and scalar potentials enter into quantum mechanics. It is, in fact, just because momentum and energy play a central role in quantum mechanics that A and \u03d5 provide the most direct way of introducing electromagnetic effects into quantum descriptions. We must review a little how quantum mechanics works. We will consider again the imaginary experiment described in Chapter 37 of Vol. I, in which electrons are diffracted by two slits. The arrangement is shown again in Fig. 15\u20135. Electrons, all of nearly the same energy, leave the source and travel toward a wall with two narrow slits. Beyond the wall is a \u201cbackstop\u201d with a movable detector. The detector measures the rate, which we call I , at which electrons arrive at a small region of the backstop at the distance x from the axis of symmetry. The rate is proportional to the probability that an individual electron that leaves the source will reach that region of the backstop. This probability has the complicated-looking distribution shown in the figure, which we understand as due to the interference of two amplitudes, one from each slit. The interference of the two amplitudes depends on their phase difference. That is, if the amplitudes are C 1 e i \u03a6 1 and C 2 e i \u03a6 2 , the phase difference \u03b4= \u03a6 1 \u2212 \u03a6 2 determines their interference pattern [see Eq. (29.12) in Vol. I]. If the distance between the screen and the slits is L , and if the difference in the path lengths for electrons going through the two slits is a , as shown in the figure, then the phase difference of the two waves is given by \u03b4= a \u02c9\u03bb . (15.27) As usual, we let \u02c9\u03bb=\u03bb/2\u03c0 , where \u03bb is the wavelength of the space variation of the probability amplitude. For simplicity, we will consider only values of x much less than L ; then we can set a= x L d x and \u03b4= x L d \u02c9\u03bb . (15.28) When x is zero, \u03b4 is zero; the waves are in phase, and the probability has a maximum. When \u03b4 is \u03c0 , the waves are out of phase, they interfere destructively, and the probability is a minimum. So we get the wavy function for the electron intensity. Now we would like to state the law that for quantum mechanics replaces the force law F=qv\u00d7B . It will be the law that determines the behavior of quantum-mechanical particles in an electromagnetic field. Since what happens is determined by amplitudes, the law must tell us how the magnetic influences affect the amplitudes; we are no longer dealing with the acceleration of a particle. The law is the following: the phase of the amplitude to arrive via any trajectory is changed by the presence of a magnetic field by an amount equal to the integral of the vector potential along the whole trajectory times the charge of the particle over Planck\u2019s constant. That is, Magnetic change in phase= q \u210f \u222b trajectory A\u22c5ds. (15.29) If there were no magnetic field there would be a certain phase of arrival. If there is a magnetic field anywhere, the phase of the arriving wave is increased by the integral in Eq. (15.29). Although we will not need to use it for our present discussion, we mention that the effect of an electrostatic field is to produce a phase change given by the negative of the time integral of the scalar potential \u03d5 : Electric change in phase=\u2212 q \u210f \u222b\u03d5dt. \u222b These two expressions are correct not only for static fields, but together give the correct result for any electromagnetic field, static or dynamic. This is the law that replaces F=q(E+v\u00d7B) . We want now, however, to consider only a static magnetic field. Suppose that there is a magnetic field present in the two-slit experiment. We want to ask for the phase of arrival at the screen of the two waves whose paths pass through the two slits. Their interference determines where the maxima in the probability will be. We may call \u03a6 1 the phase of the wave along trajectory (1) . If \u03a6 1 (B=0) is the phase without the magnetic field, then when the field is turned on the phase will be \u03a6 1 = \u03a6 1 (B=0)+ q \u210f \u222b (1) A\u22c5ds. (15.30) Similarly, the phase for trajectory (2) is \u03a6 2 = \u03a6 2 (B=0)+ q \u210f \u222b (2) A\u22c5ds. (15.31) The interference of the waves at the detector depends on the phase difference \u03b4= \u03a6 1 (B=0)\u2212 \u03a6 2 (B=0)+ q \u210f \u222b (1) A\u22c5ds\u2212 q \u210f \u222b (2) A\u22c5ds. (15.32) The no-field difference we will call \u03b4(B=0) ; it is just the phase difference we have calculated above in Eq. (15.28). Also, we notice that the two integrals can be written as one integral that goes forward along (1) and back along (2) ; we call this the closed path (1\u20132) . So we have \u03b4=\u03b4(B=0)+ q \u210f \u222e (1\u20132) A\u22c5ds. (15.33) This equation tells us how the electron motion is changed by the magnetic field; with it we can find the new positions of the intensity maxima and minima at the backstop. Before we do that, however, we want to raise the following interesting and important point. You remember that the vector potential function has some arbitrariness. Two different vector potential functions A and A \u2032 whose difference is the gradient of some scalar function \u2207\u03c8 , both represent the same magnetic field, since the curl of a gradient is zero. They give, therefore, the same classical force qv\u00d7B . If in quantum mechanics the effects depend on the vector potential, which of the many possible A -functions is correct? The answer is that the same arbitrariness in A continues to exist for quantum mechanics. If in Eq. (15.33) we change A to A \u2032 =A+\u2207\u03c8 , the integral on A becomes \u222e (1\u20132) A \u2032 \u22c5ds= \u222e (1\u20132) A\u22c5ds+ \u222e (1\u20132) \u2207\u03c8\u22c5ds. \u222e \u222e \u222e The integral of \u2207\u03c8 is around the closed path (1\u20132) , but the integral of the tangential component of a gradient on a closed path is always zero, by Stokes\u2019 theorem. Therefore both A and A \u2032 give the same phase differences and the same quantum-mechanical interference effects. In both classical and quantum theory it is only the curl of A that matters; any choice of the function of A which has the correct curl gives the correct physics. The same conclusion is evident if we use the results of Section 14\u20131. There we found that the line integral of A around a closed path is the flux of B through the path, which here is the flux between paths (1) and (2) . Equation (15.33) can, if we wish, be written as \u03b4=\u03b4(B=0)+ q \u210f [ flux of B between (1) and (2) ], (15.34) where by the flux of B we mean, as usual, the surface integral of the normal component of B . The result depends only on B , and therefore only on the curl of A . Now because we can write the result in terms of B as well as in terms of A , you might be inclined to think that the B holds its own as a \u201creal\u201d field and that the A can still be thought of as an artificial construction. But the definition of \u201creal\u201d field that we originally proposed was based on the idea that a \u201creal\u201d field would not act on a particle from a distance. We can, however, give an example in which B is zero\u2014or at least arbitrarily small\u2014at any place where there is some chance to find the particles, so that it is not possible to think of it acting directly on them. You remember that for a long solenoid carrying an electric current there is a B -field inside but none outside, while there is lots of A circulating around outside, as shown in Fig. 15\u20136. If we arrange a situation in which electrons are to be found only outside of the solenoid\u2014only where there is A \u2014there will still be an influence on the motion, according to Eq. (15.33). Classically, that is impossible. Classically, the force depends only on B ; in order to know that the solenoid is carrying current, the particle must go through it. But quantum-mechanically you can find out that there is a magnetic field inside the solenoid by going around it\u2014without ever going close to it! Suppose that we put a very long solenoid of small diameter just behind the wall and between the two slits, as shown in Fig. 15\u20137. The diameter of the solenoid is to be much smaller than the distance d between the two slits. In these circumstances, the diffraction of the electrons at the slit gives no appreciable probability that the electrons will get near the solenoid. What will be the effect on our interference experiment? We compare the situation with and without a current through the solenoid. If we have no current, we have no B or A and we get the original pattern of electron intensity at the backstop. If we turn the current on in the solenoid and build up a magnetic field B inside, then there is an A outside. There is a shift in the phase difference proportional to the circulation of A outside the solenoid, which will mean that the pattern of maxima and minima is shifted to a new position. In fact, since the flux of B inside is a constant for any pair of paths, so also is the circulation of A . For every arrival point there is the same phase change; this corresponds to shifting the entire pattern in x by a constant amount, say x 0 , that we can easily calculate. The maximum intensity will occur where the phase difference between the two waves is zero. Using Eq. (15.33) or Eq. (15.34) for \u03b4 and Eq. (15.28) for x , we have x 0 =\u2212 L d \u02c9\u03bb q \u210f \u222e (1\u20132) A\u22c5ds, (15.35) or x 0 =\u2212 L d \u02c9\u03bb q \u210f [ flux of B between (1) and (2) ]. (15.36) The pattern with the solenoid in place should appear1 as shown in Fig. 15\u20137. At least, that is the prediction of quantum mechanics. Precisely this experiment has recently been done. It is a very, very difficult experiment. Because the wavelength of the electrons is so small, the apparatus must be on a tiny scale to observe the interference. The slits must be very close together, and that means that one needs an exceedingly small solenoid. It turns out that in certain circumstances, iron crystals will grow in the form of very long, microscopically thin filaments called whiskers. When these iron whiskers are magnetized they are like a tiny solenoid, and there is no field outside except near the ends. The electron interference experiment was done with such a whisker between two slits, and the predicted displacement in the pattern of electrons was observed. In our sense then, the A -field is \u201creal.\u201d You may say: \u201cBut there was a magnetic field.\u201d There was, but remember our original idea\u2014that a field is \u201creal\u201d if it is what must be specified at the position of the particle in order to get the motion. The B -field in the whisker acts at a distance. If we want to describe its influence not as action-at-a-distance, we must use the vector potential. This subject has an interesting history. The theory we have described was known from the beginning of quantum mechanics in 1926. The fact that the vector potential appears in the wave equation of quantum mechanics (called the Schr\u00f6dinger equation) was obvious from the day it was written. That it cannot be replaced by the magnetic field in any easy way was observed by one man after the other who tried to do so. This is also clear from our example of electrons moving in a region where there is no field and being affected nevertheless. But because in classical mechanics A did not appear to have any direct importance and, furthermore, because it could be changed by adding a gradient, people repeatedly said that the vector potential had no direct physical significance\u2014that only the magnetic and electric fields are \u201cright\u201d even in quantum mechanics. It seems strange in retrospect that no one thought of discussing this experiment until 1956, when Bohm and Aharonov first suggested it and made the whole question crystal clear. The implication was there all the time, but no one paid attention to it. Thus many people were rather shocked when the matter was brought up. That\u2019s why someone thought it would be worthwhile to do the experiment to see that it really was right, even though quantum mechanics, which had been believed for so many years, gave an unequivocal answer. It is interesting that something like this can be around for thirty years but, because of certain prejudices of what is and is not significant, continues to be ignored. Now we wish to continue in our analysis a little further. We will show the connection between the quantum-mechanical formula and the classical formula\u2014to show why it turns out that if we look at things on a large enough scale it will look as though the particles are acted on by a force equal to qv\u00d7 the curl of A . To get classical mechanics from quantum mechanics, we need to consider cases in which all the wavelengths are very small compared with distances over which external conditions, like fields, vary appreciably. We shall not prove the result in great generality, but only in a very simple example, to show how it works. Again we consider the same slit experiment. But instead of putting all the magnetic field in a very tiny region between the slits, we imagine a magnetic field that extends over a larger region behind the slits, as shown in Fig. 15\u20138. We will take the idealized case where we have a magnetic field which is uniform in a narrow strip of width w , considered small as compared with L . (That can easily be arranged; the backstop can be put as far out as we want.) In order to calculate the shift in phase, we must take the two integrals of A along the two trajectories (1) and (2) . They differ, as we have seen, merely by the flux of B between the paths. To our approximation, the flux is Bwd . The phase difference for the two paths is then \u03b4=\u03b4(B=0)+ q \u210f Bwd. (15.37) We note that, to our approximation, the phase shift is independent of the angle. So again the effect will be to shift the whole pattern upward by an amount \u0394x . Using Eq. (15.35), \u0394x=\u2212 L\u02c9\u03bb d \u0394\u03b4=\u2212 L\u02c9\u03bb d [\u03b4\u2212\u03b4(B=0)]. L \ufffdx203E; \u03bb L \ufffdx203E; \u03bb Using (15.37) for \u03b4\u2212\u03b4(B=0) , \u0394x=\u2212L\u02c9\u03bb q \u210f Bw. (15.38) Such a shift is equivalent to deflecting all the trajectories by the small angle \u03b1 (see Fig. 15\u20138), where \u03b1= \u0394x L =\u2212 \u02c9\u03bb \u210f qBw. (15.39) Now classically we would also expect a thin strip of magnetic field to deflect all trajectories through some small angle, say \u03b1 \u2032 , as shown in Fig. 15\u20139(a). As the electrons go through the magnetic field, they feel a transverse force qv\u00d7B which lasts for a time w/v . The change in their transverse momentum is just equal to this impulse, so \u0394 p x =\u2212qwB. (15.40) The angular deflection [Fig. 15\u20139(b)] is equal to the ratio of this transverse momentum to the total momentum p . We get that \u03b1 \u2032 = \u0394 p x p =\u2212 qwB p . (15.41) We can compare this result with Eq. (15.39), which gives the same quantity computed quantum-mechanically. But the connection between classical mechanics and quantum mechanics is this: A particle of momentum p corresponds to a quantum amplitude varying with the wavelength \u02c9\u03bb=\u210f/p . With this equality, \u03b1 and \u03b1 \u2032 are identical; the classical and quantum calculations give the same result. From the analysis we see how it is that the vector potential which appears in quantum mechanics in an explicit form produces a classical force which depends only on its derivatives. In quantum mechanics what matters is the interference between nearby paths; it always turns out that the effects depend only on how much the field A changes from point to point, and therefore only on the derivatives of A and not on the value itself. Nevertheless, the vector potential A (together with the scalar potential \u03d5 that goes with it) appears to give the most direct description of the physics. This becomes more and more apparent the more deeply we go into the quantum theory. In the general theory of quantum electrodynamics, one takes the vector and scalar potentials as the fundamental quantities in a set of equations that replace the Maxwell equations: E and B are slowly disappearing from the modern expression of physical laws; they are being replaced by A and \u03d5 . We are now at the end of our exploration of the subject of static fields. Already in this chapter we have come perilously close to having to worry about what happens when fields change with time. We were barely able to avoid it in our treatment of magnetic energy by taking refuge in a relativistic argument. Even so, our treatment of the energy problem was somewhat artificial and perhaps even mysterious, because we ignored the fact that moving coils must, in fact, produce changing fields. It is now time to take up the treatment of time-varying fields\u2014the subject of electrodynamics. We will do so in the next chapter. First, however, we would like to emphasize a few points. Although we began this course with a presentation of the complete and correct equations of electromagnetism, we immediately began to study some incomplete pieces\u2014because that was easier. There is a great advantage in starting with the simpler theory of static fields, and proceeding only later to the more complicated theory which includes dynamic fields. There is less new material to learn all at once, and there is time for you to develop your intellectual muscles in preparation for the bigger task. But there is the danger in this process that before we get to see the complete story, the incomplete truths learned on the way may become ingrained and taken as the whole truth\u2014that what is true and what is only sometimes true will become confused. So we give in Table 15\u20131 a summary of the important formulas we have covered, separating those which are true in general from those which are true for statics, but false for dynamics. This summary also shows, in part, where we are going, since as we treat dynamics we will be developing in detail what we must just state here without proof. It may be useful to make a few remarks about the table. First, you should notice that the equations we started with are the true equations\u2014we have not misled you there. The electromagnetic force (often called the Lorentz force) F=q(E+v\u00d7B) is true. It is only Coulomb\u2019s law that is false, to be used only for statics. The four Maxwell equations for E and B are also true. The equations we took for statics are false, of course, because we left off all terms with time derivatives. Gauss\u2019 law, \u2207\u22c5E=\u03c1/ \u03f5 0 , remains, but the curl of E is not zero in general. So E cannot always be equated to the gradient of a scalar\u2014the electrostatic potential. We will see that a scalar potential still remains, but it is a time-varying quantity that must be used together with vector potentials for a complete description of the electric field. The equations governing this new scalar potential are, necessarily, also new. We must also give up the idea that E is zero in conductors. When the fields are changing, the charges in conductors do not, in general, have time to rearrange themselves to make the field zero. They are set in motion, but never reach equilibrium. The only general statement is: electric fields in conductors produce currents. So in varying fields a conductor is not an equipotential. It also follows that the idea of a capacitance is no longer precise. Since there are no magnetic charges, the divergence of B is always zero. So B can always be equated to \u2207\u00d7A . (Everything doesn\u2019t change!) But the generation of B is not only from currents; \u2207\u00d7B is proportional to the current density plus a new term \u2202E/\u2202t . This means that A is related to currents by a new equation. It is also related to \u03d5 . If we make use of our freedom to choose \u2207\u22c5A for our own convenience, the equations for A or \u03d5 can be arranged to take on a simple and elegant form. We therefore make the condition that c 2 \u2207\u22c5A=\u2212\u2202\u03d5/\u2202t , and the differential equations for A or \u03d5 appear as shown in the table. The potentials A and \u03d5 can still be found by integrals over the currents and charges, but not the same integrals as for statics. Most wonderfully, though, the true integrals are like the static ones, with only a small and physically appealing modification. When we do the integrals to find the potentials at some point, say point (1) in Fig. 15\u201310, we must use the values of j and \u03c1 at the point (2) at an earlier time t \u2032 =t\u2212 r 12 /c . As you would expect, the influences propagate from point (2) to point (1) at the speed c . With this small change, one can solve for the fields of varying currents and charges, because once we have A and \u03d5 , we get B from \u2207\u00d7A , as before, and E from \u2212\u2207\u03d5\u2212\u2202A/\u2202t . Finally, you will notice that some results\u2014for example, that the energy density in an electric field is \u03f5 0 E 2 /2 \u2014are true for electrodynamics as well as for statics. You should not be misled into thinking that this is at all \u201cnatural.\u201d The validity of any formula derived in the static case must be demonstrated over again for the dynamic case. A contrary example is the expression for the electrostatic energy in terms of a volume integral of \u03c1\u03d5 . This result is true only for statics. We will consider all these matters in more detail in due time, but it will perhaps be useful to keep in mind this summary, so you will know what you can forget, and what you should remember as always true."
    },
    {
        "input": "Resonance",
        "output": "In the present chapter we shall continue our discussion of the harmonic oscillator and, in particular, the forced harmonic oscillator, using a new technique in the analysis. In the preceding chapter we introduced the idea of complex numbers, which have real and imaginary parts and which can be represented on a diagram in which the ordinate represents the imaginary part and the abscissa represents the real part. If a is a complex number, we may write it as a= a r +i a i , where the subscript r means the real part of a , and the subscript i means the imaginary part of a . Referring to Fig. 23\u20131, we see that we may also write a complex number a=x+iy in the form x+iy=r e i\u03b8 , where r 2 = x 2 + y 2 =(x+iy)(x\u2212iy)=a a \u2217 . (The complex conjugate of a , written a \u2217 , is obtained by reversing the sign of i in a .) So we shall represent a complex number in either of two forms, a real plus an imaginary part, or a magnitude r and a phase angle \u03b8 , so-called. Given r and \u03b8 , x and y are clearly rcos\u03b8 and rsin\u03b8 and, in reverse, given a complex number x+iy , r= x 2 + y 2 \u2212 \u2212 \u2212 \u2212 \u2212 \u2212 \u221a and tan\u03b8=y/x , the ratio of the imaginary to the real part. We are going to apply complex numbers to our analysis of physical phenomena by the following trick. We have examples of things that oscillate; the oscillation may have a driving force which is a certain constant times cos\u03c9t . Now such a force, F= F 0 cos\u03c9t , can be written as the real part of a complex number F= F 0 e i\u03c9t because e i\u03c9t =cos\u03c9t+isin\u03c9t . The reason we do this is that it is easier to work with an exponential function than with a cosine. So the whole trick is to represent our oscillatory functions as the real parts of certain complex functions. The complex number F that we have so defined is not a real physical force, because no force in physics is really complex; actual forces have no imaginary part, only a real part. We shall, however, speak of the \u201cforce\u201d F 0 e i\u03c9t , but of course the actual force is the real part of that expression. Let us take another example. Suppose we want to represent a force which is a cosine wave that is out of phase with a delayed phase \u0394 . This, of course, would be the real part of F 0 e i(\u03c9t\u2212\u0394) , but exponentials being what they are, we may write e i(\u03c9t\u2212\u0394) = e i\u03c9t e \u2212i\u0394 . Thus we see that the algebra of exponentials is much easier than that of sines and cosines; this is the reason we choose to use complex numbers. We shall often write F= F 0 e \u2212i\u0394 e i\u03c9t = F ^ e i\u03c9t . (23.1) We write a little caret ( ^ ) over the F to remind ourselves that this quantity is a complex number: here the number is F ^ = F 0 e \u2212i\u0394 . Now let us solve an equation, using complex numbers, to see whether we can work out a problem for some real case. For example, let us try to solve d 2 x d t 2 + kx m = F m = F 0 m cos\u03c9t, (23.2) where F is the force which drives the oscillator and x is the displacement. Now, absurd though it may seem, let us suppose that x and F are actually complex numbers, for a mathematical purpose only. That is to say, x has a real part and an imaginary part times i , and F has a real part and an imaginary part times i . Now if we had a solution of (23.2) with complex numbers, and substituted the complex numbers in the equation, we would get d 2 ( x r +i x i ) d t 2 + k( x r +i x i ) m = F r +i F i m 2 or d 2 x r d t 2 + k x r m +i( d 2 x i d t 2 + k x i m )= F r m + i F i m . 2 2 Now, since if two complex numbers are equal, their real parts must be equal and their imaginary parts must be equal, we deduce that the real part of x satisfies the equation with the real part of the force. We must emphasize, however, that this separation into a real part and an imaginary part is not valid in general, but is valid only for equations which are linear, that is, for equations in which x appears in every term only in the first power or the zeroth power. For instance, if there were in the equation a term \u03bb x 2 , then when we substitute x r +i x i , we would get \u03bb( x r +i x i ) 2 , but when separated into real and imaginary parts this would yield \u03bb( x 2 r \u2212 x 2 i ) as the real part and 2i\u03bb x r x i as the imaginary part. So we see that the real part of the equation would not involve just \u03bb x 2 r , but also \u2212\u03bb x 2 i . In this case we get a different equation than the one we wanted to solve, with x i , the completely artificial thing we introduced in our analysis, mixed in. Let us now try our new method for the problem of the forced oscillator, that we already know how to solve. We want to solve Eq. (23.2) as before, but we say that we are going to try to solve d 2 x d t 2 + kx m = F ^ e i\u03c9t m , (23.3) where F ^ e i\u03c9t is a complex number. Of course x will also be complex, but remember the rule: take the real part to find out what is really going on. So we try to solve (23.3) for the forced solution; we shall discuss other solutions later. The forced solution has the same frequency as the applied force, and has some amplitude of oscillation and some phase, and so it can be represented also by some complex number x ^ whose magnitude represents the swing of x and whose phase represents the time delay in the same way as for the force. Now a wonderful feature of an exponential function x= x ^ e i\u03c9t is that dx/dt=i\u03c9x . When we differentiate an exponential function, we bring down the exponent as a simple multiplier. The second derivative does the same thing, it brings down another i\u03c9 , and so it is very simple to write immediately, by inspection, what the equation is for x : every time we see a differentiation, we simply multiply by i\u03c9 . (Differentiation is now as easy as multiplication! This idea of using exponentials in linear differential equations is almost as great as the invention of logarithms, in which multiplication is replaced by addition. Here differentiation is replaced by multiplication.) Thus our equation becomes (i\u03c9 ) 2 x ^ +(k x ^ /m)= F ^ /m. (23.4) (We have cancelled the common factor e i\u03c9t .) See how simple it is! Differential equations are immediately converted, by sight, into mere algebraic equations; we virtually have the solution by sight, that x ^ = F ^ /m (k/m)\u2212 \u03c9 2 , since (i\u03c9 ) 2 =\u2212 \u03c9 2 . This may be slightly simplified by substituting k/m= \u03c9 2 0 , which gives x ^ = F ^ /m( \u03c9 2 0 \u2212 \u03c9 2 ). (23.5) This, of course, is the solution we had before; for since m( \u03c9 2 0 \u2212 \u03c9 2 ) is a real number, the phase angles of F ^ and of x ^ are the same (or perhaps 180 \u2218 apart, if \u03c9 2 > \u03c9 2 0 ), as advertised previously. The magnitude of x ^ , which measures how far it oscillates, is related to the size of the F ^ by the factor 1/m( \u03c9 2 0 \u2212 \u03c9 2 ) , and this factor becomes enormous when \u03c9 is nearly equal to \u03c9 0 . So we get a very strong response when we apply the right frequency \u03c9 (if we hold a pendulum on the end of a string and shake it at just the right frequency, we can make it swing very high). That, then, is how we analyze oscillatory motion with the more elegant mathematical technique. But the elegance of the technique is not at all exhibited in such a problem that can be solved easily by other methods. It is only exhibited when one applies it to more difficult problems. Let us therefore solve another, more difficult problem, which furthermore adds a relatively realistic feature to the previous one. Equation (23.5) tells us that if the frequency \u03c9 were exactly equal to \u03c9 0 , we would have an infinite response. Actually, of course, no such infinite response occurs because some other things, like friction, which we have so far ignored, limits the response. Let us therefore add to Eq. (23.2) a friction term. Ordinarily such a problem is very difficult because of the character and complexity of the frictional term. There are, however, many circumstances in which the frictional force is proportional to the speed with which the object moves. An example of such friction is the friction for slow motion of an object in oil or a thick liquid. There is no force when it is just standing still, but the faster it moves the faster the oil has to go past the object, and the greater is the resistance. So we shall assume that there is, in addition to the terms in (23.2), another term, a resistance force proportional to the velocity: F f =\u2212cdx/dt . It will be convenient, in our mathematical analysis, to write the constant c as m times \u03b3 to simplify the equation a little. This is just the same trick we use with k when we replace it by m \u03c9 2 0 , just to simplify the algebra. Thus our equation will be m( d 2 x/d t 2 )+c(dx/dt)+kx=F (23.6) or, writing c=m\u03b3 and k=m \u03c9 2 0 and dividing out the mass m , ( d 2 x/d t 2 )+\u03b3(dx/dt)+ \u03c9 2 0 x=F/m. (23.6a) Now we have the equation in the most convenient form to solve. If \u03b3 is very small, that represents very little friction; if \u03b3 is very large, there is a tremendous amount of friction. How do we solve this new linear differential equation? Suppose that the driving force is equal to F 0 cos(\u03c9t+\u0394) ; we could put this into (23.6a) and try to solve it, but we shall instead solve it by our new method. Thus we write F as the real part of F ^ e i\u03c9t and x as the real part of x ^ e i\u03c9t , and substitute these into Eq. (23.6a). It is not even necessary to do the actual substituting, for we can see by inspection that the equation would become [(i\u03c9 ) 2 x ^ +\u03b3(i\u03c9) x ^ + \u03c9 2 0 x ^ ] e i\u03c9t =( F ^ /m) e i\u03c9t . (23.7) [As a matter of fact, if we tried to solve Eq. (23.6a) by our old straightforward way, we would really appreciate the magic of the \u201ccomplex\u201d method.] If we divide by e i\u03c9t on both sides, then we can obtain the response x ^ to the given force F ^ ; it is x ^ = F ^ /m( \u03c9 2 0 \u2212 \u03c9 2 +i\u03b3\u03c9). (23.8) Thus again x ^ is given by F ^ times a certain factor. There is no technical name for this factor, no particular letter for it, but we may call it R for discussion purposes: R= 1 m( \u03c9 2 0 \u2212 \u03c9 2 +i\u03b3\u03c9) 1 and x ^ = F ^ R. (23.9) (Although the letters \u03b3 and \u03c9 0 are in very common use, this R has no particular name.) This factor R can either be written as p+iq , or as a certain magnitude \u03c1 times e i\u03b8 . If it is written as a certain magnitude times e i\u03b8 , let us see what it means. Now F ^ = F 0 e i\u0394 , and the actual force F is the real part of F 0 e i\u0394 e i\u03c9t , that is, F 0 cos(\u03c9t+\u0394) . Next, Eq. (23.9) tells us that x ^ is equal to F ^ R . So, writing R=\u03c1 e i\u03b8 as another name for R , we get x ^ =R F ^ =\u03c1 e i\u03b8 F 0 e i\u0394 =\u03c1 F 0 e i(\u03b8+\u0394) . Finally, going even further back, we see that the physical x , which is the real part of the complex x ^ e i\u03c9t , is equal to the real part of \u03c1 F 0 e i(\u03b8+\u0394) e i\u03c9t . But \u03c1 and F 0 are real, and the real part of e i(\u03b8+\u0394+\u03c9t) is simply cos(\u03c9t+\u0394+\u03b8) . Thus x=\u03c1 F 0 cos(\u03c9t+\u0394+\u03b8). (23.10) This tells us that the amplitude of the response is the magnitude of the force F multiplied by a certain magnification factor, \u03c1 ; this gives us the \u201camount\u201d of oscillation. It also tells us, however, that x is not oscillating in phase with the force, which has the phase \u0394 , but is shifted by an extra amount \u03b8 . Therefore \u03c1 and \u03b8 represent the size of the response and the phase shift of the response. Now let us work out what \u03c1 is. If we have a complex number, the square of the magnitude is equal to the number times its complex conjugate; thus \u03c1 2 = 1 m 2 ( \u03c9 2 0 \u2212 \u03c9 2 +i\u03b3\u03c9)( \u03c9 2 0 \u2212 \u03c9 2 \u2212i\u03b3\u03c9) = 1 m 2 [( \u03c9 2 0 \u2212 \u03c9 2 ) 2 + \u03b3 2 \u03c9 2 ] . (23.11) In addition, the phase angle \u03b8 is easy to find, for if we write 1/R=1/\u03c1 e i\u03b8 =(1/\u03c1) e \u2212i\u03b8 =m( \u03c9 2 0 \u2212 \u03c9 2 +i\u03b3\u03c9), i \u03b8 i \u03b8 2 2 we see that tan\u03b8=\u2212\u03b3\u03c9/( \u03c9 2 0 \u2212 \u03c9 2 ). (23.12) It is minus because tan(\u2212\u03b8)=\u2212tan\u03b8 . A negative value for \u03b8 results for all \u03c9 , and this corresponds to the displacement x lagging the force F . Figure 23\u20132 shows how \u03c1 2 varies as a function of frequency ( \u03c1 2 is physically more interesting than \u03c1 , because \u03c1 2 is proportional to the square of the amplitude, or more or less to the energy that is developed in the oscillator by the force). We see that if \u03b3 is very small, then 1/( \u03c9 2 0 \u2212 \u03c9 2 ) 2 is the most important term, and the response tries to go up toward infinity when \u03c9 equals \u03c9 0 . Now the \u201cinfinity\u201d is not actually infinite because if \u03c9= \u03c9 0 , then 1/ \u03b3 2 \u03c9 2 is still there. The phase shift varies as shown in Fig. 23\u20133. In certain circumstances we get a slightly different formula than (23.8), also called a \u201cresonance\u201d formula, and one might think that it represents a different phenomenon, but it does not. The reason is that if \u03b3 is very small the most interesting part of the curve is near \u03c9= \u03c9 0 , and we may replace (23.8) by an approximate formula which is very accurate if \u03b3 is small and \u03c9 is near \u03c9 0 . Since \u03c9 2 0 \u2212 \u03c9 2 =( \u03c9 0 \u2212\u03c9)( \u03c9 0 +\u03c9) , if \u03c9 is near \u03c9 0 this is nearly the same as 2 \u03c9 0 ( \u03c9 0 \u2212\u03c9) and \u03b3\u03c9 is nearly the same as \u03b3 \u03c9 0 . Using these in (23.8), we see that \u03c9 2 0 \u2212 \u03c9 2 +i\u03b3\u03c9\u22482 \u03c9 0 ( \u03c9 0 \u2212\u03c9+i\u03b3/2) , so that x ^ \u2248 F ^ /2m \u03c9 0 ( \u03c9 0 \u2212\u03c9+i\u03b3/2) if \u03b3\u226a \u03c9 0 and \u03c9\u2248 \u03c9 0 . (23.13) It is easy to find the corresponding formula for \u03c1 2 . It is \u03c1 2 \u22481/4 m 2 \u03c9 2 0 [( \u03c9 0 \u2212\u03c9 ) 2 + \u03b3 2 /4]. 2 We shall leave it to the student to show the following: if we call the maximum height of the curve of \u03c1 2 vs. \u03c9 one unit, and we ask for the width \u0394\u03c9 of the curve, at one half the maximum height, the full width at half the maximum height of the curve is \u0394\u03c9=\u03b3 , supposing that \u03b3 is small. The resonance is sharper and sharper as the frictional effects are made smaller and smaller. As another measure of the width, some people use a quantity Q which is defined as Q= \u03c9 0 /\u03b3 . The narrower the resonance, the higher the Q : Q=1000 means a resonance whose width is only 1000 th of the frequency scale. The Q of the resonance curve shown in Fig. 23\u20132 is 5 . The importance of the resonance phenomenon is that it occurs in many other circumstances, and so the rest of this chapter will describe some of these other circumstances. The simplest and broadest technical applications of resonance are in electricity. In the electrical world there are a number of objects which can be connected to make electric circuits. These passive circuit elements, as they are often called, are of three main types, although each one has a little bit of the other two mixed in. Before describing them in greater detail, let us note that the whole idea of our mechanical oscillator being a mass on the end of a spring is only an approximation. All the mass is not actually at the \u201cmass\u201d; some of the mass is in the inertia of the spring. Similarly, all of the spring is not at the \u201cspring\u201d; the mass itself has a little elasticity, and although it may appear so, it is not absolutely rigid, and as it goes up and down, it flexes ever so slightly under the action of the spring pulling it. The same thing is true in electricity. There is an approximation in which we can lump things into \u201ccircuit elements\u201d which are assumed to have pure, ideal characteristics. It is not the proper time to discuss that approximation here, we shall simply assume that it is true in the circumstances. The three main kinds of circuit elements are the following. The first is called a capacitor (Fig. 23\u20134); an example is two plane metallic plates spaced a very small distance apart by an insulating material. When the plates are charged there is a certain voltage difference, that is, a certain difference in potential, between them. The same difference of potential appears between the terminals A and B , because if there were any difference along the connecting wire, electricity would flow right away. So there is a certain voltage difference V between the plates if there is a certain electric charge +q and \u2212q on them, respectively. Between the plates there will be a certain electric field; we have even found a formula for it (Chapters 13 and 14): V=\u03c3d/ \u03f5 0 =qd/ \u03f5 0 A, (23.14) where d is the spacing and A is the area of the plates. Note that the potential difference is a linear function of the charge. If we do not have parallel plates, but insulated electrodes which are of any other shape, the difference in potential is still precisely proportional to the charge, but the constant of proportionality may not be so easy to compute. However, all we need to know is that the potential difference across a capacitor is proportional to the charge: V=q/C ; the proportionality constant is 1/C , where C is the capacitance of the object. The second kind of circuit element is called a resistor; it offers resistance to the flow of electrical current. It turns out that metallic wires and many other substances resist the flow of electricity in this manner: if there is a voltage difference across a piece of some substance, there exists an electric current I=dq/dt that is proportional to the electric voltage difference: V=RI=Rdq/dt (23.15) The proportionality coefficient is called the resistance R . This relationship may already be familiar to you; it is Ohm\u2019s law. If we think of the charge q on a capacitor as being analogous to the displacement x of a mechanical system, we see that the current, I=dq/dt , is analogous to velocity, 1/C is analogous to a spring constant k , and R is analogous to the resistive coefficient c=m\u03b3 in Eq. (23.6). Now it is very interesting that there exists another circuit element which is the analog of mass! This is a coil which builds up a magnetic field within itself when there is a current in it. A changing magnetic field develops in the coil a voltage that is proportional to dI/dt (this is how a transformer works, in fact). The magnetic field is proportional to a current, and the induced voltage (so-called) in such a coil is proportional to the rate of change of the current: V=LdI/dt=L d 2 q/d t 2 . (23.16) The coefficient L is the self-inductance, and is analogous to the mass in a mechanical oscillating circuit. Suppose we make a circuit in which we have connected the three circuit elements in series (Fig. 23\u20135); then the voltage across the whole thing from 1 to 2 is the work done in carrying a charge through, and it consists of the sum of several pieces: across the inductor, V L =L d 2 q/d t 2 ; across the resistance, V R =Rdq/dt ; across the capacitor, V C =q/C . The sum of these is equal to the applied voltage, V : L d 2 q/d t 2 +Rdq/dt+q/C=V(t). (23.17) Now we see that this equation is exactly the same as the mechanical equation (23.6), and of course it can be solved in exactly the same manner. We suppose that V(t) is oscillatory: we are driving the circuit with a generator with a pure sine wave oscillation. Then we can write our V(t) as a complex V ^ with the understanding that it must be ultimately multiplied by e i\u03c9t , and the real part taken in order to find the true V . Likewise, the charge q can thus be analyzed, and then in exactly the same manner as in Eq. (23.8) we write the corresponding equation: the second derivative of q is (i\u03c9 ) 2 q ; the first derivative is (i\u03c9)q . Thus Eq. (23.17) translates to [L(i\u03c9 ) 2 +R(i\u03c9)+ 1 C ] q ^ = V ^ [ 1 ] or q ^ = V ^ L(i\u03c9 ) 2 +R(i\u03c9)+ 1 C which we can write in the form q ^ = V ^ /L( \u03c9 2 0 \u2212 \u03c9 2 +i\u03b3\u03c9), (23.18) where \u03c9 2 0 =1/LC and \u03b3=R/L . It is exactly the same denominator as we had in the mechanical case, with exactly the same resonance properties! The correspondence between the electrical and mechanical cases is outlined in Table 23\u20131. We must mention a small technical point. In the electrical literature, a different notation is used. (From one field to another, the subject is not really any different, but the way of writing the notations is often different.) First, j is commonly used instead of i in electrical engineering, to denote \u22121 \u2212 \u2212 \u2212 \u221a . (After all, i must be the current!) Also, the engineers would rather have a relationship between V ^ and I ^ than between V ^ and q ^ , just because they are more used to it that way. Thus, since I=dq/dt=i\u03c9q , we can just substitute I ^ /i\u03c9 for q ^ and get V ^ =(i\u03c9L+R+1/i\u03c9C) I ^ = Z ^ I ^ . (23.19) Another way is to rewrite Eq. (23.17), so that it looks more familiar; one often sees it written this way: LdI/dt+RI+(1/C) \u222b t Idt=V(t). (23.20) At any rate, we find the relation (23.19) between voltage V ^ and current I ^ which is just the same as (23.18) except divided by i\u03c9 , and that produces Eq. (23.19). The quantity R+i\u03c9L+1/i\u03c9C is a complex number, and is used so much in electrical engineering that it has a name: it is called the complex impedance, Z ^ . Thus we can write V ^ = Z ^ I ^ . The reason that the engineers like to do this is that they learned something when they were young: V=RI for resistances, when they only knew about resistances and dc. Now they have become more educated and have ac circuits, so they want the equation to look the same. Thus they write V ^ = Z ^ I ^ , the only difference being that the resistance is replaced by a more complicated thing, a complex quantity. So they insist that they cannot use what everyone else in the world uses for imaginary numbers, they have to use a j for that; it is a miracle that they did not insist also that the letter Z be an R ! (Then they get into trouble when they talk about current densities, for which they also use j . The difficulties of science are to a large extent the difficulties of notations, the units, and all the other artificialities which are invented by man, not by nature.) Although we have discussed the electrical case in detail, we could also bring up case after case in many fields, and show exactly how the resonance equation is the same. There are many circumstances in nature in which something is \u201coscillating\u201d and in which the resonance phenomenon occurs. We said that in an earlier chapter; let us now demonstrate it. If we walk around our study, pulling books off the shelves and simply looking through them to find an example of a curve that corresponds to Fig. 23\u20132 and comes from the same equation, what do we find? Just to demonstrate the wide range obtained by taking the smallest possible sample, it takes only five or six books to produce quite a series of phenomena which show resonances. The first two are from mechanics, the first on a large scale: the atmosphere of the whole earth. If the atmosphere, which we suppose surrounds the earth evenly on all sides, is pulled to one side by the moon or, rather, squashed prolate into a double tide, and if we could then let it go, it would go sloshing up and down; it is an oscillator. This oscillator is driven by the moon, which is effectively revolving about the earth; any one component of the force, say in the x -direction, has a cosine component, and so the response of the earth\u2019s atmosphere to the tidal pull of the moon is that of an oscillator. The expected response of the atmosphere is shown in Fig. 23\u20136, curve b (curve a is another theoretical curve under discussion in the book from which this is taken out of context). Now one might think that we only have one point on this resonance curve, since we only have the one frequency, corresponding to the rotation of the earth under the moon, which occurs at a period of 12.42 hours\u2014 12 hours for the earth (the tide is a double bump), plus a little more because the moon is going around. But from the size of the atmospheric tides, and from the phase, the amount of delay, we can get both \u03c1 and \u03b8 . From those we can get \u03c9 0 and \u03b3 , and thus draw the entire curve! This is an example of very poor science. From two numbers we obtain two numbers, and from those two numbers we draw a beautiful curve, which of course goes through the very point that determined the curve! It is of no use unless we can measure something else, and in the case of geophysics that is often very difficult. But in this particular case there is another thing which we can show theoretically must have the same timing as the natural frequency \u03c9 0 : that is, if someone disturbed the atmosphere, it would oscillate with the frequency \u03c9 0 . Now there was such a sharp disturbance in 1883; the Krakatoa volcano exploded and half the island blew off, and it made such a terrific explosion in the atmosphere that the period of oscillation of the atmosphere could be measured. It came out to 10 1 2 hours. The \u03c9 0 obtained from Fig. 23\u20136 comes out 10 hours and 20 minutes, so there we have at least one check on the reality of our understanding of the atmospheric tides. Next we go to the small scale of mechanical oscillation. This time we take a sodium chloride crystal, which has sodium ions and chlorine ions next to each other, as we described in an early chapter. These ions are electrically charged, alternately plus and minus. Now there is an interesting oscillation possible. Suppose that we could drive all the plus charges to the right and all the negative charges to the left, and let go; they would then oscillate back and forth, the sodium lattice against the chlorine lattice. How can we ever drive such a thing? That is easy, for if we apply an electric field on the crystal, it will push the plus charge one way and the minus charge the other way! So, by having an external electric field we can perhaps get the crystal to oscillate. The frequency of the electric field needed is so high, however, that it corresponds to infrared radiation! So we try to find a resonance curve by measuring the absorption of infrared light by sodium chloride. Such a curve is shown in Fig. 23\u20137. The abscissa is not frequency, but is given in terms of wavelength, but that is just a technical matter, of course, since for a wave there is a definite relation between frequency and wavelength; so it is really a frequency scale, and a certain frequency corresponds to the resonant frequency. But what about the width? What determines the width? There are many cases in which the width that is seen on the curve is not really the natural width \u03b3 that one would have theoretically. There are two reasons why there can be a wider curve than the theoretical curve. If the objects do not all have the same frequency, as might happen if the crystal were strained in certain regions, so that in those regions the oscillation frequency were slightly different than in other regions, then what we have is many resonance curves on top of each other; so we apparently get a wider curve. The other kind of width is simply this: perhaps we cannot measure the frequency precisely enough\u2014if we open the slit of the spectrometer fairly wide, so although we thought we had only one frequency, we actually had a certain range \u0394\u03c9 , then we may not have the resolving power needed to see a narrow curve. Offhand, we cannot say whether the width in Fig. 23\u20137 is natural, or whether it is due to inhomogeneities in the crystal or the finite width of the slit of the spectrometer. Now we turn to a more esoteric example, and that is the swinging of a magnet. If we have a magnet, with north and south poles, in a constant magnetic field, the N end of the magnet will be pulled one way and the S end the other way, and there will in general be a torque on it, so it will vibrate about its equilibrium position, like a compass needle. However, the magnets we are talking about are atoms. These atoms have an angular momentum, the torque does not produce a simple motion in the direction of the field, but instead, of course, a precession. Now, looked at from the side, any one component is \u201cswinging,\u201d and we can disturb or drive that swinging and measure an absorption. The curve in Fig. 23\u20138 represents a typical such resonance curve. What has been done here is slightly different technically. The frequency of the lateral field that is used to drive this swinging is always kept the same, while we would have expected that the investigators would vary that and plot the curve. They could have done it that way, but technically it was easier for them to leave the frequency \u03c9 fixed, and change the strength of the constant magnetic field, which corresponds to changing \u03c9 0 in our formula. They have plotted the resonance curve against \u03c9 0 . Anyway, this is a typical resonance with a certain \u03c9 0 and \u03b3 . Now we go still further. Our next example has to do with atomic nuclei. The motions of protons and neutrons in nuclei are oscillatory in certain ways, and we can demonstrate this by the following experiment. We bombard a lithium atom with protons, and we discover that a certain reaction, producing \u03b3 -rays, actually has a very sharp maximum typical of resonance. We note in Fig. 23\u20139, however, one difference from other cases: the horizontal scale is not a frequency, it is an energy! The reason is that in quantum mechanics what we think of classically as the energy will turn out to be really related to a frequency of a wave amplitude. When we analyze something which in simple large-scale physics has to do with a frequency, we find that when we do quantum-mechanical experiments with atomic matter, we get the corresponding curve as a function of energy. In fact, this curve is a demonstration of this relationship, in a sense. It shows that frequency and energy have some deep interrelationship, which of course they do. Now we turn to another example which also involves a nuclear energy level, but now a much, much narrower one. The \u03c9 0 in Fig. 23\u201310 corresponds to an energy of 100,000 electron volts, while the width \u03b3 is approximately 10 \u22125 electron volt; in other words, this has a Q of 10 10 ! When this curve was measured it was the largest Q of any oscillator that had ever been measured. It was measured by Dr. M\u00f6ssbauer, and it was the basis of his Nobel prize. The horizontal scale here is velocity, because the technique for obtaining the slightly different frequencies was to use the Doppler effect, by moving the source relative to the absorber. One can see how delicate the experiment is when we realize that the speed involved is a few centimeters per second! On the actual scale of the figure, zero frequency would correspond to a point about 10 10 cm to the left\u2014slightly off the paper! Finally, if we look in an issue of the Physical Review, say that of January 1, 1962, will we find a resonance curve? Every issue has a resonance curve, and Fig. 23\u201311 is the resonance curve for this one. This resonance curve turns out to be very interesting. It is the resonance found in a certain reaction among strange particles, a reaction in which a K \u2212 and a proton interact. The resonance is detected by seeing how many of some kinds of particles come out, and depending on what and how many come out, one gets different curves, but of the same shape and with the peak at the same energy. We thus determine that there is a resonance at a certain energy for the K \u2212 meson. That presumably means that there is some kind of a state, or condition, corresponding to this resonance, which can be attained by putting together a K \u2212 and a proton. This is a new particle, or resonance. Today we do not know whether to call a bump like this a \u201cparticle\u201d or simply a resonance. When there is a very sharp resonance, it corresponds to a very definite energy, just as though there were a particle of that energy present in nature. When the resonance gets wider, then we do not know whether to say there is a particle which does not last very long, or simply a resonance in the reaction probability. In the second chapter, this point is made about the particles, but when the second chapter was written this resonance was not known, so our chart should now have still another particle in it!"
    },
    {
        "input": "Quantum Behavior",
        "output": "In the last few chapters we have treated the essential ideas necessary for an understanding of most of the important phenomena of light\u2014or electromagnetic radiation in general. (We have left a few special topics for next year. Specifically, the theory of the index of dense materials and total internal reflection.) What we have dealt with is called the \u201cclassical theory\u201d of electric waves, which turns out to be a completely adequate description of nature for a large number of effects. We have not had to worry yet about the fact that light energy comes in lumps or \u201cphotons.\u201d We would like to take up as our next subject the problem of the behavior of relatively large pieces of matter\u2014their mechanical and thermal properties, for instance. In discussing these, we will find that the \u201cclassical\u201d (or older) theory fails almost immediately, because matter is really made up of atomic-sized particles. Still, we will deal only with the classical part, because that is the only part that we can understand using the classical mechanics we have been learning. But we shall not be very successful. We shall find that in the case of matter, unlike the case of light, we shall be in difficulty relatively soon. We could, of course, continuously skirt away from the atomic effects, but we shall instead interpose here a short excursion in which we will describe the basic ideas of the quantum properties of matter, i.e., the quantum ideas of atomic physics, so that you will have some feeling for what it is we are leaving out. For we will have to leave out some important subjects that we cannot avoid coming close to. So we will give now the introduction to the subject of quantum mechanics, but will not be able actually to get into the subject until much later. \u201cQuantum mechanics\u201d is the description of the behavior of matter in all its details and, in particular, of the happenings on an atomic scale. Things on a very small scale behave like nothing that you have any direct experience about. They do not behave like waves, they do not behave like particles, they do not behave like clouds, or billiard balls, or weights on springs, or like anything that you have ever seen. Newton thought that light was made up of particles, but then it was discovered, as we have seen here, that it behaves like a wave. Later, however (in the beginning of the twentieth century) it was found that light did indeed sometimes behave like a particle. Historically, the electron, for example, was thought to behave like a particle, and then it was found that in many respects it behaved like a wave. So it really behaves like neither. Now we have given up. We say: \u201cIt is like neither.\u201d There is one lucky break, however\u2014electrons behave just like light. The quantum behavior of atomic objects (electrons, protons, neutrons, photons, and so on) is the same for all, they are all \u201cparticle waves,\u201d or whatever you want to call them. So what we learn about the properties of electrons (which we shall use for our examples) will apply also to all \u201cparticles,\u201d including photons of light. The gradual accumulation of information about atomic and small-scale behavior during the first quarter of the 20th century, which gave some indications about how small things do behave, produced an increasing confusion which was finally resolved in 1926 and 1927 by Schr\u00f6dinger, Heisenberg, and Born. They finally obtained a consistent description of the behavior of matter on a small scale. We take up the main features of that description in this chapter. Because atomic behavior is so unlike ordinary experience, it is very difficult to get used to and it appears peculiar and mysterious to everyone, both to the novice and to the experienced physicist. Even the experts do not understand it the way they would like to, and it is perfectly reasonable that they should not, because all of direct, human experience and of human intuition applies to large objects. We know how large objects will act, but things on a small scale just do not act that way. So we have to learn about them in a sort of abstract or imaginative fashion and not by connection with our direct experience. In this chapter we shall tackle immediately the basic element of the mysterious behavior in its most strange form. We choose to examine a phenomenon which is impossible, absolutely impossible, to explain in any classical way, and which has in it the heart of quantum mechanics. In reality, it contains the only mystery. We cannot explain the mystery in the sense of \u201cexplaining\u201d how it works. We will tell you how it works. In telling you how it works we will have told you about the basic peculiarities of all quantum mechanics. To try to understand the quantum behavior of electrons, we shall compare and contrast their behavior, in a particular experimental setup, with the more familiar behavior of particles like bullets, and with the behavior of waves like water waves. We consider first the behavior of bullets in the experimental setup shown diagrammatically in Fig. 37\u20131. We have a machine gun that shoots a stream of bullets. It is not a very good gun, in that it sprays the bullets (randomly) over a fairly large angular spread, as indicated in the figure. In front of the gun we have a wall (made of armor plate) that has in it two holes just about big enough to let a bullet through. Beyond the wall is a backstop (say a thick wall of wood) which will \u201cabsorb\u201d the bullets when they hit it. In front of the backstop we have an object which we shall call a \u201cdetector\u201d of bullets. It might be a box containing sand. Any bullet that enters the detector will be stopped and accumulated. When we wish, we can empty the box and count the number of bullets that have been caught. The detector can be moved back and forth (in what we will call the x -direction). With this apparatus, we can find out experimentally the answer to the question: \u201cWhat is the probability that a bullet which passes through the holes in the wall will arrive at the backstop at the distance x from the center?\u201d First, you should realize that we should talk about probability, because we cannot say definitely where any particular bullet will go. A bullet which happens to hit one of the holes may bounce off the edges of the hole, and may end up anywhere at all. By \u201cprobability\u201d we mean the chance that the bullet will arrive at the detector, which we can measure by counting the number which arrive at the detector in a certain time and then taking the ratio of this number to the total number that hit the backstop during that time. Or, if we assume that the gun always shoots at the same rate during the measurements, the probability we want is just proportional to the number that reach the detector in some standard time interval. For our present purposes we would like to imagine a somewhat idealized experiment in which the bullets are not real bullets, but are indestructible bullets\u2014they cannot break in half. In our experiment we find that bullets always arrive in lumps, and when we find something in the detector, it is always one whole bullet. If the rate at which the machine gun fires is made very low, we find that at any given moment either nothing arrives, or one and only one\u2014exactly one\u2014bullet arrives at the backstop. Also, the size of the lump certainly does not depend on the rate of firing of the gun. We shall say: \u201cBullets always arrive in identical lumps.\u201d What we measure with our detector is the probability of arrival of a lump. And we measure the probability as a function of x . The result of such measurements with this apparatus (we have not yet done the experiment, so we are really imagining the result) are plotted in the graph drawn in part (c) of Fig. 37\u20131. In the graph we plot the probability to the right and x vertically, so that the x -scale fits the diagram of the apparatus. We call the probability P 12 because the bullets may have come either through hole 1 or through hole 2 . You will not be surprised that P 12 is large near the middle of the graph but gets small if x is very large. You may wonder, however, why P 12 has its maximum value at x=0 . We can understand this fact if we do our experiment again after covering up hole 2 , and once more while covering up hole 1 . When hole 2 is covered, bullets can pass only through hole 1 , and we get the curve marked P 1 in part (b) of the figure. As you would expect, the maximum of P 1 occurs at the value of x which is on a straight line with the gun and hole 1 . When hole 1 is closed, we get the symmetric curve P 2 drawn in the figure. P 2 is the probability distribution for bullets that pass through hole 2 . Comparing parts (b) and (c) of Fig. 37\u20131, we find the important result that P 12 = P 1 + P 2 . (37.1) The probabilities just add together. The effect with both holes open is the sum of the effects with each hole open alone. We shall call this result an observation of \u201cno interference,\u201d for a reason that you will see later. So much for bullets. They come in lumps, and their probability of arrival shows no interference. Now we wish to consider an experiment with water waves. The apparatus is shown diagrammatically in Fig. 37\u20132. We have a shallow trough of water. A small object labeled the \u201cwave source\u201d is jiggled up and down by a motor and makes circular waves. To the right of the source we have again a wall with two holes, and beyond that is a second wall, which, to keep things simple, is an \u201cabsorber,\u201d so that there is no reflection of the waves that arrive there. This can be done by building a gradual sand \u201cbeach.\u201d In front of the beach we place a detector which can be moved back and forth in the x -direction, as before. The detector is now a device which measures the \u201cintensity\u201d of the wave motion. You can imagine a gadget which measures the height of the wave motion, but whose scale is calibrated in proportion to the square of the actual height, so that the reading is proportional to the intensity of the wave. Our detector reads, then, in proportion to the energy being carried by the wave\u2014or rather, the rate at which energy is carried to the detector. With our wave apparatus, the first thing to notice is that the intensity can have any size. If the source just moves a very small amount, then there is just a little bit of wave motion at the detector. When there is more motion at the source, there is more intensity at the detector. The intensity of the wave can have any value at all. We would not say that there was any \u201clumpiness\u201d in the wave intensity. Now let us measure the wave intensity for various values of x (keeping the wave source operating always in the same way). We get the interesting-looking curve marked I 12 in part (c) of the figure. We have already worked out how such patterns can come about when we studied the interference of electric waves. In this case we would observe that the original wave is diffracted at the holes, and new circular waves spread out from each hole. If we cover one hole at a time and measure the intensity distribution at the absorber we find the rather simple intensity curves shown in part (b) of the figure. I 1 is the intensity of the wave from hole 1 (which we find by measuring when hole 2 is blocked off) and I 2 is the intensity of the wave from hole 2 (seen when hole 1 is blocked). The intensity I 12 observed when both holes are open is certainly not the sum of I 1 and I 2 . We say that there is \u201cinterference\u201d of the two waves. At some places (where the curve I 12 has its maxima) the waves are \u201cin phase\u201d and the wave peaks add together to give a large amplitude and, therefore, a large intensity. We say that the two waves are \u201cinterfering constructively\u201d at such places. There will be such constructive interference wherever the distance from the detector to one hole is a whole number of wavelengths larger (or shorter) than the distance from the detector to the other hole. At those places where the two waves arrive at the detector with a phase difference of \u03c0 (where they are \u201cout of phase\u201d) the resulting wave motion at the detector will be the difference of the two amplitudes. The waves \u201cinterfere destructively,\u201d and we get a low value for the wave intensity. We expect such low values wherever the distance between hole 1 and the detector is different from the distance between hole 2 and the detector by an odd number of half-wavelengths. The low values of I 12 in Fig. 37\u20132 correspond to the places where the two waves interfere destructively. You will remember that the quantitative relationship between I 1 , I 2 , and I 12 can be expressed in the following way: The instantaneous height of the water wave at the detector for the wave from hole 1 can be written as (the real part of) h ^ 1 e i\u03c9t , where the \u201camplitude\u201d h ^ 1 is, in general, a complex number. The intensity is proportional to the mean squared height or, when we use the complex numbers, to | h ^ 1 | 2 . Similarly, for hole 2 the height is h ^ 2 e i\u03c9t and the intensity is proportional to | h ^ 2 | 2 . When both holes are open, the wave heights add to give the height ( h ^ 1 + h ^ 2 ) e i\u03c9t and the intensity | h ^ 1 + h ^ 2 | 2 . Omitting the constant of proportionality for our present purposes, the proper relations for interfering waves are I 1 =| h ^ 1 | 2 , I 2 =| h ^ 2 | 2 , I 12 =| h ^ 1 + h ^ 2 | 2 . (37.2) You will notice that the result is quite different from that obtained with bullets (Eq. 37.1). If we expand | h ^ 1 + h ^ 2 | 2 we see that | h ^ 1 + h ^ 2 | 2 =| h ^ 1 | 2 +| h ^ 2 | 2 +2| h ^ 1 || h ^ 2 |cos\u03b4, (37.3) where \u03b4 is the phase difference between h ^ 1 and h ^ 2 . In terms of the intensities, we could write I 12 = I 1 + I 2 +2 I 1 I 2 \u2212 \u2212 \u2212 \u2212 \u221a cos\u03b4. (37.4) The last term in (37.4) is the \u201cinterference term.\u201d So much for water waves. The intensity can have any value, and it shows interference. Now we imagine a similar experiment with electrons. It is shown diagrammatically in Fig. 37\u20133. We make an electron gun which consists of a tungsten wire heated by an electric current and surrounded by a metal box with a hole in it. If the wire is at a negative voltage with respect to the box, electrons emitted by the wire will be accelerated toward the walls and some will pass through the hole. All the electrons which come out of the gun will have (nearly) the same energy. In front of the gun is again a wall (just a thin metal plate) with two holes in it. Beyond the wall is another plate which will serve as a \u201cbackstop.\u201d In front of the backstop we place a movable detector. The detector might be a geiger counter or, perhaps better, an electron multiplier, which is connected to a loudspeaker. We should say right away that you should not try to set up this experiment (as you could have done with the two we have already described). This experiment has never been done in just this way. The trouble is that the apparatus would have to be made on an impossibly small scale to show the effects we are interested in. We are doing a \u201cthought experiment,\u201d which we have chosen because it is easy to think about. We know the results that would be obtained because there are many experiments that have been done, in which the scale and the proportions have been chosen to show the effects we shall describe. The first thing we notice with our electron experiment is that we hear sharp \u201cclicks\u201d from the detector (that is, from the loudspeaker). And all \u201cclicks\u201d are the same. There are no \u201chalf-clicks.\u201d We would also notice that the \u201cclicks\u201d come very erratically. Something like: click \u2026.. click-click \u2026 click \u2026\u2026.. click \u2026. click-click \u2026\u2026 click \u2026, etc., just as you have, no doubt, heard a geiger counter operating. If we count the clicks which arrive in a sufficiently long time\u2014say for many minutes\u2014and then count again for another equal period, we find that the two numbers are very nearly the same. So we can speak of the average rate at which the clicks are heard (so-and-so-many clicks per minute on the average). As we move the detector around, the rate at which the clicks appear is faster or slower, but the size (loudness) of each click is always the same. If we lower the temperature of the wire in the gun the rate of clicking slows down, but still each click sounds the same. We would notice also that if we put two separate detectors at the backstop, one or the other would click, but never both at once. (Except that once in a while, if there were two clicks very close together in time, our ear might not sense the separation.) We conclude, therefore, that whatever arrives at the backstop arrives in \u201clumps.\u201d All the \u201clumps\u201d are the same size: only whole \u201clumps\u201d arrive, and they arrive one at a time at the backstop. We shall say: \u201cElectrons always arrive in identical lumps.\u201d Just as for our experiment with bullets, we can now proceed to find experimentally the answer to the question: \u201cWhat is the relative probability that an electron \u2018lump\u2019 will arrive at the backstop at various distances x from the center?\u201d As before, we obtain the relative probability by observing the rate of clicks, holding the operation of the gun constant. The probability that lumps will arrive at a particular x is proportional to the average rate of clicks at that x . The result of our experiment is the interesting curve marked P 12 in part (c) of Fig. 37\u20133. Yes! That is the way electrons go. Now let us try to analyze the curve of Fig. 37\u20133 to see whether we can understand the behavior of the electrons. The first thing we would say is that since they come in lumps, each lump, which we may as well call an electron, has come either through hole 1 or through hole 2 . Let us write this in the form of a \u201cProposition\u201d: Proposition A: Each electron either goes through hole 1 or it goes through hole 2 . Assuming Proposition A, all electrons that arrive at the backstop can be divided into two classes: (1) those that come through hole 1 , and (2) those that come through hole 2 . So our observed curve must be the sum of the effects of the electrons which come through hole 1 and the electrons which come through hole 2 . Let us check this idea by experiment. First, we will make a measurement for those electrons that come through hole 1 . We block off hole 2 and make our counts of the clicks from the detector. From the clicking rate, we get P 1 . The result of the measurement is shown by the curve marked P 1 in part (b) of Fig. 37\u20133. The result seems quite reasonable. In a similar way, we measure P 2 , the probability distribution for the electrons that come through hole 2 . The result of this measurement is also drawn in the figure. The result P 12 obtained with both holes open is clearly not the sum of P 1 and P 2 , the probabilities for each hole alone. In analogy with our water-wave experiment, we say: \u201cThere is interference.\u201d For electrons: P 12 \u2260 P 1 + P 2 . (37.5) How can such an interference come about? Perhaps we should say: \u201cWell, that means, presumably, that it is not true that the lumps go either through hole 1 or hole 2 , because if they did, the probabilities should add. Perhaps they go in a more complicated way. They split in half and \u2026\u201d But no! They cannot, they always arrive in lumps \u2026 \u201cWell, perhaps some of them go through 1 , and then they go around through 2 , and then around a few more times, or by some other complicated path \u2026 then by closing hole 2 , we changed the chance that an electron that started out through hole 1 would finally get to the backstop \u2026\u201d But notice! There are some points at which very few electrons arrive when both holes are open, but which receive many electrons if we close one hole, so closing one hole increased the number from the other. Notice, however, that at the center of the pattern, P 12 is more than twice as large as P 1 + P 2 . It is as though closing one hole decreased the number of electrons which come through the other hole. It seems hard to explain both effects by proposing that the electrons travel in complicated paths. It is all quite mysterious. And the more you look at it the more mysterious it seems. Many ideas have been concocted to try to explain the curve for P 12 in terms of individual electrons going around in complicated ways through the holes. None of them has succeeded. None of them can get the right curve for P 12 in terms of P 1 and P 2 . Yet, surprisingly enough, the mathematics for relating P 1 and P 2 to P 12 is extremely simple. For P 12 is just like the curve I 12 of Fig. 37\u20132, and that was simple. What is going on at the backstop can be described by two complex numbers that we can call \u03d5 ^ 1 and \u03d5 ^ 2 (they are functions of x , of course). The absolute square of \u03d5 ^ 1 gives the effect with only hole 1 open. That is, P 1 =| \u03d5 ^ 1 | 2 . The effect with only hole 2 open is given by \u03d5 ^ 2 in the same way. That is, P 2 =| \u03d5 ^ 2 | 2 . And the combined effect of the two holes is just P 12 =| \u03d5 ^ 1 + \u03d5 ^ 2 | 2 . The mathematics is the same as that we had for the water waves! (It is hard to see how one could get such a simple result from a complicated game of electrons going back and forth through the plate on some strange trajectory.) We conclude the following: The electrons arrive in lumps, like particles, and the probability of arrival of these lumps is distributed like the distribution of intensity of a wave. It is in this sense that an electron behaves \u201csometimes like a particle and sometimes like a wave.\u201d Incidentally, when we were dealing with classical waves we defined the intensity as the mean over time of the square of the wave amplitude, and we used complex numbers as a mathematical trick to simplify the analysis. But in quantum mechanics it turns out that the amplitudes must be represented by complex numbers. The real parts alone will not do. That is a technical point, for the moment, because the formulas look just the same. Since the probability of arrival through both holes is given so simply, although it is not equal to ( P 1 + P 2 ) , that is really all there is to say. But there are a large number of subtleties involved in the fact that nature does work this way. We would like to illustrate some of these subtleties for you now. First, since the number that arrives at a particular point is not equal to the number that arrives through 1 plus the number that arrives through 2 , as we would have concluded from Proposition A, undoubtedly we should conclude that Proposition A is false. It is not true that the electrons go either through hole 1 or hole 2 . But that conclusion can be tested by another experiment. We shall now try the following experiment. To our electron apparatus we add a very strong light source, placed behind the wall and between the two holes, as shown in Fig. 37\u20134. We know that electric charges scatter light. So when an electron passes, however it does pass, on its way to the detector, it will scatter some light to our eye, and we can see where the electron goes. If, for instance, an electron were to take the path via hole 2 that is sketched in Fig. 37\u20134, we should see a flash of light coming from the vicinity of the place marked A in the figure. If an electron passes through hole 1 we would expect to see a flash from the vicinity of the upper hole. If it should happen that we get light from both places at the same time, because the electron divides in half \u2026 Let us just do the experiment! Here is what we see: every time that we hear a \u201cclick\u201d from our electron detector (at the backstop), we also see a flash of light either near hole 1 or near hole 2 , but never both at once! And we observe the same result no matter where we put the detector. From this observation we conclude that when we look at the electrons we find that the electrons go either through one hole or the other. Experimentally, Proposition A is necessarily true. What, then, is wrong with our argument against Proposition A? Why isn\u2019t P 12 just equal to P 1 + P 2 ? Back to experiment! Let us keep track of the electrons and find out what they are doing. For each position ( x -location) of the detector we will count the electrons that arrive and also keep track of which hole they went through, by watching for the flashes. We can keep track of things this way: whenever we hear a \u201cclick\u201d we will put a count in Column 1 if we see the flash near hole 1 , and if we see the flash near hole 2 , we will record a count in Column 2 . Every electron which arrives is recorded in one of two classes: those which come through 1 and those which come through 2 . From the number recorded in Column 1 we get the probability P \u2032 1 that an electron will arrive at the detector via hole 1 ; and from the number recorded in Column 2 we get P \u2032 2 , the probability that an electron will arrive at the detector via hole 2 . If we now repeat such a measurement for many values of x , we get the curves for P \u2032 1 and P \u2032 2 shown in part (b) of Fig. 37\u20134. Well, that is not too surprising! We get for P \u2032 1 something quite similar to what we got before for P 1 by blocking off hole 2 ; and P \u2032 2 is similar to what we got by blocking hole 1 . So there is not any complicated business like going through both holes. When we watch them, the electrons come through just as we would expect them to come through. Whether the holes are closed or open, those which we see come through hole 1 are distributed in the same way whether hole 2 is open or closed. But wait! What do we have now for the total probability, the probability that an electron will arrive at the detector by any route? We already have that information. We just pretend that we never looked at the light flashes, and we lump together the detector clicks which we have separated into the two columns. We must just add the numbers. For the probability that an electron will arrive at the backstop by passing through either hole, we do find P \u2032 12 = P \u2032 1 + P \u2032 2 . That is, although we succeeded in watching which hole our electrons come through, we no longer get the old interference curve P 12 , but a new one, P \u2032 12 showing no interference! If we turn out the light P 12 is restored. We must conclude that when we look at the electrons the distribution of them on the screen is different than when we do not look. Perhaps it is turning on our light source that disturbs things? It must be that the electrons are very delicate, and the light, when it scatters off the electrons, gives them a jolt that changes their motion. We know that the electric field of the light acting on a charge will exert a force on it. So perhaps we should expect the motion to be changed. Anyway, the light exerts a big influence on the electrons. By trying to \u201cwatch\u201d the electrons we have changed their motions. That is, the jolt given to the electron when the photon is scattered by it is such as to change the electron\u2019s motion enough so that if it might have gone to where P 12 was at a maximum it will instead land where P 12 was a minimum; that is why we no longer see the wavy interference effects. You may be thinking: \u201cDon\u2019t use such a bright source! Turn the brightness down! The light waves will then be weaker and will not disturb the electrons so much. Surely, by making the light dimmer and dimmer, eventually the wave will be weak enough that it will have a negligible effect.\u201d O.K. Let\u2019s try it. The first thing we observe is that the flashes of light scattered from the electrons as they pass by does not get weaker. It is always the same-sized flash. The only thing that happens as the light is made dimmer is that sometimes we hear a \u201cclick\u201d from the detector but see no flash at all. The electron has gone by without being \u201cseen.\u201d What we are observing is that light also acts like electrons, we knew that it was \u201cwavy,\u201d but now we find that it is also \u201clumpy.\u201d It always arrives\u2014or is scattered\u2014in lumps that we call \u201cphotons.\u201d As we turn down the intensity of the light source we do not change the size of the photons, only the rate at which they are emitted. That explains why, when our source is dim, some electrons get by without being seen. There did not happen to be a photon around at the time the electron went through. This is all a little discouraging. If it is true that whenever we \u201csee\u201d the electron we see the same-sized flash, then those electrons we see are always the disturbed ones. Let us try the experiment with a dim light anyway. Now whenever we hear a click in the detector we will keep a count in three columns: in Column (1) those electrons seen by hole 1 , in Column (2) those electrons seen by hole 2 , and in Column (3) those electrons not seen at all. When we work up our data (computing the probabilities) we find these results: Those \u201cseen by hole 1 \u201d have a distribution like P \u2032 1 ; those \u201cseen by hole 2 \u201d have a distribution like P \u2032 2 (so that those \u201cseen by either hole 1 or 2 \u201d have a distribution like P \u2032 12 ); and those \u201cnot seen at all\u201d have a \u201cwavy\u201d distribution just like P 12 of Fig. 37\u20133! If the electrons are not seen, we have interference! That is understandable. When we do not see the electron, no photon disturbs it, and when we do see it, a photon has disturbed it. There is always the same amount of disturbance because the light photons all produce the same-sized effects and the effect of the photons being scattered is enough to smear out any interference effect. Is there not some way we can see the electrons without disturbing them? We learned in an earlier chapter that the momentum carried by a \u201cphoton\u201d is inversely proportional to its wavelength ( p=h/\u03bb ). Certainly the jolt given to the electron when the photon is scattered toward our eye depends on the momentum that photon carries. Aha! If we want to disturb the electrons only slightly we should not have lowered the intensity of the light, we should have lowered its frequency (the same as increasing its wavelength). Let us use light of a redder color. We could even use infrared light, or radiowaves (like radar), and \u201csee\u201d where the electron went with the help of some equipment that can \u201csee\u201d light of these longer wavelengths. If we use \u201cgentler\u201d light perhaps we can avoid disturbing the electrons so much. Let us try the experiment with longer waves. We shall keep repeating our experiment, each time with light of a longer wavelength. At first, nothing seems to change. The results are the same. Then a terrible thing happens. You remember that when we discussed the microscope we pointed out that, due to the wave nature of the light, there is a limitation on how close two spots can be and still be seen as two separate spots. This distance is of the order of the wavelength of light. So now, when we make the wavelength longer than the distance between our holes, we see a big fuzzy flash when the light is scattered by the electrons. We can no longer tell which hole the electron went through! We just know it went somewhere! And it is just with light of this color that we find that the jolts given to the electron are small enough so that P \u2032 12 begins to look like P 12 \u2014that we begin to get some interference effect. And it is only for wavelengths much longer than the separation of the two holes (when we have no chance at all of telling where the electron went) that the disturbance due to the light gets sufficiently small that we again get the curve P 12 shown in Fig. 37\u20133. In our experiment we find that it is impossible to arrange the light in such a way that one can tell which hole the electron went through, and at the same time not disturb the pattern. It was suggested by Heisenberg that the then new laws of nature could only be consistent if there were some basic limitation on our experimental capabilities not previously recognized. He proposed, as a general principle, his uncertainty principle, which we can state in terms of our experiment as follows: \u201cIt is impossible to design an apparatus to determine which hole the electron passes through, that will not at the same time disturb the electrons enough to destroy the interference pattern.\u201d If an apparatus is capable of determining which hole the electron goes through, it cannot be so delicate that it does not disturb the pattern in an essential way. No one has ever found (or even thought of) a way around the uncertainty principle. So we must assume that it describes a basic characteristic of nature. The complete theory of quantum mechanics which we now use to describe atoms and, in fact, all matter depends on the correctness of the uncertainty principle. Since quantum mechanics is such a successful theory, our belief in the uncertainty principle is reinforced. But if a way to \u201cbeat\u201d the uncertainty principle were ever discovered, quantum mechanics would give inconsistent results and would have to be discarded as a valid theory of nature. \u201cWell,\u201d you say, \u201cwhat about Proposition A? It is true, or is it not true, that the electron either goes through hole 1 or it goes through hole 2 ?\u201d The only answer that can be given is that we have found from experiment that there is a certain special way that we have to think in order that we do not get into inconsistencies. What we must say (to avoid making wrong predictions) is the following. If one looks at the holes or, more accurately, if one has a piece of apparatus which is capable of determining whether the electrons go through hole 1 or hole 2 , then one can say that it goes either through hole 1 or hole 2 . But, when one does not try to tell which way the electron goes, when there is nothing in the experiment to disturb the electrons, then one may not say that an electron goes either through hole 1 or hole 2 . If one does say that, and starts to make any deductions from the statement, he will make errors in the analysis. This is the logical tightrope on which we must walk if we wish to describe nature successfully. If the motion of all matter\u2014as well as electrons\u2014must be described in terms of waves, what about the bullets in our first experiment? Why didn\u2019t we see an interference pattern there? It turns out that for the bullets the wavelengths were so tiny that the interference patterns became very fine. So fine, in fact, that with any detector of finite size one could not distinguish the separate maxima and minima. What we saw was only a kind of average, which is the classical curve. In Fig. 37\u20135 we have tried to indicate schematically what happens with large-scale objects. Part (a) of the figure shows the probability distribution one might predict for bullets, using quantum mechanics. The rapid wiggles are supposed to represent the interference pattern one gets for waves of very short wavelength. Any physical detector, however, straddles several wiggles of the probability curve, so that the measurements show the smooth curve drawn in part (b) of the figure. We will now write a summary of the main conclusions of our experiments. We will, however, put the results in a form which makes them true for a general class of such experiments. We can write our summary more simply if we first define an \u201cideal experiment\u201d as one in which there are no uncertain external influences, i.e., no jiggling or other things going on that we cannot take into account. We would be quite precise if we said: \u201cAn ideal experiment is one in which all of the initial and final conditions of the experiment are completely specified.\u201d What we will call \u201can event\u201d is, in general, just a specific set of initial and final conditions. (For example: \u201can electron leaves the gun, arrives at the detector, and nothing else happens.\u201d) Now for our summary. Summary The probability of an event in an ideal experiment is given by the square of the absolute value of a complex number \u03d5 which is called the probability amplitude: P \u03d5 P =probability, =probability amplitude, =|\u03d5 | 2 . (37.6) When an event can occur in several alternative ways, the probability amplitude for the event is the sum of the probability amplitudes for each way considered separately. There is interference: \u03d5 P = \u03d5 1 + \u03d5 2 , =| \u03d5 1 + \u03d5 2 | 2 . (37.7) If an experiment is performed which is capable of determining whether one or another alternative is actually taken, the probability of the event is the sum of the probabilities for each alternative. The interference is lost: P= P 1 + P 2 . (37.8) One might still like to ask: \u201cHow does it work? What is the machinery behind the law?\u201d No one has found any machinery behind the law. No one can \u201cexplain\u201d any more than we have just \u201cexplained.\u201d No one will give you any deeper representation of the situation. We have no ideas about a more basic mechanism from which these results can be deduced. We would like to emphasize a very important difference between classical and quantum mechanics. We have been talking about the probability that an electron will arrive in a given circumstance. We have implied that in our experimental arrangement (or even in the best possible one) it would be impossible to predict exactly what would happen. We can only predict the odds! This would mean, if it were true, that physics has given up on the problem of trying to predict exactly what will happen in a definite circumstance. Yes! physics has given up. We do not know how to predict what would happen in a given circumstance, and we believe now that it is impossible, that the only thing that can be predicted is the probability of different events. It must be recognized that this is a retrenchment in our earlier ideal of understanding nature. It may be a backward step, but no one has seen a way to avoid it. We make now a few remarks on a suggestion that has sometimes been made to try to avoid the description we have given: \u201cPerhaps the electron has some kind of internal works\u2014some inner variables\u2014that we do not yet know about. Perhaps that is why we cannot predict what will happen. If we could look more closely at the electron we could be able to tell where it would end up.\u201d So far as we know, that is impossible. We would still be in difficulty. Suppose we were to assume that inside the electron there is some kind of machinery that determines where it is going to end up. That machine must also determine which hole it is going to go through on its way. But we must not forget that what is inside the electron should not be dependent on what we do, and in particular upon whether we open or close one of the holes. So if an electron, before it starts, has already made up its mind (a) which hole it is going to use, and (b) where it is going to land, we should find P 1 for those electrons that have chosen hole 1 , P 2 for those that have chosen hole 2 , and necessarily the sum P 1 + P 2 for those that arrive through the two holes. There seems to be no way around this. But we have verified experimentally that that is not the case. And no one has figured a way out of this puzzle. So at the present time we must limit ourselves to computing probabilities. We say \u201cat the present time,\u201d but we suspect very strongly that it is something that will be with us forever\u2014that it is impossible to beat that puzzle\u2014that this is the way nature really is. This is the way Heisenberg stated the uncertainty principle originally: If you make the measurement on any object, and you can determine the x -component of its momentum with an uncertainty \u0394p , you cannot, at the same time, know its x -position more accurately than \u0394x\u2265\u210f/2\u0394p . The uncertainties in the position and momentum at any instant must have their product greater than or equal to half the reduced Planck constant. This is a special case of the uncertainty principle that was stated above more generally. The more general statement was that one cannot design equipment in any way to determine which of two alternatives is taken, without, at the same time, destroying the pattern of interference. Let us show for one particular case that the kind of relation given by Heisenberg must be true in order to keep from getting into trouble. We imagine a modification of the experiment of Fig. 37\u20133, in which the wall with the holes consists of a plate mounted on rollers so that it can move freely up and down (in the x -direction), as shown in Fig. 37\u20136. By watching the motion of the plate carefully we can try to tell which hole an electron goes through. Imagine what happens when the detector is placed at x=0 . We would expect that an electron which passes through hole 1 must be deflected downward by the plate to reach the detector. Since the vertical component of the electron momentum is changed, the plate must recoil with an equal momentum in the opposite direction. The plate will get an upward kick. If the electron goes through the lower hole, the plate should feel a downward kick. It is clear that for every position of the detector, the momentum received by the plate will have a different value for a traversal via hole 1 than for a traversal via hole 2 . So! Without disturbing the electrons at all, but just by watching the plate, we can tell which path the electron used. Now in order to do this it is necessary to know what the momentum of the screen is, before the electron goes through. So when we measure the momentum after the electron goes by, we can figure out how much the plate\u2019s momentum has changed. But remember, according to the uncertainty principle we cannot at the same time know the position of the plate with an arbitrary accuracy. But if we do not know exactly where the plate is we cannot say precisely where the two holes are. They will be in a different place for every electron that goes through. This means that the center of our interference pattern will have a different location for each electron. The wiggles of the interference pattern will be smeared out. We shall show quantitatively in the next chapter that if we determine the momentum of the plate sufficiently accurately to determine from the recoil measurement which hole was used, then the uncertainty in the x -position of the plate will, according to the uncertainty principle, be enough to shift the pattern observed at the detector up and down in the x -direction about the distance from a maximum to its nearest minimum. Such a random shift is just enough to smear out the pattern so that no interference is observed. The uncertainty principle \u201cprotects\u201d quantum mechanics. Heisenberg recognized that if it were possible to measure the momentum and the position simultaneously with a greater accuracy, the quantum mechanics would collapse. So he proposed that it must be impossible. Then people sat down and tried to figure out ways of doing it, and nobody could figure out a way to measure the position and the momentum of anything\u2014a screen, an electron, a billiard ball, anything\u2014with any greater accuracy. Quantum mechanics maintains its perilous but accurate existence."
    },
    {
        "input": "Electrostatics",
        "output": "We begin now our detailed study of the theory of electromagnetism. All of electromagnetism is contained in the Maxwell equations. Maxwell\u2019s equations: \u2207\u22c5E = \u03c1 \u03f50 , \u2207\u00d7E =\u2212 \u2202B \u2202t , c2\u2207\u00d7B = \u2202E \u2202t + j \u03f50 , \u2207\u22c5B =0. The situations that are described by these equations can be very complicated. We will consider first relatively simple situations, and learn how to handle them before we take up more complicated ones. The easiest circumstance to treat is one in which nothing depends on the time\u2014called the static case. All charges are permanently fixed in space, or if they do move, they move as a steady flow in a circuit (so \u03c1 and j are constant in time). In these circumstances, all of the terms in the Maxwell equations which are time derivatives of the field are zero. In this case, the Maxwell equations become: Electrostatics: \u2207\u22c5E = \u03c1 \u03f50 , \u2207\u00d7E =0. Magnetostatics: \u2207\u00d7B = j \u03f50c2 , \u2207\u22c5B =0. You will notice an interesting thing about this set of four equations. It can be separated into two pairs. The electric field E appears only in the first two, and the magnetic field B appears only in the second two. The two fields are not interconnected. This means that electricity and magnetism are distinct phenomena so long as charges and currents are static. The interdependence of E and B does not appear until there are changes in charges or currents, as when a condensor is charged, or a magnet moved. Only when there are sufficiently rapid changes, so that the time derivatives in Maxwell\u2019s equations become significant, will E and B depend on each other. Now if you look at the equations of statics you will see that the study of the two subjects we call electrostatics and magnetostatics is ideal from the point of view of learning about the mathematical properties of vector fields. Electrostatics is a neat example of a vector field with zero curl and a given divergence. Magnetostatics is a neat example of a field with zero divergence and a given curl. The more conventional\u2014and you may be thinking, more satisfactory\u2014way of presenting the theory of electromagnetism is to start first with electrostatics and thus to learn about the divergence. Magnetostatics and the curl are taken up later. Finally, electricity and magnetism are put together. We have chosen to start with the complete theory of vector calculus. Now we shall apply it to the special case of electrostatics, the field of E given by the first pair of equations. We will begin with the simplest situations\u2014ones in which the positions of all charges are specified. If we had only to study electrostatics at this level (as we shall do in the next two chapters), life would be very simple\u2014in fact, almost trivial. Everything can be obtained from Coulomb\u2019s law and some integration, as you will see. In many real electrostatic problems, however, we do not know, initially, where the charges are. We know only that they have distributed themselves in ways that depend on the properties of matter. The positions that the charges take up depend on the E field, which in turn depends on the positions of the charges. Then things can get quite complicated. If, for instance, a charged body is brought near a conductor or insulator, the electrons and protons in the conductor or insulator will move around. The charge density \u03c1 in Eq. (4.5) may have one part that we know about, from the charge that we brought up; but there will be other parts from charges that have moved around in the conductor. And all of the charges must be taken into account. One can get into some rather subtle and interesting problems. So although this chapter is to be on electrostatics, it will not cover the more beautiful and subtle parts of the subject. It will treat only the situation where we can assume that the positions of all the charges are known. Naturally, you should be able to do that case before you try to handle the other ones. It would be logical to use Eqs. (4.5) and (4.6) as our starting points. It will be easier, however, if we start somewhere else and come back to these equations. The results will be equivalent. We will start with a law that we have talked about before, called Coulomb\u2019s law, which says that between two charges at rest there is a force directly proportional to the product of the charges and inversely proportional to the square of the distance between. The force is along the straight line from one charge to the other. Coulomb\u2019s law: F1= 1 4\u03c0\u03f50 q1q2 r 2 12 e12=\u2212F2. F1 is the force on charge q1 , e12 is the unit vector in the direction to q1 from q2 , and r12 is the distance between q1 and q2 . The force F2 on q2 is equal and opposite to F1 . The constant of proportionality, for historical reasons, is written as 1/4\u03c0\u03f50 . In the system of units which we use\u2014the mks system\u2014it is defined as exactly 10\u22127 times the speed of light squared. Now since the speed of light is approximately 3\u00d7108 meters per second, the constant is approximately 9\u00d7109 , and the unit turns out to be newton\u22c5 meter2 per coulomb2 or volt\u22c5 meter per coulomb. 1 4\u03c0\u03f50 =10\u22127c2(by definition) =9.0\u00d7109(by experiment). Unit: newton\u22c5meter2/coulomb2, or volt\u22c5meter/coulomb. When there are more than two charges present\u2014the only really interesting times\u2014we must supplement Coulomb\u2019s law with one other fact of nature: the force on any charge is the vector sum of the Coulomb forces from each of the other charges. This fact is called \u201cthe principle of superposition.\u201d That\u2019s all there is to electrostatics. If we combine the Coulomb law and the principle of superposition, there is nothing else. Equations (4.5) and (4.6)\u2014the electrostatic equations\u2014say no more and no less. When applying Coulomb\u2019s law, it is convenient to introduce the idea of an electric field. We say that the field E(1) is the force per unit charge on q 1 (due to all other charges). Dividing Eq. (4.9) by q 1 , we have, for one other charge besides q 1 , E(1)= 1 4\u03c0 \u03f5 0 q 2 r 2 12 e 12 . (4.11) Also, we consider that E(1) describes something about the point (1) even if q 1 were not there\u2014assuming that all other charges keep their same positions. We say: E(1) is the electric field at the point (1) . The electric field E is a vector, so by Eq. (4.11) we really mean three equations\u2014one for each component. Writing out explicitly the x -component, Eq. (4.11) means E x ( x 1 , y 1 , z 1 )= q 2 4\u03c0 \u03f5 0 x 1 \u2212 x 2 [( x 1 \u2212 x 2 ) 2 +( y 1 \u2212 y 2 ) 2 +( z 1 \u2212 z 2 ) 2 ] 3/2 , (4.12) and similarly for the other components. If there are many charges present, the field E at any point (1) is a sum of the contributions from each of the other charges. Each term of the sum will look like (4.11) or (4.12). Letting q j be the magnitude of the j th charge, and r 1j the displacement from q j to the point (1) , we write E(1)= \u2211 j 1 4\u03c0 \u03f5 0 q j r 2 1j e 1j . (4.13) Which means, of course, E x ( x 1 , y 1 , z 1 )= \u2211 j 1 4\u03c0 \u03f5 0 q j ( x 1 \u2212 x j ) [( x 1 \u2212 x j ) 2 +( y 1 \u2212 y j ) 2 +( z 1 \u2212 z j ) 2 ] 3/2 , (4.14) and so on. Often it is convenient to ignore the fact that charges come in packages like electrons and protons, and think of them as being spread out in a continuous smear\u2014or in a \u201cdistribution,\u201d as it is called. This is O.K. so long as we are not interested in what is happening on too small a scale. We describe a charge distribution by the \u201ccharge density,\u201d \u03c1(x,y,z) . If the amount of charge in a small volume \u0394 V 2 located at the point (2) is \u0394 q 2 , then \u03c1 is defined by \u0394 q 2 =\u03c1(2)\u0394 V 2 . (4.15) To use Coulomb\u2019s law with such a description, we replace the sums of Eqs. (4.13) or (4.14) by integrals over all volumes containing charges. Then we have E(1)= 1 4\u03c0 \u03f5 0 \u222b all space \u03c1(2) e 12 d V 2 r 2 12 . (4.16) Some people prefer to write e 12 = r 12 r 12 , r where r 12 is the vector displacement to (1) from (2) , as shown in Fig. 4-1. The integral for E is then written as E(1)= 1 4\u03c0 \u03f5 0 \u222b all space \u03c1(2) r 12 d V 2 r 3 12 . (4.17) When we want to calculate something with these integrals, we usually have to write them out in explicit detail. For the x -component of either Eq. (4.16) or (4.17), we would have E x ( x 1 , y 1 , z 1 )= \u222b all space ( x 1 \u2212 x 2 )\u03c1( x 2 , y 2 , z 2 )d x 2 d y 2 d z 2 4\u03c0 \u03f5 0 [( x 1 \u2212 x 2 ) 2 +( y 1 \u2212 y 2 ) 2 +( z 1 \u2212 z 2 ) 2 ] 3/2 . (4.18) We are not going to use this formula much. We write it here only to emphasize the fact that we have completely solved all the electrostatic problems in which we know the locations of all of the charges. Given the charges, what are the fields? Answer: Do this integral. So there is nothing to the subject; it is just a case of doing complicated integrals over three dimensions\u2014strictly a job for a computing machine! With our integrals we can find the fields produced by a sheet of charge, from a line of charge, from a spherical shell of charge, or from any specified distribution. It is important to realize, as we go on to draw field lines, to talk about potentials, or to calculate divergences, that we already have the answer here. It is merely a matter of it being sometimes easier to do an integral by some clever guesswork than by actually carrying it out. The guesswork requires learning all kinds of strange things. In practice, it might be easier to forget trying to be clever and always to do the integral directly instead of being so smart. We are, however, going to try to be smart about it. We shall go on to discuss some other features of the electric field. First we take up the idea of electric potential, which is related to the work done in carrying a charge from one point to another. There is some distribution of charge, which produces an electric field. We ask about how much work it would take to carry a small charge from one place to another. The work done against the electrical forces in carrying a charge along some path is the negative of the component of the electrical force in the direction of the motion, integrated along the path. If we carry a charge from point a to point b , W=\u2212 \u222b b a F\u22c5ds, b where F is the electrical force on the charge at each point, and ds is the differential vector displacement along the path. (See Fig. 4-2.) It is more interesting for our purposes to consider the work that would be done in carrying one unit of charge. Then the force on the charge is numerically the same as the electric field. Calling the work done against electrical forces in this case W(unit) , we write W(unit)=\u2212 \u222b b a E\u22c5ds. (4.19) Now, in general, what we get with this kind of an integral depends on the path we take. But if the integral of (4.19) depended on the path from a to b , we could get work out of the field by carrying the charge to b along one path and then back to a on the other. We would go to b along the path for which W is smaller and back along the other, getting out more work than we put in. There is nothing impossible, in principle, about getting energy out of a field. We shall, in fact, encounter fields where it is possible. It could be that as you move a charge you produce forces on the other part of the \u201cmachinery.\u201d If the \u201cmachinery\u201d moved against the force it would lose energy, thereby keeping the total energy in the world constant. For electrostatics, however, there is no such \u201cmachinery.\u201d We know what the forces back on the sources of the field are. They are the Coulomb forces on the charges responsible for the field. If the other charges are fixed in position\u2014as we assume in electrostatics only\u2014these back forces can do no work on them. There is no way to get energy from them\u2014provided, of course, that the principle of energy conservation works for electrostatic situations. We believe that it will work, but let\u2019s just show that it must follow from Coulomb\u2019s law of force. We consider first what happens in the field due to a single charge q . Let point a be at the distance r a from q , and point b at r b . Now we carry a different charge, which we will call the \u201ctest\u201d charge, and whose magnitude we choose to be one unit, from a to b . Let\u2019s start with the easiest possible path to calculate. We carry our test charge first along the arc of a circle, then along a radius, as shown in part (a) of Fig. 4-3. Now on that particular path it is child\u2019s play to find the work done (otherwise we wouldn\u2019t have picked it). First, there is no work done at all on the path from a to a \u2032 . The field is radial (from Coulomb\u2019s law), so it is at right angles to the direction of motion. Next, on the path from a \u2032 to b , the field is in the direction of motion and varies as 1/ r 2 . Thus the work done on the test charge in carrying it from a to b would be \u2212 \u222b b a E\u22c5ds =\u2212 q 4\u03c0 \u03f5 0 \u222b b a \u2032 dr r 2 =\u2212 q 4\u03c0 \u03f5 0 ( 1 r a \u2212 1 r b ). (4.20) Now let\u2019s take another easy path. For instance, the one shown in part (b) of Fig. 4-3. It goes for awhile along an arc of a circle, then radially for awhile, then along an arc again, then radially, and so on. Every time we go along the circular parts, we do no work. Every time we go along the radial parts, we must just integrate 1/ r 2 . Along the first radial stretch, we integrate from r a to r a \u2032 , then along the next radial stretch from r a \u2032 to r a \u2032\u2032 , and so on. The sum of all these integrals is the same as a single integral directly from r a to r b . We get the same answer for this path that we did for the first path we tried. It is clear that we would get the same answer for any path which is made up of an arbitrary number of the same kinds of pieces. What about smooth paths? Would we get the same answer? We discussed this point previously in Chapter 13 of Vol. I. Applying the same arguments used there, we can conclude that work done in carrying a unit charge from a to b is independent of the path. W(unit) a\u2192b }=\u2212 \u222b b a any path E\u22c5ds. b Since the work done depends only on the endpoints, it can be represented as the difference between two numbers. We can see this in the following way. Let\u2019s choose a reference point P 0 and agree to evaluate our integral by using a path that always goes by way of point P 0 . Let \u03d5(a) stand for the work done against the field in going from P 0 to point a , and let \u03d5(b) be the work done in going from P 0 to point b (Fig. 4-4). The work in going to P 0 from a (on the way to b ) is the negative of \u03d5(a) , so we have that \u2212 \u222b b a E\u22c5ds=\u03d5(b)\u2212\u03d5(a). (4.21) Since only the difference in the function \u03d5 at two points is ever involved, we do not really have to specify the location of P 0 . Once we have chosen some reference point, however, a number \u03d5 is determined for any point in space; \u03d5 is then a scalar field. It is a function of x , y , z . We call this scalar function the electrostatic potential at any point. Electrostatic potential: \u03d5(P)=\u2212 \u222b P P 0 E\u22c5ds. (4.22) For convenience, we will often take the reference point at infinity. Then, for a single charge at the origin, the potential \u03d5 is given for any point (x,y,z) \u2014using Eq. (4.20): \u03d5(x,y,z)= q 4\u03c0 \u03f5 0 1 r . (4.23) The electric field from several charges can be written as the sum of the electric field from the first, from the second, from the third, etc. When we integrate the sum to find the potential we get a sum of integrals. Each of the integrals is the negative of the potential from one of the charges. We conclude that the potential \u03d5 from a lot of charges is the sum of the potentials from all the individual charges. There is a superposition principle also for potentials. Using the same kind of arguments by which we found the electric field from a group of charges and for a distribution of charges, we can get the complete formulas for the potential \u03d5 at a point we call (1) : \u03d5(1) \u03d5(1) = \u2211 j 1 4\u03c0 \u03f5 0 q j r 1j , = 1 4\u03c0 \u03f5 0 \u222b all space \u03c1(2)d V 2 r 12 . (4.24) (4.25) Remember that the potential \u03d5 has a physical significance: it is the potential energy which a unit charge would have if brought to the specified point in space from some reference point. Who cares about \u03d5 ? Forces on charges are given by E , the electric field. The point is that E can be obtained easily from \u03d5 \u2014it is as easy, in fact, as taking a derivative. Consider two points, one at x and one at (x+\u0394x) , but both at the same y and z , and ask how much work is done in carrying a unit charge from one point to the other. The path is along the horizontal line from x to x+\u0394x . The work done is the difference in the potential at the two points: \u0394W=\u03d5(x+\u0394x,y,z)\u2212\u03d5(x,y,z)= \u2202\u03d5 \u2202x \u0394x. \u2202 \u03d5 But the work done against the field for the same path is \u0394W=\u2212\u222bE\u22c5ds=\u2212 E x \u0394x. \u222b We see that E x =\u2212 \u2202\u03d5 \u2202x . (4.26) Similarly, E y =\u2212\u2202\u03d5/\u2202y , E z =\u2212\u2202\u03d5/\u2202z , or, summarizing with the notation of vector analysis, E=\u2212\u2207\u03d5. (4.27) This equation is the differential form of Eq. (4.22). Any problem with specified charges can be solved by computing the potential from (4.24) or (4.25) and using (4.27) to get the field. Equation (4.27) also agrees with what we found from vector calculus: that for any scalar field \u03d5 \u222b b a \u2207\u03d5\u22c5ds=\u03d5(b)\u2212\u03d5(a). (4.28) According to Eq. (4.25) the scalar potential \u03d5 is given by a three-dimensional integral similar to the one we had for E . Is there any advantage to computing \u03d5 rather than E ? Yes. There is only one integral for \u03d5 , while there are three integrals for E \u2014because it is a vector. Furthermore, 1/r is usually a little easier to integrate than x/ r 3 . It turns out in many practical cases that it is easier to calculate \u03d5 and then take the gradient to find the electric field, than it is to evaluate the three integrals for E . It is merely a practical matter. There is also a deeper physical significance to the potential \u03d5 . We have shown that E of Coulomb\u2019s law is obtained from E=\u2212grad \u03d5 , when \u03d5 is given by (4.22). But if E is equal to the gradient of a scalar field, then we know from the vector calculus that the curl of E must vanish: \u2207\u00d7E=0. (4.29) But that is just our second fundamental equation of electrostatics, Eq. (4.6). We have shown that Coulomb\u2019s law gives an E field that satisfies that condition. So far, everything is all right. We had really proved that \u2207\u00d7E was zero before we defined the potential. We had shown that the work done around a closed path is zero. That is, that \u222eE\u22c5ds=0 \u222e for any path. We saw in Chapter 3 that for any such field \u2207\u00d7E must be zero everywhere. The electric field in electrostatics is an example of a curl-free field. You can practice your vector calculus by proving that \u2207\u00d7E is zero in a different way\u2014by computing the components of \u2207\u00d7E for the field of a point charge, as given by Eq. (4.11). If you get zero, the superposition principle says you would get zero for the field of any charge distribution. We should point out an important fact. For any radial force the work done is independent of the path, and there exists a potential. If you think about it, the entire argument we made above to show that the work integral was independent of the path depended only on the fact that the force from a single charge was radial and spherically symmetric. It did not depend on the fact that the dependence on distance was as 1/ r 2 \u2014there could have been any r dependence. The existence of a potential, and the fact that the curl of E is zero, comes really only from the symmetry and direction of the electrostatic forces. Because of this, Eq. (4.28)\u2014or (4.29)\u2014can contain only part of the laws of electricity. We will now derive a field equation that depends specifically and directly on the fact that the force law is inverse square. That the field varies inversely as the square of the distance seems, for some people, to be \u201conly natural,\u201d because \u201cthat\u2019s the way things spread out.\u201d Take a light source with light streaming out: the amount of light that passes through a surface cut out by a cone with its apex at the source is the same no matter at what radius the surface is placed. It must be so if there is to be conservation of light energy. The amount of light per unit area\u2014the intensity\u2014must vary inversely as the area cut by the cone, i.e., inversely as the square of the distance from the source. Certainly the electric field should vary inversely as the square of the distance for the same reason! But there is no such thing as the \u201csame reason\u201d here. Nobody can say that the electric field measures the flow of something like light which must be conserved. If we had a \u201cmodel\u201d of the electric field in which the electric field vector represented the direction and speed\u2014say the current\u2014of some kind of little \u201cbullets\u201d which were flying out, and if our model required that these bullets were conserved, that none could ever disappear once it was shot out of a charge, then we might say that we can \u201csee\u201d that the inverse square law is necessary. On the other hand, there would necessarily be some mathematical way to express this physical idea. If the electric field were like conserved bullets going out, then it would vary inversely as the square of the distance and we would be able to describe that behavior by an equation\u2014which is purely mathematical. Now there is no harm in thinking this way, so long as we do not say that the electric field is made out of bullets, but realize that we are using a model to help us find the right mathematics. Suppose, indeed, that we imagine for a moment that the electric field did represent the flow of something that was conserved\u2014everywhere, that is, except at charges. (It has to start somewhere!) We imagine that whatever it is flows out of a charge into the space around. If E were the vector of such a flow (as h is for heat flow), it would have a 1/ r 2 dependence near a point source. Now we wish to use this model to find out how to state the inverse square law in a deeper or more abstract way, rather than simply saying \u201cinverse square.\u201d (You may wonder why we should want to avoid the direct statement of such a simple law, and want instead to imply the same thing sneakily in a different way. Patience! It will turn out to be useful.) We ask: What is the \u201cflow\u201d of E out of an arbitrary closed surface in the neighborhood of a point charge? First let\u2019s take an easy surface\u2014the one shown in Fig. 4-5. If the E field is like a flow, the net flow out of this box should be zero. That is what we get if by the \u201cflow\u201d from this surface we mean the surface integral of the normal component of E \u2014that is, the flux of E . On the radial faces, the normal component is zero. On the spherical faces, the normal component E n is just the magnitude of E \u2014minus for the smaller face and plus for the larger face. The magnitude of E decreases as 1/ r 2 , but the surface area is proportional to r 2 , so the product is independent of r . The flux of E into face a is just cancelled by the flux out of face b . The total flow out of S is zero, which is to say that for this surface \u222b S E n da=0. (4.30) Next we show that the two end surfaces may be tilted with respect to the radial line without changing the integral (4.30). Although it is true in general, for our purposes it is only necessary to show that this is true when the end surfaces are small, so that they subtend a small angle from the source\u2014in fact, an infinitesimal angle. In Fig. 4-6 we show a surface S whose \u201csides\u201d are radial, but whose \u201cends\u201d are tilted. The end surfaces are not small in the figure, but you are to imagine the situation for very small end surfaces. Then the field E will be sufficiently uniform over the surface that we can use just its value at the center. When we tilt the surface by an angle \u03b8 , the area is increased by the factor 1/cos\u03b8 . But E n , the component of E normal to the surface, is decreased by the factor cos\u03b8 . The product E n \u0394a is unchanged. The flux out of the whole surface S is still zero. Now it is easy to see that the flux out of a volume enclosed by any surface S must be zero. Any volume can be thought of as made up of pieces, like that in Fig. 4-6. The surface will be subdivided completely into pairs of end surfaces, and since the fluxes in and out of these end surfaces cancel by pairs, the total flux out of the surface will be zero. The idea is illustrated in Fig. 4-7. We have the completely general result that the total flux of E out of any surface S in the field of a point charge is zero. But notice! Our proof works only if the surface S does not surround the charge. What would happen if the point charge were inside the surface? We could still divide our surface into pairs of areas that are matched by radial lines through the charge, as shown in Fig. 4-8. The fluxes through the two surfaces are still equal\u2014by the same arguments as before\u2014only now they have the same sign. The flux out of a surface that surrounds a charge is not zero. Then what is it? We can find out by a little trick. Suppose we \u201cremove\u201d the charge from the \u201cinside\u201d by surrounding the charge by a little surface S \u2032 totally inside the original surface S , as shown in Fig. 4-9. Now the volume enclosed between the two surfaces S and S \u2032 has no charge in it. The total flux out of this volume (including that through S \u2032 ) is zero, by the arguments we have given above. The arguments tell us, in fact, that the flux into the volume through S \u2032 is the same as the flux outward through S . We can choose any shape we wish for S \u2032 , so let\u2019s make it a sphere centered on the charge, as in Fig. 4-10. Then we can easily calculate the flux through it. If the radius of the little sphere is r , the value of E everywhere on its surface is 1 4\u03c0 \u03f5 0 q r 2 , 1 and is directed always normal to the surface. We find the total flux through S \u2032 if we multiply this normal component of E by the surface area: ( Flux through the surface S \u2032 ) =( 1 4\u03c0 \u03f5 0 q r 2 )(4\u03c0 r 2 ) = q \u03f5 0 , (4.31) a number independent of the radius of the sphere! We know then that the flux outward through S is also q/ \u03f5 0 \u2014a value independent of the shape of S so long as the charge q is inside. We can write our conclusions as follows: \u222b any closed surface S E n da= \u23a7 \u23a9 \u23a8 0; q \u03f5 0 ; q outside S q inside S (4.32) Let\u2019s return to our \u201cbullet\u201d analogy and see if it makes sense. Our theorem says that the net flow of bullets through a surface is zero if the surface does not enclose the gun that shoots the bullets. If the gun is enclosed in a surface, whatever size and shape it is, the number of bullets passing through is the same\u2014it is given by the rate at which bullets are generated at the gun. It all seems quite reasonable for conserved bullets. But does the model tell us anything more than we get simply by writing Eq. (4.32)? No one has succeeded in making these \u201cbullets\u201d do anything else but produce this one law. After that, they produce nothing but errors. That is why today we prefer to represent the electromagnetic field purely abstractly. Our nice result, Eq. (4.32), was proved for a single point charge. Now suppose that there are two charges, a charge q 1 at one point and a charge q 2 at another. The problem looks more difficult. The electric field whose normal component we integrate for the flux is the field due to both charges. That is, if E 1 represents the electric field that would have been produced by q 1 alone, and E 2 represents the electric field produced by q 2 alone, the total electric field is E= E 1 + E 2 . The flux through any closed surface S is \u222b S ( E 1n + E 2n )da= \u222b S E 1n da+ \u222b S E 2n da. (4.33) The flux with both charges present is the flux due to a single charge plus the flux due to the other charge. If both charges are outside S , the flux through S is zero. If q 1 is inside S but q 2 is outside, then the first integral gives q 1 / \u03f5 0 and the second integral gives zero. If the surface encloses both charges, each will give its contribution and we have that the flux is ( q 1 + q 2 )/ \u03f5 0 . The general rule is clearly that the total flux out of a closed surface is equal to the total charge inside, divided by \u03f5 0 . Our result is an important general law of the electrostatic field, called Gauss\u2019 law. Gauss\u2019 law: \u222b any closed surface S E n da= sum of charges inside \u03f5 0 , (4.34) or \u222b any closed surface S E\u22c5nda= Q int \u03f5 0 , (4.35) where Q int = \u2211 inside S q i . (4.36) If we describe the location of charges in terms of a charge density \u03c1 , we can consider that each infinitesimal volume dV contains a \u201cpoint\u201d charge \u03c1dV . The sum over all charges is then the integral Q int = \u222b volume inside S \u03c1dV. (4.37) From our derivation you see that Gauss\u2019 law follows from the fact that the exponent in Coulomb\u2019s law is exactly two. A 1/ r 3 field, or any 1/ r n field with n\u22602 , would not give Gauss\u2019 law. So Gauss\u2019 law is just an expression, in a different form, of the Coulomb law of forces between two charges. In fact, working back from Gauss\u2019 law, you can derive Coulomb\u2019s law. The two are quite equivalent so long as we keep in mind the rule that the forces between charges are radial. We would now like to write Gauss\u2019 law in terms of derivatives. To do this, we apply Gauss\u2019 law to an infinitesimal cubical surface. We showed in Chapter 3 that the flux of E out of such a cube is \u2207\u22c5E times the volume dV of the cube. The charge inside of dV , by the definition of \u03c1 , is equal to \u03c1dV , so Gauss\u2019 law gives \u2207\u22c5EdV= \u03c1dV \u03f5 0 , d V or \u2207\u22c5E= \u03c1 \u03f5 0 . (4.38) The differential form of Gauss\u2019 law is the first of our fundamental field equations of electrostatics, Eq. (4.5). We have now shown that the two equations of electrostatics, Eqs. (4.5) and (4.6), are equivalent to Coulomb\u2019s law of force. We will now consider one example of the use of Gauss\u2019 law. (We will come later to many more examples.) One of the difficult problems we had when we studied the theory of gravitational attractions was to prove that the force produced by a solid sphere of matter was the same at the surface of the sphere as it would be if all the matter were concentrated at the center. For many years Newton didn\u2019t make public his theory of gravitation, because he couldn\u2019t be sure this theorem was true. We proved the theorem in Chapter 13 of Vol. I by doing the integral for the potential and then finding the gravitational force by using the gradient. Now we can prove the theorem in a most simple fashion. Only this time we will prove the corresponding theorem for a uniform sphere of electrical charge. (Since the laws of electrostatics are the same as those of gravitation, the same proof could be done for the gravitational field.) We ask: What is the electric field E at a point P anywhere outside the surface of a sphere filled with a uniform distribution of charge? Since there is no \u201cspecial\u201d direction, we can assume that E is everywhere directed away from the center of the sphere. We consider an imaginary surface that is spherical and concentric with the sphere of charge, and that passes through the point P (Fig. 4-11). For this surface, the flux outward is \u222b E n da=E\u22c54\u03c0 R 2 . \u222b Gauss\u2019 law tells us that this flux is equal to the total charge Q of the sphere (over \u03f5 0 ): E\u22c54\u03c0 R 2 = Q \u03f5 0 , Q or E= 1 4\u03c0 \u03f5 0 Q R 2 , (4.39) which is the same formula we would have for a point charge Q . We have proved Newton\u2019s problem more easily than by doing the integral. It is, of course, a false kind of easiness\u2014it has taken you some time to be able to understand Gauss\u2019 law, so you may think that no time has really been saved. But after you have used the theorem more and more, it begins to pay. It is a question of efficiency. We would like now to give a geometrical description of the electrostatic field. The two laws of electrostatics, one that the flux is proportional to the charge inside and the other that the electric field is the gradient of a potential, can also be represented geometrically. We illustrate this with two examples. First, we take the field of a point charge. We draw lines in the direction of the field\u2014lines which are always tangent to the field, as in Fig. 4-12. These are called field lines. The lines show everywhere the direction of the electric vector. But we also wish to represent the magnitude of the vector. We can make the rule that the strength of the electric field will be represented by the \u201cdensity\u201d of the lines. By the density of the lines we mean the number of lines per unit area through a surface perpendicular to the lines. With these two rules we can have a picture of the electric field. For a point charge, the density of the lines must decrease as 1/ r 2 . But the area of a spherical surface perpendicular to the lines at any radius r increases as r 2 , so if we always keep the same number of lines for all distances from the charge, the density will remain in proportion to the magnitude of the field. We can guarantee that there are the same number of lines at every distance if we insist that the lines be continuous\u2014that once a line is started from the charge, it never stops. In terms of the field lines, Gauss\u2019 law says that lines should start only at plus charges and stop at minus charges. The number which leave a charge q must be equal to q/ \u03f5 0 . Now, we can find a similar geometrical picture for the potential \u03d5 . The easiest way to represent the potential is to draw surfaces on which \u03d5 is a constant. We call them equipotential surfaces\u2014surfaces of equal potential. Now what is the geometrical relationship of the equipotential surfaces to the field lines? The electric field is the gradient of the potential. The gradient is in the direction of the most rapid change of the potential, and is therefore perpendicular to an equipotential surface. If E were not perpendicular to the surface, it would have a component in the surface. The potential would be changing in the surface, but then it wouldn\u2019t be an equipotential. The equipotential surfaces must then be everywhere at right angles to the electric field lines. For a point charge all by itself, the equipotential surfaces are spheres centered at the charge. We have shown in Fig. 4-12 the intersection of these spheres with a plane through the charge. As a second example, we consider the field near two equal charges, a positive one and a negative one. To get the field is easy. The field is the superposition of the fields from each of the two charges. So, we can take two pictures like Fig. 4-12 and superimpose them\u2014impossible! Then we would have field lines crossing each other, and that\u2019s not possible, because E can\u2019t have two directions at the same point. The disadvantage of the field-line picture is now evident. By geometrical arguments it is impossible to analyze in a very simple way where the new lines go. From the two independent pictures, we can\u2019t get the combined picture. The principle of superposition, a simple and deep principle about electric fields, does not have, in the field-line picture, an easy representation. The field-line picture has its uses, however, so we might still like to draw the picture for a pair of equal (and opposite) charges. If we calculate the fields from Eq. (4.13) and the potentials from (4.24), we can draw the field lines and equipotentials. Figure 4-13 shows the result. But we first had to solve the problem mathematically!"
    },
    {
        "input": "The Internal Geometry of Crystals",
        "output": "We have finished the study of the basic laws of electricity and magnetism, and we are now going to study the electromagnetic properties of matter. We begin by describing solids\u2014that is, crystals. When the atoms of matter are not moving around very much, they get stuck together and arrange themselves in a configuration with as low an energy as possible. If the atoms in a certain place have found a pattern which seems to be of low energy, then the atoms somewhere else will probably make the same arrangement. For these reasons, we have in a solid material a repetitive pattern of atoms. In other words, the conditions in a crystal are this way: The environment of a particular atom in a crystal has a certain arrangement, and if you look at the same kind of an atom at another place farther along, you will find one whose surroundings are exactly the same. If you pick an atom farther along by the same distance, you will find the conditions exactly the same once more. The pattern is repeated over and over again\u2014and, of course, in three dimensions. Imagine the problem of designing a wallpaper\u2014or a cloth, or some geometric design for a plane area\u2014in which you are supposed to have a design element which repeats and repeats and repeats, so that you can make the area as large as you want. This is the two-dimensional analog of a problem which a crystal solves in three dimensions. For example, Fig. 30\u20131(a) shows a common kind of wallpaper design. There is a single element repeated in a pattern that can go on forever. The geometric characteristics of this wallpaper design, considering only its repetition properties and not worrying about the geometry of the flower itself or its artistic merit, are contained in Fig. 30\u20131(b). If you start at any point, you can find the corresponding point by moving the distance a along the direction of arrow 1 . You can also get to a corresponding point if you move the distance b in the direction of the other arrow. There are, of course, many other directions. You can go, for example, from point \u03b1 to point \u03b2 and reach a corresponding position, but such a step can be considered as a combination of a step along direction 1 , followed by a step along direction 2 . One of the basic properties of the pattern can be described by the two shortest steps to nearby equal positions. By \u201cequal\u201d positions we mean that if you were to stand in any one of them and look around you, you would see exactly the same thing as if you were to stand in another one. That\u2019s the fundamental property of a crystal. The only difference is that a crystal is a three-dimensional arrangement instead of a two-dimensional arrangement; and naturally, instead of flowers, each element of the lattice is some kind of an arrangement of atoms\u2014perhaps six hydrogen atoms and two carbon atoms\u2014in some kind of pattern. The pattern of atoms in a crystal can be found out experimentally by x-ray diffraction. We have mentioned this method briefly before, and won\u2019t say any more now except that the precise arrangement of the atoms in space has been worked out for most simple crystals and also for some fairly complex ones. The internal pattern of a crystal shows up in several ways. First, the binding strength of the atoms in certain directions is usually stronger than in other directions. This means that there are certain planes through the crystal where it is more easily broken than others. They are called the cleavage planes. If you crack a crystal with a knife blade it will often split apart along such a plane. Second, the internal structure often appears at the surface because of the way the crystal was formed. Imagine a crystal being deposited out of a solution. There are the atoms floating around in the solution and finally settling down when they find a position of lowest energy. (It\u2019s as if the wallpaper got made by flowers drifting around until one drifted accidentally into place and got stuck, and then the next, and the next so that the pattern gradually grows.) You can appreciate that there will be certain directions in which it will grow at a different speed than in other directions, thereby growing into some kind of geometrical shape. Because of such effects, the outside surfaces of many crystals show some of the character of the internal arrangement of the atoms. For example, Fig. 30\u20132(a) shows the shape of a typical quartz crystal whose internal pattern is hexagonal. If you look closely at such a crystal, you will notice that the outside does not make a very good hexagon because the sides are not all of equal length\u2014they are, in fact, often very unequal. But in one respect it is a very good hexagon: the angles between the faces are exactly 120\u2218 . Clearly, the size of any particular face is an accident of the growth, but the angles are a representation of the internal geometry. So every crystal of quartz has a different shape, even though the angles between corresponding faces are always the same. The internal geometry of a crystal of sodium chloride is also evident from its external shape. Figure 30\u20132(b) shows the shape of a typical grain of salt. Again the crystal is not a perfect cube, but the faces are exactly at right angles to one another. A more complicated crystal is mica, which has the shape shown in Fig. 30\u20132(c). It is a highly anisotropic crystal, as is easily seen from the fact that it is very tough if you try to pull it apart in one direction (horizontally in the figure), but very easy to split by pulling apart in the other direction (vertically). It has commonly been used to obtain very tough, thin sheets. Mica and quartz are two examples of natural minerals containing silica. A third example of a mineral with silica is asbestos, which has the interesting property that it is easily pulled apart in two directions but not in the third. It appears to be made of very strong, linear fibers. The mechanical properties of crystals clearly depend on the kind of chemical bindings between the atoms. The strikingly different strength of mica along different directions depends on the kinds of interatomic binding in the different directions. You have already learned in chemistry, no doubt, about the different kinds of chemical bonds. First, there are ionic bonds, as we have already discussed for sodium chloride. Roughly speaking, the sodium atoms have lost an electron and become positive ions; the chlorine atoms have gained an electron and become negative ions. The positive and negative ions are arranged in a three-dimensional checkerboard and are held together by electrical forces. The covalent bond\u2014in which electrons are shared between two atoms\u2014is more common and is usually very strong. In a diamond, for example, the carbon atoms have covalent bonds in all four directions to the nearest neighbors, so the crystal is very hard indeed. There is also covalent bonding between silicon and oxygen in a quartz crystal, but there the bond is really only partially covalent. Because there is not complete sharing of the electrons, the atoms are partly charged, and the crystal is somewhat ionic. Nature is not as simple as we try to make it; there are really all possible gradations between covalent and ionic bonding. A sugar crystal has still another kind of binding. In it there are large molecules in which the atoms are held strongly together by covalent bonds, so that the molecule is a tough structure. But since the strong bonds are completely satisfied, there are only relatively weak attractions between the separate, individual molecules. In such molecular crystals the molecules keep their individual identity, so to speak, and the internal arrangement might be as shown in Fig. 30\u20133. Since the molecules are not held strongly to each other, the crystals are easy to break. They are quite different from something like diamond, which is really one giant molecule that cannot be broken anywhere without disrupting strong covalent bonds. Paraffin is another example of a molecular crystal. An extreme example of a molecular crystal occurs in a substance like solid argon. There is very little attraction between the atoms\u2014each atom is a completely saturated monatomic molecule. But at very low temperatures, the thermal motion is very small, so the slight interatomic forces can cause the atoms to settle down into a regular array like a pile of closely packed spheres. The metals form a completely different class of substances. The bonding is of an entirely different kind. In a metal the bonding is not between adjacent atoms but is a property of the whole crystal. The valence electrons are not attached to one atom or to a pair of atoms but are shared throughout the crystal. Each atom contributes an electron to a universal pool of electrons, and the atomic positive ions reside in the sea of negative electrons. The electron sea holds the ions together like some kind of glue. In the metals, since there are no special bonds in any particular direction, there is no strong directionality in the binding. They are still crystalline, however, because the total energy is lowest when the atomic ions are arranged in some definite array\u2014although the energy of the preferred arrangement is not usually much lower than other possible ones. To a first approximation, the atoms of many metals are like small spheres packed in as tightly as possible. Try to imagine the natural formation of crystals in the earth. In the earth\u2019s surface there is a big mixture of all kinds of atoms. They are being continually churned about by volcanic action, by wind, and by water\u2014continually being moved about and mixed. Yet, by some trick, silicon atoms gradually begin to find each other, and to find oxygen atoms, to make silica. One atom at a time is added to the others to build up a crystal\u2014the mixture gets unmixed. And somewhere nearby, sodium and chlorine atoms are finding each other and building up a crystal of salt. How does it happen that once a crystal is started, it permits only a particular kind of atom to join on? It happens because the whole system is working toward the lowest possible energy. A growing crystal will accept a new atom if it is going to make the energy as low as possible. But how does it know that a silicon\u2014or an oxygen\u2014atom at some particular spot is going to result in the lowest possible energy? It does it by trial and error. In the liquid, all of the atoms are in perpetual motion. Each atom bounces against its neighbors about 1013 times every second. If it hits against the right spot of growing crystal, it has a somewhat smaller chance of jumping off again if the energy is low. By continually testing over periods of millions of years at a rate of 1013 tests per second, the atoms gradually build up at the places where they find their lowest energy. Eventually they grow into big crystals. The arrangement of the atoms in a crystal\u2014the crystal lattice\u2014can take on many geometric forms. We would like to describe first the simplest lattices, which are characteristic of most of the metals and of the solid form of the inert gases. They are the cubic lattices which can occur in two forms: the body-centered cubic, shown in Fig. 30\u20134(a), and the face-centered cubic shown in Fig. 30\u20134(b). The drawings show, of course, only one cube of the lattice; you are to imagine that the pattern is repeated indefinitely in three dimensions. Also, to make the drawing clearer, only the \u201ccenters\u201d of the atoms are shown. In an actual crystal, the atoms are more like spheres in contact with each other. The dark and light spheres in the drawings may, in general, stand for different kinds of atoms or may be the same kind. For instance, iron has a body-centered cubic lattice at low temperatures, but a face-centered cubic lattice at higher temperatures. The physical properties are quite different in the two crystalline forms. How do such forms come about? Imagine that you have the problem of packing spherical atoms together as tightly as possible. One way would be to start by making a layer in a \u201chexagonal close-packed array,\u201d as shown in Fig. 30\u20135(a). Then you could build up a second layer like the first, but displaced horizontally, as shown in Fig. 30\u20135(b). Next, you can put on the third layer. But notice! There are two distinct ways of placing the third layer. If you start the third layer by placing an atom at A in Fig. 30\u20135(b), each atom in the third layer is directly above an atom of the bottom layer. On the other hand, if you start the third layer by putting an atom at the position B , the atoms of the third layer will be centered at points exactly in the middle of a triangle formed by three atoms of the bottom layer. Any other starting place is equivalent to A or B , so there are only two ways of placing the third layer. If the third layer has an atom at point B , the crystal lattice is a face-centered cubic\u2014but seen at an angle. It seems funny that starting with hexagons you can end up with cubes. But notice that a cube looked at from a corner has a hexagonal outline. For instance, Fig. 30\u20136 could represent a plane hexagon or a cube seen in perspective! If a third layer is added to Fig. 30\u20135(b) by starting with an atom at A , there is no cubical structure, and the lattice has instead only a hexagonal symmetry. It is clear that both possibilities we have described are equally close-packed. Some metals\u2014for example, copper and silver\u2014choose the first alternative, the face-centered cubic. Others\u2014for example, beryllium and magnesium\u2014choose the other alternatives; they form hexagonal crystals. Clearly, which crystal lattice appears cannot depend only on the packing of little spheres, but must also be determined in part by other factors. In particular, it depends on the slight remaining angular dependence of the interatomic forces (or, in the case of the metals, on the energy of the electron pool). You will, no doubt, learn all about such things in your chemistry courses. We would now like to discuss some of the properties of crystals from the point of view of their internal symmetries. The main feature of a crystal is that if you start at one atom and move to a corresponding atom one lattice unit away, you are again in the same kind of an environment. That\u2019s the fundamental proposition. But if you were an atom, there would be another kind of change that could take you again to the same environment\u2014that is, another possible \u201csymmetry.\u201d Figure 30\u20137(a) shows another possible \u201cwallpaper-type\u201d design (though one you have probably never seen). Suppose we compare the environments for points A and B . You might, at first, think that they are the same\u2014but not quite. Points C and D are equivalent to A , but the environment of B is like that of A only if the surroundings are reversed, as in a mirror reflection. There are other kinds of \u201cequivalent\u201d points in the pattern. For instance, the points E and F have the \u201csame\u201d environments except that one is rotated 90 \u2218 with respect to the other. The pattern is quite special. A rotation of 90 \u2218 \u2014or any multiple of it\u2014about a vertex such as A gives the same pattern all over again. A crystal with such a structure would have square corners on the outside, but inside it is more complicated than a simple cube. Now that we have described some special examples, let\u2019s try to figure out all the possible symmetries a crystal can have. First, we consider what happens in a plane. A plane lattice can be defined by the two so-called primitive vectors that go from one point of the lattice to the two nearest equivalent points. The two vectors 1 and 2 are the primitive vectors of the lattice of Fig. 30\u20131. The two vectors a and b of Fig. 30\u20137(a) are the primitive vectors of the pattern there. We could, of course, equally well replace a by \u2212a , or b by \u2212b . Since a and b are equal in magnitude and at right angles, a rotation of 90 \u2218 turns a into b , and b into \u2212a , giving the same lattice once again. We see that there are lattices which have a \u201cfour-sided\u201d symmetry. And we have described earlier a close-packed array based on a hexagon which could have a six-sided symmetry. A rotation of the array of circles in Fig. 30\u20135(a) by an angle of 60 \u2218 about the center of any circle brings the pattern back to itself. What other kinds of rotational symmetry are there? Can we have, for example, a fivefold or an eightfold rotational symmetry? It is easy to see that they are impossible. The only symmetry with more sides than four is a six-sided symmetry. First, let\u2019s show that more than sixfold symmetry is impossible. Suppose we try to imagine a lattice with two equal primitive vectors with an enclosed angle less than 60 \u2218 , as in Fig. 30\u20138(a). We are to suppose that points B and C are equivalent to A , and that a and b are the two shortest vectors from A to its equivalent neighbors. But that is clearly wrong, because the distance between B and C is shorter than from either one to A . There must be a neighbor at D equivalent to A which is closer than B or C . We should have chosen b \u2032 as one of our primitive vectors. So the angle between the two primitive vectors must be 60 \u2218 or larger. Octagonal symmetry is not possible. What about fivefold symmetry? If we assume that the primitive vectors a and b have equal lengths and make an angle of 2\u03c0/5= 72 \u2218 , as in Fig. 30\u20138(b), then there should also be an equivalent lattice point at D , at 72 \u2218 from C . But the vector b \u2032 from E to D is then less than b , so b is not a primitive vector. There can be no fivefold symmetry. The only possibilities that do not get us into this kind of difficulty are \u03b8= 60 \u2218 , 90 \u2218 , or 120 \u2218 . Zero or 180 \u2218 are also clearly possible. One way of stating our result is that the pattern can be left unchanged by a rotation of one full turn (no change at all), one-half of a turn, one-third, one-fourth, or one-sixth of a turn. And those are all the possible rotational symmetries in a plane\u2014a total of five. If \u03b8=2\u03c0/n , we speak of an \u201c n -fold\u201d symmetry. We say that a pattern with n equal to 4 or to 6 has a \u201chigher symmetry\u201d than one with n equal to 1 or to 2 . Returning to Fig. 30\u20137(a), we see that the pattern has a fourfold rotational symmetry. We have drawn in Fig. 30\u20137(b) another design which has the same symmetry properties as part (a). The little comma-like figures are asymmetric objects which serve to define the symmetry of the design inside of each square. Notice that the commas are reversed in alternate squares, so that the unit cell is larger than one of the small squares. If there were no commas, the pattern would still have fourfold symmetry, but the unit cell would be smaller. The patterns of Fig. 30\u20137 also have other symmetry properties. For instance, a reflection about any of the broken lines R \u2013 R reproduces the same pattern. The patterns of Fig. 30\u20137 have still another kind of symmetry. If the pattern is reflected about the line Y \u2013 Y and shifted one square to the right (or left), we get back the original pattern. The line Y \u2013 Y is called a \u201cglide\u201d line. These are all the possible symmetries in two dimensions. There is one more spatial symmetry operation which is equivalent in two dimensions to a 180 \u2218 rotation, but which is a quite distinct operation in three dimensions. It is inversion. By an inversion we mean that any point at the vector displacement R from some origin [for instance, the point A in Fig. 30\u20139(b)] is moved to the point at \u2212R . An inversion of pattern (a) of Fig. 30\u20139 produces a new pattern, but an inversion of pattern (b) reproduces the same pattern. For a two-dimensional pattern (as you can see from the figure), an inversion of the pattern (b) through the point A is equivalent to a rotation of 180 \u2218 about the same point. Suppose, however, we make the pattern in Fig. 30\u20139(b) three dimensional by imagining that the little 6 \u2019s and 9 \u2019s each have an \u201carrow\u201d pointing out of the page. After an inversion in three dimensions all the arrows will be reversed, so the pattern is not reproduced. If we indicate the heads and tails of the arrows by dots and crosses, respectively, we can make a three-dimensional pattern, as in Fig. 30\u20139(c), which is not symmetric under an inversion, or we can make a pattern like the one shown in (d), which does have such a symmetry. Notice that it is not possible to imitate a three-dimensional inversion by any combination of rotations. If we characterize the \u201csymmetry\u201d of a pattern\u2014or lattice\u2014by the kinds of symmetry operations we have been describing, it turns out that for two dimensions 17 distinct patterns are possible. We have drawn one pattern of the lowest possible symmetry in Fig. 30\u20131, and one of high symmetry in Fig. 30\u20137. We will leave you with the game of trying to figure out all of the 17 possible patterns. It is peculiar how few of the 17 possible patterns are used in making wallpaper and fabrics. One always sees the same three or four basic patterns. Is this because of a lack of imagination of designers, or because many of the possible patterns are not pleasing to the eye? So far we have talked only about patterns in two dimensions. What we are really interested in, however, are patterns of atoms in three dimensions. First, it is clear that a three-dimensional crystal will have three primitive vectors. If we then ask about the possible symmetry operations in three dimensions, we find that there are 230 different possible symmetries! For some purposes, these 230 types can be grouped into seven classes, which are drawn in Fig. 30\u201310. The lattice with the least symmetry is called the triclinic. Its unit cell is a parallelepiped. The primitive vectors are of different lengths, and no two of the angles between them are equal. There is no possibility of any rotational or reflection symmetry. There are, however, still two possible symmetries\u2014the unit cell is, or is not, changed by an inversion through the vertex. (By an inversion in three dimensions, we again mean that spatial displacements R are replaced by \u2212R \u2014in other words, that (x,y,z) goes into (\u2212x,\u2212y,\u2212z) ). So the triclinic lattice has only two possible symmetries, unless there is some special relation among the primitive vectors. For example, if all the vectors are equal and are separated by equal angles, one has the trigonal lattice shown in the figure. This figure can have an additional symmetry; it may be unchanged by a rotation about the long, body diagonal. If one of the primitive vectors, say c , is at right angles to the other two, we get a monoclinic unit cell. A new symmetry is possible\u2014a rotation by 180 \u2218 about c . The hexagonal cell is a special case in which the vectors a and b are equal and the angle between them is 60 \u2218 , so that a rotation of 60 \u2218 , or 120 \u2218 , or 180 \u2218 about the vector c repeats the same lattice (for certain internal symmetries). If all three primitive vectors are at right angles, but of different lengths, we get the orthorhombic cell. The figure is symmetric for rotations of 180 \u2218 about the three axes. Higher-order symmetries are possible with the tetragonal cell, which has all right angles and two equal primitive vectors. Finally, there is the cubic cell, which is the most symmetric of all. The point of all this discussion about symmetries is that the internal symmetries of the crystals show up\u2014sometimes in subtle ways\u2014in the macroscopic physical properties of the crystal. For instance, a crystal will, in general, have a tensor electric polarizability. If we describe the tensor in terms of the ellipsoid of polarization, we should expect that some of the crystal symmetries should show up also in the ellipsoid. For example, a cubic crystal is symmetric with respect to a rotation of 90 \u2218 about any one of three orthogonal directions. Clearly, the only ellipsoid with this property is a sphere. A cubic crystal must be an isotropic dielectric. On the other hand, a tetragonal crystal has a fourfold rotational symmetry. Its ellipsoid must have two of its principal axes equal, and the third must be parallel to the axis of the crystal. Similarly, since the orthorhombic crystal has twofold rotational symmetry about three orthogonal axes, its axes must coincide with the axes of the polarization ellipsoid. In a like manner, one of the axes of a monoclinic crystal must be parallel to one of the principal axes of the ellipsoid, though we can\u2019t say anything about the other axes. Since a triclinic crystal has no rotational symmetry, the ellipsoid can have any orientation at all. As you can see, we can make a big game of figuring out the possible symmetries and relating them to the possible physical tensors. We have considered only the polarization tensor, but things get more complicated for others\u2014for instance, for the tensor of elasticity. There is a branch of mathematics called \u201cgroup theory\u201d that deals with such subjects, but usually you can figure out what you want with common sense. We have said that metals usually have a simple cubic crystal structure; we want now to discuss their mechanical properties\u2014which depend on this structure. Metals are, generally speaking, very \u201csoft,\u201d because it is easy to slide one layer of the crystal over the next. You may think: \u201cThat\u2019s ridiculous; metals are strong.\u201d Not so, a single crystal of a metal can be distorted very easily. Suppose we look at two layers of a crystal subjected to a shear force, as shown in the diagram of Fig. 30\u201311(a). You might at first think the whole layer would resist motion until the force was big enough to push the whole layer \u201cover the hump,\u201d so that it shifted one notch to the left. Although slipping does occur along a plane, it doesn\u2019t happen that way. (If it did, you would calculate that the metal is much stronger than it really is.) What happens is more like one atom going at a time; first the atom on the left makes its jump, then the next, and so on, as indicated in Fig. 30\u201311(b). In effect it is the vacant space between two atoms that quickly travels to the right, with the net result that the whole second layer has moved over one atomic spacing. The slipping goes this way because it takes much less energy to lift one atom at a time over the hump than to lift a whole row. Once the force is enough to start the process, it goes the rest of the way very fast. It turns out that in a real crystal, slipping will occur repeatedly at one plane, then will stop there and start at some other plane. The details of why it starts and stops are quite mysterious. It is, in fact, quite strange that successive regions of slip are often fairly evenly spaced. Figure 30\u201312 shows a photograph of a tiny thin copper crystal that has been stretched. You can see the various planes where slipping has occurred. The sudden slipping of individual crystal planes is quite apparent if you take a piece of tin wire that has large crystals in it and stretch it while holding it next to your ear. You can hear a rush of \u201cticks\u201d as the planes snap to their new positions, one after the other. The problem of having a \u201cmissing\u201d atom in one row is somewhat more difficult than it might appear from Fig. 30\u201311. When there are more layers, the situation must be something like that shown in Fig. 30\u201313. Such an imperfection in a crystal is called a dislocation. It is presumed that such dislocations are either present when the crystal was formed or are generated at some notch or crack at the surface. Once they are produced, they can move relatively freely through the crystal. The gross distortions result from the motions of many of such dislocations. Dislocations can move freely\u2014that is, they require little extra energy\u2014so long as the rest of the crystal has a perfect lattice. But they may get \u201cstuck\u201d if they encounter some other kind of imperfection in the crystal. If it takes a lot of energy for them to pass the imperfection, they will be stopped. This is precisely the mechanism that gives strength to imperfect metal crystals. Pure iron crystals are quite soft, but a small concentration of impurity atoms may cause enough imperfections to effectively immobilize the dislocations. As you know, steel, which is primarily iron, is very hard. To make steel, a small amount of carbon is dissolved in the iron melt; if the melt is cooled rapidly, the carbon precipitates out in little grains, making many microscopic distortions in the lattice. The dislocations can no longer move about, and the metal is hard. Pure copper is very soft, but can be \u201cwork-hardened.\u201d This is done by hammering on it or bending it back and forth. In this case, many new dislocations of various kinds are made which interfere with one another, cutting down their mobility. Perhaps you\u2019ve seen the trick of taking a bar of \u201cdead soft\u201d copper and gently bending it around someone\u2019s wrist as a bracelet. In the process, it becomes work-hardened and cannot easily be unbent again! A work-hardened metal like copper can be made soft again by annealing at a high temperature. The thermal motion of the atoms \u201cirons out\u201d the dislocations and makes large single crystals again. We have, so far, described only the so-called slip dislocation. There are many other kinds, one of which is the screw dislocation shown in Fig. 30\u201314. Such dislocations often play an important part in crystal growth. One of the great puzzles for a long time was how crystals can possibly grow. We have described how it is that each atom might, by repeated testing, determine whether it was better to be in the crystal or not. But that means that each atom must find a place of low energy. However, an atom put on a new surface is only bound by one or two bonds from below, and doesn\u2019t have the same energy it would have if it were placed in a corner, where it would have atoms on three sides. Suppose we imagine a growing crystal as a stack of blocks, as shown in Fig. 30\u201315. If we try a new block at, say, position A , it will have only one of the six neighbors it should ultimately get. With so many bonds lacking, its energy is not very low. It would be better off at position B , where it already has one-half of its quota of bonds. Crystals do indeed grow by attaching new atoms at places like B . What happens, though, when that line is finished? To start a new line, an atom must come to rest with only two sides attached, and that is again not very likely. Even if it did, what would happen when the layer was finished? How could a new layer get started? One answer is that the crystal prefers to grow at a dislocation, for instance around a screw dislocation like the one shown in Fig. 30\u201314. As blocks are added to this crystal, there is always some place where there are three available bonds. The crystal prefers, therefore, to grow with a dislocation built in. Such a spiral pattern of growth is shown in Fig. 30\u201316, which is a photograph of a single crystal of paraffin. We cannot, of course, see what goes on with the individual atoms in a crystal. Also, as you realize by now, there are many complicated phenomena that are not easy to treat quantitatively. Sir Lawrence Bragg and J. F. Nye have devised a scheme for making a model of a metallic crystal which shows in a striking way many of the phenomena that are believed to occur in a real metal. In the following pages we have reproduced their original article, which describes their method and shows some of the results they obtained with it. (The article is reprinted from the Proceedings of the Royal Society of London, Vol. 190, September 1947, pp. 474\u2013481\u2014with the permission of the authors and of the Royal Society.)1 1. The bubble model Models of crystal structure have been described from time to time in which the atoms are represented by small floating or suspended magnets, or by circular disks floating on a water surface and held together by the forces of capillary attraction. These models have certain disadvantages; for instance, in the case of floating objects in contact, frictional forces impede their free relative movement. A more serious disadvantage is that the number of components is limited, for a large number of components is required in order to approach the state of affairs in a real crystal. The present paper describes the behaviour of a model in which the atoms are represented by small bubbles from 2\u22c50 to 0\u22c51 mm. in diameter floating on the surface of a soap solution. These small bubbles are sufficiently persistent for experiments lasting an hour or more, they slide past each other without friction, and they can be produced in large numbers. Some of the illustrations in this paper were taken from assemblages of bubbles numbering 100,000 or more. The model most nearly represents the behaviour of a metal structure, because the bubbles are of one type only and are held together by a general capillary attraction, which represents the binding force of the free electrons in the metal. A brief description of the model has been given in the Journal of Scientific Instruments (Bragg 1942b). 2. Method of formation The bubbles are blown from a fine orifice, beneath the surface of a soap solution. We have had the best results with a solution the formula of which was given to us by Mr Green of the Royal Institution. 15\u22c52 c.c. of oleic acid (pure redistilled) is well shaken in 50 c.c. of distilled water. This is mixed thoroughly with 73 c.c. of 10% solution of tri-ethanolamine and the mixture made up to 200 c.c. To this is added 164 c.c. of pure glycerine. It is left to stand and the clear liquid is drawn off from below. In some experiments this was diluted in three times its volume of water to reduce viscosity. The orifice of the jet is about 5 mm. below the surface. A constant air pressure of 50 to 200 cm. of water is supplied by means of two Winchester flasks. Normally the bubbles are remarkably uniform in size. Occasionally they issue in an irregular manner, but this can be corrected by a change of jet or of pressure. Unwanted bubbles can easily be destroyed by playing a small flame over the surface. Figure 1 shows the apparatus. We have found it of advantage to blacken the bottom of the vessel, because details of structure, such as grain boundaries and dislocations, then show up more clearly. Figure 2, plate 8, shows a portion of a raft or two-dimensional crystal of bubbles. Its regularity can be judged by looking at the figure in a glancing direction. The size of the bubbles varies with the aperture, but does not appear to vary to any marked degree with the pressure or the depth of the orifice beneath the surface. The main effect of increasing the pressure is to increase the rate of issue of the bubbles. As an example, a thick-walled jet of 49 \u03bc bore with a pressure of 100 cm. produced bubbles of 1\u22c52 mm. in diameter. A thin-walled jet of 27 \u03bc diameter and a pressure of 180 cm. produced bubbles of 0\u22c56 mm. diameter. It is convenient to refer to bubbles of 2\u22c50 to 1\u22c50 mm. diameter as \u2018large\u2019 bubbles, those from 0\u22c58 to 0\u22c56 mm. diameter as \u2018medium\u2019 bubbles, and those from 0\u22c53 to 0\u22c51 mm. diameter as \u2018small\u2019 bubbles, since their behaviour varies with their size. With this apparatus we have not found it possible to reduce the size of the jet and so produce bubbles of smaller diameter than 0\u22c56 mm. As it was desired to experiment with very small bubbles, we had recourse to placing the soap solution in a rotating vessel and introducing a fine jet as nearly as possible parallel to a stream line. The bubbles are swept away as they form, and under steady conditions are reasonably uniform. They issue at a rate of one thousand or more per second, giving a high-pitched note. The soap solution mounts up in a steep wall around the perimeter of the vessel while it is rotating, but carries back most of the bubbles with it when rotation ceases. With this device, illustrated in figure 3, bubbles down to 0\u22c512 mm. in diameter can be obtained. As an example, an orifice 38 \u03bc across in a thin-walled jet, with a pressure of 190 cm. of water, and a speed of the fluid of 180 cm./sec. past the orifice, produced bubbles of 0\u22c514 mm. diameter. In this case a dish of diameter 9\u22c55 cm. and speed of 6 rev./sec. was used. Figure 4, plate 8, is an enlarged picture of these \u2018small\u2019 bubbles and shows their degree of regularity; the pattern is not as perfect with a rotating as with a stationary vessel, the rows being seen to be slightly irregular when viewed in a glancing direction. These two-dimensional crystals show structures which have been supposed to exist in metals, and simulate effects which have been observed, such as grain boundaries, dislocations and other types of fault, slip, recrystallization, annealing, and strains due to \u2018foreign\u2019 atoms. 3. Grain boundaries Figures 5a, 5b and 5c, plates 9 and 10, show typical grain boundaries for bubbles of 1\u22c587 , 0\u22c576 and 0\u22c530 mm. diameter respectively. The width of the disturbed area at the boundary, where the bubbles have an irregular distribution, is in general greater the smaller the bubbles. In figure 5a, which shows portions of several adjacent grains, bubbles at a boundary between two grains adhere definitely to one crystalline arrangement or the other. In figure 5c there is a marked \u2018Beilby layer\u2019 between the two grains. The small bubbles, as will be seen, have a greater rigidity than the large ones, and this appears to give rise to more irregularity at the interface. Separate grains show up distinctly when photographs of polycrystalline rafts such as figures 5a to 5c, plates 9 and 10, and figures 12a to 12e, plates 14 to 16, are viewed obliquely. With suitable lighting, the floating raft of bubbles itself when viewed obliquely resembles a polished and etched metal in a remarkable way. It often happens that some \u2018impurity atoms\u2019, or bubbles which are markedly larger or smaller than the average, are found in a polycrystalline raft, and when this is so a large proportion of them are situated at the grain boundaries. It would be incorrect to say that the irregular bubbles make their way to the boundaries; it is a defect of the model that no diffusion of bubbles through the structure can take place, mutual adjustments of neighbours alone being possible. It appears that the boundaries tend to readjust themselves by the growth of one crystal at the expense of another till they pass through the irregular atoms. 4. Dislocations When a single crystal or polycrystalline raft is compressed, extended, or otherwise deformed it exhibits a behaviour very similar to that which has been pictured for metals subjected to strain. Up to a certain limit the model is within its elastic range. Beyond that point it yields by slip along one of the three equally inclined directions of closely packed rows. Slip takes place by the bubbles in one row moving forward over those in the next row by an amount equal to the distance between neighbours. It is very interesting to watch this process taking place. The movement is not simultaneous along the whole row but begins at one end with the appearance of a \u2018dislocation\u2019, where there is locally one more bubble in the rows on one side of the slip line as compared with those on the other. This dislocation then runs along the slip line from one side of the crystal to the other, the final result being a slip by one \u2018inter-atomic\u2019 distance. Such a process has been invoked by Orowan, by Polanyi and by Taylor to explain the small forces required to produce plastic gliding in metal structures. The theory put forward by Taylor (1934) to explain the mechanism of plastic deformation of crystals considers the mutual action and equilibrium of such dislocations. The bubbles afford a very striking picture of what has been supposed to take place in the metal. Sometimes the dislocations run along quite slowly, taking a matter of seconds to cross a crystal; stationary dislocations also are to be seen in crystals which are not homogeneously strained. They appear as short black lines, and can be seen in the series of photographs, figures 12a to 12e, plates 14 to 16. When a polycrystalline raft is compressed, these dark lines are seen to be dashing about in all directions across the crystals. Figures 6a, 6b and 6c, plates 10 and 11, show examples of dislocations. In figure 6a, where the diameter of the bubbles is 1\u22c59 mm., the dislocation is very local, extending over about six bubbles. In figure 6b (diameter 0\u22c576 mm.) it extends over twelve bubbles, and in figure 6c (diameter 0\u22c530 mm.) its influence can be traced for a length of about fifty bubbles. The greater rigidity of the small bubbles leads to longer dislocations. The study of any mass of bubbles shows, however, that there is not a standard length of dislocation for each size. The length depends upon the nature of the strain in the crystal. A boundary between two crystals with corresponding axes at approximately 30 \u2218 (the maximum angle which can occur) may be regarded as a series of dislocations in alternate rows, and in this case the dislocations are very short. As the angle between the neighbouring crystals decreases, the dislocations occur at wider intervals and at the same time become longer, till one finally has single dislocations in a large body of perfect structure as shown in figures 6a, 6b and 6c. Figure 7, plate 11, shows three parallel dislocations. If we call them positive and negative (following Taylor) they are positive, negative, positive, reading from left to right. The strip between the last two has three bubbles in excess, as can be seen by looking along the rows in a horizontal direction. Figure 8, plate 12, shows a dislocation projecting from a grain boundary, an effect often observed. Figure 9, plate 12, shows a place where two bubbles take the place of one. This may be regarded as a limiting case of positive and negative dislocations on neighbouring rows, with the compressive sides of the dislocations facing each other. The contrary case would lead to a hole in the structure, one bubble being missing at the point where the dislocations met. 5. Other types of fault Figure 10, plate 12, shows a narrow strip between two crystals of parallel orientation, the strip being crossed by a number of fault lines where the bubbles are not in close packing. It is in such places as these that recrystallization may be expected. The boundaries approach and the strip is absorbed into a wider area of perfect crystal. Figures 11a to 11g, plates 13 and 14 are examples of arrangements which frequently appear in places where there is a local deficiency of bubbles. While a dislocation is seen as a dark stripe in a general view, these structures show up in the shape of the letter V or as triangles. A typical V structure is seen in figure 11a. When the model is being distorted, a V structure is formed by two dislocations meeting at an inclination of 60 \u2218 ; it is destroyed by the dislocations continuing along their paths. Figure 11b shows a small triangle, which also embodies a dislocation, for it will be noticed that the rows below the fault have one more bubble than these below. If a mild amount of \u2018thermal movement\u2019 is imposed by gentle agitation of one side of the crystal, such faulty places disappear and a perfect structure is formed. Here and there in the crystals there is a blank space where a bubble is missing, showing as a black dot in a general view. Examples occur in figure 11g. Such a gap cannot be closed by a local readjustment, since filling the hole causes another to appear. Such holes both appear and disappear when the crystal is \u2018cold-worked\u2019. These structures in the model suggest that similar local faults may exist in an actual metal. They may play a part in processes such as diffusion or the order-disorder change by reducing energy barriers in their neighbourhood, and act as nuclei for crystallization in an allotropic change. 6. Recrystallization and annealing Figures 12a to 12e, plates 14 to 16, show the same raft of bubbles at successive times. A raft covering the surface of the solution was given a vigorous stirring with a glass rake, and then left to adjust itself. Figure 12a shows its aspect about 1 sec. after stirring has ceased. The raft is broken into a number of small \u2018crystallites\u2019; these are in a high state of non-homogeneous strain as is shown by the numerous dislocations and other faults. The following photograph (figure 12b) shows the same raft 32 sec. later. The small grains have coalesced to form larger grains, and much of the strain has disappeared in the process. Recrystallization takes place right through the series, the last three photographs of which show the appearance of the raft 2 , 14 and 25 min. after the initial stirring. It is not possible to follow the rearrangement for much longer times, because the bubbles shrink after long standing, apparently due to the diffusion of air through their walls, and they also become thin and tend to burst. No agitation was given to the model during this process. An ever slower process of rearrangement goes on, the movement of the bubbles in one part of the raft setting up strains which activate a rearrangement in a neighbouring part, and that in its turn still another. A number of interesting points are to be seen in this series. Note the three small grains at the points indicated by the co-ordinates AA , BB , CC . A persists, though changed in form, throughout the whole series. B is still present after 14 min., but has disappeared in 25 min., leaving behind it four dislocations marking internal strain in the grain. Grain C shrinks and finally disappears in figure 12d, leaving a hole and a V which has disappeared in figure 12e. At the same time the ill-defined boundary in figure 12d at DD has become a definite one in figure 12e. Note also the straightening out of the grain boundary in the neighbourhood of EE in figures 12b to 12e. Dislocations of various lengths can be seen, marking all stages between a slight warping of the structure and a definite boundary. Holes where bubbles are missing show up as black dots. Some of these holes are formed or filled up by movements of dislocations, but others represent places where a bubble has burst. Many examples of V\u2019s and some of triangles can be seen. Other interesting points will be apparent from a study of this series of photographs. Figures 13a, 13b and 13c, plate 17, show a portion of a raft 1 sec., 4 sec. and 4 min. after the stirring process, and is interesting as showing two successive stages in the relaxation towards a more perfect arrangement. The changes show up well when one looks in a glancing direction across the page. The arrangement is very broken in figure 13a. In figure 13b the bubbles have grouped themselves in rows, but the curvature of these rows indicates a high degree of internal strain. In figure 13c this strain has been relieved by the formation of a new boundary at A \u2013 A , the rows on either side now being straight. It would appear that the energy of this strained crystal is greater than that of the intercrystalline boundary. We are indebted to Messrs Kodak for the photographs of figure 13, which were taken when the cinematograph film referred to below was produced. 7. Effect of impurity atom Figure 14, plate 18, shows the widespread effect of a bubble which is of the wrong size. If this figure is compared with the perfect rafts shown in figures 2 and 4, plate 8, it will be seen that three bubbles, one larger and two smaller than normal, disturb the regularity of the rows over the whole of the figure. As has been mentioned above, bubbles of the wrong size are generally found in the grain boundaries, where holes of irregular size occur which can accommodate them. 8. Mechanical properties of the two-dimensional model The mechanical properties of a two-dimensional perfect raft have been described in the paper referred to above (Bragg 1942b). The raft lies between two parallel springs dipping horizontally in the surface of the soap solution. The pitch of the springs is adjusted to fit the spacing of the rows of bubbles, which then adhere firmly to them. One spring can be translated parallel to itself by a micrometer screw, and the other is supported by two thin vertical glass fibres. The shearing stress can be measured by noting the deflexion of the glass fibres. When subjected to a shearing strain, the raft obeys Hooke\u2019s law of elasticity up to the point where the elastic limit is reached. It then slips along some intermediate row by an amount equal to the width of one bubble. The elastic shear and slip can be repeated several times. The elastic limit is approximately reached when one side of the raft has been sheared by an amount equal to a bubble width past the other side. This feature supports the basic assumption made by one of us in the calculation of the elastic limit of a metal (Bragg 1942a), in which it is supposed that each crystallite in a cold-worked metal only yields when the strain in it has reached such a value that energy is released by the slip. A calculation has been made by M. M. Nicolson of the forces between the bubbles, and will be published shortly. It shows two interesting points. The curve for the variation of potential energy with distance between centres is very similar to those which have been plotted for atoms. It has a minimum for a distance between centres slightly less than a free bubble diameter, and rises sharply for smaller distances. Further, the rise is extremely sharp for bubbles of 0\u22c51 mm. diameter but much less so for bubbles of 1 mm. diameter, thus confirming the impression given by the model that the small bubbles behave as if they were much more rigid than the large ones. 9. Three-dimensional assemblages If the bubbles are allowed to accumulate in multiple layers on the surface, they form a mass of three-dimensional \u2018crystals\u2019 with one of the arrangements of closest packing. Figure 15, plate 18, shows an oblique view of such a mass; its resemblance to a polished and etched metal surface is noticeable. In figure 16, plate 20, a similar mass is seen viewed normally. Parts of the structure are definitely in cubic closest packing, the outer surface being the (111) face or (100) face. Figure 17a, plate 19, shows a (111) face. The outlines of the three bubbles on which each upper bubble rests can be clearly seen, and the next layer of these bubbles is faintly visible in a position not beneath the uppermost layer, showing that the packing of the (111) planes has the well-known cubic succession. Figure 17b, plate 19, shows a (100) face with each bubble resting on four others. The cubic axes are of course inclined at 45 \u2218 to the close-packed rows of the surface layer. Figure 17c, plate 19, shows a twin in the cubic structure across the face (111) . The uppermost faces are (111) and (100) , and they make a small angle with each other, though this is not apparent in the figure; it shows up in an oblique view. Figure 17d, plate 19, appears to show both the cubic and hexagonal succession of closely packed planes, but it is difficult to verify whether the left-hand side follows the true hexagonal close-packed structure because it is not certain that the assemblage had a depth of more than two layers at this point. Many instances of twins, and of intercrystalline boundaries, can be seen in figure 16, plate 20. Figure 18, plate 21, shows several dislocations in a three-dimensional structure subjected to a bending strain. 10. Demonstration of the model With the co-operation of Messrs Kodak, a 16 mm. cinematograph film has been made of the movements of the dislocations and grain boundaries when single crystal and polycrystalline rafts are sheared, compressed, or extended. Moreover, if the soap solution is placed in a glass vessel with a flat bottom, the model lends itself to projection on a large scale by transmitted light. Since a certain depth is required for producing the bubbles, and the solution is rather opaque, it is desirable to make the projection through a glass block resting on the bottom of the vessel and just submerged beneath the surface. In conclusion, we wish to express our thanks to Mr C. E. Harrold, of King\u2019s College, Cambridge, who made for us some of the pipettes which were used to produce the bubbles."
    },
    {
        "input": "The Origin of the Refractive Index",
        "output": "We have said before that light goes slower in water than in air, and slower, slightly, in air than in vacuum. This effect is described by the index of refraction n . Now we would like to understand how such a slower velocity could come about. In particular, we should try to see what the relation is to some physical assumptions, or statements, we made earlier, which were the following: That the total electric field in any physical circumstance can always be represented by the sum of the fields from all the charges in the universe. That the field from a single charge is given by its acceleration evaluated with a retardation at the speed c , always (for the radiation field). But, for a piece of glass, you might think: \u201cOh, no, you should modify all this. You should say it is retarded at the speed c/n .\u201d That, however, is not right, and we have to understand why it is not. It is approximately true that light or any electrical wave does appear to travel at the speed c/n through a material whose index of refraction is n , but the fields are still produced by the motions of all the charges\u2014including the charges moving in the material\u2014and with these basic contributions of the field travelling at the ultimate velocity c . Our problem is to understand how the apparently slower velocity comes about. We shall try to understand the effect in a very simple case. A source which we shall call \u201cthe external source\u201d is placed a large distance away from a thin plate of transparent material, say glass. We inquire about the field at a large distance on the opposite side of the plate. The situation is illustrated by the diagram of Fig. 31\u20131, where S and P are imagined to be very far away from the plate. According to the principles we have stated earlier, an electric field anywhere that is far from all moving charges is the (vector) sum of the fields produced by the external source (at S ) and the fields produced by each of the charges in the plate of glass, every one with its proper retardation at the velocity c . Remember that the contribution of each charge is not changed by the presence of the other charges. These are our basic principles. The field at P can be written thus: E= \u2211 all charges Eeach charge or E=Es+ \u2211 all other charges Eeach charge, where Es is the field due to the source alone and would be precisely the field at P if there were no material present. We expect the field at P to be different from Es if there are any other moving charges. Why should there be charges moving in the glass? We know that all material consists of atoms which contain electrons. When the electric field of the source acts on these atoms it drives the electrons up and down, because it exerts a force on the electrons. And moving electrons generate a field\u2014they constitute new radiators. These new radiators are related to the source S , because they are driven by the field of the source. The total field is not just the field of the source S , but it is modified by the additional contribution from the other moving charges. This means that the field is not the same as the one which was there before the glass was there, but is modified, and it turns out that it is modified in such a way that the field inside the glass appears to be moving at a different speed. That is the idea which we would like to work out quantitatively. Now this is, in the exact case, pretty complicated, because although we have said that all the other moving charges are driven by the source field, that is not quite true. If we think of a particular charge, it feels not only the source, but like anything else in the world, it feels all of the charges that are moving. It feels, in particular, the charges that are moving somewhere else in the glass. So the total field which is acting on a particular charge is a combination of the fields from the other charges, whose motions depend on what this particular charge is doing! You can see that it would take a complicated set of equations to get the complete and exact formula. It is so complicated that we postpone this problem until next year. Instead we shall work out a very simple case in order to understand all the physical principles very clearly. We take a circumstance in which the effects from the other atoms are very small relative to the effects from the source. In other words, we take a material in which the total field is not modified very much by the motion of the other charges. That corresponds to a material in which the index of refraction is very close to 1 , which will happen, for example, if the density of the atoms is very low. Our calculation will be valid for any case in which the index is for any reason very close to 1 . In this way we shall avoid the complications of the most general, complete solution. Incidentally, you should notice that there is another effect caused by the motion of the charges in the plate. These charges will also radiate waves back toward the source S . This backward-going field is the light we see reflected from the surfaces of transparent materials. It does not come from just the surface. The backward radiation comes from everywhere in the interior, but it turns out that the total effect is equivalent to a reflection from the surfaces. These reflection effects are beyond our approximation at the moment because we shall be limited to a calculation for a material with an index so close to 1 that very little light is reflected. Before we proceed with our study of how the index of refraction comes about, we should understand that all that is required to understand refraction is to understand why the apparent wave velocity is different in different materials. The bending of light rays comes about just because the effective speed of the waves is different in the materials. To remind you how that comes about we have drawn in Fig. 31\u20132 several successive crests of an electric wave which arrives from a vacuum onto the surface of a block of glass. The arrow perpendicular to the wave crests indicates the direction of travel of the wave. Now all oscillations in the wave must have the same frequency. (We have seen that driven oscillations have the same frequency as the driving source.) This means, also, that the wave crests for the waves on both sides of the surface must have the same spacing along the surface because they must travel together, so that a charge sitting at the boundary will feel only one frequency. The shortest distance between crests of the wave, however, is the wavelength which is the velocity divided by the frequency. On the vacuum side it is \u03bb0=2\u03c0c/\u03c9 , and on the other side it is \u03bb=2\u03c0v/\u03c9 or 2\u03c0c/\u03c9n , if v=c/n is the velocity of the wave. From the figure we can see that the only way for the waves to \u201cfit\u201d properly at the boundary is for the waves in the material to be travelling at a different angle with respect to the surface. From the geometry of the figure you can see that for a \u201cfit\u201d we must have \u03bb0/sin\u03b80=\u03bb/sin\u03b8 , or sin\u03b80/sin\u03b8=n , which is Snell\u2019s law. We shall, for the rest of our discussion, consider only why light has an effective speed of c/n in material of index n , and no longer worry, in this chapter, about the bending of the light direction. We go back now to the situation shown in Fig. 31\u20131. We see that what we have to do is to calculate the field produced at P by all the oscillating charges in the glass plate. We shall call this part of the field E a , and it is just the sum written as the second term in Eq. (31.2). When we add it to the term E s , due to the source, we will have the total field at P . This is probably the most complicated thing that we are going to do this year, but it is complicated only in that there are many pieces that have to be put together; each piece, however, is very simple. Unlike other derivations where we say, \u201cForget the derivation, just look at the answer!,\u201d in this case we do not need the answer so much as the derivation. In other words, the thing to understand now is the physical machinery for the production of the index. To see where we are going, let us first find out what the \u201ccorrection field\u201d E a would have to be if the total field at P is going to look like radiation from the source that is slowed down while passing through the thin plate. If the plate had no effect on it, the field of a wave travelling to the right (along the z -axis) would be E s = E 0 cos\u03c9(t\u2212z/c) (31.3) or, using the exponential notation, E s = E 0 e i\u03c9(t\u2212z/c) . (31.4) Now what would happen if the wave travelled more slowly in going through the plate? Let us call the thickness of the plate \u0394z . If the plate were not there the wave would travel the distance \u0394z in the time \u0394z/c . But if it appears to travel at the speed c/n then it should take the longer time n\u0394z/c or the additional time \u0394t=(n\u22121)\u0394z/c . After that it would continue to travel at the speed c again. We can take into account the extra delay in getting through the plate by replacing t in Eq. (31.4) by (t\u2212\u0394t) or by [t\u2212(n\u22121)\u0394z/c] . So the wave after insertion of the plate should be written E after plate = E 0 e i\u03c9[t\u2212(n\u22121)\u0394z/c\u2212z/c] . (31.5) We can also write this equation as E after plate = e \u2212i\u03c9(n\u22121)\u0394z/c E 0 e i\u03c9(t\u2212z/c) , (31.6) which says that the wave after the plate is obtained from the wave which could exist without the plate, i.e., from E s , by multiplying by the factor e \u2212i\u03c9(n\u22121)\u0394z/c . Now we know that multiplying an oscillating function like e i\u03c9t by a factor e i\u03b8 just says that we change the phase of the oscillation by the angle \u03b8 , which is, of course, what the extra delay in passing through the thickness \u0394z has done. It has retarded the phase by the amount \u03c9(n\u22121)\u0394z/c (retarded, because of the minus sign in the exponent). We have said earlier that the plate should add a field E a to the original field E s = E 0 e i\u03c9(t\u2212z/c) , but we have found instead that the effect of the plate is to multiply the field by a factor which shifts its phase. However, that is really all right because we can get the same result by adding a suitable complex number. It is particularly easy to find the right number to add in the case that \u0394z is small, for you will remember that if x is a small number then e x is nearly equal to (1+x) . We can write, therefore, e \u2212i\u03c9(n\u22121)\u0394z/c \u22481\u2212i\u03c9(n\u22121)\u0394z/c. (31.7) Using this approximation in Eq. (31.6), we have E after plate = E 0 e i\u03c9(t\u2212z/c) \ue152 \ue153 \ue151\ue150 \ue154 \ue154 \ue154 \ue154 \ue154 \ue154 \ue154 \ue154 E s \u2212 i\u03c9(n\u22121)\u0394z c E 0 e i\u03c9(t\u2212z/c) \ue152 \ue153 \ue151\ue150 \ue154 \ue154 \ue154 \ue154 \ue154 \ue154 \ue154 \ue154 \ue154 \ue154 \ue154 \ue154 \ue154 \ue154 \ue154 \ue154 \ue154 \ue154 \ue154 \ue154 \ue154 \ue154 \ue154 \ue154 \ue154 \ue154 E a . (31.8) The first term is just the field from the source, and the second term must just be equal to E a , the field produced to the right of the plate by the oscillating charges of the plate\u2014expressed here in terms of the index of refraction n , and depending, of course, on the strength of the wave from the source. What we have been doing is easily visualized if we look at the complex number diagram in Fig. 31\u20133. We first draw the number E s (we chose some values for z and t so that E s comes out horizontal, but this is not necessary). The delay due to slowing down in the plate would delay the phase of this number, that is, it would rotate E s through a negative angle. But this is equivalent to adding the small vector E a at roughly right angles to E s . But that is just what the factor \u2212i means in the second term of Eq. (31.8). It says that if E s is real, then E a is negative imaginary or that, in general, E s and E a make a right angle. We now have to ask: Is the field E a obtained in the second term of Eq. (31.8) the kind we would expect from oscillating charges in the plate? If we can show that it is, we will then have calculated what the index n should be! [Since n is the only nonfundamental number in Eq. (31.8).] We turn now to calculating what field E a the charges in the material will produce. (To help you keep track of the many symbols we have used up to now, and will be using in the rest of our calculation, we have put them all together in Table 31\u20131.) If the source S (of Fig. 31\u20131) is far off to the left, then the field E s will have the same phase everywhere on the plate, so we can write that in the neighborhood of the plate E s = E 0 e i\u03c9(t\u2212z/c) . (31.9) Right at the plate, where z=0 , we will have E s = E 0 e i\u03c9t (at the plate). (31.10) Each of the electrons in the atoms of the plate will feel this electric field and will be driven up and down (we assume the direction of E 0 is vertical) by the electric force qE . To find what motion we expect for the electrons, we will assume that the atoms are little oscillators, that is, that the electrons are fastened elastically to the atoms, which means that if a force is applied to an electron its displacement from its normal position will be proportional to the force. You may think that this is a funny model of an atom if you have heard about electrons whirling around in orbits. But that is just an oversimplified picture. The correct picture of an atom, which is given by the theory of wave mechanics, says that, so far as problems involving light are concerned, the electrons behave as though they were held by springs. So we shall suppose that the electrons have a linear restoring force which, together with their mass m , makes them behave like little oscillators, with a resonant frequency \u03c9 0 . We have already studied such oscillators, and we know that the equation of their motion is written this way: m( d 2 x d t 2 + \u03c9 2 0 x)=F, (31.11) where F is the driving force. For our problem, the driving force comes from the electric field of the wave from the source, so we should use F= q e E s = q e E 0 e i\u03c9t , (31.12) where q e is the electric charge on the electron and for E s we use the expression E s = E 0 e i\u03c9t from (31.10). Our equation of motion for the electron is then m( d 2 x d t 2 + \u03c9 2 0 x)= q e E 0 e i\u03c9t . (31.13) We have solved this equation before, and we know that the solution is x= x 0 e i\u03c9t , (31.14) where, by substituting in (31.13), we find that x 0 = q e E 0 m( \u03c9 2 0 \u2212 \u03c9 2 ) , (31.15) so that x= q e E 0 m( \u03c9 2 0 \u2212 \u03c9 2 ) e i\u03c9t . (31.16) We have what we needed to know\u2014the motion of the electrons in the plate. And it is the same for every electron, except that the mean position (the \u201czero\u201d of the motion) is, of course, different for each electron. Now we are ready to find the field E a that these atoms produce at the point P , because we have already worked out (at the end of Chapter 30) what field is produced by a sheet of charges that all move together. Referring back to Eq. (30.19), we see that the field E a at P is just a negative constant times the velocity of the charges retarded in time by the amount z/c . Differentiating x in Eq. (31.16) to get the velocity, and sticking in the retardation [or just putting x 0 from (31.15) into (30.18)] yields E a =\u2212 \u03b7 q e 2 \u03f5 0 c [i\u03c9 q e E 0 m( \u03c9 2 0 \u2212 \u03c9 2 ) e i\u03c9(t\u2212z/c) ]. (31.17) Just as we expected, the driven motion of the electrons produced an extra wave which travels to the right (that is what the factor e i\u03c9(t\u2212z/c) says), and the amplitude of this wave is proportional to the number of atoms per unit area in the plate (the factor \u03b7 ) and also proportional to the strength of the source field (the factor E 0 ). Then there are some factors which depend on the atomic properties ( q e , m , and \u03c9 0 ), as we should expect. The most important thing, however, is that this formula (31.17) for E a looks very much like the expression for E a that we got in Eq. (31.8) by saying that the original wave was delayed in passing through a material with an index of refraction n . The two expressions will, in fact, be identical if (n\u22121)\u0394z= \u03b7 q 2 e 2 \u03f5 0 m( \u03c9 2 0 \u2212 \u03c9 2 ) . (31.18) Notice that both sides are proportional to \u0394z , since \u03b7 , which is the number of atoms per unit area, is equal to N\u0394z , where N is the number of atoms per unit volume of the plate. Substituting N\u0394z for \u03b7 and cancelling the \u0394z , we get our main result, a formula for the index of refraction in terms of the properties of the atoms of the material\u2014and of the frequency of the light: n=1+ N q 2 e 2 \u03f5 0 m( \u03c9 2 0 \u2212 \u03c9 2 ) . (31.19) This equation gives the \u201cexplanation\u201d of the index of refraction that we wished to obtain. Notice that in the above process we have obtained something very interesting. For we have not only a number for the index of refraction which can be computed from the basic atomic quantities, but we have also learned how the index of refraction should vary with the frequency \u03c9 of the light. This is something we would never understand from the simple statement that \u201clight travels slower in a transparent material.\u201d We still have the problem, of course, of knowing how many atoms per unit volume there are, and what is their natural frequency \u03c9 0 . We do not know this just yet, because it is different for every different material, and we cannot get a general theory of that now. Formulation of a general theory of the properties of different substances\u2014their natural frequencies, and so on\u2014is possible only with quantum atomic mechanics. Also, different materials have different properties and different indexes, so we cannot expect, anyway, to get a general formula for the index which will apply to all substances. However, we shall discuss the formula we have obtained, in various possible circumstances. First of all, for most ordinary gases (for instance, for air, most colorless gases, hydrogen, helium, and so on) the natural frequencies of the electron oscillators correspond to ultraviolet light. These frequencies are higher than the frequencies of visible light, that is, \u03c9 0 is much larger than \u03c9 of visible light, and to a first approximation, we can disregard \u03c9 2 in comparison with \u03c9 2 0 . Then we find that the index is nearly constant. So for a gas, the index is nearly constant. This is also true for most other transparent substances, like glass. If we look at our expression a little more closely, however, we notice that as \u03c9 rises, taking a little bit more away from the denominator, the index also rises. So n rises slowly with frequency. The index is higher for blue light than for red light. That is the reason why a prism bends the light more in the blue than in the red. The phenomenon that the index depends upon the frequency is called the phenomenon of dispersion, because it is the basis of the fact that light is \u201cdispersed\u201d by a prism into a spectrum. The equation for the index of refraction as a function of frequency is called a dispersion equation. So we have obtained a dispersion equation. (In the past few years \u201cdispersion equations\u201d have been finding a new use in the theory of elementary particles.) Our dispersion equation suggests other interesting effects. If we have a natural frequency \u03c9 0 which lies in the visible region, or if we measure the index of refraction of a material like glass in the ultraviolet, where \u03c9 gets near \u03c9 0 , we see that at frequencies very close to the natural frequency the index can get enormously large, because the denominator can go to zero. Next, suppose that \u03c9 is greater than \u03c9 0 . This would occur, for example, if we take a material like glass, say, and shine x-ray radiation on it. In fact, since many materials which are opaque to visible light, like graphite for instance, are transparent to x-rays, we can also talk about the index of refraction of carbon for x-rays. All the natural frequencies of the carbon atoms would be much lower than the frequency we are using in the x-rays, since x-ray radiation has a very high frequency. The index of refraction is that given by our dispersion equation if we set \u03c9 0 equal to zero (we neglect \u03c9 2 0 in comparison with \u03c9 2 ). A similar situation would occur if we beam radiowaves (or light) on a gas of free electrons. In the upper atmosphere electrons are liberated from their atoms by ultraviolet light from the sun and they sit up there as free electrons. For free electrons \u03c9 0 =0 (there is no elastic restoring force). Setting \u03c9 0 =0 in our dispersion equation yields the correct formula for the index of refraction for radiowaves in the stratosphere, where N is now to represent the density of free electrons (number per unit volume) in the stratosphere. But let us look again at the equation, if we beam x-rays on matter, or radiowaves (or any electric waves) on free electrons the term ( \u03c9 2 0 \u2212 \u03c9 2 ) becomes negative, and we obtain the result that n is less than one. That means that the effective speed of the waves in the substance is faster than c ! Can that be correct? It is correct. In spite of the fact that it is said that you cannot send signals any faster than the speed of light, it is nevertheless true that the index of refraction of materials at a particular frequency can be either greater or less than 1 . This just means that the phase shift which is produced by the scattered light can be either positive or negative. It can be shown, however, that the speed at which you can send a signal is not determined by the index at one frequency, but depends on what the index is at many frequencies. What the index tells us is the speed at which the nodes (or crests) of the wave travel. The node of a wave is not a signal by itself. In a perfect wave, which has no modulations of any kind, i.e., which is a steady oscillation, you cannot really say when it \u201cstarts,\u201d so you cannot use it for a timing signal. In order to send a signal you have to change the wave somehow, make a notch in it, make it a little bit fatter or thinner. That means that you have to have more than one frequency in the wave, and it can be shown that the speed at which signals travel is not dependent upon the index alone, but upon the way that the index changes with the frequency. This subject we must also delay (until Chapter 48). Then we will calculate for you the actual speed of signals through such a piece of glass, and you will see that it will not be faster than the speed of light, although the nodes, which are mathematical points, do travel faster than the speed of light. Just to give a slight hint as to how that happens, you will note that the real difficulty has to do with the fact that the responses of the charges are opposite to the field, i.e., the sign has gotten reversed. Thus in our expression for x (Eq. 31.16) the displacement of the charge is in the direction opposite to the driving field, because ( \u03c9 2 0 \u2212 \u03c9 2 ) is negative for small \u03c9 0 . The formula says that when the electric field is pulling in one direction, the charge is moving in the opposite direction. How does the charge happen to be going in the opposite direction? It certainly does not start off in the opposite direction when the field is first turned on. When the motion first starts there is a transient, which settles down after awhile, and only then is the phase of the oscillation of the charge opposite to the driving field. And it is then that the phase of the transmitted field can appear to be advanced with respect to the source wave. It is this advance in phase which is meant when we say that the \u201cphase velocity\u201d or velocity of the nodes is greater than c . In Fig. 31\u20134 we give a schematic idea of how the waves might look for a case where the wave is suddenly turned on (to make a signal). You will see from the diagram that the signal (i.e., the start of the wave) is not earlier for the wave which ends up with an advance in phase. Let us now look again at our dispersion equation. We should remark that our analysis of the refractive index gives a result that is somewhat simpler than you would actually find in nature. To be completely accurate we must add some refinements. First, we should expect that our model of the atomic oscillator should have some damping force (otherwise once started it would oscillate forever, and we do not expect that to happen). We have worked out before (Eq. 23.8) the motion of a damped oscillator and the result is that the denominator in Eq. (31.16), and therefore in (31.19), is changed from ( \u03c9 2 0 \u2212 \u03c9 2 ) to ( \u03c9 2 0 \u2212 \u03c9 2 +i\u03b3\u03c9) , where \u03b3 is the damping coefficient. We need a second modification to take into account the fact that there are several resonant frequencies for a particular kind of atom. It is easy to fix up our dispersion equation by imagining that there are several different kinds of oscillators, but that each oscillator acts separately, and so we simply add the contributions of all the oscillators. Let us say that there are N k electrons per unit of volume, whose natural frequency is \u03c9 k and whose damping factor is \u03b3 k . We would then have for our dispersion equation n=1+ q 2 e 2 \u03f5 0 m \u2211 k N k \u03c9 2 k \u2212 \u03c9 2 +i \u03b3 k \u03c9 . (31.20) We have, finally, a complete expression which describes the index of refraction that is observed for many substances.1 The real part of the index described by this formula varies with frequency roughly like the curve shown in Fig. 31\u20135(a). You will note that so long as \u03c9 is not too close to one of the resonant frequencies, the slope of the curve is positive. Such a positive slope is called \u201cnormal\u201d dispersion (because it is clearly the most common occurrence). Very near the resonant frequencies, however, there is a small range of \u03c9 \u2019s for which the slope is negative. Such a negative slope is often referred to as \u201canomalous\u201d (meaning abnormal) dispersion, because it seemed unusual when it was first observed, long before anyone even knew there were such things as electrons. From our point of view both slopes are quite \u201cnormal\u201d! Perhaps you have noticed something a little strange about the last form (Eq. 31.20) we obtained for our dispersion equation. Because of the term i\u03b3 we put in to take account of damping, the index of refraction is now a complex number! What does that mean? By working out what the real and imaginary parts of n are we could write n= n \u2032 \u2212i n \u2032\u2032 , (31.21) where n \u2032 and n \u2032\u2032 are real numbers. (We use the minus sign in front of the i n \u2032\u2032 because then n \u2032\u2032 will turn out to be a positive number, as you can show for yourself.) We can see what such a complex index means when there is only one resonant frequency by going back to Eq. (31.6), which is the equation of the wave after it goes through a plate of material with an index n . If we put our complex n into this equation, and do some rearranging, we get E after plate = e \u2212\u03c9 n \u2032\u2032 \u0394z/c \ue152 \ue153 \ue151\ue150 \ue154 \ue154 \ue154 \ue154 \ue154 \ue154 A e \u2212i\u03c9( n \u2032 \u22121)\u0394z/c E 0 e i\u03c9(t\u2212z/c) \ue152 \ue153 \ue151\ue150 \ue154 \ue154 \ue154 \ue154 \ue154 \ue154 \ue154 \ue154 \ue154 \ue154 \ue154 \ue154 \ue154 \ue154 \ue154 \ue154 \ue154 \ue154 \ue154 \ue154 \ue154 \ue154 \ue154 \ue154 B . (31.22) The last factors, marked B in Eq. (31.22), are just the form we had before, and again describe a wave whose phase has been delayed by the angle \u03c9( n \u2032 \u22121)\u0394z/c in traversing the material. The first term (A) is new and is an exponential factor with a real exponent, because there were two i \u2019s that cancelled. Also, the exponent is negative, so the factor is a real number less than one. It describes a decrease in the magnitude of the field and, as we should expect, by an amount which is more the larger \u0394z is. As the wave goes through the material, it is weakened. The material is \u201cabsorbing\u201d part of the wave. The wave comes out the other side with less energy. We should not be surprised at this, because the damping we put in for the oscillators is indeed a friction force and must be expected to cause a loss of energy. We see that the imaginary part n \u2032\u2032 of a complex index of refraction represents an absorption (or \u201cattenuation\u201d) of the wave. In fact, n \u2032\u2032 is sometimes referred to as the \u201cabsorption index.\u201d We may also point out that an imaginary part to the index n corresponds to bending the arrow E a in Fig. 31\u20133 toward the origin. It is clear why the transmitted field is then decreased. Normally, for instance as in glass, the absorption of light is very small. This is to be expected from our Eq. (31.20), because the imaginary part of the denominator, i \u03b3 k \u03c9 , is much smaller than the term ( \u03c9 2 k \u2212 \u03c9 2 ) . But if the light frequency \u03c9 is very close to \u03c9 k then the resonance term ( \u03c9 2 k \u2212 \u03c9 2 ) can become small compared with i \u03b3 k \u03c9 and the index becomes almost completely imaginary, as shown in Fig. 31\u20135(b). The absorption of the light becomes the dominant effect. It is just this effect that gives the dark lines in the spectrum of light which we receive from the sun. The light from the solar surface has passed through the sun\u2019s atmosphere (as well as the earth\u2019s), and the light has been strongly absorbed at the resonant frequencies of the atoms in the solar atmosphere. The observation of such spectral lines in the sunlight allows us to tell the resonant frequencies of the atoms and hence the chemical composition of the sun\u2019s atmosphere. The same kind of observations tell us about the materials in the stars. From such measurements we know that the chemical elements in the sun and in the stars are the same as those we find on the earth. We have seen that the imaginary part of the index means absorption. We shall now use this knowledge to find out how much energy is carried by a light wave. We have given earlier an argument that the energy carried by light is proportional to E 2 \u00af \u00af \u00af \u00af \u00af \u00af , the time average of the square of the electric field in the wave. The decrease in E due to absorption must mean a loss of energy, which would go into some friction of the electrons and, we might guess, would end up as heat in the material. If we consider the light arriving on a unit area, say one square centimeter, of our plate in Fig. 31\u20131, then we can write the following energy equation (if we assume that energy is conserved, as we do!): Energy in per sec= energy out per sec+work done per sec. (31.23) For the first term we can write \u03b1 E 2 s \u00af \u00af \u00af \u00af \u00af \u00af , where \u03b1 is the as yet unknown constant of proportionality which relates the average value of E 2 to the energy being carried. For the second term we must include the part from the radiating atoms of the material, so we should use \u03b1 ( E s + E a ) 2 \u00af \u00af \u00af \u00af \u00af \u00af \u00af \u00af \u00af \u00af \u00af \u00af \u00af \u00af \u00af \u00af \u00af \u00af \u00af \u00af \u00af \u00af \u00af \u00af , or (evaluating the square) \u03b1( E 2 s \u00af \u00af \u00af \u00af \u00af \u00af +2 E s E a \u00af \u00af \u00af \u00af \u00af \u00af \u00af \u00af \u00af \u00af \u00af \u00af + E 2 a \u00af \u00af \u00af \u00af \u00af \u00af ) . All of our calculations have been made for a thin layer of material whose index is not too far from 1 , so that E a would always be much less than E s (just to make the calculations easier). In keeping with our approximations, we should, therefore, leave out the term E 2 a \u00af \u00af \u00af \u00af \u00af \u00af , because it is much smaller than E s E a \u00af \u00af \u00af \u00af \u00af \u00af \u00af \u00af \u00af \u00af \u00af \u00af . You may say: \u201cThen you should leave out E s E a \u00af \u00af \u00af \u00af \u00af \u00af \u00af \u00af \u00af \u00af \u00af \u00af also, because it is much smaller than E 2 s \u00af \u00af \u00af \u00af \u00af \u00af .\u201d It is true that E s E a \u00af \u00af \u00af \u00af \u00af \u00af \u00af \u00af \u00af \u00af \u00af \u00af is much smaller than E 2 s \u00af \u00af \u00af \u00af \u00af \u00af , but we must keep E s E a \u00af \u00af \u00af \u00af \u00af \u00af \u00af \u00af \u00af \u00af \u00af \u00af or our approximation will be the one that would apply if we neglected the presence of the material completely! One way of checking that our calculations are consistent is to see that we always keep terms which are proportional to N\u0394z , the area density of atoms in the material, but we leave out terms which are proportional to (N\u0394z ) 2 or any higher power of N\u0394z . Ours is what should be called a \u201clow-density approximation.\u201d In the same spirit, we might remark that our energy equation has neglected the energy in the reflected wave. But that is OK because this term, too, is proportional to (N\u0394z ) 2 , since the amplitude of the reflected wave is proportional to N\u0394z . For the last term in Eq. (31.23) we wish to compute the rate at which the incoming wave is doing work on the electrons. We know that work is force times distance, so the rate of doing work (also called power) is the force times the velocity. It is really F\u22c5v , but we do not need to worry about the dot product when the velocity and force are along the same direction as they are here (except for a possible minus sign). So for each atom we take q e E s v \u00af \u00af \u00af \u00af \u00af \u00af \u00af \u00af \u00af \u00af \u00af \u00af for the average rate of doing work. Since there are N\u0394z atoms in a unit area, the last term in Eq. (31.23) should be N\u0394z q e E s v \u00af \u00af \u00af \u00af \u00af \u00af \u00af \u00af . Our energy equation now looks like \u03b1 E 2 s \u00af \u00af \u00af \u00af \u00af \u00af =\u03b1 E 2 s \u00af \u00af \u00af \u00af \u00af \u00af +2\u03b1 E s E a \u00af \u00af \u00af \u00af \u00af \u00af \u00af \u00af \u00af \u00af \u00af \u00af +N\u0394z q e E s v \u00af \u00af \u00af \u00af \u00af \u00af \u00af \u00af . (31.24) The E 2 s \u00af \u00af \u00af \u00af \u00af \u00af terms cancel, and we have 2\u03b1 E s E a \u00af \u00af \u00af \u00af \u00af \u00af \u00af \u00af \u00af \u00af \u00af \u00af =\u2212N\u0394z q e E s v \u00af \u00af \u00af \u00af \u00af \u00af \u00af \u00af . (31.25) We now go back to Eq. (30.19), which tells us that for large z E a =\u2212 N\u0394z q e 2 \u03f5 0 c v(ret by z/c) (31.26) (recalling that \u03b7=N\u0394z ). Putting Eq. (31.26) into the left-hand side of (31.25), we get \u22122\u03b1 N\u0394z q e 2 \u03f5 0 c E s (at z)\u22c5v(ret by z/c) \u00af \u00af \u00af \u00af \u00af \u00af \u00af \u00af \u00af \u00af \u00af \u00af \u00af \u00af \u00af \u00af \u00af \u00af \u00af \u00af \u00af \u00af \u00af \u00af \u00af \u00af \u00af \u00af \u00af \u00af \u00af \u00af \u00af \u00af \u00af \u00af \u00af \u00af \u00af \u00af \u00af \u00af \u00af \u00af \u00af \u00af \u00af \u00af . N \u0394 However, E s (at z) is E s (at atoms) retarded by z/c . Since the average is independent of time, it is the same now as retarded by z/c , or is E s (at atoms)\u22c5v \u00af \u00af \u00af \u00af \u00af \u00af \u00af \u00af \u00af \u00af \u00af \u00af \u00af \u00af \u00af \u00af \u00af \u00af \u00af \u00af \u00af \u00af \u00af \u00af \u00af \u00af \u00af \u00af \u00af \u00af \u00af \u00af \u00af \u00af , the same average that appears on the right-hand side of (31.25). The two sides are therefore equal if \u03b1 \u03f5 0 c =1,or\u03b1= \u03f5 0 c. (31.27) We have discovered that if energy is to be conserved, the energy carried in an electric wave per unit area and per unit time (or what we have called the intensity) must be given by \u03f5 0 c E 2 \u00af \u00af \u00af \u00af \u00af \u00af . If we call the intensity S \u00af \u00af \u00af , we have S \u00af \u00af \u00af = \u23a7 \u23a9 \u23a8 \u23aa \u23aa intensity or energy/area/time \u23ab \u23ad \u23ac \u23aa \u23aa = \u03f5 0 c E 2 \u00af \u00af \u00af \u00af \u00af \u00af , (31.28) where the bar means the time average. We have a nice bonus result from our theory of the refractive index! It is now a good time to take up a somewhat different matter which we can handle with the machinery of this chapter. In the last chapter we said that when you have an opaque screen and the light can come through some holes, the distribution of intensity\u2014the diffraction pattern\u2014could be obtained by imagining instead that the holes are replaced by sources (oscillators) uniformly distributed over the hole. In other words, the diffracted wave is the same as though the hole were a new source. We have to explain the reason for that, because the hole is, of course, just where there are no sources, where there are no accelerating charges. Let us first ask: \u201cWhat is an opaque screen?\u201d Suppose we have a completely opaque screen between a source S and an observer at P , as in Fig. 31\u20136(a). If the screen is \u201copaque\u201d there is no field at P . Why is there no field there? According to the basic principles we should obtain the field at P as the field E s of the source delayed, plus the field from all the other charges around. But, as we have seen above, the charges in the screen will be set in motion by the field E s , and these motions generate a new field which, if the screen is opaque, must exactly cancel the field E s on the back side of the screen. You say: \u201cWhat a miracle that it balances exactly! Suppose it was not exactly right!\u201d If it were not exactly right (remember that this opaque screen has some thickness), the field toward the rear part of the screen would not be exactly zero. So, not being zero, it would set into motion some other charges in the material of the screen, and thus make a little more field, trying to get the total balanced out. So if we make the screen thick enough, there is no residual field, because there is enough opportunity to finally get the thing quieted down. In terms of our formulas above we would say that the screen has a large and imaginary index, so the wave is absorbed exponentially as it goes through. You know, of course, that a thin enough sheet of the most opaque material, even gold, is transparent. Now let us see what happens with an opaque screen which has holes in it, as in Fig. 31\u20136(b). What do we expect for the field at P ? The field at P can be represented as a sum of two parts\u2014the field due to the source S plus the field due to the wall, i.e., due to the motions of the charges in the walls. We might expect the motions of the charges in the walls to be complicated, but we can find out what fields they produce in a rather simple way. Suppose that we were to take the same screen, but plug up the holes, as indicated in part (c) of the figure. We imagine that the plugs are of exactly the same material as the wall. Mind you, the plugs go where the holes were in case (b). Now let us calculate the field at P . The field at P is certainly zero in case (c), but it is also equal to the field from the source plus the field due to all the motions of the atoms in the walls and in the plugs. We can write the following equations: Case (b): Case (c): E at P E \u2032 at P = E s + E wall , =0= E s + E \u2032 wall + E \u2032 plug , where the primes refer to the case where the plugs are in place, but E s is, of course, the same in both cases. Now if we subtract the two equations, we get E at P =( E wall \u2212 E \u2032 wall )\u2212 E \u2032 plug . \u2032 \u2032 Now if the holes are not too small (say many wavelengths across), we would not expect the presence of the plugs to change the fields which arrive at the walls except possibly for a little bit around the edges of the holes. Neglecting this small effect, we can set E wall = E \u2032 wall and obtain that E at P =\u2212 E \u2032 plug . \u2032 We have the result that the field at P when there are holes in a screen (case b) is the same (except for sign) as the field that is produced by that part of a complete opaque wall which is located where the holes are! (The sign is not too interesting, since we are usually interested in intensity which is proportional to the square of the field.) It seems like an amazing backwards-forwards argument. It is, however, not only true (approximately for not too small holes), but useful, and is the justification for the usual theory of diffraction. The field E \u2032 plug is computed in any particular case by remembering that the motion of the charges everywhere in the screen is just that which will cancel out the field E s on the back of the screen. Once we know these motions, we add the radiation fields at P due just to the charges in the plugs. We remark again that this theory of diffraction is only approximate, and will be good only if the holes are not too small. For holes which are too small the E \u2032 plug term will be small and then the difference between E \u2032 wall and E wall (which difference we have taken to be zero) may be comparable to or larger than the small E \u2032 plug term, and our approximation will no longer be valid."
    },
    {
        "input": "Inside Dielectrics",
        "output": "In this chapter we are going to discuss why it is that materials are dielectric. We said in the last chapter that we could understand the properties of electrical systems with dielectrics once we appreciated that when an electric field is applied to a dielectric it induces a dipole moment in the atoms. Specifically, if the electric field E induces an average dipole moment per unit volume P, then \u03ba, the dielectric constant, is given by \u03ba\u22121= P \u03f50E . We have already discussed how this equation is applied; now we have to discuss the mechanism by which polarization arises when there is an electric field inside a material. We begin with the simplest possible example\u2014the polarization of gases. But even gases already have complications: there are two types. The molecules of some gases, like oxygen, which has a symmetric pair of atoms in each molecule, have no inherent dipole moment. But the molecules of others, like water vapor (which has a nonsymmetric arrangement of hydrogen and oxygen atoms) carry a permanent electric dipole moment. As we pointed out in Chapter 6, there is in the water vapor molecule an average plus charge on the hydrogen atoms and a negative charge on the oxygen. Since the center of gravity of the negative charge and the center of gravity of the positive charge do not coincide, the total charge distribution of the molecule has a dipole moment. Such a molecule is called a polar molecule. In oxygen, because of the symmetry of the molecule, the centers of gravity of the positive and negative charges are the same, so it is a nonpolar molecule. It does, however, become a dipole when placed in an electric field. The forms of the two types of molecules are sketched in Fig. 11\u20131. We will first discuss the polarization of nonpolar molecules. We can start with the simplest case of a monatomic gas (for instance, helium). When an atom of such a gas is in an electric field, the electrons are pulled one way by the field while the nucleus is pulled the other way, as shown in Fig. 10\u20134. Although the atoms are very stiff with respect to the electrical forces we can apply experimentally, there is a slight net displacement of the centers of charge, and a dipole moment is induced. For small fields, the amount of displacement, and so also the dipole moment, is proportional to the electric field. The displacement of the electron distribution which produces this kind of induced dipole moment is called electronic polarization. We have already discussed the influence of an electric field on an atom in Chapter 31 of Vol. I, when we were dealing with the theory of the index of refraction. If you think about it for a moment, you will see that what we must do now is exactly the same as we did then. But now we need worry only about fields that do not vary with time, while the index of refraction depended on time-varying fields. In Chapter 31 of Vol. I we supposed that when an atom is placed in an oscillating electric field the center of charge of the electrons obeys the equation m d2x dt2 +m\u03c9 2 0 x=qeE. The first term is the electron mass times its acceleration and the second is a restoring force, while the right-hand side is the force from the outside electric field. If the electric field varies with the frequency \u03c9, Eq. (11.2) has the solution x= qeE m(\u03c9 2 0 \u2212\u03c92) , which has a resonance at \u03c9=\u03c90. When we previously found this solution, we interpreted it as saying that \u03c90 was the frequency at which light (in the optical region or in the ultraviolet, depending on the atom) was absorbed. For our purposes, however, we are interested only in the case of constant fields, i.e., for \u03c9=0, so we can disregard the acceleration term in (11.2), and we find that the displacement is x= qeE m\u03c9 2 0 . From this we see that the dipole moment p of a single atom is p=qex= q 2 e E m\u03c9 2 0 . In this theory the dipole moment p is indeed proportional to the electric field. People usually write p=\u03b1\u03f50E. (Again the \u03f50 is put in for historical reasons.) The constant \u03b1 is called the polarizability of the atom, and has the dimensions L3 . It is a measure of how easy it is to induce a moment in an atom with an electric field. Comparing (11.5) and (11.6), our simple theory says that \u03b1= q 2 e \u03f50m\u03c9 2 0 = 4\u03c0e2 m\u03c9 2 0 . If there are N atoms in a unit volume, the polarization P \u2014the dipole moment per unit volume\u2014is given by P=Np=N\u03b1\u03f50E. Putting (11.1) and (11.8) together, we get \u03ba\u22121= P \u03f50E =N\u03b1 or, using (11.7), \u03ba\u22121= 4\u03c0Ne2 m\u03c9 2 0 . From Eq. (11.10) we would predict that the dielectric constant \u03ba of different gases should depend on the density of the gas and on the frequency \u03c90 of its optical absorption. Our formula is, of course, only a very rough approximation, because in Eq. (11.2) we have taken a model which ignores the complications of quantum mechanics. For example, we have assumed that an atom has only one resonant frequency, when it really has many. To calculate properly the polarizability \u03b1 of atoms we must use the complete quantum-mechanical theory, but the classical ideas above give us a reasonable estimate. Let\u2019s see if we can get the right order of magnitude for the dielectric constant of some substance. Suppose we try hydrogen. We have once estimated (Chapter 38, Vol. I) that the energy needed to ionize the hydrogen atom should be approximately E\u2248 1 2 me4 \u210f2 . For an estimate of the natural frequency \u03c90 , we can set this energy equal to \u210f\u03c90 \u2014the energy of an atomic oscillator whose natural frequency is \u03c90 . We get \u03c90\u2248 1 2 me4 \u210f3 . If we now use this value of \u03c90 in Eq. (11.7), we find for the electronic polarizability \u03b1\u224816\u03c0[ \u210f2 me2 ]3. The quantity (\u210f2/me2) is the radius of the ground-state orbit of a Bohr atom (see Chapter 38, Vol. I) and equals 0.528 angstroms. In a gas at standard pressure and temperature (1 atmosphere, 0\u2218 C) there are 2.69\u00d71019 atoms/cm3 , so Eq. (11.9) gives us \u03ba =1+(2.69\u00d71019)16\u03c0(0.528\u00d710\u22128)3 =1.00020. The dielectric constant for hydrogen gas is measured to be \u03baexp=1.00026. We see that our theory is about right. We should not expect any better, because the measurements were, of course, made with normal hydrogen gas, which has diatomic molecules, not single atoms. We should not be surprised if the polarization of the atoms in a molecule is not quite the same as that of the separate atoms. The molecular effect, however, is not really that large. An exact quantum-mechanical calculation of \u03b1 for hydrogen atoms gives a result about 12% higher than (11.12) (the 16\u03c0 is changed to 18\u03c0 ), and therefore predicts a dielectric constant somewhat closer to the observed one. In any case, it is clear that our model of a dielectric is fairly good. Another check on our theory is to try Eq. (11.7) on atoms which have a higher frequency of excitation. For instance, it takes about 24.6 electron volts to pull the electron off helium, compared with the 13.6 electron volts required to ionize hydrogen. We would, therefore, expect that the absorption frequency \u03c90 for helium would be about twice as big as for hydrogen and that \u03b1 would be one-quarter as large. So, from (11.13) we expect that \u03bahelium\u22481.000050. Experimentally, \u03bahelium=1.000068, so you see that our rough estimates are coming out on the right track. So we have understood the dielectric constant of nonpolar gas, but only qualitatively, because we have not yet used a correct atomic theory of the motions of the atomic electrons. Next we will consider a molecule which carries a permanent dipole moment p0 \u2014such as a water molecule. With no electric field, the individual dipoles point in random directions, so the net moment per unit volume is zero. But when an electric field is applied, two things happen: First, there is an extra dipole moment induced because of the forces on the electrons; this part gives just the same kind of electronic polarizability we found for a nonpolar molecule. For very accurate work, this effect should, of course, be included, but we will neglect it for the moment. (It can always be added in at the end.) Second, the electric field tends to line up the individual dipoles to produce a net moment per unit volume. If all the dipoles in a gas were to line up, there would be a very large polarization, but that does not happen. At ordinary temperatures and electric fields the collisions of the molecules in their thermal motion keep them from lining up very much. But there is some net alignment, and so some polarization (see Fig. 11\u20132). The polarization that does occur can be computed by the methods of statistical mechanics we described in Chapter 40 of Vol. I. To use this method we need to know the energy of a dipole in an electric field. Consider a dipole of moment p0 in an electric field, as shown in Fig. 11\u20133. The energy of the positive charge is q\u03d5(1) , and the energy of the negative charge is \u2212q\u03d5(2) . Thus the energy of the dipole is U=q\u03d5(1)\u2212q\u03d5(2)=qd\u22c5\u2207\u03d5, or U=\u2212p0\u22c5E=\u2212p0Ecos\u03b8, where \u03b8 is the angle between p0 and E . As we would expect, the energy is lower when the dipoles are lined up with the field. We now find out how much lining up occurs by using the methods of statistical mechanics. We found in Chapter 40 of Vol. I that in a state of thermal equilibrium, the relative number of molecules with the potential energy U is proportional to e\u2212U/kT, where U(x,y,z) is the potential energy as a function of position. The same arguments would say that using Eq. (11.14) for the potential energy as a function of angle, the number of molecules at \u03b8 per unit solid angle is proportional to e\u2212U/kT . Letting n(\u03b8) be the number of molecules per unit solid angle at \u03b8 , we have n(\u03b8)=n0e+p0Ecos\u03b8/kT. For normal temperatures and fields, the exponent is small, so we can approximate by expanding the exponential: n(\u03b8)=n0(1+ p0Ecos\u03b8 kT ). We can find n0 if we integrate (11.17) over all angles; the result should be just N , the total number of molecules per unit volume. The average value of cos\u03b8 over all angles is zero, so the integral is just n0 times the total solid angle 4\u03c0 . We get n0= N 4\u03c0 . We see from (11.17) that there will be more molecules oriented along the field ( cos\u03b8=1 ) than against the field ( cos\u03b8=\u22121 ). So in any small volume containing many molecules there will be a net dipole moment per unit volume\u2014that is, a polarization P . To calculate P , we want the vector sum of all the molecular moments in a unit volume. Since we know that the result is going to be in the direction of E , we will just sum the components in that direction (the components at right angles to E will sum to zero): P= \u2211 unit volume p 0 cos \u03b8 i . We can evaluate the sum by integrating over the angular distribution. The solid angle at \u03b8 is 2\u03c0sin\u03b8d\u03b8 , so P= \u222b \u03c0 0 n(\u03b8) p 0 cos\u03b82\u03c0sin\u03b8d\u03b8. (11.19) Substituting for n(\u03b8) from (11.17), we have P=\u2212 N 2 \u222b \u22121 1 (1+ p 0 E kT cos\u03b8) p 0 cos\u03b8d(cos\u03b8), which is easily integrated to give P= N p 2 0 E 3kT . (11.20) The polarization is proportional to the field E , so there will be normal dielectric behavior. Also, as we expect, the polarization depends inversely on the temperature, because at higher temperatures there is more disalignment by collisions. This 1/T dependence is called Curie\u2019s law. The permanent moment p 0 appears squared for the following reason: In a given electric field, the aligning force depends upon p 0 , and the mean moment that is produced by the lining up is again proportional to p 0 . The average induced moment is proportional to p 2 0 . We should now try to see how well Eq. (11.20) agrees with experiment. Let\u2019s look at the case of steam. Since we don\u2019t know what p 0 is, we cannot compute P directly, but Eq. (11.20) does predict that \u03ba\u22121 should vary inversely as the temperature, and this we should check. From (11.20) we get \u03ba\u22121= P \u03f5 0 E = N p 2 0 3 \u03f5 0 kT , (11.21) so \u03ba\u22121 should vary in direct proportion to the density N , and inversely as the absolute temperature. The dielectric constant has been measured at several different pressures and temperatures, chosen such that the number of molecules in a unit volume remained fixed.1 [Notice that if the measurements had all been taken at constant pressure, the number of molecules per unit volume would decrease linearly with increasing temperature and \u03ba\u22121 would vary as T \u22122 instead of as T \u22121 .] In Fig. 11\u20134 we plot the experimental observations for \u03ba\u22121 as a function of 1/T . The dependence predicted by (11.21) is followed quite well. There is another characteristic of the dielectric constant of polar molecules\u2014its variation with the frequency of the applied field. Due to the moment of inertia of the molecules, it takes a certain amount of time for the heavy molecules to turn toward the direction of the field. So if we apply frequencies in the high microwave region or above, the polar contribution to the dielectric constant begins to fall away because the molecules cannot follow. In contrast to this, the electronic polarizability still remains the same up to optical frequencies, because of the smaller inertia in the electrons. We now turn to an interesting but complicated question\u2014the problem of the dielectric constant in dense materials. Suppose that we take liquid helium or liquid argon or some other nonpolar material. We still expect electronic polarization. But in a dense material, P can be large, so the field on an individual atom will be influenced by the polarization of the atoms in its close neighborhood. The question is, what electric field acts on the individual atom? Imagine that the liquid is put between the plates of a condenser. If the plates are charged they will produce an electric field in the liquid. But there are also charges in the individual atoms, and the total field E is the sum of both of these effects. This true electric field varies very, very rapidly from point to point in the liquid. It is very high inside the atoms\u2014particularly right next to the nucleus\u2014and relatively small between the atoms. The potential difference between the plates is the line integral of this total field. If we ignore all the fine-grained variations, we can think of an average electric field E , which is just V/d . (This is the field we were using in the last chapter.) We should think of this field as the average over a space containing many atoms. Now you might think that an \u201caverage\u201d atom in an \u201caverage\u201d location would feel this average field. But it is not that simple, as we can show by considering what happens if we imagine different-shaped holes in a dielectric. For instance, suppose that we cut a slot in a polarized dielectric, with the slot oriented parallel to the field, as shown in part (a) of Fig. 11\u20135. Since we know that \u2207\u00d7E=0 , the line integral of E around the curve, \u0393 , which goes as shown in (b) of the figure, should be zero. The field inside the slot must give a contribution which just cancels the part from the field outside. Therefore the field E 0 actually found in the center of a long thin slot is equal to E , the average electric field found in the dielectric. Now consider another slot whose large sides are perpendicular to E , as shown in part (c) of Fig. 11\u20135. In this case, the field E 0 in the slot is not the same as E because polarization charges appear on the surfaces. If we apply Gauss\u2019 law to a surface S drawn as in (d) of the figure, we find that the field E 0 in the slot is given by E 0 =E+ P \u03f5 0 , (11.22) where E is again the electric field in the dielectric. (The Gaussian surface contains the surface polarization charge \u03c3 pol =P .) We mentioned in Chapter 10 that \u03f5 0 E+P is often called D , so \u03f5 0 E 0 = D 0 is equal to D in the dielectric. Earlier in the history of physics, when it was supposed to be very important to define every quantity by direct experiment, people were delighted to discover that they could define what they meant by E and D in a dielectric without having to crawl around between the atoms. The average field E is numerically equal to the field E 0 that would be measured in a slot cut parallel to the field. And the field D could be measured by finding E 0 in a slot cut normal to the field. But nobody ever measures them that way anyway, so it was just one of those philosophical things. For most liquids which are not too complicated in structure, we could expect that an atom finds itself, on the average, surrounded by the other atoms in what would be a good approximation to a spherical hole. And so we should ask: \u201cWhat would be the field in a spherical hole?\u201d We can find out by noticing that if we imagine carving out a spherical hole in a uniformly polarized material, we are just removing a sphere of polarized material. (We must imagine that the polarization is \u201cfrozen in\u201d before we cut out the hole.) By superposition, however, the fields inside the dielectric, before the sphere was removed, is the sum of the fields from all charges outside the spherical volume plus the fields from the charges within the polarized sphere. That is, if we call E the field in the uniform dielectric, we can write E= E hole + E plug , (11.23) where E hole is the field in the hole and E plug is the field inside a sphere which is uniformly polarized (see Fig. 11\u20136). The fields due to a uniformly polarized sphere are shown in Fig. 11\u20137. The electric field inside the sphere is uniform, and its value is E plug =\u2212 P 3 \u03f5 0 . (11.24) Using (11.23), we get E hole =E+ P 3 \u03f5 0 . (11.25) The field in a spherical cavity is greater than the average field by the amount P/3 \u03f5 0 . (The spherical hole gives a field 1/3 of the way between a slot parallel to the field and a slot perpendicular to the field.) In a liquid we expect that the field which will polarize an individual atom is more like E hole than just E . If we use the E hole of (11.25) for the polarizing field in Eq. (11.6), then Eq. (11.8) becomes P=N\u03b1 \u03f5 0 (E+ P 3 \u03f5 0 ), (11.26) or P= N\u03b1 1\u2212(N\u03b1/3) \u03f5 0 E. (11.27) Remembering that \u03ba\u22121 is just P/ \u03f5 0 E , we have \u03ba\u22121= N\u03b1 1\u2212(N\u03b1/3) , (11.28) which gives us the dielectric constant of a liquid in terms of \u03b1 , the atomic polarizability. This is called the Clausius-Mossotti equation. Whenever N\u03b1 is very small, as it is for a gas (because the density N is small), then the term N\u03b1/3 can be neglected compared with 1 , and we get our old result, Eq. (11.9), that \u03ba\u22121=N\u03b1. (11.29) Let\u2019s compare Eq. (11.28) with some experimental results. It is first necessary to look at gases for which, using the measurement of \u03ba , we can find \u03b1 from Eq. (11.29). For instance, for carbon disulfide at zero degrees centigrade the dielectric constant is 1.0029 , so N\u03b1 is 0.0029 . Now the density of the gas is easily worked out and the density of the liquid can be found in handbooks. At 20 \u2218 C, the density of liquid CS 2 is 381 times higher than the density of the gas at 0 \u2218 C. This means that N is 381 times higher in the liquid than it is in the gas, so that\u2014if we make the approximation that the basic atomic polarizability of the carbon disulfide doesn\u2019t change when it is condensed into a liquid\u2014 N\u03b1 in the liquid is equal to 381 times 0.0029 , or 1.11 . Notice that the N\u03b1/3 term amounts to almost 0.4 , so it is quite significant. With these numbers we predict a dielectric constant of 2.76 , which agrees reasonably well with the observed value of 2.64 . In Table 11\u20131 we give some experimental data on various materials (taken from the Handbook of Chemistry and Physics), together with the dielectric constants calculated from Eq. (11.28) in the way just described. The agreement between observation and theory is even better for argon and oxygen than for CS 2 \u2014and not so good for carbon tetrachloride. On the whole, the results show that Eq. (11.28) works very well. Our derivation of Eq. (11.28) is valid only for electronic polarization in liquids. It is not right for a polar molecule like H 2 O. If we go through the same calculations for water, we get 13.2 for N\u03b1 , which means that the dielectric constant for the liquid is negative, while the observed value of \u03ba is 80 . The problem has to do with the correct treatment of the permanent dipoles, and Onsager has pointed out the right way to go. We do not have the time to treat the case now, but if you are interested it is discussed in Kittel\u2019s book, Introduction to Solid State Physics. Now we turn to the solids. The first interesting fact about solids is that there can be a permanent polarization built in\u2014which exists even without applying an electric field. An example occurs with a material like wax, which contains long molecules having a permanent dipole moment. If you melt some wax and put a strong electric field on it when it is a liquid, so that the dipole moments get partly lined up, they will stay that way when the liquid freezes. The solid material will have a permanent polarization which remains when the field is removed. Such a solid is called an electret. An electret has permanent polarization charges on its surface. It is the electrical analog of a magnet. It is not as useful, though, because free charges from the air are attracted to its surfaces, eventually cancelling the polarization charges. The electret is \u201cdischarged\u201d and there are no visible external fields. A permanent internal polarization P is also found occurring naturally in some crystalline substances. In such crystals, each unit cell of the lattice has an identical permanent dipole moment, as drawn in Fig. 11\u20138. All the dipoles point in the same direction, even with no applied electric field. Many complicated crystals have, in fact, such a polarization; we do not normally notice it because the external fields are discharged, just as for the electrets. If these internal dipole moments of a crystal are changed, however, external fields appear because there is not time for stray charges to gather and cancel the polarization charges. If the dielectric is in a condenser, free charges will be induced on the electrodes. For example, the moments can change when a dielectric is heated, because of thermal expansion. The effect is called pyroelectricity. Similarly, if we change the stresses in a crystal\u2014for instance, if we bend it\u2014again the moment may change a little bit, and a small electrical effect, called piezoelectricity, can be detected. For crystals that do not have a permanent moment, one can work out a theory of the dielectric constant that involves the electronic polarizability of the atoms. It goes much the same as for liquids. Some crystals also have rotatable dipoles inside, and the rotation of these dipoles will also contribute to \u03ba . In ionic crystals such as NaCl there is also ionic polarizability. The crystal consists of a checkerboard of positive and negative ions, and in an electric field the positive ions are pulled one way and the negatives the other; there is a net relative motion of the plus and minus charges, and so a volume polarization. We could estimate the magnitude of the ionic polarizability from our knowledge of the stiffness of salt crystals, but we will not go into that subject here. We want to describe now one special class of crystals which have, just by accident almost, a built-in permanent moment. The situation is so marginal that if we increase the temperature a little bit they lose the permanent moment completely. On the other hand, if they are nearly cubic crystals, so that their moments can be turned in different directions, we can detect a large change in the moment when an applied electric field is changed. All the moments flip over and we get a large effect. Substances which have this kind of permanent moment are called ferroelectric, after the corresponding ferromagnetic effects which were first discovered in iron. We would like to explain how ferroelectricity works by describing a particular example of a ferroelectric material. There are several ways in which the ferroelectric property can originate; but we will take up only one mysterious case\u2014that of barium titanate, BaTiO 3 . This material has a crystal lattice whose basic cell is sketched in Fig. 11\u20139. It turns out that above a certain temperature, specifically 118 \u2218 C, barium titanate is an ordinary dielectric with an enormous dielectric constant. Below this temperature, however, it suddenly takes on a permanent moment. In working out the polarization of solid material, we must first find what are the local fields in each unit cell. We must include the fields from the polarization itself, just as we did for the case of a liquid. But a crystal is not a homogeneous liquid, so we cannot use for the local field what we would get in a spherical hole. If you work it out for a crystal, you find that the factor 1/3 in Eq. (11.24) becomes slightly different, but not far from 1/3 . (For a simple cubic crystal, it is just 1/3 .) We will, therefore, assume for our preliminary discussion that the factor is 1/3 for BaTiO 3 . Now when we wrote Eq. (11.28) you may have wondered what would happen if N\u03b1 became greater than 3 . It appears as though \u03ba would become negative. But that surely cannot be right. Let\u2019s see what should happen if we were gradually to increase \u03b1 in a particular crystal. As \u03b1 gets larger, the polarization gets bigger, making a bigger local field. But a bigger local field will polarize each atom more, raising the local fields still more. If the \u201cgive\u201d of the atoms is enough, the process keeps going; there is a kind of feedback that causes the polarization to increase without limit\u2014assuming that the polarization of each atom increases in proportion to the field. The \u201crunaway\u201d condition occurs when N\u03b1=3 . The polarization does not become infinite, of course, because the proportionality between the induced moment and the electric field breaks down at high fields, so that our formulas are no longer correct. What happens is that the lattice gets \u201clocked in\u201d with a high, self-generated, internal polarization. In the case of BaTiO 3 , there is, in addition to an electronic polarization, also a rather large ionic polarization, presumed to be due to titanium ions which can move a little within the cubic lattice. The lattice resists large motions, so after the titanium has gone a little way, it jams up and stops. But the crystal cell is then left with a permanent dipole moment. In most crystals, this is really the situation for all temperatures that can be reached. The very interesting thing about barium titanate is that there is such a delicate condition that if N\u03b1 is decreased just a little bit it comes unstuck. Since N decreases with increasing temperature\u2014because of thermal expansion\u2014we can vary N\u03b1 by varying the temperature. Below the critical temperature it is just barely stuck, so it is easy\u2014by applying an external field\u2014to shift the polarization and have it lock in a different direction. Let\u2019s see if we can analyze what happens in more detail. We call T c the critical temperature at which N\u03b1 is exactly 3 . As the temperature increases, N goes down a little bit because of the expansion of the lattice. Since the expansion is small, we can say that near the critical temperature N\u03b1=3\u2212\u03b2(T\u2212 T c ), (11.30) where \u03b2 is a small constant, of the same order of magnitude as the thermal expansion coefficient, or about 10 \u22125 to 10 \u22126 per degree C. Now if we substitute this relation into Eq. (11.28), we get that \u03ba\u22121= 3\u2212\u03b2(T\u2212 T c ) \u03b2(T\u2212 T c )/3 . \u03b2 ( ) Since we have assumed that \u03b2(T\u2212 T c ) is small compared with one, we can approximate this formula by \u03ba\u22121= 9 \u03b2(T\u2212 T c ) . (11.31) This relation is right, of course, only for T> T c . We see that just above the critical temperature \u03ba is enormous. Because N\u03b1 is so close to 3 , there is a tremendous magnification effect, and the dielectric constant can easily be as high as 50,000 to 100,000 . It is also very sensitive to temperature. For increases in temperature, the dielectric constant goes down inversely as the temperature, but, unlike the case of a dipolar gas, for which \u03ba\u22121 goes inversely as the absolute temperature, for ferroelectrics it varies inversely as the difference between the absolute temperature and the critical temperature (this law is called the Curie-Weiss law). When we lower the temperature to the critical temperature, what happens? If we imagine a lattice of unit cells like that in Fig. 11\u20139, we see that it is possible to pick out chains of ions along vertical lines. One of them consists of alternating oxygen and titanium ions. There are other lines made up of either barium or oxygen ions, but the spacing along these lines is greater. We make a simple model to imitate this situation by imagining, as shown in Fig. 11\u201310(a), a series of chains of ions. Along what we call the main chain, the separation of the ions is a , which is half the lattice constant; the lateral distance between identical chains is 2a . There are less-dense chains in between which we will ignore for the moment. To make the analysis a little easier, we will also suppose that all the ions on the main chain are identical. (It is not a serious simplification because all the important effects will still appear. This is one of the tricks of theoretical physics. One does a different problem because it is easier to figure out the first time\u2014then when one understands how the thing works, it is time to put in all the complications.) Now let\u2019s try to find out what would happen with our model. We suppose that the dipole moment of each atom is p and we wish to calculate the field at one of the atoms of the chain. We must find the sum of the fields from all the other atoms. We will first calculate the field from the dipoles in only one vertical chain; we will talk about the other chains later. The field at the distance r from a dipole in a direction along its axis is given by E= 1 4\u03c0 \u03f5 0 2p r 3 . (11.32) At any given atom, the dipoles at equal distances above and below it give fields in the same direction, so for the whole chain we get E chain = p 4\u03c0 \u03f5 0 2 a 3 \u22c5(2+ 2 8 + 2 27 + 2 64 +\u22ef) = p \u03f5 0 0.383 a 3 . (11.33) It is not too hard to show that if our model were like a completely cubic crystal\u2014that is, if the next identical lines were only the distance a away\u2014the number 0.383 would be changed to 1/3 . In other words, if the next lines were at the distance a they would contribute only \u22120.050 unit to our sum. However, the next main chain we are considering is at the distance 2a and, as you remember from Chapter 7, the field from a periodic structure dies off exponentially with distance. Therefore these lines contribute much less than \u22120.050 and we can just ignore all the other chains. It is necessary now to find out what polarizability \u03b1 is needed to make the runaway process work. Suppose that the induced moment p of each atom of the chain is proportional to the field on it, as in Eq. (11.6). We get the polarizing field on the atom from E chain using Eq. (11.32). So we have the two equations p=\u03b1 \u03f5 0 E chain E and E chain = 0.383 a 3 p \u03f5 0 . 0.383 There are two solutions: E chain and p both zero, or \u03b1= a 3 0.383 , 3 with E chain and p both finite. Thus if \u03b1 is as large as a 3 /0.383 , a permanent polarization sustained by its own field will set in. This critical equality must be reached for barium titanate at just the temperature T c . (Notice that if \u03b1 were larger than the critical value for small fields, it would decrease at larger fields and at equilibrium the same equality we have found would hold.) For BaTiO 3 , the spacing a is 2\u00d7 10 \u22128 cm, so we must expect that \u03b1=21.8\u00d7 10 \u221224 cm 3 . We can compare this with the known polarizabilities of the individual atoms. For oxygen, \u03b1=30.2\u00d7 10 \u221224 cm 3 ; we\u2019re on the right track! But for titanium, \u03b1=2.4\u00d7 10 \u221224 cm 3 ; rather small. To use our model we should probably take the average. (We could work out the chain again for alternating atoms, but the result would be about the same.) So \u03b1(average)=16.3\u00d7 10 \u221224 cm 3 , which is not high enough to give a permanent polarization. But wait a moment! We have so far only added up the electronic polarizabilities. There is also some ionic polarization due to the motion of the titanium ion. All we need is an ionic polarizability of 9.2\u00d7 10 \u221224 cm 3 . (A more precise computation using alternating atoms shows that actually 11.9\u00d7 10 \u221224 cm 3 is needed.) To understand the properties of BaTiO 3 , we have to assume that such an ionic polarizability exists. Why the titanium ion in barium titanate should have that much ionic polarizability is not known. Furthermore, why, at a lower temperature, it polarizes along the cube diagonal and the face diagonal equally well is not clear. If we figure out the actual size of the spheres in Fig. 11\u20139, and ask whether the titanium is a little bit loose in the box formed by its neighboring oxygen atoms\u2014which is what you would hope, so that it could be easily shifted\u2014you find quite the contrary. It fits very tightly. The barium atoms are slightly loose, but if you let them be the ones that move, it doesn\u2019t work out. So you see that the subject is really not one-hundred percent clear; there are still mysteries we would like to understand. Returning to our simple model of Fig. 11\u201310(a), we see that the field from one chain would tend to polarize the neighboring chain in the opposite direction, which means that although each chain would be locked, there would be no net permanent moment per unit volume! (Although there would be no external electric effects, there are still certain thermodynamic effects one could observe.) Such systems exist, and are called antiferroelectric. So what we have explained is really an antiferroelectric. Barium titanate, however, is really like the arrangement in Fig. 11\u201310(b). The oxygen-titanium chains are all polarized in the same direction because there are intermediate chains of atoms in between. Although the atoms in these chains are not very polarizable, or very dense, they will be somewhat polarized, in the direction antiparallel to the oxygen-titanium chains. The small fields produced at the next oxygen-titanium chain will get it started parallel to the first. So BaTiO 3 is really ferroelectric, and it is because of the atoms in between. You may be wondering: \u201cBut what about the direct effect between the two O-Ti chains?\u201d Remember, though, the direct effect dies off exponentially with the separation; the effect of the chain of strong dipoles at 2a can be less than the effect of a chain of weak ones at the distance a . This completes our rather detailed report on our present understanding of the dielectric constants of gases, of liquids, and of solids."
    },
    {
        "input": "Solutions of Maxwells Equations with Currents and Charges",
        "output": "We saw in the last chapter that among their solutions, Maxwell\u2019s equations have waves of electricity and magnetism. These waves correspond to the phenomena of radio, light, x-rays, and so on, depending on the wavelength. We have already studied light in great detail in Vol. I. In this chapter we want to tie together the two subjects\u2014we want to show that Maxwell\u2019s equations can indeed form the base for our earlier treatment of the phenomena of light. When we studied light, we began by writing down equations for the electric and magnetic fields produced by a charge which moves in any arbitrary way. Those equations were E= q 4\u03c0\u03f50 [ er\u2032 r\u20322 + r\u2032 c d dt ( er\u2032 r\u20322 )+ 1 c2 d2 dt2 er\u2032] and cB=er\u2032\u00d7E. [See Eqs. (28.3) and (28.4), Vol. I. As explained below, the signs here are the negatives of the old ones.] If a charge moves in an arbitrary way, the electric field we would find now at some point depends only on the position and motion of the charge not now, but at an earlier time\u2014at an instant which is earlier by the time it would take light, going at the speed c , to travel the distance r\u2032 from the charge to the field point. In other words, if we want the electric field at point (1) at the time t , we must calculate the location (2\u2032) of the charge and its motion at the time (t\u2212r\u2032/c) , where r\u2032 is the distance to the point (1) from the position of the charge (2\u2032) at the time (t\u2212r\u2032/c) . The prime is to remind you that r\u2032 is the so-called \u201cretarded distance\u201d from the point (2\u2032) to the point (1) , and not the actual distance between point (2) , the position of the charge at the time t , and the field point (1) (see Fig. 21-1). Note that we are using a different convention now for the direction of the unit vector er . In Chapters 28 and 34 of Vol. I it was convenient to take r (and hence er ) pointing toward the source. Now we are following the definition we took for Coulomb\u2019s law, in which r is directed from the charge, at (2) , toward the field point at (1) . The only difference, of course, is that our new r (and er ) are the negatives of the old ones. We have also seen that if the velocity v of a charge is always much less than c , and if we consider only points at large distances from the charge, so that only the last term of Eq. (21.1) is important, the fields can also be written as E= q 4\u03c0\u03f50c2r\u2032 [ acceleration of the charge at (t\u2212r\u2032/c) projected at right angles to r\u2032 ] and cB=er\u2032\u00d7E. Let\u2019s look at what the complete equation, Eq. (21.1), says in a little more detail. The vector er\u2032 is the unit vector to point (1) from the retarded position (2\u2032) . The first term, then, is what we would expect for the Coulomb field of the charge at its retarded position\u2014we may call this \u201cthe retarded Coulomb field.\u201d The electric field depends inversely on the square of the distance and is directed away from the retarded position of the charge (that is, in the direction of er\u2032 ). But that is only the first term. The other terms tell us that the laws of electricity do not say that all the fields are the same as the static ones, but just retarded (which is what people sometimes like to say). To the \u201cretarded Coulomb field\u201d we must add the other two terms. The second term says that there is a \u201ccorrection\u201d to the retarded Coulomb field which is the rate of change of the retarded Coulomb field multiplied by r\u2032/c , the retardation delay. In a way of speaking, this term tends to compensate for the retardation in the first term. The first two terms correspond to computing the \u201cretarded Coulomb field\u201d and then extrapolating it toward the future by the amount r\u2032/c , that is, right up to the time t ! The extrapolation is linear, as if we were to assume that the \u201cretarded Coulomb field\u201d would continue to change at the rate computed for the charge at the point (2\u2032) . If the field is changing slowly, the effect of the retardation is almost completely removed by the correction term, and the two terms together give us an electric field that is the \u201cinstantaneous Coulomb field\u201d\u2014that is, the Coulomb field of the charge at the point (2) \u2014to a very good approximation. Finally, there is a third term in Eq. (21.1) which is the second derivative of the unit vector er\u2032 . For our study of the phenomena of light, we made use of the fact that far away from the charge the first two terms went inversely as the square of the distance and, for large distances, became very weak in comparison to the last term, which decreases as 1/r . So we concentrated entirely on the last term, and we showed that it is (again, for large distances) proportional to the component of the acceleration of the charge at right angles to the line of sight. (Also, for most of our work in Vol. I, we took the case in which the charges were moving nonrelativistically. We considered the relativistic effects in only one chapter, Chapter 34.) Now we should try to connect the two things together. We have the Maxwell equations, and we have Eq. (21.1) for the field of a point charge. We should certainly ask whether they are equivalent. If we can deduce Eq. (21.1) from Maxwell\u2019s equations, we will really understand the connection between light and electromagnetism. To make this connection is the main purpose of this chapter. It turns out that we won\u2019t quite make it\u2014that the mathematical details get too complicated for us to carry through in all their gory details. But we will come close enough so that you should easily see how the connection could be made. The missing pieces will only be in the mathematical details. Some of you may find the mathematics in this chapter rather complicated, and you may not wish to follow the argument very closely. We think it is important, however, to make the connection between what you have learned earlier and what you are learning now, or at least to indicate how such a connection can be made. You will notice, if you look over the earlier chapters, that whenever we have taken a statement as a starting point for a discussion, we have carefully explained whether it is a new \u201cassumption\u201d that is a \u201cbasic law,\u201d or whether it can ultimately be deduced from some other laws. We owe it to you in the spirit of these lectures to make the connection between light and Maxwell\u2019s equations. If it gets difficult in places, well, that\u2019s life\u2014there is no other way. In Chapter 18 we found that Maxwell\u2019s equations could be solved by letting E=\u2212\u2207\u03d5\u2212 \u2202A \u2202t and B=\u2207\u00d7A, where \u03d5 and A must then be solutions of the equations \u22072\u03d5\u2212 1 c2 \u22022\u03d5 \u2202t2 =\u2212 \u03c1 \u03f50 and \u22072A\u2212 1 c2 \u22022A \u2202t2 =\u2212 j \u03f50c2 , and must also satisfy the condition that \u2207\u22c5A=\u2212 1 c2 \u2202\u03d5 \u2202t . Now we will find the solution of Eqs. (21.4) and (21.5). To do that we have to find the solution \u03c8 , of the equation \u22072\u03c8\u2212 1 c2 \u22022\u03c8 \u2202t2 =\u2212s, where s , which we call the source, is known. Of course, s corresponds to \u03c1/\u03f50 and \u03c8 to \u03d5 for Eq. (21.4), or s is jx/\u03f50c2 if \u03c8 is Ax , etc., but we want to solve Eq. (21.7) as a mathematical problem no matter what \u03c8 and s are physically. In places where \u03c1 and j are zero\u2014in what we have called \u201cfree\u201d space\u2014the potentials \u03d5 and A , and the fields E and B , all satisfy the three-dimensional wave equation without sources, whose mathematical form is \u22072\u03c8\u2212 1 c2 \u22022\u03c8 \u2202t2 =0. In Chapter 20 we saw that solutions of this equation can represent waves of various kinds: plane waves in the x -direction, \u03c8=f(t\u2212x/c) ; plane waves in the y - or z -direction, or in any other direction; or spherical waves of the form \u03c8(x,y,z,t)= f(t\u2212r/c) r . (The solutions can be written in still other ways, for example cylindrical waves that spread out from an axis.) We also remarked that, physically, Eq. (21.9) does not represent a wave in free space\u2014that there must be charges at the origin to get the outgoing wave started. In other words, Eq. (21.9) is a solution of Eq. (21.8) everywhere except right near r=0 , where it must be a solution of the complete equation (21.7), including some sources. Let\u2019s see how that works. What kind of a source s in Eq. (21.7) would give rise to a wave like Eq. (21.9)? Suppose we have the spherical wave of Eq. (21.9) and look at what is happening for very small r . Then the retardation \u2212r/c in f(t\u2212r/c) can be neglected\u2014provided f is a smooth function\u2014and \u03c8 becomes \u03c8= f(t) r (r\u21920). So \u03c8 is just like a Coulomb field for a charge at the origin that varies with time. That is, if we had a little lump of charge, limited to a very small region near the origin, with a density \u03c1 , we know that \u03d5= Q/4\u03c0\u03f50 r , where Q=\u222b\u03c1dV . Now we know that such a \u03d5 satisfies the equation \u22072\u03d5=\u2212 \u03c1 \u03f50 . Following the same mathematics, we would say that the \u03c8 of Eq. (21.10) satisfies \u22072\u03c8=\u2212s(r\u21920), where s is related to f by f= S 4\u03c0 , with S=\u222bsdV. The only difference is that in the general case, s , and therefore S , can be a function of time. Now the important thing is that if \u03c8 satisfies Eq. (21.11) for small r , it also satisfies Eq. (21.7). As we go very close to the origin, the 1/r dependence of \u03c8 causes the space derivatives to become very large. But the time derivatives keep their same values. [They are just the time derivatives of f(t) .] So as r goes to zero, the term \u22022\u03c8/\u2202t2 in Eq. (21.7) can be neglected in comparison with \u22072\u03c8 , and Eq. (21.7) becomes equivalent to Eq. (21.11). To summarize, then, if the source function s(t) of Eq. (21.7) is localized at the origin and has the total strength S(t)=\u222bs(t)dV, the solution of Eq. (21.7) is \u03c8(x,y,z,t)= 1 4\u03c0 S(t\u2212r/c) r . The only effect of the term \u22022\u03c8/\u2202t2 in Eq. (21.7) is to introduce the retardation (t\u2212r/c) in the Coulomb-like potential. We have found the solution of Eq. (21.7) for a \u201cpoint\u201d source. The next question is: What is the solution for a spread-out source? That\u2019s easy; we can think of any source s(x,y,z,t) as made up of the sum of many \u201cpoint\u201d sources, one for each volume element dV , and each with the source strength s(x,y,z,t)dV . Since Eq. (21.7) is linear, the resultant field is the superposition of the fields from all of such source elements. Using the results of the preceding section [Eq. (21.13)] we know that the field d\u03c8 at the point ( x 1 , y 1 , z 1 ) \u2014or (1) for short\u2014at the time t , from a source element sdV at the point ( x 2 , y 2 , z 2 ) \u2014or (2) for short\u2014is given by d\u03c8(1,t)= s(2,t\u2212 r 12 /c)d V 2 4\u03c0 r 12 , ( / ) d where r 12 is the distance from (2) to (1) . Adding the contributions from all the pieces of the source means, of course, doing an integral over all regions where s\u22600 ; so we have \u03c8(1,t)=\u222b s(2,t\u2212 r 12 /c) 4\u03c0 r 12 d V 2 . (21.14) That is, the field at (1) at the time t is the sum of all the spherical waves which leave the source elements at (2) at the times (t\u2212 r 12 /c) . This is the solution of our wave equation for any set of sources. We see now how to obtain a general solution for Maxwell\u2019s equations. If for \u03c8 we mean the scalar potential \u03d5 , the source function s becomes \u03c1/ \u03f5 0 . Or we can let \u03c8 represent any one of the three components of the vector potential A , replacing s by the corresponding component of j/ \u03f5 0 c 2 . Thus, if we know the charge density \u03c1(x,y,z,t) and the current density j(x,y,z,t) everywhere, we can immediately write down the solutions of Eqs. (21.4) and (21.5). They are \u03d5(1,t)=\u222b \u03c1(2,t\u2212 r 12 /c) 4\u03c0 \u03f5 0 r 12 d V 2 (21.15) and A(1,t)=\u222b j(2,t\u2212 r 12 /c) 4\u03c0 \u03f5 0 c 2 r 12 d V 2 . (21.16) The fields E and B can then be found by differentiating the potentials, using Eqs. (21.2) and (21.3). [Incidentally, it is possible to verify that the \u03d5 and A obtained from Eqs. (21.15) and (21.16) do satisfy the equality (21.6).] We have solved Maxwell\u2019s equations. Given the currents and charges in any circumstance, we can find the potentials directly from these integrals and then differentiate and get the fields. So we have finished with the Maxwell theory. Also this permits us to close the ring back to our theory of light, because to connect with our earlier work on light, we need only calculate the electric field from a moving charge. All that remains is to take a moving charge, calculate the potentials from these integrals, and then differentiate to find E from \u2212\u2207\u03d5\u2212\u2202A/\u2202t . We should get Eq. (21.1). It turns out to be lots of work, but that\u2019s the principle. So here is the center of the universe of electromagnetism\u2014the complete theory of electricity and magnetism, and of light; a complete description of the fields produced by any moving charges; and more. It is all here. Here is the structure built by Maxwell, complete in all its power and beauty. It is probably one of the greatest accomplishments of physics. To remind you of its importance, we will put it all together in a nice frame. Maxwell\u2019s equ \u2207\u22c5E \u2207\u00d7E \u2207\u22c5B c 2 \u2207\u00d7B Their solution ations: = \u03c1 \u03f5 0 =\u2212 \u2202B \u2202t =0 = j \u03f5 0 + \u2202E \u2202t s: E=\u2212\u2207\u03d5\u2212 \u2202A \u2202t B=\u2207\u00d7A \u03d5(1,t)=\u222b \u03c1(2,t\u2212 r 12 /c) 4\u03c0 \u03f5 0 r 12 d V 2 A(1,t)=\u222b j(2,t\u2212 r 12 /c) 4\u03c0 \u03f5 0 c 2 r 12 d V 2 We have still not lived up to our promise to derive Eq. (21.1) for the electric field of a point charge in motion. Even with the results we already have, it is a relatively complicated thing to derive. We have not found Eq. (21.1) anywhere in the published literature except in Vol. I of these lectures.1 So you can see that it is not easy to derive. (The fields of a moving charge have been written in many other forms that are equivalent, of course.) We will have to limit ourselves here just to showing that, in a few examples, Eqs. (21.15) and (21.16) give the same results as Eq. (21.1). First, we will show that Eq. (21.1) gives the correct fields with only the restriction that the motion of the charged particle is nonrelativistic. (Just this special case will take care of 90 percent, or more, of what we said about light.) We consider a situation in which we have a blob of charge that is moving about in some way, in a small region, and we will find the fields far away. To put it another way, we are finding the field at any distance from a point charge that is shaking up and down in very small motion. Since light is usually emitted from neutral objects such as atoms, we will consider that our wiggling charge q is located near an equal and opposite charge at rest. If the separation between the centers of the charges is d , the charges will have a dipole moment p=qd , which we take to be a function of time. Now we should expect that if we look at the fields close to the charges, we won\u2019t have to worry about the delay; the electric field will be exactly the same as the one we have calculated earlier for an electrostatic dipole\u2014using, of course, the instantaneous dipole moment p(t) . But if we go very far out, we ought to find a term in the field that goes as 1/r and depends on the acceleration of the charge perpendicular to the line of sight. Let\u2019s see if we get such a result. We begin by calculating the vector potential A , using Eq. (21.16). Suppose that our moving charge is in a small blob whose charge density is given by \u03c1(x,y,z) , and the whole thing is moving at any instant with the velocity v . Then the current density j(x,y,z) will be equal to v\u03c1(x,y,z) . It will be convenient to take our coordinate system so that the z -axis is in the direction of v ; then the geometry of our problem is as shown in Fig. 21-2. We want the integral \u222b j(2,t\u2212 r 12 /c) r 12 d V 2 . (21.17) Now if the size of the charge-blob is really very small compared with r 12 , we can set the r 12 term in the denominator equal to r , the distance to the center of the blob, and take r outside the integral. Next, we are also going to set r 12 =r in the numerator, although that is not really quite right. It is not right because we should take j at, say, the top of the blob at a slightly different time than we used for j at the bottom of the blob. When we set r 12 =r in j(t\u2212 r 12 /c) , we are taking the current density for the whole blob at the same time (t\u2212r/c) . That is an approximation that will be good only if the velocity v of the charge is much less than c . So we are making a nonrelativistic calculation. Replacing j by \u03c1v , the integral (21.17) becomes 1 r \u222bv\u03c1(2,t\u2212r/c)d V 2 . \u222b Since all the charge has the same velocity, this integral is just v/r times the total charge q . But qv is just \u2202p/\u2202t , the rate of change of the dipole moment\u2014which is, of course, to be evaluated at the retarded time (t\u2212r/c) . We will write it as p \u02d9 (t\u2212r/c) . So we get for the vector potential A(1,t)= 1 4\u03c0 \u03f5 0 c 2 p \u02d9 (t\u2212r/c) r . (21.18) Our result says that the current in a varying dipole produces a vector potential in the form of spherical waves whose source strength is p \u02d9 / \u03f5 0 c 2 . We can now get the magnetic field from B=\u2207\u00d7A . Since p \u02d9 is totally in the z -direction, A has only a z -component; there are only two nonzero derivatives in the curl. So B x =\u2202 A z /\u2202y and B y =\u2212\u2202 A z /\u2202x . Let\u2019s first look at B x : B x = \u2202 A z \u2202y = 1 4\u03c0 \u03f5 0 c 2 \u2202 \u2202y p \u02d9 (t\u2212r/c) r . (21.19) To carry out the differentiation, we must remember that r= x 2 + y 2 + z 2 \u2212 \u2212 \u2212 \u2212 \u2212 \u2212 \u2212 \u2212 \u2212 \u2212 \u221a , so B x = 1 4\u03c0 \u03f5 0 c 2 p \u02d9 (t\u2212r/c) 1 4\u03c0 \u03f5 0 c 2 1 r \u2202 \u2202y ( 1 r )+ \u2202 \u2202y p \u02d9 (t\u2212r/c). (21.20) Remembering that \u2202r/\u2202y=y/r , the first term gives \u2212 1 4\u03c0 \u03f5 0 c 2 y p \u02d9 (t\u2212r/c) r 3 , (21.21) which drops off as 1/ r 2 like the potential of a static dipole (because y/r is constant for a given direction). The second term in Eq. (21.20) gives us the new effects. Carrying out the differentiation, we get \u2212 1 4\u03c0 \u03f5 0 c 2 y c r 2 p \u00a8 (t\u2212r/c), (21.22) where p \u00a8 means, of course, the second derivative of p with respect to t . This term, which comes from differentiating the numerator, is responsible for radiation. First, it describes a field which decreases with distance only as 1/r . Second, it depends on the acceleration of the charge. You can begin to see how we are going to get a result like Eq. (21.1\u00b4), which describes the radiation of light. Let\u2019s examine in a little more detail how this radiation term comes about\u2014it is such an interesting and important result. We start with the expression (21.18), which has a 1/r dependence and is therefore like a Coulomb potential, except for the delay term in the numerator. Why is it then that when we differentiate with respect to space coordinates to get the fields, we don\u2019t just get a 1/ r 2 field\u2014with, of course, the corresponding time delays? We can see why in the following way: Suppose that we let our dipole oscillate up and down in a sinusoidal motion. Then we would have p= p z = p 0 sin\u03c9t sin and A z = 1 4\u03c0 \u03f5 0 c 2 \u03c9 p 0 cos\u03c9(t\u2212r/c) r . ( / ) If we plot a graph of A z as a function of r at a given instant, we get the curve shown in Fig. 21-3. The peak amplitude decreases as 1/r , but there is, in addition, an oscillation in space, bounded by the 1/r envelope. When we take the spatial derivatives, they will be proportional to the slope of the curve. From the figure we see that there are slopes much steeper than the slope of the 1/r curve itself. It is, in fact, evident that for a given frequency the peak slopes are proportional to the amplitude of the wave, which varies as 1/r . So that explains the drop-off rate of the radiation term. It all comes about because the variations with time at the source are translated into variations in space as the waves are propagated outward, and the magnetic fields depend on the spatial derivatives of the potential. Let\u2019s go back and finish our calculation of the magnetic field. We have for B x the two terms (21.21) and (21.22), so B x = 1 4\u03c0 \u03f5 0 c 2 [\u2212 y p \u02d9 (t\u2212r/c) r 3 \u2212 y p \u00a8 (t\u2212r/c) c r 2 ]. With the same kind of mathematics, we get B y = 1 4\u03c0 \u03f5 0 c 2 [ x p \u02d9 (t\u2212r/c) r 3 + x p \u00a8 (t\u2212r/c) c r 2 ]. Or we can put it all together in a nice vector formula: B= 1 4\u03c0 \u03f5 0 c 2 [ p \u02d9 +(r/c) p \u00a8 ] t\u2212r/c \u00d7r r 3 . (21.23) Now let\u2019s look at this formula. First of all, if we go very far out in r , only the p \u00a8 term counts. The direction of B is given by p \u00a8 \u00d7r , which is at right angles to the radius r and also at right angles to the acceleration, as in Fig. 21-4. Everything is coming out right; that is also the result we get from Eq. (21.1\u00b4). Now let\u2019s look at what we are not used to\u2014at what happens closer in. In Section 14-7 we worked out the law of Biot and Savart for the magnetic field of an element of current. We found that a current element jdV contributes to the magnetic field the amount dB= 1 4\u03c0 \u03f5 0 c 2 j\u00d7r r 3 dV. (21.24) You see that this formula looks very much like the first term of Eq. (21.23), if we remember that p \u02d9 is the current. But there is one difference. In Eq. (21.23), the current is to be evaluated at the time (t\u2212r/c) , which doesn\u2019t appear in Eq. (21.24). Actually, however, Eq. (21.24) is still very good for small r , because the second term of Eq. (21.23) tends to cancel out the effect of the retardation in the first term. The two together give a result very near to Eq. (21.24) when r is small. We can see that this way: When r is small, (t\u2212r/c) is not very different from t , so we can expand the bracket in Eq. (21.23) in a Taylor series. For the first term, p \u02d9 (t\u2212r/c)= p \u02d9 (t)\u2212 r c p \u00a8 (t)+etc., r and to the same order in r/c , r c p \u00a8 (t\u2212r/c)= r c p \u00a8 (t)+etc. r r When we take the sum, the two terms in p \u00a8 cancel, and we are left with the unretarded current p \u02d9 : that is, p \u02d9 (t) \u2014plus terms of order (r/c ) 2 or higher [e.g., 1 2 (r/c ) 2 p ... ] which will be very small for r small enough that p \u02d9 does not alter markedly in the time r/c . So Eq. (21.23) gives fields very much like the instantaneous theory\u2014much closer than the instantaneous theory with a delay; the first-order effects of the delay are taken out by the second term. The static formulas are very accurate, much more accurate than you might think. Of course, the compensation only works for points close in. For points far out the correction becomes very bad, because the time delays produce a very large effect, and we get the important 1/r term of the radiation. We still have the problem of computing the electric field and demonstrating that it is the same as Eq. (21.1\u00b4). For large distances we can see that the answer is going to come out all right. We know that far from the sources, where we have a propagating wave, E is perpendicular to B (and also to r ), as in Fig. 21-4, and that cB=E . So E is proportional to the acceleration p \u00a8 , as expected from Eq. (21.1\u00b4). To get the electric field completely for all distances, we need to solve for the electrostatic potential. When we computed the current integral for A to get Eq. (21.18), we made an approximation by disregarding the slight variation of r in the delay terms. This will not work for the electrostatic potential, because we would then get 1/r times the integral of the charge density, which is a constant. This approximation is too rough. We need to go to one higher order. Instead of getting involved in that higher-order computation directly, we can do something else\u2014we can determine the scalar potential from Eq. (21.6), using the vector potential we have already found. The divergence of A , in our case, is just \u2202 A z /\u2202z \u2014since A x and A y are identically zero. Differentiating in the same way that we did above to find B , \u2207\u22c5A = 1 4\u03c0 \u03f5 0 c 2 [ p \u02d9 (t\u2212r/c) \u2202 \u2202z ( 1 r )+ 1 r \u2202 \u2202z p \u02d9 (t\u2212r/c)] = 1 4\u03c0 \u03f5 0 c 2 [\u2212 z p \u02d9 (t\u2212r/c) r 3 \u2212 z p \u00a8 (t\u2212r/c) c r 2 ]. Or, in vector notation, \u2207\u22c5A=\u2212 1 4\u03c0 \u03f5 0 c 2 [ p \u02d9 +(r/c) p \u00a8 ] t\u2212r/c \u22c5r r 3 . Using Eq. (21.6), we have an equation for \u03d5 : \u2202\u03d5 \u2202t = 1 4\u03c0 \u03f5 0 [ p \u02d9 +(r/c) p \u00a8 ] t\u2212r/c \u22c5r r 3 . Integrating with respect to t just removes one dot from each of the p 's, so \u03d5(r,t)= 1 4\u03c0 \u03f5 0 [p+(r/c) p \u02d9 ] t\u2212r/c \u22c5r r 3 . (21.25) (The constant of integration would correspond to some superposed static field which could, of course, exist. For the oscillating dipole we have taken, there is no static field.) We are now able to find the electric field E from E=\u2212\u2207\u03d5\u2212 \u2202A \u2202t . \u2202 A Since the steps are tedious but straightforward [providing you remember that p(t\u2212r/c) and its time derivatives depend on x , y , and z through the retardation r/c ], we will just give the result: E(r,t)= 1 4\u03c0 \u03f5 0 r 3 [ 3( p \u2217 \u22c5r)r r 2 \u2212 p \u2217 + 1 c 2 { p \u00a8 (t\u2212r/c)\u00d7r}\u00d7r] (21.26) with p \u2217 =p(t\u2212r/c)+ r c p \u02d9 (t\u2212r/c). (21.27) Although it looks rather complicated, the result is easily interpreted. The vector p \u2217 is the dipole moment retarded and then \u201ccorrected\u201d for the retardation, so the two terms with p \u2217 give just the static dipole field when r is small. [See Chapter 6, Eq. (6.14).] When r is large, the term in p \u00a8 dominates, and the electric field is proportional to the acceleration of the charges, at right angles to r , and, in fact, directed along the projection of p \u00a8 in a plane perpendicular to r . This result agrees with what we would have gotten using Eq. (21.1). Of course, Eq. (21.1) is more general; it works with any motion, while Eq. (21.26) is valid only for small motions for which we can take the retardation r/c as constant over the source. At any rate, we have now provided the underpinnings for our entire previous discussion of light (excepting some matters discussed in Chapter 34 of Vol. I), for it all hinged on the last term of Eq. (21.26). We will discuss next how the fields can be obtained for more rapidly moving charges (leading to the relativistic effects of Chapter 34 of Vol. I). In the last section we made a simplification in calculating our integral for A by considering only low velocities. But in doing so we missed an important point and also one where it is easy to go wrong. We will therefore take up now a calculation of the potentials for a point charge moving in any way whatever\u2014even with a relativistic velocity. Once we have this result, we will have the complete electromagnetism of electric charges. Even Eq. (21.1) can then be derived by taking derivatives. The story will be complete. So bear with us. Let\u2019s try to calculate the scalar potential \u03d5(1) at the point ( x 1 , y 1 , z 1 ) produced by a point charge, such as an electron, moving in any manner whatsoever. By a \u201cpoint\u201d charge we mean a very small ball of charge, shrunk down as small as you like, with a charge density \u03c1(x,y,z) . We can find \u03d5 from Eq. (21.15): \u03d5(1,t)= 1 4\u03c0 \u03f5 0 \u222b \u03c1(2,t\u2212 r 12 /c) r 12 d V 2 . (21.28) The answer would seem to be\u2014and almost everyone would, at first, think\u2014that the integral of \u03c1 over such a \u201cpoint\u201d charge is just the total charge q , so that \u03d5(1,t)= 1 4\u03c0 \u03f5 0 q r \u2032 12 (wrong). 1 By r \u2032 12 we mean the radius vector from the charge at point (2) to point (1) at the retarded time (t\u2212 r 12 /c) . It is wrong. The correct answer is \u03d5(1,t)= 1 4\u03c0 \u03f5 0 q r \u2032 12 \u22c5 1 1\u2212 v r \u2032 /c , (21.29) where v r \u2032 , is the component of the velocity of the charge parallel to r \u2032 12 \u2014namely, toward point (1) . We will now show you why. To make the argument easier to follow, we will make the calculation first for a \u201cpoint\u201d charge which is in the form of a little cube of charge moving toward the point (1) with the speed v , as shown in Fig. 21-5(a). Let the length of a side of the cube be a , which we take to be much, much less than r 12 , the distance from the center of the charge to the point (1) . Now to evaluate the integral of Eq. (21.28), we will return to basic principles; we will write it as the sum \u2211 i \u03c1 i \u0394 V i r i , (21.30) where r i is the distance from point (1) to the i th volume element \u0394 V i and \u03c1 i is the charge density at \u0394 V i at the time t i =t\u2212 r i /c . Since r i \u226ba , always, it will be convenient to take our \u0394 V i in the form of thin, rectangular slices perpendicular to r 12 , as shown in Fig. 21-5(b). Suppose we start by taking the volume elements \u0394 V i with some thickness w much less than a . The individual elements will appear as shown in Fig. 21-6(a), where we have put in more than enough to cover the charge. But we have not shown the charge, and for a good reason. Where should we draw it? For each volume element \u0394 V i we are to take \u03c1 at the time t i =(t\u2212 r i /c) , but since the charge is moving, it is in a different place for each volume element \u0394 V i ! Let\u2019s say that we begin with the volume element labeled \u201c1\u201d in Fig. 21-6(a), chosen so that at the time t 1 =(t\u2212 r 1 /c) the \u201cback\u201d edge of the charge occupies \u0394 V 1 , as shown in Fig. 21-6(b). Then when we evaluate \u03c1 2 \u0394 V 2 , we must use the position of the charge at the slightly later time t 2 =(t\u2212 r 2 /c) , when the charge will be in the position shown in Fig. 21-6(c). And so on, for \u0394 V 3 , \u0394 V 4 , etc. Now we can evaluate the sum. Since the thickness of each \u0394 V i is w , its volume is w a 2 . Then each volume element that overlaps the charge distribution contains the amount of charge w a 2 \u03c1 , where \u03c1 is the density of charge within the cube\u2014which we take to be uniform. When the distance from the charge to point (1) is large, we will make a negligible error by setting all the r i \u2019s in the denominators equal to some average value, say the retarded position r \u2032 of the center of the charge. Then the sum (21.30) is \u2211 i=1 N \u03c1w a 2 r \u2032 , N where \u0394 V N is the last \u0394 V i that overlaps the charge distributions, as shown in Fig. 21-6(e). The sum is, clearly, N \u03c1w a 2 r \u2032 = \u03c1 a 3 r \u2032 ( Nw a ). 2 3 Now \u03c1 a 3 is just the total charge q and Nw is the length b shown in part (e) of the figure. So we have \u03d5= q 4\u03c0 \u03f5 0 r \u2032 ( b a ). (21.31) What is b ? It is the length of the cube of charge increased by the distance moved by the charge between t 1 =(t\u2212 r 1 /c) and t N =(t\u2212 r N /c) \u2014which is the distance the charge moves in the time \u0394t= t N \u2212 t 1 =( r 1 \u2212 r N )/c=b/c. ( ) / b / Since the speed of the charge is v , the distance moved is v\u0394t=vb/c . But the length b is this distance added to a : b=a+ v c b. v Solving for b , we get b= a 1\u2212(v/c) . a Of course by v we mean the velocity at the retarded time t \u2032 =(t\u2212 r \u2032 /c) , which we can indicate by writing [1\u2212v/c ] ret , and Eq. (21.31) for the potential becomes \u03d5(1,t)= q 4\u03c0 \u03f5 0 r \u2032 1 [1\u2212(v/c) ] ret . 1 This result agrees with our assertion, Eq. (21.29). There is a correction term which comes about because the charge is moving as our integral \u201csweeps over the charge.\u201d When the charge is moving toward the point (1) , its contribution to the integral is increased by the ratio b/a . Therefore the correct integral is q/ r \u2032 multiplied by b/a , which is 1/[1\u2212v/c ] ret . If the velocity of the charge is not directed toward the observation point (1) , you can see that what matters is the component of its velocity toward point (1) . Calling this velocity component v r , the correction factor is 1/[1\u2212 v r /c ] ret . Also, the analysis we have made goes exactly the same way for a charge distribution of any shape\u2014it doesn\u2019t have to be a cube. Finally, since the \u201csize\u201d of the charge q doesn\u2019t enter into the final result, the same result holds when we let the charge shrink to any size\u2014even to a point. The general result is that the scalar potential for a point charge moving with any velocity is \u03d5(1,t)= q 4\u03c0 \u03f5 0 r \u2032 [1\u2212( v r /c) ] ret . (21.32) This equation is often written in the equivalent form \u03d5(1,t)= q 4\u03c0 \u03f5 0 [r\u2212(v\u22c5r/c) ] ret , (21.33) where r is the vector from the charge to the point (1) , where \u03d5 is being evaluated, and all the quantities in the bracket are to have their values at the retarded time t \u2032 =t\u2212 r \u2032 /c . The same thing happens when we compute A for a point charge, from Eq. (21.16). The current density is \u03c1v and the integral over \u03c1 is the same as we found for \u03d5 . The vector potential is A(1,t)= q v ret 4\u03c0 \u03f5 0 c 2 [r\u2212(v\u22c5r/c) ] ret . (21.34) The potentials for a point charge were first deduced in this form by Li\u00e9nard and Wiechert and are called the Li\u00e9nard-Wiechert potentials. To close the ring back to Eq. (21.1) it is only necessary to compute E and B from these potentials (using B=\u2207\u00d7A and E=\u2212\u2207\u03d5\u2212\u2202A/\u2202t ). It is now only arithmetic. The arithmetic, however, is fairly involved, so we will not write out the details. Perhaps you will take our word for it that Eq. (21.1) is equivalent to the Li\u00e9nard-Wiechert potentials we have derived.2 We want next to use the Li\u00e9nard-Wiechert potentials for a special case\u2014to find the fields of a charge moving with uniform velocity in a straight line. We will do it again later, using the principle of relativity. We already know what the potentials are when we are standing in the rest frame of a charge. When the charge is moving, we can figure everything out by a relativistic transformation from one system to the other. But relativity had its origin in the theory of electricity and magnetism. The formulas of the Lorentz transformation (Chapter 15, Vol. I) were discoveries made by Lorentz when he was studying the equations of electricity and magnetism. So that you can appreciate where things have come from, we would like to show that the Maxwell equations do lead to the Lorentz transformation. We begin by calculating the potentials of a charge moving with uniform velocity, directly from the electrodynamics of Maxwell\u2019s equations. We have shown that Maxwell\u2019s equations lead to the potentials for a moving charge that we got in the last section. So when we use these potentials, we are using Maxwell\u2019s theory. Suppose we have a charge moving along the x -axis with the speed v . We want the potentials at the point P(x,y,z) , as shown in Fig. 21-7. If t=0 is the moment when the charge is at the origin, at the time t the charge is at x=vt , y=z=0 . What we need to know, however, is its position at the retarded time t \u2032 =t\u2212 r \u2032 c , (21.35) where r \u2032 is the distance to the point P from the charge at the retarded time. At the earlier time t \u2032 , the charge was at x=v t \u2032 , so r \u2032 = (x\u2212v t \u2032 ) 2 + y 2 + z 2 \u2212 \u2212 \u2212 \u2212 \u2212 \u2212 \u2212 \u2212 \u2212 \u2212 \u2212 \u2212 \u2212 \u2212 \u2212 \u2212 \u221a . (21.36) To find r \u2032 or t \u2032 we have to combine this equation with Eq. (21.35). First, we eliminate r \u2032 by solving Eq. (21.35) for r \u2032 and substituting in Eq. (21.36). Then, squaring both sides, we get c 2 (t\u2212 t \u2032 ) 2 =(x\u2212v t \u2032 ) 2 + y 2 + z 2 , 2 2 which is a quadratic equation in t \u2032 . Expanding the squared binomials and collecting like terms in t \u2032 , we get ( v 2 \u2212 c 2 ) t \u20322 \u22122(xv\u2212 c 2 t) t \u2032 + x 2 + y 2 + z 2 \u2212(ct ) 2 =0. 2 Solving for t \u2032 , (1\u2212 v 2 c 2 ) t \u2032 = t\u2212 vx c 2 \u2212 1 c (x\u2212vt ) 2 +(1\u2212 v 2 c 2 )( y 2 + z 2 ) \u2212 \u2212 \u2212 \u2212 \u2212 \u2212 \u2212 \u2212 \u2212 \u2212 \u2212 \u2212 \u2212 \u2212 \u2212 \u2212 \u2212 \u2212 \u2212 \u2212 \u2212 \u2212 \u2212 \u2212 \u2212 \u221a . (21.37) To get r \u2032 we have to substitute this expression for t \u2032 into r \u2032 =c(t\u2212 t \u2032 ). \u2032 \u2032 Now we are ready to find \u03d5 from Eq. (21.33), which, since v is constant, becomes \u03d5(x,y,z,t)= q 4\u03c0 \u03f5 0 1 r \u2032 \u2212(v\u22c5 r \u2032 /c) . (21.38) The component of v in the direction of r \u2032 is v\u00d7(x\u2212v t \u2032 )/ r \u2032 , so v\u22c5 r \u2032 is just v\u00d7(x\u2212v t \u2032 ) , and the whole denominator is c(t\u2212 t \u2032 )\u2212 v c (x\u2212v t \u2032 )=c[t\u2212 vx c 2 \u2212(1\u2212 v 2 c 2 ) t \u2032 ]. 2 Substituting for (1\u2212 v 2 / c 2 ) t \u2032 from Eq. (21.37), we get for \u03d5 \u03d5(x,y,z,t)= q 4\u03c0 \u03f5 0 1 (x\u2212vt ) 2 +(1\u2212 v 2 c 2 )( y 2 + z 2 ) \u2212 \u2212 \u2212 \u2212 \u2212 \u2212 \u2212 \u2212 \u2212 \u2212 \u2212 \u2212 \u2212 \u2212 \u2212 \u2212 \u2212 \u2212 \u2212 \u2212 \u2212 \u2212 \u2212 \u2212 \u2212 \u221a . This equation is more understandable if we rewrite it as \u03d5(x,y,z,t)= q 4\u03c0 \u03f5 0 1 1\u2212 v 2 c 2 \u2212 \u2212 \u2212 \u2212 \u2212 \u221a 1 [( x\u2212vt 1\u2212 v 2 / c 2 \u2212 \u2212 \u2212 \u2212 \u2212 \u2212 \u2212 \u221a ) 2 + y 2 + z 2 ] 1/2 . (21.39) The vector potential A is the same expression with an additional factor of v/ c 2 : A= v c 2 \u03d5. v In Eq. (21.39) you can clearly see the beginning of the Lorentz transformation. If the charge were at the origin in its own rest frame, its potential would be \u03d5(x,y,z)= q 4\u03c0 \u03f5 0 1 [ x 2 + y 2 + z 2 ] 1/2 . 1 We are seeing it in a moving coordinate system, and it appears that the coordinates should be transformed by x\u2192 x\u2212vt 1\u2212 v 2 / c 2 \u2212 \u2212 \u2212 \u2212 \u2212 \u2212 \u2212 \u2212 \u221a , y\u2192y, z\u2192z. That is just the Lorentz transformation, and what we have done is essentially the way Lorentz discovered it. But what about that extra factor 1/ 1\u2212 v 2 / c 2 \u2212 \u2212 \u2212 \u2212 \u2212 \u2212 \u2212 \u2212 \u221a that appears at the front of Eq. (21.39)? Also, how does the vector potential A appear, when it is everywhere zero in the rest frame of the particle? We will soon show that (when c=1 ) A and \u03d5 together constitute a four-vector, like the momentum p and the total energy U of a particle. The extra 1/ 1\u2212 v 2 / c 2 \u2212 \u2212 \u2212 \u2212 \u2212 \u2212 \u2212 \u2212 \u221a in Eq. (21.39) is the same factor that always comes in when one transforms the components of a four-vector\u2014just as the charge density \u03c1 transforms to \u03c1/ 1\u2212 v 2 / c 2 \u2212 \u2212 \u2212 \u2212 \u2212 \u2212 \u2212 \u2212 \u221a . In fact, it is almost apparent from Eqs. (21.4) and (21.5) that A and \u03d5/c are components of a four-vector, because we have already shown in Chapter 13 that j and c\u03c1 are the components of a four-vector. Later we will take up in more detail the relativity of electrodynamics; here we only wished to show how naturally the Maxwell equations lead to the Lorentz transformation. You will not, then, be surprised to find that the laws of electricity and magnetism are already correct for Einstein\u2019s relativity. We will not have to \u201cfix them up,\u201d as we had to do for Newton\u2019s laws of mechanics."
    },
    {
        "input": "Conservation of Momentum",
        "output": "On the basis of Newton\u2019s second law of motion, which gives the relation between the acceleration of any body and the force acting on it, any problem in mechanics can be solved in principle. For example, to determine the motion of a few particles, one can use the numerical method developed in the preceding chapter. But there are good reasons to make a further study of Newton\u2019s laws. First, there are quite simple cases of motion which can be analyzed not only by numerical methods, but also by direct mathematical analysis. For example, although we know that the acceleration of a falling body is 32 ft/sec\u00b2, and from this fact could calculate the motion by numerical methods, it is much easier and more satisfactory to analyze the motion and find the general solution, s=s0+v0t+16t2 . In the same way, although we can work out the positions of a harmonic oscillator by numerical methods, it is also possible to show analytically that the general solution is a simple cosine function of t , and so it is unnecessary to go to all that arithmetical trouble when there is a simple and more accurate way to get the result. In the same manner, although the motion of one body around the sun, determined by gravitation, can be calculated point by point by the numerical methods of Chapter 9, which show the general shape of the orbit, it is nice also to get the exact shape, which analysis reveals as a perfect ellipse. Unfortunately, there are really very few problems which can be solved exactly by analysis. In the case of the harmonic oscillator, for example, if the spring force is not proportional to the displacement, but is something more complicated, one must fall back on the numerical method. Or if there are two bodies going around the sun, so that the total number of bodies is three, then analysis cannot produce a simple formula for the motion, and in practice the problem must be done numerically. That is the famous three-body problem, which so long challenged human powers of analysis; it is very interesting how long it took people to appreciate the fact that perhaps the powers of mathematical analysis were limited and it might be necessary to use the numerical methods. Today an enormous number of problems that cannot be done analytically are solved by numerical methods, and the old three-body problem, which was supposed to be so difficult, is solved as a matter of routine in exactly the same manner that was described in the preceding chapter, namely, by doing enough arithmetic. However, there are also situations where both methods fail: the simple problems we can do by analysis, and the moderately difficult problems by numerical, arithmetical methods, but the very complicated problems we cannot do by either method. A complicated problem is, for example, the collision of two automobiles, or even the motion of the molecules of a gas. There are countless particles in a cubic millimeter of gas, and it would be ridiculous to try to make calculations with so many variables (about 1017 \u2014a hundred million billion). Anything like the motion of the molecules or atoms of a gas or a block of iron, or the motion of the stars in a globular cluster, instead of just two or three planets going around the sun\u2014such problems we cannot do directly, so we have to seek other means. In the situations in which we cannot follow details, we need to know some general properties, that is, general theorems or principles which are consequences of Newton\u2019s laws. One of these is the principle of conservation of energy, which was discussed in Chapter 4. Another is the principle of conservation of momentum, the subject of this chapter. Another reason for studying mechanics further is that there are certain patterns of motion that are repeated in many different circumstances, so it is good to study these patterns in one particular circumstance. For example, we shall study collisions; different kinds of collisions have much in common. In the flow of fluids, it does not make much difference what the fluid is, the laws of the flow are similar. Other problems that we shall study are vibrations and oscillations and, in particular, the peculiar phenomena of mechanical waves\u2014sound, vibrations of rods, and so on. In our discussion of Newton\u2019s laws it was explained that these laws are a kind of program that says \u201cPay attention to the forces,\u201d and that Newton told us only two things about the nature of forces. In the case of gravitation, he gave us the complete law of the force. In the case of the very complicated forces between atoms, he was not aware of the right laws for the forces; however, he discovered one rule, one general property of forces, which is expressed in his Third Law, and that is the total knowledge that Newton had about the nature of forces\u2014the law of gravitation and this principle, but no other details. This principle is that action equals reaction. What is meant is something of this kind: Suppose we have two small bodies, say particles, and suppose that the first one exerts a force on the second one, pushing it with a certain force. Then, simultaneously, according to Newton\u2019s Third Law, the second particle will push on the first with an equal force, in the opposite direction; furthermore, these forces effectively act in the same line. This is the hypothesis, or law, that Newton proposed, and it seems to be quite accurate, though not exact (we shall discuss the errors later). For the moment we shall take it to be true that action equals reaction. Of course, if there is a third particle, not on the same line as the other two, the law does not mean that the total force on the first one is equal to the total force on the second, since the third particle, for instance, exerts its own push on each of the other two. The result is that the total effect on the first two is in some other direction, and the forces on the first two particles are, in general, neither equal nor opposite. However, the forces on each particle can be resolved into parts, there being one contribution or part due to each other interacting particle. Then each pair of particles has corresponding components of mutual interaction that are equal in magnitude and opposite in direction. Now what are the interesting consequences of the above relationship? Suppose, for simplicity, that we have just two interacting particles, possibly of different mass, and numbered 1 and 2 . The forces between them are equal and opposite; what are the consequences? According to Newton\u2019s Second Law, force is the time rate of change of the momentum, so we conclude that the rate of change of momentum p1 of particle 1 is equal to minus the rate of change of momentum p2 of particle 2 , or dp1/dt=\u2212dp2/dt. Now if the rate of change is always equal and opposite, it follows that the total change in the momentum of particle 1 is equal and opposite to the total change in the momentum of particle 2 ; this means that if we add the momentum of particle 1 to the momentum of particle 2 , the rate of change of the sum of these, due to the mutual forces (called internal forces) between particles, is zero; that is d(p1+p2)/dt=0. There is assumed to be no other force in the problem. If the rate of change of this sum is always zero, that is just another way of saying that the quantity (p1+p2) does not change. (This quantity is also written m1v1+m2v2 , and is called the total momentum of the two particles.) We have now obtained the result that the total momentum of the two particles does not change because of any mutual interactions between them. This statement expresses the law of conservation of momentum in that particular example. We conclude that if there is any kind of force, no matter how complicated, between two particles, and we measure or calculate m1v1+m2v2 , that is, the sum of the two momenta, both before and after the forces act, the results should be equal, i.e., the total momentum is a constant. If we extend the argument to three or more interacting particles in more complicated circumstances, it is evident that so far as internal forces are concerned, the total momentum of all the particles stays constant, since an increase in momentum of one, due to another, is exactly compensated by the decrease of the second, due to the first. That is, all the internal forces will balance out, and therefore cannot change the total momentum of the particles. Then if there are no forces from the outside (external forces), there are no forces that can change the total momentum; hence the total momentum is a constant. It is worth describing what happens if there are forces that do not come from the mutual actions of the particles in question: suppose we isolate the interacting particles. If there are only mutual forces, then, as before, the total momentum of the particles does not change, no matter how complicated the forces. On the other hand, suppose there are also forces coming from the particles outside the isolated group. Any force exerted by outside bodies on inside bodies, we call an external force. We shall later demonstrate that the sum of all external forces equals the rate of change of the total momentum of all the particles inside, a very useful theorem. The conservation of the total momentum of a number of interacting particles can be expressed as m1v1+m2v2+m3v3+\u22ef=a constant, if there are no net external forces. Here the masses and corresponding velocities of the particles are numbered 1 , 2 , 3 , 4 , \u2026 The general statement of Newton\u2019s Second Law for each particle, F= d dt (mv), is true specifically for the components of force and momentum in any given direction; thus the x -component of the force on a particle is equal to the x -component of the rate of change of momentum of that particle, or Fx= d dt (mvx), and similarly for the y - and z -directions. Therefore Eq. (10.3) is really three equations, one for each direction. In addition to the law of conservation of momentum, there is another interesting consequence of Newton\u2019s Second Law, to be proved later, but merely stated now. This principle is that the laws of physics will look the same whether we are standing still or moving with a uniform speed in a straight line. For example, a child bouncing a ball in an airplane finds that the ball bounces the same as though he were bouncing it on the ground. Even though the airplane is moving with a very high velocity, unless it changes its velocity, the laws look the same to the child as they do when the airplane is standing still. This is the so-called relativity principle. As we use it here we shall call it \u201cGalilean relativity\u201d to distinguish it from the more careful analysis made by Einstein, which we shall study later. We have just derived the law of conservation of momentum from Newton\u2019s laws, and we could go on from here to find the special laws that describe impacts and collisions. But for the sake of variety, and also as an illustration of a kind of reasoning that can be used in physics in other circumstances where, for example, one might not know Newton\u2019s laws and might take a different approach, we shall discuss the laws of impacts and collisions from a completely different point of view. We shall base our discussion on the principle of Galilean relativity, stated above, and shall end up with the law of conservation of momentum. We shall start by assuming that nature would look the same if we run along at a certain speed and watch it as it would if we were standing still. Before discussing collisions in which two bodies collide and stick together, or come together and bounce apart, we shall first consider two bodies that are held together by a spring or something else, and are then suddenly released and pushed by the spring or perhaps by a little explosion. Further, we shall consider motion in only one direction. First, let us suppose that the two objects are exactly the same, are nice symmetrical objects, and then we have a little explosion between them. After the explosion, one of the bodies will be moving, let us say toward the right, with a velocity v . Then it appears reasonable that the other body is moving toward the left with a velocity v , because if the objects are alike there is no reason for right or left to be preferred and so the bodies would do something that is symmetrical. This is an illustration of a kind of thinking that is very useful in many problems but would not be brought out if we just started with the formulas. The first result from our experiment is that equal objects will have equal speed, but now suppose that we have two objects made of different materials, say copper and aluminum, and we make the two masses equal. We shall now suppose that if we do the experiment with two masses that are equal, even though the objects are not identical, the velocities will be equal. Someone might object: \u201cBut you know, you could do it backwards, you did not have to suppose that. You could define equal masses to mean two masses that acquire equal velocities in this experiment.\u201d We follow that suggestion and make a little explosion between the copper and a very large piece of aluminum, so heavy that the copper flies out and the aluminum hardly budges. That is too much aluminum, so we reduce the amount until there is just a very tiny piece, then when we make the explosion the aluminum goes flying away, and the copper hardly budges. That is not enough aluminum. Evidently there is some right amount in between; so we keep adjusting the amount until the velocities come out equal. Very well then\u2014let us turn it around, and say that when the velocities are equal, the masses are equal. This appears to be just a definition, and it seems remarkable that we can transform physical laws into mere definitions. Nevertheless, there are some physical laws involved, and if we accept this definition of equal masses, we immediately find one of the laws, as follows. Suppose we know from the foregoing experiment that two pieces of matter, A and B (of copper and aluminum), have equal masses, and we compare a third body, say a piece of gold, with the copper in the same manner as above, making sure that its mass is equal to the mass of the copper. If we now make the experiment between the aluminum and the gold, there is nothing in logic that says these masses must be equal; however, the experiment shows that they actually are. So now, by experiment, we have found a new law. A statement of this law might be: If two masses are each equal to a third mass (as determined by equal velocities in this experiment), then they are equal to each other. (This statement does not follow at all from a similar statement used as a postulate regarding mathematical quantities.) From this example we can see how quickly we start to infer things if we are careless. It is not just a definition to say the masses are equal when the velocities are equal, because to say the masses are equal is to imply the mathematical laws of equality, which in turn makes a prediction about an experiment. As a second example, suppose that A and B are found to be equal by doing the experiment with one strength of explosion, which gives a certain velocity; if we then use a stronger explosion, will it be true or not true that the velocities now obtained are equal? Again, in logic there is nothing that can decide this question, but experiment shows that it is true. So, here is another law, which might be stated: If two bodies have equal masses, as measured by equal velocities at one velocity, they will have equal masses when measured at another velocity. From these examples we see that what appeared to be only a definition really involved some laws of physics. In the development that follows we shall assume it is true that equal masses have equal and opposite velocities when an explosion occurs between them. We shall make another assumption in the inverse case: If two identical objects, moving in opposite directions with equal velocities, collide and stick together by some kind of glue, then which way will they be moving after the collision? This is again a symmetrical situation, with no preference between right and left, so we assume that they stand still. We shall also suppose that any two objects of equal mass, even if the objects are made of different materials, which collide and stick together, when moving with the same velocity in opposite directions will come to rest after the collision. We can verify the above assumptions experimentally: first, that if two stationary objects of equal mass are separated by an explosion they will move apart with the same speed, and second, if two objects of equal mass, coming together with the same speed, collide and stick together they will stop. This we can do by means of a marvelous invention called an air trough,1 which gets rid of friction, the thing which continually bothered Galileo (Fig. 10\u20131). He could not do experiments by sliding things because they do not slide freely, but, by adding a magic touch, we can today get rid of friction. Our objects will slide without difficulty, on and on at a constant velocity, as advertised by Galileo. This is done by supporting the objects on air. Because air has very low friction, an object glides along with practically constant velocity when there is no applied force. First, we use two glide blocks which have been made carefully to have the same weight, or mass (their weight was measured really, but we know that this weight is proportional to the mass), and we place a small explosive cap in a closed cylinder between the two blocks (Fig. 10\u20132). We shall start the blocks from rest at the center point of the track and force them apart by exploding the cap with an electric spark. What should happen? If the speeds are equal when they fly apart, they should arrive at the ends of the trough at the same time. On reaching the ends they will both bounce back with practically opposite velocity, and will come together and stop at the center where they started. It is a good test; when it is actually done the result is just as we have described (Fig. 10\u20133). Now the next thing we would like to figure out is what happens in a less simple situation. Suppose we have two equal masses, one moving with velocity v and the other standing still, and they collide and stick; what is going to happen? There is a mass 2m altogether when we are finished, drifting with an unknown velocity. What velocity? That is the problem. To find the answer, we make the assumption that if we ride along in a car, physics will look the same as if we are standing still. We start with the knowledge that two equal masses, moving in opposite directions with equal speeds v , will stop dead when they collide. Now suppose that while this happens, we are riding by in an automobile, at a velocity \u2212v . Then what does it look like? Since we are riding along with one of the two masses which are coming together, that one appears to us to have zero velocity. The other mass, however, going the other way with velocity v , will appear to be coming toward us at a velocity 2v (Fig. 10\u20134). Finally, the combined masses after collision will seem to be passing by with velocity v . We therefore conclude that an object with velocity 2v , hitting an equal one at rest, will end up with velocity v , or what is mathematically exactly the same, an object with velocity v hitting and sticking to one at rest will produce an object moving with velocity v/2 . Note that if we multiply the mass and the velocity beforehand and add them together, mv+0 , we get the same answer as when we multiply the mass and the velocity of everything afterwards, 2m times v/2 . So that tells us what happens when a mass of velocity v hits one standing still. In exactly the same manner we can deduce what happens when equal objects having any two velocities hit each other. Suppose we have two equal bodies with velocities v 1 and v 2 , respectively, which collide and stick together. What is their velocity v after the collision? Again we ride by in an automobile, say at velocity v 2 , so that one body appears to be at rest. The other then appears to have a velocity v 1 \u2212 v 2 , and we have the same case that we had before. When it is all finished they will be moving at 1 2 ( v 1 \u2212 v 2 ) with respect to the car. What then is the actual speed on the ground? It is v= 1 2 ( v 1 \u2212 v 2 )+ v 2 or 1 2 ( v 1 + v 2 ) (Fig. 10\u20135). Again we note that m v 1 +m v 2 =2m( v 1 + v 2 )/2. (10.6) Thus, using this principle, we can analyze any kind of collision in which two bodies of equal mass hit each other and stick. In fact, although we have worked only in one dimension, we can find out a great deal about much more complicated collisions by imagining that we are riding by in a car in some oblique direction. The principle is the same, but the details get somewhat complicated. In order to test experimentally whether an object moving with velocity v , colliding with an equal one at rest, forms an object moving with velocity v/2 , we may perform the following experiment with our air-trough apparatus. We place in the trough three equally massive objects, two of which are initially joined together with our explosive cylinder device, the third being very near to but slightly separated from these and provided with a sticky bumper so that it will stick to another object which hits it. Now, a moment after the explosion, we have two objects of mass m moving with equal and opposite velocities v . A moment after that, one of these collides with the third object and makes an object of mass 2m moving, so we believe, with velocity v/2 . How do we test whether it is really v/2 ? By arranging the initial positions of the masses on the trough so that the distances to the ends are not equal, but are in the ratio 2:1 . Thus our first mass, which continues to move with velocity v , should cover twice as much distance in a given time as the two which are stuck together (allowing for the small distance travelled by the second object before it collided with the third). The mass m and the mass 2m should reach the ends at the same time, and when we try it, we find that they do (Fig. 10\u20136). The next problem that we want to work out is what happens if we have two different masses. Let us take a mass m and a mass 2m and apply our explosive interaction. What will happen then? If, as a result of the explosion, m moves with velocity v , with what velocity does 2m move? The experiment we have just done may be repeated with zero separation between the second and third masses, and when we try it we get the same result, namely, the reacting masses m and 2m attain velocities \u2212v and v/2 . Thus the direct reaction between m and 2m gives the same result as the symmetrical reaction between m and m , followed by a collision between m and a third mass m in which they stick together. Furthermore, we find that the masses m and 2m returning from the ends of the trough, with their velocities (nearly) exactly reversed, stop dead if they stick together. Now the next question we may ask is this. What will happen if a mass m with velocity v , say, hits and sticks to another mass 2m at rest? This is very easy to answer using our principle of Galilean relativity, for we simply watch the collision which we have just described from a car moving with velocity \u2212v/2 (Fig. 10\u20137). From the car, the velocities are v \u2032 1 =v\u2212v(car)=v+v/2=3v/2 \u2032 and v \u2032 2 =\u2212v/2\u2212v(car)=\u2212v/2+v/2=0. \u2032 After the collision, the mass 3m appears to us to be moving with velocity v/2 . Thus we have the answer, i.e., the ratio of velocities before and after collision is 3 to 1 : if an object of mass m collides with a stationary object of mass 2m , then the whole thing moves off, stuck together, with a velocity 1/3 as much. The general rule again is that the sum of the products of the masses and the velocities stays the same: mv+0 equals 3m times v/3 , so we are gradually building up the theorem of the conservation of momentum, piece by piece. Now we have one against two. Using the same arguments, we can predict the result of one against three, two against three, etc. The case of two against three, starting from rest, is shown in Fig. 10\u20138. In every case we find that the mass of the first object times its velocity, plus the mass of the second object times its velocity, is equal to the total mass of the final object times its velocity. These are all examples, then, of the conservation of momentum. Starting from simple, symmetrical cases, we have demonstrated the law for more complex cases. We could, in fact, do it for any rational mass ratio, and since every ratio is exceedingly close to a rational ratio, we can handle every ratio as precisely as we wish. All the foregoing examples are simple cases where the bodies collide and stick together, or were initially stuck together and later separated by an explosion. However, there are situations in which the bodies do not cohere, as, for example, two bodies of equal mass which collide with equal speeds and then rebound. For a brief moment they are in contact and both are compressed. At the instant of maximum compression they both have zero velocity and energy is stored in the elastic bodies, as in a compressed spring. This energy is derived from the kinetic energy the bodies had before the collision, which becomes zero at the instant their velocity is zero. The loss of kinetic energy is only momentary, however. The compressed condition is analogous to the cap that releases energy in an explosion. The bodies are immediately decompressed in a kind of explosion, and fly apart again; but we already know that case\u2014the bodies fly apart with equal speeds. However, this speed of rebound is less, in general, than the initial speed, because not all the energy is available for the explosion, depending on the material. If the material is putty no kinetic energy is recovered, but if it is something more rigid, some kinetic energy is usually regained. In the collision the rest of the kinetic energy is transformed into heat and vibrational energy\u2014the bodies are hot and vibrating. The vibrational energy also is soon transformed into heat. It is possible to make the colliding bodies from highly elastic materials, such as steel, with carefully designed spring bumpers, so that the collision generates very little heat and vibration. In these circumstances the velocities of rebound are practically equal to the initial velocities; such a collision is called elastic. That the speeds before and after an elastic collision are equal is not a matter of conservation of momentum, but a matter of conservation of kinetic energy. That the velocities of the bodies rebounding after a symmetrical collision are equal to and opposite each other, however, is a matter of conservation of momentum. We might similarly analyze collisions between bodies of different masses, different initial velocities, and various degrees of elasticity, and determine the final velocities and the loss of kinetic energy, but we shall not go into the details of these processes. Elastic collisions are especially interesting for systems that have no internal \u201cgears, wheels, or parts.\u201d Then when there is a collision there is nowhere for the energy to be impounded, because the objects that move apart are in the same condition as when they collided. Therefore, between very elementary objects, the collisions are always elastic or very nearly elastic. For instance, the collisions between atoms or molecules in a gas are said to be perfectly elastic. Although this is an excellent approximation, even such collisions are not perfectly elastic; otherwise one could not understand how energy in the form of light or heat radiation could come out of a gas. Once in a while, in a gas collision, a low-energy infrared ray is emitted, but this occurrence is very rare and the energy emitted is very small. So, for most purposes, collisions of molecules in gases are considered to be perfectly elastic. As an interesting example, let us consider an elastic collision between two objects of equal mass. If they come together with the same speed, they would come apart at that same speed, by symmetry. But now look at this in another circumstance, in which one of them is moving with velocity v and the other one is at rest. What happens? We have been through this before. We watch the symmetrical collision from a car moving along with one of the objects, and we find that if a stationary body is struck elastically by another body of exactly the same mass, the moving body stops, and the one that was standing still now moves away with the same speed that the other one had; the bodies simply exchange velocities. This behavior can easily be demonstrated with a suitable impact apparatus. More generally, if both bodies are moving, with different velocities, they simply exchange velocity at impact. Another example of an almost elastic interaction is magnetism. If we arrange a pair of U-shaped magnets in our glide blocks, so that they repel each other, when one drifts quietly up to the other, it pushes it away and stands perfectly still, and now the other goes along, frictionlessly. The principle of conservation of momentum is very useful, because it enables us to solve many problems without knowing the details. We did not know the details of the gas motions in the cap explosion, yet we could predict the velocities with which the bodies came apart, for example. Another interesting example is rocket propulsion. A rocket of large mass, M , ejects a small piece, of mass m , with a terrific velocity V relative to the rocket. After this the rocket, if it were originally standing still, will be moving with a small velocity, v . Using the principle of conservation of momentum, we can calculate this velocity to be v= m M \u22c5V. m So long as material is being ejected, the rocket continues to pick up speed. Rocket propulsion is essentially the same as the recoil of a gun: there is no need for any air to push against. In modern times the law of conservation of momentum has undergone certain modifications. However, the law is still true today, the modifications being mainly in the definitions of things. In the theory of relativity it turns out that we do have conservation of momentum; the particles have mass and the momentum is still given by mv , the mass times the velocity, but the mass changes with the velocity, hence the momentum also changes. The mass varies with velocity according to the law m= m 0 1\u2212 v 2 / c 2 \u2212 \u2212 \u2212 \u2212 \u2212 \u2212 \u2212 \u2212 \u221a , (10.7) where m 0 is the mass of the body at rest and c is the speed of light. It is easy to see from the formula that there is negligible difference between m and m 0 unless v is very large, and that for ordinary velocities the expression for momentum reduces to the old formula. The components of momentum for a single particle are written as p x p y p z = m 0 v x 1\u2212 v 2 / c 2 \u2212 \u2212 \u2212 \u2212 \u2212 \u2212 \u2212 \u2212 \u221a , = m 0 v y 1\u2212 v 2 / c 2 \u2212 \u2212 \u2212 \u2212 \u2212 \u2212 \u2212 \u2212 \u221a , = m 0 v z 1\u2212 v 2 / c 2 \u2212 \u2212 \u2212 \u2212 \u2212 \u2212 \u2212 \u2212 \u221a , (10.8) where v 2 = v 2 x + v 2 y + v 2 z . If the x -components are summed over all the interacting particles, both before and after a collision, the sums are equal; that is, momentum is conserved in the x -direction. The same holds true in any direction. In Chapter 4 we saw that the law of conservation of energy is not valid unless we recognize that energy appears in different forms, electrical energy, mechanical energy, radiant energy, heat energy, and so on. In some of these cases, heat energy for example, the energy might be said to be \u201chidden.\u201d This example might suggest the question, \u201cAre there also hidden forms of momentum\u2014perhaps heat momentum?\u201d The answer is that it is very hard to hide momentum for the following reasons. The random motions of the atoms of a body furnish a measure of heat energy, if the squares of the velocities are summed. This sum will be a positive result, having no directional character. The heat is there, whether or not the body moves as a whole, and conservation of energy in the form of heat is not very obvious. On the other hand, if one sums the velocities, which have direction, and finds a result that is not zero, that means that there is a drift of the entire body in some particular direction, and such a gross momentum is readily observed. Thus there is no random internal lost momentum, because the body has net momentum only when it moves as a whole. Therefore momentum, as a mechanical quantity, is difficult to hide. Nevertheless, momentum can be hidden\u2014in the electromagnetic field, for example. This case is another effect of relativity. One of the propositions of Newton was that interactions at a distance are instantaneous. It turns out that such is not the case; in situations involving electrical forces, for instance, if an electrical charge at one location is suddenly moved, the effects on another charge, at another place, do not appear instantaneously\u2014there is a little delay. In those circumstances, even if the forces are equal the momentum will not check out; there will be a short time during which there will be trouble, because for a while the first charge will feel a certain reaction force, say, and will pick up some momentum, but the second charge has felt nothing and has not yet changed its momentum. It takes time for the influence to cross the intervening distance, which it does at 186,000 miles a second. In that tiny time the momentum of the particles is not conserved. Of course after the second charge has felt the effect of the first one and all is quieted down, the momentum equation will check out all right, but during that small interval momentum is not conserved. We represent this by saying that during this interval there is another kind of momentum besides that of the particle, mv , and that is momentum in the electromagnetic field. If we add the field momentum to the momentum of the particles, then momentum is conserved at any moment all the time. The fact that the electromagnetic field can possess momentum and energy makes that field very real, and so, for better understanding, the original idea that there are just the forces between particles has to be modified to the idea that a particle makes a field, and a field acts on another particle, and the field itself has such familiar properties as energy content and momentum, just as particles can have. To take another example: an electromagnetic field has waves, which we call light; it turns out that light also carries momentum with it, so when light impinges on an object it carries in a certain amount of momentum per second; this is equivalent to a force, because if the illuminated object is picking up a certain amount of momentum per second, its momentum is changing and the situation is exactly the same as if there were a force on it. Light can exert pressure by bombarding an object; this pressure is very small, but with sufficiently delicate apparatus it is measurable. Now in quantum mechanics it turns out that momentum is a different thing\u2014it is no longer mv . It is hard to define exactly what is meant by the velocity of a particle, but momentum still exists. In quantum mechanics the difference is that when the particles are represented as particles, the momentum is still mv , but when the particles are represented as waves, the momentum is measured by the number of waves per centimeter: the greater this number of waves, the greater the momentum. In spite of the differences, the law of conservation of momentum holds also in quantum mechanics. Even though the law F=ma is false, and all the derivations of Newton were wrong for the conservation of momentum, in quantum mechanics, nevertheless, in the end, that particular law maintains itself!"
    },
    {
        "input": "Relativistic Effects in Radiation",
        "output": "In the present chapter we shall describe a number of miscellaneous effects in connection with radiation, and then we shall be finished with the classical theory of light propagation. In our analysis of light, we have gone rather far and into considerable detail. The only phenomena of any consequence associated with electromagnetic radiation that we have not discussed is what happens if radiowaves are contained in a box with reflecting walls, the size of the box being comparable to a wavelength, or are transmitted down a long tube. The phenomena of so-called cavity resonators and waveguides we shall discuss later; we shall first use another physical example\u2014sound\u2014and then we shall return to this subject. Except for this, the present chapter is our last consideration of the classical theory of light. We can summarize all the effects that we shall now discuss by remarking that they have to do with the effects of moving sources. We no longer assume that the source is localized, with all its motion being at a relatively low speed near a fixed point. We recall that the fundamental laws of electrodynamics say that, at large distances from a moving charge, the electric field is given by the formula E=\u2212 q 4\u03c0\u03f50c2 d2eR\u2032 dt2 . The second derivative of the unit vector eR\u2032 which points in the apparent direction of the charge, is the determining feature of the electric field. This unit vector does not point toward the present position of the charge, of course, but rather in the direction that the charge would seem to be, if the information travels only at the finite speed c from the charge to the observer. Associated with the electric field is a magnetic field, always at right angles to the electric field and at right angles to the apparent direction of the source, given by the formula B=\u2212eR\u2032\u00d7E/c. Until now we have considered only the case in which motions are nonrelativistic in speed, so that there is no appreciable motion in the direction of the source to be considered. Now we shall be more general and study the case where the motion is at an arbitrary velocity, and see what different effects may be expected in those circumstances. We shall let the motion be at an arbitrary speed, but of course we shall still assume that the detector is very far from the source. We already know from our discussion in Chapter 28 that the only things that count in d2eR\u2032/dt2 are the changes in the direction of eR\u2032 . Let the coordinates of the charge be (x,y,z) , with z measured along the direction of observation (Fig. 34\u20131). At a given moment in time, say the moment \u03c4 , the three components of the position are x(\u03c4) , y(\u03c4) , and z(\u03c4) . The distance R is very nearly equal to R(\u03c4)=R0+z(\u03c4) . Now the direction of the vector eR\u2032 depends mainly on x and y , but hardly at all upon z : the transverse components of the unit vector are x/R and y/R , and when we differentiate these components we get things like R2 in the denominator: d(x/R) dt = dx/dt R \u2212 dz dt x R2 . So, when we are far enough away the only terms we have to worry about are the variations of x and y . Thus we take out the factor R0 and get Ex =\u2212 q 4\u03c0\u03f50c2R0 d2x\u2032 dt2 , Ey =\u2212 q 4\u03c0\u03f50c2R0 d2y\u2032 dt2 , where R0 is the distance, more or less, to q ; let us take it as the distance OP to the origin of the coordinates (x,y,z) . Thus the electric field is a constant multiplied by a very simple thing, the second derivatives of the x - and y -coordinates. (We could put it more mathematically by calling x and y the transverse components of the position vector r of the charge, but this would not add to the clarity.) Of course, we realize that the coordinates must be measured at the retarded time. Here we find that z(\u03c4) does affect the retardation. What time is the retarded time? If the time of observation is called t (the time at P ) then the time \u03c4 to which this corresponds at A is not the time t , but is delayed by the total distance that the light has to go, divided by the speed of light. In the first approximation, this delay is R 0 /c , a constant (an uninteresting feature), but in the next approximation we must include the effects of the position in the z -direction at the time \u03c4 , because if q is a little farther back, there is a little more retardation. This is an effect that we have neglected before, and it is the only change needed in order to make our results valid for all speeds. What we must now do is to choose a certain value of t and calculate the value of \u03c4 from it, and thus find out where x and y are at that \u03c4 . These are then the retarded x and y , which we call x \u2032 and y \u2032 , whose second derivatives determine the field. Thus \u03c4 is determined by t=\u03c4+ R 0 c + z(\u03c4) c R ( ) and x \u2032 (t)=x(\u03c4), y \u2032 (t)=y(\u03c4). (34.4) Now these are complicated equations, but it is easy enough to make a geometrical picture to describe their solution. This picture will give us a good qualitative feeling for how things work, but it still takes a lot of detailed mathematics to deduce the precise results of a complicated problem. The above equation has an interesting simplification. If we disregard the uninteresting constant delay R 0 /c , which just means that we must change the origin of t by a constant, then it says that ct=c\u03c4+z(\u03c4), x \u2032 =x(\u03c4), y \u2032 =y(\u03c4). (34.5) Now we need to find x \u2032 and y \u2032 as functions of t , not \u03c4 , and we can do this in the following way: Eq. (34.5) says that we should take the actual motion and add a constant (the speed of light) times \u03c4 . What that turns out to mean is shown in Fig. 34\u20132. We take the actual motion of the charge (shown at left) and imagine that as it is going around it is being swept away from the point P at the speed c (there are no contractions from relativity or anything like that; this is just a mathematical addition of the c\u03c4 ). In this way we get a new motion, in which the line-of-sight coordinate is ct , as shown at the right. (The figure shows the result for a rather complicated motion in a plane, but of course the motion may not be in one plane\u2014it may be even more complicated than motion in a plane.) The point is that the horizontal (i.e., line-of-sight) distance now is no longer the old z , but is z+c\u03c4 , and therefore is ct . Thus we have found a picture of the curve, x \u2032 (and y \u2032 ) against t ! All we have to do to find the field is to look at the acceleration of this curve, i.e., to differentiate it twice. So the final answer is: in order to find the electric field for a moving charge, take the motion of the charge and translate it back at the speed c to \u201copen it out\u201d; then the curve, so drawn, is a curve of the x \u2032 and y \u2032 positions of the function of t . The acceleration of this curve gives the electric field as a function of t . Or, if we wish, we can now imagine that this whole \u201crigid\u201d curve moves forward at the speed c through the plane of sight, so that the point of intersection with the plane of sight has the coordinates x \u2032 and y \u2032 . The acceleration of this point makes the electric field. This solution is just as exact as the formula we started with\u2014it is simply a geometrical representation. If the motion is relatively slow, for instance if we have an oscillator just going up and down slowly, then when we shoot that motion away at the speed of light, we would get, of course, a simple cosine curve, and that gives a formula we have been looking at for a long time: it gives the field produced by an oscillating charge. A more interesting example is an electron moving rapidly, very nearly at the speed of light, in a circle. If we look in the plane of the circle, the retarded x \u2032 (t) appears as shown in Fig. 34\u20133. What is this curve? If we imagine a radius vector from the center of the circle to the charge, and if we extend this radial line a little bit past the charge, just a shade if it is going fast, then we come to a point on the line that goes at the speed of light. Therefore, when we translate the motion back at the speed of light, that corresponds to having a wheel with a charge on it rolling backward (without slipping) at the speed c ; thus we find a curve which is very close to a cycloid\u2014it is called a curtate cycloid. If the charge is going very nearly at the speed of light, the \u201ccusps\u201d are very sharp indeed; if it went at exactly the speed of light, they would be actual cusps, infinitely sharp. \u201cInfinitely sharp\u201d is interesting; it means that near a cusp the second derivative is enormous. Once in each cycle we get a sharp pulse of electric field. This is not at all what we would get from a nonrelativistic motion, where each time the charge goes around there is an oscillation which is of about the same \u201cstrength\u201d all the time. Instead, there are very sharp pulses of electric field spaced at time intervals T 0 apart, where T 0 is the period of revolution. These strong electric fields are emitted in a narrow cone in the direction of motion of the charge. When the charge is moving away from P , there is very little curvature and there is very little radiated field in the direction of P . We have very fast electrons moving in circular paths in the synchrotron; they are travelling at very nearly the speed c , and it is possible to see the above radiation as actual light! Let us discuss this in more detail. In the synchrotron we have electrons which go around in circles in a uniform magnetic field. First, let us see why they go in circles. From Eq. (28.2), we know that the force on a particle in a magnetic field is given by F=qv\u00d7B, (34.6) and it is at right angles both to the field and to the velocity. As usual, the force is equal to the rate of change of momentum with time. If the field is directed upward out of the paper, the momentum of the particle and the force on it are as shown in Fig. 34\u20134. Since the force is at right angles to the velocity, the kinetic energy, and therefore the speed, remains constant. All the magnetic field does is to change the direction of motion. In a short time \u0394t , the momentum vector changes at right angles to itself by an amount \u0394p=F\u0394t , and therefore p turns through an angle \u0394\u03b8= \u0394p/p= qvB\u0394t/p , since |F|=qvB . But in this same time the particle has gone a distance \u0394s=v\u0394t . Evidently, the two lines AB and CD will intersect at a point O such that OA= OC= R , where \u0394s=R\u0394\u03b8 . Combining this with the previous expressions, we find R\u0394\u03b8/\u0394t= R\u03c9= v= qvBR/p , from which we find p=qBR (34.7) and \u03c9=qvB/p. (34.8) Since this same argument can be applied during the next instant, the next, and so on, we conclude that the particle must be moving in a circle of radius R , with angular velocity \u03c9 . The result that the momentum of the particle is equal to a charge times the radius times the magnetic field is a very important law that is used a great deal. It is important for practical purposes because if we have elementary particles which all have the same charge and we observe them in a magnetic field, we can measure the radii of curvature of their orbits and, knowing the magnetic field, thus determine the momenta of the particles. If we multiply both sides of Eq. (34.7) by c , and express q in terms of the electronic charge, we can measure the momentum in units of the electron volt. In those units our formula is pc(eV)=3\u00d7 10 8 (q/ q e )BR, (34.9) where B , R , and the speed of light are all expressed in the mks system, the latter being 3\u00d7 10 8 , numerically. The mks unit of magnetic field is called a weber per square meter. There is an older unit which is still in common use, called a gauss. One weber/m\u00b2 is equal to 10 4 gauss. To give an idea of how big magnetic fields are, the strongest magnetic field that one can usually make in iron is about 1.5\u00d7 10 4 gauss; beyond that, the advantage of using iron disappears. Today, electromagnets wound with superconducting wire are able to produce steady fields of over 10 5 gauss strength\u2014that is, 10 mks units. The field of the earth is a few tenths of a gauss at the equator. Returning to Eq. (34.9), we could imagine the synchrotron running at a billion electron volts, so pc would be 10 9 for a billion electron volts. (We shall come back to the energy in just a moment.) Then, if we had a B corresponding to, say, 10,000 gauss, which is a good substantial field, one mks unit, then we see that R would have to be 3.3 meters. The actual radius of the Caltech synchrotron is 3.7 meters, the field is a little bigger, and the energy is 1.5 billion, but it is the same idea. So now we have a feeling for why the synchrotron has the size it has. We have calculated the momentum, but we know that the total energy, including the rest energy, is given by W= p 2 c 2 + m 2 c 4 \u2212 \u2212 \u2212 \u2212 \u2212 \u2212 \u2212 \u2212 \u2212 \u2212 \u221a , and for an electron the rest energy corresponding to m c 2 is 0.511\u00d7 10 6 eV, so when pc is 10 9 eV we can neglect m c 2 , and so for all practical purposes W=pc when the speeds are relativistic. It is practically the same to say the energy of an electron is a billion electron volts as to say the momentum times c is a billion electron volts. If W= 10 9 eV, it is easy to show that the speed differs from the speed of light by but one part in eight million! We turn now to the radiation emitted by such a particle. A particle moving on a circle of radius 3.3 meters, or 20 meters circumference, goes around once in roughly the time it takes light to go 20 meters. So the wavelength that should be emitted by such a particle would be 20 meters\u2014in the shortwave radio region. But because of the piling up effect that we have been discussing (Fig. 34\u20133), and because the distance by which we must extend the radius to reach the speed c is only one part in eight million of the radius, the cusps of the curtate cycloid are enormously sharp compared with the distance between them. The acceleration, which involves a second derivative with respect to time, gets twice the \u201ccompression factor\u201d of 8\u00d7 10 6 because the time scale is reduced by eight million twice in the neighborhood of the cusp. Thus we might expect the effective wavelength to be much shorter, to the extent of 64 times 10 12 smaller than 20 meters, and that corresponds to the x-ray region. (Actually, the cusp itself is not the entire determining factor; one must also include a certain region about the cusp. This changes the factor to the 3/2 power instead of the square, but still leaves us above the optical region.) Thus, even though a slowly moving electron would have radiated 20 -meter radiowaves, the relativistic effect cuts down the wavelength so much that we can see it! Clearly, the light should be polarized, with the electric field perpendicular to the uniform magnetic field. To further appreciate what we would observe, suppose that we were to take such light (to simplify things, because these pulses are so far apart in time, we shall just take one pulse) and direct it onto a diffraction grating, which is a lot of scattering wires. After this pulse comes away from the grating, what do we see? (We should see red light, blue light, and so on, if we see any light at all.) What do we see? The pulse strikes the grating head-on, and all the oscillators in the grating, together, are violently moved up and then back down again, just once. They then produce effects in various directions, as shown in Fig. 34\u20135. But the point P is closer to one end of the grating than to the other, so at this point the electric field arrives first from wire A , next from B , and so on; finally, the pulse from the last wire arrives. In short, the sum of the reflections from all the successive wires is as shown in Fig. 34\u20136(a); it is an electric field which is a series of pulses, and it is very like a sine wave whose wavelength is the distance between the pulses, just as it would be for monochromatic light striking the grating! So, we get colored light all right. But, by the same argument, will we not get light from any kind of a \u201cpulse\u201d? No. Suppose that the curve were much smoother; then we would add all the scattered waves together, separated by a small time between them (Fig. 34\u20136b). Then we see that the field would not shake at all, it would be a very smooth curve, because each pulse does not vary much in the time interval between pulses. The electromagnetic radiation emitted by relativistic charged particles circulating in a magnetic field is called synchrotron radiation. It is so named for obvious reasons, but it is not limited specifically to synchrotrons, or even to earthbound laboratories. It is exciting and interesting that it also occurs in nature! In the year 1054 the Chinese and Japanese civilizations were among the most advanced in the world; they were conscious of the external universe, and they recorded, most remarkably, an explosive bright star in that year. (It is amazing that none of the European monks, writing all the books of the middle ages, even bothered to write that a star exploded in the sky, but they did not.) Today we may take a picture of that star, and what we see is shown in Fig. 34\u20137. On the outside is a big mass of red filaments, which is produced by the atoms of the thin gas \u201cringing\u201d at their natural frequencies; this makes a bright line spectrum with different frequencies in it. The red happens in this case to be due to nitrogen. On the other hand, in the central region is a mysterious, fuzzy patch of light in a continuous distribution of frequency, i.e., there are no special frequencies associated with particular atoms. Yet this is not dust \u201clit up\u201d by nearby stars, which is one way by which one can get a continuous spectrum. We can see stars through it, so it is transparent, but it is emitting light. In Fig. 34\u20138 we look at the same object, using light in a region of the spectrum which has no bright spectral line, so that we see only the central region. But in this case, also, polarizers have been put on the telescope, and the two views correspond to two orientations 90 \u2218 apart. We see that the pictures are different! That is to say, the light is polarized. The reason, presumably, is that there is a local magnetic field, and many very energetic electrons are going around in that magnetic field. We have just illustrated how the electrons could go around the field in a circle. We can add to this, of course, any uniform motion in the direction of the field, since the force, qv\u00d7B , has no component in this direction and, as we have already remarked, the synchrotron radiation is evidently polarized in a direction at right angles to the projection of the magnetic field onto the plane of sight. Putting these two facts together, we see that in a region where one picture is bright and the other one is black, the light must have its electric field completely polarized in one direction. This means that there is a magnetic field at right angles to this direction, while in other regions, where there is a strong emission in the other picture, the magnetic field must be the other way. If we look carefully at Fig. 34\u20138, we may notice that there is, roughly speaking, a general set of \u201clines\u201d that go one way in one picture and at right angles to this in the other. The pictures show a kind of fibrous structure. Presumably, the magnetic field lines will tend to extend relatively long distances in their own direction, and so, presumably, there are long regions of magnetic field with all the electrons spiralling one way, while in another region the field is the other way and the electrons are also spiralling that way. What keeps the electron energy so high for so long a time? After all, it is 900 years since the explosion\u2014how can they keep going so fast? How they maintain their energy and how this whole thing keeps going is still not thoroughly understood. We shall next remark briefly on one other interesting effect of a very fast-moving particle that radiates energy. The idea is very similar to the one we have just discussed. Suppose that there are charged particles in a piece of matter and a very fast electron, say, comes by (Fig. 34\u20139). Then, because of the electric field around the atomic nucleus the electron is pulled, accelerated, so that the curve of its motion has a slight kink or bend in it. If the electron is travelling at very nearly the speed of light, what is the electric field produced in the direction C ? Remember our rule: we take the actual motion, translate it backwards at speed c , and that gives us a curve whose curvature measures the electric field. It was coming toward us at the speed v , so we get a backward motion, with the whole picture compressed into a smaller distance in proportion as c\u2212v is smaller than c . So, if 1\u2212v/c\u226a1 , there is a very sharp and rapid curvature at B \u2032 , and when we take the second derivative of that we get a very high field in the direction of the motion. So when very energetic electrons move through matter they spit radiation in a forward direction. This is called bremsstrahlung. As a matter of fact, the synchrotron is used, not so much to make high-energy electrons (actually if we could get them out of the machine more conveniently we would not say this) as to make very energetic photons\u2014gamma rays\u2014by passing the energetic electrons through a solid tungsten \u201ctarget,\u201d and letting them radiate photons from this bremsstrahlung effect. Now we go on to consider some other examples of the effects of moving sources. Let us suppose that the source is a stationary atom which is oscillating at one of its natural frequencies, \u03c9 0 . Then we know that the frequency of the light we would observe is \u03c9 0 . But now let us take another example, in which we have a similar oscillator oscillating with a frequency \u03c9 1 , and at the same time the whole atom, the whole oscillator, is moving along in a direction toward the observer at velocity v . Then the actual motion in space, of course, is as shown in Fig. 34\u201310(a). Now we play our usual game, we add c\u03c4 ; that is to say, we translate the whole curve backward and we find then that it oscillates as in Fig. 34\u201310(b). In a given amount of time \u03c4 , when the oscillator would have gone a distance v\u03c4 , on the x \u2032 vs. ct diagram it goes a distance (c\u2212v)\u03c4 . So all the oscillations of frequency \u03c9 1 in the time \u0394\u03c4 are now found in the interval \u0394t=(1\u2212v/c)\u0394\u03c4 ; they are squashed together, and as this curve comes by us at speed c , we will see light of a higher frequency, higher by just the compression factor (1\u2212v/c) . Thus we observe \u03c9= \u03c9 1 1\u2212v/c . (34.10) We can, of course, analyze this situation in various other ways. Suppose that the atom were emitting, instead of sine waves, a series of pulses, pip, pip, pip, pip, at a certain frequency \u03c9 1 . At what frequency would they be received by us? The first one that arrives has a certain delay, but the next one is delayed less because in the meantime the atom moves closer to the receiver. Therefore, the time between the \u201cpips\u201d is decreased by the motion. If we analyze the geometry of the situation, we find that the frequency of the pips is increased by the factor 1/(1\u2212v/c) . Is \u03c9= \u03c9 0 /(1\u2212v/c) , then, the frequency that would be observed if we took an ordinary atom, which had a natural frequency \u03c9 0 , and moved it toward the receiver at speed v ? No; as we well know, the natural frequency \u03c9 1 of a moving atom is not the same as that measured when it is standing still, because of the relativistic dilation in the rate of passage of time. Thus if \u03c9 0 were the true natural frequency, then the modified natural frequency \u03c9 1 would be \u03c9 1 = \u03c9 0 1\u2212 v 2 / c 2 \u2212 \u2212 \u2212 \u2212 \u2212 \u2212 \u2212 \u2212 \u221a . (34.11) Therefore the observed frequency \u03c9 is \u03c9= \u03c9 0 1\u2212 v 2 / c 2 \u2212 \u2212 \u2212 \u2212 \u2212 \u2212 \u2212 \u2212 \u221a 1\u2212v/c . (34.12) The shift in frequency observed in the above situation is called the Doppler effect: if something moves toward us the light it emits appears more violet, and if it moves away it appears more red. We shall now give two more derivations of this same interesting and important result. Suppose, now, that the source is standing still and is emitting waves at frequency \u03c9 0 , while the observer is moving with speed v toward the source. After a certain period of time t the observer will have moved to a new position, a distance vt from where he was at t=0 . How many radians of phase will he have seen go by? A certain number, \u03c9 0 t , went past any fixed point, and in addition the observer has swept past some more by his own motion, namely a number vt k 0 (the number of radians per meter times the distance). So the total number of radians in the time t , or the observed frequency, would be \u03c9 1 = \u03c9 0 + k 0 v . We have made this analysis from the point of view of a man at rest; we would like to know how it would look to the man who is moving. Here we have to worry again about the difference in clock rate for the two observers, and this time that means that we have to divide by 1\u2212 v 2 / c 2 \u2212 \u2212 \u2212 \u2212 \u2212 \u2212 \u2212 \u2212 \u221a . So if k 0 is the wave number, the number of radians per meter in the direction of motion, and \u03c9 0 is the frequency, then the observed frequency for a moving man is \u03c9= \u03c9 0 + k 0 v 1\u2212 v 2 / c 2 \u2212 \u2212 \u2212 \u2212 \u2212 \u2212 \u2212 \u2212 \u221a . (34.13) For the case of light, we know that k 0 = \u03c9 0 /c . So, in this particular problem, the equation would read \u03c9= \u03c9 0 (1+v/c) 1\u2212 v 2 / c 2 \u2212 \u2212 \u2212 \u2212 \u2212 \u2212 \u2212 \u2212 \u221a , (34.14) which looks completely unlike formula (34.12)! Is the frequency that we would observe if we move toward a source different than the frequency that we would see if the source moved toward us? Of course not! The theory of relativity says that these two must be exactly equal. If we were expert enough mathematicians we would probably recognize that these two mathematical expressions are exactly equal! In fact, the necessary equality of the two expressions is one of the ways by which some people like to demonstrate that relativity requires a time dilation, because if we did not put those square-root factors in, they would no longer be equal. Since we know about relativity, let us analyze it in still a third way, which may appear a little more general. (It is really the same thing, since it makes no difference how we do it!) According to the relativity theory there is a relationship between position and time as observed by one man and position and time as seen by another who is moving relative to him. We wrote down those relationships long ago (Chapter 16). This is the Lorentz transformation and its inverse: x \u2032 t \u2032 = x+vt 1\u2212 v 2 / c 2 \u2212 \u2212 \u2212 \u2212 \u2212 \u2212 \u2212 \u2212 \u221a , = t+vx/ c 2 1\u2212 v 2 / c 2 \u2212 \u2212 \u2212 \u2212 \u2212 \u2212 \u2212 \u2212 \u221a , x t = x \u2032 \u2212v t \u2032 1\u2212 v 2 / c 2 \u2212 \u2212 \u2212 \u2212 \u2212 \u2212 \u2212 \u2212 \u221a , = t \u2032 \u2212v x \u2032 / c 2 1\u2212 v 2 / c 2 \u2212 \u2212 \u2212 \u2212 \u2212 \u2212 \u2212 \u2212 \u221a . (34.15) If we were standing still on the ground, the form of a wave would be cos(\u03c9t\u2212kx) ; all the nodes and maxima and minima would follow this form. But what would a man in motion, observing the same physical wave, see? Where the field is zero, the positions of all the nodes are the same (when the field is zero, everyone measures the field as zero); that is a relativistic invariant. So the form is the same for the other man too, except that we must transform it into his frame of reference: cos(\u03c9t\u2212kx)=cos[\u03c9 t \u2032 \u2212v x \u2032 / c 2 1\u2212 v 2 / c 2 \u2212 \u2212 \u2212 \u2212 \u2212 \u2212 \u2212 \u2212 \u221a \u2212k x \u2032 \u2212v t \u2032 1\u2212 v 2 / c 2 \u2212 \u2212 \u2212 \u2212 \u2212 \u2212 \u2212 \u2212 \u221a ]. \u2032 \u2032 2 \u2032 \u2032 If we regroup the terms inside the brackets, we get cos(\u03c9t\u2212kx) =cos[ \u03c9+kv 1\u2212 v 2 / c 2 \u2212 \u2212 \u2212 \u2212 \u2212 \u2212 \u2212 \u2212 \u221a t \u2032 \ue152 \ue153 \ue151\ue150 \ue154 \ue154 \ue154 \ue154 \ue154 \ue154 \ue154 \ue154 \ue154 \ue154 \ue154 \ue154 =cos[ \u03c9 \u2032 t \u2032 \u2212 \u2212 k+v\u03c9/ c 2 1\u2212 v 2 / c 2 \u2212 \u2212 \u2212 \u2212 \u2212 \u2212 \u2212 \u2212 \u221a x \u2032 \ue152 \ue153 \ue151\ue150 \ue154 \ue154 \ue154 \ue154 \ue154 \ue154 \ue154 \ue154 \ue154 \ue154 \ue154 \ue154 \ue154 \ue154 ] k \u2032 x \u2032 ]. (34.16) This is again a wave, a cosine wave, in which there is a certain frequency \u03c9 \u2032 , a constant multiplying t \u2032 , and some other constant, k \u2032 , multiplying x \u2032 . We call k \u2032 the wave number, or the number of waves per meter, for the other man. Therefore the other man will see a new frequency and a new wave number given by \u03c9 \u2032 k \u2032 = \u03c9+kv 1\u2212 v 2 / c 2 \u2212 \u2212 \u2212 \u2212 \u2212 \u2212 \u2212 \u2212 \u221a , = k+\u03c9v/ c 2 1\u2212 v 2 / c 2 \u2212 \u2212 \u2212 \u2212 \u2212 \u2212 \u2212 \u2212 \u221a . (34.17) (34.18) If we look at (34.17), we see that it is the same formula (34.13), that we obtained by a more physical argument. The relationships indicated in Eqs. (34.17) and (34.18) are very interesting, because these say that the new frequency \u03c9 \u2032 is a combination of the old frequency \u03c9 and the old wave number k , and that the new wave number is a combination of the old wave number and frequency. Now the wave number is the rate of change of phase with distance, and the frequency is the rate of change of phase with time, and in these expressions we see a close analogy with the Lorentz transformation of the position and time: if \u03c9 is thought of as being like t , and k is thought of as being like x divided by c 2 , then the new \u03c9 \u2032 will be like t \u2032 , and the new k \u2032 will be like x \u2032 / c 2 . That is to say, under the Lorentz transformation \u03c9 and k transform the same way as do t and x . They constitute what we call a four-vector; when a quantity has four components transforming like time and space, it is a four-vector. Everything seems all right, then, except for one little thing: we said that a four-vector has to have four components; where are the other two components? We have seen that \u03c9 and k are like time and space in one space direction, but not in all directions, and so we must next study the problem of the propagation of light in three space dimensions, not just in one direction, as we have been doing up until now. Suppose that we have a coordinate system, x , y , z , and a wave which is travelling along and whose wavefronts are as shown in Fig. 34\u201311. The wavelength of the wave is \u03bb , but the direction of motion of the wave does not happen to be in the direction of one of the axes. What is the formula for such a wave? The answer is clearly cos(\u03c9t\u2212ks) , where k=2\u03c0/\u03bb and s is the distance along the direction of motion of the wave\u2014the component of the spatial position in the direction of motion. Let us put it this way: if r is the vector position of a point in space, then s is r\u22c5 e k , where e k is a unit vector in the direction of motion. That is, s is just rcos(r, e k ) , the component of distance in the direction of motion. Therefore our wave is cos(\u03c9t\u2212k e k \u22c5r) . Now it turns out to be very convenient to define a vector k , which is called the wave vector, which has a magnitude equal to the wave number, 2\u03c0/\u03bb , and is pointed in the direction of propagation of the waves: k=2\u03c0 e k /\u03bb=k e k . (34.19) Using this vector, our wave can be written as cos(\u03c9t\u2212k\u22c5r) , or as cos(\u03c9t\u2212 k x x\u2212 k y y\u2212 k z z) . What is the significance of a component of k , say k x ? Clearly, k x is the rate of change of phase with respect to x . Referring to Fig. 34\u201311, we see that the phase changes as we change x , just as if there were a wave along x , but of a longer wavelength. The \u201cwavelength in the x -direction\u201d is longer than a natural, true wavelength by the secant of the angle \u03b1 between the actual direction of propagation and the x -axis: \u03bb x =\u03bb/cos\u03b1. (34.20) Therefore the rate of change of phase, which is proportional to the reciprocal of \u03bb x , is smaller by the factor cos\u03b1 ; that is just how k x would vary\u2014it would be the magnitude of k , times the cosine of the angle between k and the x -axis! That, then, is the nature of the wave vector that we use to represent a wave in three dimensions. The four quantities \u03c9 , k x , k y , k z transform in relativity as a four-vector, where \u03c9 corresponds to the time, and k x , k y , k z correspond to the x -, y -, and z -components of the four-vector. In our previous discussion of special relativity (Chapter 17), we learned that there are ways of making relativistic dot products with four-vectors. If we use the position vector x \u03bc , where \u03bc stands for the four components (time and three space ones), and if we call the wave vector k \u03bc , where the index \u03bc again has four values, time and three space ones, then the dot product of x \u03bc and k \u03bc is written \u2211 \u2032 k \u03bc x \u03bc (see Chapter 17). This dot product is an invariant, independent of the coordinate system; what is it equal to? By the definition of this dot product in four dimensions, it is \u2211 \u2032 k \u03bc x \u03bc =\u03c9t\u2212 k x x\u2212 k y y\u2212 k z z. (34.21) We know from our study of vectors that \u2211 \u2032 k \u03bc x \u03bc is invariant under the Lorentz transformation, since k \u03bc is a four-vector. But this quantity is precisely what appears inside the cosine for a plane wave, and it ought to be invariant under a Lorentz transformation. We cannot have a formula with something that changes inside the cosine, since we know that the phase of the wave cannot change when we change the coordinate system. In deriving Eqs. (34.17) and (34.18), we have taken a simple example where k happened to be in a direction of motion, but of course we can generalize it to other cases also. For example, suppose there is a source sending out light in a certain direction from the point of view of a man at rest, but we are moving along on the earth, say (Fig. 34\u201312). From which direction does the light appear to come? To find out, we will have to write down the four components of k \u03bc and apply the Lorentz transformation. The answer, however, can be found by the following argument: we have to point our telescope at an angle to see the light. Why? Because light is coming down at the speed c , and we are moving sidewise at the speed v , so the telescope has to be tilted forward so that as the light comes down it goes \u201cstraight\u201d down the tube. It is very easy to see that the horizontal distance is vt when the vertical distance is ct , and therefore, if \u03b8 \u2032 is the angle of tilt, tan \u03b8 \u2032 =v/c . How nice! How nice, indeed\u2014except for one little thing: \u03b8 \u2032 is not the angle at which we would have to set the telescope relative to the earth, because we made our analysis from the point of view of a \u201cfixed\u201d observer. When we said the horizontal distance is vt , the man on the earth would have found a different distance, since he measured with a \u201csquashed\u201d ruler. It turns out that, because of that contraction effect, tan\u03b8= v/c 1\u2212 v 2 / c 2 \u2212 \u2212 \u2212 \u2212 \u2212 \u2212 \u2212 \u2212 \u221a , (34.22) which is equivalent to sin\u03b8=v/c. (34.23) It will be instructive for the student to derive this result, using the Lorentz transformation. This effect, that a telescope has to be tilted, is called aberration, and it has been observed. How can we observe it? Who can say where a given star should be? Suppose we do have to look in the wrong direction to see a star; how do we know it is the wrong direction? Because the earth goes around the sun. Today we have to point the telescope one way; six months later we have to tilt the telescope the other way. That is how we can tell that there is such an effect. Now we turn to a different topic. We have never, in all our discussion of the past few chapters, said anything about the effects of the magnetic field that is associated with light. Ordinarily, the effects of the magnetic field are very small, but there is one interesting and important effect which is a consequence of the magnetic field. Suppose that light is coming from a source and is acting on a charge and driving that charge up and down. We will suppose that the electric field is in the x -direction, so the motion of the charge is also in the x -direction: it has a position x and a velocity v , as shown in Fig. 34\u201313. The magnetic field is at right angles to the electric field. Now as the electric field acts on the charge and moves it up and down, what does the magnetic field do? The magnetic field acts on the charge (say an electron) only when it is moving; but the electron is moving, it is driven by the electric field, so the two of them work together: While the thing is going up and down it has a velocity and there is a force on it, B times v times q ; but in which direction is this force? It is in the direction of the propagation of light. Therefore, when light is shining on a charge and it is oscillating in response to that light, there is a driving force in the direction of the light beam. This is called radiation pressure or light pressure. Let us determine how strong the radiation pressure is. Evidently it is F=qvB or, since everything is oscillating, it is the time average of this, \u27e8F\u27e9 . From (34.2) the strength of the magnetic field is the same as the strength of the electric field divided by c , so we need to find the average of the electric field, times the velocity, times the charge, times 1/c : \u27e8F\u27e9=q\u27e8vE\u27e9/c . But the charge q times the field E is the electric force on a charge, and the force on the charge times the velocity is the work dW/dt being done on the charge! Therefore the force, the \u201cpushing momentum,\u201d that is delivered per second by the light, is equal to 1/c times the energy absorbed from the light per second! That is a general rule, since we did not say how strong the oscillator was, or whether some of the charges cancel out. In any circumstance where light is being absorbed, there is a pressure. The momentum that the light delivers is always equal to the energy that is absorbed, divided by c : \u27e8F\u27e9= dW/dt c . (34.24) That light carries energy we already know. We now understand that it also carries momentum, and further, that the momentum carried is always 1/c times the energy. When light is emitted from a source there is a recoil effect: the same thing in reverse. If an atom is emitting an energy W in some direction, then there is a recoil momentum p=W/c . If light is reflected normally from a mirror, we get twice the force. That is as far as we shall go using the classical theory of light. Of course we know that there is a quantum theory, and that in many respects light acts like a particle. The energy of a light-particle is a constant times the frequency: W=h\u03bd=\u210f\u03c9. (34.25) We now appreciate that light also carries a momentum equal to the energy divided by c , so it is also true that these effective particles, these photons, carry a momentum p=W/c=\u210f\u03c9/c=\u210fk. (34.26) The direction of the momentum is, of course, the direction of propagation of the light. So, to put it in vector form, W=\u210f\u03c9,p=\u210fk. (34.27) We also know, of course, that the energy and momentum of a particle should form a four-vector. We have just discovered that \u03c9 and k form a four-vector. Therefore it is a good thing that (34.27) has the same constant in both cases; it means that the quantum theory and the theory of relativity are mutually consistent. Equation (34.27) can be written more elegantly as p \u03bc =\u210f k \u03bc , a relativistic equation, for a particle associated with a wave. Although we have discussed this only for photons, for which k (the magnitude of k ) equals \u03c9/c and p=W/c , the relation is much more general. In quantum mechanics all particles, not only photons, exhibit wavelike properties, but the frequency and wave number of the waves is related to the energy and momentum of particles by (34.27) (called the de Broglie relations) even when p is not equal to W/c . In the last chapter we saw that a beam of right or left circularly polarized light also carries angular momentum in an amount proportional to the energy E of the wave. In the quantum picture, a beam of circularly polarized light is regarded as a stream of photons, each carrying an angular momentum \u00b1\u210f , along the direction of propagation. That is what becomes of polarization in the corpuscular point of view\u2014the photons carry angular momentum like spinning rifle bullets. But this \u201cbullet\u201d picture is really as incomplete as the \u201cwave\u201d picture, and we shall have to discuss these ideas more fully in a later chapter on Quantum Behavior."
    },
    {
        "input": "The Schrdinger Equation in a Classical Context: A Seminar on Superconductivity",
        "output": "This lecture is only for entertainment. I would like to give the lecture in a somewhat different style\u2014just to see how it works out. It\u2019s not a part of the course\u2014in the sense that it is not supposed to be a last minute effort to teach you something new. But, rather, I imagine that I\u2019m giving a seminar or research report on the subject to a more advanced audience, to people who have already been educated in quantum mechanics. The main difference between a seminar and a regular lecture is that the seminar speaker does not carry out all the steps, or all the algebra. He says: \u201cIf you do such and such, this is what comes out,\u201d instead of showing all of the details. So in this lecture I\u2019ll describe the ideas all the way along but just give you the results of the computations. You should realize that you\u2019re not supposed to understand everything immediately, but believe (more or less) that things would come out if you went through the steps. All that aside, this is a subject I want to talk about. It is recent and modern and would be a perfectly legitimate talk to give at a research seminar. My subject is the Schr\u00f6dinger equation in a classical setting\u2014the case of superconductivity. Ordinarily, the wave function which appears in the Schr\u00f6dinger equation applies to only one or two particles. And the wave function itself is not something that has a classical meaning\u2014unlike the electric field, or the vector potential, or things of that kind. The wave function for a single particle is a \u201cfield\u201d\u2014in the sense that it is a function of position\u2014but it does not generally have a classical significance. Nevertheless, there are some situations in which a quantum mechanical wave function does have classical significance, and they are the ones I would like to take up. The peculiar quantum mechanical behavior of matter on a small scale doesn\u2019t usually make itself felt on a large scale except in the standard way that it produces Newton\u2019s laws\u2014the laws of the so-called classical mechanics. But there are certain situations in which the peculiarities of quantum mechanics can come out in a special way on a large scale. At low temperatures, when the energy of a system has been reduced very, very low, instead of a large number of states being involved, only a very, very small number of states near the ground state are involved. Under those circumstances the quantum mechanical character of that ground state can appear on a macroscopic scale. It is the purpose of this lecture to show a connection between quantum mechanics and large-scale effects\u2014not the usual discussion of the way that quantum mechanics reproduces Newtonian mechanics on the average, but a special situation in which quantum mechanics will produce its own characteristic effects on a large or \u201cmacroscopic\u201d scale. I will begin by reminding you of some of the properties of the Schr\u00f6dinger equation.1 I want to describe the behavior of a particle in a magnetic field using the Schr\u00f6dinger equation, because the superconductive phenomena are involved with magnetic fields. An external magnetic field is described by a vector potential, and the problem is: what are the laws of quantum mechanics in a vector potential? The principle that describes the behavior of quantum mechanics in a vector potential is very simple. The amplitude that a particle goes from one place to another along a certain route when there\u2019s a field present is the same as the amplitude that it would go along the same route when there\u2019s no field, multiplied by the exponential of the line integral of the vector potential, times the electric charge divided by Planck\u2019s constant2 (see Fig. 21\u20131): \u27e8b|a\u27e9in A=\u27e8b|a\u27e9A=0\u22c5exp[ iq \u210f \u222b b a A\u22c5ds]. It is a basic statement of quantum mechanics. Now without the vector potential the Schr\u00f6dinger equation of a charged particle (nonrelativistic, no spin) is \u2212 \u210f i \u2202\u03c8 \u2202t = \u02c6 H \u03c8= 1 2m ( \u210f i \u2207)\u22c5( \u210f i \u2207)\u03c8+q\u03d5\u03c8, where \u03d5 is the electric potential so that q\u03d5 is the potential energy.3 Equation (21.1) is equivalent to the statement that in a magnetic field the gradients in the Hamiltonian are replaced in each case by the gradient minus qA , so that Eq. (21.2) becomes \u2212 \u210f i \u2202\u03c8 \u2202t = \u02c6 H \u03c8= 1 2m ( \u210f i \u2207\u2212qA)\u22c5( \u210f i \u2207\u2212qA)\u03c8+q\u03d5\u03c8. This is the Schr\u00f6dinger equation for a particle with charge q moving in an electromagnetic field A,\u03d5 (nonrelativistic, no spin). To show that this is true I\u2019d like to illustrate by a simple example in which instead of having a continuous situation we have a line of atoms along the x -axis with the spacing b and we have an amplitude iK/\u210f per unit time for an electron to jump from one atom to another when there is no field.4 Now according to Eq. (21.1) if there\u2019s a vector potential in the x -direction Ax(x,t) , the amplitude to jump will be altered from what it was before by a factor exp[(iq/\u210f)Axb] , the exponent being iq/\u210f times the vector potential integrated from one atom to the next. For simplicity we will write (q/\u210f)Ax\u2261f(x) , since Ax , will, in general, depend on x . If the amplitude to find the electron at the atom \u201cn \u201d located at x is called C(x)\u2261Cn , then the rate of change of that amplitude is given by the following equation: \u2212 \u210f i \u2202 \u2202t C(x)=E0C(x) \u2212Ke\u2212ibf(x+b/2)C(x+b) \u2212Ke+ibf(x\u2212b/2)C(x\u2212b). There are three pieces. First, there\u2019s some energy E0 if the electron is located at x . As usual, that gives the term E0C(x) . Next, there is the term \u2212KC(x+b) , which is the amplitude for the electron to have jumped backwards one step from atom \u201cn+1 ,\u201d located at x+b . However, in doing so in a vector potential, the phase of the amplitude must be shifted according to the rule in Eq. (21.1). If Ax is not changing appreciably in one atomic spacing, the integral can be written as just the value of Ax at the midpoint, times the spacing b . So (iq/\u210f) times the integral is just ibf(x+b/2) . Since the electron is jumping backwards, I showed this phase shift with a minus sign. That gives the second piece. In the same manner there\u2019s a certain amplitude to have jumped from the other side, but this time we need the vector potential at a distance (b/2) on the other side of x , times the distance b . That gives the third piece. The sum gives the equation for the amplitude to be at x in a vector potential. Now we know that if the function C(x) is smooth enough (we take the long wavelength limit), and if we let the atoms get closer together, Eq. (21.4) will approach the behavior of an electron in free space. So the next step is to expand the right-hand side of (21.4) in powers of b , assuming b is very small. For example, if b is zero the right-hand side is just (E0\u22122K)C(x) , so in the zeroth approximation the energy is E0\u22122K . Next comes the terms in b . But because the two exponentials have opposite signs, only even powers of b remain. So if you make a Taylor expansion of C(x) , of f(x) , and of the exponentials, and then collect the terms in b2 , you get \u2212 \u210f i \u2202C(x) \u2202t =E0C(x)\u22122KC(x) \u2212Kb2{C\u2033(x)\u22122if(x)C\u2032(x)\u2212 if\u2032(x)C(x)\u2212f2(x)C(x)}. (The \u201cprimes\u201d mean differentiation with respect to x .) Now this horrible combination of things looks quite complicated. But mathematically it\u2019s exactly the same as \u2212 \u210f i \u2202C(x) \u2202t =(E0\u22122K)C(x) \u2212Kb2[ \u2202 \u2202x \u2212if(x)][ \u2202 \u2202x \u2212if(x)]C(x). The second bracket operating on C(x) gives C\u2032(x) minus if(x)C(x) . The first bracket operating on these two terms gives the C\u2033 term and terms in the first derivative of f(x) and the first derivative of C(x) . Now remember that the solutions for zero magnetic field5 represent a particle with an effective mass meff given by Kb2= \u210f2 2meff . If you then set E0=2K , and put back f(x)=(q/\u210f)Ax , you can easily check that Eq. (21.6) is the same as the first part of Eq. (21.3). (The origin of the potential energy term is well known, so I haven\u2019t bothered to include it in this discussion.) The proposition of Eq. (21.1) that the vector potential changes all the amplitudes by the exponential factor is the same as the rule that the momentum operator, (\u210f/i)\u2207 gets replaced by \u210f i \u2207\u2212qA, as you see in the Schr\u00f6dinger equation of (21.3). Now I turn to a second point. An important part of the Schr\u00f6dinger equation for a single particle is the idea that the probability to find the particle at a position is given by the absolute square of the wave function. It is also characteristic of the quantum mechanics that probability is conserved in a local sense. When the probability of finding the electron somewhere decreases, while the probability of the electron being elsewhere increases (keeping the total probability unchanged), something must be going on in between. In other words, the electron has a continuity in the sense that if the probability decreases at one place and builds up at another place, there must be some kind of flow between. If you put a wall, for example, in the way, it will have an influence and the probabilities will not be the same. So the conservation of probability alone is not the complete statement of the conservation law, just as the conservation of energy alone is not as deep and important as the local conservation of energy.6 If energy is disappearing, there must be a flow of energy to correspond. In the same way, we would like to find a \u201ccurrent\u201d of probability such that if there is any change in the probability density (the probability of being found in a unit volume), it can be considered as coming from an inflow or an outflow due to some current. This current would be a vector which could be interpreted this way\u2014the x -component would be the net probability per second and per unit area that a particle passes in the x -direction across a plane parallel to the yz -plane. Passage toward +x is considered a positive flow, and passage in the opposite direction, a negative flow. Is there such a current? Well, you know that the probability density P(r,t) is given in terms of the wave function by P(r,t)= \u03c8 \u2217 (r,t)\u03c8(r,t). (21.7) I am asking: Is there a current J such that \u2202P \u2202t =\u2212\u2207\u22c5J? (21.8) If I take the time derivative of Eq. (21.7), I get two terms: \u2202P \u2202t = \u03c8 \u2217 \u2202\u03c8 \u2202t +\u03c8 \u2202 \u03c8 \u2217 \u2202t . (21.9) Now use the Schr\u00f6dinger equation\u2014Eq. (21.3)\u2014for \u2202\u03c8/\u2202t ; and take the complex conjugate of it to get \u2202 \u03c8 \u2217 /\u2202t \u2014each i gets its sign reversed. You get \u2202P \u2202t = \u2212 i \u210f [ \u03c8 \u2217 1 2m ( \u210f i \u2207\u2212qA)\u22c5( \u210f i \u2207\u2212qA)\u03c8+q\u03d5 \u03c8 \u2217 \u03c8 \u2212\u03c8 1 2m (\u2212 \u210f i \u2207\u2212qA)\u22c5(\u2212 \u210f i \u2207\u2212qA) \u03c8 \u2217 \u2212q\u03d5\u03c8 \u03c8 \u2217 ]. (21.10) The potential terms and a lot of other stuff cancel out. And it turns out that what is left can indeed be written as a perfect divergence. The whole equation is equivalent to \u2202P \u2202t =\u2212\u2207\u22c5{ 1 2m \u03c8 \u2217 ( \u210f i \u2207\u2212qA)\u03c8+ 1 2m \u03c8(\u2212 \u210f i \u2207\u2212qA) \u03c8 \u2217 }. (21.11) It is really not as complicated as it seems. It is a symmetrical combination of \u03c8 \u2217 times a certain operation on \u03c8 , plus \u03c8 times the complex conjugate operation on \u03c8 \u2217 . It is some quantity plus its own complex conjugate, so the whole thing is real\u2014as it ought to be. The operation can be remembered this way: it is just the momentum operator P ^ minus qA . I could write the current in Eq. (21.8) as J= 1 2 { \u03c8 \u2217 [ P ^ \u2212qA m ]\u03c8+\u03c8[ P ^ \u2212qA m ] \u2217 \u03c8 \u2217 }. (21.12) There is then a current J which completes Eq. (21.8). Equation (21.11) shows that the probability is conserved locally. If a particle disappears from one region it cannot appear in another without something going on in between. Imagine that the first region is surrounded by a closed surface far enough out that there is zero probability to find the electron at the surface. The total probability to find the electron somewhere inside the surface is the volume integral of P . But according to Gauss\u2019s theorem the volume integral of the divergence J is equal to the surface integral of its normal component. If \u03c8 is zero at the surface, Eq. (21.12) says that J is zero, so the total probability to find the particle inside can\u2019t change. Only if some of the probability approaches the boundary can some of it leak out. We can say that it only gets out by moving through the surface\u2014and that is local conservation. The equation for the current is rather interesting, and sometimes causes a certain amount of worry. You would think the current would be something like the density of particles times the velocity. The density should be something like \u03c8 \u03c8 \u2217 , which is o.k. And each term in Eq. (21.12) looks like the typical form for the average-value of the operator P ^ \u2212qA m , (21.13) so maybe we should think of it as the velocity of flow. It looks as though we have two suggestions for relations of velocity to momentum, because we would also think that momentum divided by mass, P ^ /m , should be a velocity. The two possibilities differ by the vector potential. It happens that these two possibilities were also discovered in classical physics, when it was found that momentum could be defined in two ways.7 One of them is called \u201ckinematic momentum,\u201d but for absolute clarity I will in this lecture call it the \u201c mv -momentum.\u201d This is the momentum obtained by multiplying mass by velocity. The other is a more mathematical, more abstract momentum, sometimes called the \u201cdynamical momentum,\u201d which I\u2019ll call \u201c p -momentum.\u201d The two possibilities are mv-momentum=mv, (21.14) p-momentum=mv+qA. (21.15) It turns out that in quantum mechanics with magnetic fields it is the p -momentum which is connected to the gradient operator P ^ , so it follows that (21.13) is the operator of a velocity. I\u2019d like to make a brief digression to show you what this is all about\u2014why there must be something like Eq. (21.15) in the quantum mechanics. The wave function changes with time according to the Schr\u00f6dinger equation in Eq. (21.3). If I would suddenly change the vector potential, the wave function wouldn\u2019t change at the first instant; only its rate of change changes. Now think of what would happen in the following circumstance. Suppose I have a long solenoid, in which I can produce a flux of magnetic field ( B -field), as shown in Fig. 21\u20132. And there is a charged particle sitting nearby. Suppose this flux nearly instantaneously builds up from zero to something. I start with zero vector potential and then I turn on a vector potential. That means that I produce suddenly a circumferential vector potential A . You\u2019ll remember that the line integral of A around a loop is the same as the flux of B through the loop.8 Now what happens if I suddenly turn on a vector potential? According to the quantum mechanical equation the sudden change of A does not make a sudden change of \u03c8 ; the wave function is still the same. So the gradient is also unchanged. But remember what happens electrically when I suddenly turn on a flux. During the short time that the flux is rising, there\u2019s an electric field generated whose line integral is the rate of change of the flux with time: E=\u2212 \u2202A \u2202t . (21.16) That electric field is enormous if the flux is changing rapidly, and it gives a force on the particle. The force is the charge times the electric field, and so during the build up of the flux the particle obtains a total impulse (that is, a change in mv ) equal to \u2212qA . In other words, if you suddenly turn on a vector potential at a charge, this charge immediately picks up an mv -momentum equal to \u2212qA . But there is something that isn\u2019t changed immediately and that\u2019s the difference between mv and \u2212qA . And so the sum p=mv+qA is something which is not changed when you make a sudden change in the vector potential. This quantity p is what we have called the p -momentum and is of importance in classical mechanics in the theory of dynamics, but it also has a direct significance in quantum mechanics. It depends on the character of the wave function, and it is the one to be identified with the operator P ^ = \u210f i \u2207. \u210f When Schr\u00f6dinger first discovered his equation he discovered the conservation law of Eq. (21.8) as a consequence of his equation. But he imagined incorrectly that P was the electric charge density of the electron and that J was the electric current density, so he thought that the electrons interacted with the electromagnetic field through these charges and currents. When he solved his equations for the hydrogen atom and calculated \u03c8 , he wasn\u2019t calculating the probability of anything\u2014there were no amplitudes at that time\u2014the interpretation was completely different. The atomic nucleus was stationary but there were currents moving around; the charges P and currents J would generate electromagnetic fields and the thing would radiate light. He soon found on doing a number of problems that it didn\u2019t work out quite right. It was at this point that Born made an essential contribution to our ideas regarding quantum mechanics. It was Born who correctly (as far as we know) interpreted the \u03c8 of the Schr\u00f6dinger equation in terms of a probability amplitude\u2014that very difficult idea that the square of the amplitude is not the charge density but is only the probability per unit volume of finding an electron there, and that when you do find the electron some place the entire charge is there. That whole idea is due to Born. The wave function \u03c8(r) for an electron in an atom does not, then, describe a smeared-out electron with a smooth charge density. The electron is either here, or there, or somewhere else, but wherever it is, it is a point charge. On the other hand, think of a situation in which there are an enormous number of particles in exactly the same state, a very large number of them with exactly the same wave function. Then what? One of them is here and one of them is there, and the probability of finding any one of them at a given place is proportional to \u03c8 \u03c8 \u2217 . But since there are so many particles, if I look in any volume dxdydz I will generally find a number close to \u03c8 \u03c8 \u2217 dxdydz . So in a situation in which \u03c8 is the wave function for each of an enormous number of particles which are all in the same state, \u03c8 \u03c8 \u2217 can be interpreted as the density of particles. If, under these circumstances, each particle carries the same charge q , we can, in fact, go further and interpret \u03c8 \u2217 \u03c8 as the density of electricity. Normally, \u03c8 \u03c8 \u2217 is given the dimensions of a probability density, then \u03c8 should be multiplied by q to give the dimensions of a charge density. For our present purposes we can put this constant factor into \u03c8 , and take \u03c8 \u03c8 \u2217 itself as the electric charge density. With this understanding, J (the current of probability I have calculated) becomes directly the electric current density. So in the situation in which we can have very many particles in exactly the same state, there is possible a new physical interpretation of the wave functions. The charge density and the electric current can be calculated directly from the wave functions and the wave functions take on a physical meaning which extends into classical, macroscopic situations. Something similar can happen with neutral particles. When we have the wave function of a single photon, it is the amplitude to find a photon somewhere. Although we haven\u2019t ever written it down there is an equation for the photon wave function analogous to the Schr\u00f6dinger equation for the electron. The photon equation is just the same as Maxwell\u2019s equations for the electromagnetic field, and the wave function is the same as the vector potential A . The wave function turns out to be just the vector potential. The quantum physics is the same thing as the classical physics because photons are noninteracting Bose particles and many of them can be in the same state\u2014as you know, they like to be in the same state. The moment that you have billions in the same state (that is, in the same electromagnetic wave), you can measure the wave function, which is the vector potential, directly. Of course, it worked historically the other way. The first observations were on situations with many photons in the same state, and so we were able to discover the correct equation for a single photon by observing directly with our hands on a macroscopic level the nature of the wave function. Now the trouble with the electron is that you cannot put more than one in the same state. Therefore, it was long believed that the wave function of the Schr\u00f6dinger equation would never have a macroscopic representation analogous to the macroscopic representation of the amplitude for photons. On the other hand, it is now realized that the phenomenon of superconductivity presents us with just this situation. As you know, very many metals become superconducting below a certain temperature9\u2014the temperature is different for different metals. When you reduce the temperature sufficiently the metals conduct electricity without any resistance. This phenomenon has been observed for a very large number of metals but not for all, and the theory of this phenomenon has caused a great deal of difficulty. It took a very long time to understand what was going on inside of superconductors, and I will only describe enough of it for our present purposes. It turns out that due to the interactions of the electrons with the vibrations of the atoms in the lattice, there is a small net effective attraction between the electrons. The result is that the electrons form together, if I may speak very qualitatively and crudely, bound pairs. Now you know that a single electron is a Fermi particle. But a bound pair would act as a Bose particle, because if I exchange both electrons in a pair I change the sign of the wave function twice, and that means that I don\u2019t change anything. A pair is a Bose particle. The energy of pairing\u2014that is, the net attraction\u2014is very, very weak. Only a tiny temperature is needed to throw the electrons apart by thermal agitation, and convert them back to \u201cnormal\u201d electrons. But when you make the temperature sufficiently low that they have to do their very best to get into the absolutely lowest state; then they do collect in pairs. I don\u2019t wish you to imagine that the pairs are really held together very closely like a point particle. As a matter of fact, one of the great difficulties of understanding this phenomenon originally was that that is not the way things are. The two electrons which form the pair are really spread over a considerable distance; and the mean distance between pairs is relatively smaller than the size of a single pair. Several pairs are occupying the same space at the same time. Both the reason why electrons in a metal form pairs and an estimate of the energy given up in forming a pair have been a triumph of recent times. This fundamental point in the theory of superconductivity was first explained in the theory of Bardeen, Cooper, and Schrieffer,10 but that is not the subject of this seminar. We will accept, however, the idea that the electrons do, in some manner or other, work in pairs, that we can think of these pairs as behaving more or less like particles, and that we can therefore talk about the wave function for a \u201cpair.\u201d Now the Schr\u00f6dinger equation for the pair will be more or less like Eq. (21.3). There will be one difference in that the charge q will be twice the charge of an electron. Also, we don\u2019t know the inertia\u2014or effective mass\u2014for the pair in the crystal lattice, so we don\u2019t know what number to put in for m . Nor should we think that if we go to very high frequencies (or short wavelengths), this is exactly the right form, because the kinetic energy that corresponds to very rapidly varying wave functions may be so great as to break up the pairs. At finite temperatures there are always a few pairs which are broken up according to the usual Boltzmann theory. The probability that a pair is broken is proportional to exp(\u2212 E pair /\u03baT) . The electrons that are not bound in pairs are called \u201cnormal\u201d electrons and will move around in the crystal in the ordinary way. I will, however, consider only the situation at essentially zero temperature\u2014or, in any case, I will disregard the complications produced by those electrons which are not in pairs. Since electron pairs are bosons, when there are a lot of them in a given state there is an especially large amplitude for other pairs to go to the same state. So nearly all of the pairs will be locked down at the lowest energy in exactly the same state\u2014it won\u2019t be easy to get one of them into another state. There\u2019s more amplitude to go into the same state than into an unoccupied state by the famous factor n \u2212 \u2212 \u221a , where n\u22121 is the occupancy of the lowest state. So we would expect all the pairs to be moving in the same state. What then will our theory look like? I\u2019ll call \u03c8 the wave function of a pair in the lowest energy state. However, since \u03c8 \u03c8 \u2217 is going to be proportional to the charge density \u03c1 , I can just as well write \u03c8 as the square root of the charge density times some phase factor: \u03c8(r)= \u03c1 1/2 (r) e i\u03b8(r) , (21.17) where \u03c1 and \u03b8 are real functions of r . (Any complex function can, of course, be written this way.) It\u2019s clear what we mean when we talk about the charge density, but what is the physical meaning of the phase \u03b8 of the wave function? Well, let\u2019s see what happens if we substitute \u03c8(r) into Eq. (21.12), and express the current density in terms of these new variables \u03c1 and \u03b8 . It\u2019s just a change of variables and I won\u2019t go through all the algebra, but it comes out J= \u210f m (\u2207\u03b8\u2212 q \u210f A)\u03c1. (21.18) Since both the current density and the charge density have a direct physical meaning for the superconducting electron gas, both \u03c1 and \u03b8 are real things. The phase is just as observable as \u03c1 ; it is a piece of the current density J . The absolute phase is not observable, but if the gradient of the phase is known everywhere, the phase is known except for a constant. You can define the phase at one point, and then the phase everywhere is determined. Incidentally, the equation for the current can be analyzed a little nicer, when you think that the current density J is in fact the charge density times the velocity of motion of the fluid of electrons, or \u03c1v . Equation (21.18) is then equivalent to mv=\u210f\u2207\u03b8\u2212qA. (21.19) Notice that there are two pieces in the mv -momentum; one is a contribution from the vector potential, and the other, a contribution from the behavior of the wave function. In other words, the quantity \u210f\u2207\u03b8 is just what we have called the p -momentum. Now we can describe some of the phenomena of superconductivity. First, there is no electrical resistance. There\u2019s no resistance because all the electrons are collectively in the same state. In the ordinary flow of current you knock one electron or the other out of the regular flow, gradually deteriorating the general momentum. But here to get one electron away from what all the others are doing is very hard because of the tendency of all Bose particles to go in the same state. A current once started, just keeps on going forever. It\u2019s also easy to understand that if you have a piece of metal in the superconducting state and turn on a magnetic field which isn\u2019t too strong (we won\u2019t go into the details of how strong), the magnetic field can\u2019t penetrate the metal. If, as you build up the magnetic field, any of it were to build up inside the metal, there would be a rate of change of flux which would produce an electric field, and an electric field would immediately generate a current which, by Lenz\u2019s law, would oppose the flux. Since all the electrons will move together, an infinitesimal electric field will generate enough current to oppose completely any applied magnetic field. So if you turn the field on after you\u2019ve cooled a metal to the superconducting state, it will be excluded. Even more interesting is a related phenomenon discovered experimentally by Meissner.11 If you have a piece of the metal at a high temperature (so that it is a normal conductor) and establish a magnetic field through it, and then you lower the temperature below the critical temperature (where the metal becomes a superconductor), the field is expelled. In other words, it starts up its own current\u2014and in just the right amount to push the field out. We can see the reason for that in the equations, and I\u2019d like to explain how. Suppose that we take a piece of superconducting material which is in one lump. Then in a steady situation of any kind the divergence of the current must be zero because there\u2019s no place for it to go. It is convenient to choose to make the divergence of A equal to zero. (I should explain why choosing this convention doesn\u2019t mean any loss of generality, but I don\u2019t want to take the time.) Taking the divergence of Eq. (21.18), then gives that the Laplacian of \u03b8 is equal to zero. One moment. What about the variation of \u03c1 ? I forgot to mention an important point. There is a background of positive charge in this metal due to the atomic ions of the lattice. If the charge density \u03c1 is uniform there is no net charge and no electric field. If there would be any accumulation of electrons in one region the charge wouldn\u2019t be neutralized and there would be a terrific repulsion pushing the electrons apart.12 So in ordinary circumstances the charge density of the electrons in the superconductor is almost perfectly uniform\u2014I can take \u03c1 as a constant. Now the only way that \u2207 2 \u03b8 can be zero everywhere inside the lump of metal is for \u03b8 to be a constant. And that means that there is no contribution to J from p -momentum. Equation (21.18) then says that the current is proportional to \u03c1 times A . So everywhere in a lump of superconducting material the current is necessarily proportional to the vector potential: J=\u2212\u03c1 q m A. (21.20) Since \u03c1 and q have the same (negative) sign, and since \u03c1 is a constant, I can set \u2212\u03c1q/m=\u2212(some positive constant) ; then J=\u2212(some positive constant)A. (21.21) This equation was originally proposed by London and London13 to explain the experimental observations of superconductivity\u2014long before the quantum mechanical origin of the effect was understood. Now we can use Eq. (21.20) in the equations of electromagnetism to solve for the fields. The vector potential is related to the current density by \u2207 2 A=\u2212 1 \u03f5 0 c 2 J. (21.22) If I use Eq. (21.21) for J , I have \u2207 2 A= \u03bb 2 A, (21.23) where \u03bb 2 is just a new constant; \u03bb 2 =\u03c1 q \u03f5 0 m c 2 . (21.24) We can now try to solve this equation for A and see what happens in detail. For example, in one dimension Eq. (21.23) has exponential solutions of the form e \u2212\u03bbx and e +\u03bbx . These solutions mean that the vector potential must decrease exponentially as you go from the surface into the material. (It can\u2019t increase because there would be a blow up.) If the piece of metal is very large compared to 1/\u03bb , the field only penetrates to a thin layer at the surface\u2014a layer about 1/\u03bb in thickness. The entire remainder of the interior is free of field, as sketched in Fig. 21\u20133. This is the explanation of the Meissner effect. How big is the distance 1/\u03bb ? Well, remember that r 0 , the \u201celectromagnetic radius\u201d of the electron ( 2.8\u00d7 10 \u221213 cm), is given by m c 2 = q 2 e 4\u03c0 \u03f5 0 r 0 . 2 Also, remember that q in Eq. (21.24) is twice the charge of an electron, so q \u03f5 0 m c 2 = 8\u03c0 r 0 q e . 8 Writing \u03c1 as q e N , where N is the number of electrons per cubic centimeter, we have \u03bb 2 =8\u03c0N r 0 . (21.25) For a metal such as lead there are about 3\u00d7 10 22 atoms per cm 3 , so if each one contributed only one conduction electron, 1/\u03bb would be about 2\u00d7 10 \u22126 cm. That gives you the order of magnitude. The London equation (21.21) was proposed to account for the observed facts of superconductivity including the Meissner effect. In recent times, however, there have been some even more dramatic predictions. One prediction made by London was so peculiar that nobody paid much attention to it until recently. I will now discuss it. This time instead of taking a single lump, suppose we take a ring whose thickness is large compared to 1/\u03bb , and try to see what would happen if we started with a magnetic field through the ring, then cooled it to the superconducting state, and afterward removed the original source of B . The sequence of events is sketched in Fig. 21\u20134. In the normal state there will be a field in the body of the ring as sketched in part (a) of the figure. When the ring is made superconducting, the field is forced outside of the material (as we have just seen). There will then be some flux through the hole of the ring as sketched in part (b). If the external field is now removed, the lines of field going through the hole are \u201ctrapped\u201d as shown in part (c). The flux \u03a6 through the center can\u2019t decrease because \u2202\u03a6/\u2202t must be equal to the line integral of E around the ring, which is zero in a superconductor. As the external field is removed a super current starts flowing around the ring to keep the flux through the ring a constant. (It\u2019s the old eddy-current idea, only with zero resistance.) These currents will, however, all flow near the surface (down to a depth 1/\u03bb ), as can be shown by the same kind of analysis that I made for the solid block. These currents can keep the magnetic field out of the body of the ring, and produce the permanently trapped magnetic field as well. Now, however, there is an essential difference, and our equations predict a surprising effect. The argument I made above that \u03b8 must be a constant in a solid block does not apply for a ring, as you can see from the following arguments. Well inside the body of the ring the current density J is zero; so Eq. (21.18) gives \u210f\u2207\u03b8=qA. (21.26) Now consider what we get if we take the line integral of A around a curve \u0393 , which goes around the ring near the center of its cross-section so that it never gets near the surface, as drawn in Fig. 21\u20135. From Eq. (21.26), \u210f\u222e\u2207\u03b8\u22c5ds=q\u222eA\u22c5ds. (21.27) Now you know that the line integral of A around any loop is equal to the flux of B through the loop \u222eA\u22c5ds=\u03a6. \u222e Equation (21.27) then becomes \u222e\u2207\u03b8\u22c5ds= q \u210f \u03a6. (21.28) The line integral of a gradient from one point to another (say from point 1 to point 2 ) is the difference of the values of the function at the two points. Namely, \u222b 2 1 \u2207\u03b8\u22c5ds= \u03b8 2 \u2212 \u03b8 1 . 2 If we let the two end points 1 and 2 come together to make a closed loop you might at first think that \u03b8 2 would equal \u03b8 1 , so that the integral in Eq. (21.28) would be zero. That would be true for a closed loop in a simply-connected piece of superconductor, but it is not necessarily true for a ring-shaped piece. The only physical requirement we can make is that there can be only one value of the wave function for each point. Whatever \u03b8 does as you go around the ring, when you get back to the starting point the \u03b8 you get must give the same value for the wave function \u03c8= \u03c1 \u2212 \u2212 \u221a e i\u03b8 . i \u03b8 This will happen if \u03b8 changes by 2\u03c0n , where n is any integer. So if we make one complete turn around the ring the left-hand side of Eq. (21.27) must be \u210f\u22c52\u03c0n . Using Eq. (21.28), I get that 2\u03c0n\u210f=q\u03a6. (21.29) The trapped flux must always be an integer times 2\u03c0\u210f/q ! If you would think of the ring as a classical object with an ideally perfect (that is, infinite) conductivity, you would think that whatever flux was initially found through it would just stay there\u2014any amount of flux at all could be trapped. But the quantum-mechanical theory of superconductivity says that the flux can be zero, or 2\u03c0\u210f/q , or 4\u03c0\u210f/q , or 6\u03c0\u210f/q , and so on, but no value in between. It must be a multiple of a basic quantum mechanical unit. London14 predicted that the flux trapped by a superconducting ring would be quantized and said that the possible values of the flux would be given by Eq. (21.29) with q equal to the electronic charge. According to London the basic unit of flux should be 2\u03c0\u210f/ q e , which is about 4\u00d7 10 \u22127 gauss\u22c5 cm 2 . To visualize such a flux, think of a tiny cylinder a tenth of a millimeter in diameter; the magnetic field inside it when it contains this amount of flux is about one percent of the earth\u2019s magnetic field. It should be possible to observe such a flux by a sensitive magnetic measurement. In 1961 such a quantized flux was looked for and found by Deaver and Fairbank15 at Stanford University and at about the same time by Doll and N\u00e4bauer16 in Germany. In the experiment of Deaver and Fairbank, a tiny cylinder of superconductor was made by electroplating a thin layer of tin on a one-centimeter length of No. 56 ( 1.3\u00d7 10 \u22123 cm diameter) copper wire. The tin becomes superconducting below 3.8 \u2218 K while the copper remains a normal metal. The wire was put in a small controlled magnetic field, and the temperature reduced until the tin became superconducting. Then the external source of field was removed. You would expect this to generate a current by Lenz\u2019s law so that the flux inside would not change. The little cylinder should now have magnetic moment proportional to the flux inside. The magnetic moment was measured by jiggling the wire up and down (like the needle on a sewing machine, but at the rate of 100 cycles per second) inside a pair of little coils at the ends of the tin cylinder. The induced voltage in the coils was then a measure of the magnetic moment. When the experiment was done by Deaver and Fairbank, they found that the flux was quantized, but that the basic unit was only one-half as large as London had predicted. Doll and N\u00e4bauer got the same result. At first this was quite mysterious,17 but we now understand why it should be so. According to the Bardeen, Cooper, and Schrieffer theory of superconductivity, the q which appears in Eq. (21.29) is the charge of a pair of electrons and so is equal to 2 q e . The basic flux unit is \u03a6 0 = \u03c0\u210f q e \u22482\u00d7 10 \u22127 gauss\u22c5 cm 2 (21.30) or one-half the amount predicted by London. Everything now fits together, and the measurements show the existence of the predicted purely quantum-mechanical effect on a large scale. The Meissner effect and the flux quantization are two confirmations of our general ideas. Just for the sake of completeness I would like to show you what the complete equations of a superconducting fluid would be from this point of view\u2014it is rather interesting. Up to this point I have only put the expression for \u03c8 into equations for charge density and current. If I put it into the complete Schr\u00f6dinger equation I get equations for \u03c1 and \u03b8 . It should be interesting to see what develops, because here we have a \u201cfluid\u201d of electron pairs with a charge density \u03c1 and a mysterious \u03b8 \u2014we can try to see what kind of equations we get for such a \u201cfluid\u201d! So we substitute the wave function of Eq. (21.17) into the Schr\u00f6dinger equation (21.3) and remember that \u03c1 and \u03b8 are real functions of x , y , z , and t . If we separate real and imaginary parts we obtain then two equations. To write them in a shorter form I will\u2014following Eq. (21.19)\u2014write \u210f m \u2207\u03b8\u2212 q m A=v. (21.31) One of the equations I get is then \u2202\u03c1 \u2202t =\u2212\u2207\u22c5\u03c1v. (21.32) Since \u03c1v is first J , this is just the continuity equation once more. The other equation I obtain tells how \u03b8 varies; it is \u210f \u2202\u03b8 \u2202t =\u2212 m 2 v 2 \u2212q\u03d5+ \u210f 2 2m { 1 \u03c1 \u2212 \u2212 \u221a \u2207 2 ( \u03c1 \u2212 \u2212 \u221a )}. (21.33) Those who are thoroughly familiar with hydrodynamics (of which I\u2019m sure few of you are) will recognize this as the equation of motion for an electrically charged fluid if we identify \u210f\u03b8 as the \u201cvelocity potential\u201d\u2014except that the last term, which should be the energy of compression of the fluid, has a rather strange dependence on the density \u03c1 . In any case, the equation says that the rate of change of the quantity \u210f\u03b8 is given by a kinetic energy term, \u2212 1 2 m v 2 , plus a potential energy term, \u2212q\u03d5 , with an additional term, containing the factor \u210f 2 , which we could call a \u201cquantum mechanical energy.\u201d We have seen that inside a superconductor \u03c1 is kept very uniform by the electrostatic forces, so this term can almost certainly be neglected in every practical application provided we have only one superconducting region. If we have a boundary between two superconductors (or other circumstances in which the value of \u03c1 may change rapidly) this term can become important. For those who are not so familiar with the equations of hydrodynamics, I can rewrite Eq. (21.33) in a form that makes the physics more apparent by using Eq. (21.31) to express \u03b8 in terms of v . Taking the gradient of the whole of Eq. (21.33) and expressing \u2207\u03b8 in terms of A and v by using (21.31), I get \u2202v \u2202t = q m (\u2212\u2207\u03d5\u2212 \u2202A \u2202t )\u2212v\u00d7(\u2207\u00d7v) \u2212(v\u22c5\u2207)v+\u2207 \u210f 2 2 m 2 ( 1 \u03c1 \u2212 \u2212 \u221a \u2207 2 \u03c1 \u2212 \u2212 \u221a ). (21.34) What does this equation mean? First, remember that \u2212\u2207\u03d5\u2212 \u2202A \u2202t =E. (21.35) Next, notice that if I take the curl of Eq. (21.31), I get \u2207\u00d7v=\u2212 q m \u2207\u00d7A, (21.36) since the curl of a gradient is always zero. But \u2207\u00d7A is the magnetic field B , so the first two terms can be written as q m (E+v\u00d7B). q Finally, you should understand that \u2202v/\u2202t stands for the rate of change of the velocity of the fluid at a point. If you concentrate on a particular particle, its acceleration is the total derivative of v (or, as it is sometimes called in fluid dynamics, the \u201ccomoving acceleration\u201d), which is related to \u2202v/\u2202t by18 dv dt \u2223 \u2223 \u2223 comoving = \u2202v \u2202t +(v\u22c5\u2207)v. (21.37) This extra term also appears as the third term on the right side of Eq. (21.34). Taking it to the left side, I can write Eq. (21.34) in the following way: m dv dt \u2223 \u2223 \u2223 comoving =q(E+v\u00d7B)+\u2207 \u210f 2 2m ( 1 \u03c1 \u2212 \u2212 \u221a \u2207 2 \u03c1 \u2212 \u2212 \u221a ). (21.38) We also have from Eq. (21.36) that \u2207\u00d7v=\u2212 q m B. (21.39) These two equations are the equations of motion of the superconducting electron fluid. The first equation is just Newton\u2019s law for a charged fluid in an electromagnetic field. It says that the acceleration of each particle of the fluid whose charge is q comes from the ordinary Lorentz force q(E+v\u00d7B) plus an additional force, which is the gradient of some mystical quantum mechanical potential\u2014a force which is not very big except at the junction between two superconductors. The second equation says that the fluid is \u201cideal\u201d\u2014the curl of v has zero divergence (the divergence of B is always zero). That means that the velocity can be expressed in terms of velocity potential. Ordinarily one writes that \u2207\u00d7v=0 for an ideal fluid, but for an ideal charged fluid in a magnetic field, this gets modified to Eq. (21.39). So, Schr\u00f6dinger\u2019s equation for the electron pairs in a superconductor gives us the equations of motion of an electrically charged ideal fluid. Superconductivity is the same as the problem of the hydrodynamics of a charged liquid. If you want to solve any problem about superconductors you take these equations for the fluid [or the equivalent pair, Eqs. (21.32) and (21.33)], and combine them with Maxwell\u2019s equations to get the fields. (The charges and currents you use to get the fields must, of course, include the ones from the superconductor as well as from the external sources.) Incidentally, I believe that Eq. (21.38) is not quite correct, but ought to have an additional term involving the density. This new term does not depend on quantum mechanics, but comes from the ordinary energy associated with variations of density. Just as in an ordinary fluid there should be a potential energy density proportional to the square of the deviation of \u03c1 from \u03c1 0 , the undisturbed density (which is, here, also equal to the charge density of the crystal lattice). Since there will be forces proportional to the gradient of this energy, there should be another term in Eq. (21.38) of the form: (const)\u2207(\u03c1\u2212 \u03c1 0 ) 2 . This term did not appear from the analysis because it comes from the interactions between particles, which I neglected in using an independent-particle approximation. It is, however, just the force I referred to when I made the qualitative statement that electrostatic forces would tend to keep \u03c1 nearly constant inside a superconductor. I would like to discuss next a very interesting situation that was noticed by Josephson19 while analyzing what might happen at a junction between two superconductors. Suppose we have two superconductors which are connected by a thin layer of insulating material as in Fig. 21\u20136. Such an arrangement is now called a \u201cJosephson junction.\u201d If the insulating layer is thick, the electrons can\u2019t get through; but if the layer is thin enough, there can be an appreciable quantum mechanical amplitude for electrons to jump across. This is just another example of the quantum-mechanical penetration of a barrier. Josephson analyzed this situation and discovered that a number of strange phenomena should occur. In order to analyze such a junction I\u2019ll call the amplitude to find an electron on one side, \u03c8 1 , and the amplitude to find it on the other, \u03c8 2 . In the superconducting state the wave function \u03c8 1 is the common wave function of all the electrons on one side, and \u03c8 2 is the corresponding function on the other side. I could do this problem for different kinds of superconductors, but let us take a very simple situation in which the material is the same on both sides so that the junction is symmetrical and simple. Also, for a moment let there be no magnetic field. Then the two amplitudes should be related in the following way: i\u210f \u2202 \u03c8 1 \u2202t i\u210f \u2202 \u03c8 2 \u2202t = U 1 \u03c8 1 +K \u03c8 2 , = U 2 \u03c8 2 +K \u03c8 1 . The constant K is a characteristic of the junction. If K were zero, these two equations would just describe the lowest energy state\u2014with energy U \u2014of each superconductor. But there is coupling between the two sides by the amplitude K that there may be leakage from one side to the other. (It is just the \u201cflip-flop\u201d amplitude of a two-state system.) If the two sides are identical, U 1 would equal U 2 and I could just subtract them off. But now suppose that we connect the two superconducting regions to the two terminals of a battery so that there is a potential difference V across the junction. Then U 1 \u2212 U 2 =qV . I can, for convenience, define the zero of energy to be halfway between, then the two equations are i\u210f \u2202 \u03c8 1 \u2202t i\u210f \u2202 \u03c8 2 \u2202t =+ qV 2 \u03c8 1 +K \u03c8 2 , =\u2212 qV 2 \u03c8 2 +K \u03c8 1 . (21.40) These are the standard equations for two quantum mechanical states coupled together. This time, let\u2019s analyze these equations in another way. Let\u2019s make the substitutions \u03c8 1 \u03c8 2 = \u03c1 1 \u2212 \u2212 \u221a e i \u03b8 1 , = \u03c1 2 \u2212 \u2212 \u221a e i \u03b8 2 , (21.41) where \u03b8 1 and \u03b8 2 are the phases on the two sides of the junction and \u03c1 1 and \u03c1 2 are the density of electrons at those two points. Remember that in actual practice \u03c1 1 and \u03c1 2 are almost exactly the same and are equal to \u03c1 0 , the normal density of electrons in the superconducting material. Now if you substitute these equations for \u03c8 1 and \u03c8 2 into (21.40), you get four equations by equating the real and imaginary parts in each case. Letting ( \u03b8 2 \u2212 \u03b8 1 )=\u03b4 , for short, the result is \u03c1 \u02d9 1 \u03c1 \u02d9 2 =+ 2 \u210f K \u03c1 2 \u03c1 1 \u2212 \u2212 \u2212 \u2212 \u221a sin\u03b4, =\u2212 2 \u210f K \u03c1 2 \u03c1 1 \u2212 \u2212 \u2212 \u2212 \u221a sin\u03b4, \u03b8 \u02d9 1 \u03b8 \u02d9 2 =\u2212 K \u210f \u03c1 2 \u03c1 1 \u2212 \u2212 \u2212 \u221a cos\u03b4\u2212 qV 2\u210f , =\u2212 K \u210f \u03c1 1 \u03c1 2 \u2212 \u2212 \u2212 \u221a cos\u03b4+ qV 2\u210f . (21.42) (21.43) The first two equations say that \u03c1 \u02d9 1 =\u2212 \u03c1 \u02d9 2 . \u201cBut,\u201d you say, \u201cthey must both be zero if \u03c1 1 and \u03c1 2 are both constant and equal to \u03c1 0 .\u201d Not quite. These equations are not the whole story. They say what \u03c1 \u02d9 1 and \u03c1 \u02d9 2 would be if there were no extra electric forces due to an unbalance between the electron fluid and the background of positive ions. They tell how the densities would start to change, and therefore describe the kind of current that would begin to flow. This current from side 1 to side 2 would be just \u03c1 \u02d9 1 (or \u2212 \u03c1 \u02d9 2 ), or J= 2K \u210f \u03c1 1 \u03c1 2 \u2212 \u2212 \u2212 \u2212 \u221a sin\u03b4. (21.44) Such a current would soon charge up side 2 , except that we have forgotten that the two sides are connected by wires to the battery. The current that flows will not charge up region 2 (or discharge region 1 ) because currents will flow to keep the potential constant. These currents from the battery have not been included in our equations. When they are included, \u03c1 1 and \u03c1 2 do not in fact change, but the current across the junction is still given by Eq. (21.44). Since \u03c1 1 and \u03c1 2 do remain constant and equal to \u03c1 0 , let\u2019s set 2K \u03c1 0 /\u210f= J 0 , and write J= J 0 sin\u03b4. (21.45) J 0 , like K , is then a number which is a characteristic of the particular junction. The other pair of equations (21.43) tells us about \u03b8 1 and \u03b8 2 . We are interested in the difference \u03b4= \u03b8 2 \u2212 \u03b8 1 to use Eq. (21.45); what we get is \u03b4 \u02d9 = \u03b8 \u02d9 2 \u2212 \u03b8 \u02d9 1 = qV \u210f . (21.46) That means that we can write \u03b4(t)= \u03b4 0 + q \u210f \u222bV(t)dt, (21.47) where \u03b4 0 is the value of \u03b4 at t=0 . Remember also that q is the charge of a pair, namely, q=2 q e . In Eqs. (21.45) and (21.47) we have an important result, the general theory of the Josephson junction. Now what are the consequences? First, put on a dc voltage. If you put on a dc voltage, V 0 , the argument of the sine becomes ( \u03b4 0 +(q/\u210f) V 0 t) . Since \u210f is a small number (compared to ordinary voltage and times), the sine oscillates rather rapidly and the net current is nothing. (In practice, since the temperature is not zero, you would get a small current due to the conduction by \u201cnormal\u201d electrons.) On the other hand if you have zero voltage across the junction, you can get a current! With no voltage the current can be any amount between + J 0 and \u2212 J 0 (depending on the value of \u03b4 0 ). But try to put a voltage across it and the current goes to zero. This strange behavior has recently been observed experimentally.20 There is another way of getting a current\u2014by applying a voltage at a very high frequency in addition to a dc voltage. Let V= V 0 +vcos\u03c9t, V V t where v\u226a V 0 . Then \u03b4(t) is \u03b4 0 + q \u210f V 0 t+ q \u210f v \u03c9 sin\u03c9t. q q v Now for \u0394x small, sin(x+\u0394x)\u2248sinx+\u0394xcosx. ( ) Using this approximation for sin\u03b4 , I get J= J 0 [sin( \u03b4 0 + q \u210f V 0 t)+ q \u210f v \u03c9 sin\u03c9tcos( \u03b4 0 + q \u210f V 0 t)]. q q v q The first term is zero on the average, but the second term is not if \u03c9= q \u210f V 0 . q There should be a current if the ac voltage has just this frequency. Shapiro21 claims to have observed such a resonance effect. If you look up papers on the subject you will find that they often write the formula for the current as J= J 0 sin( \u03b4 0 + 2 q e \u210f \u222bA\u22c5ds), (21.48) where the integral is to be taken across the junction. The reason for this is that when there\u2019s a vector potential across the junction the flip-flop amplitude is modified in phase in the way that we explained earlier. If you chase that extra phase through, it comes out as given above. Finally, I would like to describe a very dramatic and interesting experiment which has recently been made on the interference of the currents from each of two junctions. In quantum mechanics we\u2019re used to the interference between amplitudes from two different slits. Now we\u2019re going to do the interference between two junctions caused by the difference in the phase of the arrival of the currents through two different paths. In Fig. 21\u20137, I show two different junctions, \u201ca\u201d and \u201cb\u201d, connected in parallel. The ends, P and Q , are connected to our electrical instruments which measure any current flow. The external current, J total , will be the sum of the currents through the two junctions. Let J a and J b be the currents through the two junctions, and let their phases be \u03b4 a and \u03b4 b . Now the phase difference of the wave functions between P and Q must be the same whether you go on one route or the other. Along the route through junction \u201ca\u201d, the phase difference between P and Q is \u03b4 a plus the line integral of the vector potential along the upper route: \u0394 Phase P\u2192Q = \u03b4 a + 2 q e \u210f \u222b upper A\u22c5ds. (21.49) Why? Because the phase \u03b8 is related to A by Eq. (21.26). If you integrate that equation along some path, the left-hand side gives the phase change, which is then just proportional to the line integral of A , as we have written here. The phase change along the lower route can be written similarly \u0394 Phase P\u2192Q = \u03b4 b + 2 q e \u210f \u222b lower A\u22c5ds. (21.50) These two must be equal; and if I subtract them I get that the difference of the deltas must be the line integral of A around the circuit: \u03b4 b \u2212 \u03b4 a = 2 q e \u210f \u222e \u0393 A\u22c5ds. 2 \u222e Here the integral is around the closed loop \u0393 of Fig. 21\u20137 which circles through both junctions. The integral over A is the magnetic flux \u03a6 through the loop. So the two \u03b4 \u2019s are going to differ by 2 q e /\u210f times the magnetic flux \u03a6 which passes between the two branches of the circuit: \u03b4 b \u2212 \u03b4 a = 2 q e \u210f \u03a6. (21.51) I can control this phase difference by changing the magnetic field on the circuit, so I can adjust the differences in phases and see whether or not the total current that flows through the two junctions shows any interference of the two parts. The total current will be the sum of J a and J b . For convenience, I will write \u03b4 a = \u03b4 0 \u2212 q e \u210f \u03a6, \u03b4 b = \u03b4 0 + q e \u210f \u03a6. q q Then, J total = J 0 {sin( \u03b4 0 \u2212 q e \u210f \u03a6)+sin( \u03b4 0 + q e \u210f \u03a6)} =2 J 0 sin \u03b4 0 cos q e \u03a6 \u210f . (21.52) Now we don\u2019t know anything about \u03b4 0 , and nature can adjust that anyway she wants depending on the circumstances. In particular, it will depend on the external voltage we apply to the junction. No matter what we do, however, sin \u03b4 0 can never get bigger than 1 . So the maximum current for any given \u03a6 is given by J max =2 J 0 \u2223 \u2223 cos q e \u210f \u03a6 \u2223 \u2223 . | q | This maximum current will vary with \u03a6 and will itself have maxima whenever \u03a6=n \u03c0\u210f q e , \u210f with n some integer. That is to say that the current takes on its maximum values where the flux linkage has just those quantized values we found in Eq. (21.30)! The Josephson current through a double junction was recently measured22 as a function of the magnetic field in the area between the junctions. The results are shown in Fig. 21\u20138. There is a general background of current from various effects we have neglected, but the rapid oscillations of the current with changes in the magnetic field are due to the interference term cos q e \u03a6/\u210f of Eq. (21.52). One of the intriguing questions about quantum mechanics is the question of whether the vector potential exists in a place where there\u2019s no field.23 This experiment I have just described has also been done with a tiny solenoid between the two junctions so that the only significant magnetic B field is inside the solenoid and a negligible amount is on the superconducting wires themselves. Yet it is reported that the amount of current depends oscillatorily on the flux of magnetic field inside that solenoid even though that field never touches the wires\u2014another demonstration of the \u201cphysical reality\u201d of the vector potential.24 I don\u2019t know what will come next. But look what can be done. First, notice that the interference between two junctions can be used to make a sensitive magnetometer. If a pair of junctions is made with an enclosed area of, say, 1 mm 2 , the maxima in the curve of Fig. 21\u20138 would be separated by 2\u00d7 10 \u22126 gauss. It is certainly possible to tell when you are 1/10 of the way between two peaks; so it should be possible to use such a junction to measure magnetic fields as small as 2\u00d7 10 \u22127 gauss\u2014or to measure larger fields to such a precision. One should be able to go even further. Suppose for example we put a set of 10 or 20 junctions close together and equally spaced. Then we can have the interference between 10 or 20 slits and as we change the magnetic field we will get very sharp maxima and minima. Instead of a 2 -slit interference we can have a 20 - or perhaps even a 100 -slit interferometer for measuring the magnetic field. Perhaps we can predict that the measurement of magnetic fields will\u2014by using the effects of quantum-mechanical interference\u2014eventually become almost as precise as the measurement of wavelength of light. These then are some illustrations of things that are happening in modern times\u2014the transistor, the laser, and now these junctions, whose ultimate practical applications are still not known. The quantum mechanics which was discovered in 1926 has had nearly 40 years of development, and rather suddenly it has begun to be exploited in many practical and real ways. We are really getting control of nature on a very delicate and beautiful level. I am sorry to say, gentlemen, that to participate in this adventure it is absolutely imperative that you learn quantum mechanics as soon as possible. It was our hope that in this course we would find a way to make comprehensible to you at the earliest possible moment the mysteries of this part of physics."
    },
    {
        "input": "The Laws of Induction",
        "output": "In the last chapter we described many phenomena which show that the effects of induction are quite complicated and interesting. Now we want to discuss the fundamental principles which govern these effects. We have already defined the emf in a conducting circuit as the total accumulated force on the charges throughout the length of the loop. More specifically, it is the tangential component of the force per unit charge, integrated along the wire once around the circuit. This quantity is equal, therefore, to the total work done on a single charge that travels once around the circuit. We have also given the \u201cflux rule,\u201d which says that the emf is equal to the rate at which the magnetic flux through such a conducting circuit is changing. Let\u2019s see if we can understand why that might be. First, we\u2019ll consider a case in which the flux changes because a circuit is moved in a steady field. In Fig. 17\u20131 we show a simple loop of wire whose dimensions can be changed. The loop has two parts, a fixed U-shaped part (a) and a movable crossbar (b) that can slide along the two legs of the U. There is always a complete circuit, but its area is variable. Suppose we now place the loop in a uniform magnetic field with the plane of the U perpendicular to the field. According to the rule, when the crossbar is moved there should be in the loop an emf that is proportional to the rate of change of the flux through the loop. This emf will cause a current in the loop. We will assume that there is enough resistance in the wire that the currents are small. Then we can neglect any magnetic field from this current. The flux through the loop is wLB , so the \u201cflux rule\u201d would give for the emf\u2014which we write as E \u2014 E=wB dL dt =wBv, where v is the speed of translation of the crossbar. Now we should be able to understand this result from the magnetic v\u00d7B forces on the charges in the moving crossbar. These charges will feel a force, tangential to the wire, equal to vB per unit charge. It is constant along the length w of the crossbar and zero elsewhere, so the integral is E=wvB, which is the same result we got from the rate of change of the flux. The argument just given can be extended to any case where there is a fixed magnetic field and the wires are moved. One can prove, in general, that for any circuit whose parts move in a fixed magnetic field the emf is the time derivative of the flux, regardless of the shape of the circuit. On the other hand, what happens if the loop is stationary and the magnetic field is changed? We cannot deduce the answer to this question from the same argument. It was Faraday\u2019s discovery\u2014from experiment\u2014that the \u201cflux rule\u201d is still correct no matter why the flux changes. The force on electric charges is given in complete generality by F=q(E+v\u00d7B) ; there are no new special \u201cforces due to changing magnetic fields.\u201d Any forces on charges at rest in a stationary wire come from the E term. Faraday\u2019s observations led to the discovery that electric and magnetic fields are related by a new law: in a region where the magnetic field is changing with time, electric fields are generated. It is this electric field which drives the electrons around the wire\u2014and so is responsible for the emf in a stationary circuit when there is a changing magnetic flux. The general law for the electric field associated with a changing magnetic field is \u2207\u00d7E=\u2212 \u2202B \u2202t . We will call this Faraday\u2019s law. It was discovered by Faraday but was first written in differential form by Maxwell, as one of his equations. Let\u2019s see how this equation gives the \u201cflux rule\u201d for circuits. Using Stokes\u2019 theorem, this law can be written in integral form as \u222e\u0393E\u22c5ds =\u222bS(\u2207\u00d7E)\u22c5nda =\u2212\u222bS \u2202B \u2202t \u22c5nda, where, as usual, \u0393 is any closed curve and S is any surface bounded by it. Here, remember, \u0393 is a mathematical curve fixed in space, and S is a fixed surface. Then the time derivative can be taken outside the integral and we have \u222e\u0393E\u22c5ds =\u2212 d dt \u222bSB\u22c5nda =\u2212 d dt (flux through S). Applying this relation to a curve \u0393 that follows a fixed circuit of conductor, we get the \u201cflux rule\u201d once again. The integral on the left is the emf, and that on the right is the negative rate of change of the flux linked by the circuit. So Eq. (17.1) applied to a fixed circuit is equivalent to the \u201cflux rule.\u201d So the \u201cflux rule\u201d\u2014that the emf in a circuit is equal to the rate of change of the magnetic flux through the circuit\u2014applies whether the flux changes because the field changes or because the circuit moves (or both). The two possibilities\u2014\u201ccircuit moves\u201d or \u201cfield changes\u201d\u2014are not distinguished in the statement of the rule. Yet in our explanation of the rule we have used two completely distinct laws for the two cases\u2014 v\u00d7B for \u201ccircuit moves\u201d and \u2207\u00d7E=\u2212\u2202B/\u2202t for \u201cfield changes.\u201d We know of no other place in physics where such a simple and accurate general principle requires for its real understanding an analysis in terms of two different phenomena. Usually such a beautiful generalization is found to stem from a single deep underlying principle. Nevertheless, in this case there does not appear to be any such profound implication. We have to understand the \u201crule\u201d as the combined effects of two quite separate phenomena. We must look at the \u201cflux rule\u201d in the following way. In general, the force per unit charge is F/q=E+v\u00d7B . In moving wires there is the force from the second term. Also, there is an E -field if there is somewhere a changing magnetic field. They are independent effects, but the emf around the loop of wire is always equal to the rate of change of magnetic flux through it. We will now give some examples, due in part to Faraday, which show the importance of keeping clearly in mind the distinction between the two effects responsible for induced emf\u2019s. Our examples involve situations to which the \u201cflux rule\u201d cannot be applied\u2014either because there is no wire at all or because the path taken by induced currents moves about within an extended volume of a conductor. We begin by making an important point: The part of the emf that comes from the E -field does not depend on the existence of a physical wire (as does the v\u00d7B part). The E -field can exist in free space, and its line integral around any imaginary line fixed in space is the rate of change of the flux of B through that line. (Note that this is quite unlike the E -field produced by static charges, for in that case the line integral of E around a closed loop is always zero.) Now we will describe a situation in which the flux through a circuit does not change, but there is nevertheless an emf. Figure 17\u20132 shows a conducting disc which can be rotated on a fixed axis in the presence of a magnetic field. One contact is made to the shaft and another rubs on the outer periphery of the disc. A circuit is completed through a galvanometer. As the disc rotates, the \u201ccircuit,\u201d in the sense of the place in space where the currents are, is always the same. But the part of the \u201ccircuit\u201d in the disc is in material which is moving. Although the flux through the \u201ccircuit\u201d is constant, there is still an emf, as can be observed by the deflection of the galvanometer. Clearly, here is a case where the v\u00d7B force in the moving disc gives rise to an emf which cannot be equated to a change of flux. Now we consider, as an opposite example, a somewhat unusual situation in which the flux through a \u201ccircuit\u201d (again in the sense of the place where the current is) changes but where there is no emf. Imagine two metal plates with slightly curved edges, as shown in Fig. 17\u20133, placed in a uniform magnetic field perpendicular to their surfaces. Each plate is connected to one of the terminals of a galvanometer, as shown. The plates make contact at one point P , so there is a complete circuit. If the plates are now rocked through a small angle, the point of contact will move to P \u2032 . If we imagine the \u201ccircuit\u201d to be completed through the plates on the dotted line shown in the figure, the magnetic flux through this circuit changes by a large amount as the plates are rocked back and forth. Yet the rocking can be done with small motions, so that v\u00d7B is very small and there is practically no emf. The \u201cflux rule\u201d does not work in this case. It must be applied to circuits in which the material of the circuit remains the same. When the material of the circuit is changing, we must return to the basic laws. The correct physics is always given by the two basic laws F=q(E+v\u00d7B), \u2207\u00d7E=\u2212 \u2202B \u2202t . We have said that the electromotive force generated by a changing magnetic field can exist even without conductors; that is, there can be magnetic induction without wires. We may still imagine an electromotive force around an arbitrary mathematical curve in space. It is defined as the tangential component of E integrated around the curve. Faraday\u2019s law says that this line integral is equal to minus the rate of change of the magnetic flux through the closed curve, Eq. (17.3). As an example of the effect of such an induced electric field, we want now to consider the motion of an electron in a changing magnetic field. We imagine a magnetic field which, everywhere on a plane, points in a vertical direction, as shown in Fig. 17\u20134. The magnetic field is produced by an electromagnet, but we will not worry about the details. For our example we will imagine that the magnetic field is symmetric about some axis, i.e., that the strength of the magnetic field will depend only on the distance from the axis. The magnetic field is also varying with time. We now imagine an electron that is moving in this field on a path that is a circle of constant radius with its center at the axis of the field. (We will see later how this motion can be arranged.) Because of the changing magnetic field, there will be an electric field E tangential to the electron\u2019s orbit which will drive it around the circle. Because of the symmetry, this electric field will have the same value everywhere on the circle. If the electron\u2019s orbit has the radius r , the line integral of E around the orbit is equal to minus the rate of change of the magnetic flux through the circle. The line integral of E is just its magnitude times the circumference of the circle, 2\u03c0r . The magnetic flux must, in general, be obtained from an integral. For the moment, we let B av represent the average magnetic field in the interior of the circle; then the flux is this average magnetic field times the area of the circle. We will have 2\u03c0rE= d dt ( B av \u22c5\u03c0 r 2 ). d Since we are assuming r is constant, E is proportional to the time derivative of the average field: E= r 2 d B av dt . (17.4) The electron will feel the electric force qE and will be accelerated by it. Remembering that the relativistically correct equation of motion is that the rate of change of the momentum is proportional to the force, we have qE= dp dt . (17.5) For the circular orbit we have assumed, the electric force on the electron is always in the direction of its motion, so its total momentum will be increasing at the rate given by Eq. (17.5). Combining Eqs. (17.5) and (17.4), we may relate the rate of change of momentum to the change of the average magnetic field: dp dt = qr 2 d B av dt . (17.6) Integrating with respect to t , we find for the electron\u2019s momentum p= p 0 + qr 2 \u0394 B av , (17.7) where p 0 is the momentum with which the electrons start out, and \u0394 B av , is the subsequent change in B av . The operation of a betatron\u2014a machine for accelerating electrons to high energies\u2014is based on this idea. To see how the betatron operates in detail, we must now examine how the electron can be constrained to move on a circle. We have discussed in Chapter 11 of Vol. I the principle involved. If we arrange that there is a magnetic field B at the orbit of the electron, there will be a transverse force qv\u00d7B which, for a suitably chosen B , can cause the electron to keep moving on its assumed orbit. In the betatron this transverse force causes the electron to move in a circular orbit of constant radius. We can find out what the magnetic field at the orbit must be by using again the relativistic equation of motion, but this time, for the transverse component of the force. In the betatron (see Fig. 17\u20134), B is at right angles to v , so the transverse force is qvB . Thus the force is equal to the rate of change of the transverse component p t of the momentum: qvB= d p t dt . (17.8) When a particle is moving in a circle, the rate of change of its transverse momentum is equal to the magnitude of the total momentum times \u03c9 , the angular velocity of rotation (following the arguments of Chapter 11, Vol. I): d p t dt =\u03c9p, (17.9) where, since the motion is circular, \u03c9= v r . (17.10) Setting the magnetic force equal to the transverse acceleration, we have qv B orbit =p v r , (17.11) where B orbit is the field at the radius r . As the betatron operates, the momentum of the electron grows in proportion to B av , according to Eq. (17.7), and if the electron is to continue to move in its proper circle, Eq. (17.11) must continue to hold as the momentum of the electron increases. The value of B orbit must increase in proportion to the momentum p . Comparing Eq. (17.11) with Eq. (17.7), which determines p , we see that the following relation must hold between B av , the average magnetic field inside the orbit at the radius r , and the magnetic field B orbit at the orbit: \u0394 B av =2\u0394 B orbit . (17.12) The correct operation of a betatron requires that the average magnetic field inside the orbit increases at twice the rate of the magnetic field at the orbit itself. In these circumstances, as the energy of the particle is increased by the induced electric field the magnetic field at the orbit increases at just the rate required to keep the particle moving in a circle. The betatron is used to accelerate electrons to energies of tens of millions of volts, or even to hundreds of millions of volts. However, it becomes impractical for the acceleration of electrons to energies much higher than a few hundred million volts for several reasons. One of them is the practical difficulty of attaining the required high average value for the magnetic field inside the orbit. Another is that Eq. (17.6) is no longer correct at very high energies because it does not include the loss of energy from the particle due to its radiation of electromagnetic energy (the so-called synchrotron radiation discussed in Chapter 34, Vol. I). For these reasons, the acceleration of electrons to the highest energies\u2014to many billions of electron volts\u2014is accomplished by means of a different kind of machine, called a synchrotron. We would now like to describe for you an apparent paradox. A paradox is a situation which gives one answer when analyzed one way, and a different answer when analyzed another way, so that we are left in somewhat of a quandary as to actually what should happen. Of course, in physics there are never any real paradoxes because there is only one correct answer; at least we believe that nature will act in only one way (and that is the right way, naturally). So in physics a paradox is only a confusion in our own understanding. Here is our paradox. Imagine that we construct a device like that shown in Fig. 17\u20135. There is a thin, circular plastic disc supported on a concentric shaft with excellent bearings, so that it is quite free to rotate. On the disc is a coil of wire in the form of a short solenoid concentric with the axis of rotation. This solenoid carries a steady current I provided by a small battery, also mounted on the disc. Near the edge of the disc and spaced uniformly around its circumference are a number of small metal spheres insulated from each other and from the solenoid by the plastic material of the disc. Each of these small conducting spheres is charged with the same electrostatic charge Q . Everything is quite stationary, and the disc is at rest. Suppose now that by some accident\u2014or by prearrangement\u2014the current in the solenoid is interrupted, without, however, any intervention from the outside. So long as the current continued, there was a magnetic flux through the solenoid more or less parallel to the axis of the disc. When the current is interrupted, this flux must go to zero. There will, therefore, be an electric field induced which will circulate around in circles centered at the axis. The charged spheres on the perimeter of the disc will all experience an electric field tangential to the perimeter of the disc. This electric force is in the same sense for all the charges and so will result in a net torque on the disc. From these arguments we would expect that as the current in the solenoid disappears, the disc would begin to rotate. If we knew the moment of inertia of the disc, the current in the solenoid, and the charges on the small spheres, we could compute the resulting angular velocity. But we could also make a different argument. Using the principle of the conservation of angular momentum, we could say that the angular momentum of the disc with all its equipment is initially zero, and so the angular momentum of the assembly should remain zero. There should be no rotation when the current is stopped. Which argument is correct? Will the disc rotate or will it not? We will leave this question for you to think about. We should warn you that the correct answer does not depend on any nonessential feature, such as the asymmetric position of a battery, for example. In fact, you can imagine an ideal situation such as the following: The solenoid is made of superconducting wire through which there is a current. After the disc has been carefully placed at rest, the temperature of the solenoid is allowed to rise slowly. When the temperature of the wire reaches the transition temperature between superconductivity and normal conductivity, the current in the solenoid will be brought to zero by the resistance of the wire. The flux will, as before, fall to zero, and there will be an electric field around the axis. We should also warn you that the solution is not easy, nor is it a trick. When you figure it out, you will have discovered an important principle of electromagnetism. In the remainder of this chapter we apply the principles of Section 17\u20131 to analyze a number of the phenomena discussed in Chapter 16. We first look in more detail at the alternating-current generator. Such a generator consists basically of a coil of wire rotating in a uniform magnetic field. The same result can also be achieved by a fixed coil in a magnetic field whose direction rotates in the manner described in the last chapter. We will consider only the former case. Suppose we have a circular coil of wire which can be turned on an axis along one of its diameters. Let this coil be located in a uniform magnetic field perpendicular to the axis of rotation, as in Fig. 17\u20136. We also imagine that the two ends of the coil are brought to external connections through some kind of sliding contacts. Due to the rotation of the coil, the magnetic flux through it will be changing. The circuit of the coil will therefore have an emf in it. Let S be the area of the coil and \u03b8 the angle between the magnetic field and the normal to the plane of the coil.1 The flux through the coil is then BScos\u03b8. (17.13) If the coil is rotating at the uniform angular velocity \u03c9 , \u03b8 varies with time as \u03b8=\u03c9t . Each turn of the coil will have an emf equal to the rate of change of this flux. If the coil has N turns of wire the total emf will be N times larger, so E =\u2212N d dt (BScos\u03c9t) =NBS\u03c9sin\u03c9t. (17.14) If we bring the wires from the generator to a point some distance from the rotating coil, where the magnetic field is zero, or at least is not varying with time, the curl of E in this region will be zero and we can define an electric potential. In fact, if there is no current being drawn from the generator, the potential difference V between the two wires will be equal to the emf in the rotating coil. That is, V=NBS\u03c9sin\u03c9t= V 0 sin\u03c9t. V N B S sin V sin The potential difference between the wires varies as sin\u03c9t . Such a varying potential difference is called an alternating voltage. Since there is an electric field between the wires, they must be electrically charged. It is clear that the emf of the generator has pushed some excess charges out to the wire until the electric field from them is strong enough to exactly counterbalance the induction force. Seen from outside the generator, the two wires appear as though they had been electrostatically charged to the potential difference V , and as though the charge was being changed with time to give an alternating potential difference. There is also another difference from an electrostatic situation. If we connect the generator to an external circuit that permits passage of a current, we find that the emf does not permit the wires to be discharged but continues to provide charge to the wires as current is drawn from them, attempting to keep the wires always at the same potential difference. If, in fact, the generator is connected in a circuit whose total resistance is R , the current through the circuit will be proportional to the emf of the generator and inversely proportional to R . Since the emf has a sinusoidal time variation, so also does the current. There is an alternating current I= E R = V 0 R sin\u03c9t. E V The schematic diagram of such a circuit is shown in Fig. 17\u20137. We can also see that the emf determines how much energy is supplied by the generator. Each charge in the wire is receiving energy at the rate F\u22c5v , where F is the force on the charge and v is its velocity. Now let the number of moving charges per unit length of the wire be n ; then the power being delivered into any element ds of the wire is F\u22c5vnds. F d For a wire, v is always along ds , so we can rewrite the power as nvF\u22c5ds. F d The total power being delivered to the complete circuit is the integral of this expression around the complete loop: Power=\u222envF\u22c5ds. (17.15) Now remember that qnv is the current I , and that the emf is defined as the integral of F/q around the circuit. We get the result Power from a generator=EI. (17.16) When there is a current in the coil of the generator, there will also be mechanical forces on it. In fact, we know that the torque on the coil is proportional to its magnetic moment, to the magnetic field strength B , and to the sine of the angle between. The magnetic moment is the current in the coil times its area. Therefore the torque is \u03c4=NISBsin\u03b8. (17.17) The rate at which mechanical work must be done to keep the coil rotating is the angular velocity \u03c9 times the torque: dW dt =\u03c9\u03c4=\u03c9NISBsin\u03b8. (17.18) Comparing this equation with Eq. (17.14), we see that the rate of mechanical work required to rotate the coil against the magnetic forces is just equal to EI , the rate at which electrical energy is delivered by the emf of the generator. All of the mechanical energy used up in the generator appears as electrical energy in the circuit. As another example of the currents and forces due to an induced emf, let\u2019s analyze what happens in the setup described in Section 17\u20131, and shown in Fig. 17\u20131. There are two parallel wires and a sliding crossbar located in a uniform magnetic field perpendicular to the plane of the parallel wires. Now let\u2019s assume that the \u201cbottom\u201d of the U (the left side in the figure) is made of wires of high resistance, while the two side wires are made of a good conductor like copper\u2014then we don\u2019t need to worry about the change of the circuit resistance as the crossbar is moved. As before, the emf in the circuit is E=vBw. (17.19) The current in the circuit is proportional to this emf and inversely proportional to the resistance of the circuit: I= E R = vBw R . (17.20) Because of this current there will be a magnetic force on the crossbar that is proportional to its length, to the current in it, and to the magnetic field, such that F=BIw. (17.21) Taking I from Eq. (17.20), we have for the force F= B 2 w 2 R v. (17.22) We see that the force is proportional to the velocity of the crossbar. The direction of the force, as you can easily see, is opposite to its velocity. Such a \u201cvelocity-proportional\u201d force, which is like the force of viscosity, is found whenever induced currents are produced by moving conductors in a magnetic field. The examples of eddy currents we gave in the last chapter also produced forces on the conductors proportional to the velocity of the conductor, even though such situations, in general, give a complicated distribution of currents which is difficult to analyze. It is often convenient in the design of mechanical systems to have damping forces which are proportional to the velocity. Eddy-current forces provide one of the most convenient ways of getting such a velocity-dependent force. An example of the application of such a force is found in the conventional domestic wattmeter. In the wattmeter there is a thin aluminum disc that rotates between the poles of a permanent magnet. This disc is driven by a small electric motor whose torque is proportional to the power being consumed in the electrical circuit of the house. Because of the eddy-current forces in the disc, there is a resistive force proportional to the velocity. In equilibrium, the velocity is therefore proportional to the rate of consumption of electrical energy. By means of a counter attached to the rotating disc, a record is kept of the number of revolutions it makes. This count is an indication of the total energy consumption, i.e., the number of watthours used. We may also point out that Eq. (17.22) shows that the force from induced currents\u2014that is, any eddy-current force\u2014is inversely proportional to the resistance. The force will be larger, the better the conductivity of the material. The reason, of course, is that an emf produces more current if the resistance is low, and the stronger currents represent greater mechanical forces. We can also see from our formulas how mechanical energy is converted into electrical energy. As before, the electrical energy supplied to the resistance of the circuit is the product EI . The rate at which work is done in moving the conducting crossbar is the force on the bar times its velocity. Using Eq. (17.22) for the force, the rate of doing work is dW dt = v 2 B 2 w 2 R . 2 We see that this is indeed equal to the product EI we would get from Eqs. (17.19) and (17.20). Again the mechanical work appears as electrical energy. We now want to consider a situation in which there are fixed coils of wire but changing magnetic fields. When we described the production of magnetic fields by currents, we considered only the case of steady currents. But so long as the currents are changed slowly, the magnetic field will at each instant be nearly the same as the magnetic field of a steady current. We will assume in the discussion of this section that the currents are always varying sufficiently slowly that this is true. In Fig. 17\u20138 is shown an arrangement of two coils which demonstrates the basic effects responsible for the operation of a transformer. Coil 1 consists of a conducting wire wound in the form of a long solenoid. Around this coil\u2014and insulated from it\u2014is wound coil 2 , consisting of a few turns of wire. If now a current is passed through coil 1 , we know that a magnetic field will appear inside it. This magnetic field also passes through coil 2 . As the current in coil 1 is varied, the magnetic flux will also vary, and there will be an induced emf in coil 2 . We will now calculate this induced emf. We have seen in Section 13\u20135 that the magnetic field inside a long solenoid is uniform and has the magnitude B= 1 \u03f5 0 c 2 N 1 I 1 l , (17.23) where N 1 is the number of turns in coil 1 , I 1 is the current through it, and l is its length. Let\u2019s say that the cross-sectional area of coil 1 is S ; then the flux of B is its magnitude times S . If coil 2 has N 2 turns, this flux links the coil N 2 times. Therefore the emf in coil 2 is given by E 2 =\u2212 N 2 S dB dt . (17.24) The only quantity in Eq. (17.23) which varies with time is I 1 . The emf is therefore given by E 2 =\u2212 N 1 N 2 S \u03f5 0 c 2 l d I 1 dt . (17.25) We see that the emf in coil 2 is proportional to the rate of change of the current in coil 1 . The constant of proportionality, which is basically a geometric factor of the two coils, is called the mutual inductance, and is usually designated M 21 . Equation (17.25) is then written E 2 = M 21 d I 1 dt . (17.26) Suppose now that we were to pass a current through coil 2 and ask about the emf in coil 1 . We would compute the magnetic field, which is everywhere proportional to the current I 2 . The flux linkage through coil 1 would depend on the geometry, but would be proportional to the current I 2 . The emf in coil 1 would, therefore, again be proportional to d I 2 /dt : We can write E 1 = M 12 d I 2 dt . (17.27) The computation of M 12 would be more difficult than the computation we have just done for M 21 . We will not carry through that computation now, because we will show later in this chapter that M 12 is necessarily equal to M 21 . Since for any coil its field is proportional to its current, the same kind of result would be obtained for any two coils of wire. The equations (17.26) and (17.27) would have the same form; only the constants M 21 and M 12 would be different. Their values would depend on the shapes of the coils and their relative positions. Suppose that we wish to find the mutual inductance between any two arbitrary coils\u2014for example, those shown in Fig. 17\u20139. We know that the general expression for the emf in coil 1 can be written as E 1 =\u2212 d dt \u222b (1) B\u22c5nda, \u222b where B is the magnetic field and the integral is to be taken over a surface bounded by circuit 1 . We have seen in Section 14\u20131 that such a surface integral of B can be related to a line integral of the vector potential. In particular, \u222b (1) B\u22c5nda= \u222e (1) A\u22c5d s 1 , \u222b \u222e where A represents the vector potential and d s 1 is an element of circuit 1 . The line integral is to be taken around circuit 1 . The emf in coil 1 can therefore be written as E 1 =\u2212 d dt \u222e (1) A\u22c5d s 1 . (17.28) Now let\u2019s assume that the vector potential at circuit 1 comes from currents in circuit 2 . Then it can be written as a line integral around circuit 2 : A= 1 4\u03c0 \u03f5 0 c 2 \u222e (2) I 2 d s 2 r 12 , (17.29) where I 2 is the current in circuit 2 , and r 12 is the distance from the element of the circuit d s 2 to the point on circuit 1 at which we are evaluating the vector potential. (See Fig. 17\u20139.) Combining Eqs. (17.28) and (17.29), we can express the emf in circuit 1 as a double line integral: E 1 =\u2212 1 4\u03c0 \u03f5 0 c 2 d dt \u222e (1) \u222e (2) I 2 d s 2 r 12 \u22c5d s 1 . \u222e \u222e In this equation the integrals are all taken with respect to stationary circuits. The only variable quantity is the current I 2 , which does not depend on the variables of integration. We may therefore take it out of the integrals. The emf can then be written as E 1 = M 12 d I 2 dt , d I where the coefficient M 12 is M 12 =\u2212 1 4\u03c0 \u03f5 0 c 2 \u222e (1) \u222e (2) d s 2 \u22c5d s 1 r 12 . (17.30) We see from this integral that M 12 depends only on the circuit geometry. It depends on a kind of average separation of the two circuits, with the average weighted most for parallel segments of the two coils. Our equation can be used for calculating the mutual inductance of any two circuits of arbitrary shape. Also, it shows that the integral for M 12 is identical to the integral for M 21 . We have therefore shown that the two coefficients are identical. For a system with only two coils, the coefficients M 12 and M 21 are often represented by the symbol M without subscripts, called simply the mutual inductance: M 12 = M 21 =M. M M M In discussing the induced electromotive forces in the two coils of Figs. 17\u20138 or 17\u20139, we have considered only the case in which there was a current in one coil or the other. If there are currents in the two coils simultaneously, the magnetic flux linking either coil will be the sum of the two fluxes which would exist separately, because the law of superposition applies for magnetic fields. The emf in either coil will therefore be proportional not only to the change of the current in the other coil, but also to the change in the current of the coil itself. Thus the total emf in coil 2 should be written2 E 2 = M 21 d I 1 dt + M 22 d I 2 dt . (17.31) Similarly, the emf in coil 1 will depend not only on the changing current in coil 2 , but also on the changing current in itself: E 1 = M 12 d I 2 dt + M 11 d I 1 dt . (17.32) The coefficients M 22 and M 11 are always negative numbers. It is usual to write M 11 =\u2212 L 1 , M 22 =\u2212 L 2 , (17.33) where L 1 and L 2 are called the self-inductances of the two coils. The self-induced emf will, of course, exist even if we have only one coil. Any coil by itself will have a self-inductance L . The emf will be proportional to the rate of change of the current in it. For a single coil, it is usual to adopt the convention that the emf and the current are considered positive if they are in the same direction. With this convention, we may write for the emf of a single coil E=\u2212L dI dt . (17.34) The negative sign indicates that the emf opposes the change in current\u2014it is often called a \u201cback emf.\u201d Since any coil has a self-inductance which opposes the change in current, the current in the coil has a kind of inertia. In fact, if we wish to change the current in a coil we must overcome this inertia by connecting the coil to some external voltage source such as a battery or a generator, as shown in the schematic diagram of Fig. 17\u201310(a). In such a circuit, the current I depends on the voltage V according to the relation V=L dI dt . (17.35) This equation has the same form as Newton\u2019s law of motion for a particle in one dimension. We can therefore study it by the principle that \u201cthe same equations have the same solutions.\u201d Thus, if we make the externally applied voltage V correspond to an externally applied force F , and the current I in a coil correspond to the velocity v of a particle, the inductance L of the coil corresponds to the mass m of the particle.3 See Fig. 17\u201310(b). We can make the following table of corresponding quantities. Continuing with the analogy of the preceding section, we would expect that corresponding to the mechanical momentum p=mv , whose rate of change is the applied force, there should be an analogous quantity equal to LI , whose rate of change is V . We have no right, of course, to say that LI is the real momentum of the circuit; in fact, it isn\u2019t. The whole circuit may be standing still and have no momentum. It is only that LI is analogous to the momentum mv in the sense of satisfying corresponding equations. In the same way, to the kinetic energy 1 2 m v 2 , there corresponds an analogous quantity 1 2 L I 2 . But there we have a surprise. This 1 2 L I 2 is really the energy in the electrical case also. This is because the rate of doing work on the inductance is VI , and in the mechanical system it is Fv , the corresponding quantity. Therefore, in the case of the energy, the quantities not only correspond mathematically, but also have the same physical meaning as well. We may see this in more detail as follows. As we found in Eq. (17.16), the rate of electrical work by induced forces is the product of the electromotive force and the current: dW dt =EI. d W Replacing E by its expression in terms of the current from Eq. (17.34), we have dW dt =\u2212LI dI dt . (17.36) Integrating this equation, we find that the energy required from an external source to overcome the emf in the self-inductance while building up the current4 (which must equal the energy stored, U ) is \u2212W=U= 1 2 L I 2 . (17.37) Therefore the energy stored in an inductance is 1 2 L I 2 . Applying the same arguments to a pair of coils such as those in Figs. 17\u20138 or 17\u20139, we can show that the total electrical energy of the system is given by U= 1 2 L 1 I 2 1 + 1 2 L 2 I 2 2 +M I 1 I 2 . (17.38) For, starting with I=0 in both coils, we could first turn on the current I 1 in coil 1 , with I 2 =0 . The work done is just 1 2 L 1 I 2 1 . But now, on turning up I 2 , we not only do the work 1 2 L 2 I 2 2 against the emf in circuit 2 , but also an additional amount M I 1 I 2 , which is the integral of the emf [ M(d I 2 /dt) ] in circuit 1 times the now constant current I 1 in that circuit. Suppose we now wish to find the force between any two coils carrying the currents I 1 and I 2 . We might at first expect that we could use the principle of virtual work, by taking the change in the energy of Eq. (17.38). We must remember, of course, that as we change the relative positions of the coils the only quantity which varies is the mutual inductance M . We might then write the equation of virtual work as \u2212F\u0394x=\u0394U= I 1 I 2 \u0394M(wrong). ( ) But this equation is wrong because, as we have seen earlier, it includes only the change in the energy of the two coils and not the change in the energy of the sources which are maintaining the currents I 1 and I 2 at their constant values. We can now understand that these sources must supply energy against the induced emf\u2019s in the coils as they are moved. If we wish to apply the principle of virtual work correctly, we must also include these energies. As we have seen, however, we may take a short cut and use the principle of virtual work by remembering that the total energy is the negative of what we have called U mech , the \u201cmechanical energy.\u201d We can therefore write for the force \u2212F\u0394x=\u0394 U mech =\u2212\u0394U. (17.39) The force between two coils is then given by F\u0394x= I 1 I 2 \u0394M. F \u0394 I I \u0394 M Equation (17.38) for the energy of a system of two coils can be used to show that an interesting inequality exists between mutual inductance M and the self-inductances L 1 and L 2 of the two coils. It is clear that the energy of two coils must be positive. If we begin with zero currents in the coils and increase these currents to some values, we have been adding energy to the system. If not, the currents would spontaneously increase with release of energy to the rest of the world\u2014an unlikely thing to happen! Now our energy equation, Eq. (17.38), can equally well be written in the following form: U= 1 2 L 1 + 1 2 ( I 1 + M L 1 I 2 ) 2 ( L 2 \u2212 M 2 L 1 ) I 2 2 . (17.40) That is just an algebraic transformation. This quantity must always be positive for any values of I 1 and I 2 . In particular, it must be positive if I 2 should happen to have the special value I 2 =\u2212 L 1 M I 1 . (17.41) But with this current for I 2 , the first term in Eq. (17.40) is zero. If the energy is to be positive, the last term in (17.40) must be greater than zero. We have the requirement that L 1 L 2 > M 2 . 2 We have thus proved the general result that the magnitude of the mutual inductance M of any two coils is necessarily less than or equal to the geometric mean of the two self-inductances. ( M itself may be positive or negative, depending on the sign conventions for the currents I 1 and I 2 .) |M|< L 1 L 2 \u2212 \u2212 \u2212 \u2212 \u221a . (17.42) The relation between M and the self-inductances is usually written as M=k L 1 L 2 \u2212 \u2212 \u2212 \u2212 \u221a . (17.43) The constant k is called the coefficient of coupling. If most of the flux from one coil links the other coil, the coefficient of coupling is near one; we say the coils are \u201ctightly coupled.\u201d If the coils are far apart or otherwise arranged so that there is very little mutual flux linkage, the coefficient of coupling is near zero and the mutual inductance is very small. For calculating the mutual inductance of two coils, we have given in Eq. (17.30) a formula which is a double line integral around the two circuits. We might think that the same formula could be used to get the self-inductance of a single coil by carrying out both line integrals around the same coil. This, however, will not work, because the denominator r 12 of the integrand will go to zero when the two line elements d s 1 and d s 2 are at the same point on the coil. The self-inductance obtained from this formula is infinite. The reason is that this formula is an approximation that is valid only when the cross sections of the wires of the two circuits are small compared with the distance from one circuit to the other. Clearly, this approximation doesn\u2019t hold for a single coil. It is, in fact, true that the inductance of a single coil tends logarithmically to infinity as the diameter of its wire is made smaller and smaller. We must, then, look for a different way of calculating the self-inductance of a single coil. It is necessary to take into account the distribution of the currents within the wires because the size of the wire is an important parameter. We should therefore ask not what is the inductance of a \u201ccircuit,\u201d but what is the inductance of a distribution of conductors. Perhaps the easiest way to find this inductance is to make use of the magnetic energy. We found earlier, in Section 15\u20133, an expression for the magnetic energy of a distribution of stationary currents: U= 1 2 \u222bj\u22c5AdV. (17.44) If we know the distribution of current density j , we can compute the vector potential A and then evaluate the integral of Eq. (17.44) to get the energy. This energy is equal to the magnetic energy of the self-inductance, 1 2 L I 2 . Equating the two gives us a formula for the inductance: L= 1 I 2 \u222bj\u22c5AdV. (17.45) We expect, of course, that the inductance is a number depending only on the geometry of the circuit and not on the current I in the circuit. The formula of Eq. (17.45) will indeed give such a result, because the integral in this equation is proportional to the square of the current\u2014the current appears once through j and again through the vector potential A . The integral divided by I 2 will depend on the geometry of the circuit but not on the current I . Equation (17.44) for the energy of a current distribution can be put in a quite different form which is sometimes more convenient for calculation. Also, as we will see later, it is a form that is important because it is more generally valid. In the energy equation, Eq. (17.44), both A and j can be related to B , so we can hope to express the energy in terms of the magnetic field\u2014just as we were able to relate the electrostatic energy to the electric field. We begin by replacing j by \u03f5 0 c 2 \u2207\u00d7B . We cannot replace A so easily, since B=\u2207\u00d7A cannot be reversed to give A in terms of B . Anyway, we can write U= \u03f5 0 c 2 2 \u222b(\u2207\u00d7B)\u22c5AdV. (17.46) The interesting thing is that\u2014with some restrictions\u2014this integral can be written as U= \u03f5 0 c 2 2 \u222bB\u22c5(\u2207\u00d7A)dV. (17.47) To see this, we write out in detail a typical term. Suppose that we take the term (\u2207\u00d7B ) z A z which occurs in the integral of Eq. (17.46). Writing out the components, we get \u222b( \u2202 B y \u2202x \u2212 \u2202 B x \u2202y ) A z dxdydz. \u2202 B (There are, of course, two more integrals of the same kind.) We now integrate the first term with respect to x \u2014integrating by parts. That is, we can say \u222b \u2202 B y \u2202x A z dx= B y A z \u2212\u222b B y \u2202 A z \u2202x dx. \u2202 B Now suppose that our system\u2014meaning the sources and fields\u2014is finite, so that as we go to large distances all fields go to zero. Then if the integrals are carried out over all space, evaluating the term B y A z at the limits will give zero. We have left only the term with B y (\u2202 A z /\u2202x) , which is evidently one part of B y (\u2207\u00d7A ) y and, therefore, of B\u22c5(\u2207\u00d7A) . If you work out the other five terms, you will see that Eq. (17.47) is indeed equivalent to Eq. (17.46). But now we can replace (\u2207\u00d7A) by B , to get U= \u03f5 0 c 2 2 \u222bB\u22c5BdV. (17.48) We have expressed the energy of a magnetostatic situation in terms of the magnetic field only. The expression corresponds closely to the formula we found for the electrostatic energy: U= \u03f5 0 2 \u222bE\u22c5EdV. (17.49) One reason for emphasizing these two energy formulas is that sometimes they are more convenient to use. More important, it turns out that for dynamic fields (when E and B are changing with time) the two expressions (17.48) and (17.49) remain true, whereas the other formulas we have given for electric or magnetic energies are no longer correct\u2014they hold only for static fields. If we know the magnetic field B of a single coil, we can find the self-inductance by equating the energy expression (17.48) to 1 2 L I 2 . Let\u2019s see how this works by finding the self-inductance of a long solenoid. We have seen earlier that the magnetic field inside a solenoid is uniform and B outside is zero. The magnitude of the field inside is B=nI/ \u03f5 0 c 2 , where n is the number of turns per unit length in the winding and I is the current. If the radius of the coil is r and its length is L (we take L very long, so that we can neglect end effects, i.e., L\u226br ), the volume inside is \u03c0 r 2 L . The magnetic energy is therefore U= \u03f5 0 c 2 2 B 2 \u22c5(Vol)= n 2 I 2 2 \u03f5 0 c 2 \u03c0 r 2 L, 2 2 which is equal to 1 2 L I 2 . Or, L= \u03c0 r 2 n 2 \u03f5 0 c 2 L. (17.50)"
    },
    {
        "input": "Interference",
        "output": "In this chapter we shall discuss the subject of the preceding chapter more mathematically. We have qualitatively demonstrated that there are maxima and minima in the radiation field from two sources, and our problem now is to describe the field in mathematical detail, not just qualitatively. We have already physically analyzed the meaning of formula (28.6) quite satisfactorily, but there are a few points to be made about it mathematically. In the first place, if a charge is accelerating up and down along a line, in a motion of very small amplitude, the field at some angle \u03b8 from the axis of the motion is in a direction at right angles to the line of sight and in the plane containing both the acceleration and the line of sight (Fig. 29\u20131). If the distance is called r , then at time t the electric field has the magnitude E(t)= \u2212qa(t\u2212r/c)sin\u03b8 4\u03c0 \u03f5 0 c 2 r , (29.1) where a(t\u2212r/c) is the acceleration at the time (t\u2212r/c) , called the retarded acceleration. Now it would be interesting to draw a picture of the field under different conditions. The thing that is interesting, of course, is the factor a(t\u2212r/c) , and to understand it we can take the simplest case, \u03b8= 90 \u2218 , and plot the field graphically. What we had been thinking of before is that we stand in one position and ask how the field there changes with time. But instead of that, we are now going to see what the field looks like at different positions in space at a given instant. So what we want is a \u201csnapshot\u201d picture which tells us what the field is in different places. Of course it depends upon the acceleration of the charge. Suppose that the charge at first had some particular motion: it was initially standing still, and it suddenly accelerated in some manner, as shown in Fig. 29\u20132, and then stopped. Then, a little bit later, we measure the field at a different place. Then we may assert that the field will appear as shown in Fig. 29\u20133. At each point the field is determined by the acceleration of the charge at an earlier time, the amount earlier being the delay r/c . The field at farther and farther points is determined by the acceleration at earlier and earlier times. So the curve in Fig. 29\u20133 is really, in a sense, a \u201creversed\u201d plot of the acceleration as a function of time; the distance is related to time by a constant scale factor c , which we often take as unity. This is easily seen by considering the mathematical behavior of a(t\u2212r/c) . Evidently, if we add a little time \u0394t , we get the same value for a(t\u2212r/c) as we would have if we had subtracted a little distance: \u0394r=\u2212c\u0394t . Stated another way: if we add a little time \u0394t , we can restore a(t\u2212r/c) to its former value by adding a little distance \u0394r=c\u0394t . That is, as time goes on the field moves as a wave outward from the source. That is the reason why we sometimes say light is propagated as waves. It is equivalent to saying that the field is delayed, or to saying that the electric field is moving outward as time goes on. An interesting special case is that where the charge q is moving up and down in an oscillatory manner. The case which we studied experimentally in the last chapter was one in which the displacement x at any time t was equal to a certain constant x 0 , the magnitude of the oscillation, times cos\u03c9t . Then the acceleration is a=\u2212 \u03c9 2 x 0 cos\u03c9t= a 0 cos\u03c9t, (29.2) where a 0 is the maximum acceleration, \u2212 \u03c9 2 x 0 . Putting this formula into (29.1), we find E=\u2212qsin\u03b8 a 0 cos\u03c9(t\u2212r/c) 4\u03c0 \u03f5 0 r c 2 . (29.3) Now, ignoring the angle \u03b8 and the constant factors, let us see what that looks like as a function of position or as a function of time. First of all, at any particular moment or in any particular place, the strength of the field varies inversely as the distance r , as we mentioned previously. Now we must point out that the energy content of a wave, or the energy effects that such an electric field can have, are proportional to the square of the field, because if, for instance, we have some kind of a charge or an oscillator in the electric field, then if we let the field act on the oscillator, it makes it move. If this is a linear oscillator, the acceleration, velocity, and displacement produced by the electric field acting on the charge are all proportional to the field. So the kinetic energy which is developed in the charge is proportional to the square of the field. So we shall take it that the energy that a field can deliver to a system is proportional somehow to the square of the field. This means that the energy that the source can deliver decreases as we get farther away; in fact, it varies inversely as the square of the distance. But that has a very simple interpretation: if we wanted to pick up all the energy we could from the wave in a certain cone at a distance r 1 (Fig. 29\u20134), and we do the same at another distance r 2 , we find that the amount of energy per unit area at any one place goes inversely as the square of r , but the area of the surface intercepted by the cone goes directly as the square of r . So the energy that we can take out of the wave within a given conical angle is the same, no matter how far away we are! In particular, the total energy that we could take out of the whole wave by putting absorbing oscillators all around is a certain fixed amount. So the fact that the amplitude of E varies as 1/r is the same as saying that there is an energy flux which is never lost, an energy which goes on and on, spreading over a greater and greater effective area. Thus we see that after a charge has oscillated, it has lost some energy which it can never recover; the energy keeps going farther and farther away without diminution. So if we are far enough away that our basic approximation is good enough, the charge cannot recover the energy which has been, as we say, radiated away. Of course the energy still exists somewhere, and is available to be picked up by other systems. We shall study this energy \u201closs\u201d further in Chapter 32. Let us now consider more carefully how the wave (29.3) varies as a function of time at a given place, and as a function of position at a given time. Again we ignore the 1/r variation and the constants. First let us fix the position r , and watch the field as a function of time. It is oscillatory at the angular frequency \u03c9 . The angular frequency \u03c9 can be defined as the rate of change of phase with time (radians per second). We have already studied such a thing, so it should be quite familiar to us by now. The period is the time needed for one oscillation, one complete cycle, and we have worked that out too; it is 2\u03c0/\u03c9 , because \u03c9 times the period is one cycle of the cosine. Now we introduce a new quantity which is used a great deal in physics. This has to do with the opposite situation, in which we fix t and look at the wave as a function of distance r . Of course we notice that, as a function of r , the wave (29.3) is also oscillatory. That is, aside from 1/r , which we are ignoring, we see that E oscillates as we change the position. So, in analogy with \u03c9 , we can define a quantity called the wave number, symbolized as k . This is defined as the rate of change of phase with distance (radians per meter). That is, as we move in space at a fixed time, the phase changes. There is another quantity that corresponds to the period, and we might call it the period in space, but it is usually called the wavelength, symbolized \u03bb . The wavelength is the distance occupied by one complete cycle. It is easy to see, then, that the wavelength is 2\u03c0/k , because k times the wavelength would be the number of radians that the whole thing changes, being the product of the rate of change of the radians per meter, times the number of meters, and we must make a 2\u03c0 change for one cycle. So k\u03bb=2\u03c0 is exactly analogous to \u03c9 t 0 =2\u03c0 . Now in our particular wave there is a definite relationship between the frequency and the wavelength, but the above definitions of k and \u03c9 are actually quite general. That is, the wavelength and the frequency may not be related in the same way in other physical circumstances. However, in our circumstance the rate of change of phase with distance is easily determined, because if we call \u03d5=\u03c9(t\u2212r/c) the phase, and differentiate (partially) with respect to distance r , the rate of change, \u2202\u03d5/\u2202r , is \u2223 \u2223 \u2223 \u2202\u03d5 \u2202r \u2223 \u2223 \u2223 =k= \u03c9 c . (29.4) There are many ways to represent the same thing, such as \u03bb \u03c9 =c t 0 =ck (29.5) (29.6) \u03bb\u03bd \u03c9\u03bb =c =2\u03c0c (29.7) (29.8) Why is the wavelength equal to c times the period? That\u2019s very easy, of course, because if we sit still and wait for one period to elapse, the waves, travelling at the speed c , will move a distance c t 0 , and will of course have moved over just one wavelength. In a physical situation other than that of light, k is not necessarily related to \u03c9 in this simple way. If we call the distance along an axis x , then the formula for a cosine wave moving in a direction x with a wave number k and an angular frequency \u03c9 will be written in general as cos(\u03c9t\u2212kx) . Now that we have introduced the idea of wavelength, we may say something more about the circumstances in which (29.1) is a legitimate formula. We recall that the field is made up of several pieces, one of which varies inversely as r , another part which varies inversely as r 2 , and others which vary even faster. It would be worthwhile to know in what circumstances the 1/r part of the field is the most important part, and the other parts are relatively small. Naturally, the answer is \u201cif we go \u2018far enough\u2019 away,\u201d because terms which vary inversely as the square ultimately become negligible compared with the 1/r term. How far is \u201cfar enough\u201d? The answer is, qualitatively, that the other terms are of order \u03bb/r smaller than the 1/r term. Thus, so long as we are beyond a few wavelengths, (29.1) is an excellent approximation to the field. Sometimes the region beyond a few wavelengths is called the \u201cwave zone.\u201d Next let us discuss the mathematics involved in combining the effects of two oscillators to find the net field at a given point. This is very easy in the few cases that we considered in the previous chapter. We shall first describe the effects qualitatively, and then more quantitatively. Let us take the simple case, where the oscillators are situated with their centers in the same horizontal plane as the detector, and the line of vibration is vertical. Figure 29\u20135(a) represents the top view of two such oscillators, and in this particular example they are half a wavelength apart in a N\u2013S direction, and are oscillating together in the same phase, which we call zero phase. Now we would like to know the intensity of the radiation in various directions. By the intensity we mean the amount of energy that the field carries past us per second, which is proportional to the square of the field, averaged in time. So the thing to look at, when we want to know how bright the light is, is the square of the electric field, not the electric field itself. (The electric field tells the strength of the force felt by a stationary charge, but the amount of energy that is going past, in watts per square meter, is proportional to the square of the electric field. We shall derive the constant of proportionality in Chapter 31.) If we look at the array from the W side, both oscillators contribute equally and in phase, so the electric field is twice as strong as it would be from a single oscillator. Therefore the intensity is four times as strong as it would be if there were only one oscillator. (The numbers in Fig. 29\u20135 represent how strong the intensity would be in this case, compared with what it would be if there were only a single oscillator of unit strength.) Now, in either the N or S direction along the line of the oscillators, since they are half a wavelength apart, the effect of one oscillator turns out to be out of phase by exactly half an oscillation from the other, and therefore the fields add to zero. At a certain particular intermediate angle (in fact, at 30 \u2218 ) the intensity is 2 , and it falls off, 4 , 2 , 0 , and so forth. We have to learn how to find these numbers at other angles. It is a question of adding two oscillations with different phases. Let us quickly look at some other cases of interest. Suppose the oscillators are again one-half a wavelength apart, but the phase \u03b1 of one is set half a period behind the other in its oscillation (Fig. 29\u20135b). In the W direction the intensity is now zero, because one oscillator is \u201cpushing\u201d when the other one is \u201cpulling.\u201d But in the N direction the signal from the near one comes at a certain time, and that of the other comes half a period later. But the latter was originally half a period behind in timing, and therefore it is now exactly in time with the first one, and so the intensity in this direction is 4 units. The intensity in the direction at 30 \u2218 is still 2 , as we can prove later. Now we come to an interesting case which shows up a possibly useful feature. Let us remark that one of the reasons that phase relations of oscillators are interesting is for beaming radio transmitters. For instance, if we build an antenna system and want to send a radio signal, say, to Hawaii, we set the antennas up as in Fig. 29\u20135(a) and we broadcast with our two antennas in phase, because Hawaii is to the west of us. Then we decide that tomorrow we are going to broadcast toward Alberta, Canada. Since that is north, not west, all we have to do is to reverse the phase of one of our antennas, and we can broadcast to the north. So we can build antenna systems with various arrangements. Ours is one of the simplest possible ones; we can make them much more complicated, and by changing the phases in the various antennas we can send the beams in various directions and send most of the power in the direction in which we wish to transmit, without ever moving the antenna! In both of the preceding cases, however, while we are broadcasting toward Alberta we are wasting a lot of power on Easter Island, and it would be interesting to ask whether it is possible to send it in only one direction. At first sight we might think that with a pair of antennas of this nature the result is always going to be symmetrical. So let us consider a case that comes out unsymmetrical, to show the possible variety. If the antennas are separated by one-quarter wavelength, and if the N one is one-fourth period behind the S one in time, then what happens (Fig. 29\u20136)? In the W direction we get 2 , as we will see later. In the S direction we get zero, because the signal from S comes at a certain time; that from N comes 90 \u2218 later in time, but it is already 90 \u2218 behind in its built-in phase, therefore it arrives, altogether, 180 \u2218 out of phase, and there is no effect. On the other hand, in the N direction, the N signal arrives earlier than the S signal by 90 \u2218 in time, because it is a quarter wavelength closer. But its phase is set so that it is oscillating 90 \u2218 behind in time, which just compensates the delay difference, and therefore the two signals appear together in phase, making the field strength twice as large, and the energy four times as great. Thus, by using some cleverness in spacing and phasing our antennas, we can send the power all in one direction. But still it is distributed over a great range of angles. Can we arrange it so that it is focused still more sharply in a particular direction? Let us consider the case of Hawaii again, where we are sending the beam east and west but it is spread over quite an angle, because even at 30 \u2218 we are still getting half the intensity\u2014we are wasting the power. Can we do better than that? Let us take a situation in which the separation is ten wavelengths (Fig. 29\u20137), which is more nearly comparable to the situation in which we experimented in the previous chapter, with separations of several wavelengths rather than a small fraction of a wavelength. Here the picture is quite different. If the oscillators are ten wavelengths apart (we take the in-phase case to make it easy), we see that in the E\u2013W direction, they are in phase, and we get a strong intensity, four times what we would get if one of them were there alone. On the other hand, at a very small angle away, the arrival times differ by 180 \u2218 and the intensity is zero. To be precise, if we draw a line from each oscillator to a distant point and the difference \u0394 in the two distances is \u03bb/2 , half an oscillation, then they will be out of phase. So this first null occurs when that happens. (The figure is not drawn to scale; it is only a rough sketch.) This means that we do indeed have a very sharp beam in the direction we want, because if we just move over a little bit we lose all our intensity. Unfortunately for practical purposes, if we were thinking of making a radio broadcasting array and we doubled the distance \u0394 , then we would be a whole cycle out of phase, which is the same as being exactly in phase again! Thus we get many successive maxima and minima, just as we found with the 2 1 2 \u03bb spacing in Chapter 28. Now how can we arrange to get rid of all these extra maxima, or \u201clobes,\u201d as they are called? We could get rid of the unwanted lobes in a rather interesting way. Suppose that we were to place another set of antennas between the two that we already have. That is, the outside ones are still 10\u03bb apart, but between them, say every 2\u03bb , we have put another antenna, and we drive them all in phase. There are now six antennas, and if we looked at the intensity in the E\u2013W direction, it would, of course, be much higher with six antennas than with one. The field would be six times and the intensity thirty-six times as great (the square of the field). We get 36 units of intensity in that direction. Now if we look at neighboring points, we find a zero as before, roughly, but if we go farther, to where we used to get a big \u201cbump,\u201d we get a much smaller \u201cbump\u201d now. Let us try to see why. The reason is that although we might expect to get a big bump when the distance \u0394 is exactly equal to the wavelength, it is true that dipoles 1 and 6 are then in phase and are cooperating in trying to get some strength in that direction. But numbers 3 and 4 are roughly 1 2 a wavelength out of phase with 1 and 6 , and although 1 and 6 push together, 3 and 4 push together too, but in opposite phase. Therefore there is very little intensity in this direction\u2014but there is something; it does not balance exactly. This kind of thing keeps on happening; we get very little bumps, and we have the strong beam in the direction where we want it. But in this particular example, something else will happen: namely, since the distance between successive dipoles is 2\u03bb , it is possible to find an angle where the distance \u03b4 between successive dipoles is exactly one wavelength, so that the effects from all of them are in phase again. Each one is delayed relative to the next one by 360 \u2218 , so they all come back in phase, and we have another strong beam in that direction! It is easy to avoid this in practice because it is possible to put the dipoles closer than one wavelength apart. If we put in more antennas, closer than one wavelength apart, then this cannot happen. But the fact that this can happen at certain angles, if the spacing is bigger than one wavelength, is a very interesting and useful phenomenon in other applications\u2014not radio broadcasting, but in diffraction gratings. Now we have finished our analysis of the phenomena of dipole radiators qualitatively, and we must learn how to analyze them quantitatively. To find the effect of two sources at some particular angle in the most general case, where the two oscillators have some intrinsic relative phase \u03b1 from one another and the strengths A 1 and A 2 are not equal, we find that we have to add two cosines having the same frequency, but with different phases. It is very easy to find this phase difference; it is made up of a delay due to the difference in distance, and the intrinsic, built-in phase of the oscillation. Mathematically, we have to find the sum R of two waves: R= A 1 cos(\u03c9t+ \u03d5 1 )+ A 2 cos(\u03c9t+ \u03d5 2 ) . How do we do it? It is really very easy, and we presume that we already know how to do it. However, we shall outline the procedure in some detail. First, we can, if we are clever with mathematics and know enough about cosines and sines, simply work it out. The easiest such case is the one where A 1 and A 2 are equal, let us say they are both equal to A . In those circumstances, for example (we could call this the trigonometric method of solving the problem), we have R=A[cos(\u03c9t+ \u03d5 1 )+cos(\u03c9t+ \u03d5 2 )]. (29.9) Once, in our trigonometry class, we may have learned the rule that cosA+cosB=2cos 1 2 (A+B)cos 1 2 (A\u2212B). (29.10) If we know that, then we can immediately write R as R=2Acos 1 2 ( \u03d5 1 \u2212 \u03d5 2 )cos(\u03c9t+ 1 2 \u03d5 1 + 1 2 \u03d5 2 ). (29.11) So we find that we have an oscillatory wave with a new phase and a new amplitude. In general, the result will be an oscillatory wave with a new amplitude A R , which we may call the resultant amplitude, oscillating at the same frequency but with a phase difference \u03d5 R , called the resultant phase. In view of this, our particular case has the following result: that the resultant amplitude is A R =2Acos 1 2 ( \u03d5 1 \u2212 \u03d5 2 ), (29.12) and the resultant phase is the average of the two phases, and we have completely solved our problem. Now suppose that we cannot remember that the sum of two cosines is twice the cosine of half the sum times the cosine of half the difference. Then we may use another method of analysis which is more geometrical. Any cosine function of \u03c9t can be considered as the horizontal projection of a rotating vector. Suppose there were a vector A 1 of length A 1 rotating with time, so that its angle with the horizontal axis is \u03c9t+ \u03d5 1 . (We shall leave out the \u03c9t in a minute, and see that it makes no difference.) Suppose that we take a snapshot at the time t=0 , although, in fact, the picture is rotating with angular velocity \u03c9 (Fig. 29\u20139). The projection of A 1 along the horizontal axis is precisely A 1 cos(\u03c9t+ \u03d5 1 ) . Now at t=0 the second wave could be represented by another vector, A 2 , of length A 2 and at an angle \u03d5 2 , and also rotating. They are both rotating with the same angular velocity \u03c9 , and therefore the relative positions of the two are fixed. The system goes around like a rigid body. The horizontal projection of A 2 is A 2 cos(\u03c9t+ \u03d5 2 ) . But we know from the theory of vectors that if we add the two vectors in the ordinary way, by the parallelogram rule, and draw the resultant vector A R , the x -component of the resultant is the sum of the x -components of the other two vectors. That solves our problem. It is easy to check that this gives the correct result for the special case we treated above, where A 1 = A 2 = A . In this case, we see from Fig. 29\u20139 that A R lies midway between A 1 and A 2 and makes an angle 1 2 ( \u03d5 2 \u2212 \u03d5 1 ) with each. Therefore we see that A R =2Acos 1 2 ( \u03d5 2 \u2212 \u03d5 1 ) , as before. Also, as we see from the triangle, the phase of A R , as it goes around, is the average angle of A 1 and A 2 when the two amplitudes are equal. Clearly, we can also solve for the case where the amplitudes are not equal, just as easily. We can call that the geometrical way of solving the problem. There is still another way of solving the problem, and that is the analytical way. That is, instead of having actually to draw a picture like Fig. 29\u20139, we can write something down which says the same thing as the picture: instead of drawing the vectors, we write a complex number to represent each of the vectors. The real parts of the complex numbers are the actual physical quantities. So in our particular case the waves could be written in this way: A 1 e i(\u03c9t+ \u03d5 1 ) [the real part of this is A 1 cos(\u03c9t+ \u03d5 1 ) ] and A 2 e i(\u03c9t+ \u03d5 2 ) . Now we can add the two: R = A 1 e i(\u03c9t+ \u03d5 1 ) + A 2 e i(\u03c9t+ \u03d5 2 ) =( A 1 e i \u03d5 1 + A 2 e i \u03d5 2 ) e i\u03c9t (29.13) or R ^ = A 1 e i \u03d5 1 + A 2 e i \u03d5 2 = A R e i \u03d5 R . (29.14) This solves the problem that we wanted to solve, because it represents the result as a complex number of magnitude A R and phase \u03d5 R . To see how this method works, let us find the amplitude A R which is the \u201clength\u201d of R ^ . To get the \u201clength\u201d of a complex quantity, we always multiply the quantity by its complex conjugate, which gives the length squared. The complex conjugate is the same expression, but with the sign of the i \u2019s reversed. Thus we have A 2 R =( A 1 e i \u03d5 1 + A 2 e i \u03d5 2 )( A 1 e \u2212i \u03d5 1 + A 2 e \u2212i \u03d5 2 ). (29.15) In multiplying this out, we get A 2 1 + A 2 2 (here the e \u2019s cancel), and for the cross terms we have A 1 A 2 ( e i( \u03d5 1 \u2212 \u03d5 2 ) + e i( \u03d5 2 \u2212 \u03d5 1 ) ). i ( \u03d5 \u03d5 ) i ( \u03d5 \u03d5 ) Now e i\u03b8 + e \u2212i\u03b8 =cos\u03b8+isin\u03b8+cos\u03b8\u2212isin\u03b8. i \u03b8 i \u03b8 That is to say, e i\u03b8 + e \u2212i\u03b8 =2cos\u03b8 . Our final result is therefore A 2 R = A 2 1 + A 2 2 +2 A 1 A 2 cos( \u03d5 2 \u2212 \u03d5 1 ). (29.16) As we see, this agrees with the length of A R in Fig. 29\u20139, using the rules of trigonometry. Thus the sum of the two effects has the intensity A 2 1 we would get with one of them alone, plus the intensity A 2 2 we would get with the other one alone, plus a correction. This correction we call the interference effect. It is really only the difference between what we get simply by adding the intensities, and what actually happens. We call it interference whether it is positive or negative. (Interference in ordinary language usually suggests opposition or hindrance, but in physics we often do not use language the way it was originally designed!) If the interference term is positive, we call that case constructive interference, horrible though it may sound to anybody other than a physicist! The opposite case is called destructive interference. Now let us see how to apply our general formula (29.16) for the case of two oscillators to the special situations which we have discussed qualitatively. To apply this general formula, it is only necessary to find what phase difference, \u03d5 2 \u2212 \u03d5 1 , exists between the signals arriving at a given point. (It depends only on the phase difference, of course, and not on the phase itself.) So let us consider the case where the two oscillators, of equal amplitude, are separated by some distance d and have an intrinsic relative phase \u03b1 . (When one is at phase zero, the phase of the other is \u03b1 .) Then we ask what the intensity will be in some azimuth direction \u03b8 from the E\u2013W line. [Note that this is not the same \u03b8 as appears in (29.1). We are torn between using an unconventional symbol like U , or the conventional symbol \u03b8 (Fig. 29\u201310).] The phase relationship is found by noting that the difference in distance from P to the two oscillators is dsin\u03b8 , so that the phase difference contribution from this is the number of wavelengths in dsin\u03b8 , multiplied by 2\u03c0 . (Those who are more sophisticated might want to multiply the wave number k , which is the rate of change of phase with distance, by dsin\u03b8 ; it is exactly the same.) The phase difference due to the distance difference is thus 2\u03c0dsin\u03b8/\u03bb , but, due to the timing of the oscillators, there is an additional phase \u03b1 . So the phase difference at arrival would be \u03d5 2 \u2212 \u03d5 1 =\u03b1+2\u03c0dsin\u03b8/\u03bb. (29.17) This takes care of all the cases. Thus all we have to do is substitute this expression into (29.16) for the case A 1 = A 2 , and we can calculate all the various results for two antennas of equal intensity. Now let us see what happens in our various cases. The reason we know, for example, that the intensity is 2 at 30 \u2218 in Fig. 29\u20135 is the following: the two oscillators are 1 2 \u03bb apart, so at 30 \u2218 , dsin\u03b8=\u03bb/4 . Thus \u03d5 2 \u2212 \u03d5 1 = 2\u03c0\u03bb/4\u03bb= \u03c0/2 , and so the interference term is zero. (We are adding two vectors at 90 \u2218 .) The result is the hypotenuse of a 45 \u2218 right-angle triangle, which is 2 \u2013 \u221a times the unit amplitude; squaring it, we get twice the intensity of one oscillator alone. All the other cases can be worked out in this same way."
    },
    {
        "input": "Beats",
        "output": "Some time ago we discussed in considerable detail the properties of light waves and their interference\u2014that is, the effects of the superposition of two waves from different sources. In all these analyses we assumed that the frequencies of the sources were all the same. In this chapter we shall discuss some of the phenomena which result from the interference of two sources which have different frequencies. It is easy to guess what is going to happen. Proceeding in the same way as we have done previously, suppose we have two equal oscillating sources of the same frequency whose phases are so adjusted, say, that the signals arrive in phase at some point P . At that point, if it is light, the light is very strong; if it is sound, it is very loud; or if it is electrons, many of them arrive. On the other hand, if the arriving signals were 180\u2218 out of phase, we would get no signal at P , because the net amplitude there is then a minimum. Now suppose that someone twists the \u201cphase knob\u201d of one of the sources and changes the phase at P back and forth, say, first making it 0\u2218 and then 180\u2218 , and so on. Of course, we would then find variations in the net signal strength. Now we also see that if the phase of one source is slowly changing relative to that of the other in a gradual, uniform manner, starting at zero, going up to ten, twenty, thirty, forty degrees, and so on, then what we would measure at P would be a series of strong and weak \u201cpulsations,\u201d because when the phase shifts through 360\u2218 the amplitude returns to a maximum. Of course, to say that one source is shifting its phase relative to another at a uniform rate is the same as saying that the number of oscillations per second is slightly different for the two. So we know the answer: if we have two sources at slightly different frequencies we should find, as a net result, an oscillation with a slowly pulsating intensity. That is all there really is to the subject! It is very easy to formulate this result mathematically also. Suppose, for example, that we have two waves, and that we do not worry for the moment about all the spatial relations, but simply analyze what arrives at P . From one source, let us say, we would have cos\u03c91t , and from the other source, cos\u03c92t , where the two \u03c9 \u2019s are not exactly the same. Of course the amplitudes may not be the same, either, but we can solve the general problem later; let us first take the case where the amplitudes are equal. Then the total amplitude at P is the sum of these two cosines. If we plot the amplitudes of the waves against the time, as in Fig. 48\u20131, we see that where the crests coincide we get a strong wave, and where a trough and crest coincide we get practically zero, and then when the crests coincide again we get a strong wave again. Mathematically, we need only to add two cosines and rearrange the result somehow. There exist a number of useful relations among cosines which are not difficult to derive. Of course we know that ei(a+b)=eiaeib, and that eia has a real part, cosa , and an imaginary part, sina . If we take the real part of ei(a+b) , we get cos(a+b) . If we multiply out: eiaeib=(cosa+isina)(cosb+isinb), we get cosacosb\u2212sinasinb , plus some imaginary parts. But we now need only the real part, so we have cos(a+b)=cosacosb\u2212sinasinb. Now if we change the sign of b , since the cosine does not change sign while the sine does, the same equation, for negative b , is cos(a\u2212b)=cosacosb+sinasinb. If we add these two equations together, we lose the sines and we learn that the product of two cosines is half the cosine of the sum, plus half the cosine of the difference: cosacosb= 1 2 cos(a+b)+ 1 2 cos(a\u2212b). Now we can also reverse the formula and find a formula for cos\u03b1+cos\u03b2 if we simply let \u03b1=a+b and \u03b2=a\u2212b . That is, a= 1 2 (\u03b1+\u03b2) and b= 1 2 (\u03b1\u2212\u03b2) , so that cos\u03b1+cos\u03b2=2cos 1 2 (\u03b1+\u03b2)cos 1 2 (\u03b1\u2212\u03b2). Now we can analyze our problem. The sum of cos \u03c9 1 t and cos \u03c9 2 t is cos \u03c9 1 t +cos \u03c9 2 t= 2cos 1 2 ( \u03c9 1 + \u03c9 2 )tcos 1 2 ( \u03c9 1 \u2212 \u03c9 2 )t. (48.6) Now let us suppose that the two frequencies are nearly the same, so that 1 2 ( \u03c9 1 + \u03c9 2 ) is the average frequency, and is more or less the same as either. But \u03c9 1 \u2212 \u03c9 2 is much smaller than \u03c9 1 or \u03c9 2 because, as we suppose, \u03c9 1 and \u03c9 2 are nearly equal. That means that we can represent the solution by saying that there is a high-frequency cosine wave more or less like the ones we started with, but that its \u201csize\u201d is slowly changing\u2014its \u201csize\u201d is pulsating with a frequency which appears to be 1 2 ( \u03c9 1 \u2212 \u03c9 2 ) . But is this the frequency at which the beats are heard? Although (48.6) says that the amplitude goes as cos 1 2 ( \u03c9 1 \u2212 \u03c9 2 )t , what it is really telling us is that the high-frequency oscillations are contained between two opposed cosine curves (shown dotted in Fig. 48\u20131). On this basis one could say that the amplitude varies at the frequency 1 2 ( \u03c9 1 \u2212 \u03c9 2 ) , but if we are talking about the intensity of the wave we must think of it as having twice this frequency. That is, the modulation of the amplitude, in the sense of the strength of its intensity, is at frequency \u03c9 1 \u2212 \u03c9 2 , although the formula tells us that we multiply by a cosine wave at half that frequency. The technical basis for the difference is that the high frequency-wave has a little different phase relationship in the second half-cycle. Ignoring this small complication, we may conclude that if we add two waves of frequency \u03c9 1 and \u03c9 2 , we will get a net resulting wave of average frequency 1 2 ( \u03c9 1 + \u03c9 2 ) which oscillates in strength with a frequency \u03c9 1 \u2212 \u03c9 2 . If the two amplitudes are different, we can do it all over again by multiplying the cosines by different amplitudes A 1 and A 2 , and do a lot of mathematics, rearranging, and so on, using equations like (48.2)\u2013(48.5). However, there are other, easier ways of doing the same analysis. For example, we know that it is much easier to work with exponentials than with sines and cosines and that we can represent A 1 cos \u03c9 1 t as the real part of A 1 e i \u03c9 1 t . The other wave would similarly be the real part of A 2 e i \u03c9 2 t . If we add the two, we get A 1 e i \u03c9 1 t + A 2 e i \u03c9 2 t . If we then factor out the average frequency, we have A 1 e i \u03c9 1 t + A 2 e i \u03c9 2 t = e i( \u03c9 1 + \u03c9 2 )t/2 [ A 1 e i( \u03c9 1 \u2212 \u03c9 2 )t/2 + A 2 e \u2212i( \u03c9 1 \u2212 \u03c9 2 )t/2 ]. (48.7) Again we have the high-frequency wave with a modulation at the lower frequency. If we are now asked for the intensity of the wave of Eq. (48.7), we can either take the absolute square of the left side, or of the right side. Let us take the left side. The intensity then is I= A 2 1 + A 2 2 +2 A 1 A 2 cos( \u03c9 1 \u2212 \u03c9 2 )t. (48.8) We see that the intensity swells and falls at a frequency \u03c9 1 \u2212 \u03c9 2 , varying between the limits ( A 1 + A 2 ) 2 and ( A 1 \u2212 A 2 ) 2 . If A 1 \u2260 A 2 , the minimum intensity is not zero. One more way to represent this idea is by means of a drawing, like Fig. 48\u20132. We draw a vector of length A 1 , rotating at a frequency \u03c9 1 , to represent one of the waves in the complex plane. We draw another vector of length A 2 , going around at a frequency \u03c9 2 , to represent the second wave. If the two frequencies are exactly equal, their resultant is of fixed length as it keeps revolving, and we get a definite, fixed intensity from the two. But if the frequencies are slightly different, the two complex vectors go around at different speeds. Figure 48\u20133 shows what the situation looks like relative to the vector A 1 e i \u03c9 1 t . We see that A 2 is turning slowly away from A 1 , and so the amplitude that we get by adding the two is first strong, and then, as it opens out, when it gets to the 180 \u2218 relative position the resultant gets particularly weak, and so on. As the vectors go around, the amplitude of the sum vector gets bigger and smaller, and the intensity thus pulsates. It is a relatively simple idea, and there are many different ways of representing the same thing. The effect is very easy to observe experimentally. In the case of acoustics, we may arrange two loudspeakers driven by two separate oscillators, one for each loudspeaker, so that they each make a tone. We thus receive one note from one source and a different note from the other source. If we make the frequencies exactly the same, the resulting effect will have a definite strength at a given space location. If we then de-tune them a little bit, we hear some variations in the intensity. The farther they are de-tuned, the more rapid are the variations of sound. The ear has some trouble following variations more rapid than ten or so per second. We may also see the effect on an oscilloscope which simply displays the sum of the currents to the two speakers. If the frequency of pulsing is relatively low, we simply see a sinusoidal wave train whose amplitude pulsates, but as we make the pulsations more rapid we see the kind of wave shown in Fig. 48\u20131. As we go to greater frequency differences, the \u201cbumps\u201d move closer together. Also, if the amplitudes are not equal and we make one signal stronger than the other, then we get a wave whose amplitude does not ever become zero, just as we expect. Everything works the way it should, both acoustically and electrically. The opposite phenomenon occurs too! In radio transmission using so-called amplitude modulation (am), the sound is broadcast by the radio station as follows: the radio transmitter has an ac electric oscillation which is at a very high frequency, for example 800 kilocycles per second, in the broadcast band. If this carrier signal is turned on, the radio station emits a wave which is of uniform amplitude at 800,000 oscillations a second. The way the \u201cinformation\u201d is transmitted, the useless kind of information about what kind of car to buy, is that when somebody talks into a microphone the amplitude of the carrier signal is changed in step with the vibrations of sound entering the microphone. If we take as the simplest mathematical case the situation where a soprano is singing a perfect note, with perfect sinusoidal oscillations of her vocal cords, then we get a signal whose strength is alternating as shown in Fig. 48\u20134. The audiofrequency alternation is then recovered in the receiver; we get rid of the carrier wave and just look at the envelope which represents the oscillations of the vocal cords, or the sound of the singer. The loudspeaker then makes corresponding vibrations at the same frequency in the air, and the listener is then essentially unable to tell the difference, so they say. Because of a number of distortions and other subtle effects, it is, in fact, possible to tell whether we are listening to a radio or to a real soprano; otherwise the idea is as indicated above. Mathematically, the modulated wave described above would be expressed as S=(1+bcos \u03c9 m t)cos \u03c9 c t, (48.9) where \u03c9 c represents the frequency of the carrier and \u03c9 m is the frequency of the audio tone. Again we use all those theorems about the cosines, or we can use e i\u03b8 ; it makes no difference\u2014it is easier with e i\u03b8 , but it is the same thing. We then get S=cos \u03c9 c t + 1 2 bcos( \u03c9 c + \u03c9 m )t + 1 2 bcos( \u03c9 c \u2212 \u03c9 m )t. (48.10) So, from another point of view, we can say that the output wave of the system consists of three waves added in superposition: first, the regular wave at the frequency \u03c9 c , that is, at the carrier frequency, and then two new waves at two new frequencies. One is the carrier frequency plus the modulation frequency, and the other is the carrier frequency minus the modulation frequency. If, therefore, we make some kind of plot of the intensity being generated by the generator as a function of frequency, we would find a lot of intensity at the frequency of the carrier, naturally, but when a singer started to sing, we would suddenly also find intensity proportional to the strength of the singer, b 2 , at frequency \u03c9 c + \u03c9 m and \u03c9 c \u2212 \u03c9 m , as shown in Fig. 48\u20135. These are called side bands; when there is a modulated signal from the transmitter, there are side bands. If there is more than one note at the same time, say \u03c9 m and \u03c9 m \u2032 , there are two instruments playing; or if there is any other complicated cosine wave, then, of course, we can see from the mathematics that we get some more waves that correspond to the frequencies \u03c9 c \u00b1 \u03c9 m \u2032 . Therefore, when there is a complicated modulation that can be represented as the sum of many cosines,1 we find that the actual transmitter is transmitting over a range of frequencies, namely the carrier frequency plus or minus the maximum frequency that the modulation signal contains. Although at first we might believe that a radio transmitter transmits only at the nominal frequency of the carrier, since there are big, superstable crystal oscillators in there, and everything is adjusted to be at precisely 800 kilocycles, the moment someone announces that they are at 800 kilocycles, he modulates the 800 kilocycles, and so they are no longer precisely at 800 kilocycles! Suppose that the amplifiers are so built that they are able to transmit over a good range of the ear\u2019s sensitivity (the ear can hear up to 20,000 cycles per second, but usually radio transmitters and receivers do not work beyond 10,000 , so we do not hear the highest parts), then, when the man speaks, his voice may contain frequencies ranging up, say, to 10,000 cycles, so the transmitter is transmitting frequencies which may range from 790 to 810 kilocycles per second. Now if there were another station at 795 kc/sec, there would be a lot of confusion. Also, if we made our receiver so sensitive that it picked up only 800 , and did not pick up the 10 kilocycles on either side, we would not hear what the man was saying, because the information would be on these other frequencies! Therefore it is absolutely essential to keep the stations a certain distance apart, so that their side bands do not overlap and, also, the receiver must not be so selective that it does not permit reception of the side bands as well as of the main nominal frequency. In the case of sound, this problem does not really cause much trouble. We can hear over a \u00b120 kc/sec range, and we have usually from 500 to 1500 kc/sec in the broadcast band, so there is plenty of room for lots of stations. The television problem is more difficult. As the electron beam goes across the face of the picture tube, there are various little spots of light and dark. That \u201clight\u201d and \u201cdark\u201d is the \u201csignal.\u201d Now ordinarily the beam scans over the whole picture, 500 lines, approximately, in a thirtieth of a second. Let us consider that the resolution of the picture vertically and horizontally is more or less the same, so that there are the same number of spots per inch along a scan line. We want to be able to distinguish dark from light, dark from light, dark from light, over, say, 500 lines. In order to be able to do this with cosine waves, the shortest wavelength needed thus corresponds to a wavelength, from maximum to maximum, of one 250 th of the screen size. So we have 250\u00d7500\u00d730 pieces of information per second. The highest frequency that we are going to carry, therefore, is close to 4 megacycles per second. Actually, to keep the television stations apart, we have to use a little bit more than this, about 6 mc/sec; part of it is used to carry the sound signal, and other information. So, television channels are 6 megacycles per second wide. It certainly would not be possible to transmit tv on an 800 kc/sec carrier, since we cannot modulate at a higher frequency than the carrier. At any rate, the television band starts at 54 megacycles. The first transmission channel, which is channel 2 (!), has a frequency range from 54 to 60 mc/sec, which is 6 mc/sec wide. \u201cBut,\u201d one might say, \u201cwe have just proved that there were side bands on both sides, and therefore it should be twice that wide.\u201d It turns out that the radio engineers are rather clever. If we analyze the modulation signal using not just cosine terms, but cosine and sine terms, to allow for phase differences, we then see that there is a definite, invariant relationship between the side band on the high-frequency side and the side band on the low-frequency side. What we mean is that there is no new information on that other side band. So what is done is to suppress one side band, and the receiver is wired inside such that the information which is missing is reconstituted by looking at the single side band and the carrier. Single side-band transmission is a clever scheme for decreasing the band widths needed to transmit information. The next subject we shall discuss is the interference of waves in both space and time. Suppose that we have two waves travelling in space. We know, of course, that we can represent a wave travelling in space by e i(\u03c9t\u2212kx) . This might be, for example, the displacement in a sound wave. This is a solution of the wave equation provided that \u03c9 2 = k 2 c 2 , where c is the speed of propagation of the wave. In this case we can write it as e \u2212ik(x\u2212ct) , which is of the general form f(x\u2212ct) . Therefore this must be a wave which is travelling at this velocity, \u03c9/k , and that is c and everything is all right. Now we want to add two such waves together. Suppose we have a wave that is travelling with one frequency, and another wave travelling with another frequency. We leave to the reader to consider the case where the amplitudes are different; it makes no real difference. Thus we want to add e i( \u03c9 1 t\u2212 k 1 x) + e i( \u03c9 2 t\u2212 k 2 x) . We can add these by the same kind of mathematics we used when we added signal waves. Of course, if c is the same for both, this is easy, since it is the same as what we did before: e i \u03c9 1 (t\u2212x/c) + e i \u03c9 2 (t\u2212x/c) = e i \u03c9 1 t \u2032 + e i \u03c9 2 t \u2032 , (48.11) except that t \u2032 =t\u2212x/c is the variable instead of t . So we get the same kind of modulations, naturally, but we see, of course, that those modulations are moving along with the wave. In other words, if we added two waves, but these waves were not just oscillating, but also moving in space, then the resultant wave would move along also, at the same speed. Now we would like to generalize this to the case of waves in which the relationship between the frequency and the wave number k is not so simple. Example: material having an index of refraction. We have already studied the theory of the index of refraction in Chapter 31, where we found that we could write k=n\u03c9/c , where n is the index of refraction. As an interesting example, for x-rays we found that the index n is n=1\u2212 N q 2 e 2 \u03f5 0 m \u03c9 2 . (48.12) We actually derived a more complicated formula in Chapter 31, but this one is as good as any, as an example. Incidentally, we know that even when \u03c9 and k are not linearly proportional, the ratio \u03c9/k is certainly the speed of propagation for the particular frequency and wave number. We call this ratio the phase velocity; it is the speed at which the phase, or the nodes of a single wave, would move along: v p = \u03c9 k . (48.13) This phase velocity, for the case of x-rays in glass, is greater than the speed of light in vacuum (since n in 48.12 is less than 1 ), and that is a bit bothersome, because we do not think we can send signals faster than the speed of light! What we are going to discuss now is the interference of two waves in which \u03c9 and k have a definite formula relating them. The above formula for n says that k is given as a definite function of \u03c9 . To be specific, in this particular problem, the formula for k in terms of \u03c9 is k= \u03c9 c \u2212 a \u03c9c , (48.14) where a=N q 2 e /2 \u03f5 0 m , a constant. At any rate, for each frequency there is a definite wave number, and we want to add two such waves together. Let us do it just as we did in Eq. (48.7): e i( \u03c9 1 t\u2212 k 1 x) + e i[( \u03c9 1 + \u03c9 2 )t\u2212( k 1 + k 2 )x]/2 \u00d7[ e i( \u03c9 2 t\u2212 k 2 x) = e i[( \u03c9 1 \u2212 \u03c9 2 )t\u2212( k 1 \u2212 k 2 )x]/2 + e \u2212i[( \u03c9 1 \u2212 \u03c9 2 )t\u2212( k 1 \u2212 k 2 )x]/2 ]. (48.15) So we have a modulated wave again, a wave which travels with the mean frequency and the mean wave number, but whose strength is varying with a form which depends on the difference frequency and the difference wave number. Now let us take the case that the difference between the two waves is relatively small. Let us suppose that we are adding two waves whose frequencies are nearly equal; then ( \u03c9 1 + \u03c9 2 )/2 is practically the same as either one of the \u03c9 \u2019s, and similarly for ( k 1 + k 2 )/2 . Thus the speed of the wave, the fast oscillations, the nodes, is still essentially \u03c9/k . But look, the speed of propagation of the modulation is not the same! How much do we have to change x to account for a certain amount of t ? The speed of this modulation wave is the ratio v M = \u03c9 1 \u2212 \u03c9 2 k 1 \u2212 k 2 . (48.16) The speed of modulation is sometimes called the group velocity. If we take the case that the difference in frequency is relatively small, and the difference in wave number is then also relatively small, then this expression approaches, in the limit, v g = d\u03c9 dk . (48.17) In other words, for the slowest modulation, the slowest beats, there is a definite speed at which they travel which is not the same as the phase speed of the waves\u2014what a mysterious thing! The group velocity is the derivative of \u03c9 with respect to k , and the phase velocity is \u03c9/k . Let us see if we can understand why. Consider two waves, again of slightly different wavelength, as in Fig. 48\u20131. They are out of phase, in phase, out of phase, and so on. Now these waves represent, really, the waves in space travelling with slightly different frequencies also. Now because the phase velocity, the velocity of the nodes of these two waves, is not precisely the same, something new happens. Suppose we ride along with one of the waves and look at the other one; if they both went at the same speed, then the other wave would stay right where it was relative to us, as we ride along on this crest. We ride on that crest and right opposite us we see a crest; if the two velocities are equal the crests stay on top of each other. But it is not so that the two velocities are really equal. There is only a small difference in frequency and therefore only a small difference in velocity, but because of that difference in velocity, as we ride along the other wave moves slowly forward, say, or behind, relative to our wave. So as time goes on, what happens to the node? If we move one wave train just a shade forward, the node moves forward (or backward) a considerable distance. That is, the sum of these two waves has an envelope, and as the waves travel along, the envelope rides on them at a different speed. The group velocity is the speed at which modulated signals would be transmitted. If we made a signal, i.e., some kind of change in the wave that one could recognize when he listened to it, a kind of modulation, then that modulation would travel at the group velocity, provided that the modulations were relatively slow. (When they are fast, it is much more difficult to analyze.) Now we may show (at long last), that the speed of propagation of x-rays in a block of carbon is not greater than the speed of light, although the phase velocity is greater than the speed of light. In order to do that, we must find d\u03c9/dk , which we get by differentiating (48.14): dk/d\u03c9=1/c+a/ \u03c9 2 c . The group velocity, therefore, is the reciprocal of this, namely, v g = c 1+a/ \u03c9 2 , (48.18) which is smaller than c ! So although the phases can travel faster than the speed of light, the modulation signals travel slower, and that is the resolution of the apparent paradox! Of course, if we have the simple case that \u03c9=kc , then d\u03c9/dk is also c . So when all the phases have the same velocity, naturally the group has the same velocity. Let us now consider one more example of the phase velocity which is extremely interesting. It has to do with quantum mechanics. We know that the amplitude to find a particle at a place can, in some circumstances, vary in space and time, let us say in one dimension, in this manner: \u03c8=A e i(\u03c9t\u2212kx) , (48.19) where \u03c9 is the frequency, which is related to the classical idea of the energy through E=\u210f\u03c9 , and k is the wave number, which is related to the momentum through p=\u210fk . We would say the particle had a definite momentum p if the wave number were exactly k , that is, a perfect wave which goes on with the same amplitude everywhere. Equation (48.19) gives the amplitude, and if we take the absolute square, we get the relative probability for finding the particle as a function of position and time. This is a constant, which means that the probability is the same to find a particle anywhere. Now suppose, instead, that we have a situation where we know that the particle is more likely to be at one place than at another. We would represent such a situation by a wave which has a maximum and dies out on either side (Fig. 48\u20136). (It is not quite the same as a wave like (48.1) which has a series of maxima, but it is possible, by adding several waves of nearly the same \u03c9 and k together, to get rid of all but one maximum.) Now in those circumstances, since the square of (48.19) represents the chance of finding a particle somewhere, we know that at a given instant the particle is most likely to be near the center of the \u201clump,\u201d where the amplitude of the wave is maximum. If now we wait a few moments, the waves will move, and after some time the \u201clump\u201d will be somewhere else. If we knew that the particle originally was situated somewhere, classically, we would expect that it would later be elsewhere as a matter of fact, because it has a speed, after all, and a momentum. The quantum theory, then, will go into the correct classical theory for the relationship of momentum, energy, and velocity only if the group velocity, the velocity of the modulation, is equal to the velocity that we would obtain classically for a particle of the same momentum. It is now necessary to demonstrate that this is, or is not, the case. According to the classical theory, the energy is related to the velocity through an equation like E= m c 2 1\u2212 v 2 / c 2 \u2212 \u2212 \u2212 \u2212 \u2212 \u2212 \u2212 \u2212 \u221a . (48.20) Similarly, the momentum is p= mv 1\u2212 v 2 / c 2 \u2212 \u2212 \u2212 \u2212 \u2212 \u2212 \u2212 \u2212 \u221a . (48.21) That is the classical theory, and as a consequence of the classical theory, by eliminating v , we can show that E 2 \u2212 p 2 c 2 = m 2 c 4 . 2 That is the four-dimensional grand result that we have talked and talked about, that p \u03bc p \u03bc = m 2 ; that is the relation between energy and momentum in the classical theory. Now that means, since these E \u2019s and p \u2019s are going to become \u03c9 \u2019s and k \u2019s, by substitution of E=\u210f\u03c9 and p=\u210fk , that for quantum mechanics it is necessary that \u210f 2 \u03c9 2 c 2 \u2212 \u210f 2 k 2 = m 2 c 2 . (48.22) This, then, is the relationship between the frequency and the wave number of a quantum-mechanical amplitude wave representing a particle of mass m . From this equation we can deduce that \u03c9 is \u03c9=c k 2 + m 2 c 2 / \u210f 2 \u2212 \u2212 \u2212 \u2212 \u2212 \u2212 \u2212 \u2212 \u2212 \u2212 \u2212 \u221a . The phase velocity, \u03c9/k , is here again faster than the speed of light! Now let us look at the group velocity. The group velocity should be d\u03c9/dk , the speed at which the modulations move. We have to differentiate a square root, which is not very difficult. The derivative is d\u03c9 dk = kc k 2 + m 2 c 2 / \u210f 2 \u2212 \u2212 \u2212 \u2212 \u2212 \u2212 \u2212 \u2212 \u2212 \u2212 \u2212 \u221a . d k Now the square root is, after all, \u03c9/c , so we could write this as d\u03c9/dk= c 2 k/\u03c9 . Further, k/\u03c9 is p/E , so v g = c 2 p E . 2 But from (48.20) and (48.21), c 2 p/E=v , the velocity of the particle, according to classical mechanics. So we see that whereas the fundamental quantum-mechanical relationship E=\u210f\u03c9 and p=\u210fk , for the identification of \u03c9 and k with the classical E and p , only produces the equation \u03c9 2 \u2212 k 2 c 2 = m 2 c 4 / \u210f 2 , now we also understand the relationships (48.20) and (48.21) which connected E and p to the velocity. Of course the group velocity must be the velocity of the particle if the interpretation is going to make any sense. If we think the particle is over here at one time, and then ten minutes later we think it is over there, as the quantum mechanics said, the distance traversed by the \u201clump,\u201d divided by the time interval, must be, classically, the velocity of the particle. We shall now bring our discussion of waves to a close with a few general remarks about the wave equation. These remarks are intended to give some view of the future\u2014not that we can understand everything exactly just now, but rather to see what things are going to look like when we study waves a little more. First of all, the wave equation for sound in one dimension was \u2202 2 \u03c7 \u2202 x 2 = 1 c 2 \u2202 2 \u03c7 \u2202 t 2 , 2 2 where c is the speed of whatever the wave is\u2014in the case of sound, it is the sound speed; in the case of light, it is the speed of light. We showed that for a sound wave the displacements would propagate themselves at a certain speed. But the excess pressure also propagates at a certain speed, and so does the excess density. So we should expect that the pressure would satisfy the same equation, as indeed it does. We shall leave it to the reader to prove that it does. Hint: \u03c1 e is proportional to the rate of change of \u03c7 with respect to x . Therefore if we differentiate the wave equation with respect to x , we will immediately discover that \u2202\u03c7/\u2202x satisfies the same equation. That is to say, \u03c1 e satisfies the same equation. But P e is proportional to \u03c1 e , and therefore P e does too. So the pressure, the displacements, everything, satisfy the same wave equation. Usually one sees the wave equation for sound written in terms of pressure instead of in terms of displacement, because the pressure is a scalar and has no direction. But the displacement is a vector and has direction, and it is thus easier to analyze the pressure. The next matter we discuss has to do with the wave equation in three dimensions. We know that the sound wave solution in one dimension is e i(\u03c9t\u2212kx) , with \u03c9=k c s , but we also know that in three dimensions a wave would be represented by e i(\u03c9t\u2212 k x x\u2212 k y y\u2212 k z z) , where, in this case, \u03c9 2 = k 2 c 2 s , which is, of course, ( k 2 x + k 2 y + k 2 z ) c 2 s . Now what we want to do is to guess what the correct wave equation in three dimensions is. Naturally, for the case of sound this can be deduced by going through the same dynamic argument in three dimensions that we made in one dimension. But we shall not do that; instead we just write down what comes out: the equation for the pressure (or displacement, or anything) is \u2202 2 P e \u2202 x 2 + \u2202 2 P e \u2202 y 2 + \u2202 2 P e \u2202 z 2 = 1 c 2 s \u2202 2 P e \u2202 t 2 . (48.23) That this is true can be verified by substituting in e i(\u03c9t\u2212k\u22c5r) . Clearly, every time we differentiate with respect to x , we multiply by \u2212i k x . If we differentiate twice, it is equivalent to multiplying by \u2212 k 2 x , so the first term would become \u2212 k 2 x P e , for that wave. Similarly, the second term becomes \u2212 k 2 y P e , and the third term becomes \u2212 k 2 z P e . On the right, we get \u2212( \u03c9 2 / c 2 s ) P e . Then, if we take away the P e \u2019s and change the sign, we see that the relationship between k and \u03c9 is the one that we want. Working backwards again, we cannot resist writing down the grand equation which corresponds to the dispersion equation (48.22) for quantum-mechanical waves. If \u03d5 represents the amplitude for finding a particle at position x,y,z , at the time t , then the great equation of quantum mechanics for free particles is this: \u2202 2 \u03d5 \u2202 x 2 + \u2202 2 \u03d5 \u2202 y 2 + \u2202 2 \u03d5 \u2202 z 2 \u2212 1 c 2 \u2202 2 \u03d5 \u2202 t 2 = m 2 c 2 \u210f 2 \u03d5. (48.24) First of all, the relativity character of this expression is suggested by the appearance of x , y , z and t in the nice combination relativity usually involves. Second, it is a wave equation which, if we try a plane wave, would produce as a consequence that \u2212 k 2 + \u03c9 2 / c 2 = m 2 c 2 / \u210f 2 , which is the right relationship for quantum mechanics. There is still another great thing contained in the wave equation: the fact that any superposition of waves is also a solution. So this equation contains all of the quantum mechanics and the relativity that we have been discussing so far, at least so long as it deals with a single particle in empty space with no external potentials or forces on it! Now we turn to another example of the phenomenon of beats which is rather curious and a little different. Imagine two equal pendulums which have, between them, a rather weak spring connection. They are made as nearly as possible the same length. If we pull one aside and let go, it moves back and forth, and it pulls on the connecting spring as it moves back and forth, and so it really is a machine for generating a force which has the natural frequency of the other pendulum. Therefore, as a consequence of the theory of resonance, which we studied before, when we put a force on something at just the right frequency, it will drive it. So, sure enough, one pendulum moving back and forth drives the other. However, in this circumstance there is a new thing happening, because the total energy of the system is finite, so when one pendulum pours its energy into the other to drive it, it finds itself gradually losing energy, until, if the timing is just right along with the speed, it loses all its energy and is reduced to a stationary condition! Then, of course, it is the other pendulum ball that has all the energy and the first one which has none, and as time goes on we see that it works also in the opposite direction, and that the energy is passed back into the first ball; this is a very interesting and amusing phenomenon. We said, however, that this is related to the theory of beats, and we must now explain how we can analyze this motion from the point of view of the theory of beats. We note that the motion of either of the two balls is an oscillation which has an amplitude which changes cyclically. Therefore the motion of one of the balls is presumably analyzable in a different way, in that it is the sum of two oscillations, present at the same time but having two slightly different frequencies. Therefore it ought to be possible to find two other motions in this system, and to claim that what we saw was a superposition of the two solutions, because this is of course a linear system. Indeed, it is easy to find two ways that we could start the motion, each one of which is a perfect, single-frequency motion\u2014absolutely periodic. The motion that we started with before was not strictly periodic, since it did not last; soon one ball was passing energy to the other and so changing its amplitude; but there are ways of starting the motion so that nothing changes and, of course, as soon as we see it we understand why. For example, if we made both pendulums go together, then, since they are of the same length and the spring is not then doing anything, they will of course continue to swing like that for all time, assuming no friction and that everything is perfect. On the other hand, there is another possible motion which also has a definite frequency: that is, if we move the pendulums oppositely, pulling them aside exactly equal distances, then again they would be in absolutely periodic motion. We can appreciate that the spring just adds a little to the restoring force that the gravity supplies, that is all, and the system just keeps oscillating at a slightly higher frequency than in the first case. Why higher? Because the spring is pulling, in addition to the gravitation, and it makes the system a little \u201cstiffer,\u201d so that the frequency of this motion is just a shade higher than that of the other. Thus this system has two ways in which it can oscillate with unchanging amplitude: it can either oscillate in a manner in which both pendulums go the same way and oscillate all the time at one frequency, or they could go in opposite directions at a slightly higher frequency. Now the actual motion of the thing, because the system is linear, can be represented as a superposition of the two. (The subject of this chapter, remember, is the effects of adding two motions with different frequencies.) So think what would happen if we combined these two solutions. If at t=0 the two motions are started with equal amplitude and in the same phase, the sum of the two motions means that one ball, having been impressed one way by the first motion and the other way by the second motion, is at zero, while the other ball, having been displaced the same way in both motions, has a large amplitude. As time goes on, however, the two basic motions proceed independently, so the phase of one relative to the other is slowly shifting. That means, then, that after a sufficiently long time, when the time is enough that one motion could have gone \u201c 900 1 2 \u201d oscillations, while the other went only \u201c 900 ,\u201d the relative phase would be just reversed with respect to what it was before. That is, the large-amplitude motion will have fallen to zero, and in the meantime, of course, the initially motionless ball will have attained full strength! So we see that we could analyze this complicated motion either by the idea that there is a resonance and that one passes energy to the other, or else by the superposition of two constant-amplitude motions at two different frequencies."
    },
    {
        "input": "Reflection from Surfaces",
        "output": "The subject of this chapter is the reflection and refraction of light\u2014or electromagnetic waves in general\u2014at surfaces. We have already discussed the laws of reflection and refraction in Chapters 26 and 33 of Volume I. Here\u2019s what we found out there: The angle of reflection is equal to the angle of incidence. With the angles defined as shown in Fig. 33-1, \u03b8r=\u03b8i. The product nsin\u03b8 is the same for the incident and transmitted beams (Snell\u2019s law): n1sin\u03b8i=n2sin\u03b8t. The intensity of the reflected light depends on the angle of incidence and also on the direction of polarization. For E perpendicular to the plane of incidence, the reflection coefficient R\u22a5 is R\u22a5= Ir Ii = sin2(\u03b8i\u2212\u03b8t) sin2(\u03b8i+\u03b8t) . For E parallel to the plane of incidence, the reflection coefficient R\u2225 is R\u2225= Ir Ii = tan2(\u03b8i\u2212\u03b8t) tan2(\u03b8i+\u03b8t) . For normal incidence (any polarization, of course!), Ir Ii =( n2\u2212n1 n2+n1 )2. (Earlier, we used i for the incident angle and r for the refracted angle. Since we can\u2019t use r for both \u201crefracted\u201d and \u201creflected\u201d angles, we are now using \u03b8i= incident angle, \u03b8r= reflected angle, and \u03b8t= transmitted angle.) Our earlier discussion is really about as far as anyone would normally need to go with the subject, but we are going to do it all over again a different way. Why? One reason is that we assumed before that the indexes were real (no absorption in the materials). But another reason is that you should know how to deal with what happens to waves at surfaces from the point of view of Maxwell\u2019s equations. We\u2019ll get the same answers as before, but now from a straightforward solution of the wave problem, rather than by some clever arguments. We want to emphasize that the amplitude of a surface reflection is not a property of the material, as is the index of refraction. It is a \u201csurface property,\u201d one that depends precisely on how the surface is made. A thin layer of extraneous junk on the surface between two materials of indices n1 and n2 will usually change the reflection. (There are all kinds of possibilities of interference here\u2014like the colors of oil films. Suitable thickness can even reduce the reflected amplitude to zero for a given frequency; that\u2019s how coated lenses are made.) The formulas we will derive are correct only if the change of index is sudden\u2014within a distance very small compared with one wavelength. For light, the wavelength is about 5000 \u00c5, so by a \u201csmooth\u201d surface we mean one in which the conditions change in going a distance of only a few atoms (or a few angstroms). Our equations will work for light for highly polished surfaces. In general, if the index changes gradually over a distance of several wavelengths, there is very little reflection at all. First, we remind you about the convenient way of describing a sinusoidal plane wave we used in Chapter 34 of Volume I. Any field component in the wave (we use E as an example) can be written in the form E=E0ei(\u03c9t\u2212k\u22c5r), where E represents the amplitude at the point r (from the origin) at the time t . The vector k points in the direction the wave is travelling, and its magnitude |k|= k= 2\u03c0/\u03bb is the wave number. The phase velocity of the wave is vph=\u03c9/k ; for a light wave in a material of index n , vph=c/n , so k= \u03c9n c . Suppose k is in the z -direction; then k\u22c5r is just kz , as we have often used it. For k in any other direction, we should replace z by rk , the distance from the origin in the k -direction; that is, we should replace kz by krk , which is just k\u22c5r . (See Fig. 33\u20132.) So Eq. (33.6) is a convenient representation of a wave in any direction. We must remember, of course, that k\u22c5r=kxx+kyy+kzz, where kx , ky , and kz are the components of k along the three axes. In fact, we pointed out once that (\u03c9,kx,ky,kz) is a four-vector, and that its scalar product with (t,x,y,z) is an invariant. So the phase of a wave is an invariant, and Eq. (33.6) could be written E=E0eik\u03bcx\u03bc. But we don\u2019t need to be that fancy now. For a sinusoidal E , as in Eq. (33.6), \u2202E/\u2202t is the same as i\u03c9E , and \u2202E/\u2202x is \u2212ikxE , and so on for the other components. You can see why it is very convenient to use the form in Eq. (33.6) when working with differential equations\u2014differentiations are replaced by multiplications. One further useful point: The operation \u2207=(\u2202/\u2202x,\u2202/\u2202y,\u2202/\u2202z) gets replaced by the three multiplications (\u2212ikx,\u2212iky,\u2212ikz) . But these three factors transform as the components of the vector k , so the operator \u2207 gets replaced by multiplication with \u2212ik : \u2202 \u2202t \u2192i\u03c9, \u2207\u2192\u2212ik. This remains true for any \u2207 operation\u2014whether it is the gradient, or the divergence, or the curl. For instance, the z -component of \u2207\u00d7E is \u2202Ey \u2202x \u2212 \u2202Ex \u2202y . If both Ey and Ex vary as e\u2212ik\u22c5r , then we get \u2212ikxEy+ikyEx, which is, you see, the z -component of \u2212ik\u00d7E . So we have the very useful general fact that whenever you have to take the gradient of a vector that varies as a wave in three dimensions (they are an important part of physics), you can always take the derivations quickly and almost without thinking by remembering that the operation \u2207 is equivalent to multiplication by \u2212ik . For instance, the Faraday equation \u2207\u00d7E=\u2212 \u2202B \u2202t becomes for a wave \u2212ik\u00d7E=\u2212i\u03c9B. This tells us that B= k\u00d7E \u03c9 , which corresponds to the result we found earlier for waves in free space\u2014that B , in a wave, is at right angles to E and to the wave direction. (In free space, \u03c9/k=c .) You can remember the sign in Eq. (33.9) from the fact that k is in the direction of Poynting\u2019s vector S=\u03f50c2E\u00d7B . If you use the same rule with the other Maxwell equations, you get again the results of the last chapter and, in particular, that k\u22c5k=k2= \u03c92n2 c2 . But since we know that, we won\u2019t do it again. If you want to entertain yourself, you can try the following terrifying problem that was the ultimate test for graduate students back in 1890: solve Maxwell\u2019s equations for plane waves in an anisotropic crystal, that is, when the polarization P is related to the electric field E by a tensor of polarizability. You should, of course, choose your axes along the principal axes of the tensor, so that the relations are simplest (then Px=\u03b1aEx , Py=\u03b1bEy , and Pz=\u03b1cEz ), but let the waves have an arbitrary direction and polarization. You should be able to find the relations between E and B , and how k varies with direction and wave polarization. Then you will understand the optics of an anisotropic crystal. It would be best to start with the simpler case of a birefringent crystal\u2014like calcite\u2014for which two of the polarizabilities are equal (say, \u03b1b=\u03b1c ), and see if you can understand why you see double when you look through such a crystal. If you can do that, then try the hardest case, in which all three \u03b1 \u2019s are different. Then you will know whether you are up to the level of a graduate student of 1890. In this chapter, however, we will consider only isotropic substances. We know from experience that when a plane wave arrives at the boundary between two different materials\u2014say, air and glass, or water and oil\u2014there is a wave reflected and a wave transmitted. Suppose we assume no more than that and see what we can work out. We choose our axes with the yz -plane in the surface and the xy -plane perpendicular to the incident wave surfaces, as shown in Fig. 33\u20133. The electric vector of the incident wave can then be written as Ei=E0ei(\u03c9t\u2212k\u22c5r). Since k is perpendicular to the z -axis, k\u22c5r=kxx+kyy. We write the reflected wave as Er=E \u2032 0 ei(\u03c9\u2032t\u2212k\u2032\u22c5r), so that its frequency is \u03c9\u2032 , its wave number is k\u2032 , and its amplitude is E \u2032 0 . (We know, of course, that the frequency is the same and the magnitude of k\u2032 is the same as for the incident wave, but we are not going to assume even that. We will let it come out of the mathematical machinery.) Finally, we write for the transmitted wave, Et=E \u2033 0 ei(\u03c9\u2033t\u2212k\u2033\u22c5r). We know that one of Maxwell\u2019s equations gives Eq. (33.9), so for each of the waves we have B i = k\u00d7 E i \u03c9 , B r = k \u2032 \u00d7 E r \u03c9 \u2032 , B t = k \u2032\u2032 \u00d7 E t \u03c9 \u2032\u2032 . (33.15) Also, if we call the indexes of the two media n 1 and n 2 , we have from Eq. (33.10) k 2 = k 2 x + k 2 y = \u03c9 2 n 2 1 c 2 . (33.16) Since the reflected wave is in the same material, then k \u20322 = \u03c9 \u20322 n 2 1 c 2 (33.17) whereas for the transmitted wave, k \u2032\u20322 = \u03c9 \u2032\u20322 n 2 2 c 2 . (33.18) All we have done so far is to describe the three waves; our problem now is to work out the parameters of the reflected and transmitted waves in terms of those of the incident wave. How can we do that? The three waves we have described satisfy Maxwell\u2019s equations in the uniform material, but Maxwell\u2019s equations must also be satisfied at the boundary between the two different materials. So we must now look at what happens right at the boundary. We will find that Maxwell\u2019s equations demand that the three waves fit together in a certain way. As an example of what we mean, the y -component of the electric field E must be the same on both sides of the boundary. This is required by Faraday\u2019s law, \u2207\u00d7E=\u2212 \u2202B \u2202t , (33.19) as we can see in the following way. Consider a little rectangular loop \u0393 which straddles the boundary, as shown in Fig. 33\u20134. Equation (33.19) says that the line integral of E around \u0393 is equal to the rate of change of the flux of B through the loop: \u222e \u0393 E\u22c5ds=\u2212 \u2202 \u2202t \u222bB\u22c5nda. \u222e \u222b Now imagine that the rectangle is very narrow, so that the loop encloses an infinitesimal area. If B remains finite (and there\u2019s no reason it should be infinite at the boundary!) the flux through the area is zero. So the line integral of E must be zero. If E y1 and E y2 are the components of the field on the two sides of the boundary and if the length of the rectangle is l , we have E y1 l\u2212 E y2 l=0 E l E l or E y1 = E y2 , (33.20) as we have said. This gives us one relation among the fields of the three waves. The procedure of working out the consequences of Maxwell\u2019s equations at the boundary is called \u201cdetermining the boundary conditions.\u201d Ordinarily, it is done by finding as many equations like Eq. (33.20) as one can, by making arguments about little rectangles like \u0393 in Fig. 33\u20134, or by using little Gaussian surfaces that straddle the boundary. Although that is a perfectly good way of proceeding, it gives the impression that the problem of dealing with a boundary is different for every different physical problem. For example, in a problem of heat flow across a boundary, how are the temperatures on the two sides related? Well, you could argue, for one thing, that the heat flow to the boundary from one side would have to equal the flow away from the other side. It is usually possible, and generally quite useful, to work out the boundary conditions by making such physical arguments. There may be times, however, when in working on some problem you have only some equations, and you may not see right away what physical arguments to use. So although we are at the moment interested only in an electromagnetic problem, where we can make the physical arguments, we want to show you a method that can be used for any problem\u2014a general way of finding what happens at a boundary directly from the differential equations. We begin by writing all the Maxwell equations for a dielectric\u2014and this time we are very specific and write out explicitly all the components: \u2207\u22c5E=\u2212 \u2207\u22c5P \u03f5 0 \u03f5 0 ( \u2202 E x \u2202x + \u2202 E y \u2202y + \u2202 E z \u2202z )=\u2212( \u2202 P x \u2202x + \u2202 P y \u2202y + \u2202 P z \u2202z ) \u2207\u00d7E=\u2212 \u2202B \u2202t \u2202 E z \u2202y \u2212 \u2202 E y \u2202z =\u2212 \u2202 B x \u2202t \u2202 E x \u2202z \u2212 \u2202 E z \u2202x =\u2212 \u2202 B y \u2202t \u2202 E y \u2202x \u2212 \u2202 E x \u2202y =\u2212 \u2202 B z \u2202t \u2207\u22c5B=0 \u2202 B x \u2202x + \u2202 B y \u2202y + \u2202 B z \u2202z =0 c 2 \u2207\u00d7B= 1 \u03f5 0 \u2202P \u2202t + \u2202E \u2202t c 2 ( \u2202 B z \u2202y \u2212 \u2202 B y \u2202z )= 1 \u03f5 0 \u2202 P x \u2202t + \u2202 E x \u2202t c 2 ( \u2202 B x \u2202z \u2212 \u2202 B z \u2202x )= 1 \u03f5 0 \u2202 P y \u2202t + \u2202 E y \u2202t c 2 ( \u2202 B y \u2202x \u2212 \u2202 B x \u2202y )= 1 \u03f5 0 \u2202 P z \u2202t + \u2202 E z \u2202t (33.21) (33.22a) (33.22b) (33.22c) (33.23) (33.24a) (33.24b) (33.24c) Now these equations must all hold in region 1 (to the left of the boundary) and in region 2 (to the right of the boundary). We have already written the solutions in regions 1 and 2 . Finally, they must also be satisfied in the boundary, which we can call region 3 . Although we usually think of the boundary as being sharply discontinuous, in reality it is not. The physical properties change very rapidly but not infinitely fast. In any case, we can imagine that there is a very rapid, but continuous, transition of the index between region 1 and 2 , in a short distance we can call region 3 . Also, any field quantity like P x , or E y , etc., will make a similar kind of transition in region 3 . In this region, the differential equations must still be satisfied, and it is by following the differential equations in this region that we can arrive at the needed \u201cboundary conditions.\u201d For instance, suppose that we have a boundary between vacuum (region 1 ) and glass (region 2 ). There is nothing to polarize in the vacuum, so P 1 =0 . Let\u2019s say there is some polarization P 2 in the glass. Between the vacuum and the glass there is a smooth, but rapid, transition. If we look at any component of P , say P x , it might vary as drawn in Fig. 33\u20135(a). Suppose now we take the first of our equations, Eq. (33.21). It involves derivatives of the components of P with respect to x , y , and z . The y - and z -derivatives are not interesting; nothing spectacular is happening in those directions. But the x -derivative of P x will have some very large values in region 3 , because of the tremendous slope of P x . The derivative \u2202 P x /\u2202x will have a sharp spike at the boundary, as shown in Fig. 33\u20135(b). If we imagine squashing the boundary to an even thinner layer, the spike would get much higher. If the boundary is really sharp for the waves we are interested in, the magnitude of \u2202 P x /\u2202x in region 3 will be much, much greater than any contributions we might have from the variation of P in the wave away from the boundary\u2014so we ignore any variations other than those due to the boundary. Now how can Eq. (33.21) be satisfied if there is a whopping big spike on the right-hand side? Only if there is an equally whopping big spike on the other side. Something on the left-hand side must also be big. The only candidate is \u2202 E x /\u2202x , because the variations with y and z are only those small effects in the wave we just mentioned. So \u2212 \u03f5 0 (\u2202 E x /\u2202x) must be as drawn in Fig. 33\u20135(c)\u2014just a copy of \u2202 P x /\u2202x . We have that \u03f5 0 \u2202 E x \u2202x =\u2212 \u2202 P x \u2202x . \u2202 E \u2202 P If we integrate this equation with respect to x across region 3 , we conclude that \u03f5 0 ( E x2 \u2212 E x1 )=\u2212( P x2 \u2212 P x1 ). (33.25) In other words, the jump in \u03f5 0 E x in going from region 1 to region 2 must be equal to the jump in \u2212 P x . We can rewrite Eq. (33.25) as \u03f5 0 E x2 + P x2 = \u03f5 0 E x1 + P x1 , (33.26) which says that the quantity ( \u03f5 0 E x + P x ) has equal values in region 2 and region 1 . People say: the quantity ( \u03f5 0 E x + P x ) is continuous across the boundary. We have, in this way, one of our boundary conditions. Although we took as an illustration the case in which P 1 was zero because region 1 was a vacuum, it is clear that the same argument applies for any two materials in the two regions, so Eq. (33.26) is true in general. Let\u2019s now go through the rest of Maxwell\u2019s equations and see what each of them tells us. We take next Eq. (33.22a). There are no x -derivatives, so it doesn\u2019t tell us anything. (Remember that the fields themselves do not get especially large at the boundary; only the derivatives with respect to x can become so huge that they dominate the equation.) Next, we look at Eq. (33.22b). Ah! There is an x -derivative! We have \u2202 E z /\u2202x on the left-hand side. Suppose it has a huge derivative. But wait a moment! There is nothing on the right-hand side to match it with; therefore E z cannot have any jump in going from region 1 to region 2 . [If it did, there would be a spike on the left of Eq. (33.22b) but none on the right, and the equation would be false.] So we have a new condition: E z2 = E z1 . (33.27) By the same argument, Eq. (33.22c) gives E y2 = E y1 . (33.28) This last result is just what we got in Eq. (33.20) by a line integral argument. We go on to Eq. (33.23). The only term that could have a spike is \u2202 B x /\u2202x . But there\u2019s nothing on the right to match it, so we conclude that B x2 = B x1 . (33.29) On to the last of Maxwell\u2019s equations! Equation (33.24a) gives nothing, because there are no x -derivatives. Equation (33.24b) has one, \u2212 c 2 \u2202 B z /\u2202x , but again, there is nothing to match it with. We get B z2 = B z1 . (33.30) The last equation is quite similar, and gives B y2 = B y1 . (33.31) The last three equations gives us that B 2 = B 1 . We want to emphasize, however, that we get this result only when the materials on both sides of the boundary are nonmagnetic\u2014or rather, when we can neglect any magnetic effects of the materials. This can usually be done for most materials, except ferromagnetic ones. (We will treat the magnetic properties of materials in some later chapters.) Our program has netted us the six relations between the fields in region 1 and those in region 2 . We have put them all together in Table 33\u20131. We can now use them to match the waves in the two regions. We want to emphasize, however, that the idea we have just used will work in any physical situation in which you have differential equations and you want a solution that crosses a sharp boundary between two regions where some property changes. For our present purposes, we could have easily derived the same equations by using arguments about the fluxes and circulations at the boundary. (You might see whether you can get the same result that way.) But now you have seen a method that will work in case you ever get stuck and don\u2019t see any easy argument about the physics of what is happening at the boundary\u2014you can just work with the equations. Now we are ready to apply our boundary conditions to the waves we wrote down in Section 33\u20132. We had: E i E r E t B i B r B t = E 0 e i(\u03c9t\u2212 k x x\u2212 k y y) , = E \u2032 0 e i( \u03c9 \u2032 t\u2212 k \u2032 x x\u2212 k \u2032 y y) , = E \u2032\u2032 0 e i( \u03c9 \u2032\u2032 t\u2212 k \u2032\u2032 x x\u2212 k \u2032\u2032 y y) , = k\u00d7 E i \u03c9 , = k \u2032 \u00d7 E r \u03c9 \u2032 , = k \u2032\u2032 \u00d7 E t \u03c9 \u2032\u2032 . (33.32) (33.33) (33.34) (33.35) (33.36) (33.37) We have one further bit of knowledge: E is perpendicular to its propagation vector k for each wave. The results will depend on the direction of the E -vector (the \u201cpolarization\u201d) of the incoming wave. The analysis is much simplified if we treat separately the case of an incident wave with its E -vector parallel to the \u201cplane of incidence\u201d (that is, the xy -plane) and the case of an incident wave with the E -vector perpendicular to the plane of incidence. A wave of any other polarization is just a linear combination of two such waves. In other words, the reflected and transmitted intensities are different for different polarizations, and it is easiest to pick the two simplest cases and treat them separately. We will carry through the analysis for an incoming wave polarized perpendicular to the plane of incidence and then just give you the result for the other. We are cheating a little by taking the simplest case, but the principle is the same for both. So we take that E i has only a z -component, and since all the E -vectors are in the same direction we can leave off the vector signs. So long as both materials are isotropic, the induced oscillations of charges in the material will also be in the z -direction, and the E -field of the transmitted and radiated waves will have only z -components. So for all the waves, E x and E y and P x and P y are zero. The waves will have their E - and B -vectors as drawn in Fig. 33\u20136. (We are cutting a corner here on our original plan of getting everything from the equations. This result would also come out of the boundary conditions, but we can save a lot of algebra by using the physical argument. When you have some spare time, see if you can get the same result from the equations. It is clear that what we have said agrees with the equations; it is just that we have not shown that there are no other possibilities.) Now our boundary conditions, Eqs. (33.26) through (33.31), give relations between the components of E and B in regions 1 and 2 . For region 2 we have only the transmitted wave, but in region 1 we have two waves. Which one do we use? The fields in region 1 are, of course, the superposition of the fields of the incident and reflected waves. (Since each satisfies Maxwell\u2019s equations, so does the sum.) So when we use the boundary conditions, we must use that E 1 = E i + E r , E 2 = E t , E E E E E and similarly for the B \u2019s. For the polarization we are considering, Eqs. (33.26) and (33.28) give us no new information; only Eq. (33.27) is useful. It says that E i + E r = E t , E E E at the boundary, that is, for x=0 . So we have that E 0 e i(\u03c9t\u2212 k y y) + E \u2032 0 e i( \u03c9 \u2032 t\u2212 k \u2032 y y) = E \u2032\u2032 0 e i( \u03c9 \u2032\u2032 t\u2212 k \u2032\u2032 y y) , (33.38) which must be true for all t and for all y . Suppose we look first at y=0 . Then we have E 0 e i\u03c9t + E \u2032 0 e i \u03c9 \u2032 t = E \u2032\u2032 0 e i \u03c9 \u2032\u2032 t . \u2032 \u2033 This equation says that two oscillating terms are equal to a third oscillation. That can happen only if all the oscillations have the same frequency. (It is impossible for three\u2014or any number\u2014of such terms with different frequencies to add to zero for all times.) So \u03c9 \u2032\u2032 = \u03c9 \u2032 =\u03c9. (33.39) As we knew all along, the frequencies of the reflected and transmitted waves are the same as that of the incident wave. We should really have saved ourselves some trouble by putting that in at the beginning, but we wanted to show you that it can also be got out of the equations. When you are doing a real problem, it is usually the best thing to put everything you know into the works right at the start and save yourself a lot of trouble. By definition, the magnitude of k is given by k 2 = n 2 \u03c9 2 / c 2 , so we have also that k \u2032\u20322 n 2 2 = k \u20322 n 2 1 = k 2 n 2 1 . (33.40) Now look at Eq. (33.38) for t=0 . Using again the same kind of argument we have just made, but this time based on the fact that the equation must hold for all values of y , we get that k \u2032\u2032 y = k \u2032 y = k y . (33.41) From Eq. (33.40), k \u20322 = k 2 , so k \u20322 x + k \u20322 y = k 2 x + k 2 y . \u2032 2 \u2032 2 2 2 Combining this with Eq. (33.41), we have that k \u20322 x = k 2 x , \u2032 2 2 or that k \u2032 x =\u00b1 k x . The positive sign makes no sense; that would not give a reflected wave, but another incident wave, and we said at the start that we were solving the problem of only one incident wave. So we have k \u2032 x =\u2212 k x . (33.42) The two equations (33.41) and (33.42) give us that the angle of reflection is equal to the angle of incidence, as we expected. (See Fig. 33\u20133.) The reflected wave is E r = E \u2032 0 e i(\u03c9t+ k x x\u2212 k y y) . (33.43) For the transmitted wave we already have that k \u2032\u2032 y = k y , \u2033 and k \u2032\u20322 n 2 2 = k 2 n 2 1 ; (33.44) so we can solve these to find k \u2032\u2032 x . We get k \u2032\u20322 x = k \u2032\u20322 \u2212 k \u2032\u20322 y = n 2 2 n 2 1 k 2 \u2212 k 2 y . (33.45) Suppose for a moment that n 1 and n 2 are real numbers (that the imaginary parts of the indexes are very small). Then all the k \u2019s are also real numbers, and from Fig. 33\u20133 we find that k y k =sin \u03b8 i , k \u2032\u2032 y k \u2032\u2032 =sin \u03b8 t . (33.46) From (33.44) we get that n 2 sin \u03b8 t = n 1 sin \u03b8 i , (33.47) which is Snell\u2019s law of refraction\u2014again, something we already knew. If the indexes are not real, the wave numbers are complex, and we have to use Eq. (33.45). [We could still define the angles \u03b8 i and \u03b8 t by Eq. (33.46), and Snell\u2019s law, Eq. (33.47), would be true in general. But then the \u201cangles\u201d also are complex numbers, thereby losing their simple geometrical interpretation as angles. It is best then to describe the behavior of the waves by their complex k x or k \u2032\u2032 x values.] So far, we haven\u2019t found anything new. We have just had the simple-minded delight of getting some obvious answers from a complicated mathematical machinery. Now we are ready to find the amplitudes of the waves which we have not yet known. Using our results for the \u03c9 \u2019s and k \u2019s, the exponential factors in Eq. (33.38) can be cancelled, and we get E 0 + E \u2032 0 = E \u2032\u2032 0 . (33.48) Since both E \u2032 0 and E \u2032\u2032 0 are unknown, we need one more relationship. We must use another of the boundary conditions. The equations for E x and E y are no help, because all the E \u2019s have only a z -component. So we must use the conditions on B . Let\u2019s try Eq. (33.29): B x2 = B x1 . B B From Eqs. (33.35) through (33.37), B xi B xr B xt = k y E i \u03c9 , = k \u2032 y E r \u03c9 \u2032 , = k \u2032\u2032 y E t \u03c9 \u2032\u2032 . Recalling that \u03c9 \u2032\u2032 = \u03c9 \u2032 =\u03c9 and k \u2032\u2032 y = k \u2032 y = k y , we get that E 0 + E \u2032 0 = E \u2032\u2032 0 . \u2032 \u2033 But this is just Eq. (33.48) all over again! We\u2019ve just wasted time getting something we already knew. We could try Eq. (33.30), B z2 = B z1 , but there are no z -components of B ! So there\u2019s only one equation left: Eq. (33.31), B y2 = B y1 . For the three waves: B yi =\u2212 k x E i \u03c9 , B yr =\u2212 k \u2032 x E r \u03c9 \u2032 , B yt =\u2212 k \u2032\u2032 x E t \u03c9 \u2032\u2032 . (33.49) Putting for E i , E r , and E t the wave expression for x=0 (to be at the boundary), the boundary condition is k x \u03c9 E 0 e i(\u03c9t\u2212 k y y) + k \u2032 x \u03c9 \u2032 E \u2032 0 e i( \u03c9 \u2032 t\u2212 k \u2032 y y) = k \u2032\u2032 x \u03c9 \u2032\u2032 E \u2032\u2032 0 e i( \u03c9 \u2032\u2032 t\u2212 k \u2032\u2032 y y) . \u2032 \u2033 Again all \u03c9 \u2019s and k y \u2019s are equal, so this reduces to k x E 0 + k \u2032 x E \u2032 0 = k \u2032\u2032 x E \u2032\u2032 0 . (33.50) This gives us an equation for the E \u2019s that is different from Eq. (33.48). With the two, we can solve for E \u2032 0 and E \u2032\u2032 0 . Remembering that k \u2032 x =\u2212 k x , we get E \u2032 0 E \u2032\u2032 0 = k x \u2212 k \u2032\u2032 x k x + k \u2032\u2032 x E 0 , = 2 k x k x + k \u2032\u2032 x E 0 . (33.51) (33.52) These, together with Eq. (33.45) or Eq. (33.46) for k \u2032\u2032 x , give us what we wanted to know. We will discuss the consequences of this result in the next section. If we begin with a wave polarized with its E -vector parallel to the plane of incidence, E will have both x - and y -components, as shown in Fig. 33\u20137. The algebra is straightforward but more complicated. (The work can be somewhat reduced by expressing things in this case in terms of the magnetic fields, which are all in the z -direction.) One finds that | E \u2032 0 |= n 2 2 k x \u2212 n 2 1 k \u2032\u2032 x n 2 2 k x + n 2 1 k \u2032\u2032 x | E 0 | (33.53) and | E \u2032\u2032 0 |= 2 n 1 n 2 k x n 2 2 k x + n 2 1 k \u2032\u2032 x | E 0 |. (33.54) Let\u2019s see whether our results agree with those we got earlier. Equation (33.3) is the result we worked out in Chapter 33 of Volume I for the ratio of the intensity of the reflected wave to the intensity of the incident wave. Then, however, we were considering only real indexes. For real indexes (and k \u2019s), we can write k x =kcos \u03b8 i = \u03c9 n 1 c cos \u03b8 i , k \u2032\u2032 x = k \u2032\u2032 cos \u03b8 t = \u03c9 n 2 c cos \u03b8 t . Substituting in Eq. (33.51), we have E \u2032 0 E 0 = n 1 cos \u03b8 i \u2212 n 2 cos \u03b8 t n 1 cos \u03b8 i + n 2 cos \u03b8 t , (33.55) which does not look the same as Eq. (33.3). It will, however, if we use Snell\u2019s law to get rid of the n \u2019s. Setting n 2 = n 1 sin \u03b8 i /sin \u03b8 t , and multiplying the numerator and denominator by sin \u03b8 t , we get E \u2032 0 E 0 = cos \u03b8 i sin \u03b8 t \u2212sin \u03b8 i cos \u03b8 t cos \u03b8 i sin \u03b8 t +sin \u03b8 i cos \u03b8 t . \u2032 The numerator and denominator are just the sines of \u2212( \u03b8 i \u2212 \u03b8 t ) and ( \u03b8 i + \u03b8 t ) ; we get E \u2032 0 E 0 =\u2212 sin( \u03b8 i \u2212 \u03b8 t ) sin( \u03b8 i + \u03b8 t ) . (33.56) Since E \u2032 0 and E 0 are in the same material, the intensities are proportional to the squares of the electric fields, and we get the same result as before. Similarly, Eq. (33.53) is the same as Eq. (33.4). For waves which arrive at normal incidence, \u03b8 i =0 and \u03b8 t =0 . Equation (33.56) gives 0/0 , which is not very useful. We can, however, go back to Eq. (33.55), which gives I r I i =( E \u2032 0 E 0 ) 2 =( n 1 \u2212 n 2 n 1 + n 2 ) 2 . (33.57) This result, naturally, applies for \u201ceither\u201d polarization, since for normal incidence there is no special \u201cplane of incidence.\u201d We can now use our results to understand the interesting phenomenon of reflection from metals. Why is it that metals are shiny? We saw in the last chapter that metals have an index of refraction which, for some frequencies, has a large imaginary part. Let\u2019s see what we would get for the reflected intensity when light shines from air (with n=1 ) onto a material with n=\u2212i n I . Then Eq. (33.55) gives (for normal incidence) E \u2032 0 E 0 = 1+i n I 1\u2212i n I . \u2032 For the intensity of the reflected wave, we want the square of the absolute values of E \u2032 0 and E 0 : I r I i = | E \u2032 0 | 2 | E 0 | 2 = |1+i n I | 2 |1\u2212i n I | 2 , (33.58) or I r I i = 1+ n 2 I 1+ n 2 I =1. (33.59) For a material with an index which is a pure imaginary number, there is 100 percent reflection! Metals do not reflect 100 percent, but many do reflect visible light very well. In other words, the imaginary part of their indexes is very large. But we have seen that a large imaginary part of the index means a strong absorption. So there is a general rule that if any material gets to be a very good absorber at any frequency, the waves are strongly reflected at the surface and very little gets inside to be absorbed. You can see this effect with strong dyes. Pure crystals of the strongest dyes have a \u201cmetallic\u201d shine. Probably you have noticed that at the edge of a bottle of purple ink the dried dye will give a golden metallic reflection, or that dried red ink will sometimes give a greenish metallic reflection. Red ink absorbs out the greens of transmitted light, so if the ink is very concentrated, it will exhibit a strong surface reflection for the frequencies of green light. You can easily show this effect by coating a glass plate with red ink and letting it dry. If you direct a beam of white light at the back of the plate, as shown in Fig. 33\u20138, there will be a transmitted beam of red light and a reflected beam of green light. If light goes from a material like glass, with a real index n greater than 1 , toward, say, air, with an index n 2 equal to 1 , Snell\u2019s law says that sin \u03b8 t =nsin \u03b8 i . sin \u03b8 sin \u03b8 The angle \u03b8 t of the transmitted wave becomes 90 \u2218 when the incident angle \u03b8 i is equal to the \u201ccritical angle\u201d \u03b8 c given by nsin \u03b8 c =1. (33.60) What happens for \u03b8 i greater than the critical angle? You know that there is total internal reflection. But how does that come about? Let\u2019s go back to Eq. (33.45) which gives the wave number k \u2032\u2032 x for the transmitted wave. We would have k \u2032\u20322 x = k 2 n 2 \u2212 k 2 y . 2 Now k y =ksin \u03b8 i and k=\u03c9n/c , so k \u2032\u20322 x = \u03c9 2 c 2 (1\u2212 n 2 sin 2 \u03b8 i ). 2 If nsin \u03b8 i is greater than one, k \u2032\u20322 x is negative and k \u2032\u2032 x is a pure imaginary, say \u00b1i k I . You know by now what that means! The \u201ctransmitted\u201d wave (Eq. 33.34) will have the form E t = E \u2032\u2032 0 e \u00b1 k I x e i(\u03c9t\u2212 k y y) . \u2033 i ( k ) The wave amplitude either grows or drops off exponentially with increasing x . Clearly, what we want here is the negative sign. Then the amplitude of the wave to the right of the boundary will go as shown in Fig. 33\u20139. Notice that k I is around \u03c9/c \u2014which is of the order 1/ \u03bb 0 , the reciprocal of the free-space wavelength of the light. When light is totally reflected from the inside of a glass-air surface, there are fields in the air, but they extend beyond the surface only a distance of the order of the wavelength of the light. We can now see how to answer the following question: If a light wave in glass arrives at the surface at a large enough angle, it is reflected; if another piece of glass is brought up to the surface (so that the \u201csurface\u201d in effect disappears) the light is transmitted. Exactly when does this happen? Surely there must be continuous change from total reflection to no reflection! The answer, of course, is that if the air gap is so small that the exponential tail of the wave in the air has an appreciable strength at the second piece of glass, it will shake the electrons there and generate a new wave, as shown in Fig. 33\u201310. Some light will be transmitted. (Clearly, our solution is incomplete; we should solve all the equations again for a thin layer of air between two regions of glass.) This transmission effect can be observed with ordinary light only if the air gap is very small (of the order of the wavelength of light, like 10 \u22125 cm), but it is easily demonstrated with three-centimeter waves. Then the exponentially decreasing field extends several centimeters. A microwave apparatus that shows the effect is drawn in Fig. 33\u201311. Waves from a small three-centimeter transmitter are directed at a 45 \u2218 prism of paraffin. The index of refraction of paraffin for these frequencies is 1.50 , and therefore the critical angle is 41.5 \u2218 . So the wave is totally reflected from the 45 \u2218 face and is picked up by detector A , as indicated in Fig. 33\u201311(a). If a second paraffin prism is placed in contact with the first, as shown in part (b) of the figure, the wave passes straight through and is picked up at detector B . If a gap of a few centimeters is left between the two prisms, as in part (c), there are both transmitted and reflected waves. The electric field outside the 45 \u2218 face of the prism in Fig. 33\u201311(a) can also be shown by bringing detector B to within a few centimeters of the surface."
    },
    {
        "input": "Probability",
        "output": "\u201cThe true logic of this world is in the calculus of probabilities.\u201d \u2014James Clerk Maxwell \u201cChance\u201d is a word which is in common use in everyday living. The radio reports speaking of tomorrow\u2019s weather may say: \u201cThere is a sixty percent chance of rain.\u201d You might say: \u201cThere is a small chance that I shall live to be one hundred years old.\u201d Scientists also use the word chance. A seismologist may be interested in the question: \u201cWhat is the chance that there will be an earthquake of a certain size in Southern California next year?\u201d A physicist might ask the question: \u201cWhat is the chance that a particular geiger counter will register twenty counts in the next ten seconds?\u201d A politician or statesman might be interested in the question: \u201cWhat is the chance that there will be a nuclear war within the next ten years?\u201d You may be interested in the chance that you will learn something from this chapter. By chance, we mean something like a guess. Why do we make guesses? We make guesses when we wish to make a judgment but have incomplete information or uncertain knowledge. We want to make a guess as to what things are, or what things are likely to happen. Often we wish to make a guess because we have to make a decision. For example: Shall I take my raincoat with me tomorrow? For what earth movement should I design a new building? Shall I build myself a fallout shelter? Shall I change my stand in international negotiations? Shall I go to class today? Sometimes we make guesses because we wish, with our limited knowledge, to say as much as we can about some situation. Really, any generalization is in the nature of a guess. Any physical theory is a kind of guesswork. There are good guesses and there are bad guesses. The theory of probability is a system for making better guesses. The language of probability allows us to speak quantitatively about some situation which may be highly variable, but which does have some consistent average behavior. Let us consider the flipping of a coin. If the toss\u2014and the coin\u2014are \u201chonest,\u201d we have no way of knowing what to expect for the outcome of any particular toss. Yet we would feel that in a large number of tosses there should be about equal numbers of heads and tails. We say: \u201cThe probability that a toss will land heads is 0.5.\u201d We speak of probability only for observations that we contemplate being made in the future. By the \u201cprobability\u201d of a particular outcome of an observation we mean our estimate for the most likely fraction of a number of repeated observations that will yield that particular outcome. If we imagine repeating an observation\u2014such as looking at a freshly tossed coin\u2014N times, and if we call NA our estimate of the most likely number of our observations that will give some specified result A, say the result \u201cheads,\u201d then by P(A), the probability of observing A, we mean P(A)=NA/N. Our definition requires several comments. First of all, we may speak of a probability of something happening only if the occurrence is a possible outcome of some repeatable observation. It is not clear that it would make any sense to ask: \u201cWhat is the probability that there is a ghost in that house?\u201d You may object that no situation is exactly repeatable. That is right. Every different observation must at least be at a different time or place. All we can say is that the \u201crepeated\u201d observations should, for our intended purposes, appear to be equivalent. We should assume, at least, that each observation was made from an equivalently prepared situation, and especially with the same degree of ignorance at the start. (If we sneak a look at an opponent\u2019s hand in a card game, our estimate of our chances of winning are different than if we do not!) We should emphasize that N and NA in Eq. (6.1) are not intended to represent numbers based on actual observations. NA is our best estimate of what would occur in N imagined observations. Probability depends, therefore, on our knowledge and on our ability to make estimates. In effect, on our common sense! Fortunately, there is a certain amount of agreement in the common sense of many things, so that different people will make the same estimate. Probabilities need not, however, be \u201cabsolute\u201d numbers. Since they depend on our ignorance, they may become different if our knowledge changes. You may have noticed another rather \u201csubjective\u201d aspect of our definition of probability. We have referred to NA as \u201cour estimate of the most likely number \u2026\u201d We do not mean that we expect to observe exactly NA, but that we expect a number near NA, and that the number NA is more likely than any other number in the vicinity. If we toss a coin, say, 30 times, we should expect that the number of heads would not be very likely to be exactly 15, but rather only some number near to 15, say 12, 13, 14, 15, 16, or 17. However, if we must choose, we would decide that 15 heads is more likely than any other number. We would write P(heads)=0.5. Why did we choose 15 as more likely than any other number? We must have argued with ourselves in the following manner: If the most likely number of heads is NH in a total number of tosses N , then the most likely number of tails NT is (N\u2212NH) . (We are assuming that every toss gives either heads or tails, and no \u201cother\u201d result!) But if the coin is \u201chonest,\u201d there is no preference for heads or tails. Until we have some reason to think the coin (or toss) is dishonest, we must give equal likelihoods for heads and tails. So we must set NT=NH . It follows that NT= NH= N/2 , or P(H)= P(T)= 0.5 . We can generalize our reasoning to any situation in which there are m different but \u201cequivalent\u201d (that is, equally likely) possible results of an observation. If an observation can yield m different results, and we have reason to believe that any one of them is as likely as any other, then the probability of a particular outcome A is P(A)=1/m . If there are seven different-colored balls in an opaque box and we pick one out \u201cat random\u201d (that is, without looking), the probability of getting a ball of a particular color is 1 7 . The probability that a \u201cblind draw\u201d from a shuffled deck of 52 cards will show the ten of hearts is 1 52 . The probability of throwing a double-one with dice is 1 36 . In Chapter 5 we described the size of a nucleus in terms of its apparent area, or \u201ccross section.\u201d When we did so we were really talking about probabilities. When we shoot a high-energy particle at a thin slab of material, there is some chance that it will pass right through and some chance that it will hit a nucleus. (Since the nucleus is so small that we cannot see it, we cannot aim right at a nucleus. We must \u201cshoot blind.\u201d) If there are n atoms in our slab and the nucleus of each atom has a cross-sectional area \u03c3 , then the total area \u201cshadowed\u201d by the nuclei is n\u03c3 . In a large number N of random shots, we expect that the number of hits NC of some nucleus will be in the ratio to N as the shadowed area is to the total area of the slab: NC/N=n\u03c3/A. We may say, therefore, that the probability that any one projectile particle will suffer a collision in passing through the slab is PC= n A \u03c3, where n/A is the number of atoms per unit area in our slab. We would like now to use our ideas about probability to consider in some greater detail the question: \u201cHow many heads do I really expect to get if I toss a coin N times?\u201d Before answering the question, however, let us look at what does happen in such an \u201cexperiment.\u201d Figure 6\u20131 shows the results obtained in the first three \u201cruns\u201d of such an experiment in which N=30 . The sequences of \u201cheads\u201d and \u201ctails\u201d are shown just as they were obtained. The first game gave 11 heads; the second also 11 ; the third 16 . In three trials we did not once get 15 heads. Should we begin to suspect the coin? Or were we wrong in thinking that the most likely number of \u201cheads\u201d in such a game is 15 ? Ninety-seven more runs were made to obtain a total of 100 experiments of 30 tosses each. The results of the experiments are given in Table 6\u20131.1 Looking at the numbers in Table 6\u20131, we see that most of the results are \u201cnear\u201d 15 , in that they are between 12 and 18 . We can get a better feeling for the details of these results if we plot a graph of the distribution of the results. We count the number of games in which a score of k was obtained, and plot this number for each k . Such a graph is shown in Fig. 6\u20132. A score of 15 heads was obtained in 13 games. A score of 14 heads was also obtained 13 times. Scores of 16 and 17 were each obtained more than 13 times. Are we to conclude that there is some bias toward heads? Was our \u201cbest estimate\u201d not good enough? Should we conclude now that the \u201cmost likely\u201d score for a run of 30 tosses is really 16 heads? But wait! In all the games taken together, there were 3000 tosses. And the total number of heads obtained was 1493 . The fraction of tosses that gave heads is 0.498 , very nearly, but slightly less than half. We should certainly not assume that the probability of throwing heads is greater than 0.5 ! The fact that one particular set of observations gave 16 heads most often, is a fluctuation. We still expect that the most likely number of heads is 15 . We may ask the question: \u201cWhat is the probability that a game of 30 tosses will yield 15 heads\u2014or 16 , or any other number?\u201d We have said that in a game of one toss, the probability of obtaining one head is 0.5 , and the probability of obtaining no head is 0.5 . In a game of two tosses there are four possible outcomes: HH , HT , TH , TT . Since each of these sequences is equally likely, we conclude that (a) the probability of a score of two heads is 1 4 , (b) the probability of a score of one head is 2 4 , (c) the probability of a zero score is 1 4 . There are two ways of obtaining one head, but only one of obtaining either zero or two heads. Consider now a game of 3 tosses. The third toss is equally likely to be heads or tails. There is only one way to obtain 3 heads: we must have obtained 2 heads on the first two tosses, and then heads on the last. There are, however, three ways of obtaining 2 heads. We could throw tails after having thrown two heads (one way) or we could throw heads after throwing only one head in the first two tosses (two ways). So for scores of 3 -H , 2 -H , 1 -H , 0 -H we have that the number of equally likely ways is 1 , 3 , 3 , 1 , with a total of 8 different possible sequences. The probabilities are 1 8 , 3 8 , 3 8 , 1 8 . The argument we have been making can be summarized by a diagram like that in Fig. 6\u20133. It is clear how the diagram should be continued for games with a larger number of tosses. Figure 6\u20134 shows such a diagram for a game of 6 tosses. The number of \u201cways\u201d to any point on the diagram is just the number of different \u201cpaths\u201d (sequences of heads and tails) which can be taken from the starting point. The vertical position gives us the total number of heads thrown. The set of numbers which appears in such a diagram is known as Pascal\u2019s triangle. The numbers are also known as the binomial coefficients, because they also appear in the expansion of (a+b)n . If we call n the number of tosses and k the number of heads thrown, then the numbers in the diagram are usually designated by the symbol ( n k ) . We may remark in passing that the binomial coefficients can also be computed from ( n k )= n! k!(n\u2212k)! , where n! , called \u201cn -factorial,\u201d represents the product (n)(n\u22121)(n\u22122)\u22ef(3)(2)(1) . We are now ready to compute the probability P(k,n) of throwing k heads in n tosses, using our definition Eq. (6.1). The total number of possible sequences is 2n (since there are 2 outcomes for each toss), and the number of ways of obtaining k heads is ( n k ) , all equally likely, so we have P(k,n)= ( n k ) 2n . Since P(k,n) is the fraction of games which we expect to yield k heads, then in 100 games we should expect to find k heads 100\u22c5P(k,n) times. The dashed curve in Fig. 6\u20132 passes through the points computed from 100\u22c5P(k,30) . We see that we expect to obtain a score of 15 heads in 14 or 15 games, whereas this score was observed in 13 games. We expect a score of 16 in 13 or 14 games, but we obtained that score in 15 games. Such fluctuations are \u201cpart of the game.\u201d The method we have just used can be applied to the most general situation in which there are only two possible outcomes of a single observation. Let us designate the two outcomes by W (for \u201cwin\u201d) and L (for \u201close\u201d). In the general case, the probability of W or L in a single event need not be equal. Let p be the probability of obtaining the result W . Then q , the probability of L , is necessarily (1\u2212p) . In a set of n trials, the probability P(k,n) that W will be obtained k times is P(k,n)=( n k )pkqn\u2212k. This probability function is called the Bernoulli or, also, the binomial probability. There is another interesting problem in which the idea of probability is required. It is the problem of the \u201crandom walk.\u201d In its simplest version, we imagine a \u201cgame\u201d in which a \u201cplayer\u201d starts at the point x=0 and at each \u201cmove\u201d is required to take a step either forward (toward +x ) or backward (toward \u2212x ). The choice is to be made randomly, determined, for example, by the toss of a coin. How shall we describe the resulting motion? In its general form the problem is related to the motion of atoms (or other particles) in a gas\u2014called Brownian motion\u2014and also to the combination of errors in measurements. You will see that the random-walk problem is closely related to the coin-tossing problem we have already discussed. First, let us look at a few examples of a random walk. We may characterize the walker\u2019s progress by the net distance DN traveled in N steps. We show in the graph of Fig. 6\u20135 three examples of the path of a random walker. (We have used for the random sequence of choices the results of the coin tosses shown in Fig. 6\u20131.) What can we say about such a motion? We might first ask: \u201cHow far does he get on the average?\u201d We must expect that his average progress will be zero, since he is equally likely to go either forward or backward. But we have the feeling that as N increases, he is more likely to have strayed farther from the starting point. We might, therefore, ask what is his average distance travelled in absolute value, that is, what is the average of |D| . It is, however, more convenient to deal with another measure of \u201cprogress,\u201d the square of the distance: D2 is positive for either positive or negative motion, and is therefore a reasonable measure of such random wandering. We can show that the expected value of D 2 N is just N , the number of steps taken. By \u201cexpected value\u201d we mean the probable value (our best guess), which we can think of as the expected average behavior in many repeated sequences. We represent such an expected value by \u27e8D 2 N \u27e9 , and may refer to it also as the \u201cmean square distance.\u201d After one step, D2 is always +1 , so we have certainly \u27e8D 2 1 \u27e9=1 . (All distances will be measured in terms of a unit of one step. We shall not continue to write the units of distance.) The expected value of D 2 N for N>1 can be obtained from DN\u22121 . If, after (N\u22121) steps, we have DN\u22121 , then after N steps we have DN=DN\u22121+1 or DN=DN\u22121\u22121 . For the squares, D 2 N ={ D 2 N\u22121 +2DN\u22121+1, or D 2 N\u22121 \u22122DN\u22121+1. In a number of independent sequences, we expect to obtain each value one-half of the time, so our average expectation is just the average of the two possible values. The expected value of D 2 N is then D 2 N\u22121 +1 . In general, we should expect for D 2 N\u22121 its \u201cexpected value\u201d \u27e8D 2 N\u22121 \u27e9 (by definition!). So \u27e8D 2 N \u27e9=\u27e8D 2 N\u22121 \u27e9+1. We have already shown that \u27e8D 2 1 \u27e9=1 ; it follows then that \u27e8D 2 N \u27e9=N, a particularly simple result! If we wish a number like a distance, rather than a distance squared, to represent the \u201cprogress made away from the origin\u201d in a random walk, we can use the \u201croot-mean-square distance\u201d Drms : Drms= \u221a \u27e8D2\u27e9 = \u221a N . We have pointed out that the random walk is closely similar in its mathematics to the coin-tossing game we considered at the beginning of the chapter. If we imagine the direction of each step to be in correspondence with the appearance of heads or tails in a coin toss, then D is just N H \u2212 N T , the difference in the number of heads and tails. Since N H + N T =N , the total number of steps (and tosses), we have D=2 N H \u2212N . We have derived earlier an expression for the expected distribution of N H (also called k ) and obtained the result of Eq. (6.5). Since N is just a constant, we have the corresponding distribution for D . (Since for every head more than N/2 there is a tail \u201cmissing,\u201d we have the factor of 2 between N H and D .) The graph of Fig. 6\u20132 represents the distribution of distances we might get in 30 random steps (where k=15 is to be read D=0 ; k=16 , D=2 ; etc.). The variation of N H from its expected value N/2 is N H \u2212 N 2 = D 2 . (6.11) The rms deviation is ( N H \u2212 N 2 ) rms = 1 2 N \u2212 \u2212 \u221a . (6.12) According to our result for D rms , we expect that the \u201ctypical\u201d distance in 30 steps ought to be 30 \u2212 \u2212 \u221a \u22485.5 , or a typical k should be about 5.5/2=2.75 units from 15 . We see that the \u201cwidth\u201d of the curve in Fig. 6\u20132, measured from the center, is just about 3 units, in agreement with this result. We are now in a position to consider a question we have avoided until now. How shall we tell whether a coin is \u201chonest\u201d or \u201cloaded\u201d? We can give now at least a partial answer. For an honest coin, we expect the fraction of the times heads appears to be 0.5 , that is, \u27e8 N H \u27e9 N =0.5. (6.13) We also expect an actual N H to deviate from N/2 by about N \u2212 \u2212 \u221a /2 , or the fraction to deviate by 1 N N \u2212 \u2212 \u221a 2 = 1 2 N \u2212 \u2212 \u221a . The larger N is, the closer we expect the fraction N H /N to be to one-half. In Fig. 6\u20136 we have plotted the fraction N H /N for the coin tosses reported earlier in this chapter. We see the tendency for the fraction of heads to approach 0.5 for large N . Unfortunately, for any given run or combination of runs there is no guarantee that the observed deviation will be even near the expected deviation. There is always the finite chance that a large fluctuation\u2014a long string of heads or tails\u2014will give an arbitrarily large deviation. All we can say is that if the deviation is near the expected 1/2 N \u2212 \u2212 \u221a (say within a factor of 2 or 3 ), we have no reason to suspect the honesty of the coin. If it is much larger, we may be suspicious, but cannot prove, that the coin is loaded (or that the tosser is clever!). We have also not considered how we should treat the case of a \u201ccoin\u201d or some similar \u201cchancy\u201d object (say a stone that always lands in either of two positions) that we have good reason to believe should have a different probability for heads and tails. We have defined P(H)=\u27e8 N H \u27e9/N . How shall we know what to expect for N H ? In some cases, the best we can do is to observe the number of heads obtained in large numbers of tosses. For want of anything better, we must set \u27e8 N H \u27e9= N H (observed) . (How could we expect anything else?) We must understand, however, that in such a case a different experiment, or a different observer, might conclude that P(H) was different. We would expect, however, that the various answers should agree within the deviation 1/2 N \u2212 \u2212 \u221a [if P(H) is near one-half]. An experimental physicist usually says that an \u201cexperimentally determined\u201d probability has an \u201cerror,\u201d and writes P(H)= N H N \u00b1 1 2 N \u2212 \u2212 \u221a . (6.14) There is an implication in such an expression that there is a \u201ctrue\u201d or \u201ccorrect\u201d probability which could be computed if we knew enough, and that the observation may be in \u201cerror\u201d due to a fluctuation. There is, however, no way to make such thinking logically consistent. It is probably better to realize that the probability concept is in a sense subjective, that it is always based on uncertain knowledge, and that its quantitative evaluation is subject to change as we obtain more information. Let us return now to the random walk and consider a modification of it. Suppose that in addition to a random choice of the direction ( + or \u2212 ) of each step, the length of each step also varied in some unpredictable way, the only condition being that on the average the step length was one unit. This case is more representative of something like the thermal motion of a molecule in a gas. If we call the length of a step S , then S may have any value at all, but most often will be \u201cnear\u201d 1 . To be specific, we shall let \u27e8 S 2 \u27e9=1 or, equivalently, S rms =1 . Our derivation for \u27e8 D 2 \u27e9 would proceed as before except that Eq. (6.8) would be changed now to read \u27e8 D 2 N \u27e9=\u27e8 D 2 N\u22121 \u27e9+\u27e8 S 2 \u27e9=\u27e8 D 2 N\u22121 \u27e9+1. (6.15) We have, as before, that \u27e8 D 2 N \u27e9=N. (6.16) What would we expect now for the distribution of distances D ? What is, for example, the probability that D=0 after 30 steps? The answer is zero! The probability is zero that D will be any particular value, since there is no chance at all that the sum of the backward steps (of varying lengths) would exactly equal the sum of forward steps. We cannot plot a graph like that of Fig. 6\u20132. We can, however, obtain a representation similar to that of Fig. 6\u20132, if we ask, not what is the probability of obtaining D exactly equal to 0 , 1 , or 2 , but instead what is the probability of obtaining D near 0 , 1 , or 2 . Let us define P(x,\u0394x) as the probability that D will lie in the interval \u0394x located at x (say from x to x+\u0394x ). We expect that for small \u0394x the chance of D landing in the interval is proportional to \u0394x , the width of the interval. So we can write P(x,\u0394x)=p(x)\u0394x. (6.17) The function p(x) is called the probability density. The form of p(x) will depend on N , the number of steps taken, and also on the distribution of individual step lengths. We cannot demonstrate the proofs here, but for large N , p(x) is the same for all reasonable distributions in individual step lengths, and depends only on N . We plot p(x) for three values of N in Fig. 6\u20137. You will notice that the \u201chalf-widths\u201d (typical spread from x=0 ) of these curves is N \u2212 \u2212 \u221a , as we have shown it should be. You may notice also that the value of p(x) near zero is inversely proportional to N \u2212 \u2212 \u221a . This comes about because the curves are all of a similar shape and their areas under the curves must all be equal. Since p(x)\u0394x is the probability of finding D in \u0394x when \u0394x is small, we can determine the chance of finding D somewhere inside an arbitrary interval from x 1 to x 2 , by cutting the interval in a number of small increments \u0394x and evaluating the sum of the terms p(x)\u0394x for each increment. The probability that D lands somewhere between x 1 and x 2 , which we may write P( x 1 <D< x 2 ) , is equal to the shaded area in Fig. 6\u20138. The smaller we take the increments \u0394x , the more correct is our result. We can write, therefore, P( x 1 <D< x 2 )=\u2211p(x)\u0394x = \u222b x 2 x 1 p(x)dx. (6.18) The area under the whole curve is the probability that D lands somewhere (that is, has some value between x=\u2212\u221e and x=+\u221e ). That probability is surely 1 . We must have that \u222b +\u221e \u2212\u221e p(x)dx=1. (6.19) Since the curves in Fig. 6\u20137 get wider in proportion to N \u2212 \u2212 \u221a , their heights must be proportional to 1/ N \u2212 \u2212 \u221a to maintain the total area equal to 1 . The probability density function we have been describing is one that is encountered most commonly. It is known as the normal or Gaussian probability density. It has the mathematical form p(x)= 1 \u03c3 2\u03c0 \u2212 \u2212 \u221a e \u2212 x 2 /2 \u03c3 2 , (6.20) where \u03c3 is called the standard deviation and is given, in our case, by \u03c3= N \u2212 \u2212 \u221a or, if the rms step size is different from 1 , by \u03c3= N \u2212 \u2212 \u221a S rms . We remarked earlier that the motion of a molecule, or of any particle, in a gas is like a random walk. Suppose we open a bottle of an organic compound and let some of its vapor escape into the air. If there are air currents, so that the air is circulating, the currents will also carry the vapor with them. But even in perfectly still air, the vapor will gradually spread out\u2014will diffuse\u2014until it has penetrated throughout the room. We might detect it by its color or odor. The individual molecules of the organic vapor spread out in still air because of the molecular motions caused by collisions with other molecules. If we know the average \u201cstep\u201d size, and the number of steps taken per second, we can find the probability that one, or several, molecules will be found at some distance from their starting point after any particular passage of time. As time passes, more steps are taken and the gas spreads out as in the successive curves of Fig. 6\u20137. In a later chapter, we shall find out how the step sizes and step frequencies are related to the temperature and pressure of a gas. Earlier, we said that the pressure of a gas is due to the molecules bouncing against the walls of the container. When we come later to make a more quantitative description, we will wish to know how fast the molecules are going when they bounce, since the impact they make will depend on that speed. We cannot, however, speak of the speed of the molecules. It is necessary to use a probability description. A molecule may have any speed, but some speeds are more likely than others. We describe what is going on by saying that the probability that any particular molecule will have a speed between v and v+\u0394v is p(v)\u0394v , where p(v) , a probability density, is a given function of the speed v . We shall see later how Maxwell, using common sense and the ideas of probability, was able to find a mathematical expression for p(v) . The form2 of the function p(v) is shown in Fig. 6\u20139. Velocities may have any value, but are most likely to be near the most probable value v p . We often think of the curve of Fig. 6\u20139 in a somewhat different way. If we consider the molecules in a typical container (with a volume of, say, one liter), then there are a very large number N of molecules present ( N\u2248 10 22 ). Since p(v)\u0394v is the probability that one molecule will have its velocity in \u0394v , by our definition of probability we mean that the expected number \u27e8\u0394N\u27e9 to be found with a velocity in the interval \u0394v is given by \u27e8\u0394N\u27e9=Np(v)\u0394v. (6.21) We call Np(v) the \u201cdistribution in velocity.\u201d The area under the curve between two velocities v 1 and v 2 , for example the shaded area in Fig. 6\u20139, represents [for the curve Np(v) ] the expected number of molecules with velocities between v 1 and v 2 . Since with a gas we are usually dealing with large numbers of molecules, we expect the deviations from the expected numbers to be small (like 1/ N \u2212 \u2212 \u221a ), so we often neglect to say the \u201cexpected\u201d number, and say instead: \u201cThe number of molecules with velocities between v 1 and v 2 is the area under the curve.\u201d We should remember, however, that such statements are always about probable numbers. The ideas of probability are certainly useful in describing the behavior of the 10 22 or so molecules in a sample of a gas, for it is clearly impractical even to attempt to write down the position or velocity of each molecule. When probability was first applied to such problems, it was considered to be a convenience\u2014a way of dealing with very complex situations. We now believe that the ideas of probability are essential to a description of atomic happenings. According to quantum mechanics, the mathematical theory of particles, there is always some uncertainty in the specification of positions and velocities. We can, at best, say that there is a certain probability that any particle will have a position near some coordinate x . We can give a probability density p 1 (x) , such that p 1 (x)\u0394x is the probability that the particle will be found between x and x+\u0394x . If the particle is reasonably well localized, say near x 0 , the function p 1 (x) might be given by the graph of Fig. 6\u201310(a). Similarly, we must specify the velocity of the particle by means of a probability density p 2 (v) , with p 2 (v)\u0394v the probability that the velocity will be found between v and v+\u0394v . It is one of the fundamental results of quantum mechanics that the two functions p 1 (x) and p 2 (v) cannot be chosen independently and, in particular, cannot both be made arbitrarily narrow. If we call the typical \u201cwidth\u201d of the p 1 (x) curve [\u0394x] , and that of the p 2 (v) curve [\u0394v] (as shown in the figure), nature demands that the product of the two widths be at least as big as the number \u210f/2m , where m is the mass of the particle. We may write this basic relationship as [\u0394x]\u22c5[\u0394v]\u2265\u210f/2m. (6.22) This equation is a statement of the Heisenberg uncertainty principle that we mentioned earlier. Since the right-hand side of Eq. (6.22) is a constant, this equation says that if we try to \u201cpin down\u201d a particle by forcing it to be at a particular place, it ends up by having a high speed. Or if we try to force it to go very slowly, or at a precise velocity, it \u201cspreads out\u201d so that we do not know very well just where it is. Particles behave in a funny way! The uncertainty principle describes an inherent fuzziness that must exist in any attempt to describe nature. Our most precise description of nature must be in terms of probabilities. There are some people who do not like this way of describing nature. They feel somehow that if they could only tell what is really going on with a particle, they could know its speed and position simultaneously. In the early days of the development of quantum mechanics, Einstein was quite worried about this problem. He used to shake his head and say, \u201cBut, surely God does not throw dice in determining how electrons should go!\u201d He worried about that problem for a long time and he probably never really reconciled himself to the fact that this is the best description of nature that one can give. There are still one or two physicists who are working on the problem who have an intuitive conviction that it is possible somehow to describe the world in a different way and that all of this uncertainty about the way things are can be removed. No one has yet been successful. The necessary uncertainty in our specification of the position of a particle becomes most important when we wish to describe the structure of atoms. In the hydrogen atom, which has a nucleus of one proton with one electron outside of the nucleus, the uncertainty in the position of the electron is as large as the atom itself! We cannot, therefore, properly speak of the electron moving in some \u201corbit\u201d around the proton. The most we can say is that there is a certain chance p(r)\u0394V , of observing the electron in an element of volume \u0394V at the distance r from the proton. The probability density p(r) is given by quantum mechanics. For an undisturbed hydrogen atom p(r)=A e \u22122r/a . The number a is the \u201ctypical\u201d radius, where the function is decreasing rapidly. Since there is a small probability of finding the electron at distances from the nucleus much greater than a , we may think of a as \u201cthe radius of the atom,\u201d about 10 \u221210 meter. We can form an image of the hydrogen atom by imagining a \u201ccloud\u201d whose density is proportional to the probability density for observing the electron. A sample of such a cloud is shown in Fig. 6\u201311. Thus our best \u201cpicture\u201d of a hydrogen atom is a nucleus surrounded by an \u201celectron cloud\u201d (although we really mean a \u201cprobability cloud\u201d). The electron is there somewhere, but nature permits us to know only the chance of finding it at any particular place. In its efforts to learn as much as possible about nature, modern physics has found that certain things can never be \u201cknown\u201d with certainty. Much of our knowledge must always remain uncertain. The most we can know is in terms of probabilities."
    },
    {
        "input": "Lorentz Transformations of the Fields",
        "output": "We saw in the last chapter that the potential A\u03bc=(\u03d5,A) is a four-vector. The time component is the scalar potential \u03d5 , and the three space components are the vector potential A . We also worked out the potentials of a particle moving with uniform speed on a straight line by using the Lorentz transformation. (We had already found them by another method in Chapter 21.) For a point charge whose position at the time t is (vt,0,0) , the potentials at the point (x,y,z) are \u03d5 = 1 4\u03c0\u03f50 \u221a 1\u2212v2 q [ (x\u2212vt)2 1\u2212v2 +y2+z2]1/2 Ax = 1 4 \u03c0\u03f50 \u221a 1\u2212v2 qv [ (x\u2212vt)2 1\u2212v2 +y2+z2]1/2 Ay =Az=0. Equations (26.1) give the potentials at x , y , and z at the time t , for a charge whose \u201cpresent\u201d position (by which we mean the position at the time t ) is at x=vt . Notice that the equations are in terms of (x\u2212vt) , y , and z which are the coordinates measured from the current position P of the moving charge (see Fig. 26\u20131). The actual influence we know really travels at the speed c , so it is the behavior of the charge back at the retarded position P\u2032 that really counts.1 The point P\u2032 is at x=vt\u2032 (where t\u2032=t\u2212r\u2032/c is the retarded time). But we said that the charge was moving with uniform velocity in a straight line, so naturally the behavior at P\u2032 and the current position are directly related. In fact, if we make the added assumption that the potentials depend only upon the position and the velocity at the retarded moment, we have in equations (26.1) a complete formula for the potentials for a charge moving any way. It works this way. Suppose that you have a charge moving in some arbitrary fashion, say with the trajectory in Fig. 26\u20132, and you are trying to find the potentials at the point (x,y,z) . First, you find the retarded position P\u2032 and the velocity v\u2032 at that point. Then you imagine that the charge would keep on moving with this velocity during the delay time (t\u2032\u2212t) , so that it would then appear at an imaginary position Pproj , which we can call the \u201cprojected position,\u201d and would arrive there with the velocity v\u2032 . (Of course, it doesn\u2019t do that; its real position at t is at P .) Then the potentials at (x,y,z) are just what equations (26.1) would give for the imaginary charge at the projected position Pproj . What we are saying is that since the potentials depend only on what the charge is doing at the retarded time, the potentials will be the same whether the charge continued moving at a constant velocity or whether it changed its velocity after t\u2032 \u2014that is, after the potentials that were going to appear at (x,y,z) at the time t were already determined. You know, of course, that the moment that we have the formula for the potentials from a charge moving in any manner whatsoever, we have the complete electrodynamics; we can get the potentials of any charge distribution by superposition. Therefore we can summarize all the phenomena of electrodynamics either by writing Maxwell\u2019s equations or by the following series of remarks. (Remember them in case you are ever on a desert island. From them, all can be reconstructed. You will, of course, know the Lorentz transformation; you will never forget that on a desert island or anywhere else.) First, A\u03bc is a four-vector. Second, the Coulomb potential for a stationary charge is q/4\u03c0\u03f50r . Third, the potentials produced by a charge moving in any way depend only upon the velocity and position at the retarded time. With those three facts we have everything. From the fact that A\u03bc is a four-vector, we transform the Coulomb potential, which we know, and get the potentials for a constant velocity. Then, by the last statement that potentials depend only upon the past velocity at the retarded time, we can use the projected position game to find them. It is not a particularly useful way of doing things, but it is interesting to show that the laws of physics can be put in so many different ways. It is sometimes said, by people who are careless, that all of electrodynamics can be deduced solely from the Lorentz transformation and Coulomb\u2019s law. Of course, that is completely false. First, we have to suppose that there is a scalar potential and a vector potential that together make a four-vector. That tells us how the potentials transform. Then why is it that the effects at the retarded time are the only things that count? Better yet, why is it that the potentials depend only on the position and the velocity and not, for instance, on the acceleration? The fields E and B do depend on the acceleration. If you try to make the same kind of an argument with respect to them, you would say that they depend only upon the position and velocity at the retarded time. But then the fields from an accelerating charge would be the same as the fields from a charge at the projected position\u2014which is false. The fields depend not only on the position and the velocity along the path but also on the acceleration. So there are several additional tacit assumptions in this great statement that everything can be deduced from the Lorentz transformation. (Whenever you see a sweeping statement that a tremendous amount can come from a very small number of assumptions, you always find that it is false. There are usually a large number of implied assumptions that are far from obvious if you think about them sufficiently carefully.) Now that we have the potentials from a point charge moving at constant velocity, we ought to find the fields\u2014for practical reasons. There are many cases where we have uniformly moving particles\u2014for instance, cosmic rays going through a cloud chamber, or even slow-moving electrons in a wire. So let\u2019s at least see what the fields actually do look like for any speed\u2014even for speeds nearly that of light\u2014assuming only that there is no acceleration. It is an interesting question. We get the fields from the potentials by the usual rules: E=\u2212\u2207\u03d5\u2212 \u2202A \u2202t ,B=\u2207\u00d7A. First, for Ez Ez=\u2212 \u2202\u03d5 \u2202z \u2212 \u2202Az \u2202t . But Az is zero; so differentiating \u03d5 in equations (26.1), we get Ez= q 4 \u03c0\u03f50 \u221a 1\u2212v2 z [ (x\u2212vt)2 1\u2212v2 +y2+z2]3/2 . Similarly, for Ey , Ey= q 4 \u03c0\u03f50 \u221a 1\u2212v2 y [ (x\u2212vt)2 1\u2212v2 +y2+z2]3/2 . The x -component is a little more work. The derivative of \u03d5 is more complicated and Ax is not zero. First, \u2212 \u2202\u03d5 \u2202x = q 4 \u03c0\u03f50 \u221a 1\u2212v2 (x\u2212vt)/(1\u2212v2) [ (x\u2212vt)2 1\u2212v2 +y2+z2]3/2 . Then, differentiating Ax with respect to t , we find \u2212 \u2202Ax \u2202t = q 4 \u03c0\u03f50 \u221a 1\u2212v2 \u2212v2(x\u2212vt)/(1\u2212v2) [ (x\u2212vt)2 1\u2212v2 +y2+z2]3/2 . And finally, taking the sum, Ex= q 4 \u03c0\u03f50 \u221a 1\u2212v2 x\u2212vt [ (x\u2212vt)2 1\u2212v2 +y2+z2]3/2 . We\u2019ll look at the physics of E in a minute; let\u2019s first find B . For the z -component, B z = \u2202 A y \u2202x \u2212 \u2202 A x \u2202y . \u2202 A Since A y is zero, we have just one derivative to get. Notice, however, that A x is just v\u03d5 , and \u2202/\u2202y of v\u03d5 is just \u2212v E y . So B z =v E y . (26.7) Similarly, B y = \u2202 A x \u2202z \u2212 \u2202 A z \u2202x =+v \u2202\u03d5 \u2202z , \u2202 A \u2202 A \u2202 \u03d5 and B y =\u2212v E z . (26.8) Finally, B x is zero, since A y and A z are both zero. We can write the magnetic field simply as B=v\u00d7E. (26.9) Now let\u2019s see what the fields look like. We will try to draw a picture of the field at various positions around the present position of the charge. It is true that the influence of the charge comes, in a certain sense, from the retarded position; but because the motion is exactly specified, the retarded position is uniquely given in terms of the present position. For uniform velocities, it\u2019s nicer to relate the fields to the current position, because the field components at (x,y,z) depend only on (x\u2212vt) , y , and z \u2014which are the components of the displacement r from the present position to (x,y,z) (see Fig. 26\u20133). Consider first a point with z=0 . Then E has only x - and y -components. From Eqs. (26.3) and (26.6), the ratio of these components is just equal to the ratio of the x - and y -components of the displacement. That means that E is in the same direction as r , as shown in Fig. 26\u20133. Since E z is also proportional to z , it is clear that this result holds in three dimensions. In short, the electric field is radial from the charge, and the field lines radiate directly out of the charge, just as they do for a stationary charge. Of course, the field isn\u2019t exactly the same as for the stationary charge, because of all the extra factors of (1\u2212 v 2 ) . But we can show something rather interesting. The difference is just what you would get if you were to draw the Coulomb field with a peculiar set of coordinates in which the scale of x was squashed up by the factor 1\u2212 v 2 \u2212 \u2212 \u2212 \u2212 \u2212 \u221a . If you do that, the field lines will be spread out ahead and behind the charge and will be squeezed together around the sides, as shown in Fig. 26\u20134. If we relate the strength of E to the density of the field lines in the conventional way, we see a stronger field at the sides and a weaker field ahead and behind, which is just what the equations say. First, if we look at the strength of the field at right angles to the line of motion, that is, for (x\u2212vt)=0 , the distance from the charge is y 2 + z 2 \u2212 \u2212 \u2212 \u2212 \u2212 \u2212 \u221a . Here the total field strength is E 2 y + E 2 z \u2212 \u2212 \u2212 \u2212 \u2212 \u2212 \u2212 \u221a , which is E= q 4\u03c0 \u03f5 0 1\u2212 v 2 \u2212 \u2212 \u2212 \u2212 \u2212 \u221a 1 y 2 + z 2 . (26.10) The field is proportional to the inverse square of the distance\u2014just like the Coulomb field except increased by the constant, extra factor 1/ 1\u2212 v 2 \u2212 \u2212 \u2212 \u2212 \u2212 \u221a , which is always greater than one. So at the sides of a moving charge, the electric field is stronger than you get from the Coulomb law. In fact, the field in the sidewise direction is bigger than the Coulomb potential by the ratio of the energy of the particle to its rest mass. Ahead of the charge (and behind), y and z are zero and E= E x = q(1\u2212 v 2 ) 4\u03c0 \u03f5 0 (x\u2212vt ) 2 . (26.11) The field again varies as the inverse square of the distance from the charge but is now reduced by the factor (1\u2212 v 2 ) , in agreement with the picture of the field lines. If v/c is small, v 2 / c 2 is still smaller, and the effect of the (1\u2212 v 2 ) terms is very small; we get back to Coulomb\u2019s law. But if a particle is moving very close to the speed of light, the field in the forward direction is enormously reduced, and the field in the sidewise direction is enormously increased. Our results for the electric field of a charge can be put this way: Suppose you were to draw on a piece of paper the field lines for a charge at rest, and then set the picture to travelling with the speed v . Then, of course, the whole picture would be compressed by the Lorentz contraction; that is, the carbon granules on the paper would appear in different places. The miracle of it is that the picture you would see as the page flies by would still represent the field lines of the point charge. The contraction moves them closer together at the sides and spreads them out ahead and behind, just in the right way to give the correct line densities. We have emphasized before that field lines are not real but are only one way of representing the field. However, here they almost seem to be real. In this particular case, if you make the mistake of thinking that the field lines are somehow really there in space, and transform them, you get the correct field. That doesn\u2019t, however, make the field lines any more real. All you need do to remind yourself that they aren\u2019t real is to think about the electric fields produced by a charge together with a magnet; when the magnet moves, new electric fields are produced, and destroy the beautiful picture. So the neat idea of the contracting picture doesn\u2019t work in general. It is, however, a handy way to remember what the fields from a fast-moving charge are like. The magnetic field is v\u00d7E [from Eq. (26.9)]. If you take the velocity crossed into a radial E -field, you get a B which circles around the line of motion, as shown in Fig. 26\u20135. If we put back the c \u2019s, you will see that it\u2019s the same result we had for low-velocity charges. A good way to see where the c \u2019s must go is to refer back to the force law, F=q(E+v\u00d7B). ( ) You see that a velocity times the magnetic field has the same dimensions as an electric field. So the right-hand side of Eq. (26.9) must have a factor 1/ c 2 : B= v\u00d7E c 2 . (26.12) For a slow-moving charge ( v\u226ac ), we can take for E the Coulomb field; then B= q 4\u03c0 \u03f5 0 c 2 v\u00d7r r 3 . (26.13) This formula corresponds exactly to equations for the magnetic field of a current that we found in Section 14-7. We would like to point out, in passing, something interesting for you to think about. (We will come back to discuss it again later.) Imagine two protons with velocities at right angles, so that one will cross over the path of the other, but in front of it, so they don\u2019t collide. At some instant, their relative positions will be as in Fig. 26\u20136(a). We look at the force on q 1 due to q 2 and vice versa. On q 2 there is only the electric force from q 1 , since q 1 makes no magnetic field along its line of motion. On q 1 , however, there is again the electric force but, in addition, a magnetic force, since it is moving in a B -field made by q 2 . The forces are as drawn in Fig. 26\u20136(b). The electric forces on q 1 and q 2 are equal and opposite. However, there is a sidewise (magnetic) force on q 1 and no sidewise force on q 2 . Does action not equal reaction? We leave it for you to worry about. In the last section we calculated the electric and magnetic fields from the transformed potentials. The fields are important, of course, in spite of the arguments given earlier that there is physical meaning and reality to the potentials. The fields, too, are real. It would be convenient for many purposes to have a way to compute the fields in a moving system if you already know the fields in some \u201crest\u201d system. We have the transformation laws for \u03d5 and A , because A \u03bc is a four-vector. Now we would like to know the transformation laws of E and B . Given E and B in one frame, how do they look in another frame moving past? It is a convenient transformation to have. We could always work back through the potentials, but it is useful sometimes to be able to transform the fields directly. We will now see how that goes. How can we find the transformation laws of the fields? We know the transformation laws of the \u03d5 and A , and we know how the fields are given in terms of \u03d5 and A \u2014it should be easy to find the transformation for the B and E . (You might think that with every vector there should be something to make it a four-vector, so with E there\u2019s got to be something else we can use for the fourth component. And also for B . But it\u2019s not so. It\u2019s quite different from what you would expect.) To begin with, let\u2019s take just a magnetic field B , which is, of course \u2207\u00d7A . Now we know that the vector potential with its x -, y -, and z -components is only a piece of something; there is also a t -component. Also we know that for derivatives like \u2207 , besides the x , y , z parts, there is also a derivative with respect to t . So let\u2019s try to figure out what happens if we replace a \u201c y \u201d by a \u201c t \u201d, or a \u201c z \u201d by a \u201c t ,\u201d or something like that. First, notice the form of the terms in \u2207\u00d7A when we write out the components: B x B y B z = \u2202 A z \u2202y \u2212 \u2202 A y \u2202z , = \u2202 A x \u2202z \u2212 \u2202 A z \u2202x , = \u2202 A y \u2202x \u2212 \u2202 A x \u2202y . (26.14) The x -component is equal to a couple of terms that involve only y - and z -components. Suppose we call this combination of derivatives and components a \u201c zy -thing,\u201d and give it a shorthand name, F zy . We simply mean that F zy \u2261 \u2202 A z \u2202y \u2212 \u2202 A y \u2202z . (26.15) Similarly, B y is equal to the same kind of \u201cthing,\u201d but this time it is an \u201c xz -thing.\u201d And B z is, of course, the corresponding \u201c yx -thing.\u201d We have B x = F zy , B y = F xz , B z = F yx . (26.16) Now what happens if we simply try to concoct also some \u201c t \u201d-type things like F xt and F tz (since nature should be nice and symmetric in x , y , z , and t )? For instance, what is F tz ? It is, of course, \u2202 A t \u2202z \u2212 \u2202 A z \u2202t . \u2202 A \u2202 A But remember that A t =\u03d5 , so it is also \u2202\u03d5 \u2202z \u2212 \u2202 A z \u2202t . \u2202 \u03d5 \u2202 A You\u2019ve seen that before. It is the z -component of E . Well, almost\u2014there is a sign wrong. But we forgot that in the four-dimensional gradient the t -derivative comes with the opposite sign from x , y , and z . So we should really have taken the more consistent extension of F tz , as F tz = \u2202 A t \u2202z + \u2202 A z \u2202t (26.17) Then it is exactly equal to \u2212 E z . Trying also F tx and F ty , we find that the three possibilities give F tx =\u2212 E x , F ty =\u2212 E y , F tz =\u2212 E z . (26.18) What happens if both subscripts are t ? Or, for that matter, if both are x ? We get things like F tt = \u2202 A t \u2202t \u2212 \u2202 A t \u2202t , \u2202 A \u2202 A and F xx = \u2202 A x \u2202x \u2212 \u2202 A x \u2202x , \u2202 A \u2202 A which give nothing but zero. We have then six of these F -things. There are six more which you get by reversing the subscripts, but they give nothing really new, since F xy =\u2212 F yx , F F and so on. So, out of sixteen possible combinations of the four subscripts taken in pairs, we get only six different physical objects; and they are the components of B and E . To represent the general term of F , we will use the general subscripts \u03bc and \u03bd , where each can stand for 0 , 1 , 2 , or 3 \u2014meaning in our usual four-vector notation t , x , y , and z . Also, everything will be consistent with our four-vector notation if we define F \u03bc\u03bd by F \u03bc\u03bd =\u2207 \u03bc A \u03bd \u2212\u2207 \u03bd A \u03bc , (26.19) remembering that \u2207 \u03bc =(\u2202/\u2202t,\u2212\u2202/\u2202x,\u2212\u2202/\u2202y,\u2212\u2202/\u2202z) and that A \u03bc =(\u03d5, A x , A y , A z ) . What we have found is that there are six quantities that belong together in nature\u2014that are different aspects of the same thing. The electric and magnetic fields which we have considered as separate vectors in our slow-moving world (where we don\u2019t worry about the speed of light) are not vectors in four-space. They are parts of a new \u201cthing.\u201d Our physical \u201cfield\u201d is really the six-component object F \u03bc\u03bd . That is the way we must look at it for relativity. We summarize our results on F \u03bc\u03bd in Table 26\u20131. You see that what we have done here is to generalize the cross product. We began with the curl operation, and the fact that the transformation properties of the curl are the same as the transformation properties of two vectors\u2014the ordinary three-dimensional vector A and the gradient operator which we know also behaves like a vector. Let\u2019s look for a moment at an ordinary cross product in three dimensions, for example, the angular momentum of a particle. When an object is moving in a plane, the quantity (x v y \u2212y v x ) is important. For motion in three dimensions, there are three such important quantities, which we call the angular momentum: L xy L yz L zx =m(x v y \u2212y v x ), =m(y v z \u2212z v y ), =m(z v x \u2212x v z ). Then (although you may have forgotten by now) we discovered in Chapter 20 of Vol. I the miracle that these three quantities could be identified with the components of a vector. In order to do so, we had to make an artificial rule with a right-hand convention. It was just luck. It was luck because L ij (with i and j equal to x , y , or z ) was an antisymmetric object: L ij =\u2212 L ji , L ii =0. L L L 0. Of the nine possible quantities, there are only three independent numbers. And it just happens that when you change coordinate systems these three objects transform in exactly the same way as the components of a vector. The same thing lets us represent an element of surface as a vector. A surface element has two parts\u2014say dx and dy \u2014which we can represent by the vector da normal to the surface. But we can\u2019t do that in four dimensions. What is the \u201cnormal\u201d to dxdy ? Is it along z or along t ? In short, for three dimensions it happens by luck that after you\u2019ve taken a combination of two vectors like L ij , you can represent it again by another vector because there are just three terms that happen to transform like the components of a vector. But in four dimensions that is evidently impossible, because there are six independent terms, and you can\u2019t represent six things by four things. Even in three dimensions it is possible to have combinations of vectors that can\u2019t be represented by vectors. Suppose we take any two vectors a=( a x , a y , a z ) and b=( b x , b y , b z ) , and make the various possible combinations of components, like a x b x , a x b y , etc. There would be nine possible quantities: a x b x , a y b x , a z b x , a x b y , a y b y , a z b y , a x b z , a y b z , a z b z . We might call these quantities T ij . If we now go to a rotated coordinate system (say rotated about the z -axis), the components of a and b are changed. In the new system, a x , for example, gets replaced by a \u2032 x = a x cos\u03b8+ a y sin\u03b8, \u2032 and b y gets replaced by b \u2032 y = b y cos\u03b8\u2212 b x sin\u03b8. \u2032 And similarly for other components. The nine components of the product quantity T ij we have invented are all changed too, of course. For instance, T xy = a x b y gets changed to T \u2032 xy = a x b y ( cos 2 \u03b8)\u2212 a x b x (cos\u03b8sin\u03b8)+ a y b y (sin\u03b8cos\u03b8)\u2212 a y b x ( sin 2 \u03b8), or T \u2032 xy = T xy cos 2 \u03b8\u2212 T xx cos\u03b8sin\u03b8+ T yy sin\u03b8cos\u03b8\u2212 T yx sin 2 \u03b8. Each component of T \u2032 ij is a linear combination of the components of T ij . So we discover that it is not only possible to have a \u201cvector product\u201d like a\u00d7b which has three components that transform like a vector, but we can\u2014artificially\u2014also make another kind of \u201cproduct\u201d of two vectors T ij with nine components that transform under a rotation by a complicated set of rules that we could figure out. Such an object which has two indices to describe it, instead of one, is called a tensor. It is a tensor of the \u201csecond rank,\u201d because you can play this game with three vectors too and get a tensor of the third rank\u2014or with four, to get a tensor of the fourth rank, and so on. A tensor of the first rank is a vector. The point of all this is that our electromagnetic quantity F \u03bc\u03bd is also a tensor of the second rank, because it has two indices in it. It is, however, a tensor in four dimensions. It transforms in a special way which we will work out in a moment\u2014it is just the way a product of vectors transforms. For F \u03bc\u03bd it happens that if you change the indices around, F \u03bc\u03bd changes sign. That\u2019s a special case\u2014it is an antisymmetric tensor. So we say: the electric and magnetic fields are both part of an antisymmetric tensor of the second rank in four dimensions. You\u2019ve come a long way. Remember way back when we defined what a velocity meant? Now we are talking about \u201can antisymmetric tensor of the second rank in four dimensions.\u201d Now we have to find the law of the transformation of F \u03bc\u03bd . It isn\u2019t at all difficult to do; it\u2019s just laborious\u2014the brains involved are nil, but the work is not. What we want is the Lorentz transformation of \u2207 \u03bc A \u03bd \u2212\u2207 \u03bd A \u03bc . Since \u2207 \u03bc is just a special case of a vector, we will work with the general antisymmetric vector combination, which we can call G \u03bc\u03bd : G \u03bc\u03bd = a \u03bc b \u03bd \u2212 a \u03bd b \u03bc . (26.20) (For our purposes, a \u03bc will eventually be replaced by \u2207 \u03bc and b \u03bc will be replaced by the potential A \u03bc .) The components of a \u03bc and b \u03bc transform by the Lorentz formulas, which are a \u2032 t a \u2032 x a \u2032 y a \u2032 z = a t \u2212v a x 1\u2212 v 2 \u2212 \u2212 \u2212 \u2212 \u2212 \u221a , = a x \u2212v a t 1\u2212 v 2 \u2212 \u2212 \u2212 \u2212 \u2212 \u221a , = a y , = a z , b \u2032 t b \u2032 x b \u2032 y b \u2032 z = b t \u2212v b x 1\u2212 v 2 \u2212 \u2212 \u2212 \u2212 \u2212 \u221a , = b x \u2212v b t 1\u2212 v 2 \u2212 \u2212 \u2212 \u2212 \u2212 \u221a , = b y , = b z . (26.21) Now let\u2019s transform the components of G \u03bc\u03bd . We start with G tx : G \u2032 tx = a \u2032 t b \u2032 x \u2212 a \u2032 x b \u2032 t =( a t \u2212v a x 1\u2212 v 2 \u2212 \u2212 \u2212 \u2212 \u2212 \u221a )( b x \u2212v b t 1\u2212 v 2 \u2212 \u2212 \u2212 \u2212 \u2212 \u221a )\u2212( a x \u2212v a t 1\u2212 v 2 \u2212 \u2212 \u2212 \u2212 \u2212 \u221a )( b t \u2212v b x 1\u2212 v 2 \u2212 \u2212 \u2212 \u2212 \u2212 \u221a ) = a t b x \u2212 a x b t . But that is just G tx ; so we have the simple result G \u2032 tx = G tx . \u2032 We will do one more. G \u2032 ty = a t \u2212v a x 1\u2212 v 2 \u2212 \u2212 \u2212 \u2212 \u2212 \u221a b y \u2212 a y b t \u2212v b x 1\u2212 v 2 \u2212 \u2212 \u2212 \u2212 \u2212 \u221a = ( a t b y \u2212 a y b t )\u2212v( a x b y \u2212 a y b x ) 1\u2212 v 2 \u2212 \u2212 \u2212 \u2212 \u2212 \u221a . So we get that G \u2032 ty = G ty \u2212v G xy 1\u2212 v 2 \u2212 \u2212 \u2212 \u2212 \u2212 \u221a . G G And, of course, in the same way, G \u2032 tz = G tz \u2212v G xz 1\u2212 v 2 \u2212 \u2212 \u2212 \u2212 \u2212 \u221a . G G It is clear how the rest will go. Let\u2019s make a table of all six terms; only now we may as well write them for F \u03bc\u03bd : F \u2032 tx F \u2032 ty F \u2032 tz = F tx , = F ty \u2212v F xy 1\u2212 v 2 \u2212 \u2212 \u2212 \u2212 \u2212 \u221a , = F tz \u2212v F xz 1\u2212 v 2 \u2212 \u2212 \u2212 \u2212 \u2212 \u221a , F \u2032 xy F \u2032 yz F \u2032 zx = F xy \u2212v F ty 1\u2212 v 2 \u2212 \u2212 \u2212 \u2212 \u2212 \u221a , = F yz , = F zx \u2212v F zt 1\u2212 v 2 \u2212 \u2212 \u2212 \u2212 \u2212 \u221a . (26.22) Of course, we still have F \u2032 \u03bc\u03bd =\u2212 F \u2032 \u03bd\u03bc and F \u2032 \u03bc\u03bc =0 . So we have the transformation of the electric and magnetic fields. All we have to do is look at Table 26\u20131 to find out what our grand notation in terms of F \u03bc\u03bd means in terms of E and B . It\u2019s just a matter of substitution. So that we can see how it looks in the ordinary symbols, we\u2019ll rewrite our transformation of the field components in Table 26\u20132. The equations in Table 26\u20132 tell us how E and B change if we go from one inertial frame to another. If we know E and B in one system, we can find what they are in another that moves by with the speed v . We can write these equations in a form that is easier to remember if we notice that since v is in the x -direction, all the terms with v are components of the cross products v\u00d7E and v\u00d7B . So we can rewrite the transformations as shown in Table 26\u20133. It is now easier to remember which components go where. In fact, the transformation can be written even more simply if we define the field components along x as the \u201cparallel\u201d components E \u2225 and B \u2225 (because they are parallel to the relative velocity of S and S \u2032 ), and the total transverse components\u2014the vector sums of the y - and z -components\u2014as the \u201cperpendicular\u201d components E \u22a5 and B \u22a5 . Then we get the equations in Table 26\u20134. (We have also put back the c \u2019s, so it will be more convenient when we want to refer back later.) The field transformations give us another way of solving some problems we have done before\u2014for instance, for finding the fields of a moving point charge. We have worked out the fields before by differentiating the potentials. But we could now do it by transforming the Coulomb field. If we have a point charge at rest in the S -frame, then there is only the simple radial E -field. In the S \u2032 -frame we will see a point charge moving with the velocity u , if the S \u2032 -frame moves by the S -frame with the speed v=\u2212u . We will let you show that the transformations of Tables 26\u20133 and 26\u20134 give the same electric and magnetic fields we got in Section 26-2. The transformation of Table 26\u20132 gives us an interesting and simple answer for what we see if we move past any system of fixed charges. For example, suppose we want to know the fields in our frame S \u2032 if we are moving along between the plates of a condenser, as shown in Fig. 26\u20137. (It is, of course, the same thing if we say that a charged condenser is moving past us.) What do we see? The transformation is easy in this case because the B -field in the original system is zero. Suppose, first, that our motion is perpendicular to E ; then we will see an E \u2032 =E/ 1\u2212 v 2 / c 2 \u2212 \u2212 \u2212 \u2212 \u2212 \u2212 \u2212 \u2212 \u221a which is still completely transverse. We will see, in addition, a magnetic field B \u2032 =\u2212v\u00d7 E \u2032 / c 2 . (The 1\u2212 v 2 / c 2 \u2212 \u2212 \u2212 \u2212 \u2212 \u2212 \u2212 \u2212 \u221a doesn\u2019t appear in our formula for B \u2032 because we wrote it in terms of E \u2032 rather than E ; but it's the same thing.) So when we move along perpendicular to a static electric field, we see an added transverse B . If our motion is not perpendicular to E , we break E into E \u2225 and E \u22a5 . The parallel part is unchanged, E \u2032 \u2225 = E \u2225 , and the perpendicular component does as just described. Let\u2019s take the opposite case, and imagine we are moving through a pure static magnetic field. This time we would see an electric field E \u2032 equal to v\u00d7 B \u2032 , and the magnetic field changed by the factor 1/ 1\u2212 v 2 / c 2 \u2212 \u2212 \u2212 \u2212 \u2212 \u2212 \u2212 \u2212 \u221a (assuming it is transverse). So long as v is much less than c , we can neglect the change in the magnetic field, and the main effect is that an electric field appears. As one example of this effect, consider this once famous problem of determining the speed of an airplane. It\u2019s no longer famous, since radar can now be used to determine the air speed from ground reflections, but for many years it was very hard to find the speed of an airplane in bad weather. You could not see the ground and you didn\u2019t know which way was up, and so on. Yet it was important to know how fast you were moving relative to the earth. How can this be done without seeing the earth? Many who knew the transformation formulas thought of the idea of using the fact that the airplane moves in the magnetic field of the earth. Suppose that an airplane is flying where there is a magnetic field more or less known. Let\u2019s just take the simple case where the magnetic field is vertical. If we were flying through it with a horizontal velocity v , then, according to our formula, we should see an electric field which is v\u00d7B , i.e., perpendicular to the line of motion. If we hang an insulated wire across the airplane, this electric field will induce charges on the ends of the wire. That is nothing new. From the point of view of someone on the ground, we are moving a wire through a field, and the v\u00d7B force causes charges to move to the ends of the wire. The transformation equations just say the same thing in a different way. (The fact that we can say the thing more than one way doesn\u2019t mean that one way is better than another. We are getting so many different methods and tools that we can usually get the same result in 65 different ways!) So to measure v , all we have to do is measure the voltage between the ends of the wire. We can\u2019t do it with a voltmeter because the same fields will act on the wires in the voltmeter, but there are ways of measuring such fields. We talked about some of them when we discussed atmospheric electricity in Chapter 9. So it should be possible to measure the speed of the airplane. This important problem was, however, never solved this way. The reason is that the electric field that is developed is of the order of millivolts per meter. It is possible to measure such fields, but the trouble is that these fields are, unfortunately, not any different from any other electric fields. The field that is produced by motion through the magnetic field can\u2019t be distinguished from some electric field that was already in the air from another cause, say from electrostatic charges in the air, or on the clouds. We described in Chapter 9 that there are, typically, electric fields above the surface of the earth with strengths of about 100 volts per meter. But they are quite irregular. So as the airplane flies through the air, it sees fluctuations of atmospheric electric fields which are enormous in comparison to the tiny fields produced by the v\u00d7B term, and it turns out for practical reasons to be impossible to measure speeds of an airplane by its motion through the earth\u2019s magnetic field. It doesn\u2019t do much good to find electric and magnetic fields from Maxwell\u2019s equations unless we know what the fields do when we have them. You may remember that the fields are required to find the forces on charges, and that those forces determine the motion of the charge. So, of course, part of the theory of electrodynamics is the relation between the motion of charges and the forces. For a single charge in the fields E and B , the force is F=q(E+v\u00d7B). (26.23) This force is equal to the mass times the acceleration for low velocities, but the correct law for any velocity is that the force is equal to dp/dt . Writing p= m 0 v/ 1\u2212 v 2 / c 2 \u2212 \u2212 \u2212 \u2212 \u2212 \u2212 \u2212 \u2212 \u221a , we find that the relativistically correct equation of motion is d dt ( m 0 v 1\u2212 v 2 / c 2 \u2212 \u2212 \u2212 \u2212 \u2212 \u2212 \u2212 \u2212 \u221a )=F=q(E+v\u00d7B). (26.24) We would like now to discuss this equation from the point of view of relativity. Since we have put our Maxwell equations in relativistic form, it would be interesting to see what the equations of motion would look like in relativistic form. Let\u2019s see whether we can rewrite the equation in a four-vector notation. We know that the momentum is part of a four-vector p \u03bc whose time component is the energy m 0 c 2 / 1\u2212 v 2 / c 2 \u2212 \u2212 \u2212 \u2212 \u2212 \u2212 \u2212 \u2212 \u221a divided by c . So we might think to replace the left-hand side of Eq. (26.24) by d p \u03bc /dt . Then we need only find a fourth component to go with F . This fourth component must be related to the rate-of-change of the energy, or the rate of doing work, which is F\u22c5v . We would then like to write the right-hand side of Eq. (26.24) as a four-vector like (F\u22c5v/c, F x , F y , F z ) . But this does not make a four-vector. The time derivative of a four-vector is no longer a four-vector, because the d/dt requires the choice of some special frame for measuring t . We got into that trouble before when we tried to make v into a four-vector. Our first guess was that the time component would be cdt/dt=c . But the quantities (c, dx dt , dy dt , dz dt )=(c,v) (26.25) are not the components of a four-vector. We found that they could be made into one by multiplying each component by 1/ 1\u2212 v 2 / c 2 \u2212 \u2212 \u2212 \u2212 \u2212 \u2212 \u2212 \u2212 \u221a . The \u201cfour-velocity\u201d u \u03bc is the four-vector u \u03bc =( c 1\u2212 v 2 / c 2 \u2212 \u2212 \u2212 \u2212 \u2212 \u2212 \u2212 \u2212 \u221a , v 1\u2212 v 2 / c 2 \u2212 \u2212 \u2212 \u2212 \u2212 \u2212 \u2212 \u2212 \u221a ). (26.26) So it appears that the trick is to multiply d/dt by 1/ 1\u2212 v 2 / c 2 \u2212 \u2212 \u2212 \u2212 \u2212 \u2212 \u2212 \u2212 \u221a , if we want the derivatives to make a four-vector. Our second guess then is that 1 1\u2212 v 2 / c 2 \u2212 \u2212 \u2212 \u2212 \u2212 \u2212 \u2212 \u2212 \u221a d dt ( p \u03bc ) (26.27) should be a four-vector. But what is v ? It is the velocity of the particle\u2014not of a coordinate frame! Then the quantity f \u03bc defined by f \u03bc =( F\u22c5v/c 1\u2212 v 2 / c 2 \u2212 \u2212 \u2212 \u2212 \u2212 \u2212 \u2212 \u2212 \u221a , F 1\u2212 v 2 / c 2 \u2212 \u2212 \u2212 \u2212 \u2212 \u2212 \u2212 \u2212 \u221a ) (26.28) is the extension into four dimensions of a force\u2014we can call it the \u201cfour-force.\u201d It is indeed a four-vector, and its space components are not the components of F but of F/ 1\u2212 v 2 / c 2 \u2212 \u2212 \u2212 \u2212 \u2212 \u2212 \u2212 \u2212 \u221a . The question is\u2014why is f \u03bc a four-vector? It would be nice to get a little understanding of that 1/ 1\u2212 v 2 / c 2 \u2212 \u2212 \u2212 \u2212 \u2212 \u2212 \u2212 \u2212 \u221a factor. Since it has come up twice now, it is time to see why the d/dt can always be fixed by the same factor. The answer is in the following: When we take the time derivative of some function x , we compute the increment \u0394x in a small interval \u0394t in the variable t . But in another frame, the interval \u0394t might correspond to a change in both t \u2032 and x \u2032 , so if we vary only t \u2032 , the change in x will be different. We have to find a variable for our differentiation that is a measure of an \u201cinterval\u201d in space-time, which will then be the same in all coordinate systems. When we take \u0394x for that interval, it will be the same for all coordinate frames. When a particle \u201cmoves\u201d in four-space, there are the changes \u0394t , \u0394x , \u0394y , \u0394z . Can we make an invariant interval out of them? Well, they are the components of the four-vector x \u03bc =(ct,x,y,z) so if we define a quantity \u0394s by (\u0394s ) 2 = 1 c 2 \u0394 x \u03bc \u0394 x \u03bc = 1 c 2 ( c 2 \u0394 t 2 \u2212\u0394 x 2 \u2212\u0394 y 2 \u2212\u0394 z 2 ) (26.29) \u2014which is a four-dimensional dot product\u2014we then have a good four-scalar to use as a measure of a four-dimensional interval. From \u0394s \u2014or its limit ds \u2014we can define a parameter s=\u222bds . And a derivative with respect to s , d/ds , is a nice four-dimensional operation, because it is invariant with respect to a Lorentz transformation. It is easy to relate ds to dt for a moving particle. For a moving point particle, dx= v x dt,dy= v y dt,dz= v z dt, (26.30) and ds = (d t 2 / c 2 )( c 2 \u2212 v 2 x \u2212 v 2 y \u2212 v 2 z ) \u2212 \u2212 \u2212 \u2212 \u2212 \u2212 \u2212 \u2212 \u2212 \u2212 \u2212 \u2212 \u2212 \u2212 \u2212 \u2212 \u2212 \u2212 \u2212 \u2212 \u2212 \u221a =dt 1\u2212 v 2 / c 2 \u2212 \u2212 \u2212 \u2212 \u2212 \u2212 \u2212 \u2212 \u221a . (26.31) So the operator 1 1\u2212 v 2 / c 2 \u2212 \u2212 \u2212 \u2212 \u2212 \u2212 \u2212 \u2212 \u221a d dt d is an invariant operator. If we operate on any four-vector with it, we get another four-vector. For instance, if we operate on (ct,x,y,z) , we get the four-velocity u \u03bc : d x \u03bc ds = u \u03bc . d We see now why the factor 1\u2212 v 2 / c 2 \u2212 \u2212 \u2212 \u2212 \u2212 \u2212 \u2212 \u2212 \u221a fixes things up. The invariant variable s is a useful physical quantity. It is called the \u201cproper time\u201d along the path of a particle, because ds is always an interval of time in a frame that is moving with the particle at any particular instant. (Then, \u0394x= \u0394y= \u0394z= 0 , and \u0394s=\u0394t .) If you can imagine some \u201cclock\u201d whose rate doesn\u2019t depend on the acceleration, such a clock carried along with the particle would show the time s . We can now go back and write Newton\u2019s law (as corrected by Einstein) in the neat form d p \u03bc ds = f \u03bc , (26.32) where f \u03bc is given in Eq. (26.28). Also, the momentum p \u03bc can be written as p \u03bc = m 0 u \u03bc = m 0 d x \u03bc ds , (26.33) where the coordinates x \u03bc =(ct,x,y,z) now describe the trajectory of the particle. Finally, the four-dimensional notation gives us this very simple form of the equations of motion: f \u03bc = m 0 d 2 x \u03bc d s 2 , (26.34) which is reminiscent of F=ma . It is important to notice that Eq. (26.34) is not the same as F=ma , because the four-vector formula Eq. (26.34) has in it the relativistic mechanics which are different from Newton\u2019s law for high velocities. It is unlike the case of Maxwell\u2019s equations, where we were able to rewrite the equations in the relativistic form without any change in the meaning at all\u2014but with just a change of notation. Now let\u2019s return to Eq. (26.24) and see how we can write the right-hand side in four-vector notation. The three components\u2014when divided by 1\u2212 v 2 / c 2 \u2212 \u2212 \u2212 \u2212 \u2212 \u2212 \u2212 \u2212 \u221a \u2014are the components of f \u03bc , so f x = q(E+v\u00d7B ) x 1\u2212 v 2 / c 2 \u2212 \u2212 \u2212 \u2212 \u2212 \u2212 \u2212 \u2212 \u221a =q[ E x 1\u2212 v 2 / c 2 \u2212 \u2212 \u2212 \u2212 \u2212 \u2212 \u2212 \u2212 \u221a + v y B z 1\u2212 v 2 / c 2 \u2212 \u2212 \u2212 \u2212 \u2212 \u2212 \u2212 \u2212 \u221a \u2212 v z B y 1\u2212 v 2 / c 2 \u2212 \u2212 \u2212 \u2212 \u2212 \u2212 \u2212 \u2212 \u221a ]. (26.35) Now we must put all quantities in their relativistic notation. First, c/ 1\u2212 v 2 / c 2 \u2212 \u2212 \u2212 \u2212 \u2212 \u2212 \u2212 \u2212 \u221a and v y / 1\u2212 v 2 / c 2 \u2212 \u2212 \u2212 \u2212 \u2212 \u2212 \u2212 \u2212 \u221a and v z / 1\u2212 v 2 / c 2 \u2212 \u2212 \u2212 \u2212 \u2212 \u2212 \u2212 \u2212 \u221a are the t -, y -, and z -components of the four-velocity u \u03bc . And the components of E and B are components of the second-rank tensor of the fields F \u03bc\u03bd . Looking back in Table 26\u20131 for the components of F \u03bc\u03bd that correspond to E x , B z , and B y , we get3 f x =q( u t F xt \u2212 u y F xy \u2212 u z F xz ), f ( ) which begins to look interesting. Every term has the subscript x , which is reasonable, since we\u2019re finding an x -component. Then all the others appear in pairs: tt , yy , zz \u2014except that the xx -term is missing. So we just stick it in, and write f x =q( u t F xt \u2212 u x F xx \u2212 u y F xy \u2212 u z F xz ). (26.36) We haven\u2019t changed anything because F \u03bc\u03bd is antisymmetric, and F xx is zero. The reason for wanting to put in the xx -term is so that we can write Eq. (26.36) in the short-hand form f \u03bc =q u \u03bd F \u03bc\u03bd . (26.37) This equation is the same as Eq. (26.36) if we make the rule that whenever any subscript occurs twice (as \u03bd does here), you automatically sum over terms in the same way as for the scalar product, using the same convention for the signs. You can easily believe that (26.37) works equally well for \u03bc=y or \u03bc=z , but what about \u03bc=t ? Let\u2019s see, for fun, what it says: f t =q( u t F tt \u2212 u x F tx \u2212 u y F ty \u2212 u z F tz ). f ( ) Now we have to translate back to E \u2019s and B \u2019s. We get f t =q(0 + v x 1\u2212 v 2 / c 2 \u2212 \u2212 \u2212 \u2212 \u2212 \u2212 \u2212 \u2212 \u221a E x /c + v y 1\u2212 v 2 / c 2 \u2212 \u2212 \u2212 \u2212 \u2212 \u2212 \u2212 \u2212 \u221a E y /c + v z 1\u2212 v 2 / c 2 \u2212 \u2212 \u2212 \u2212 \u2212 \u2212 \u2212 \u2212 \u221a E z /c), (26.38) or f t = qv\u22c5E/c 1\u2212 v 2 / c 2 \u2212 \u2212 \u2212 \u2212 \u2212 \u2212 \u2212 \u2212 \u221a . E / But from Eq. (26.28), f t is supposed to be F\u22c5v/c 1\u2212 v 2 / c 2 \u2212 \u2212 \u2212 \u2212 \u2212 \u2212 \u2212 \u2212 \u221a = q(E+v\u00d7B)\u22c5v/c 1\u2212 v 2 / c 2 \u2212 \u2212 \u2212 \u2212 \u2212 \u2212 \u2212 \u2212 \u221a . / ( ) / This is the same thing as Eq. (26.38), since (v\u00d7B)\u22c5v is zero. So everything comes out all right. Summarizing, our equation of motion can be written in the elegant form m 0 d 2 x \u03bc d s 2 = f \u03bc =q u \u03bd F \u03bc\u03bd . (26.39) Although it is nice to see that the equations can be written that way, this form is not particularly useful. It\u2019s usually more convenient to solve for particle motions by using the original equations (26.24), and that\u2019s what we will usually do."
    },
    {
        "input": "Induced Currents",
        "output": "The discovery in 1820 that there was a close connection between electricity and magnetism was very exciting\u2014until then, the two subjects had been considered as quite independent. The first discovery was that currents in wires make magnetic fields; then, in the same year, it was found that wires carrying current in a magnetic field have forces on them. One of the excitements whenever there is a mechanical force is the possibility of using it in an engine to do work. Almost immediately after their discovery, people started to design electric motors using the forces on current-carrying wires. The principle of the electromagnetic motor is shown in bare outline in Fig. 16\u20131. A permanent magnet\u2014usually with some pieces of soft iron\u2014is used to produce a magnetic field in two slots. Across each slot there is a north and south pole, as shown. A rectangular coil of copper is placed with one side in each slot. When a current passes through the coil, it flows in opposite directions in the two slots, so the forces are also opposite, producing a torque on the coil about the axis shown. If the coil is mounted on a shaft so that it can turn, it can be coupled to pulleys or gears and can do work. The same idea can be used for making a sensitive instrument for electrical measurements. Thus the moment the force law was discovered the precision of electrical measurements was greatly increased. First, the torque of such a motor can be made much greater for a given current by making the current go around many turns instead of just one. Then the coil can be mounted so that it turns with very little torque\u2014either by supporting its shaft on very delicate jewel bearings or by hanging the coil on a very fine wire or a quartz fiber. Then an exceedingly small current will make the coil turn, and for small angles the amount of rotation will be proportional to the current. The rotation can be measured by gluing a pointer to the coil or, for the most delicate instruments, by attaching a small mirror to the coil and looking at the shift of the image of a scale. Such instruments are called galvanometers. Voltmeters and ammeters work on the same principle. The same ideas can be applied on a large scale to make large motors for providing mechanical power. The coil can be made to go around and around by arranging that the connections to the coil are reversed each half-turn by contacts mounted on the shaft. Then the torque is always in the same direction. Small dc motors are made just this way. Larger motors, dc or ac, are often made by replacing the permanent magnet by an electromagnet, energized from the electrical power source. With the realization that electric currents make magnetic fields, people immediately suggested that, somehow or other, magnets might also make electric fields. Various experiments were tried. For example, two wires were placed parallel to each other and a current was passed through one of them in the hope of finding a current in the other. The thought was that the magnetic field might in some way drag the electrons along in the second wire, giving some such law as \u201clikes prefer to move alike.\u201d With the largest available current and the most sensitive galvanometer to detect any current, the result was negative. Large magnets next to wires also produced no observed effects. Finally, Faraday discovered in 1840 the essential feature that had been missed\u2014that electric effects exist only when there is something changing. If one of a pair of wires has a changing current, a current is induced in the other, or if a magnet is moved near an electric circuit, there is a current. We say that currents are induced. This was the induction effect discovered by Faraday. It transformed the rather dull subject of static fields into a very exciting dynamic subject with an enormous range of wonderful phenomena. This chapter is devoted to a qualitative description of some of them. As we will see, one can quickly get into fairly complicated situations that are hard to analyze quantitatively in all their details. But never mind, our main purpose in this chapter is first to acquaint you with the phenomena involved. We will take up the detailed analysis later. We can easily understand one feature of magnetic induction from what we already know, although it was not known in Faraday\u2019s time. It comes from the v\u00d7B force on a moving charge that is proportional to its velocity in a magnetic field. Suppose that we have a wire which passes near a magnet, as shown in Fig. 16\u20132, and that we connect the ends of the wire to a galvanometer. If we move the wire across the end of the magnet the galvanometer pointer moves. The magnet produces some vertical magnetic field, and when we push the wire across the field, the electrons in the wire feel a sideways force\u2014at right angles to the field and to the motion. The force pushes the electrons along the wire. But why does this move the galvanometer, which is so far from the force? Because when the electrons which feel the magnetic force try to move, they push\u2014by electric repulsion\u2014the electrons a little farther down the wire; they, in turn, repel the electrons a little farther on, and so on for a long distance. An amazing thing. It was so amazing to Gauss and Weber\u2014who first built a galvanometer\u2014that they tried to see how far the forces in the wire would go. They strung a wire all the way across their city. Mr. Gauss, at one end, connected the wires to a battery (batteries were known before generators) and Mr. Weber watched the galvanometer move. They had a way of signaling long distances\u2014it was the beginning of the telegraph! Of course, this has nothing directly to do with induction\u2014it has to do with the way wires carry currents, whether the currents are pushed by induction or not. Now suppose in the setup of Fig. 16\u20132 we leave the wire alone and move the magnet. We still see an effect on the galvanometer. As Faraday discovered, moving the magnet under the wire\u2014one way\u2014has the same effect as moving the wire over the magnet\u2014the other way. But when the magnet is moved, we no longer have any v\u00d7B force on the electrons in the wire. This is the new effect that Faraday found. Today, we might hope to understand it from a relativity argument. We already understand that the magnetic field of a magnet comes from its internal currents. So we expect to observe the same effect if instead of a magnet in Fig. 16\u20132 we use a coil of wire in which there is a current. If we move the wire past the coil there will be a current through the galvanometer, or also if we move the coil past the wire. But there is now a more exciting thing: If we change the magnetic field of the coil not by moving it, but by changing its current, there is again an effect in the galvanometer. For example, if we have a loop of wire near a coil, as shown in Fig. 16\u20133, and if we keep both of them stationary but switch off the current, there is a pulse of current through the galvanometer. When we switch the coil on again, the galvanometer kicks in the other direction. Whenever the galvanometer in a situation such as the one shown in Fig. 16\u20132, or in Fig. 16\u20133, has a current, there is a net push on the electrons in the wire in one direction along the wire. There may be pushes in different directions at different places, but there is more push in one direction than another. What counts is the push integrated around the complete circuit. We call this net integrated push the electromotive force (abbreviated emf) in the circuit. More precisely, the emf is defined as the tangential force per unit charge in the wire integrated over length, once around the complete circuit. Faraday\u2019s complete discovery was that emf\u2019s can be generated in a wire in three different ways: by moving the wire, by moving a magnet near the wire, or by changing a current in a nearby wire. Let\u2019s consider the simple machine of Fig. 16\u20131 again, only now, instead of putting a current through the wire to make it turn, let\u2019s turn the loop by an external force, for example by hand or by a waterwheel. When the coil rotates, its wires are moving in the magnetic field and we will find an emf in the circuit of the coil. The motor becomes a generator. The coil of the generator has an induced emf from its motion. The amount of the emf is given by a simple rule discovered by Faraday. (We will just state the rule now and wait until later to examine it in detail.) The rule is that when the magnetic flux that passes through the loop (this flux is the normal component of B integrated over the area of the loop) is changing with time, the emf is equal to the rate of change of the flux. We will refer to this as \u201cthe flux rule.\u201d You see that when the coil of Fig. 16\u20131 is rotated, the flux through it changes. At the start some flux goes through one way; then when the coil has rotated 180 \u2218 the same flux goes through the other way. If we continuously rotate the coil the flux is first positive, then negative, then positive, and so on. The rate of change of the flux must alternate also. So there is an alternating emf in the coil. If we connect the two ends of the coil to outside wires through some sliding contacts\u2014called slip-rings\u2014(just so the wires won\u2019t get twisted) we have an alternating-current generator. Or we can also arrange, by means of some sliding contacts, that after every one-half rotation, the connection between the coil ends and the outside wires is reversed, so that when the emf reverses, so do the connections. Then the pulses of emf will always push currents in the same direction through the external circuit. We have what is called a direct-current generator. The machine of Fig. 16\u20131 is either a motor or a generator. The reciprocity between motors and generators is nicely shown by using two identical dc \u201cmotors\u201d of the permanent magnet kind, with their coils connected by two copper wires. When the shaft of one is turned mechanically, it becomes a generator and drives the other as a motor. If the shaft of the second is turned, it becomes the generator and drives the first as a motor. So here is an interesting example of a new kind of equivalence of nature: motor and generator are equivalent. The quantitative equivalence is, in fact, not completely accidental. It is related to the law of conservation of energy. Another example of a device that can operate either to generate emf\u2019s or to respond to emf\u2019s is the receiver of a standard telephone\u2014that is, an \u201cearphone.\u201d The original telephone of Bell consisted of two such \u201cearphones\u201d connected by two long wires. The basic principle is shown in Fig. 16\u20134. A permanent magnet produces a magnetic field in two \u201cyokes\u201d of soft iron and in a thin diaphragm that is moved by sound pressure. When the diaphragm moves, it changes the amount of magnetic field in the yokes. Therefore a coil of wire wound around one of the yokes will have the flux through it changed when a sound wave hits the diaphragm. So there is an emf in the coil. If the ends of the coil are connected to a circuit, a current which is an electrical representation of the sound is set up. If the ends of the coil of Fig. 16\u20134 are connected by two wires to another identical gadget, varying currents will flow in the second coil. These currents will produce a varying magnetic field and will make a varying attraction on the iron diaphragm. The diaphragm will wiggle and make sound waves approximately similar to the ones that moved the original diaphragm. With a few bits of iron and copper the human voice is transmitted over wires! (The modern home telephone uses a receiver like the one described but uses an improved invention to get a more powerful transmitter. It is the \u201ccarbon-button microphone,\u201d that uses sound pressure to vary the electric current from a battery.) One of the most interesting features of Faraday\u2019s discoveries is not that an emf exists in a moving coil\u2014which we can understand in terms of the magnetic force qv\u00d7B \u2014but that a changing current in one coil makes an emf in a second coil. And quite surprisingly the amount of emf induced in the second coil is given by the same \u201cflux rule\u201d: that the emf is equal to the rate of change of the magnetic flux through the coil. Suppose that we take two coils, each wound around separate bundles of iron sheets (these help to make stronger magnetic fields), as shown in Fig. 16\u20135. Now we connect one of the coils\u2014coil (a)\u2014to an alternating-current generator. The continually changing current produces a continuously varying magnetic field. This varying field generates an alternating emf in the second coil\u2014coil (b). This emf can, for example, produce enough power to light an electric bulb. The emf alternates in coil (b) at a frequency which is, of course, the same as the frequency of the original generator. But the current in coil (b) can be larger or smaller than the current in coil (a). The current in coil (b) depends on the emf induced in it and on the resistance and inductance of the rest of its circuit. The emf can be less than that of the generator if, say, there is little flux change. Or the emf in coil (b) can be made much larger than that in the generator by winding coil (b) with many turns, since in a given magnetic field the flux through the coil is then greater. (Or if you prefer to look at it another way, the emf is the same in each turn, and since the total emf is the sum of the emf\u2019s of the separate turns, many turns in series produce a large emf.) Such a combination of two coils\u2014usually with an arrangement of iron sheets to guide the magnetic fields\u2014is called a transformer. It can \u201ctransform\u201d one emf (also called a \u201cvoltage\u201d) to another. There are also induction effects in a single coil. For instance, in the setup in Fig. 16\u20135 there is a changing flux not only through coil (b), which lights the bulb, but also through coil (a). The varying current in coil (a) produces a varying magnetic field inside itself and the flux of this field is continually changing, so there is a self-induced emf in coil (a). There is an emf acting on any current when it is building up a magnetic field\u2014or, in general, when its field is changing in any way. The effect is called self-inductance. When we gave \u201cthe flux rule\u201d that the emf is equal to the rate of change of the flux linkage, we didn\u2019t specify the direction of the emf. There is a simple rule, called Lenz\u2019s rule, for figuring out which way the emf goes: the emf tries to oppose any flux change. That is, the direction of an induced emf is always such that if a current were to flow in the direction of the emf, it would produce a flux of B that opposes the change in B that produces the emf. Lenz\u2019s rule can be used to find the direction of the emf in the generator of Fig. 16\u20131, or in the transformer winding of Fig. 16\u20133. In particular, if there is a changing current in a single coil (or in any wire) there is a \u201cback\u201d emf in the circuit. This emf acts on the charges flowing in coil (a) of Fig. 16\u20135 to oppose the change in magnetic field, and so in the direction to oppose the change in current. It tries to keep the current constant; it is opposite to the current when the current is increasing, and it is in the direction of the current when it is decreasing. A current in a self-inductance has \u201cinertia,\u201d because the inductive effects try to keep the flow constant, just as mechanical inertia tries to keep the velocity of an object constant. Any large electromagnet will have a large self-inductance. Suppose that a battery is connected to the coil of a large electromagnet, as in Fig. 16\u20136, and that a strong magnetic field has been built up. (The current reaches a steady value determined by the battery voltage and the resistance of the wire in the coil.) But now suppose that we try to disconnect the battery by opening the switch. If we really opened the circuit, the current would go to zero rapidly, and in doing so it would generate an enormous emf. In most cases this emf would be large enough to develop an arc across the opening contacts of the switch. The high voltage that appears might also damage the insulation of the coil\u2014or you, if you are the person who opens the switch! For these reasons, electromagnets are usually connected in a circuit like the one shown in Fig. 16\u20136. When the switch is opened, the current does not change rapidly but remains steady, flowing instead through the lamp, being driven by the emf from the self-inductance of the coil. You have probably seen the dramatic demonstration of Lenz\u2019s rule made with the gadget shown in Fig. 16\u20137. It is an electromagnet, just like coil (a) of Fig. 16\u20135. An aluminum ring is placed on the end of the magnet. When the coil is connected to an alternating-current generator by closing the switch, the ring flies into the air. The force comes, of course, from the induced currents in the ring. The fact that the ring flies away shows that the currents in it oppose the change of the field through it. When the magnet is making a north pole at its top, the induced current in the ring is making a downward-pointing north pole. The ring and the coil are repelled just like two magnets with like poles opposite. If a thin radial cut is made in the ring the force disappears, showing that it does indeed come from the currents in the ring. If, instead of the ring, we place a disc of aluminum or copper across the end of the electromagnet of Fig. 16\u20137, it is also repelled; induced currents circulate in the material of the disc, and again produce a repulsion. An interesting effect, similar in origin, occurs with a sheet of a perfect conductor. In a \u201cperfect conductor\u201d there is no resistance whatever to the current. So if currents are generated in it, they can keep going forever. In fact, the slightest emf would generate an arbitrarily large current\u2014which really means that there can be no emf\u2019s at all. Any attempt to make a magnetic flux go through such a sheet generates currents that create opposite B fields\u2014all with infinitesimal emf\u2019s, so with no flux entering. If we have a sheet of a perfect conductor and put an electromagnet next to it, when we turn on the current in the magnet, currents called eddy currents appear in the sheet, so that no magnetic flux enters. The field lines would look as shown in Fig. 16\u20138. The same thing happens, of course, if we bring a bar magnet near a perfect conductor. Since the eddy currents are creating opposing fields, the magnets are repelled from the conductor. This makes it possible to suspend a bar magnet in air above a sheet of perfect conductor shaped like a dish, as shown in Fig. 16\u20139. The magnet is suspended by the repulsion of the induced eddy currents in the perfect conductor. There are no perfect conductors at ordinary temperatures, but some materials become perfect conductors at low enough temperatures. For instance, below 3.8 \u2218 K tin conducts perfectly. It is called a superconductor. If the conductor in Fig. 16\u20138 is not quite perfect there will be some resistance to flow of the eddy currents. The currents will tend to die out and the magnet will slowly settle down. The eddy currents in an imperfect conductor need an emf to keep them going, and to have an emf the flux must keep changing. The flux of the magnetic field gradually penetrates the conductor. In a normal conductor, there are not only repulsive forces from eddy currents, but there can also be sidewise forces. For instance, if we move a magnet sideways along a conducting surface the eddy currents produce a force of drag, because the induced currents are opposing the changing of the location of flux. Such forces are proportional to the velocity and are like a kind of viscous force. These effects show up nicely in the apparatus shown in Fig. 16\u201310. A square sheet of copper is suspended on the end of a rod to make a pendulum. The copper swings back and forth between the poles of an electromagnet. When the magnet is turned on, the pendulum motion is suddenly arrested. As the metal plate enters the gap of the magnet, there is a current induced in the plate which acts to oppose the change in flux through the plate. If the sheet were a perfect conductor, the currents would be so great that they would push the plate out again\u2014it would bounce back. With a copper plate there is some resistance in the plate, so the currents at first bring the plate almost to a dead stop as it starts to enter the field. Then, as the currents die down, the plate slowly settles to rest in the magnetic field. The nature of the eddy currents in the copper pendulum is shown in Fig. 16\u201311. The strength and geometry of the currents are quite sensitive to the shape of the plate. If, for instance, the copper plate is replaced by one which has several narrow slots cut in it, as shown in Fig. 16\u201312, the eddy-current effects are drastically reduced. The pendulum swings through the magnetic field with only a small retarding force. The reason is that the currents in each section of the copper have less flux to drive them, so the effects of the resistance of each loop are greater. The currents are smaller and the drag is less. The viscous character of the force is seen even more clearly if a sheet of copper is placed between the poles of the magnet of Fig. 16\u201310 and then released. It doesn\u2019t fall; it just sinks slowly downward. The eddy currents exert a strong resistance to the motion\u2014just like the viscous drag in honey. If, instead of dragging a conductor past a magnet, we try to rotate it in a magnetic field, there will be a resistive torque from the same effects. Alternatively, if we rotate a magnet\u2014end over end\u2014near a conducting plate or ring, the ring is dragged around; currents in the ring will create a torque that tends to rotate the ring with the magnet. A field just like that of a rotating magnet can be made with an arrangement of coils such as is shown in Fig. 16\u201313. We take a torus of iron (that is, a ring of iron like a doughnut) and wind six coils on it. If we put a current, as shown in part (a), through windings (1) and (4), there will be a magnetic field in the direction shown in the figure. If we now switch the current to windings (2) and (5), the magnetic field will be in a new direction, as shown in part (b) of the figure. Continuing the process, we get the sequence of fields shown in the rest of the figure. If the process is done smoothly, we have a \u201crotating\u201d magnetic field. We can easily get the required sequence of currents by connecting the coils to a three-phase power line, which provides just such a sequence of currents. \u201cThree-phase power\u201d is made in a generator using the principle of Fig. 16\u20131, except that there are three loops fastened together on the same shaft in a symmetrical way\u2014that is, with an angle of 120 \u2218 from one loop to the next. When the coils are rotated as a unit, the emf is a maximum in one, then in the next, and so on in a regular sequence. There are many practical advantages of three-phase power. One of them is the possibility of making a rotating magnetic field. The torque produced on a conductor by such a rotating field is easily shown by standing a metal ring on an insulating table just above the torus, as shown in Fig. 16\u201314. The rotating field causes the ring to spin about a vertical axis. The basic elements seen here are quite the same as those at play in a large commercial three-phase induction motor. Another form of induction motor is shown in Fig. 16\u201315. The arrangement shown is not suitable for a practical high-efficiency motor but will illustrate the principle. The electromagnet M , consisting of a bundle of laminated iron sheets wound with a solenoidal coil, is powered with alternating current from a generator. The magnet produces a varying flux of B through the aluminum disc. If we have just these two components, as shown in part (a) of the figure, we do not yet have a motor. There are eddy currents in the disc, but they are symmetric and there is no torque. (There will be some heating of the disc due to the induced currents.) If we now cover only one-half of the magnet pole with an aluminum plate, as shown in part (b) of the figure, the disc begins to rotate, and we have a motor. The operation depends on two eddy-current effects. First, the eddy currents in the aluminum plate oppose the change of flux through it, so the magnetic field above the plate always lags the field above that half of the pole which is not covered. This so-called \u201cshaded-pole\u201d effect produces a field which in the \u201cshaded\u201d region varies much like that in the \u201cunshaded\u201d region except that it is delayed a constant amount in time. The whole effect is as if there were a magnet only half as wide which is continually being moved from the unshaded region toward the shaded one. Then the varying fields interact with the eddy currents in the disc to produce the torque on it. When Faraday first made public his remarkable discovery that a changing magnetic flux produces an emf, he was asked (as anyone is asked when he discovers a new fact of nature), \u201cWhat is the use of it?\u201d All he had found was the oddity that a tiny current was produced when he moved a wire near a magnet. Of what possible \u201cuse\u201d could that be? His answer was: \u201cWhat is the use of a newborn baby?\u201d Yet think of the tremendous practical applications his discovery has led to. What we have been describing are not just toys but examples chosen in most cases to represent the principle of some practical machine. For instance, the rotating ring in the turning field is an induction motor. There are, of course, some differences between it and a practical induction motor. The ring has a very small torque; it can be stopped with your hand. For a good motor, things have to be put together more intimately: there shouldn\u2019t be so much \u201cwasted\u201d magnetic field out in the air. First, the field is concentrated by using iron. We have not discussed how iron does that, but iron can make the magnetic field tens of thousands of times stronger than copper coils alone could do. Second, the gaps between the pieces of iron are made small; to do that, some iron is even built into the rotating ring. Everything is arranged so as to get the greatest forces and the greatest efficiency\u2014that is, conversion of electrical power to mechanical power\u2014until the \u201cring\u201d can no longer be held still by your hand. This problem of closing the gaps and making the thing work in the most practical way is engineering. It requires serious study of design problems, although there are no new basic principles from which the forces are obtained. But there is a long way to go from the basic principles to a practical and economic design. Yet it is just such careful engineering design that has made possible such a tremendous thing as Boulder Dam and all that goes with it. What is Boulder Dam? A huge river is stopped by a concrete wall. But what a wall it is! Shaped with a perfect curve that is very carefully worked out so that the least possible amount of concrete will hold back a whole river. It thickens at the bottom in that wonderful shape that the artists like but that the engineers can appreciate because they know that such thickening is related to the increase of pressure with the depth of the water. But we are getting away from electricity. Then the water of the river is diverted into a huge pipe. That\u2019s a nice engineering accomplishment in itself. The pipe feeds the water into a \u201cwaterwheel\u201d\u2014a huge turbine\u2014and makes wheels turn. (Another engineering feat.) But why turn wheels? They are coupled to an exquisitely intricate mess of copper and iron, all twisted and interwoven. With two parts\u2014one that turns and one that doesn\u2019t. All a complex intermixture of a few materials, mostly iron and copper but also some paper and shellac for insulation. A revolving monster thing. A generator. Somewhere out of the mess of copper and iron come a few special pieces of copper. The dam, the turbine, the iron, the copper, all put there to make something special happen to a few bars of copper\u2014an emf. Then the copper bars go a little way and circle for several times around another piece of iron in a transformer; then their job is done. But around that same piece of iron curls another cable of copper which has no direct connection whatsoever to the bars from the generator; they have just been influenced because they passed near it\u2014to get their emf. The transformer converts the power from the relatively low voltages required for the efficient design of the generator to the very high voltages that are best for efficient transmission of electrical energy over long cables. And everything must be enormously efficient\u2014there can be no waste, no loss. Why? The power for a metropolis is going through. If a small fraction were lost\u2014one or two percent\u2014think of the energy left behind! If one percent of the power were left in the transformer, that energy would need to be taken out somehow. If it appeared as heat, it would quickly melt the whole thing. There is, of course, some small inefficiency, but all that is required are a few pumps which circulate some oil through a radiator to keep the transformer from heating up. Out of the Boulder Dam come a few dozen rods of copper\u2014long, long, long rods of copper perhaps the thickness of your wrist that go for hundreds of miles in all directions. Small rods of copper carrying the power of a giant river. Then the rods are split to make more rods \u2026 then to more transformers \u2026 sometimes to great generators which recreate the current in another form \u2026 sometimes to engines turning for big industrial purposes \u2026 to more transformers \u2026 then more splitting and spreading \u2026 until finally the river is spread throughout the whole city\u2014turning motors, making heat, making light, working gadgetry. The miracle of hot lights from cold water over 600 miles away\u2014all done with specially arranged pieces of copper and iron. Large motors for rolling steel, or tiny motors for a dentist\u2019s drill. Thousands of little wheels, turning in response to the turning of the big wheel at Boulder Dam. Stop the big wheel, and all the wheels stop; the lights go out. They really are connected. Yet there is more. The same phenomena that take the tremendous power of the river and spread it through the countryside, until a few drops of the river are running the dentist\u2019s drill, come again into the building of extremely fine instruments \u2026 for the detection of incredibly small amounts of current \u2026 for the transmission of voices, music, and pictures \u2026 for computers \u2026 for automatic machines of fantastic precision. All this is possible because of carefully designed arrangements of copper and iron\u2014efficiently created magnetic fields \u2026 blocks of rotating iron six feet in diameter whirling with clearances of 1/16 of an inch \u2026 careful proportions of copper for the optimum efficiency \u2026 strange shapes all serving a purpose, like the curve of the dam. If some future archaeologist uncovers Boulder Dam, we may guess that he would admire the beauty of its curves. But also the explorers from some great future civilizations will look at the generators and transformers and say: \u201cNotice that every iron piece has a beautifully efficient shape. Think of the thought that has gone into every piece of copper!\u201d This is the power of engineering and the careful design of our electrical technology. There has been created in the generator something which exists nowhere else in nature. It is true that there are forces of induction in other places. Certainly in some places around the sun and stars there are effects of electromagnetic induction. Perhaps also (though it\u2019s not certain) the magnetic field of the earth is maintained by an analog of an electric generator that operates on circulating currents in the interior of the earth. But nowhere have there been pieces put together with moving parts to generate electrical power as is done in the generator\u2014with great efficiency and regularity. You may think that designing electric generators is no longer an interesting subject, that it is a dead subject because they are all designed. Almost perfect generators or motors can be taken from a shelf. Even if this were true, we can admire the wonderful accomplishment of a problem solved to near perfection. But there remain as many unfinished problems. Even generators and transformers are returning as problems. It is likely that the whole field of low temperatures and superconductors will soon be applied to the problem of electric power distribution. With a radically new factor in the problem, new optimum designs will have to be created. Power networks of the future may have little resemblance to those of today. You can see that there is an endless number of applications and problems that one could take up while studying the laws of induction. The study of the design of electrical machinery is a life work in itself. We cannot go very far in that direction, but we should be aware of the fact that when we have discovered the law of induction, we have suddenly connected our theory to an enormous practical development. We must, however, leave that subject to the engineers and applied scientists who are interested in working out the details of particular applications. Physics only supplies the base\u2014the basic principles that apply, no matter what. (We have not yet completed the base, because we have yet to consider in detail the properties of iron and of copper. Physics has something to say about these as we will see a little later!) Modern electrical technology began with Faraday\u2019s discoveries. The useless baby developed into a prodigy and changed the face of the earth in ways its proud father could never have imagined."
    },
    {
        "input": "The Principles of Statistical Mechanics",
        "output": "We have discussed some of the properties of large numbers of intercolliding atoms. The subject is called kinetic theory, a description of matter from the point of view of collisions between the atoms. Fundamentally, we assert that the gross properties of matter should be explainable in terms of the motion of its parts. We limit ourselves for the present to conditions of thermal equilibrium, that is, to a subclass of all the phenomena of nature. The laws of mechanics which apply just to thermal equilibrium are called statistical mechanics, and in this section we want to become acquainted with some of the central theorems of this subject. We already have one of the theorems of statistical mechanics, namely, the mean value of the kinetic energy for any motion at the absolute temperature T is 1 2 kT for each independent motion, i.e., for each degree of freedom. That tells us something about the mean square velocities of the atoms. Our objective now is to learn more about the positions of the atoms, to discover how many of them are going to be in different places at thermal equilibrium, and also to go into a little more detail on the distribution of the velocities. Although we have the mean square velocity, we do not know how to answer a question such as how many of them are going three times faster than the root mean square, or how many of them are going one-quarter of the root mean square speed. Or have they all the same speed exactly? So, these are the two questions that we shall try to answer: How are the molecules distributed in space when there are forces acting on them, and how are they distributed in velocity? It turns out that the two questions are completely independent, and that the distribution of velocities is always the same. We already received a hint of the latter fact when we found that the average kinetic energy is the same, 1 2 kT per degree of freedom, no matter what forces are acting on the molecules. The distribution of the velocities of the molecules is independent of the forces, because the collision rates do not depend upon the forces. Let us begin with an example: the distribution of the molecules in an atmosphere like our own, but without the winds and other kinds of disturbance. Suppose that we have a column of gas extending to a great height, and at thermal equilibrium\u2014unlike our atmosphere, which as we know gets colder as we go up. We could remark that if the temperature differed at different heights, we could demonstrate lack of equilibrium by connecting a rod to some balls at the bottom (Fig. 40\u20131), where they would pick up 1 2 kT from the molecules there and would shake, via the rod, the balls at the top and those would shake the molecules at the top. So, ultimately, of course, the temperature becomes the same at all heights in a gravitational field. If the temperature is the same at all heights, the problem is to discover by what law the atmosphere becomes tenuous as we go up. If N is the total number of molecules in a volume V of gas at pressure P , then we know PV=NkT , or P=nkT , where n=N/V is the number of molecules per unit volume. In other words, if we know the number of molecules per unit volume, we know the pressure, and vice versa: they are proportional to each other, since the temperature is constant in this problem. But the pressure is not constant, it must increase as the altitude is reduced, because it has to hold, so to speak, the weight of all the gas above it. That is the clue by which we may determine how the pressure changes with height. If we take a unit area at height h , then the vertical force from below, on this unit area, is the pressure P . The vertical force per unit area pushing down at a height h+dh would be the same, in the absence of gravity, but here it is not, because the force from below must exceed the force from above by the weight of gas in the section between h and h+dh . Now mg is the force of gravity on each molecule, where g is the acceleration due to gravity, and ndh is the total number of molecules in the unit section. So this gives us the differential equation Ph+dh\u2212Ph= dP= \u2212mgndh . Since P=nkT , and T is constant, we can eliminate either P or n , say P , and get dn dh =\u2212 mg kT n for the differential equation, which tells us how the density goes down as we go up in energy. We thus have an equation for the particle density n , which varies with height, but which has a derivative which is proportional to itself. Now a function which has a derivative proportional to itself is an exponential, and the solution of this differential equation is n=n0e\u2212mgh/kT. Here the constant of integration, n0 , is obviously the density at h=0 (which can be chosen anywhere), and the density goes down exponentially with height. Note that if we have different kinds of molecules with different masses, they go down with different exponentials. The ones which were heavier would decrease with altitude faster than the light ones. Therefore we would expect that because oxygen is heavier than nitrogen, as we go higher and higher in an atmosphere with nitrogen and oxygen the proportion of nitrogen would increase. This does not really happen in our own atmosphere, at least at reasonable heights, because there is so much agitation which mixes the gases back together again. It is not an isothermal atmosphere. Nevertheless, there is a tendency for lighter materials, like hydrogen, to dominate at very great heights in the atmosphere, because the lowest masses continue to exist, while the other exponentials have all died out (Fig. 40\u20132). Here we note the interesting fact that the numerator in the exponent of Eq. (40.1) is the potential energy of an atom. Therefore we can also state this particular law as: the density at any point is proportional to e\u2212the potential energy of each atom/kT. That may be an accident, i.e., may be true only for this particular case of a uniform gravitational field. However, we can show that it is a more general proposition. Suppose that there were some kind of force other than gravity acting on the molecules in a gas. For example, the molecules may be charged electrically, and may be acted on by an electric field or another charge that attracts them. Or, because of the mutual attractions of the atoms for each other, or for the wall, or for a solid, or something, there is some force of attraction which varies with position and which acts on all the molecules. Now suppose, for simplicity, that the molecules are all the same, and that the force acts on each individual one, so that the total force on a piece of gas would be simply the number of molecules times the force on each one. To avoid unnecessary complication, let us choose a coordinate system with the x -axis in the direction of the force, F . In the same manner as before, if we take two parallel planes in the gas, separated by a distance dx , then the force on each atom, times the n atoms per cm\u00b3 (the generalization of the previous nmg ), times dx , must be balanced by the pressure change: Fndx=dP=kTdn . Or, to put this law in a form which will be useful to us later, F=kT d dx (lnn). For the present, observe that \u2212Fdx is the work we would do in taking a molecule from x to x+dx , and if F comes from a potential, i.e., if the work done can be represented by a potential energy at all, then this would also be the difference in the potential energy (P.E.). The negative differential of potential energy is the work done, Fdx , and we find that d(lnn)=\u2212d(P.E.)/kT , or, after integrating, n=(constant)e\u2212P.E./kT. Therefore what we noticed in a special case turns out to be true in general. (What if F does not come from a potential? Then (40.2) has no solution at all. Energy can be generated, or lost by the atoms running around in cyclic paths for which the work done is not zero, and no equilibrium can be maintained at all. Thermal equilibrium cannot exist if the external forces on the atoms are not conservative.) Equation (40.3), known as Boltzmann\u2019s law, is another of the principles of statistical mechanics: that the probability of finding molecules in a given spatial arrangement varies exponentially with the negative of the potential energy of that arrangement, divided by kT . This, then, could tell us the distribution of molecules: Suppose that we had a positive ion in a liquid, attracting negative ions around it, how many of them would be at different distances? If the potential energy is known as a function of distance, then the proportion of them at different distances is given by this law, and so on, through many applications. In more advanced statistical mechanics one tries to solve the following important problem. Consider an assembly of molecules which attract each other, and suppose that the force between any two, say i and j , depends only on their separation r ij , and can be represented as the derivative of a potential function V( r ij ) . Figure 40\u20133 shows a form such a function might have. For r> r 0 , the energy decreases as the molecules come together, because they attract, and then the energy increases very sharply as they come still closer together, because they repel strongly, which is characteristic of the way molecules behave, roughly speaking. Now suppose we have a whole box full of such molecules, and we would like to know how they arrange themselves on the average. The answer is e \u2212P.E./kT . The total potential energy in this case would be the sum over all the pairs, supposing that the forces are all in pairs (there may be three-body forces in more complicated things, but in electricity, for example, the potential energy is all in pairs). Then the probability for finding molecules in any particular combination of r ij \u2019s will be proportional to exp[\u2212 \u2211 i,j V( r ij )/kT]. Now, if the temperature is very high, so that kT\u226b|V( r 0 )| , the exponent is relatively small almost everywhere, and the probability of finding a molecule is almost independent of position. Let us take the case of just two molecules: the e \u2212P.E./kT would be the probability of finding them at various mutual distances r . Clearly, where the potential goes most negative, the probability is largest, and where the potential goes toward infinity, the probability is almost zero, which occurs for very small distances. That means that for such atoms in a gas, there is no chance that they are on top of each other, since they repel so strongly. But there is a greater chance of finding them per unit volume at the point r 0 than at any other point. How much greater, depends on the temperature. If the temperature is very large compared with the difference in energy between r= r 0 and r=\u221e , the exponential is always nearly unity. In this case, where the mean kinetic energy (about kT ) greatly exceeds the potential energy, the forces do not make much difference. But as the temperature falls, the probability of finding the molecules at the preferred distance r 0 gradually increases relative to the probability of finding them elsewhere and, in fact, if kT is much less than |V( r 0 )| , we have a relatively large positive exponent in that neighborhood. In other words, in a given volume they are much more likely to be at the distance of minimum energy than far apart. As the temperature falls, the atoms fall together, clump in lumps, and reduce to liquids, and solids, and molecules, and as you heat them up they evaporate. The requirements for the determination of exactly how things evaporate, exactly how things should happen in a given circumstance, involve the following. First, to discover the correct molecular-force law V(r) , which must come from something else, quantum mechanics, say, or experiment. But, given the law of force between the molecules, to discover what a billion molecules are going to do merely consists of studying the function e \u2212\u2211 V ij /kT . Surprisingly enough, since it is such a simple function and such an easy idea, given the potential, the labor is enormously complicated; the difficulty is the tremendous number of variables. In spite of such difficulties, the subject is quite exciting and interesting. It is often called an example of a \u201cmany-body problem,\u201d and it really has been a very interesting thing. In that single formula must be contained all the details, for example, about the solidification of gas, or the forms of the crystals that the solid can take, and people have been trying to squeeze it out, but the mathematical difficulties are very great, not in writing the law, but in dealing with so enormous a number of variables. That then, is the distribution of particles in space. That is the end of classical statistical mechanics, practically speaking, because if we know the forces, we can, in principle, find the distribution in space, and the distribution of velocities is something that we can work out once and for all, and is not something that is different for the different cases. The great problems are in getting particular information out of our formal solution, and that is the main subject of classical statistical mechanics. Now we go on to discuss the distribution of velocities, because sometimes it is interesting or useful to know how many of them are moving at different speeds. In order to do that, we may make use of the facts which we discovered with regard to the gas in the atmosphere. We take it to be a perfect gas, as we have already assumed in writing the potential energy, disregarding the energy of mutual attraction of the atoms. The only potential energy that we included in our first example was gravity. We would, of course, have something more complicated if there were forces between the atoms. Thus we assume that there are no forces between the atoms and, for a moment, disregard collisions also, returning later to the justification of this. Now we saw that there are fewer molecules at the height h than there are at the height 0 ; according to formula (40.1), they decrease exponentially with height. How can there be fewer at greater heights? After all, do not all the molecules which are moving up at height 0 arrive at h ? No!, because some of those which are moving up at 0 are going too slowly, and cannot climb the potential hill to h . With that clue, we can calculate how many must be moving at various speeds, because from (40.1) we know how many are moving with less than enough speed to climb a given distance h . Those are just the ones that account for the fact that the density at h is lower than at 0 . Now let us put that idea a little more precisely: let us count how many molecules are passing from below to above the plane h=0 (by calling it height =0 , we do not mean that there is a floor there; it is just a convenient label, and there is gas at negative h ). These gas molecules are moving around in every direction, but some of them are moving through the plane, and at any moment a certain number per second of them are passing through the plane from below to above with different velocities. Now we note the following: if we call u the velocity which is just needed to get up to the height h (kinetic energy m u 2 /2=mgh ), then the number of molecules per second which are passing upward through the lower plane in a vertical direction with velocity component greater than u is exactly the same as the number which pass through the upper plane with any upward velocity. Those molecules whose vertical velocity does not exceed u cannot get through the upper plane. So therefore we see that ( Number passing h=0 with v z >u )=( number passing h=h with v z >0 ). ( ) ( ) But the number which pass through h with any velocity greater than 0 is less than the number which pass through the lower height with any velocity greater than 0 , because the number of atoms is greater; that is all we need. We know already that the distribution of velocities is the same, after the argument we made earlier about the temperature being constant all the way through the atmosphere. So, since the velocity distributions are the same, and it is just that there are more atoms lower down, clearly the number n >0 (h) , passing with positive velocity at height h , and the number n >0 (0) , passing with positive velocity at height 0 , are in the same ratio as the densities at the two heights, which is e \u2212mgh/kT . But n >0 (h)= n >u (0) , and therefore we find that n >u (0) n >0 (0) = e \u2212mgh/kT = e \u2212m u 2 /2kT , ( ) since 1 2 m u 2 =mgh . Thus, in words, the number of molecules per unit area per second passing the height 0 with a z -component of velocity greater than u is e \u2212m u 2 /2kT times the total number that are passing through the plane with velocity greater than zero. Now this is not only true at the arbitrarily chosen height 0 , but of course it is true at any other height, and thus the distributions of velocities are all the same! (The final statement does not involve the height h , which appeared only in the intermediate argument.) The result is a general proposition that gives us the distribution of velocities. It tells us that if we drill a little hole in the side of a gas pipe, a very tiny hole, so that the collisions are few and far between, i.e., are farther apart than the diameter of the hole, then the particles which are coming out will have different velocities, but the fraction of particles which come out at a velocity greater than u is e \u2212m u 2 /2kT . Now we return to the question about the neglect of collisions: Why does it not make any difference? We could have pursued the same argument, not with a finite height h , but with an infinitesimal height h , which is so small that there would be no room for collisions between 0 and h . But that was not necessary: the argument is evidently based on an analysis of the energies involved, the conservation of energy, and in the collisions that occur there is an exchange of energies among the molecules. However, we do not really care whether we follow the same molecule if energy is merely exchanged with another molecule. So it turns out that even if the problem is analyzed more carefully (and it is more difficult, naturally, to do a rigorous job), it still makes no difference in the result. It is interesting that the velocity distribution we have found is just n >u \u221d e \u2212kinetic energy/kT . (40.4) This way of describing the distribution of velocities, by giving the number of molecules that pass a given area with a certain minimum z -component, is not the most convenient way of giving the velocity distribution. For instance, inside the gas, one more often wants to know how many molecules are moving with a z -component of velocity between two given values, and that, of course, is not directly given by Eq. (40.4). We would like to state our result in the more conventional form, even though what we already have written is quite general. Note that it is not possible to say that any molecule has exactly some stated velocity; none of them has a velocity exactly equal to 1.7962899173 meters per second. So in order to make a meaningful statement, we have to ask how many are to be found in some range of velocities. We have to say how many have velocities between 1.796 and 1.797 , and so on. On mathematical terms, let f(u)du be the fraction of all the molecules which have velocities between u and u+du or, what is the same thing (if du is infinitesimal), all that have a velocity u with a range du . Figure 40\u20135 shows a possible form for the function f(u) , and the shaded part, of width du and mean height f(u) , represents this fraction f(u)du . That is, the ratio of the shaded area to the total area of the curve is the relative proportion of molecules with velocity u within du . If we define f(u) so that the fraction having a velocity in this range is given directly by the shaded area, then the total area must be 100 percent of them, that is, \u222b \u221e \u2212\u221e f(u)du=1. (40.5) Now we have only to get this distribution by comparing it with the theorem we derived before. First we ask, what is the number of molecules passing through an area per second with a velocity greater than u , expressed in terms of f(u) ? At first we might think it is merely the integral of \u222b \u221e u f(u)du , but it is not, because we want the number that are passing the area per second. The faster ones pass more often, so to speak, than the slower ones, and in order to express how many pass, you have to multiply by the velocity. (We discussed that in the previous chapter when we talked about the number of collisions.) In a given time t the total number which pass through the surface is all of those which have been able to arrive at the surface, and the number which arrive come from a distance ut . So the number of molecules which arrive is not simply the number which are there, but the number that are there per unit volume, multiplied by the distance that they sweep through in racing for the area through which they are supposed to go, and that distance is proportional to u . Thus we need the integral of u times f(u)du , an infinite integral with a lower limit u , and this must be the same as we found before, namely e \u2212m u 2 /2kT , with a proportionality constant which we will get later: \u222b \u221e u uf(u)du=const\u22c5 e \u2212m u 2 /2kT . (40.6) Now if we differentiate the integral with respect to u , we get the thing that is inside the integral, i.e., the integrand (with a minus sign, since u is the lower limit), and if we differentiate the other side, we get u times the same exponential (and some constants). The u \u2019s cancel and we find f(u)du=C e \u2212m u 2 /2kT du. (40.7) We retain the du on both sides as a reminder that it is a distribution, and it tells what the proportion is for velocity between u and u+du . The constant C must be so determined that the integral is unity, according to Eq. (40.5). Now we can prove1 that \u222b \u221e \u2212\u221e e \u2212 x 2 dx= \u03c0 \u2212 \u2212 \u221a . \u221e Using this fact, it is easy to find that C= m/2\u03c0kT \u2212 \u2212 \u2212 \u2212 \u2212 \u2212 \u2212 \u221a . Since velocity and momentum are proportional, we may say that the distribution of momenta is also proportional to e \u2212K.E./kT per unit momentum range. It turns out that this theorem is true in relativity too, if it is in terms of momentum, while if it is in velocity it is not, so it is best to learn it in momentum instead of in velocity: f(p)dp=C e \u2212K.E./kT dp. (40.8) So we find that the probabilities of different conditions of energy, kinetic and potential, are both given by e \u2212energy/kT , a very easy thing to remember and a rather beautiful proposition. So far we have, of course, only the distribution of the velocities \u201cvertically.\u201d We might want to ask, what is the probability that a molecule is moving in another direction? Of course these distributions are connected, and one can obtain the complete distribution from the one we have, because the complete distribution depends only on the square of the magnitude of the velocity, not upon the z -component. It must be something that is independent of direction, and there is only one function involved, the probability of different magnitudes. We have the distribution of the z -component, and therefore we can get the distribution of the other components from it. The result is that the probability is still proportional to e \u2212K.E./kT , but now the kinetic energy involves three parts, m v 2 x /2 , m v 2 y /2 , and m v 2 z /2 , summed in the exponent. Or we can write it as a product: f( v x , v y , v z ) d v x d v y d v z \u221d e \u2212m v 2 x /2kT \u22c5 e \u2212m v 2 y /2kT \u22c5 e \u2212m v 2 z /2kT d v x d v y d v z . (40.9) You can see that this formula must be right because, first, it is a function only of v 2 , as required, and second, the probabilities of various values of v z obtained by integrating over all v x and v y is just (40.7). But this one function (40.9) can do both those things! Now we shall look at some ways to test the theory, and to see how successful is the classical theory of gases. We saw earlier that if U is the internal energy of N molecules, then PV= NkT= (\u03b3\u22121)U holds, sometimes, for some gases, maybe. If it is a monatomic gas, we know this is also equal to 2 3 of the kinetic energy of the center-of-mass motion of the atoms. If it is a monatomic gas, then the kinetic energy is equal to the internal energy, and therefore \u03b3\u22121= 2 3 . But suppose it is, say, a more complicated molecule, that can spin and vibrate, and let us suppose (it turns out to be true according to classical mechanics) that the energies of the internal motions are also proportional to kT . Then at a given temperature, in addition to kinetic energy 3 2 kT , it has internal vibrational and rotational energies. So the total U includes not just the kinetic energy, but also the rotational and vibrational energies, and we get a different value of \u03b3 . Technically, the best way to measure \u03b3 is by measuring the specific heat, which is the change in energy with temperature. We will return to that approach later. For our present purposes, we may suppose \u03b3 is found experimentally from the P V \u03b3 curve for adiabatic compression. Let us make a calculation of \u03b3 for some cases. First, for a monatomic gas U is the total energy, the same as the kinetic energy, and we know already that \u03b3 should be 5 3 . For a diatomic gas, we may take, as an example, oxygen, hydrogen iodide, hydrogen, etc., and suppose that the diatomic gas can be represented as two atoms held together by some kind of force like the one of Fig. 40\u20133. We may also suppose, and it turns out to be quite true, that at the temperatures that are of interest for the diatomic gas, the pairs of atoms tend strongly to be separated by r 0 , the distance of potential minimum. If this were not true, if the probability were not strongly varying enough to make the great majority sit near the bottom, we would have to remember that oxygen gas is a mixture of O 2 and single oxygen atoms in a nontrivial ratio. We know that there are, in fact, very few single oxygen atoms, which means that the potential energy minimum is very much greater in magnitude than kT , as we have seen. Since they are clustered strongly around r 0 , the only part of the curve that is needed is the part near the minimum, which may be approximated by a parabola. A parabolic potential implies a harmonic oscillator, and in fact, to an excellent approximation, the oxygen molecule can be represented as two atoms connected by a spring. Now what is the total energy of this molecule at temperature T ? We know that for each of the two atoms, each of the kinetic energies should be 3 2 kT , so the kinetic energy of both of them is 3 2 kT+ 3 2 kT . We can also put this in a different way: the same 3 2 plus 3 2 can also be looked at as kinetic energy of the center of mass ( 3 2 ), kinetic energy of rotation ( 2 2 ), and kinetic energy of vibration ( 1 2 ). We know that the kinetic energy of vibration is 1 2 , since there is just one dimension involved and each degree of freedom has 1 2 kT . Regarding the rotation, it can turn about either of two axes, so there are two independent motions. We assume that the atoms are some kind of points, and cannot spin about the line joining them; this is something to bear in mind, because if we get a disagreement, maybe that is where the trouble is. But we have one more thing, which is the potential energy of vibration; how much is that? In a harmonic oscillator the average kinetic energy and average potential energy are equal, and therefore the potential energy of vibration is 1 2 kT , also. The grand total of energy is U= 7 2 kT , or kT is 2 7 U per atom. That means, then, that \u03b3 is 9 7 instead of 5 3 , i.e., \u03b3=1.286 . We may compare these numbers with the relevant measured values shown in Table 40\u20131. Looking first at helium, which is a monatomic gas, we find very nearly 5 3 , and the error is probably experimental, although at such a low temperature there may be some forces between the atoms. Krypton and argon, both monatomic, agree also within the accuracy of the experiment. We turn to the diatomic gases and find hydrogen with 1.404 , which does not agree with the theory, 1.286 . Oxygen, 1.399 , is very similar, but again not in agreement. Hydrogen iodide again is similar at 1.40 . It begins to look as though the right answer is 1.40 , but it is not, because if we look further at bromine we see 1.32 , and at iodine we see 1.30 . Since 1.30 is reasonably close to 1.286 , iodine may be said to agree rather well, but oxygen is far off. So here we have a dilemma. We have it right for one molecule, we do not have it right for another molecule, and we may need to be pretty ingenious in order to explain both. Let us look further at a still more complicated molecule with large numbers of parts, for example, C 2 H 6 , which is ethane. It has eight different atoms, and they are all vibrating and rotating in various combinations, so the total amount of internal energy must be an enormous number of kT \u2019s, at least 12kT for kinetic energy alone, and \u03b3\u22121 must be very close to zero, or \u03b3 almost exactly 1 . In fact, it is lower, but 1.22 is not so much lower, and is higher than the 1 1 12 calculated from the kinetic energy alone, and it is just not understandable! Furthermore, the whole mystery is deep, because the diatomic molecule cannot be made rigid by a limit. Even if we made the couplings stiffer indefinitely, although it might not vibrate much, it would nevertheless keep vibrating. The vibrational energy inside is still kT , since it does not depend on the strength of the coupling. But if we could imagine absolute rigidity, stopping all vibration to eliminate a variable, then we would get U= 5 2 kT and \u03b3=1.40 for the diatomic case. This looks good for H 2 or O 2 . On the other hand, we would still have problems, because \u03b3 for either hydrogen or oxygen varies with temperature! From the measured values shown in Fig. 40\u20136, we see that for H 2 , \u03b3 varies from about 1.6 at \u2212 185 \u2218 C to 1.3 at 2000 \u2218 C. The variation is more substantial in the case of hydrogen than for oxygen, but nevertheless, even in oxygen, \u03b3 tends definitely to go up as we go down in temperature. So, all in all, we might say that we have some difficulty. We might try some force law other than a spring, but it turns out that anything else will only make U higher. If we include more forms of energy, \u03b3 approaches unity more closely, contradicting the facts. All the classical theoretical things that one can think of will only make it worse. The fact is that there are electrons in each atom, and we know from their spectra that there are internal motions; each of the electrons should have at least 1 2 kT of kinetic energy, and something for the potential energy, so when these are added in, \u03b3 gets still smaller. It is ridiculous. It is wrong. The first great paper on the dynamical theory of gases was by Maxwell in 1859. On the basis of ideas we have been discussing, he was able accurately to explain a great many known relations, such as Boyle\u2019s law, the diffusion theory, the viscosity of gases, and things we shall talk about in the next chapter. He listed all these great successes in a final summary, and at the end he said, \u201cFinally, by establishing a necessary relation between the motions of translation and rotation (he is talking about the 1 2 kT theorem) of all particles not spherical, we proved that a system of such particles could not possibly satisfy the known relation between the two specific heats.\u201d He is referring to \u03b3 (which we shall see later is related to two ways of measuring specific heat), and he says we know we cannot get the right answer. Ten years later, in a lecture, he said, \u201cI have now put before you what I consider to be the greatest difficulty yet encountered by the molecular theory.\u201d These words represent the first discovery that the laws of classical physics were wrong. This was the first indication that there was something fundamentally impossible, because a rigorously proved theorem did not agree with experiment. About 1905, Sir James Hopwood Jeans and Lord Rayleigh (John William Strutt) were to talk about this puzzle again. One often hears it said that physicists at the latter part of the nineteenth century thought they knew all the significant physical laws and that all they had to do was to calculate more decimal places. Someone may have said that once, and others copied it. But a thorough reading of the literature of the time shows they were all worrying about something. Jeans said about this puzzle that it is a very mysterious phenomenon, and it seems as though as the temperature falls, certain kinds of motions \u201cfreeze out.\u201d If we could assume that the vibrational motion, say, did not exist at low temperature and did exist at high temperature, then we could imagine that a gas might exist at a temperature sufficiently low that vibrational motion does not occur, so \u03b3=1.40 , or a higher temperature at which it begins to come in, so \u03b3 falls. The same might be argued for the rotation. If we can eliminate the rotation, say it \u201cfreezes out\u201d at sufficiently low temperature, then we can understand the fact that the \u03b3 of hydrogen approaches 1.66 as we go down in temperature. How can we understand such a phenomenon? Of course that these motions \u201cfreeze out\u201d cannot be understood by classical mechanics. It was only understood when quantum mechanics was discovered. Without proof, we may state the results for statistical mechanics of the quantum-mechanical theory. We recall that according to quantum mechanics, a system which is bound by a potential, for the vibrations, for example, will have a discrete set of energy levels, i.e., states of different energy. Now the question is: how is statistical mechanics to be modified according to quantum-mechanical theory? It turns out, interestingly enough, that although most problems are more difficult in quantum mechanics than in classical mechanics, problems in statistical mechanics are much easier in quantum theory! The simple result we have in classical mechanics, that n= n 0 e \u2212energy/kT , becomes the following very important theorem: If the energies of the set of molecular states are called, say, E 0 , E 1 , E 2 , \u2026, E i , \u2026, then in thermal equilibrium the probability of finding a molecule in the particular state of having energy E i is proportional to e \u2212 E i /kT . That gives the probability of being in various states. In other words, the relative chance, the probability, of being in state E 1 relative to the chance of being in state E 0 , is P 1 P 0 = e \u2212 E 1 /kT e \u2212 E 0 /kT , (40.10) which, of course, is the same as n 1 = n 0 e \u2212( E 1 \u2212 E 0 )/kT , (40.11) since P 1 = n 1 /N and P 0 = n 0 /N . So it is less likely to be in a higher energy state than in a lower one. The ratio of the number of atoms in the upper state to the number in the lower state is e raised to the power (minus the energy difference, over kT )\u2014a very simple proposition. Now it turns out that for a harmonic oscillator the energy levels are evenly spaced. Calling the lowest energy E 0 =0 (it actually is not zero, it is a little different, but it does not matter if we shift all energies by a constant), the first one is then E 1 =\u210f\u03c9 , and the second one is 2\u210f\u03c9 , and the third one is 3\u210f\u03c9 , and so on. Now let us see what happens. We suppose we are studying the vibrations of a diatomic molecule, which we approximate as a harmonic oscillator. Let us ask what is the relative chance of finding a molecule in state E 1 instead of in state E 0 . The answer is that the chance of finding it in state E 1 , relative to that of finding it in state E 0 , goes down as e \u2212\u210f\u03c9/kT . Now suppose that kT is much less than \u210f\u03c9 , and we have a low-temperature circumstance. Then the probability of its being in state E 1 is extremely small. Practically all the atoms are in state E 0 . If we change the temperature but still keep it very small, then the chance of its being in state E 1 =\u210f\u03c9 remains infinitesimal\u2014the energy of the oscillator remains nearly zero; it does not change with temperature so long as the temperature is much less than \u210f\u03c9 . All oscillators are in the bottom state, and their motion is effectively \u201cfrozen\u201d; there is no contribution of it to the specific heat. We can judge, then, from Table 40\u20131, that at 100 \u2218 C, which is 373 degrees absolute, kT is much less than the vibrational energy in the oxygen or hydrogen molecules, but not so in the iodine molecule. The reason for the difference is that an iodine atom is very heavy, compared with hydrogen, and although the forces may be comparable in iodine and hydrogen, the iodine molecule is so heavy that the natural frequency of vibration is very low compared with the natural frequency of hydrogen. With \u210f\u03c9 higher than kT at room temperature for hydrogen, but lower for iodine, only the latter, iodine, exhibits the classical vibrational energy. As we increase the temperature of a gas, starting from a very low value of T , with the molecules almost all in their lowest state, they gradually begin to have an appreciable probability to be in the second state, and then in the next state, and so on. When the probability is appreciable for many states, the behavior of the gas approaches that given by classical physics, because the quantized states become nearly indistinguishable from a continuum of energies, and the system can have almost any energy. Thus, as the temperature rises, we should again get the results of classical physics, as indeed seems to be the case in Fig. 40\u20136. It is possible to show in the same way that the rotational states of atoms are also quantized, but the states are so much closer together that in ordinary circumstances kT is bigger than the spacing. Then many levels are excited, and the rotational kinetic energy in the system participates in the classical way. The one example where this is not quite true at room temperature is for hydrogen. This is the first time that we have really deduced, by comparison with experiment, that there was something wrong with classical physics, and we have looked for a resolution of the difficulty in quantum mechanics in much the same way as it was done originally. It took 30 or 40 years before the next difficulty was discovered, and that had to do again with statistical mechanics, but this time the mechanics of a photon gas. That problem was solved by Planck, in the early years of the 20th century."
    },
    {
        "input": "Harmonics",
        "output": "Pythagoras is said to have discovered the fact that two similar strings under the same tension and differing only in length, when sounded together give an effect that is pleasant to the ear if the lengths of the strings are in the ratio of two small integers. If the lengths are as one is to two, they then correspond to the octave in music. If the lengths are as two is to three, they correspond to the interval between C and G , which is called a fifth. These intervals are generally accepted as \u201cpleasant\u201d sounding chords. Pythagoras was so impressed by this discovery that he made it the basis of a school\u2014Pythagoreans they were called\u2014which held mystic beliefs in the great powers of numbers. It was believed that something similar would be found out about the planets\u2014or \u201cspheres.\u201d We sometimes hear the expression: \u201cthe music of the spheres.\u201d The idea was that there would be some numerical relationships between the orbits of the planets or between other things in nature. People usually think that this is just a kind of superstition held by the Greeks. But is it so different from our own scientific interest in quantitative relationships? Pythagoras\u2019 discovery was the first example, outside geometry, of any numerical relationship in nature. It must have been very surprising to suddenly discover that there was a fact of nature that involved a simple numerical relationship. Simple measurements of lengths gave a prediction about something which had no apparent connection to geometry\u2014the production of pleasant sounds. This discovery led to the extension that perhaps a good tool for understanding nature would be arithmetic and mathematical analysis. The results of modern science justify that point of view. Pythagoras could only have made his discovery by making an experimental observation. Yet this important aspect does not seem to have impressed him. If it had, physics might have had a much earlier start. (It is always easy to look back at what someone else has done and to decide what he should have done!) We might remark on a third aspect of this very interesting discovery: that the discovery had to do with two notes that sound pleasant to the ear. We may question whether we are any better off than Pythagoras in understanding why only certain sounds are pleasant to our ear. The general theory of aesthetics is probably no further advanced now than in the time of Pythagoras. In this one discovery of the Greeks, there are the three aspects: experiment, mathematical relationships, and aesthetics. Physics has made great progress on only the first two parts. This chapter will deal with our present-day understanding of the discovery of Pythagoras. Among the sounds that we hear, there is one kind that we call noise. Noise corresponds to a sort of irregular vibration of the eardrum that is produced by the irregular vibration of some object in the neighborhood. If we make a diagram to indicate the pressure of the air on the eardrum (and, therefore, the displacement of the drum) as a function of time, the graph which corresponds to a noise might look like that shown in Fig. 50\u20131(a). (Such a noise might correspond roughly to the sound of a stamped foot.) The sound of music has a different character. Music is characterized by the presence of more-or-less sustained tones\u2014or musical \u201cnotes.\u201d (Musical instruments may make noises as well!) The tone may last for a relatively short time, as when a key is pressed on a piano, or it may be sustained almost indefinitely, as when a flute player holds a long note. What is the special character of a musical note from the point of view of the pressure in the air? A musical note differs from a noise in that there is a periodicity in its graph. There is some uneven shape to the variation of the air pressure with time, and the shape repeats itself over and over again. An example of a pressure-time function that would correspond to a musical note is shown in Fig. 50\u20131(b). Musicians will usually speak of a musical tone in terms of three characteristics: the loudness, the pitch, and the \u201cquality.\u201d The \u201cloudness\u201d is found to correspond to the magnitude of the pressure changes. The \u201cpitch\u201d corresponds to the period of time for one repetition of the basic pressure function. (\u201cLow\u201d notes have longer periods than \u201chigh\u201d notes.) The \u201cquality\u201d of a tone has to do with the differences we may still be able to hear between two notes of the same loudness and pitch. An oboe, a violin, or a soprano are still distinguishable even when they sound notes of the same pitch. The quality has to do with the structure of the repeating pattern. Let us consider, for a moment, the sound produced by a vibrating string. If we pluck the string, by pulling it to one side and releasing it, the subsequent motion will be determined by the motions of the waves we have produced. We know that these waves will travel in both directions, and will be reflected at the ends. They will slosh back and forth for a long time. No matter how complicated the wave is, however, it will repeat itself. The period of repetition is just the time T required for the wave to travel two full lengths of the string. For that is just the time required for any wave, once started, to reflect off each end and return to its starting position, and be proceeding in the original direction. The time is the same for waves which start out in either direction. Each point on the string will, then, return to its starting position after one period, and again one period later, etc. The sound wave produced must also have the same repetition. We see why a plucked string produces a musical tone. We have discussed in the preceding chapter another way of looking at the motion of a vibrating system. We have seen that a string has various natural modes of oscillation, and that any particular kind of vibration that may be set up by the starting conditions can be thought of as a combination\u2014in suitable proportions\u2014of several of the natural modes, oscillating together. For a string we found that the normal modes of oscillation had the frequencies \u03c90 , 2\u03c90 , 3\u03c90 , \u2026 The most general motion of a plucked string, therefore, is composed of the sum of a sinusoidal oscillation at the fundamental frequency \u03c90 , another at the second harmonic frequency 2\u03c90 , another at the third harmonic 3\u03c90 , etc. Now the fundamental mode repeats itself every period T1=2\u03c0/\u03c90 . The second harmonic mode repeats itself every T2=2\u03c0/2\u03c90 . It also repeats itself every T1=2T2 , after two of its periods. Similarly, the third harmonic mode repeats itself after a time T1 which is 3 of its periods. We see again why a plucked string repeats its whole pattern with a periodicity of T1 . It produces a musical tone. We have been talking about the motion of the string. But the sound, which is the motion of the air, is produced by the motion of the string, so its vibrations too must be composed of the same harmonics\u2014though we are no longer thinking about the normal modes of the air. Also, the relative strength of the harmonics may be different in the air than in the string, particularly if the string is \u201ccoupled\u201d to the air via a sounding board. The efficiency of the coupling to the air is different for different harmonics. If we let f(t) represent the air pressure as a function of time for a musical tone [such as that in Fig. 50\u20131(b)], then we expect that f(t) can be written as the sum of a number of simple harmonic functions of time\u2014like cos\u03c9t \u2014for each of the various harmonic frequencies. If the period of the vibration is T , the fundamental angular frequency will be \u03c9=2\u03c0/T , and the harmonics will be 2\u03c9 , 3\u03c9 , etc. There is one slight complication. For each frequency we may expect that the starting phases will not necessarily be the same for all frequencies. We should, therefore, use functions like cos(\u03c9t+\u03d5) . It is, however, simpler to use instead both the sine and cosine functions for each frequency. We recall that cos(\u03c9t+\u03d5)=(cos\u03d5cos\u03c9t\u2212sin\u03d5sin\u03c9t) and since \u03d5 is a constant, any sinusoidal oscillation at the frequency \u03c9 can be written as the sum of a term with cos\u03c9t and another term with sin\u03c9t . We conclude, then, that any function f(t) that is periodic with the period T can be written mathematically as f(t) = a 0 + a 1 cos + a 2 cos2 + a 3 cos3 +\u22ef \u03c9t \u03c9t \u03c9t + b 1 sin + b 2 sin2 + b 3 sin3 +\u22ef \u03c9t \u03c9t \u03c9t (50.2) where \u03c9=2\u03c0/T and the a \u2019s and b \u2019s are numerical constants which tell us how much of each component oscillation is present in the oscillation f(t) . We have added the \u201czero-frequency\u201d term a 0 so that our formula will be completely general, although it is usually zero for a musical tone. It represents a shift of the average value (that is, the \u201czero\u201d level) of the sound pressure. With it our formula can take care of any case. The equality of Eq. (50.2) is represented schematically in Fig. 50\u20132. (The amplitudes, a n and b n , of the harmonic functions must be suitably chosen. They are shown schematically and without any particular scale in the figure.) The series (50.2) is called the Fourier series for f(t) . We have said that any periodic function can be made up in this way. We should correct that and say that any sound wave, or any function we ordinarily encounter in physics, can be made up of such a sum. The mathematicians can invent functions which cannot be made up of simple harmonic functions\u2014for instance, a function that has a \u201creverse twist\u201d so that it has two values for some values of t ! We need not worry about such functions here. Now we are able to describe what it is that determines the \u201cquality\u201d of a musical tone. It is the relative amounts of the various harmonics\u2014the values of the a \u2019s and b \u2019s. A tone with only the first harmonic is a \u201cpure\u201d tone. A tone with many strong harmonics is a \u201crich\u201d tone. A violin produces a different proportion of harmonics than does an oboe. We can \u201cmanufacture\u201d various musical tones if we connect several \u201coscillators\u201d to a loudspeaker. (An oscillator usually produces a nearly pure simple harmonic function.) We should choose the frequencies of the oscillators to be \u03c9 , 2\u03c9 , 3\u03c9 , etc. Then by adjusting the volume control on each oscillator, we can add in any amount we wish of each harmonic\u2014thereby producing tones of different quality. An electric organ works in much this way. The \u201ckeys\u201d select the frequency of the fundamental oscillator and the \u201cstops\u201d are switches that control the relative proportions of the harmonics. By throwing these switches, the organ can be made to sound like a flute, or an oboe, or a violin. It is interesting that to produce such \u201cartificial\u201d tones we need only one oscillator for each frequency\u2014we do not need separate oscillators for the sine and cosine components. The ear is not very sensitive to the relative phases of the harmonics. It pays attention mainly to the total of the sine and cosine parts of each frequency. Our analysis is more accurate than is necessary to explain the subjective aspect of music. The response of a microphone or other physical instrument does depend on the phases, however, and our complete analysis may be needed to treat such cases. The \u201cquality\u201d of a spoken sound also determines the vowel sounds that we recognize in speech. The shape of the mouth determines the frequencies of the natural modes of vibration of the air in the mouth. Some of these modes are set into vibration by the sound waves from the vocal chords. In this way, the amplitudes of some of the harmonics of the sound are increased with respect to others. When we change the shape of our mouth, harmonics of different frequencies are given preference. These effects account for the difference between an \u201ce\u2013e\u2013e\u201d sound and an \u201ca\u2013a\u2013a\u201d sound. We all know that a particular vowel sound\u2014say \u201ce\u2013e\u2013e\u201d\u2014still \u201csounds like\u201d the same vowel whether we say (or sing) it at a high or a low pitch. From the mechanism we describe, we would expect that particular frequencies are emphasized when we shape our mouth for an \u201ce\u2013e\u2013e,\u201d and that they do not change as we change the pitch of our voice. So the relation of the important harmonics to the fundamental\u2014that is, the \u201cquality\u201d\u2014changes as we change pitch. Apparently the mechanism by which we recognize speech is not based on specific harmonic relationships. What should we say now about Pythagoras\u2019 discovery? We understand that two similar strings with lengths in the ratio of 2 to 3 will have fundamental frequencies in the ratio 3 to 2 . But why should they \u201csound pleasant\u201d together? Perhaps we should take our clue from the frequencies of the harmonics. The second harmonic of the lower shorter string will have the same frequency as the third harmonic of the longer string. (It is easy to show\u2014or to believe\u2014that a plucked string produces strongly the several lowest harmonics.) Perhaps we should make the following rules. Notes sound consonant when they have harmonics with the same frequency. Notes sound dissonant if their upper harmonics have frequencies near to each other but far enough apart that there are rapid beats between the two. Why beats do not sound pleasant, and why unison of the upper harmonics does sound pleasant, is something that we do not know how to define or describe. We cannot say from this knowledge of what sounds good, what ought, for example, to smell good. In other words, our understanding of it is not anything more general than the statement that when they are in unison they sound good. It does not permit us to deduce anything more than the properties of concordance in music. It is easy to check on the harmonic relationships we have described by some simple experiments with a piano. Let us label the 3 successive C\u2019s near the middle of the keyboard by C, C \u2032 \u2032 , and C \u2032\u2032 \u2033 , and the G\u2019s just above by G, G \u2032 \u2032 , and G \u2032\u2032 \u2033 . Then the fundamentals will have relative frequencies as follows: C C \u2032 C \u2032\u2032 \u20132 \u20134 \u20138 G G \u2032 G \u2032\u2032 \u20133 \u20136 \u201312 These harmonic relationships can be demonstrated in the following way: Suppose we press C \u2032 \u2032 slowly\u2014so that it does not sound but we cause the damper to be lifted. If we then sound C, it will produce its own fundamental and some second harmonic. The second harmonic will set the strings of C \u2032 \u2032 into vibration. If we now release C (keeping C \u2032 \u2032 pressed) the damper will stop the vibration of the C strings, and we can hear (softly) the note C \u2032 \u2032 as it dies away. In a similar way, the third harmonic of C can cause a vibration of G \u2032 \u2032 . Or the sixth of C (now getting much weaker) can set up a vibration in the fundamental of G \u2032\u2032 \u2033 . A somewhat different result is obtained if we press G quietly and then sound C \u2032 \u2032 . The third harmonic of C \u2032 \u2032 will correspond to the fourth harmonic of G, so only the fourth harmonic of G will be excited. We can hear (if we listen closely) the sound of G \u2032\u2032 \u2033 , which is two octaves above the G we have pressed! It is easy to think up many more combinations for this game. We may remark in passing that the major scale can be defined just by the condition that the three major chords (F\u2013A\u2013C); (C\u2013E\u2013G); and (G\u2013B\u2013D) each represent tone sequences with the frequency ratio (4:5:6) . These ratios\u2014plus the fact that an octave (C\u2013C \u2032 \u2032 , B\u2013B \u2032 \u2032 , etc.) has the ratio 1:2 \u2014determine the whole scale for the \u201cideal\u201d case, or for what is called \u201cjust intonation.\u201d Keyboard instruments like the piano are not usually tuned in this manner, but a little \u201cfudging\u201d is done so that the frequencies are approximately correct for all possible starting tones. For this tuning, which is called \u201ctempered,\u201d the octave (still 1:2 ) is divided into 12 equal intervals for which the frequency ratio is (2 ) 1/12 . A fifth no longer has the frequency ratio 3/2 , but 2 7/12 =1.499 , which is apparently close enough for most ears. We have stated a rule for consonance in terms of the coincidence of harmonics. Is this coincidence perhaps the reason that two notes are consonant? One worker has claimed that two pure tones\u2014tones carefully manufactured to be free of harmonics\u2014do not give the sensations of consonance or dissonance as the relative frequencies are placed at or near the expected ratios. (Such experiments are difficult because it is difficult to manufacture pure tones, for reasons that we shall see later.) We cannot still be certain whether the ear is matching harmonics or doing arithmetic when we decide that we like a sound. Let us return now to the idea that any note\u2014that is, a periodic sound\u2014can be represented by a suitable combination of harmonics. We would like to show how we can find out what amount of each harmonic is required. It is, of course, easy to compute f(t) , using Eq. (50.2), if we are given all the coefficients a and b . The question now is, if we are given f(t) how can we know what the coefficients of the various harmonic terms should be? (It is easy to make a cake from a recipe; but can we write down the recipe if we are given a cake?) Fourier discovered that it was not really very difficult. The term a 0 is certainly easy. We have already said that it is just the average value of f(t) over one period (from t=0 to t=T ). We can easily see that this is indeed so. The average value of a sine or cosine function over one period is zero. Over two, or three, or any whole number of periods, it is also zero. So the average value of all of the terms on the right-hand side of Eq. (50.2) is zero, except for a 0 . (Recall that we must choose \u03c9=2\u03c0/T .) Now the average of a sum is the sum of the averages. So the average of f(t) is just the average of a 0 . But a 0 is a constant, so its average is just the same as its value. Recalling the definition of an average, we have a 0 = 1 T \u222b T 0 f(t)dt. (50.3) The other coefficients are only a little more difficult. To find them we can use a trick discovered by Fourier. Suppose we multiply both sides of Eq. (50.2) by some harmonic function\u2014say by cos7\u03c9t . We have then f(t)\u22c5cos7\u03c9t = a 0 \u22c5cos7\u03c9t + a 1 cos\u03c9t\u22c5cos7\u03c9t + b 1 sin\u03c9t\u22c5cos7\u03c9t + a 2 cos2\u03c9t\u22c5cos7\u03c9t + b 2 sin2\u03c9t\u22c5cos7\u03c9t +\u22ef + a 7 cos7\u03c9t\u22c5cos7\u03c9t + b 7 sin7\u03c9t\u22c5cos7\u03c9t +\u22ef (50.4) Now let us average both sides. The average of a 0 cos7\u03c9t over the time T is proportional to the average of a cosine over 7 whole periods. But that is just zero. The average of almost all of the rest of the terms is also zero. Let us look at the a 1 term. We know, in general, that cosAcosB= 1 2 cos(A+B)+ 1 2 cos(A\u2212B). (50.5) The a 1 term becomes 1 2 a 1 (cos8\u03c9t+cos6\u03c9t). (50.6) We thus have two cosine terms, one with 8 full periods in T and the other with 6 . They both average to zero. The average of the a 1 term is therefore zero. For the a 2 term, we would find a 2 cos9\u03c9t and a 2 cos5\u03c9t , each of which also averages to zero. For the a 9 term, we would find cos16\u03c9t and cos(\u22122\u03c9t) . But cos(\u22122\u03c9t) is the same as cos2\u03c9t , so both of these have zero averages. It is clear that all of the a terms will have a zero average except one. And that one is the a 7 term. For this one we have 1 2 a 7 (cos14\u03c9t+cos0). (50.7) The cosine of zero is one, and its average, of course, is one. So we have the result that the average of all of the a terms of Eq. (50.4) equals 1 2 a 7 . The b terms are even easier. When we multiply by any cosine term like cosn\u03c9t , we can show by the same method that all of the b terms have the average value zero. We see that Fourier\u2019s \u201ctrick\u201d has acted like a sieve. When we multiply by cos7\u03c9t and average, all terms drop out except a 7 , and we find that Average[f(t)\u22c5cos7\u03c9t]= a 7 /2, (50.8) or a 7 = 2 T \u222b T 0 f(t)\u22c5cos7\u03c9tdt. (50.9) We shall leave it for the reader to show that the coefficient b 7 can be obtained by multiplying Eq. (50.2) by sin7\u03c9t and averaging both sides. The result is b 7 = 2 T \u222b T 0 f(t)\u22c5sin7\u03c9tdt. (50.10) Now what is true for 7 we expect is true for any integer. So we can summarize our proof and result in the following more elegant mathematical form. If m and n are integers other than zero, and if \u03c9=2\u03c0/T , then I. \u222b T 0 sinn\u03c9tcosm\u03c9tdt=0. II. \u222b T 0 cosn\u03c9tcosm\u03c9tdt= III. \u222b T 0 sinn\u03c9tsinm\u03c9tdt= \u23ab \u23ad \u23ac \u23aa \u23aa \u23aa \u23aa \u23aa \u23aa \u23aa \u23aa { 0 T/2 if n\u2260m. if n=m. IV.f(t)= a 0 + \u2211 n=1 \u221e a n cosn\u03c9t + \u2211 n=1 \u221e b n sinn\u03c9t. V. a 0 = 1 T \u222b T 0 f(t)dt. a n = 2 T \u222b T 0 f(t)\u22c5cosn\u03c9tdt. b n = 2 T \u222b T 0 f(t)\u22c5sinn\u03c9tdt. (50.11) (50.12) (50.13) (50.14) (50.15) (50.16) In earlier chapters it was convenient to use the exponential notation for representing simple harmonic motion. Instead of cos\u03c9t we used Re e i\u03c9t , the real part of the exponential function. We have used cosine and sine functions in this chapter because it made the derivations perhaps a little clearer. Our final result of Eq. (50.13) can, however, be written in the compact form f(t)=Re \u2211 n=0 \u221e a ^ n e in\u03c9t , (50.17) where a ^ n is the complex number a n \u2212i b n (with b 0 =0 ). If we wish to use the same notation throughout, we can write also a ^ n = 2 T \u222b T 0 f(t) e \u2212in\u03c9t dt(n\u22651). (50.18) We now know how to \u201canalyze\u201d a periodic wave into its harmonic components. The procedure is called Fourier analysis, and the separate terms are called Fourier components. We have not shown, however, that once we find all of the Fourier components and add them together, we do indeed get back our f(t) . The mathematicians have shown, for a wide class of functions, in fact for all that are of interest to physicists, that if we can do the integrals we will get back f(t) . There is one minor exception. If the function f(t) is discontinuous, i.e., if it jumps suddenly from one value to another, the Fourier sum will give a value at the breakpoint halfway between the upper and lower values at the discontinuity. So if we have the strange function f(t)=0 , 0\u2264t< t 0 , and f(t)=1 for t 0 \u2264t\u2264T , the Fourier sum will give the right value everywhere except at t 0 , where it will have the value 1 2 instead of 1 . It is rather unphysical anyway to insist that a function should be zero up to t 0 , but 1 right at t 0 . So perhaps we should make the \u201crule\u201d for physicists that any discontinuous function (which can only be a simplification of a real physical function) should be defined with halfway values at the discontinuities. Then any such function\u2014with any finite number of such jumps\u2014as well as all other physically interesting functions, are given correctly by the Fourier sum. As an exercise, we suggest that the reader determine the Fourier series for the function shown in Fig. 50\u20133. Since the function cannot be written in an explicit algebraic form, you will not be able to do the integrals from zero to T in the usual way. The integrals are easy, however, if we separate them into two parts: the integral from zero to T/2 (over which f(t)=1 ) and the integral from T/2 to T (over which f(t)=\u22121 ). The result should be f(t)= 4 \u03c0 (sin\u03c9t+ 1 3 sin3\u03c9t+ 1 5 sin5\u03c9t+\u22ef), (50.19) where \u03c9=2\u03c0/T . We thus find that our square wave (with the particular phase chosen) has only odd harmonics, and their amplitudes are in inverse proportion to their frequencies. Let us check that Eq. (50.19) does indeed give us back f(t) for some value of t . Let us choose t=T/4 , or \u03c9t=\u03c0/2 . We have f(t) = 4 \u03c0 (sin \u03c0 2 + 1 3 sin 3\u03c0 2 + 1 5 sin 5\u03c0 2 +\u22ef) = 4 \u03c0 (1\u2212 1 3 + 1 5 \u2212 1 7 \u00b1\u22ef). (50.20) (50.21) The series1 has the value \u03c0/4 , and we find that f(t)=1 . The energy in a wave is proportional to the square of its amplitude. For a wave of complex shape, the energy in one period will be proportional to \u222b T 0 f 2 (t)dt . We can also relate this energy to the Fourier coefficients. We write \u222b T 0 f 2 (t)dt= \u222b T 0 [ a 0 + \u2211 n=1 \u221e a n cosn\u03c9t+ \u2211 n=1 \u221e b n sinn\u03c9t ] 2 dt. (50.22) When we expand the square of the bracketed term we will get all possible cross terms, such as a 5 cos5\u03c9t\u22c5 a 7 cos7\u03c9t and a 5 cos5\u03c9t\u22c5 b 7 sin7\u03c9t . We have shown above, however, [Eqs. (50.11) and (50.12)] that the integrals of all such terms over one period is zero. We have left only the square terms like a 2 5 cos 2 5\u03c9t . The integral of any cosine squared or sine squared over one period is equal to T/2 , so we get \u222b T 0 f 2 (t)dt= T a 2 0 + T 2 ( a 2 1 + a 2 2 +\u22ef+ b 2 1 + b 2 2 +\u22ef)= T a 2 0 + T 2 \u2211 n=1 \u221e ( a 2 n + b 2 n ). (50.23) This equation is called the \u201cenergy theorem,\u201d and says that the total energy in a wave is just the sum of the energies in all of the Fourier components. For example, applying this theorem to the series (50.19), since [f(t) ] 2 =1 we get T= T 2 \u22c5( 4 \u03c0 ) 2 (1+ 1 3 2 + 1 5 2 + 1 7 2 +\u22ef), T 4 1 1 1 so we learn that the sum of the squares of the reciprocals of the odd integers is \u03c0 2 /8 . In a similar way, by first obtaining the Fourier series for the function f(t)=(t\u2212T/2 ) 2 and using the energy theorem, we can prove that 1+1/ 2 4 +1/ 3 4 +\u22ef is \u03c0 4 /90 , a result we needed in Chapter 45. Finally, in the theory of harmonics there is an important phenomenon which should be remarked upon because of its practical importance\u2014that of nonlinear effects. In all the systems that we have been considering so far, we have supposed that everything was linear, that the responses to forces, say the displacements or the accelerations, were always proportional to the forces. Or that the currents in the circuits were proportional to the voltages, and so on. We now wish to consider cases where there is not a strict proportionality. We think, at the moment, of some device in which the response, which we will call x out at the time t , is determined by the input x in at the time t . For example, x in might be the force and x out might be the displacement. Or x in might be the current and x out the voltage. If the device is linear, we would have x out (t)=K x in (t), (50.24) where K is a constant independent of t and of x in . Suppose, however, that the device is nearly, but not exactly, linear, so that we can write x out (t)=K[ x in (t)+\u03f5 x 2 in (t)], (50.25) where \u03f5 is small in comparison with unity. Such linear and nonlinear responses are shown in the graphs of Fig. 50\u20134. Nonlinear responses have several important practical consequences. We shall discuss some of them now. First we consider what happens if we apply a pure tone at the input. We let x in =cos\u03c9t . If we plot x out as a function of time we get the solid curve shown in Fig. 50\u20135. The dashed curve gives, for comparison, the response of a linear system. We see that the output is no longer a cosine function. It is more peaked at the top and flatter at the bottom. We say that the output is distorted. We know, however, that such a wave is no longer a pure tone, that it will have harmonics. We can find what the harmonics are. Using x in =cos\u03c9t with Eq. (50.25), we have x out (t)=K(cos\u03c9t+\u03f5 cos 2 \u03c9t). (50.26) From the equality cos 2 \u03b8= 1 2 (1+cos2\u03b8) , we have x out (t)=K(cos\u03c9t+ \u03f5 2 + \u03f5 2 cos2\u03c9t). (50.27) The output has not only a component at the fundamental frequency, that was present at the input, but also has some of its second harmonic. There has also appeared at the output a constant term K(\u03f5/2) , which corresponds to the shift of the average value, shown in Fig. 50\u20135. The process of producing a shift of the average value is called rectification. A nonlinear response will rectify and will produce harmonics of the frequencies at its input. Although the nonlinearity we assumed produced only second harmonics, nonlinearities of higher order\u2014those which have terms like x 3 in and x 4 in , for example\u2014will produce harmonics higher than the second. Another effect which results from a nonlinear response is modulation. If our input function contains two (or more) pure tones, the output will have not only their harmonics, but still other frequency components. Let x in =Acos \u03c9 1 t+Bcos \u03c9 2 t , where now \u03c9 1 and \u03c9 2 are not intended to be in a harmonic relation. In addition to the linear term (which is K times the input) we shall have a component in the output given by x out =K\u03f5(Acos \u03c9 1 t+Bcos \u03c9 2 t ) 2 =K\u03f5( A 2 cos 2 \u03c9 1 t+ B 2 cos 2 \u03c9 2 t +2ABcos \u03c9 1 tcos \u03c9 2 t). (50.28) (50.29) The first two terms in the parentheses of Eq. (50.29) are just those which gave the constant terms and second harmonic terms we found above. The last term is new. We can look at this new \u201ccross term\u201d ABcos \u03c9 1 tcos \u03c9 2 t in two ways. First, if the two frequencies are widely different (for example, if \u03c9 1 is much greater than \u03c9 2 ) we can consider that the cross term represents a cosine oscillation of varying amplitude. That is, we can think of the factors in this way: ABcos \u03c9 1 tcos \u03c9 2 t=C(t)cos \u03c9 1 t, (50.30) with C(t)=ABcos \u03c9 2 t. (50.31) We say that the amplitude of cos \u03c9 1 t is modulated with the frequency \u03c9 2 . Alternatively, we can write the cross term in another way: ABcos \u03c9 1 tcos \u03c9 2 t= AB 2 [cos( \u03c9 1 + \u03c9 2 )t+cos( \u03c9 1 \u2212 \u03c9 2 )t]. (50.32) We would now say that two new components have been produced, one at the sum frequency ( \u03c9 1 + \u03c9 2 ) , another at the difference frequency ( \u03c9 1 \u2212 \u03c9 2 ) . We have two different, but equivalent, ways of looking at the same result. In the special case that \u03c9 1 \u226b \u03c9 2 , we can relate these two different views by remarking that since ( \u03c9 1 + \u03c9 2 ) and ( \u03c9 1 \u2212 \u03c9 2 ) are near to each other we would expect to observe beats between them. But these beats have just the effect of modulating the amplitude of the average frequency \u03c9 1 by one-half the difference frequency 2 \u03c9 2 . We see, then, why the two descriptions are equivalent. In summary, we have found that a nonlinear response produces several effects: rectification, generation of harmonics, and modulation, or the generation of components with sum and difference frequencies. We should notice that all these effects (Eq. 50.29) are proportional not only to the nonlinearity coefficient \u03f5 , but also to the product of two amplitudes\u2014either A 2 , B 2 , or AB . We expect these effects to be much more important for strong signals than for weak ones. The effects we have been describing have many practical applications. First, with regard to sound, it is believed that the ear is nonlinear. This is believed to account for the fact that with loud sounds we have the sensation that we hear harmonics and also sum and difference frequencies even if the sound waves contain only pure tones. The components which are used in sound-reproducing equipment\u2014amplifiers, loudspeakers, etc.\u2014always have some nonlinearity. They produce distortions in the sound\u2014they generate harmonics, etc.\u2014which were not present in the original sound. These new components are heard by the ear and are apparently objectionable. It is for this reason that \u201cHi-Fi\u201d equipment is designed to be as linear as possible. (Why the nonlinearities of the ear are not \u201cobjectionable\u201d in the same way, or how we even know that the nonlinearity is in the loudspeaker rather than in the ear is not clear!) Nonlinearities are quite necessary, and are, in fact, intentionally made large in certain parts of radio transmitting and receiving equipment. In an am transmitter the \u201cvoice\u201d signal (with frequencies of some kilocycles per second) is combined with the \u201ccarrier\u201d signal (with a frequency of some megacycles per second) in a nonlinear circuit called a modulator, to produce the modulated oscillation that is transmitted. In the receiver, the components of the received signal are fed to a nonlinear circuit which combines the sum and difference frequencies of the modulated carrier to generate again the voice signal. When we discussed the transmission of light, we assumed that the induced oscillations of charges were proportional to the electric field of the light\u2014that the response was linear. That is indeed a very good approximation. It is only within the last few years that light sources have been devised (lasers) which produce an intensity of light strong enough so that nonlinear effects can be observed. It is now possible to generate harmonics of light frequencies. When a strong red light passes through a piece of glass, a little bit of blue light\u2014second harmonic\u2014comes out!"
    },
    {
        "input": "Mechanisms of Seeing",
        "output": "In discussing the sense of sight, we have to realize that (outside of a gallery of modern art!) one does not see random spots of color or spots of light. When we look at an object we see a man or a thing; in other words, the brain interprets what we see. How it does that, no one knows, and it does it, of course, at a very high level. Although we evidently do learn to recognize what a man looks like after much experience, there are a number of features of vision which are more elementary but which also involve combining information from different parts of what we see. To help us understand how we make an interpretation of an entire image, it is worthwhile to study the earliest stages of the putting together of information from the different retinal cells. In the present chapter we shall concentrate mainly on that aspect of vision, although we shall also mention a number of side issues as we go along. An example of the fact that we have an accumulation, at a very elementary level, of information from several parts of the eye at the same time, beyond our voluntary control or ability to learn, was that blue shadow which was produced by white light when both white and red were shining on the same screen. This effect at least involves the knowledge that the background of the screen is pink, even though, when we are looking at the blue shadow, it is only \u201cwhite\u201d light coming into a particular spot in the eye; somewhere, pieces of information have been put together. The more complete and familiar the context is, the more the eye will make corrections for peculiarities. In fact, Land has shown that if we mix that apparent blue and the red in various proportions, by using two photographic transparencies with absorption in front of the red and the white in different proportions, it can be made to represent a real scene, with real objects, rather faithfully. In this case we get a lot of intermediate apparent colors too, analogous to what we would get by mixing red and blue-green; it seems to be an almost complete set of colors, but if we look very hard at them, they are not so very good. Even so, it is surprising how much can be obtained from just red and white. The more the scene looks like a real situation, the more one is able to compensate for the fact that all the light is actually nothing but pink! Another example is the appearance of \u201ccolors\u201d in a black-and-white rotating disc, whose black and white areas are as shown in Fig. 36\u20131. When the disc is rotated, the variations of light and dark at any one radius are exactly the same; it is only the background that is different for the two kinds of \u201cstripes.\u201d Yet one of the \u201crings\u201d appears colored with one color and the other with another.1 No one yet understands the reason for those colors, but it is clear that information is being put together at a very elementary level, in the eye itself, most likely. Almost all present-day theories of color vision agree that the color-mixing data indicate that there are only three pigments in the cones of the eye, and that it is the spectral absorption in those three pigments that fundamentally produces the color sense. But the total sensation that is associated with the absorption characteristics of the three pigments acting together is not necessarily the sum of the individual sensations. We all agree that yellow simply does not seem to be reddish green; in fact it might be a tremendous surprise to most people to discover that light is, in fact, a mixture of colors, because presumably the sensation of light is due to some other process than a simple mixture like a chord in music, where the three notes are there at the same time and if we listen hard we can hear them individually. We cannot look hard and see the red and the green. The earliest theories of vision said that there are three pigments and three kinds of cones, each kind containing one pigment; that a nerve runs from each cone to the brain, so that the three pieces of information are carried to the brain; and then in the brain, anything can happen. This, of course, is an incomplete idea: it does no good to discover that the information is carried along the optic nerve to the brain, because we have not even started to solve the problem. We must ask more basic questions: Does it make any difference where the information is put together? Is it important that it be carried right up into the brain in the optic nerve, or could the retina do some analysis first? We have seen a picture of the retina as an extremely complicated thing with lots of interconnections (Fig. 35\u20132) and it might make some analyses. As a matter of fact, people who study anatomy and the development of the eye have shown that the retina is, in fact, the brain: in the development of the embryo, a piece of the brain comes out in front, and long fibers grow back, connecting the eyes to the brain. The retina is organized in just the way the brain is organized and, as someone has beautifully put it, \u201cThe brain has developed a way to look out upon the world.\u201d The eye is a piece of brain that is touching light, so to speak, on the outside. So it is not at all unlikely that some analysis of the color has already been made in the retina. This gives us a very interesting opportunity. None of the other senses involves such a large amount of calculation, so to speak, before the signal gets into a nerve that one can make measurements on. The calculations for all the rest of the senses usually happen in the brain itself, where it is very difficult to get at specific places to make measurements, because there are so many interconnections. Here, with the visual sense, we have the light, three layers of cells making calculations, and the results of the calculations being transmitted through the optic nerve. So we have the first chance to observe physiologically how, perhaps, the first layers of the brain work in their first steps. It is thus of double interest, not simply interesting for vision, but interesting to the whole problem of physiology. The fact that there are three pigments does not mean that there must be three kinds of sensations. One of the other theories of color vision has it that there are really opposing color schemes (Fig. 36\u20132). That is, one of the nerve fibers carries a lot of impulses if there is yellow being seen, and less than usual for blue. Another nerve fiber carries green and red information in the same way, and another, white and black. In other words, in this theory someone has already started to make a guess as to the system of wiring, the method of calculation. The problems we are trying to solve by guessing at these first calculations are questions about the apparent colors that are seen on a pink background, what happens when the eye is adapted to different colors, and also the so-called psychological phenomena. The psychological phenomena are of the nature, for instance, that white does not \u201cfeel\u201d like red and yellow and blue, and this theory was advanced because the psychologists say that there are four apparent pure colors: \u201cThere are four stimuli which have a remarkable capacity to evoke psychologically simple blue, yellow, green, and red hues respectively. Unlike sienna, magenta, purple, or most of the discriminable colors, these simple hues are unmixed in the sense that none partakes of the nature of the other; specifically, blue is not yellowish, reddish, or greenish, and so on; these are psychologically primary hues.\u201d That is a psychological fact, so-called. To find out from what evidence this psychological fact was deduced, we must search very hard indeed through all the literature: In the modern literature all we find on the subject are repeats of the same statement, or of one by a German psychologist, who uses as one of his authorities Leonardo da Vinci, who, of course, we all know was a great artist. He says, \u201cLeonardo thought there were five colors.\u201d Then, looking still further, we find, in a still older book, the evidence for the subject. The book says something like this: \u201cPurple is reddish-blue, orange is reddish-yellow, but can red be seen as purplish-orange? Are not red and yellow more unitary than purple or orange? The average person, asked to state which colors are unitary, names red, yellow, and blue, these three, and some observers add a fourth, green. Psychologists are accustomed to accept the four as salient hues.\u201d So that is the situation in the psychological analysis of this matter: if everybody says there are three, and somebody says there are four, and they want it to be four, it will be four. That shows the difficulty with psychological researches. It is clear that we have such feelings, but it is very difficult to obtain much information about them. So the other direction to go is the physiological direction, to find out experimentally what actually happens in the brain, the eye, the retina, or wherever, and perhaps to discover that some combinations of impulses from various cells move along certain nerve fibers. Incidentally, primary pigments do not have to be in separate cells; one could have cells in which are mixtures of the various pigments, cells with the red and the green pigments, cells with all three (the information of all three is then white information), and so on. There are many ways of hooking the system up, and we have to find out which way nature has used. It would be hoped, ultimately, that when we understand the physiological connections we will have a little bit of understanding of some of those aspects of the psychology, so we look in that direction. We begin by talking not only about color vision, but about vision in general, just to remind ourselves about the interconnections in the retina, shown in Fig. 35\u20132. The retina is really like the surface of the brain. Although the actual picture through a microscope is a little more complicated looking than this somewhat schematized drawing, by careful analysis one can see all these interconnections. There is no question that one part of the surface of the retina is connected to other parts, and that the information that comes out on the long axons, which produce the optic nerve, are combinations of information from many cells. There are three layers of cells in the succession of function: there are retinal cells, which are the ones that the light affects, an intermediate cell which takes information from a single or a few retinal cells and gives it out again to several cells in a third layer of cells and carries it to the brain. There are all kinds of cross connections between cells in the layers. We now turn to some aspects of the structure and performance of the eye (see Fig. 35\u20131). The focusing of the light is accomplished mainly by the cornea, by the fact that it has a curved surface which \u201cbends\u201d the light. This is why we cannot see clearly under water, because we then do not have enough difference between the index of the cornea, which is 1.37 , and that of the water, which is 1.33 . Behind the cornea is water, practically, with an index of 1.33 , and behind that is a lens which has a very interesting structure: it is a series of layers, like an onion, except that it is all transparent, and it has an index of 1.40 in the middle and 1.38 at the outside. (It would be nice if we could make optical glass in which we could adjust the index throughout, for then we would not have to curve it as much as we do when we have a uniform index.) Furthermore, the shape of the cornea is not that of a sphere. A spherical lens has a certain amount of spherical aberration. The cornea is \u201cflatter\u201d at the outside than is a sphere, in just such a manner that the spherical aberration is less for the cornea than it would be if we put a spherical lens in there! The light is focused by the cornea-lens system onto the retina. As we look at things that are closer and farther away, the lens tightens and loosens and changes the focus to adjust for the different distances. To adjust for the total amount of light there is the iris, which is what we call the color of the eye, brown or blue, depending on who it is; as the amount of light increases and decreases, the iris moves in and out. Let us now look at the neural machinery for controlling the accommodation of the lens, the motion of the eye, the muscles which turn the eye in the socket, and the iris, shown schematically in Fig. 36\u20133. Of all the information that comes out of the optic nerve A , the great majority is divided into one of two bundles (which we will talk about later) and thence to the brain. But there are a few fibers, of interest to us now, which do not run directly to the visual cortex of the brain where we \u201csee\u201d the images, but instead go into the mid-brain H . These are the fibers which measure the average light and make adjustment for the iris; or, if the image looks foggy, they try to correct the lens; or, if there is a double image, they try to adjust the eye for binocular vision. At any rate, they go through the mid-brain and feed back into the eye. At K are the muscles which run the accommodation of the lens, and at L another one that runs into the iris. The iris has two muscle systems. One is a circular muscle L which, when it is excited, pulls in and closes down the iris; it acts very rapidly and the nerves are directly connected from the brain through short axons into the iris. The opposite muscles are radial muscles, so that, when the things get dark and the circular muscle relaxes, these radial muscles pull out. Here we have, as in many places in the body, a pair of muscles which work in opposite directions, and in almost every such case the nerve systems which control the two are very delicately adjusted, so that when signals are sent in to tighten one, signals are automatically sent in to loosen the other. The iris is a peculiar exception: the nerves which make the iris contract are the ones we have already described, but the nerves which make the iris expand come out from no one knows exactly where, go down into the spinal cord back of the chest, into the thoracic sections, out of the spinal cord, up through the neck ganglia, and all the way around and back up into the head in order to run the other end of the iris. In fact, the signal goes through a completely different nervous system, not the central nervous system at all, but the sympathetic nervous system, so it is a very strange way of making things go. We have already emphasized another strange thing about the eye, that the light-sensitive cells are on the wrong side, so that the light has to go through several layers of other cells before it gets to the receptors\u2014it is built inside out! So some of the features are wonderful and some are apparently stupid. Figure 36\u20134 shows the connections of the eye to the part of the brain which is most directly concerned with the visual process. The optic nerve fibers run into a certain area just beyond D , called the lateral geniculate, whereupon they run out to a section of the brain called the visual cortex. Notice that some of the fibers from each eye are sent over to the other side of the brain, so the picture formed is incomplete. The optic nerves from the left side of the right eye run across the optic chiasma B , while the ones on the left side of the left eye come around and go this same way. So the left side of the brain receives all the information which comes from the left side of the eyeball of each eye, i.e., on the right side of the visual field, while the right side of the brain sees the left side of the visual field. This is the manner in which the information from each of the two eyes is put together in order to tell how far away things are. This is the system of binocular vision. The connections between the retina and the visual cortex are interesting. If a spot in the retina is excised or destroyed in any way, then the whole fiber will die, and we can thereby find out where it is connected. It turns out that, essentially, the connections are one to one\u2014for each spot in the retina there is one spot in the visual cortex\u2014and spots that are very close together in the retina are very close together in the visual cortex. So the visual cortex still represents the spatial arrangement of the rods and cones, but of course much distorted. Things which are in the center of the field, which occupy a very small part of the retina, are expanded over many, many cells in the visual cortex. It is clear that it is useful to have things which are originally close together, still close together. The most remarkable aspect of the matter, however, is the following. The place where one would think it would be most important to have things close together would be right in the middle of the visual field. Believe it or not, the up-and-down line in our visual field as we look at something is of such a nature that the information from all the points on the right side of that line is going into the left side of the brain, and information from the points on the left side is going into the right side of the brain, and the way this area is made, there is a cut right down through the middle, so that the things that are very close together right in the middle are very far apart in the brain! Somehow, the information has to go from one side of the brain to the other through some other channels, which is quite surprising. The question of how this network ever gets \u201cwired\u201d together is very interesting. The problem of how much is already wired and how much is learned is an old one. It used to be thought long ago that perhaps it does not have to be wired carefully at all, it is only just roughly interconnected, and then, by experience, the young child learns that when a thing is \u201cup there\u201d it produces some sensation in the brain. (Doctors always tell us what the young child \u201cfeels,\u201d but how do they know what a child feels at the age of one?) The child, at the age of one, supposedly sees that an object is \u201cup there,\u201d gets a certain sensation, and learns to reach \u201cthere,\u201d because when he reaches \u201chere,\u201d it does not work. That approach probably is not correct, because we already see that in many cases there are these special detailed interconnections. More illuminating are some most remarkable experiments done with a salamander. (Incidentally, with the salamander there is a direct crossover connection, without the optic chiasma, because the eyes are on each side of the head and have no common area. Salamanders do not have binocular vision.) The experiment is this. We can cut the optic nerve in a salamander and the nerve will grow out from the eyes again. Thousands and thousands of cell fibers will thus re-establish themselves. Now, in the optic nerve the fibers do not stay adjacent to each other\u2014it is like a great, sloppily made telephone cable, all the fibers twisting and turning, but when it gets to the brain they are all sorted out again. When we cut the optic nerve of the salamander, the interesting question is, will it ever get straightened out? The answer is remarkable: yes. If we cut the optic nerve of the salamander and it grows back, the salamander has good visual acuity again. However, if we cut the optic nerve and turn the eye upside down and let it grow back again, it has good visual acuity all right, but it has a terrible error: when the salamander sees a fly \u201cup here,\u201d it jumps at it \u201cdown there,\u201d and it never learns. Therefore there is some mysterious way by which the thousands and thousands of fibers find their right places in the brain. This problem of how much is wired in, and how much is not, is an important problem in the theory of the development of creatures. The answer is not known, but is being studied intensively. The same experiment in the case of a goldfish shows that there is a terrible knot, like a great scar or complication, in the optic nerve where we cut it, but in spite of all this the fibers grow back to their right places in the brain. In order to do this, as they grow into the old channels of the optic nerve they must make several decisions about the direction in which they should grow. How do they do this? There seem to be chemical clues that different fibers respond to differently. Think of the enormous number of growing fibers, each of which is an individual differing in some way from its neighbors; in responding to whatever the chemical clues are, it responds in a unique enough way to find its proper place for ultimate connection in the brain! This is an interesting\u2014a fantastic\u2014thing. It is one of the great recently discovered phenomena of biology and is undoubtedly connected to many older unsolved problems of growth, organization, and development of organisms, and particularly of embryos. One other interesting phenomenon has to do with the motion of the eye. The eyes must be moved in order to make the two images coincide in different circumstances. These motions are of different kinds: one is to follow something, which requires that both eyes must go in the same direction, right or left, and the other is to point them toward the same place at various distances away, which requires that they must move oppositely. The nerves going into the muscles of the eye are already wired up for just such purposes. There is one set of nerves which will pull the muscles on the inside of one eye and the outside of the other, and relax the opposite muscles, so that the two eyes move together. There is another center where an excitation will cause the eyes to move in toward each other from parallel. Either eye can be turned out to the corner if the other eye moves toward the nose, but it is impossible consciously or unconsciously to turn both eyes out at the same time, not because there are no muscles, but because there is no way to send a signal to turn both eyes out, unless we have had an accident or there is something the matter, for instance if a nerve has been cut. Although the muscles of one eye can certainly steer that eye about, not even a Yogi is able to move both eyes out freely under voluntary control, because there does not seem to be any way to do it. We are already wired to a certain extent. This is an important point, because most of the earlier books on anatomy and psychology, and so on, do not appreciate or do not emphasize the fact that we are so completely wired already\u2014they say that everything is just learned. Let us now examine in more detail what happens in the rod cells. Figure 36\u20135 shows an electron micrograph of the middle of a rod cell (the rod cell keeps going up out of the field). There are layer after layer of plane structures, shown magnified at the right, which contain the substance rhodopsin (visual purple), the dye, or pigment, which produces the effects of vision in the rods. The rhodopsin, which is the pigment, is a big protein which contains a special group called retinene, which can be taken off the protein, and which is, undoubtedly, the main cause of the absorption of light. We do not understand the reason for the planes, but it is very likely that there is some reason for holding all the rhodopsin molecules parallel. The chemistry of the thing has been worked out to a large extent, but there might be some physics to it. It may be that all of the molecules are arranged in some kind of a row so that when one is excited an electron which is generated, say, may run all the way down to some place at the end to get the signal out, or something. This subject is very important, and has not been worked out. It is a field in which both biochemistry and solid state physics, or something like it, will ultimately be used. This kind of a structure, with layers, appears in other circumstances where light is important, for example in the chloroplast in plants, where the light causes photosynthesis. If we magnify those, we find the same thing with almost the same kind of layers, but there we have chlorophyll, of course, instead of retinene. The chemical form of retinene is shown in Fig. 36\u20136. It has a series of alternate double bonds along the side chain, which is characteristic of nearly all strongly absorbing organic substances, like chlorophyll, blood, and so on. This substance is impossible for human beings to manufacture in their own cells\u2014we have to eat it. So we eat it in the form of a special substance, which is exactly the same as retinene except that there is a hydrogen tied on the right end; it is called vitamin A, and if we do not eat enough of it, we do not get a supply of retinene, and the eye becomes what we call night blind, because there is then not enough pigment in the rhodopsin to see with the rods at night. The reason why such a series of double bonds absorbs light very strongly is also known. We may just give a hint: The alternating series of double bonds is called a conjugated double bond; a double bond means that there is an extra electron there, and this extra electron is easily shifted to the right or left. When light strikes this molecule, the electron of each double bond is shifted over by one step. All the electrons in the whole chain shift, like a string of dominoes falling over, and though each one moves only a little distance (we would expect that, in a single atom, we could move the electron only a little distance), the net effect is the same as though the one at the end was moved over to the other end! It is the same as though one electron went the whole distance back and forth, and so, in this manner, we get a much stronger absorption under the influence of the electric field, than if we could only move the electron a distance which is associated with one atom. So, since it is easy to move the electrons back and forth, retinene absorbs light very strongly; that is the machinery of the physical-chemical end of it. Let us now return to biology. The human eye is not the only kind of eye. In the vertebrates, almost all eyes are essentially like the human eye. However, in the lower animals there are many other kinds of eyes: eye spots, various eye cups, and other less sensitive things, which we have no time to discuss. But there is one other highly developed eye among the invertebrates, the compound eye of the insect. (Most insects having large compound eyes also have various additional simpler eyes as well.) A bee is an insect whose vision has been studied very carefully. It is easy to study the properties of the vision of bees because they are attracted to honey, and we can make experiments in which we identify the honey by putting it on blue paper or red paper, and see which one they come to. By this method some very interesting things have been discovered about the vision of the bee. In the first place, in trying to measure how acutely bees could see the color difference between two pieces of \u201cwhite\u201d paper, some researchers found they were not very good, and others found they were fantastically good. Even if the two pieces of white paper were almost exactly the same, the bees could still tell the difference. The experimenters used zinc white for one piece of paper and lead white for the other, and although these look exactly the same to us, the bee could easily distinguish them, because they reflect a different amount in the ultraviolet. In this way it was discovered that the bee\u2019s eye is sensitive over a wider range of the spectrum than is our own. Our eye works from 7000 angstroms to 4000 angstroms, from red to violet, but the bee\u2019s can see down to 3000 angstroms into the ultraviolet! This makes for a number of different interesting effects. In the first place, bees can distinguish between many flowers which to us look alike. Of course, we must realize that the colors of flowers are not designed for our eyes, but for the bee; they are signals to attract the bees to a specific flower. We all know that there are many \u201cwhite\u201d flowers. Apparently white is not very interesting to the bees, because it turns out that all of the white flowers have different proportions of reflection in the ultraviolet; they do not reflect one hundred percent of the ultraviolet as would a true white. All the light is not coming back, the ultraviolet is missing, and that is a color, just as, for us, if the blue is missing, it comes out yellow. So, all the flowers are colored for the bees. However, we also know that red cannot be seen by bees. Thus we might expect that all red flowers should look black to the bee. Not so! A careful study of red flowers shows, first, that even with our own eye we can see that a great majority of red flowers have a bluish tinge because they are mainly reflecting an additional amount in the blue, which is the part that the bee sees. Furthermore, experiments also show that flowers vary in their reflection of the ultraviolet over different parts of the petals, and so on. So if we could see the flowers as bees see them they would be even more beautiful and varied! It has been shown, however, that there are a few red flowers which do not reflect in the blue or in the ultraviolet, and would, therefore, appear black to the bee! This was of quite some concern to the people who worry about this matter, because black does not seem like an interesting color, since it is hard to tell from a dirty old shadow. It actually turned out that these flowers were not visited by bees, these are the flowers that are visited by hummingbirds, and hummingbirds can see the red! Another interesting aspect of the vision of the bee is that bees can apparently tell the direction of the sun by looking at a patch of blue sky, without seeing the sun itself. We cannot easily do this. If we look out the window at the sky and see that it is blue, in which direction is the sun? The bee can tell, because the bee is quite sensitive to the polarization of light, and the scattered light of the sky is polarized.2 There is still some debate about how this sensitivity operates. Whether it is because the reflections of the light are different in different circumstances, or the bee\u2019s eye is directly sensitive, is not yet known.3 It is also said that the bee can notice flicker up to 200 oscillations per second, while we see it only up to 20 . The motions of bees in the hives are very quick; the feet move and the wings vibrate, but it is very hard for us to see these motions with our eye. However, if we could see more rapidly we would be able to see the motion. It is probably very important to the bee that its eye has such a rapid response. Now let us discuss the visual acuity we could expect from the bee. The eye of a bee is a compound eye, and it is made of a large number of special cells called ommatidia, which are arranged conically on the surface of a sphere (roughly) on the outside of the bee\u2019s head. Figure 36\u20137 shows a picture of one such ommatidium. At the top there is a transparent area, a kind of \u201clens,\u201d but actually it is more like a filter or light pipe to make the light come down along the narrow fiber, which is where the absorption presumably occurs. Out of the other end of it comes the nerve fiber. The central fiber is surrounded on its sides by six cells which, in fact, have secreted the fiber. That is enough description for our purposes; the point is that it is a conical thing and many can fit next to each other all over the surface of the eye of the bee. Now let us discuss the resolution of the eye of the bee. If we draw lines (Fig. 36\u20138) to represent the ommatidia on the surface, which we suppose is a sphere of radius r , we may actually calculate how wide each ommatidium is by using our brains, and assuming that evolution is as clever as we are! If we have a very large ommatidium we do not have much resolution. That is, one cell gets a piece of information from one direction, and the adjacent cell gets a piece of information from another direction, and so on, and the bee cannot see things in between very well. So the uncertainty of visual acuity in the eye will surely correspond to an angle, the angle of the end of the ommatidium relative to the center of curvature of the eye. (The eye cells, of course, exist only at the surface of the sphere; inside that is the head of the bee.) This angle, from one ommatidium to the next, is, of course, the diameter of the ommatidia divided by the radius of the eye surface: \u0394\u03b8g=\u03b4/r. So, we may say, \u201cThe finer we make the \u03b4 , the more the visual acuity. So why doesn\u2019t the bee just use very, very fine ommatidia?\u201d Answer: We know enough physics to realize that if we are trying to get light down into a narrow slot, we cannot see accurately in a given direction because of the diffraction effect. The light that comes from several directions can enter and, due to diffraction, we will get light coming in at angle \u0394\u03b8d such that \u0394\u03b8d=\u03bb/\u03b4. Now we see that if we make the \u03b4 too small, then each ommatidium does not look in only one direction, because of diffraction! If we make them too big, each one sees in a definite direction, but there are not enough of them to get a good view of the scene. So we adjust the distance \u03b4 in order to make minimal the total effect of these two. If we add the two together, and find the place where the sum has a minimum (Fig. 36\u20139), we find that d(\u0394\u03b8g+\u0394\u03b8d) d\u03b4 =0= 1 r \u2212 \u03bb \u03b42 , which gives us a distance \u03b4= \u221a \u03bbr . If we guess that r is about 3 millimeters, take the light that the bee sees as 4000 angstroms, and put the two together and take the square root, we find \u03b4 =(3\u00d710\u22123\u00d74\u00d710\u22127)1/2 m =3.5\u00d710\u22125 m=35 \u03bcm. The book says the diameter is 30 \u03bc m, so that is rather good agreement! So, apparently, it really works, and we can understand what determines the size of the bee\u2019s eye! It is also easy to put the above number back in and find out how good the bee\u2019s eye actually is in angular resolution; it is very poor relative to our own. We can see things that are thirty times smaller in apparent size than the bee; the bee has a rather fuzzy out-of-focus image relative to what we can see. Nevertheless it is all right, and it is the best they can do. We might ask why the bees do not develop a good eye like our own, with a lens and so on. There are several interesting reasons. In the first place, the bee is too small; if it had an eye like ours, but on his scale, the opening would be about 30 \u03bc m in size and diffraction would be so important that it would not be able to see very well anyway. The eye is not good if it is too small. Secondly, if it were as big as the bee\u2019s head, then the eye would occupy the whole head of the bee. The beauty of the compound eye is that it takes up no space, it is just a very thin layer on the surface of the bee. So when we argue that they should have done it our way, we must remember that they had their own problems! Besides the bees, many other animals can see color. Fish, butterflies, birds, and reptiles can see color, but it is believed that most mammals cannot. The primates can see color. The birds certainly see color, and that accounts for the colors of birds. There would be no point in having such brilliantly colored males if the females could not notice it! That is, the evolution of the sexual \u201cwhatever it is\u201d that the birds have is a result of the female being able to see color. So next time we look at a peacock and think of what a brilliant display of gorgeous color it is, and how delicate all the colors are, and what a wonderful aesthetic sense it takes to appreciate all that, we should not compliment the peacock, but should compliment the visual acuity and aesthetic sense of the peahen, because that is what has generated the beautiful scene! All invertebrates have poorly developed eyes or compound eyes, but all the vertebrates have eyes very similar to our own, with one exception. If we consider the highest form of animal, we usually say, \u201cHere we are!,\u201d but if we take a less prejudiced point of view and restrict ourselves to the invertebrates, so that we cannot include ourselves, and ask what is the highest invertebrate animal, most zoologists agree that the octopus is the highest animal! It is very interesting that, besides the development of its brain and its reactions and so on, which are rather good for an invertebrate, it has also developed, independently, a different eye. It is not a compound eye or an eye spot\u2014it has a cornea, it has lids, it has an iris, it has a lens, it has two regions of water, it has a retina behind. It is essentially the same as the eye of the vertebrates! It is a remarkable example of a coincidence in evolution where nature has twice discovered the same solution to a problem, with one slight improvement. In the octopus it also turns out, amazingly, that the retina is a piece of the brain that has come out in the same way in its embryonic development as is true for vertebrates, but the interesting thing which is different is that the cells which are sensitive to light are on the inside, and the cells which do the calculation are in back of them, rather than \u201cinside out,\u201d as in our eye. So we see, at least, that there is no good reason for its being inside out. The other time nature tried it, she got it straightened out! (See Fig. 36\u201310.) The biggest eyes in the world are those of the giant squid; they have been found up to 15 inches in diameter! One of the main points of our subject is the interconnection of information from one part of the eye to the other. Let us consider the compound eye of the horseshoe crab, on which considerable experimentation has been done. First of all, we must appreciate what kind of information can come along nerves. A nerve carries a kind of disturbance which has an electrical effect that is easy to detect, a kind of wavelike disturbance which runs down the nerve and produces an effect at the other end: a long piece of the nerve cell, called the axon, carries the information along, and a certain kind of impulse, called a \u201cspike,\u201d goes along if it is excited at one end. When one spike goes down the nerve, another cannot immediately follow. All the spikes are of the same size, so it is not that we get higher spikes when the thing is more strongly excited, but that we get more spikes per second. The size of the spike is determined by the fiber. It is important to appreciate this in order to see what happens next. Figure 36\u201311(a) shows the compound eye of the horseshoe crab; it is not very much of an eye, it has only about a thousand ommatidia. Figure 36\u201311(b) is a cross section through the system; one can see the ommatidia, with the nerve fibers that run out of them and go into the brain. But note that even in a horseshoe crab there are little interconnections. They are much less elaborate than in the human eye, and it gives us a chance to study a simpler example. Let us now look at the experiments which have been done by putting fine electrodes into the optic nerve of the horseshoe crab, and shining light on only one of the ommatidia, which is easy to do with lenses. If we turn a light on at some instant t 0 , and measure the electrical pulses that come out, we find that there is a slight delay and then a rapid series of discharges which gradually slow down to a uniform rate, as shown in Fig. 36\u201312(a). When the light goes out, the discharge stops. Now it is very interesting that if, while our amplifier is connected to this same nerve fiber, we shine light on a different ommatidium nothing happens; no signal. Now we do another experiment: we shine the light on the original ommatidium and get the same response, but if we now turn light on another one nearby as well, the pulses are interrupted briefly and then run at a much lower rate (Fig. 36\u201312b). The rate of one is inhibited by the impulses which are coming out of the other! In other words, each nerve fiber carries the information from one ommatidium, but the amount that it carries is inhibited by the signals from the others. So, for example, if the whole eye is more or less uniformly illuminated, the information coming from any one ommatidium will be relatively weak, because it is inhibited by so many. In fact the inhibition is additive\u2014if we shine light on several nearby ommatidia the inhibition is very great. The inhibition is greater when the ommatidia are closer, and if the ommatidia are far enough away from one another, inhibition is practically zero. So it is additive and depends on the distance; here is a first example of information from different parts of the eye being combined in the eye itself. We can see, perhaps, if we think about it awhile, that this is a device to enhance contrast at the edges of objects, because if a part of the scene is light and a part is black, then the ommatidia in the lighted area give impulses that are inhibited by all the other light in the neighborhood, so it is relatively weak. On the other hand, an ommatidium at the boundary which is given a \u201cwhite\u201d impulse is also inhibited by others in the neighborhood, but there are not as many of them, since some are black; the net signal is therefore stronger. The result would be a curve, something like that of Fig. 36\u201313. The crab will see an enhancement of the contour. The fact that there is an enhancement of contours has long been known; in fact it is a remarkable thing that has been commented on by psychologists many times. In order to draw an object, we have only to draw its outline. How used we are to looking at pictures that have only the outline! What is the outline? The outline is only the edge difference between light and dark or one color and another. It is not something definite. It is not, believe it or not, that every object has a line around it! There is no such line. It is only in our own psychological makeup that there is a line; we are beginning to understand the reasons why the \u201cline\u201d is enough of a clue to get the whole thing. Presumably our own eye works in some similar manner\u2014much more complicated, but similar. Finally, we shall briefly describe the more elaborate work, the beautiful, advanced work that has been done on the frog. Doing a corresponding experiment on a frog, by putting very fine, beautifully built needlelike probes into the optic nerve of a frog, one can obtain the signals that are going along one particular axon and, just as in the case of the horseshoe crab, we find that the information does not depend on just one spot in the eye, but is a sum of information over several spots. The most recent picture of the operation of the frog\u2019s eye is the following. One can find four different kinds of optic nerve fibers, in the sense that there are four different kinds of responses. These experiments were not done by shining on-and-off impulses of light, because that is not what a frog sees. A frog just sits there and his eyes never move, unless the lily pad is flopping back and forth, and in that case his eyes wobble just right so that the image stays put. He does not turn his eyes. If anything moves in his field of vision, like a little bug (he has to be able to see something small moving in the fixed background), it turns out that there are four different kinds of fibers which discharge, whose properties are summarized in Table 36\u20131. Sustained edge detection, nonerasable, means that if we bring an object with an edge into the field of view of the frog, then there are a lot of impulses in this particular fiber while the object is moving, but they die down to a sustained impulse that continues as long as the edge is there, even if it is standing still. If we turn out the light, the impulses stop. If we turn it on again while the edge is still in view, they start again. They are not erasable. Another kind of fiber is very similar, except that if the edge is straight it does not work. It must be a convex edge with dark behind it! How complicated must be the system of interconnections in the retina of the eye of the frog in order for it to understand that a convex surface has moved in! Furthermore, although this fiber does sustain somewhat, it does not sustain as long as the other, and if we turn out the light and turn it on again it does not build up again. It depends on the moving in of the convex surface. The eye sees it move in and remembers that it is there, but if we merely turn out the light for a moment, it simply forgets it and no longer sees it. Another example is change-in-contrast detection. If there is an edge moving in or out there are pulses, but if the thing stands still there are no pulses at all. Then there is a dimming detector. If the light intensity is going down it creates pulses, but if it stays down or stays up, the impulse stops; it only works while the light is dimming. Then, finally, there are a few fibers which are dark detectors\u2014a most amazing thing\u2014they fire all the time! If we increase the light, they fire less rapidly, but all the time. If we decrease the light, they fire more rapidly, all the time. In the dark they fire like mad, perpetually saying, \u201cIt is dark! It is dark! It is dark!\u201d Now these responses seem to be rather complicated to classify, and we might wonder whether perhaps the experiments are being misinterpreted. But it is very interesting that these same classes are very clearly separated in the anatomy of the frog! By other measurements, after these responses had been classified (afterwards, that is what is important about this), it was discovered that the speed of the signals on the different fibers was not the same, so here was another, independent way to check which kind of a fiber we have found! Another interesting question is from how big an area is one particular fiber making its calculations? The answer is different for the different classes. Figure 36\u201314 shows the surface of the so-called tectum of a frog, where the nerves come into the brain from the optic nerve. All the nerve fibers coming in from the optic nerve make connections in various layers of the tectum. This layered structure is analogous to the retina; that is partly why we know that the brain and retina are very similar. Now, by taking an electrode and moving it down in succession through the layers, we can find out which kinds of optic nerves end where, and the beautiful and wonderful result is that the different kinds of fibers end in different layers! The first ones end in number 1 type, the second in number 2 , the threes and fives end in the same place, and deepest of all is number four. (What a coincidence, they got the numbers almost in the right order! No, that is why they numbered them that way, the first paper had the numbers in a different order!) We may briefly summarize what we have just learned this way: There are three pigments, presumably. There may be many different kinds of receptor cells containing the three pigments in different proportions, but there are many cross connections which may permit additions and subtractions through addition and reinforcement in the nervous system. So before we really understand color vision, we will have to understand the final sensation. This subject is still an open one, but these researches with microelectrodes and so on will perhaps ultimately give us more information on how we see color. bibliography Committee on Colorimetry, Optical Society of America, The Science of Color, Thomas Y. Crowell Company, New York, 1953. \u201cMechanisms of Vision,\u201d 2nd Supplement to Journal of General Physiology, Vol. 43, No. 6, Part 2, July 1960, Rockefeller Institute Press. specific articles: DeRobertis, E., \u201cSome Observations on the Ultrastructure and Morphogenesis of Photoreceptors,\u201d pp. 1\u201315. Hurvich, L. M. and D. Jameson, \u201cPerceived Color, Induction Effects, and Opponent-Response Mechanisms,\u201d pp. 63\u201380. Rosenblith, W. A., ed., Sensory Communication, Massachusetts Institute of Technology Press, Cambridge, Mass., 1961. \u201cSight, Sense of,\u201d Encyclopaedia Britannica, Vol. 20, 1957, pp. 628\u2014635."
    },
    {
        "input": "Space-Time",
        "output": "The theory of relativity shows us that the relationships of positions and times as measured in one coordinate system and another are not what we would have expected on the basis of our intuitive ideas. It is very important that we thoroughly understand the relations of space and time implied by the Lorentz transformation, and therefore we shall consider this matter more deeply in this chapter. The Lorentz transformation between the positions and times (x,y,z,t) as measured by an observer \u201cstanding still,\u201d and the corresponding coordinates and time ( x \u2032 , y \u2032 , z \u2032 , t \u2032 ) measured inside a \u201cmoving\u201d space ship, moving with velocity u are x \u2032 y \u2032 z \u2032 t \u2032 = x\u2212ut 1\u2212 u 2 / c 2 \u2212 \u2212 \u2212 \u2212 \u2212 \u2212 \u2212 \u2212 \u221a , =y, =z, = t\u2212ux/ c 2 1\u2212 u 2 / c 2 \u2212 \u2212 \u2212 \u2212 \u2212 \u2212 \u2212 \u2212 \u221a . (17.1) Let us compare these equations with Eq. (11.5), which also relates measurements in two systems, one of which in this instance is rotated relative to the other: x \u2032 y \u2032 z \u2032 =x =y =z cos\u03b8+y cos\u03b8\u2212x . sin\u03b8, sin\u03b8, (17.2) In this particular case, Moe and Joe are measuring with axes having an angle \u03b8 between the x \u2032 - and x -axes. In each case, we note that the \u201cprimed\u201d quantities are \u201cmixtures\u201d of the \u201cunprimed\u201d ones: the new x \u2032 is a mixture of x and y , and the new y \u2032 is also a mixture of x and y . An analogy is useful: When we look at an object, there is an obvious thing we might call the \u201capparent width,\u201d and another we might call the \u201cdepth.\u201d But the two ideas, width and depth, are not fundamental properties of the object, because if we step aside and look at the same thing from a different angle, we get a different width and a different depth, and we may develop some formulas for computing the new ones from the old ones and the angles involved. Equations (17.2) are these formulas. One might say that a given depth is a kind of \u201cmixture\u201d of all depth and all width. If it were impossible ever to move, and we always saw a given object from the same position, then this whole business would be irrelevant\u2014we would always see the \u201ctrue\u201d width and the \u201ctrue\u201d depth, and they would appear to have quite different qualities, because one appears as a subtended optical angle and the other involves some focusing of the eyes or even intuition; they would seem to be very different things and would never get mixed up. It is because we can walk around that we realize that depth and width are, somehow or other, just two different aspects of the same thing. Can we not look at the Lorentz transformations in the same way? Here also we have a mixture\u2014of positions and the time. A difference between a space measurement and a time measurement produces a new space measurement. In other words, in the space measurements of one man there is mixed in a little bit of the time, as seen by the other. Our analogy permits us to generate this idea: The \u201creality\u201d of an object that we are looking at is somehow greater (speaking crudely and intuitively) than its \u201cwidth\u201d and its \u201cdepth\u201d because they depend upon how we look at it; when we move to a new position, our brain immediately recalculates the width and the depth. But our brain does not immediately recalculate coordinates and time when we move at high speed, because we have had no effective experience of going nearly as fast as light to appreciate the fact that time and space are also of the same nature. It is as though we were always stuck in the position of having to look at just the width of something, not being able to move our heads appreciably one way or the other; if we could, we understand now, we would see some of the other man\u2019s time\u2014we would see \u201cbehind,\u201d so to speak, a little bit. Thus we shall try to think of objects in a new kind of world, of space and time mixed together, in the same sense that the objects in our ordinary space-world are real, and can be looked at from different directions. We shall then consider that objects occupying space and lasting for a certain length of time occupy a kind of a \u201cblob\u201d in a new kind of world, and that we look at this \u201cblob\u201d from different points of view when we are moving at different velocities. This new world, this geometrical entity in which the \u201cblobs\u201d exist by occupying position and taking up a certain amount of time, is called space-time. A given point (x,y,z,t) in space-time is called an event. Imagine, for example, that we plot the x -positions horizontally, y and z in two other directions, both mutually at \u201cright angles\u201d and at \u201cright angles\u201d to the paper (!), and time, vertically. Now, how does a moving particle, say, look on such a diagram? If the particle is standing still, then it has a certain x , and as time goes on, it has the same x , the same x , the same x ; so its \u201cpath\u201d is a line that runs parallel to the t -axis (Fig. 17\u20131 a). On the other hand, if it drifts outward, then as the time goes on x increases (Fig. 17\u20131 b). So a particle, for example, which starts to drift out and then slows up should have a motion something like that shown in Fig. 17\u20131(c). A particle, in other words, which is permanent and does not disintegrate is represented by a line in space-time. A particle which disintegrates would be represented by a forked line, because it would turn into two other things which would start from that point. What about light? Light travels at the speed c , and that would be represented by a line having a certain fixed slope (Fig. 17\u20131 d). Now according to our new idea, if a given event occurs to a particle, say if it suddenly disintegrates at a certain space-time point into two new ones which follow some new tracks, and this interesting event occurred at a certain value of x and a certain value of t , then we would expect that, if this makes any sense, we just have to take a new pair of axes and turn them, and that will give us the new t and the new x in our new system, as shown in Fig. 17\u20132(a). But this is wrong, because Eq. (17.1) is not exactly the same mathematical transformation as Eq. (17.2). Note, for example, the difference in sign between the two, and the fact that one is written in terms of cos\u03b8 and sin\u03b8 , while the other is written with algebraic quantities. (Of course, it is not impossible that the algebraic quantities could be written as cosine and sine, but actually they cannot.) But still, the two expressions are very similar. As we shall see, it is not really possible to think of space-time as a real, ordinary geometry because of that difference in sign. In fact, although we shall not emphasize this point, it turns out that a man who is moving has to use a set of axes which are inclined equally to the light ray, using a special kind of projection parallel to the x \u2032 - and t \u2032 -axes, for his x \u2032 and t \u2032 , as shown in Fig. 17\u20132(b). We shall not deal with the geometry, since it does not help much; it is easier to work with the equations. Although the geometry of space-time is not Euclidean in the ordinary sense, there is a geometry which is very similar, but peculiar in certain respects. If this idea of geometry is right, there ought to be some functions of coordinates and time which are independent of the coordinate system. For example, under ordinary rotations, if we take two points, one at the origin, for simplicity, and the other one somewhere else, both systems would have the same origin, and the distance from here to the other point is the same in both. That is one property that is independent of the particular way of measuring it. The square of the distance is x 2 + y 2 + z 2 . Now what about space-time? It is not hard to demonstrate that we have here, also, something which stays the same, namely, the combination c 2 t 2 \u2212 x 2 \u2212 y 2 \u2212 z 2 is the same before and after the transformation: c 2 t \u20322 \u2212 x \u20322 \u2212 y \u20322 \u2212 z \u20322 = c 2 t 2 \u2212 x 2 \u2212 y 2 \u2212 z 2 . (17.3) This quantity is therefore something which, like the distance, is \u201creal\u201d in some sense; it is called the interval between the two space-time points, one of which is, in this case, at the origin. (Actually, of course, it is the interval squared, just as x 2 + y 2 + z 2 is the distance squared.) We give it a different name because it is in a different geometry, but the interesting thing is only that some signs are reversed and there is a c in it. Let us get rid of the c ; that is an absurdity if we are going to have a wonderful space with x \u2019s and y \u2019s that can be interchanged. One of the confusions that could be caused by someone with no experience would be to measure widths, say, by the angle subtended at the eye, and measure depth in a different way, like the strain on the muscles needed to focus them, so that the depths would be measured in feet and the widths in meters. Then one would get an enormously complicated mess of equations in making transformations such as (17.2), and would not be able to see the clarity and simplicity of the thing for a very simple technical reason, that the same thing is being measured in two different units. Now in Eqs. (17.1) and (17.3) nature is telling us that time and space are equivalent; time becomes space; they should be measured in the same units. What distance is a \u201csecond\u201d? It is easy to figure out from (17.3) what it is. It is 3\u00d7 10 8 meters, the distance that light would go in one second. In other words, if we were to measure all distances and times in the same units, seconds, then our unit of distance would be 3\u00d7 10 8 meters, and the equations would be simpler. Or another way that we could make the units equal is to measure time in meters. What is a meter of time? A meter of time is the time it takes for light to go one meter, and is therefore 1/3\u00d7 10 \u22128 sec, or 3.3 billionths of a second! We would like, in other words, to put all our equations in a system of units in which c=1 . If time and space are measured in the same units, as suggested, then the equations are obviously much simplified. They are x \u2032 y \u2032 z \u2032 t \u2032 = x\u2212ut 1\u2212 u 2 \u2212 \u2212 \u2212 \u2212 \u2212 \u221a , =y, =z, = t\u2212ux 1\u2212 u 2 \u2212 \u2212 \u2212 \u2212 \u2212 \u221a . t \u20322 \u2212 x \u20322 \u2212 y \u20322 \u2212 z \u20322 = t 2 \u2212 x 2 \u2212 y 2 \u2212 z 2 . (17.4) (17.5) If we are ever unsure or \u201cfrightened\u201d that after we have this system with c=1 we shall never be able to get our equations right again, the answer is quite the opposite. It is much easier to remember them without the c \u2019s in them, and it is always easy to put the c \u2019s back, by looking after the dimensions. For instance, in 1\u2212 u 2 \u2212 \u2212 \u2212 \u2212 \u2212 \u221a , we know that we cannot subtract a velocity squared, which has units, from the pure number 1 , so we know that we must divide u 2 by c 2 in order to make that unitless, and that is the way it goes. The difference between space-time and ordinary space, and the character of an interval as related to the distance, is very interesting. According to formula (17.5), if we consider a point which in a given coordinate system had zero time, and only space, then the interval squared would be negative and we would have an imaginary interval, the square root of a negative number. Intervals can be either real or imaginary in the theory. The square of an interval may be either positive or negative, unlike distance, which has a positive square. When an interval is imaginary, we say that the two points have a space-like interval between them (instead of imaginary), because the interval is more like space than like time. On the other hand, if two objects are at the same place in a given coordinate system, but differ only in time, then the square of the time is positive and the distances are zero and the interval squared is positive; this is called a time-like interval. In our diagram of space-time, therefore, we would have a representation something like this: at 45 \u2218 there are two lines (actually, in four dimensions these will be \u201ccones,\u201d called light cones) and points on these lines are all at zero interval from the origin. Where light goes from a given point is always separated from it by a zero interval, as we see from Eq. (17.5). Incidentally, we have just proved that if light travels with speed c in one system, it travels with speed c in another, for if the interval is the same in both systems, i.e., zero in one and zero in the other, then to state that the propagation speed of light is invariant is the same as saying that the interval is zero. The space-time region surrounding a given space-time point can be separated into three regions, as shown in Fig. 17\u20133. In one region we have space-like intervals, and in two regions, time-like intervals. Physically, these three regions into which space-time around a given point is divided have an interesting physical relationship to that point: a physical object or a signal can get from a point in region 2 to the event O by moving along at a speed less than the speed of light. Therefore events in this region can affect the point O , can have an influence on it from the past. In fact, of course, an object at P on the negative t -axis is precisely in the \u201cpast\u201d with respect to O ; it is the same space-point as O , only earlier. What happened there then, affects O now. (Unfortunately, that is the way life is.) Another object at Q can get to O by moving with a certain speed less than c , so if this object were in a space ship and moving, it would be, again, the past of the same space-point. That is, in another coordinate system, the axis of time might go through both O and Q . So all points of region 2 are in the \u201cpast\u201d of O , and anything that happens in this region can affect O . Therefore region 2 is sometimes called the affective past, or affecting past; it is the locus of all events which can affect point O in any way. Region 3 , on the other hand, is a region which we can affect from O , we can \u201chit\u201d things by shooting \u201cbullets\u201d out at speeds less than c . So this is the world whose future can be affected by us, and we may call that the affective future. Now the interesting thing about all the rest of space-time, i.e., region 1 , is that we can neither affect it now from O , nor can it affect us now at O , because nothing can go faster than the speed of light. Of course, what happens at R can affect us later; that is, if the sun is exploding \u201cright now,\u201d it takes eight minutes before we know about it, and it cannot possibly affect us before then. What we mean by \u201cright now\u201d is a mysterious thing which we cannot define and we cannot affect, but it can affect us later, or we could have affected it if we had done something far enough in the past. When we look at the star Alpha Centauri, we see it as it was four years ago; we might wonder what it is like \u201cnow.\u201d \u201cNow\u201d means at the same time from our special coordinate system. We can only see Alpha Centauri by the light that has come from our past, up to four years ago, but we do not know what it is doing \u201cnow\u201d; it will take four years before what it is doing \u201cnow\u201d can affect us. Alpha Centauri \u201cnow\u201d is an idea or concept of our mind; it is not something that is really definable physically at the moment, because we have to wait to observe it; we cannot even define it right \u201cnow.\u201d Furthermore, the \u201cnow\u201d depends on the coordinate system. If, for example, Alpha Centauri were moving, an observer there would not agree with us because he would put his axes at an angle, and his \u201cnow\u201d would be a different time. We have already talked about the fact that simultaneity is not a unique thing. There are fortune tellers, or people who tell us they can know the future, and there are many wonderful stories about the man who suddenly discovers that he has knowledge about the affective future. Well, there are lots of paradoxes produced by that because if we know something is going to happen, then we can make sure we will avoid it by doing the right thing at the right time, and so on. But actually there is no fortune teller who can even tell us the present! There is no one who can tell us what is really happening right now, at any reasonable distance, because that is unobservable. We might ask ourselves this question, which we leave to the student to try to answer: Would any paradox be produced if it were suddenly to become possible to know things that are in the space-like intervals of region 1 ? Let us now return to our consideration of the analogy of the Lorentz transformation and rotations of the space axes. We have learned the utility of collecting together other quantities which have the same transformation properties as the coordinates, to form what we call vectors, directed lines. In the case of ordinary rotations, there are many quantities that transform the same way as x , y , and z under rotation: for example, the velocity has three components, an x , y , and z -component; when seen in a different coordinate system, none of the components is the same, instead they are all transformed to new values. But, somehow or other, the velocity \u201citself\u201d has a greater reality than do any of its particular components, and we represent it by a directed line. We therefore ask: Is it or is it not true that there are quantities which transform, or which are related, in a moving system and in a nonmoving system, in the same way as x , y , z , and t ? From our experience with vectors, we know that three of the quantities, like x , y , z , would constitute the three components of an ordinary space-vector, but the fourth quantity would look like an ordinary scalar under space rotation, because it does not change so long as we do not go into a moving coordinate system. Is it possible, then, to associate with some of our known \u201cthree-vectors\u201d a fourth object, that we could call the \u201ctime component,\u201d in such a manner that the four objects together would \u201crotate\u201d the same way as position and time in space-time? We shall now show that there is, indeed, at least one such thing (there are many of them, in fact): the three components of momentum, and the energy as the time component, transform together to make what we call a \u201cfour-vector.\u201d In demonstrating this, since it is quite inconvenient to have to write c \u2019s everywhere, we shall use the same trick concerning units of the energy, the mass, and the momentum, that we used in Eq. (17.4). Energy and mass, for example, differ only by a factor c 2 which is merely a question of units, so we can say energy is the mass. Instead of having to write the c 2 , we put E=m , and then, of course, if there were any trouble we would put in the right amounts of c so that the units would straighten out in the last equation, but not in the intermediate ones. Thus our equations for energy and momentum are E p =m= m 0 / 1\u2212 v 2 \u2212 \u2212 \u2212 \u2212 \u2212 \u221a , =mv= m 0 v/ 1\u2212 v 2 \u2212 \u2212 \u2212 \u2212 \u2212 \u221a . (17.6) Also in these units, we have E 2 \u2212 p 2 = m 2 0 . (17.7) For example, if we measure energy in electron volts, what does a mass of 1 electron volt mean? It means the mass whose rest energy is 1 electron volt, that is, m 0 c 2 is one electron volt. For example, the rest mass of an electron is 0.511\u00d7 10 6 eV. Now what would the momentum and energy look like in a new coordinate system? To find out, we shall have to transform Eq. (17.6), which we can do because we know how the velocity transforms. Suppose that, as we measure it, an object has a velocity v , but we look upon the same object from the point of view of a space ship which itself is moving with a velocity u , and in that system we use a prime to designate the corresponding thing. In order to simplify things at first, we shall take the case that the velocity v is in the direction of u . (Later, we can do the more general case.) What is v \u2032 , the velocity as seen from the space ship? It is the composite velocity, the \u201cdifference\u201d between v and u . By the law which we worked out before, v \u2032 = v\u2212u 1\u2212uv . (17.8) Now let us calculate the new energy E \u2032 , the energy as the fellow in the space ship would see it. He would use the same rest mass, of course, but he would use v \u2032 for the velocity. What we have to do is square v \u2032 , subtract it from one, take the square root, and take the reciprocal: v \u20322 1\u2212 v \u20322 = v 2 \u22122uv+ u 2 1\u22122uv+ u 2 v 2 , = 1\u22122uv+ u 2 v 2 \u2212 v 2 +2uv\u2212 u 2 1\u22122uv+ u 2 v 2 , = 1\u2212 v 2 \u2212 u 2 + u 2 v 2 1\u22122uv+ u 2 v 2 , = (1\u2212 v 2 )(1\u2212 u 2 ) (1\u2212uv ) 2 . Therefore 1 1\u2212 v \u20322 \u2212 \u2212 \u2212 \u2212 \u2212 \u2212 \u221a = 1\u2212uv 1\u2212 v 2 \u2212 \u2212 \u2212 \u2212 \u2212 \u221a 1\u2212 u 2 \u2212 \u2212 \u2212 \u2212 \u2212 \u221a . (17.9) The energy E \u2032 is then simply m 0 times the above expression. But we want to express the energy in terms of the unprimed energy and momentum, and we note that E \u2032 = m 0 \u2212 m 0 uv 1\u2212 v 2 \u2212 \u2212 \u2212 \u2212 \u2212 \u221a 1\u2212 u 2 \u2212 \u2212 \u2212 \u2212 \u2212 \u221a = ( m 0 / 1\u2212 v 2 \u2212 \u2212 \u2212 \u2212 \u2212 \u221a )\u2212( m 0 v/ 1\u2212 v 2 \u2212 \u2212 \u2212 \u2212 \u2212 \u221a )u 1\u2212 u 2 \u2212 \u2212 \u2212 \u2212 \u2212 \u221a , or E \u2032 = E\u2212u p x 1\u2212 u 2 \u2212 \u2212 \u2212 \u2212 \u2212 \u221a , (17.10) which we recognize as being exactly of the same form as t \u2032 = t\u2212ux 1\u2212 u 2 \u2212 \u2212 \u2212 \u2212 \u2212 \u221a . t Next we must find the new momentum p \u2032 x . This is just the energy E \u2032 times v \u2032 , and is also simply expressed in terms of E and p : p \u2032 x = E \u2032 v \u2032 = m 0 (1\u2212uv) 1\u2212 v 2 \u2212 \u2212 \u2212 \u2212 \u2212 \u221a 1\u2212 u 2 \u2212 \u2212 \u2212 \u2212 \u2212 \u221a \u22c5 v\u2212u (1\u2212uv) = m 0 v\u2212 m 0 u 1\u2212 v 2 \u2212 \u2212 \u2212 \u2212 \u2212 \u221a 1\u2212 u 2 \u2212 \u2212 \u2212 \u2212 \u2212 \u221a . Thus p \u2032 x = p x \u2212uE 1\u2212 u 2 \u2212 \u2212 \u2212 \u2212 \u2212 \u221a , (17.11) which we recognize as being of precisely the same form as x \u2032 = x\u2212ut 1\u2212 u 2 \u2212 \u2212 \u2212 \u2212 \u2212 \u221a . t Thus the transformations for the new energy and momentum in terms of the old energy and momentum are exactly the same as the transformations for t \u2032 in terms of t and x , and x \u2032 in terms of x and t : all we have to do is, every time we see t in (17.4) substitute E , and every time we see x substitute p x , and then the equations (17.4) will become the same as Eqs. (17.10) and (17.11). This would imply, if everything works right, an additional rule that p \u2032 y = p y and that p \u2032 z = p z . To prove this would require our going back and studying the case of motion up and down. Actually, we did study the case of motion up and down in the last chapter. We analyzed a complicated collision and we noticed that, in fact, the transverse momentum is not changed when viewed from a moving system; so we have already verified that p \u2032 y = p y and p \u2032 z = p z . The complete transformation, then, is p \u2032 x p \u2032 y p \u2032 z E \u2032 = p x \u2212uE 1\u2212 u 2 \u2212 \u2212 \u2212 \u2212 \u2212 \u221a , = p y , = p z , = E\u2212u p x 1\u2212 u 2 \u2212 \u2212 \u2212 \u2212 \u2212 \u221a . (17.12) In these transformations, therefore, we have discovered four quantities which transform like x , y , z , and t , and which we call the four-vector momentum. Since the momentum is a four-vector, it can be represented on a space-time diagram of a moving particle as an \u201carrow\u201d tangent to the path, as shown in Fig. 17\u20134. This arrow has a time component equal to the energy, and its space components represent its three-vector momentum; this arrow is more \u201creal\u201d than either the energy or the momentum, because those just depend on how we look at the diagram. The notation for four-vectors is different than it is for three-vectors. In the case of three-vectors, if we were to talk about the ordinary three-vector momentum we would write it p . If we wanted to be more specific, we could say it has three components which are, for the axes in question, p x , p y , and p z , or we could simply refer to a general component as p i , and say that i could either be x , y , or z , and that these are the three components; that is, imagine that i is any one of three directions, x , y , or z . The notation that we use for four-vectors is analogous to this: we write p \u03bc for the four-vector, and \u03bc stands for the four possible directions t , x , y , or z . We could, of course, use any notation we want; do not laugh at notations; invent them, they are powerful. In fact, mathematics is, to a large extent, invention of better notations. The whole idea of a four-vector, in fact, is an improvement in notation so that the transformations can be remembered easily. A \u03bc , then, is a general four-vector, but for the special case of momentum, the p t is identified as the energy, p x is the momentum in the x -direction, p y is that in the y -direction, and p z is that in the z -direction. To add four-vectors, we add the corresponding components. If there is an equation among four-vectors, then the equation is true for each component. For instance, if the law of conservation of three-vector momentum is to be true in particle collisions, i.e., if the sum of the momenta for a large number of interacting or colliding particles is to be a constant, that must mean that the sums of all momenta in the x -direction, in the y -direction, and in the z -direction, for all the particles, must each be constant. This law alone would be impossible in relativity because it is incomplete; it is like talking about only two of the components of a three-vector. It is incomplete because if we rotate the axes, we mix the various components, so we must include all three components in our law. Thus, in relativity, we must complete the law of conservation of momentum by extending it to include the time component. This is absolutely necessary to go with the other three, or there cannot be relativistic invariance. The conservation of energy is the fourth equation which goes with the conservation of momentum to make a valid four-vector relationship in the geometry of space and time. Thus the law of conservation of energy and momentum in four-dimensional notation is \u2211 particles in p \u03bc = \u2211 particles out p \u03bc (17.13) or, in a slightly different notation \u2211 i p i\u03bc = \u2211 j p j\u03bc , (17.14) where i=1 , 2 , \u2026 refers to the particles going into the collision, j=1 , 2 , \u2026 refers to the particles coming out of the collision, and \u03bc=x , y , z , or t . You say, \u201cIn which axes?\u201d It makes no difference. The law is true for each component, using any axes. In vector analysis we discussed one other thing, the dot product of two vectors. Let us now consider the corresponding thing in space-time. In ordinary rotation we discovered there was an unchanged quantity x 2 + y 2 + z 2 . In four dimensions, we find that the corresponding quantity is t 2 \u2212 x 2 \u2212 y 2 \u2212 z 2 (Eq. 17.3). How can we write that? One way would be to write some kind of four-dimensional thing with a square dot between, like A \u03bc \u22a1 B \u03bc ; one of the notations which is actually used is \u2211 \u2032 \u03bc A \u03bc A \u03bc = A 2 t \u2212 A 2 x \u2212 A 2 y \u2212 A 2 z . (17.15) The prime on \u2211 means that the first term, the \u201ctime\u201d term, is positive, but the other three terms have minus signs. This quantity, then, will be the same in any coordinate system, and we may call it the square of the length of the four-vector. For instance, what is the square of the length of the four-vector momentum of a single particle? This will be equal to p 2 t \u2212 p 2 x \u2212 p 2 y \u2212 p 2 z or, in other words, E 2 \u2212 p 2 , because we know that p t is E . What is E 2 \u2212 p 2 ? It must be something which is the same in every coordinate system. In particular, it must be the same for a coordinate system which is moving right along with the particle, in which the particle is standing still. If the particle is standing still, it would have no momentum. So in that coordinate system, it is purely its energy, which is the same as its rest mass. Thus E 2 \u2212 p 2 = m 2 0 . So we see that the square of the length of this vector, the four-vector momentum, is equal to m 2 0 . From the square of a vector, we can go on to invent the \u201cdot product,\u201d or the product which is a scalar: if a \u03bc is one four-vector and b \u03bc is another four-vector, then the scalar product is \u2211 \u2032 a \u03bc b \u03bc = a t b t \u2212 a x b x \u2212 a y b y \u2212 a z b z . (17.16) It is the same in all coordinate systems. Finally, we shall mention certain things whose rest mass m 0 is zero. A photon of light, for example. A photon is like a particle, in that it carries an energy and a momentum. The energy of a photon is a certain constant, called Planck\u2019s constant, times the frequency of the photon: E=h\u03bd . Such a photon also carries a momentum, and the momentum of a photon (or of any other particle, in fact) is h divided by the wavelength: p=h/\u03bb . But, for a photon, there is a definite relationship between the frequency and the wavelength: \u03bd=c/\u03bb . (The number of waves per second, times the wavelength of each, is the distance that the light goes in one second, which, of course, is c .) Thus we see immediately that the energy of a photon must be the momentum times c , or if c=1 , the energy and momentum are equal. That is to say, the rest mass is zero. Let us look at that again; that is quite curious. If it is a particle of zero rest mass, what happens when it stops? It never stops! It always goes at the speed c . The usual formula for energy is m 0 / 1\u2212 v 2 \u2212 \u2212 \u2212 \u2212 \u2212 \u221a . Now can we say that m 0 =0 and v=1 , so the energy is 0 ? We cannot say that it is zero; the photon really can (and does) have energy even though it has no rest mass, but this it possesses by perpetually going at the speed of light! We also know that the momentum of any particle is equal to its total energy times its velocity: if c=1 , p=vE or, in ordinary units, p=vE/ c 2 . For any particle moving at the speed of light, p=E if c=1 . The formulas for the energy of a photon as seen from a moving system are, of course, given by Eq. (17.12), but for the momentum we must substitute the energy divided by c (or by 1 in this case). The different energies after transformation means that there are different frequencies. This is called the Doppler effect, and one can calculate it easily from Eq. (17.12), using also E=p and E=h\u03bd . As Minkowski said, \u201cSpace of itself, and time of itself will sink into mere shadows, and only a kind of union between them shall survive.\u201d"
    },
    {
        "input": "The Magnetic Field in Various Situations",
        "output": "In this chapter we continue our discussion of magnetic fields associated with steady currents\u2014the subject of magnetostatics. The magnetic field is related to electric currents by our basic equations \u2207\u22c5B=0, c2\u2207\u00d7B= j \u03f50 . We want now to solve these equations mathematically in a general way, that is, without requiring any special symmetry or intuitive guessing. In electrostatics, we found that there was a straightforward procedure for finding the field when the positions of all electric charges are known: One simply works out the scalar potential \u03d5 by taking an integral over the charges\u2014as in Eq. (4.25). Then if one wants the electric field, it is obtained from the derivatives of \u03d5 . We will now show that there is a corresponding procedure for finding the magnetic field B if we know the current density j of all moving charges. In electrostatics we saw that (because the curl of E was always zero) it was possible to represent E as the gradient of a scalar field \u03d5 . Now the curl of B is not always zero, so it is not possible, in general, to represent it as a gradient. However, the divergence of B is always zero, and this means that we can always represent B as the curl of another vector field. For, as we saw in Section 2\u20137, the divergence of a curl is always zero. Thus we can always relate B to a field we will call A by B=\u2207\u00d7A. Or, by writing out the components, Bx =(\u2207\u00d7A)x = \u2202Az \u2202y \u2212 \u2202Ay \u2202z , By =(\u2207\u00d7A)y = \u2202Ax \u2202z \u2212 \u2202Az \u2202x , Bz =(\u2207\u00d7A)z = \u2202Ay \u2202x \u2212 \u2202Ax \u2202y . Writing B=\u2207\u00d7A guarantees that Eq. (14.1) is satisfied, since, necessarily, \u2207\u22c5B=\u2207\u22c5(\u2207\u00d7A)=0. The field A is called the vector potential. You will remember that the scalar potential \u03d5 was not completely specified by its definition. If we have found \u03d5 for some problem, we can always find another potential \u03d5\u2032 that is equally good by adding a constant: \u03d5\u2032=\u03d5+C. The new potential \u03d5\u2032 gives the same electric fields, since the gradient \u2207C is zero; \u03d5\u2032 and \u03d5 represent the same physics. Similarly, we can have different vector potentials A which give the same magnetic fields. Again, because B is obtained from A by differentiation, adding a constant to A doesn\u2019t change anything physical. But there is even more latitude for A . We can add to A any field which is the gradient of some scalar field, without changing the physics. We can show this as follows. Suppose we have an A that gives correctly the magnetic field B for some real situation, and ask in what circumstances some other new vector potential A\u2032 will give the same field B if substituted into (14.3). Then A and A\u2032 must have the same curl: B=\u2207\u00d7A\u2032=\u2207\u00d7A. Therefore \u2207\u00d7A\u2032\u2212\u2207\u00d7A=\u2207\u00d7(A\u2032\u2212A)=0. But if the curl of a vector is zero it must be the gradient of some scalar field, say \u03c8 , so A\u2032\u2212A=\u2207\u03c8 . That means that if A is a satisfactory vector potential for a problem then, for any \u03c8 , at all, A\u2032=A+\u2207\u03c8 will be an equally satisfactory vector potential, leading to the same field B . It is usually convenient to take some of the \u201clatitude\u201d out of A by arbitrarily placing some other condition on it (in much the same way that we found it convenient\u2014often\u2014to choose to make the potential \u03d5 zero at large distances). We can, for instance, restrict A by choosing arbitrarily what the divergence of A must be. We can always do that without affecting B . This is because although A\u2032 and A have the same curl, and give the same B , they do not need to have the same divergence. In fact, \u2207\u22c5A\u2032=\u2207\u22c5A+\u22072\u03c8 , and by a suitable choice of \u03c8 we can make \u2207\u22c5A\u2032 anything we wish. What should we choose for \u2207\u22c5A ? The choice should be made to get the greatest mathematical convenience and will depend on the problem we are doing. For magnetostatics, we will make the simple choice \u2207\u22c5A=0. (Later, when we take up electrodynamics, we will change our choice.) Our complete definition1 of A is then, for the moment, \u2207\u00d7A=B and \u2207\u22c5A=0 . To get some experience with the vector potential, let\u2019s look first at what it is for a uniform magnetic field B0 . Taking our z -axis in the direction of B0 , we must have Bx = \u2202Az \u2202y \u2212 \u2202Ay \u2202z =0, By = \u2202Ax \u2202z \u2212 \u2202Az \u2202x =0, Bz = \u2202Ay \u2202x \u2212 \u2202Ax \u2202y =B0. By inspection, we see that one possible solution of these equations is Ay=xB0,Ax=0,Az=0. Or we could equally well take Ax=\u2212yB0,Ay=0,Az=0. Still another solution is a linear combination of the two: Ax=\u2212 1 2 yB0,Ay= 1 2 xB0,Az=0. It is clear that for any particular field B , the vector potential A is not unique; there are many possibilities. The third solution, Eq. (14.8), has some interesting properties. Since the x -component is proportional to \u2212y and the y -component is proportional to +x , A must be at right angles to the vector from the z -axis, which we will call r \u2032 (the \u201cprime\u201d is to remind us that it is not the vector displacement from the origin). Also, the magnitude of A is proportional to x 2 + y 2 \u2212 \u2212 \u2212 \u2212 \u2212 \u2212 \u221a and, hence, to r \u2032 . So A can be simply written (for our uniform field) as A= 1 2 B 0 \u00d7 r \u2032 . (14.9) The vector potential A has the magnitude B 0 r \u2032 /2 and rotates about the z -axis as shown in Fig. 14\u20131. If, for example, the B field is the axial field inside a solenoid, then the vector potential circulates in the same sense as do the currents of the solenoid. The vector potential for a uniform field can be obtained in another way. The circulation of A on any closed loop \u0393 can be related to the surface integral of \u2207\u00d7A by Stokes\u2019 theorem, Eq. (3.38): \u222e \u0393 A\u22c5ds= \u222b inside \u0393 (\u2207\u00d7A)\u22c5nda. (14.10) But the integral on the right is equal to the flux of B through the loop, so \u222e \u0393 A\u22c5ds= \u222b inside \u0393 B\u22c5nda. (14.11) So the circulation of A around any loop is equal to the flux of B through the loop. If we take a circular loop, of radius r \u2032 in a plane perpendicular to a uniform field B , the flux is just \u03c0 r \u20322 B. \u2032 2 If we choose our origin on an axis of symmetry, so that we can take A as circumferential and a function only of r \u2032 , the circulation will be \u222eA\u22c5ds=2\u03c0 r \u2032 A=\u03c0 r \u20322 B. \u222e We get, as before, A= B r \u2032 2 . \u2032 In the example we have just given, we have calculated the vector potential from the magnetic field, which is opposite to what one normally does. In complicated problems it is usually easier to solve for the vector potential, and then determine the magnetic field from it. We will now show how this can be done. Since B is determined by currents, so also is A . We want now to find A in terms of the currents. We start with our basic equation (14.2): c 2 \u2207\u00d7B= j \u03f5 0 , j which means, of course, that c 2 \u2207\u00d7(\u2207\u00d7A)= j \u03f5 0 . (14.12) This equation is for magnetostatics what the equation \u2207\u22c5\u2207\u03d5=\u2212 \u03c1 \u03f5 0 (14.13) was for electrostatics. Our equation (14.12) for the vector potential looks even more like that for \u03d5 if we rewrite \u2207\u00d7(\u2207\u00d7A) using the vector identity Eq. (2.58): \u2207\u00d7(\u2207\u00d7A)=\u2207(\u2207\u22c5A)\u2212 \u2207 2 A. (14.14) Since we have chosen to make \u2207\u22c5A=0 (and now you see why), Eq. (14.12) becomes \u2207 2 A=\u2212 j \u03f5 0 c 2 . (14.15) This vector equation means, of course, three equations: \u2207 2 A x \u2207 2 A y \u2207 2 A z =\u2212 j x \u03f5 0 c 2 , =\u2212 j y \u03f5 0 c 2 , =\u2212 j z \u03f5 0 c 2 . (14.16) And each of these equations is mathematically identical to \u2207 2 \u03d5=\u2212 \u03c1 \u03f5 0 . (14.17) All we have learned about solving for potentials when \u03c1 is known can be used for solving for each component of A when j is known! We have seen in Chapter 4 that a general solution for the electrostatic equation (14.17) is \u03d5(1)= 1 4\u03c0 \u03f5 0 \u222b \u03c1(2)d V 2 r 12 . \u222b ( ) So we know immediately that a general solution for A x is A x (1)= 1 4\u03c0 \u03f5 0 c 2 \u222b j x (2)d V 2 r 12 , (14.18) and similarly for A y and A z . (Figure 14\u20132 will remind you of our conventions for r 12 and d V 2 .) We can combine the three solutions in the vector form A(1)= 1 4\u03c0 \u03f5 0 c 2 \u222b j(2)d V 2 r 12 , (14.19) (You can verify if you wish, by direct differentiation of components, that this integral for A satisfies \u2207\u22c5A=0 so long as \u2207\u22c5j=0 , which, as we saw, must happen for steady currents.) We have, then, a general method for finding the magnetic field of steady currents. The principle is: the x -component of vector potential arising from a current density j is the same as the electric potential \u03d5 that would be produced by a charge density \u03c1 equal to j x / c 2 \u2014and similarly for the y - and z -components. (This principle works only with components in fixed directions. The \u201cradial\u201d component of A does not come in the same way from the \u201cradial\u201d component of j , for example.) So from the vector current density j , we can find A using Eq. (14.19)\u2014that is, we find each component of A by solving three imaginary electrostatic problems for the charge distributions \u03c1 1 = j x / c 2 , \u03c1 2 = j y / c 2 , and \u03c1 3 = j z / c 2 . Then we get B by taking various derivatives of A to obtain \u2207\u00d7A . It\u2019s a little more complicated than electrostatics, but the same idea. We will now illustrate the theory by solving for the vector potential in a few special cases. For our first example, we will again find the field of a straight wire\u2014which we solved in the last chapter by using Eq. (14.2) and some arguments of symmetry. We take a long straight wire of radius a , carrying the steady current I . Unlike the charge on a conductor in the electrostatic case, a steady current in a wire is uniformly distributed throughout the cross section of the wire. If we choose our coordinates as shown in Fig. 14\u20133, the current density vector j has only a z -component. Its magnitude is j z = I \u03c0 a 2 (14.20) inside the wire, and zero outside. Since j x and j y are both zero, we have immediately A x =0, A y =0. A 0 A 0. To get A z we can use our solution for the electrostatic potential \u03d5 of a wire with a uniform charge density \u03c1= j z / c 2 . For points outside an infinite charged cylinder, the electrostatic potential is \u03d5=\u2212 \u03bb 2\u03c0 \u03f5 0 ln r \u2032 , \u03bb where r \u2032 = x 2 + y 2 \u2212 \u2212 \u2212 \u2212 \u2212 \u2212 \u221a and \u03bb is the charge per unit length, \u03c0 a 2 \u03c1 . So A z must be A z =\u2212 \u03c0 a 2 j z 2\u03c0 \u03f5 0 c 2 ln r \u2032 2 for points outside a long wire carrying a uniform current. Since \u03c0 a 2 j z =I , we can also write A z =\u2212 I 2\u03c0 \u03f5 0 c 2 ln r \u2032 (14.21) Now we can find B from (14.4). There are only two of the six derivatives that are not zero. We get B x B y B z =\u2212 = = I 2\u03c0 \u03f5 0 c 2 \u2202 \u2202y I 2\u03c0 \u03f5 0 c 2 \u2202 \u2202x 0 . ln r \u2032 =\u2212 ln r \u2032 = I 2\u03c0 \u03f5 0 c 2 y r \u20322 I 2\u03c0 \u03f5 0 c 2 x r \u20322 , , (14.22) (14.23) We get the same result as before: B circles around the wire, and has the magnitude B= 1 4\u03c0 \u03f5 0 c 2 2I r \u2032 . (14.24) Next, we consider again the infinitely long solenoid with a circumferential current on the surface of nI per unit length. (We imagine there are n turns of wire per unit length, carrying the current I , and we neglect the slight pitch of the winding.) Just as we have defined a \u201csurface charge density\u201d \u03c3 , we define here a \u201csurface current density\u201d J equal to the current per unit length on the surface of the solenoid (which is, of course, just the average j times the thickness of the thin winding). The magnitude of J is, here, nI . This surface current (see Fig. 14\u20134) has the components: J x =\u2212Jsin\u03d5, J y =Jcos\u03d5, J z =0. J J sin \u03d5 J J \u03d5 J 0. Now we must find A for such a current distribution. First, we wish to find A x for points outside the solenoid. The result is the same as the electrostatic potential outside a cylinder with a surface charge density \u03c3= \u03c3 0 sin\u03d5, sin \u03d5 with \u03c3 0 =\u2212J/ c 2 . We have not solved such a charge distribution, but we have done something similar. This charge distribution is equivalent to two solid cylinders of charge, one positive and one negative, with a slight relative displacement of their axes in the y -direction. The potential of such a pair of cylinders is proportional to the derivative with respect to y of the potential of a single uniformly charged cylinder. We could work out the constant of proportionality, but let\u2019s not worry about it for the moment. The potential of a cylinder of charge is proportional to ln r \u2032 ; the potential of the pair is then \u03d5\u221d \u2202ln r \u2032 \u2202y = y r \u20322 . \u2032 So we know that A x =\u2212K y r \u20322 , (14.25) where K is some constant. Following the same argument, we would find A y =K x r \u20322 . (14.26) Although we said before that there was no magnetic field outside a solenoid, we find now that there is an A -field which circulates around the z -axis, as in Fig. 14\u20134. The question is: Is its curl zero? Clearly, B x and B y are zero, and B z = \u2202 \u2202x (K x r \u20322 )\u2212 \u2202 \u2202y (\u2212K y r \u20322 ) =K( 1 r \u20322 \u2212 2 x 2 r \u20324 + 1 r \u20322 \u2212 2 y 2 r \u20324 )=0. So the magnetic field outside a very long solenoid is indeed zero, even though the vector potential is not. We can check our result against something else we know: The circulation of the vector potential around the solenoid should be equal to the flux of B inside the coil (Eq. 14.11). The circulation is A\u22c52\u03c0 r \u2032 or, since A=K/ r \u2032 , the circulation is 2\u03c0K . Notice that it is independent of r \u2032 . That is just as it should be if there is no B outside, because the flux is just the magnitude of B inside the solenoid times \u03c0 a 2 . It is the same for all circles of radius r \u2032 >a . We have found in the last chapter that the field inside is nI/ \u03f5 0 c 2 , so we can determine the constant K : 2\u03c0K=\u03c0 a 2 nI \u03f5 0 c 2 , I or K= nI a 2 2 \u03f5 0 c 2 . 2 So the vector potential outside has the magnitude A= nI a 2 2 \u03f5 0 c 2 1 r \u2032 , (14.27) and is always perpendicular to the vector r \u2032 . We have been thinking of a solenoidal coil of wire, but we would produce the same fields if we rotated a long cylinder with an electrostatic charge on the surface. If we have a thin cylindrical shell of radius a with a surface charge \u03c3 , rotating the cylinder makes a surface current J=\u03c3v , where v=a\u03c9 is the velocity of the surface charge. There will then be a magnetic field B=\u03c3a\u03c9/ \u03f5 0 c 2 inside the cylinder. Now we can raise an interesting question. Suppose we put a short piece of wire W perpendicular to the axis of the cylinder, extending from the axis out to the surface, and fastened to the cylinder so that it rotates with it, as in Fig. 14\u20135. This wire is moving in a magnetic field, so the v\u00d7B forces will cause the ends of the wire to be charged (they will charge up until the E -field from the charges just balances the v\u00d7B force). If the cylinder has a positive charge, the end of the wire at the axis will have a negative charge. By measuring the charge on the end of the wire, we could measure the speed of rotation of the system. We would have an \u201cangular-velocity meter\u201d! But are you wondering: \u201cWhat if I put myself in the frame of reference of the rotating cylinder? Then there is just a charged cylinder at rest, and I know that the electrostatic equations say there will be no electric fields inside, so there will be no force pushing charges to the center. So something must be wrong.\u201d But there is nothing wrong. There is no \u201crelativity of rotation.\u201d A rotating system is not an inertial frame, and the laws of physics are different. We must be sure to use equations of electromagnetism only with respect to inertial coordinate systems. It would be nice if we could measure the absolute rotation of the earth with such a charged cylinder, but unfortunately the effect is much too small to observe even with the most delicate instruments now available. Let\u2019s use the vector-potential method to find the magnetic field of a small loop of current. As usual, by \u201csmall\u201d we mean simply that we are interested in the fields only at distances large compared with the size of the loop. It will turn out that any small loop is a \u201cmagnetic dipole.\u201d That is, it produces a magnetic field like the electric field from an electric dipole. We take first a rectangular loop, and choose our coordinates as shown in Fig. 14\u20136. There are no currents in the z -direction, so A z is zero. There are currents in the x -direction on the two sides of length a . In each leg, the current density (and current) is uniform. So the solution for A x is just like the electrostatic potential from two charged rods (see Fig. 14\u20137). Since the rods have opposite charges, their electric potential at large distances would be just the dipole potential (Section 6\u20135). At the point P in Fig. 14\u20136, the potential would be \u03d5= 1 4\u03c0 \u03f5 0 p\u22c5 e R R 2 , (14.28) where p is the dipole moment of the charge distribution. The dipole moment, in this case, is the total charge on one rod times the separation between them: p=\u03bbab. (14.29) The dipole moment points in the negative y -direction, so the cosine of the angle between R and p is \u2212y/R (where y is the coordinate of P ). So we have \u03d5=\u2212 1 4\u03c0 \u03f5 0 \u03bbab R 2 y R . \u03bb b We get A x simply by replacing \u03bb by I/ c 2 : A x =\u2212 Iab 4\u03c0 \u03f5 0 c 2 y R 3 . (14.30) By the same reasoning, A y = Iab 4\u03c0 \u03f5 0 c 2 x R 3 . (14.31) Again, A y is proportional to x and A x is proportional to \u2212y , so the vector potential (at large distances) goes in circles around the z -axis, circulating in the same sense as I in the loop, as shown in Fig. 14\u20138. The strength of A is proportional to Iab , which is the current times the area of the loop. This product is called the magnetic dipole moment (or, often, just \u201cmagnetic moment\u201d) of the loop. We represent it by \u03bc : \u03bc=Iab. (14.32) The vector potential of a small plane loop of any shape (circle, triangle, etc.) is also given by Eqs. (14.30) and (14.31) provided we replace Iab by \u03bc=I\u22c5(area of the loop). (14.33) We leave the proof of this to you. We can put our equation in vector form if we define the direction of the vector \u03bc to be the normal to the plane of the loop, with a positive sense given by the right-hand rule (Fig. 14\u20138). Then we can write A= 1 4\u03c0 \u03f5 0 c 2 \u03bc\u00d7R R 3 = 1 4\u03c0 \u03f5 0 c 2 \u03bc\u00d7 e R R 2 . (14.34) We have still to find B . Using (14.33) and (14.34), together with (14.4), we get B x =\u2212 \u2202 \u2202z \u03bc 4\u03c0 \u03f5 0 c 2 x R 3 =\u22ef 3xz R 5 (14.35) (where by \u22ef we mean \u03bc/4\u03c0 \u03f5 0 c 2 ), B y B z = \u2202 \u2202z (\u2212\u22ef y R 3 )=\u22ef 3yz R 5 , = \u2202 \u2202x (\u22ef x R 3 )\u2212 \u2202 \u2202y (\u2212\u22ef y R 3 ) =\u2212\u22ef( 1 R 3 \u2212 3 z 2 R 5 ). (14.36) The components of the B -field behave exactly like those of the E -field for a dipole oriented along the z -axis. (See Eqs. (6.14) and (6.15); also Fig. 6\u20134.) That\u2019s why we call the loop a magnetic dipole. The word \u201cdipole\u201d is slightly misleading when applied to a magnetic field because there are no magnetic \u201cpoles\u201d that correspond to electric charges. The magnetic \u201cdipole field\u201d is not produced by two \u201ccharges,\u201d but by an elementary current loop. It is curious, though, that starting with completely different laws, \u2207\u22c5E=\u03c1/ \u03f5 0 and \u2207\u00d7B=j/ \u03f5 0 c 2 , we can end up with the same kind of a field. Why should that be? It is because the dipole fields appear only when we are far away from all charges or currents. So through most of the relevant space the equations for E and B are identical: both have zero divergence and zero curl. So they give the same solutions. However, the sources whose configuration we summarize by the dipole moments are physically quite different\u2014in one case, it\u2019s a circulating current; in the other, a pair of charges, one above and one below the plane of the loop for the corresponding field. We are often interested in the magnetic fields produced by circuits of wire in which the diameter of the wire is very small compared with the dimensions of the whole system. In such cases, we can simplify the equations for the magnetic field. For a thin wire we can write our volume element as dV=Sds d V S d where S is the cross-sectional area of the wire and ds is the element of distance along the wire. In fact, since the vector ds is in the same direction as j , as shown in Fig. 14\u20139 (and we can assume that j is constant across any given cross section), we can write a vector equation: jdV=jSds. (14.37) But jS is just what we call the current I in a wire, so our integral for the vector potential (14.19) becomes A(1)= 1 4\u03c0 \u03f5 0 c 2 \u222b Id s 2 r 12 (14.38) (see Fig. 14\u201310). (We assume that I is the same throughout the circuit. If there are several branches with different currents, we should, of course, use the appropriate I for each branch.) Again, we can find the fields from (14.38) either by integrating directly or by solving the corresponding electrostatic problems. In studying electrostatics we found that the electric field of a known charge distribution could be obtained directly with an integral, Eq. (4.16): E(1)= 1 4\u03c0 \u03f5 0 \u222b \u03c1(2) e 12 d V 2 r 2 12 . \u222b ( ) As we have seen, it is usually more work to evaluate this integral\u2014there are really three integrals, one for each component\u2014than to do the integral for the potential and take its gradient. There is a similar integral which relates the magnetic field to the currents. We already have an integral for A , Eq. (14.19); we can get an integral for B by taking the curl of both sides: B(1) =\u2207\u00d7A(1) =\u2207\u00d7[ 1 4\u03c0 \u03f5 0 c 2 \u222b j(2)d V 2 r 12 ]. (14.39) Now we must be careful: The curl operator means taking the derivatives of A(1) , that is, it operates only on the coordinates ( x 1 , y 1 , z 1 ) . We can move the \u2207\u00d7 operator inside the integral sign if we remember that it operates only on variables with the subscript 1 , which of course, appear only in r 12 =[( x 1 \u2212 x 2 ) 2 +( y 1 \u2212 y 2 ) 2 +( z 1 \u2212 z 2 ) 2 ] 1/2 . (14.40) We have, for the x -component of B , B x = \u2202 A z \u2202 y 1 \u2212 \u2202 A y \u2202 z 1 = 1 4\u03c0 \u03f5 0 c 2 \u222b[ j z \u2202 \u2202 y 1 ( 1 r 12 )\u2212 j y \u2202 \u2202 z 1 ( 1 r 12 )]d V 2 =\u2212 1 4\u03c0 \u03f5 0 c 2 \u222b[ j z y 1 \u2212 y 2 r 3 12 \u2212 j y z 1 \u2212 z 2 r 3 12 ]d V 2 . (14.41) The quantity in brackets is just the negative of the x -component of j\u00d7 r 12 r 3 12 = j\u00d7 e 12 r 2 12 j j Corresponding results will be found for the other components, so we have B(1)= 1 4\u03c0 \u03f5 0 c 2 \u222b j(2)\u00d7 e 12 r 2 12 d V 2 . (14.42) The integral gives B directly in terms of the known currents. The geometry involved is the same as that shown in Fig. 14\u20132. If the currents exist only in circuits of small wires we can, as in the last section, immediately do the integral across the wire, replacing jdV by Ids , where ds is an element of length of the wire. Then, using the symbols in Fig. 14\u201310, B(1)=\u2212 1 4\u03c0 \u03f5 0 c 2 \u222b I e 12 \u00d7d s 2 r 2 12 . (14.43) (The minus sign appears because we have reversed the order of the cross product.) This equation for B is called the Biot-Savart law, after its discoverers. It gives a formula for obtaining directly the magnetic field produced by wires carrying currents. You may wonder: \u201cWhat is the advantage of the vector potential if we can find B directly with a vector integral? After all, A also involves three integrals!\u201d Because of the cross product, the integrals for B are usually more complicated, as is evident from Eq. (14.41). Also, since the integrals for A are like those of electrostatics, we may already know them. Finally, we will see that in more advanced theoretical matters (in relativity, in advanced formulations of the laws of mechanics, like the principle of least action to be discussed later, and in quantum mechanics) the vector potential plays an important role."
    },
    {
        "input": "Color Vision",
        "output": "The phenomenon of colors depends partly on the physical world. We discuss the colors of soap films and so on as being produced by interference. But also, of course, it depends on the eye, or what happens behind the eye, in the brain. Physics characterizes the light that enters the eye, but after that, our sensations are the result of photochemical-neural processes and psychological responses. There are many interesting phenomena associated with vision which involve a mixture of physical phenomena and physiological processes, and the full appreciation of natural phenomena, as we see them, must go beyond physics in the usual sense. We make no apologies for making these excursions into other fields, because the separation of fields, as we have emphasized, is merely a human convenience, and an unnatural thing. Nature is not interested in our separations, and many of the interesting phenomena bridge the gaps between fields. In Chapter 3 we have already discussed the relation of physics to the other sciences in general terms, but now we are going to look in some detail at a specific field in which physics and other sciences are very, very closely interrelated. That area is vision. In particular, we shall discuss color vision. In the present chapter we shall discuss mainly the observable phenomena of human vision, and in the next chapter we shall consider the physiological aspects of vision, both in man and in other animals. It all begins with the eye; so, in order to understand what phenomena we see, some knowledge of the eye is required. In the next chapter we shall discuss in some detail how the various parts of the eye work, and how they are interconnected with the nervous system. For the present, we shall describe only briefly how the eye functions (Fig. 35\u20131). Light enters the eye through the cornea; we have already discussed how it is bent and is imaged on a layer called the retina in the back of the eye, so that different parts of the retina receive light from different parts of the visual field outside. The retina is not absolutely uniform: there is a place, a spot, in the center of our field of view which we use when we are trying to see things very carefully, and at which we have the greatest acuity of vision; it is called the fovea or macula. The side parts of the eye, as we can immediately appreciate from our experience in looking at things, are not as effective for seeing detail as is the center of the eye. There is also a spot in the retina where the nerves carrying all the information run out; that is a blind spot. There is no sensitive part of the retina here, and it is possible to demonstrate that if we close, say, the left eye and look straight at something, and then move a finger or another small object slowly out of the field of view it suddenly disappears somewhere. The only practical use of this fact that we know of is that some physiologist became quite a favorite in the court of a king of France by pointing this out to him; in the boring sessions that he had with his courtiers, the king could amuse himself by \u201ccutting off their heads\u201d by looking at one and watching another\u2019s head disappear. Figure 35\u20132 shows a magnified view of the inside of the retina in somewhat schematic form. In different parts of the retina there are different kinds of structures. The objects that occur more densely near the periphery of the retina are called rods. Closer to the fovea, we find, besides these rod cells, also cone cells. We shall describe the structure of these cells later. As we get close to the fovea, the number of cones increases, and in the fovea itself there are in fact nothing but cone cells, packed very tightly, so tightly that the cone cells are much finer, or narrower here than anywhere else. So we must appreciate that we see with the cones right in the middle of the field of view, but as we go to the periphery we have the other cells, the rods. Now the interesting thing is that in the retina each of the cells which is sensitive to light is not connected by a fiber directly to the optic nerve, but is connected to many other cells, which are themselves connected to each other. There are several kinds of cells: there are cells that carry the information toward the optic nerve, but there are others that are mainly interconnected \u201chorizontally.\u201d There are essentially four kinds of cells, but we shall not go into these details now. The main thing we emphasize is that the light signal is already being \u201cthought about.\u201d That is to say, the information from the various cells does not immediately go to the brain, spot for spot, but in the retina a certain amount of the information has already been digested, by a combining of the information from several visual receptors. It is important to understand that some brain-function phenomena occur in the eye itself. One of the most striking phenomena of vision is the dark adaptation of the eye. If we go into the dark from a brightly lighted room, we cannot see very well for a while, but gradually things become more and more apparent, and eventually we can see something where we could see nothing before. If the intensity of the light is very low, the things that we see have no color. It is known that this dark-adapted vision is almost entirely due to the rods, while the vision in bright light is due to the cones. As a result, there are a number of phenomena that we can easily appreciate because of this transfer of function from the cones and rods together, to just the rods. There are many situations in which, if the light intensity were stronger, we could see color, and we would find these things quite beautiful. One example is that through a telescope we nearly always see \u201cblack and white\u201d images of faint nebulae, but W. C. Miller of the Mt. Wilson and Palomar Observatories had the patience to make color pictures of some of these objects. Nobody has ever really seen these colors with the eye, but they are not artificial colors, it is merely that the light intensity is not strong enough for the cones in our eye to see them. Among the more spectacular such objects are the ring nebula and the Crab nebula. The former shows a beautiful blue inner part, with a bright red outer halo, and the latter shows a general bluish haze permeated by bright red-orange filaments. In the bright light, apparently, the rods are at very low sensitivity but, in the dark, as time goes on they pick up their ability to see light. The variations in light intensity for which one can adapt is over a million to one. Nature does not do all this with just one kind of cell, but she passes her job from bright-light-seeing cells, the color-seeing cells, the cones, to low-intensity, dark-adapted cells, the rods. Among the interesting consequences of this shift is, first, that there is no color, and second, that there is a difference in the relative brightness of differently colored objects. It turns out that the rods see better toward the blue than the cones do, and the cones can see, for example, deep red light, while the rods find that absolutely impossible to see. So red light is black so far as the rods are concerned. Thus two pieces of colored paper, say blue and red, in which the red might be even brighter than the blue in good light, will, in the dark, appear completely reversed. It is a very striking effect. If we are in the dark and can find a magazine or something that has colors and, before we know for sure what the colors are, we judge the lighter and darker areas, and if we then carry the magazine into the light, we may see this very remarkable shift between which was the brightest color and which was not. The phenomenon is called the Purkinje effect. In Fig. 35\u20133, the dashed curve represents the sensitivity of the eye in the dark, i.e., using the rods, while the solid curve represents it in the light. We see that the peak sensitivity of the rods is in the green region and that of the cones is more in the yellow region. If there is a red-colored page (red is about 650 m\u03bc) we can see it if it is brightly lighted, but in the dark it is almost invisible. Another effect of the fact that rods take over in the dark, and that there are no rods in the fovea, is that when we look straight at something in the dark, our vision is not quite as acute as when we look to one side. A faint star or nebula can sometimes be seen better by looking a little to one side than directly at it, because we do not have sensitive rods in the middle of the fovea. Another interesting effect of the fact that the number of cones decreases as we go farther to the side of the field of view is that even in a bright light color disappears as the object goes far to one side. The way to test that is to look in some particular fixed direction, let a friend walk in from one side with colored cards, and try to decide what color they are before they are right in front of you. One finds that he can see that the cards are there long before he can determine the color. When doing this, it is advisable to come in from the side opposite the blind spot, because it is otherwise rather confusing to almost see the color, then not see anything, then to see the color again. Another interesting phenomenon is that the periphery of the retina is very sensitive to motion. Although we cannot see very well from the corner of our eye, if a little bug moves and we do not expect anything to be moving over there, we are immediately sensitive to it. We are all \u201cwired up\u201d to look for something jiggling to the side of the field. Now we go to the cone vision, to the brighter vision, and we come to the question which is most characteristic of cone vision, and that is color. As we know, white light can be split by a prism into a whole spectrum of wavelengths which appear to us to have different colors; that is what colors are, of course: appearances. Any source of light can be analyzed by a grating or a prism, and one can determine the spectral distribution, i.e., the \u201camount\u201d of each wavelength. A certain light may have a lot of blue, considerable red, very little yellow, and so on. That is all very precise in the sense of physics, but the question is, what color will it appear to be? It is evident that the different colors depend somehow upon the spectral distribution of the light, but the problem is to find what characteristics of the spectral distribution produce the various sensations. For example, what do we have to do to get a green color? We all know that we can simply take a piece of the spectrum which is green. But is that the only way to get green, or orange, or any other color? Is there more than one spectral distribution which produces the same apparent visual effect? The answer is, definitely yes. There is a very limited number of visual effects, in fact just a three-dimensional manifold of them, as we shall shortly see, but there is an infinite number of different curves that we can draw for the light that comes from different sources. Now the question we have to discuss is, under what conditions do different distributions of light appear as exactly the same color to the eye? The most powerful psycho-physical technique in color judgment is to use the eye as a null instrument. That is, we do not try to define what constitutes a green sensation, or to measure in what circumstances we get a green sensation, because it turns out that this is extremely complicated. Instead, we study the conditions under which two stimuli are indistinguishable. Then we do not have to decide whether two people see the same sensation in different circumstances, but only whether, if for one person two sensations are the same, they are also the same for another. We do not have to decide whether, when one sees something green, what it feels like inside is the same as what it feels like inside someone else when he sees something green; we do not know anything about that. To illustrate the possibilities, we may use a series of four projector lamps which have filters on them, and whose brightnesses are continuously adjustable over a wide range: one has a red filter and makes a spot of red light on the screen, the next one has a green filter and makes a green spot, the third one has a blue filter, and the fourth one is a white circle with a black spot in the middle of it. Now if we turn on some red light, and next to it put some green, we see that in the area of overlap it produces a sensation which is not what we call reddish green, but a new color, yellow in this particular case. By changing the proportions of the red and the green, we can go through various shades of orange and so forth. If we have set it for a certain yellow, we can also obtain that same yellow, not by mixing these two colors but by mixing some other ones, perhaps a yellow filter with white light, or something like that, to get the same sensation. In other words, it is possible to make various colors in more than one way by mixing the lights from various filters. What we have just discovered may be expressed analytically as follows. A particular yellow, for example, can be represented by a certain symbol Y , which is the \u201csum\u201d of certain amounts of red-filtered light (R ) and green-filtered light (G ). By using two numbers, say r and g , to describe how bright the R and G are, we can write a formula for this yellow: Y=rR+gG. The question is, can we make all the different colors by adding together two or three lights of different, fixed colors? Let us see what can be done in that connection. We certainly cannot get all the different colors by mixing only red and green, because, for instance, blue never appears in such a mixture. However, by putting in some blue the central region, where all three spots overlap, may be made to appear to be a fairly nice white. By mixing the various colors and looking at this central region, we find that we can get a considerable range of colors in that region by changing the proportions, and so it is not impossible that all the colors can be made by mixing these three colored lights. We shall discuss to what extent this is true; it is in fact essentially correct, and we shall shortly see how to define the proposition better. In order to illustrate our point, we move the spots on the screen so that they all fall on top of each other, and then we try to match a particular color which appears in the annular ring made by the fourth lamp. What we once thought was \u201cwhite\u201d coming from the fourth lamp now appears yellowish. We may try to match that by adjusting the red and green and blue as best we can by a kind of trial and error, and we find that we can approach rather closely this particular shade of \u201ccream\u201d color. So it is not hard to believe that we can make all colors. We shall try to make yellow in a moment, but before we do that, there is one color that might be very hard to make. People who give lectures on color make all the \u201cbright\u201d colors, but they never make brown, and it is hard to recall ever having seen brown light. As a matter of fact, this color is never used for any stage effect, one never sees a spotlight with brown light; so we think it might be impossible to make brown. In order to find out whether it is possible to make brown, we point out that brown light is merely something that we are not used to seeing without its background. As a matter of fact, we can make it by mixing some red and yellow. To prove that we are looking at brown light, we merely increase the brightness of the annular background against which we see the very same light, and we see that that is, in fact, what we call brown! Brown is always a dark color next to a lighter background. We can easily change the character of the brown. For example, if we take some green out we get a reddish brown, apparently a chocolaty reddish brown, and if we put more green into it, in proportion, we get that horrible color which all the uniforms of the Army are made of, but the light from that color is not so horrible by itself; it is of yellowish green, but seen against a light background. Now we put a yellow filter in front of the fourth light and try to match that. (The intensity must of course be within the range of the various lamps; we cannot match something which is too bright, because we do not have enough power in the lamp.) But we can match the yellow; we use a green and red mixture, and put in a touch of blue to make it even more perfect. Perhaps we are ready to believe that, under good conditions, we can make a perfect match of any given color. Now let us discuss the laws of color mixture. In the first place, we found that different spectral distributions can produce the same color; next, we saw that \u201cany\u201d color can be made by adding together three special colors, red, blue, and green. The most interesting feature of color mixing is this: if we have a certain light, which we may call X , and if it appears indistinguishable from Y , to the eye (it may be a different spectral distribution, but it appears indistinguishable), we call these colors \u201cequal,\u201d in the sense that the eye sees them as equal, and we write X=Y. Here is one of the great laws of color: if two spectral distributions are indistinguishable, and we add to each one a certain light, say Z (if we write X+Z , this means that we shine both lights on the same patch), and then we take Y and add the same amount of the same other light, Z , the new mixtures are also indistinguishable: X+Z=Y+Z. We have just matched our yellow; if we now shine pink light on the whole thing, it will still match. So adding any other light to the matched lights leaves a match. In other words, we can summarize all these color phenomena by saying that once we have a match between two colored lights, seen next to each other in the same circumstances, then this match will remain, and one light can be substituted for the other light in any other color mixing situation. In fact, it turns out, and it is very important and interesting, that this matching of the color of lights is not dependent upon the characteristics of the eye at the moment of observation: we know that if we look for a long time at a bright red surface, or a bright red light, and then look at a white paper, it looks greenish, and other colors are also distorted by our having looked so long at the bright red. If we now have a match between, say, two yellows, and we look at them and make them match, then we look at a bright red surface for a long time, and then turn back to the yellow, it may not look yellow any more; I do not know what color it will look, but it will not look yellow. Nevertheless the yellows will still look matched, and so, as the eye adapts to various levels of intensity, the color match still works, with the obvious exception of when we go into the region where the intensity of the light gets so low that we have shifted from cones to rods; then the color match is no longer a color match, because we are using a different system. The second principle of color mixing of lights is this: any color at all can be made from three different colors, in our case, red, green, and blue lights. By suitably mixing the three together we can make anything at all, as we demonstrated with our two examples. Further, these laws are very interesting mathematically. For those who are interested in the mathematics of the thing, it turns out as follows. Suppose that we take our three colors, which were red, green, and blue, but label them A , B , and C , and call them our primary colors. Then any color could be made by certain amounts of these three: say an amount a of color A , an amount b of color B , and an amount c of color C makes X : X=aA+bB+cC. Now suppose another color Y is made from the same three colors: Y=a\u2032A+b\u2032B+c\u2032C. Then it turns out that the mixture of the two lights (it is one of the consequences of the laws that we have already mentioned) is obtained by taking the sum of the components of X and Y : Z=X+Y =(a+a\u2032)A+(b+b\u2032)B+(c+c\u2032)C. It is just like the mathematics of the addition of vectors, where (a,b,c) are the components of one vector, and (a\u2032,b\u2032,c\u2032) are those of another vector, and the new light Z is then the \u201csum\u201d of the vectors. This subject has always appealed to physicists and mathematicians. In fact, Schr\u00f6dinger wrote a wonderful paper on color vision in which he developed this theory of vector analysis as applied to the mixing of colors.1 Now a question is, what are the correct primary colors to use? There is no such thing as \u201cthe\u201d correct primary colors for the mixing of lights. There may be, for practical purposes, three paints that are more useful than others for getting a greater variety of mixed pigments, but we are not discussing that matter now. Any three differently colored lights whatsoever2 can always be mixed in the correct proportion to produce any color whatsoever. Can we demonstrate this fantastic fact? Instead of using red, green, and blue, let us use red, blue, and yellow in our projector. Can we use red, blue, and yellow to make, say, green? By mixing these three colors in various proportions, we get quite an array of different colors, ranging over quite a spectrum. But as a matter of fact, after a lot of trial and error, we find that nothing ever looks like green. The question is, can we make green? The answer is yes. How? By projecting some red onto the green, then we can make a match with a certain mixture of yellow and blue! So we have matched them, except that we had to cheat by putting the red on the other side. But since we have some mathematical sophistication, we can appreciate that what we really showed was not that X could always be made, say, of red, blue, and yellow, but by putting the red on the other side we found that red plus X could be made out of blue and yellow. Putting it on the other side of the equation, we can interpret that as a negative amount, so if we will allow that the coefficients in equations like (35.4) can be both positive and negative, and if we interpret negative amounts to mean that we have to add those to the other side, then any color can be matched by any three, and there is no such thing as \u201cthe\u201d fundamental primaries. We may ask whether there are three colors that come only with positive amounts for all mixings. The answer is no. Every set of three primaries requires negative amounts for some colors, and therefore there is no unique way to define a primary. In elementary books they are said to be red, green, and blue, but that is merely because with these a wider range of colors is available without minus signs for some of the combinations. Now let us discuss the combination of colors on a mathematical level as a geometrical proposition. If any one color is represented by Eq. (35.4), we can plot it as a vector in space by plotting along three axes the amounts a , b , and c , and then a certain color is a point. If another color is a\u2032 , b\u2032 , c\u2032 , that color is located somewhere else. The sum of the two, as we know, is the color which comes from adding these as vectors. We can simplify this diagram and represent everything on a plane by the following observation: if we had a certain color light, and merely doubled a and b and c , that is, if we make them all stronger in the same ratio, it is the same color, but brighter. So if we agree to reduce everything to the same light intensity, then we can project everything onto a plane, and this has been done in Fig. 35\u20134. It follows that any color obtained by mixing a given two in some proportion will lie somewhere on a line drawn between the two points. For instance, a fifty-fifty mixture would appear halfway between them, and 1/4 of one and 3/4 of the other would appear 1/4 of the way from one point to the other, and so on. If we use a blue and a green and a red, as primaries, we see that all the colors that we can make with positive coefficients are inside the dotted triangle, which contains almost all of the colors that we can ever see, because all the colors that we can ever see are enclosed in the oddly shaped area bounded by the curve. Where did this area come from? Once somebody made a very careful match of all the colors that we can see against three special ones. But we do not have to check all colors that we can see, we only have to check the pure spectral colors, the lines of the spectrum. Any light can be considered as a sum of various positive amounts of various pure spectral colors\u2014pure from the physical standpoint. A given light will have a certain amount of red, yellow, blue, and so on\u2014spectral colors. So if we know how much of each of our three chosen primaries is needed to make each of these pure components, we can calculate how much of each is needed to make our given color. So, if we find out what the color coefficients of all the spectral colors are for any given three primary colors, then we can work out the whole color mixing table. An example of such experimental results for mixing three lights together is given in Fig. 35\u20135. This figure shows the amount of each of three different particular primaries, red, green and blue, which is required to make each of the spectral colors. Red is at the left end of the spectrum, yellow is next, and so on, all the way to blue. Notice that at some points minus signs are necessary. It is from such data that it is possible to locate the position of all of the colors on a chart, where the x - and the y -coordinates are related to the amounts of the different primaries that are used. That is the way that the curved boundary line has been found. It is the locus of the pure spectral colors. Now any other color can be made by adding spectral lines, of course, and so we find that anything that can be produced by connecting one part of this curve to another is a color that is available in nature. The straight line connects the extreme violet end of the spectrum with the extreme red end. It is the locus of the purples. Inside the boundary are colors that can be made with lights, and outside it are colors that cannot be made with lights, and nobody has ever seen them (except, possibly, in after-images!). Now the next aspect of the matter is the question, why do colors behave in this way? The simplest theory, proposed by Young and Helmholtz, supposes that in the eye there are three different pigments which receive the light and that these have different absorption spectra, so that one pigment absorbs strongly, say, in the red, another absorbs strongly in the blue, another absorbs in the green. Then when we shine a light on them we will get different amounts of absorptions in the three regions, and these three pieces of information are somehow maneuvered in the brain or in the eye, or somewhere, to decide what the color is. It is easy to demonstrate that all of the rules of color mixing would be a consequence of this proposition. There has been considerable debate about the thing because the next problem, of course, is to find the absorption characteristics of each of the three pigments. It turns out, unfortunately, that because we can transform the color coordinates in any manner we want to, we can only find all kinds of linear combinations of absorption curves by the color-mixing experiments, but not the curves for the individual pigments. People have tried in various ways to obtain a specific curve which does describe some particular physical property of the eye. One such curve is called a brightness curve, demonstrated in Fig. 35\u20133. In this figure are two curves, one for eyes in the dark, the other for eyes in the light; the latter is the cone brightness curve. This is measured by finding what is the smallest amount of colored light we need in order to be able to just see it. This measures how sensitive the eye is in different spectral regions. There is another very interesting way to measure this. If we take two colors and make them appear in an area, by flickering back and forth from one to the other, we see a flicker if the frequency is too low. However, as the frequency increases, the flicker will ultimately disappear at a certain frequency that depends on the brightness of the light, let us say at 16 repetitions per second. Now if we adjust the brightness or the intensity of one color against the other, there comes an intensity where the flicker at 16 cycles disappears. To get flicker with the brightness so adjusted, we have to go to a much lower frequency in order to see a flicker of the color. So, we get what we call a flicker of the brightness at a higher frequency and, at a lower frequency, a flicker of the color. It is possible to match two colors for \u201cequal brightness\u201d by this flicker technique. The results are almost, but not exactly, the same as those obtained by measuring the threshold sensitivity of the eye for seeing weak light by the cones. Most workers use the flicker system as a definition of the brightness curve. Now, if there are three color-sensitive pigments in the eye, the problem is to determine the shape of the absorption spectrum of each one. How? We know there are people who are color blind\u2014eight percent of the male population, and one-half of one percent of the female population. Most of the people who are color blind or abnormal in color vision have a different degree of sensitivity than others to a variation of color, but they still need three colors to match. However, there are some who are called dichromats, for whom any color can be matched using only two primary colors. The obvious suggestion, then, is to say that they are missing one of the three pigments. If we can find three kinds of color-blind dichromats who have different color-mixing rules, one kind should be missing the red, another the green, and another the blue pigmentation. By measuring all these types we can determine the three curves! It turns out that there are three types of dichromatic color blindness; there are two common types and a third very rare type, and from these three it has been possible to deduce the pigment absorption spectra. Figure 35\u20136 shows the color mixing of a particular type of color-blind person called a deuteranope. For him, the loci of constant colors are not points, but certain lines, along each of which the color appears to him to be the same. If the theory that he is missing one of the three pieces of information is right, all these lines should intersect at a point. If we carefully measure on this graph, they do intersect perfectly. Obviously, therefore, this has been made by a mathematician and does not represent real data! As a matter of fact, if we look at the latest paper with real data, it turns out that in the graph of Fig. 35\u20136, the point of focus of all the lines is not exactly at the right place. Using the lines in the above figure, we cannot find reasonable spectra; we need negative and positive absorptions in different regions. But using the new data of Yustova, it turns out that each of the absorption curves is everywhere positive. Figure 35\u20137 shows a different kind of color blindness, that of the protanope, which has a focus near the red end of the boundary curve. Yustova gets approximately the same position in this case. Using the three different kinds of color blindness, the three pigment response curves have finally been determined, and are shown in Fig. 35\u20138. Finally? Perhaps. There is a question as to whether the three-pigment idea is right, whether color blindness results from lack of one pigment, and even whether the color-mix data on color blindness are right. Different workers get different results. This field is still very much under development. Now, what about checking these curves against actual pigments in the eye? The pigments that can be obtained from a retina consist mainly of a pigment called visual purple. The most remarkable features of this are, first, that it is in the eye of almost every vertebrate animal, and second, that its response curve fits beautifully with the sensitivity of the eye, as seen in Fig. 35\u20139, in which are plotted on the same scale the absorption of visual purple and the sensitivity of the dark-adapted eye. This pigment is evidently the pigment that we see with in the dark: visual purple is the pigment for the rods, and it has nothing to do with color vision. This fact was discovered in 1877. Even today it can be said that the color pigments of the cones have never been obtained in a test tube. In 1958 it could be said that the color pigments had never been seen at all. But since that time, two of them have been detected by Rushton by a very simple and beautiful technique. The trouble is, presumably, that since the eye is so weakly sensitive to bright light compared with light of low intensity, it needs a lot of visual purple to see with, but not much of the color pigments for seeing colors. Rushton\u2019s idea is to leave the pigment in the eye, and measure it anyway. What he does is this. There is an instrument called an ophthalmoscope for sending light into the eye through the lens and then focusing the light that comes back out. With it one can measure how much is reflected. So one measures the reflection coefficient of light which has gone twice through the pigment (reflected by a back layer in the eyeball, and coming out through the pigment of the cone again). Nature is not always so beautifully designed. The cones are interestingly designed so that the light that comes into the cone bounces around and works its way down into the little sensitive points at the apex. The light goes right down into the sensitive point, bounces at the bottom and comes back out again, having traversed a considerable amount of the color-vision pigment; also, by looking at the fovea, where there are no rods, one is not confused by visual purple. But the color of the retina has been seen a long time ago: it is a sort of orangey pink; then there are all the blood vessels, and the color of the material at the back, and so on. How do we know when we are looking at the pigment? Answer: First we take a color-blind person, who has fewer pigments and for whom it is therefore easier to make the analysis. Second, the various pigments, like visual purple, have an intensity change when they are bleached by light; when we shine light on them they change their concentration. So, while looking at the absorption spectrum of the eye, Rushton put another beam in the whole eye, which changes the concentration of the pigment, and he measured the change in the spectrum, and the difference, of course, has nothing to do with the amount of blood or the color of the reflecting layers, and so on, but only the pigment, and in this manner Rushton obtained a curve for the pigment of the protanope eye, which is given in Fig. 35\u201310. The second curve in Fig. 35\u201310 is a curve obtained with a normal eye. This was obtained by taking a normal eye and, having already determined what one pigment was, bleaching the other one in the red where the first one is insensitive. Red light has no effect on the protanope eye, but does in the normal eye, and thus one can obtain the curve for the missing pigment. The shape of one curve fits beautifully with Yustova\u2019s green curve, but the red curve is a little bit displaced. So perhaps we are getting on the right track. Or perhaps not\u2014the latest work with deuteranopes does not show any definite pigment missing. Color is not a question of the physics of the light itself. Color is a sensation, and the sensation for different colors is different in different circumstances. For instance, if we have a pink light, made by superimposing crossing beams of white light and red light (all we can make with white and red is pink, obviously), we may show that white light may appear blue. If we place an object in the beams, it casts two shadows\u2014one illuminated by the white light alone and the other by the red. For most people the \u201cwhite\u201d shadow of an object looks blue, but if we keep expanding this shadow until it covers the entire screen, we see that it suddenly appears white, not blue! We can get other effects of the same nature by mixing red, yellow, and white light. Red, yellow, and white light can produce only orangey yellows, and so on. So if we mix such lights roughly equally, we get only orange light. Nevertheless, by casting different kinds of shadows in the light, with various overlaps of colors, one gets quite a series of beautiful colors which are not in the light themselves (that is only orange), but in our sensations. We clearly see many different colors that are quite unlike the \u201cphysical\u201d ones in the beam. It is very important to appreciate that a retina is already \u201cthinking\u201d about the light; it is comparing what it sees in one region with what it sees in another, although not consciously. What we know of how it does that is the subject of the next chapter. bibliography Committee on Colorimetry, Optical Society of America, The Science of Color, Thomas Y. Crowell Company, New York, 1953. Hecht, S., S. Shlaer, and M. H. Pirenne, \u201cEnergy, Quanta, and Vision,\u201d Journal of General Physiology, 1942, 25, 819-840. Morgan, Clifford, and Eliot Stellar, Physiological Psychology, 2nd ed., McGraw-Hill Book Company, Inc., 1950. Nuberg, N. D. and E. N. Yustova, \u201cResearches on Dichromatic Vision and the Spectral Sensitivity of the Receptors of Trichromats,\u201d presented at Symposium No. 8, Visual Problems of Colour, Vol. II, National Physical Laboratory, Teddington, England, September 1957. Published by Her Majesty\u2019s Stationery Office, London, 1958. Rushton, W. A., \u201cThe Cone Pigments of the Human Fovea in Colour Blind and Normal,\u201d presented at Symposium No. 8, Visual Problems of Colour, Vol. I, National Physical Laboratory, Teddington, England, September 1957. Published by Her Majesty\u2019s Stationery Office, London, 1958. Woodworth, Robert S., Experimental Psychology, Henry Holt and Company, New York, 1938. Revised edition, 1954, by Robert S. Woodworth and H. Schlosberg."
    },
    {
        "input": "The Magnetism of Matter",
        "output": "In this chapter we are going to talk about the magnetic properties of materials. The material which has the most striking magnetic properties is, of course, iron. Similar magnetic properties are shared also by the elements nickel, cobalt, and\u2014at sufficiently low temperatures (below 16\u2218 C)\u2014by gadolinium, as well as by a number of peculiar alloys. That kind of magnetism, called ferromagnetism, is sufficiently striking and complicated that we will discuss it in a special chapter. However, all ordinary substances do show some magnetic effects, although very small ones\u2014a thousand to a million times less than the effects in ferromagnetic materials. Here we are going to describe ordinary magnetism, that is to say, the magnetism of substances other than the ferromagnetic ones. This small magnetism is of two kinds. Some materials are attracted toward magnetic fields; others are repelled. Unlike the electrical effect in matter, which always causes dielectrics to be attracted, there are two signs to the magnetic effect. These two signs can be easily shown with the help of a strong electromagnet which has one sharply pointed pole piece and one flat pole piece, as drawn in Fig. 34-1. The magnetic field is much stronger near the pointed pole than near the flat pole. If a small piece of material is fastened to a long string and suspended between the poles, there will, in general, be a small force on it. This small force can be seen by the slight displacement of the hanging material when the magnet is turned on. The few ferromagnetic materials are attracted very strongly toward the pointed pole; all other materials feel only a very weak force. Some are weakly attracted to the pointed pole; and some are weakly repelled. The effect is most easily seen with a small cylinder of bismuth, which is repelled from the high-field region. Substances which are repelled in this way are called diamagnetic. Bismuth is one of the strongest diamagnetic materials, but even with it, the effect is still quite weak. Diamagnetism is always very weak. If a small piece of aluminum is suspended between the poles, there is also a weak force, but toward the pointed pole. Substances like aluminum are called paramagnetic. (In such an experiment, eddy-current forces arise when the magnet is turned on and off, and these can give off strong impulses. You must be careful to look for the net displacement after the hanging object settles down.) We want now to describe briefly the mechanisms of these two effects. First, in many substances the atoms have no permanent magnetic moments, or rather, all the magnets within each atom balance out so that the net moment of the atom is zero. The electron spins and orbital motions all exactly balance out, so that any particular atom has no average magnetic moment. In these circumstances, when you turn on a magnetic field little extra currents are generated inside the atom by induction. According to Lenz\u2019s law, these currents are in such a direction as to oppose the increasing field. So the induced magnetic moments of the atoms are directed opposite to the magnetic field. This is the mechanism of diamagnetism. Then there are some substances for which the atoms do have a permanent magnetic moment\u2014in which the electron spins and orbits have a net circulating current that is not zero. So besides the diamagnetic effect (which is always present), there is also the possibility of lining up the individual atomic magnetic moments. In this case, the moments try to line up with the magnetic field (in the way the permanent dipoles of a dielectric are lined up by the electric field), and the induced magnetism tends to enhance the magnetic field. These are the paramagnetic substances. Paramagnetism is generally fairly weak because the lining-up forces are relatively small compared with the forces from the thermal motions which try to derange the order. It also follows that paramagnetism is usually sensitive to the temperature. (The paramagnetism arising from the spins of the electrons responsible for conduction in a metal constitutes an exception. We will not be discussing this phenomenon here.) For ordinary paramagnetism, the lower the temperature, the stronger the effect. There is more lining-up at low temperatures when the deranging effects of the collisions are less. Diamagnetism, on the other hand, is more or less independent of the temperature. In any substance with built-in magnetic moments there is a diamagnetic as well as a paramagnetic effect, but the paramagnetic effect usually dominates. In Chapter 11 we described a ferroelectric material, in which all the electric dipoles get lined up by their own mutual electric fields. It is also possible to imagine the magnetic analog of ferroelectricity, in which all the atomic moments would line up and lock together. If you make calculations of how this should happen, you will find that because the magnetic forces are so much smaller than the electric forces, thermal motions should knock out this alignment even at temperatures as low as a few tenths of a degree Kelvin. So it would be impossible at room temperature to have any permanent lining up of the magnets. On the other hand, this is exactly what does happen in iron\u2014it does get lined up. There is an effective force between the magnetic moments of the different atoms of iron which is much, much greater than the direct magnetic interaction. It is an indirect effect which can be explained only by quantum mechanics. It is about ten thousand times stronger than the direct magnetic interaction, and is what lines up the moments in ferromagnetic materials. We discuss this special interaction in a later chapter. Now that we have tried to give you a qualitative explanation of diamagnetism and paramagnetism, we must correct ourselves and say that it is not possible to understand the magnetic effects of materials in any honest way from the point of view of classical physics. Such magnetic effects are a completely quantum-mechanical phenomenon. It is, however, possible to make some phoney classical arguments and to get some idea of what is going on. We might put it this way. You can make some classical arguments and get guesses as to the behavior of the material, but these arguments are not \u201clegal\u201d in any sense because it is absolutely essential that quantum mechanics be involved in every one of these magnetic phenomena. On the other hand, there are situations, such as in a plasma or a region of space with many free electrons, where the electrons do obey the laws of classical mechanics. And in those circumstances, some of the theorems from classical magnetism are worthwhile. Also, the classical arguments are of some value for historical reasons. The first few times that people were able to guess at the meaning and behavior of magnetic materials, they used classical arguments. Finally, as we have already illustrated, classical mechanics can give us some useful guesses as to what might happen\u2014even though the really honest way to study this subject would be to learn quantum mechanics first and then to understand the magnetism in terms of quantum mechanics. On the other hand, we don\u2019t want to wait until we learn quantum mechanics inside out to understand a simple thing like diamagnetism. We will have to lean on the classical mechanics as kind of half showing what happens, realizing, however, that the arguments are really not correct. We therefore make a series of theorems about classical magnetism that will confuse you because they will prove different things. Except for the last theorem, every one of them will be wrong. Furthermore, they will all be wrong as a description of the physical world, because quantum mechanics is left out. The first theorem we want to prove from classical mechanics is the following: If an electron is moving in a circular orbit (for example, revolving around a nucleus under the influence of a central force), there is a definite ratio between the magnetic moment and the angular momentum. Let\u2019s call J the angular momentum and \u03bc the magnetic moment of the electron in the orbit. The magnitude of the angular momentum is the mass of the electron times the velocity times the radius. (See Fig. 34-2.) It is directed perpendicular to the plane of the orbit. J=mvr. (34.1) (This is, of course, a nonrelativistic formula, but it is a good approximation for atoms, because for the electrons involved v/c is generally of the order of e 2 /\u210fc\u22481/137 , or about 1 percent.) The magnetic moment of the same orbit is the current times the area. (See Section 14-5.) The current is the charge per unit time which passes any point on the orbit, namely, the charge q times the frequency of rotation. The frequency is the velocity divided by the circumference of the orbit; so I=q v 2\u03c0r . v The area is \u03c0 r 2 , so the magnetic moment is \u03bc= qvr 2 . (34.2) It is also directed perpendicular to the plane of the orbit. So J and \u03bc are in the same direction: \u03bc= q 2m J(orbit). (34.3) Their ratio depends neither on the velocity nor on the radius. For any particle moving in a circular orbit the magnetic moment is equal to q/2m times the angular momentum. For an electron, the charge is negative\u2014we can call it \u2212 q e ; so for an electron \u03bc=\u2212 q e 2m J(electron orbit). (34.4) That\u2019s what we would expect classically and, miraculously enough, it is also true quantum-mechanically. It\u2019s one of those things. However, if you keep going with the classical physics, you find other places where it gives the wrong answers, and it is a great game to try to remember which things are right and which things are wrong. We might as well give you immediately what is true in general in quantum mechanics. First, Eq. (34.4) is true for orbital motion, but that\u2019s not the only magnetism that exists. The electron also has a spin rotation about its own axis (something like the earth rotating on its axis), and as a result of that spin it has both an angular momentum and a magnetic moment. But for reasons that are purely quantum-mechanical\u2014there is no classical explanation\u2014the ratio of \u03bc to J for the electron spin is twice as large as it is for orbital motion of the spinning electron: \u03bc=\u2212 q e m J(electron spin). (34.5) In any atom there are, generally speaking, several electrons and some combination of spin and orbit rotations which builds up a total angular momentum and a total magnetic moment. Although there is no classical reason why it should be so, it is always true in quantum mechanics that (for an isolated atom) the direction of the magnetic moment is exactly opposite to the direction of the angular momentum. The ratio of the two is not necessarily either \u2212 q e /m or \u2212 q e /2m , but somewhere in between, because there is a mixture of the contributions from the orbits and the spins. We can write \u03bc=\u2212g( q e 2m )J, (34.6) where g is a factor which is characteristic of the state of the atom. It would be 1 for a pure orbital moment, or 2 for a pure spin moment, or some other number in between for a complicated system like an atom. This formula does not, of course, tell us very much. It says that the magnetic moment is parallel to the angular momentum, but can have any magnitude. The form of Eq. (34.6) is convenient, however, because g \u2014called the \u201cLand\u00e9 g -factor\u201d\u2014is a dimensionless constant whose magnitude is of the order of one. It is one of the jobs of quantum mechanics to predict the g -factor for any particular atomic state. You might also be interested in what happens in nuclei. In nuclei there are protons and neutrons which may move around in some kind of orbit and at the same time, like an electron, have an intrinsic spin. Again the magnetic moment is parallel to the angular momentum. Only now the order of magnitude of the ratio of the two is what you would expect for a proton going around in a circle, with m in Eq. (34.3) equal to the proton mass. Therefore it is usual to write for nuclei \u03bc=g( q e 2 m p )J, (34.7) where m p is the mass of the proton, and g \u2014called the nuclear g -factor\u2014is a number near one, to be determined for each nucleus. Another important difference for a nucleus is that the spin magnetic moment of the proton does not have a g -factor of 2 , as the electron does. For a proton, g=2\u22c5(2.79) . Surprisingly enough, the neutron also has a spin magnetic moment, and its magnetic moment relative to its angular momentum is 2\u22c5(\u22121.91) . The neutron, in other words, is not exactly \u201cneutral\u201d in the magnetic sense. It is like a little magnet, and it has the kind of magnetic moment that a rotating negative charge would have. One of the consequences of having the magnetic moment proportional to the angular momentum is that an atomic magnet placed in a magnetic field will precess. First we will argue classically. Suppose that we have the magnetic moment \u03bc suspended freely in a uniform magnetic field. It will feel a torque \u03c4 , equal to \u03bc\u00d7B , which tries to bring it in line with the field direction. But the atomic magnet is a gyroscope\u2014it has the angular momentum J . Therefore the torque due to the magnetic field will not cause the magnet to line up. Instead, the magnet will precess, as we saw when we analyzed a gyroscope in Chapter 20 of Volume I. The angular momentum\u2014and with it the magnetic moment\u2014precesses about an axis parallel to the magnetic field. We can find the rate of precession by the same method we used in Chapter 20 of the first volume. Suppose that in a small time \u0394t the angular momentum changes from J to J \u2032 , as drawn in Fig. 34-3, staying always at the same angle \u03b8 with respect to the direction of the magnetic field B . Let\u2019s call \u03c9 p the angular velocity of the precession, so that in the time \u0394t the angle of precession is \u03c9 p \u0394t . From the geometry of the figure, we see that the change of angular momentum in the time \u0394t is \u0394J=(Jsin\u03b8)( \u03c9 p \u0394t). ( \u03b8 ) ( ) So the rate of change of the angular momentum is dJ dt = \u03c9 p Jsin\u03b8, (34.8) which must be equal to the torque: \u03c4=\u03bcBsin\u03b8. (34.9) The angular velocity of precession is then \u03c9 p = \u03bc J B. (34.10) Substituting \u03bc/J from Eq. (34.6), we see that for an atomic system \u03c9 p =g q e B 2m ; (34.11) the precession frequency is proportional to B . It is handy to remember that for an atom (or electron) f p = \u03c9 p 2\u03c0 =(1.4 megacycles/gauss)gB, (34.12) and that for a nucleus f p = \u03c9 p 2\u03c0 =(0.76 kilocycles/gauss)gB. (34.13) (The formulas for atoms and nuclei are different only because of the different conventions for g for the two cases.) According to the classical theory, then, the electron orbits\u2014and spins\u2014in an atom should precess in a magnetic field. Is it also true quantum-mechanically? It is essentially true, but the meaning of the \u201cprecession\u201d is different. In quantum mechanics one cannot talk about the direction of the angular momentum in the same sense as one does classically; nevertheless, there is a very close analogy\u2014so close that we continue to call it \u201cprecession.\u201d We will discuss it later when we talk about the quantum-mechanical point of view. Next we want to look at diamagnetism from the classical point of view. It can be worked out in several ways, but one of the nice ways is the following. Suppose that we slowly turn on a magnetic field in the vicinity of an atom. As the magnetic field changes an electric field is generated by magnetic induction. From Faraday\u2019s law, the line integral of E around any closed path is the rate of change of the magnetic flux through the path. Suppose we pick a path \u0393 which is a circle of radius r concentric with the center of the atom, as shown in Fig. 34-4. The average tangential electric field E around this path is given by E2\u03c0r=\u2212 d dt (B\u03c0 r 2 ), d and there is a circulating electric field whose strength is E=\u2212 r 2 dB dt . d B The induced electric field acting on an electron in the atom produces a torque equal to \u2212 q e Er , which must equal the rate of change of the angular momentum dJ/dt : dJ dt = q e r 2 2 dB dt . (34.14) Integrating with respect to time from zero field, we find that the change in angular momentum due to turning on the field is \u0394J= q e r 2 2 B. (34.15) This is the extra angular momentum from the twist given to the electrons as the field is turned on. This added angular momentum makes an extra magnetic moment which, because it is an orbital motion, is just \u2212 q e /2m times the angular momentum. The induced diamagnetic moment is \u0394\u03bc=\u2212 q e 2m \u0394J=\u2212 q 2 e r 2 4m B. (34.16) The minus sign (as you can see is right by using Lenz\u2019s law) means that the added moment is opposite to the magnetic field. We would like to write Eq. (34.16) a little differently. The r 2 which appears is the radius from an axis through the atom parallel to B , so if B is along the z -direction, it is x 2 + y 2 . If we consider spherically symmetric atoms (or average over atoms with their natural axes in all directions) the average of x 2 + y 2 is 2/3 of the average of the square of the true radial distance from the center point of the atom. It is therefore usually more convenient to write Eq. (34.16) as \u0394\u03bc=\u2212 q 2 e 6m \u27e8 r 2 \u27e9 av B. (34.17) In any case, we have found an induced atomic moment proportional to the magnetic field B and opposing it. This is diamagnetism of matter. It is this magnetic effect that is responsible for the small force on a piece of bismuth in a nonuniform magnetic field. (You could compute the force by working out the energy of the induced moments in the field and seeing how the energy changes as the material is moved into or out of the high-field region.) We are still left with the problem: What is the mean square radius, \u27e8 r 2 \u27e9 av ? Classical mechanics cannot supply an answer. We must go back and start over with quantum mechanics. In an atom we cannot really say where an electron is, but only know the probability that it will be at some place. If we interpret \u27e8 r 2 \u27e9 av to mean the average of the square of the distance from the center for the probability distribution, the diamagnetic moment given by quantum mechanics is just the same as formula (34.17). This equation, of course, is the moment for one electron. The total moment is given by the sum over all the electrons in the atom. The surprising thing is that the classical argument and quantum mechanics give the same answer, although, as we shall see, the classical argument that gives Eq. (34.17) is not really valid in classical mechanics. The same diamagnetic effect occurs even when an atom already has a permanent moment. Then the system will precess in the magnetic field. As the whole atom precesses, it takes up an additional small angular velocity, and that slow turning gives a small current which represents a correction to the magnetic moment. This is just the diamagnetic effect represented in another way. But we don\u2019t really have to worry about that when we talk about paramagnetism. If the diamagnetic effect is first computed, as we have done here, we don\u2019t have to worry about the fact that there is an extra little current from the precession. That has already been included in the diamagnetic term. We can already conclude something from our results so far. First of all, in the classical theory the moment \u03bc was always proportional to J , with a given constant of proportionality for a particular atom. There wasn\u2019t any spin of the electrons, and the constant of proportionality was always \u2212 q e /2m ; that is to say, in Eq. (34.6) we should set g=1 . The ratio of \u03bc to J was independent of the internal motion of the electrons. Thus, according to the classical theory, all systems of electrons would precess with the same angular velocity. (This is not true in quantum mechanics.) This result is related to a theorem in classical mechanics that we would now like to prove. Suppose we have a group of electrons which are all held together by attraction toward a central point\u2014as the electrons are attracted by a nucleus. The electrons will also be interacting with each other, and can, in general, have complicated motions. Suppose you have solved for the motions with no magnetic field and then want to know what the motions would be with a weak magnetic field. The theorem says that the motion with a weak magnetic field is always one of the no-field solutions with an added rotation, about the axis of the field, with the angular velocity \u03c9 L = q e B/2m . (This is the same as \u03c9 p , if g=1 .) There are, of course, many possible motions. The point is that for every motion without the magnetic field there is a corresponding motion in the field, which is the original motion plus a uniform rotation. This is called Larmor\u2019s theorem, and \u03c9 L is called the Larmor frequency. We would like to show how the theorem can be proved, but we will let you work out the details. Take, first, one electron in a central force field. The force on it is just F(r) , directed toward the center. If we now turn on a uniform magnetic field, there is an additional force, qv\u00d7B ; so the total force is F(r)+qv\u00d7B. (34.18) Now let\u2019s look at the same system from a coordinate system rotating with angular velocity \u03c9 about an axis through the center of force and parallel to B . This is no longer an inertial system, so we have to put in the proper pseudo forces\u2014the centrifugal and Coriolis forces we talked about in Chapter 19 of Volume I. We found there that in a frame rotating with angular velocity \u03c9 , there is an apparent tangential force proportional to v r , the radial component of velocity: F t =\u22122m\u03c9 v r . (34.19) And there is an apparent radial force which is given by F r =m \u03c9 2 r+2m\u03c9 v t , (34.20) where v t is the tangential component of the velocity, measured in the rotating frame. (The radial component v r for rotating and inertial frames is the same.) Now for small enough angular velocities (that is, if \u03c9r\u226a v t ), we can neglect the first term (centrifugal) in Eq. (34.20) in comparison with the second (Coriolis). Then Eqs. (34.19) and (34.20) can be written together as F=\u22122m\u03c9\u00d7v. (34.21) If we now combine a rotation and a magnetic field, we must add the force in Eq. (34.21) to that in Eq. (34.18). The total force is F(r)+qv\u00d7B+2mv\u00d7\u03c9 (34.22) [we reverse the cross product and the sign of Eq. (34.21) to get the last term]. Looking at our result, we see that if 2m\u03c9=\u2212qB 2 B the two terms on the right cancel, and in the moving frame the only force is F(r) . The motion of the electron is just the same as with no magnetic field\u2014and, of course, no rotation. We have proved Larmor\u2019s theorem for one electron. Since the proof assumes a small \u03c9 , it also means that the theorem is true only for weak magnetic fields. The only thing we could ask you to improve on is to take the case of many electrons mutually interacting with each other, but all in the same central field, and prove the same theorem. So no matter how complex an atom is, if it has a central field the theorem is true. But that\u2019s the end of the classical mechanics, because it isn\u2019t true in fact that the motions precess in that way. The precession frequency \u03c9 p of Eq. (34.11) is only equal to \u03c9 L if g happens to be equal to 1 . Now we would like to demonstrate that according to classical mechanics there can be no diamagnetism and no paramagnetism at all. It sounds crazy\u2014first, we have proved that there are paramagnetism, diamagnetism, precessing orbits, and so on, and now we are going to prove that it is all wrong. Yes!\u2014We are going to prove that if you follow the classical mechanics far enough, there are no such magnetic effects\u2014they all cancel out. If you start a classical argument in a certain place and don\u2019t go far enough, you can get any answer you want. But the only legitimate and correct proof shows that there is no magnetic effect whatever. It is a consequence of classical mechanics that if you have any kind of system\u2014a gas with electrons, protons, and whatever\u2014kept in a box so that the whole thing can\u2019t turn, there will be no magnetic effect. It is possible to have a magnetic effect if you have an isolated system, like a star held together by itself, which can start rotating when you put on the magnetic field. But if you have a piece of material that is held in place so that it can\u2019t start spinning, then there will be no magnetic effects. What we mean by holding down the spin is summarized this way: At a given temperature we suppose that there is only one state of thermal equilibrium. The theorem then says that if you turn on a magnetic field and wait for the system to get into thermal equilibrium, there will be no paramagnetism or diamagnetism\u2014there will be no induced magnetic moment. Proof: According to statistical mechanics, the probability that a system will have any given state of motion is proportional to e \u2212U/kT , where U is the energy of that motion. Now what is the energy of motion? For a particle moving in a constant magnetic field, the energy is the ordinary potential energy plus m v 2 /2 , with nothing additional for the magnetic field. [You know that the forces from electromagnetic fields are q(E+v\u00d7B) , and that the rate of work F\u22c5v is just qE\u22c5v , which is not affected by the magnetic field.] So the energy of a system, whether it is in a magnetic field or not, is always given by the kinetic energy plus the potential energy. Since the probability of any motion depends only on the energy\u2014that is, on the velocity and position\u2014it is the same whether or not there is a magnetic field. For thermal equilibrium, therefore, the magnetic field has no effect. If we have one system in a box, and then have another system in a second box, this time with a magnetic field, the probability of any particular velocity at any point in the first box is the same as in the second. If the first box has no average circulating current (which it will not have if it is in equilibrium with the stationary walls), there is no average magnetic moment. Since in the second box all the motions are the same, there is no average magnetic moment there either. Hence, if the temperature is kept constant and thermal equilibrium is re-established after the field is turned on, there can be no magnetic moment induced by the field\u2014according to classical mechanics. We can only get a satisfactory understanding of magnetic phenomena from quantum mechanics. Unfortunately, we cannot assume that you have a thorough understanding of quantum mechanics, so this is hardly the place to discuss the matter. On the other hand, we don\u2019t always have to learn something first by learning the exact rules and then by learning how they are applied in different cases. Almost every subject that we have taken up in this course has been treated in a different way. In the case of electricity, we wrote the Maxwell equations on \u201cPage One\u201d and then deduced all the consequences. That\u2019s one way. But we will not now try to begin a new \u201cPage One,\u201d writing the equations of quantum mechanics and deducing everything from them. We will just have to tell you some of the consequences of quantum mechanics, before you learn where they come from. So here we go. We have already given you a relation between the magnetic moment and the angular momentum. That\u2019s pleasant. But what do the magnetic moment and the angular momentum mean in quantum mechanics? In quantum mechanics it turns out to be best to define things like magnetic moments in terms of the other concepts such as energy, in order to make sure that one knows what it means. Now, it is easy to define a magnetic moment in terms of energy, because the energy of a moment in a magnetic field is, in the classical theory, \u03bc\u22c5B . Therefore, the following definition has been taken in quantum mechanics: If we calculate the energy of a system in a magnetic field and we find that it is proportional to the field strength (for small field), the coefficient is called the component of magnetic moment in the direction of the field. (We don\u2019t have to get so elegant for our work now; we can still think of the magnetic moment in the ordinary, to some extent classical, sense.) Now we would like to discuss the idea of angular momentum in quantum mechanics\u2014or rather, the characteristics of what, in quantum mechanics, is called angular momentum. You see, when you go to new kinds of laws, you can\u2019t just assume that each word is going to mean exactly the same thing. You may think, say, \u201cOh, I know what angular momentum is. It\u2019s that thing that is changed by a torque.\u201d But what\u2019s a torque? In quantum mechanics we have to have new definitions of old quantities. It would, therefore, be legally best to call it by some other name such as \u201cquantangular momentum,\u201d or something like that, because it is the angular momentum as defined in quantum mechanics. But if we can find a quantity in quantum mechanics which is identical to our old idea of angular momentum when the system becomes large enough, there is no use in inventing an extra word. We might as well just call it angular momentum. With that understanding, this odd thing that we are about to describe is angular momentum. It is the thing which in a large system we recognize as angular momentum in classical mechanics. First, we take a system in which angular momentum is conserved, such as an atom all by itself in empty space. Now such a thing (like the earth spinning on its axis) could, in the ordinary sense, be spinning around any axis one wished to choose. And for a given spin, there could be many different \u201cstates,\u201d all of the same energy, each \u201cstate\u201d corresponding to a particular direction of the axis of the angular momentum. So in the classical theory, with a given angular momentum, there is an infinite number of possible states, all of the same energy. It turns out in quantum mechanics, however, that several strange things happen. First, the number of states in which such a system can exist is limited\u2014there is only a finite number. If the system is small, the finite number is very small, and if the system is large, the finite number gets very, very large. Second, we cannot describe a \u201cstate\u201d by giving the direction of its angular momentum, but only by giving the component of the angular momentum along some direction\u2014say in the z -direction. Classically, an object with a given total angular momentum J could have, for its z -component, any value from +J to \u2212J . But quantum-mechanically, the z -component of angular momentum can have only certain discrete values. Any given system\u2014a particular atom, or a nucleus, or anything\u2014with a given energy, has a characteristic number j , and its z -component of angular momentum can only be one of the following set of values: j\u210f (j\u22121)\u210f (j\u22122)\u210f \u22ee \u2212(j\u22122)\u210f \u2212(j\u22121)\u210f \u2212j\u210f (34.23) The largest z -component is j times \u210f ; the next smaller is one unit of \u210f less, and so on down to \u2212j\u210f . The number j is called \u201cthe spin of the system.\u201d (Some people call it the \u201ctotal angular momentum quantum number\u201d; but we\u2019ll call it the \u201cspin.\u201d) You may be worried that what we are saying can only be true for some \u201cspecial\u201d z -axis. But that is not so. For a system whose spin is j , the component of angular momentum along any axis can have only one of the values in (34.23). Although it is quite mysterious, we ask you just to accept it for the moment. We will come back and discuss the point later. You may at least be pleased to hear that the z -component goes from some number to minus the same number, so that we at least don\u2019t have to decide which is the plus direction of the z -axis. (Certainly, if we said that it went from +j to minus a different amount, that would be infinitely mysterious, because we wouldn\u2019t have been able to define the z -axis, pointing the other way.) Now if the z -component of angular momentum must go down by integers from +j to \u2212j , then j must be an integer. No! Not quite; twice j must be an integer. It is only the difference between +j and \u2212j that must be an integer. So, in general, the spin j is either an integer or a half-integer, depending on whether 2j is even or odd. Take, for instance, a nucleus like lithium, which has a spin of three-halves, j=3/2 . Then the angular momentum around the z -axis, in units of \u210f , is one of the following: +3/2 +1/2 \u22121/2 \u22123/2. There are four possible states, each of the same energy, if the nucleus is in empty space with no external fields. If we have a system whose spin is two, then the z -component of angular momentum has only the values, in units of \u210f , 2 1 0 \u22121 \u22122. If you count how many states there are for a given j , there are (2j+1) possibilities. In other words, if you tell me the energy and also the spin j , it turns out that there are exactly (2j+1) states with that energy, each state corresponding to one of the different possible values of the z -component of the angular momentum. We would like to add one other fact. If you pick out any atom of known j at random and measure the z -component of the angular momentum, then you may get any one of the possible values, and each of the values is equally likely. All of the states are in fact single states, and each is just as good as any other. Each one has the same \u201cweight\u201d in the world. (We are assuming that nothing has been done to sort out a special sample.) This fact has, incidentally, a simple classical analog. If you ask the same question classically: What is the likelihood of a particular z -component of angular momentum if you take a random sample of systems, all with the same total angular momentum?\u2014the answer is that all values from the maximum to the minimum are equally likely. (You can easily work that out.) The classical result corresponds to the equal probability of the (2j+1) possibilities in quantum mechanics. From what we have so far, we can get another interesting and somewhat surprising conclusion. In certain classical calculations the quantity that appears in the final result is the square of the magnitude of the angular momentum J \u2014in other words, J\u22c5J . It turns out that it is often possible to guess at the correct quantum-mechanical formula by using the classical calculation and the following simple rule: Replace J 2 =J\u22c5J by j(j+1) \u210f 2 . This rule is commonly used, and usually gives the correct result, but not always. We can give the following argument to show why you might expect this rule to work. The scalar product J\u22c5J can be written as J\u22c5J= J 2 x + J 2 y + J 2 z . 2 2 2 Since it is a scalar, it should be the same for any orientation of the spin. Suppose we pick samples of any given atomic system at random and make measurements of J 2 x , or J 2 y , or J 2 z , the average value should be the same for each. (There is no special distinction for any one of the directions.) Therefore, the average of J\u22c5J is just equal to three times the average of any component squared, say of J 2 z ; \u27e8J\u22c5J \u27e9 av =3\u27e8 J 2 z \u27e9 av . 2 But since J\u22c5J is the same for all orientations, its average is, of course, just its constant value; we have J\u22c5J=3\u27e8 J 2 z \u27e9 av . (34.24) If we now say that we will use the same equation for quantum mechanics, we can easily find \u27e8 J 2 z \u27e9 av . We just have to take the sum of the (2j+1) possible values of J 2 z , and divide by the total number; \u27e8 J 2 z \u27e9 av = j 2 +(j\u22121 ) 2 +\u22ef+(\u2212j+1 ) 2 +(\u2212j ) 2 2j+1 \u210f 2 . (34.25) For a system with a spin of 3/2 , it goes like this: \u27e8 J 2 z \u27e9 av = (3/2 ) 2 +(1/2 ) 2 +(\u22121/2 ) 2 +(\u22123/2 ) 2 4 \u210f 2 = 5 4 \u210f 2 . We conclude that J\u22c5J=3\u27e8 J 2 z \u27e9 av =3 5 4 \u210f 2 = 3 2 ( 3 2 +1) \u210f 2 . 5 3 3 We will leave it for you to show that Eq. (34.25), together with Eq. (34.24), gives the general result J\u22c5J=j(j+1) \u210f 2 . (34.26) Although we would think classically that the largest possible value of the z -component of J is just the magnitude of J \u2014namely, J\u22c5J \u2212 \u2212 \u2212 \u2212 \u221a \u2014quantum mechanically the maximum of J z is always a little less than that, because j\u210f is always less than j(j+1) \u2212 \u2212 \u2212 \u2212 \u2212 \u2212 \u221a \u210f . The angular momentum is never \u201ccompletely along the z -direction.\u201d Now we want to talk again about the magnetic moment. We have said that in quantum mechanics the magnetic moment of a particular atomic system can be written in terms of the angular momentum by Eq. (34.6); \u03bc=\u2212g( q e 2m )J, (34.27) where \u2212 q e and m are the charge and mass of the electron. An atomic magnet placed in an external magnetic field will have an extra magnetic energy which depends on the component of its magnetic moment along the field direction. We know that U mag =\u2212\u03bc\u22c5B. (34.28) Choosing our z -axis along the direction of B , U mag =\u2212 \u03bc z B. (34.29) Using Eq. (34.27), we have that U mag =g( q e 2m ) J z B. q Quantum mechanics says that J z can have only certain values: j\u210f , (j\u22121)\u210f , \u2026, \u2212j\u210f . Therefore, the magnetic energy of an atomic system is not arbitrary; it can have only certain values. Its maximum value, for instance, is g( q e 2m )\u210fjB. q The quantity q e \u210f/2m is usually given the name \u201cthe Bohr magneton\u201d and written \u03bc B : \u03bc B = q e \u210f 2m . \u210f The possible values of the magnetic energy are U mag =g \u03bc B B J z \u210f , J where J z /\u210f takes on the possible values j , (j\u22121) , (j\u22122) , \u2026, (\u2212j+1) , \u2212j . In other words, the energy of an atomic system is changed when it is put in a magnetic field by an amount that is proportional to the field, and proportional to J z . We say that the energy of an atomic system is \u201csplit into 2j+1 levels\u201d by a magnetic field. For instance, an atom whose energy is U 0 outside a magnetic field and whose j is 3/2 , will have four possible energies when placed in a field. We can show these energies by an energy-level diagram like that drawn in Fig. 34-5. Any particular atom can have only one of the four possible energies in any given field B . That is what quantum mechanics says about the behavior of an atomic system in a magnetic field. The simplest \u201catomic\u201d system is a single electron. The spin of an electron is 1/2 , so there are two possible states: J z =\u210f/2 and J z =\u2212\u210f/2 . For an electron at rest (no orbital motion), the spin magnetic moment has a g -value of 2 , so the magnetic energy can be either \u00b1 \u03bc B B . The possible energies in a magnetic field are shown in Fig. 34-6. Speaking loosely we say that the electron either has its spin \u201cup\u201d (along the field) or \u201cdown\u201d (opposite the field). For systems with higher spins, there are more states. We can think that the spin is \u201cup\u201d or \u201cdown\u201d or cocked at some \u201cangle\u201d in between, depending on the value of J z . We will use these quantum mechanical results to discuss the magnetic properties of materials in the next chapter."
    },
    {
        "input": "Motion",
        "output": "In order to find the laws governing the various changes that take place in bodies as time goes on, we must be able to describe the changes and have some way to record them. The simplest change to observe in a body is the apparent change in its position with time, which we call motion. Let us consider some solid object with a permanent mark, which we shall call a point, that we can observe. We shall discuss the motion of the little marker, which might be the radiator cap of an automobile or the center of a falling ball, and shall try to describe the fact that it moves and how it moves. These examples may sound trivial, but many subtleties enter into the description of change. Some changes are more difficult to describe than the motion of a point on a solid object, for example the speed of drift of a cloud that is drifting very slowly, but rapidly forming or evaporating, or the change of a woman\u2019s mind. We do not know a simple way to analyze a change of mind, but since the cloud can be represented or described by many molecules, perhaps we can describe the motion of the cloud in principle by describing the motion of all its individual molecules. Likewise, perhaps even the changes in the mind may have a parallel in changes of the atoms inside the brain, but we have no such knowledge yet. At any rate, that is why we begin with the motion of points; perhaps we should think of them as atoms, but it is probably better to be more rough in the beginning and simply to think of some kind of small objects\u2014small, that is, compared with the distance moved. For instance, in describing the motion of a car that is going a hundred miles, we do not have to distinguish between the front and the back of the car. To be sure, there are slight differences, but for rough purposes we say \u201cthe car,\u201d and likewise it does not matter that our points are not absolute points; for our present purposes it is not necessary to be extremely precise. Also, while we take a first look at this subject we are going to forget about the three dimensions of the world. We shall just concentrate on moving in one direction, as in a car on one road. We shall return to three dimensions after we see how to describe motion in one dimension. Now, you may say, \u201cThis is all some kind of trivia,\u201d and indeed it is. How can we describe such a one-dimensional motion\u2014let us say, of a car? Nothing could be simpler. Among many possible ways, one would be the following. To determine the position of the car at different times, we measure its distance from the starting point and record all the observations. In Table 8\u20131, s represents the distance of the car, in feet, from the starting point, and t represents the time in minutes. The first line in the table represents zero distance and zero time\u2014the car has not started yet. After one minute it has started and has gone 1200 feet. Then in two minutes, it goes farther\u2014notice that it picked up more distance in the second minute\u2014it has accelerated; but something happened between 3 and 4 and even more so at 5 \u2014it stopped at a light perhaps? Then it speeds up again and goes 13,000 feet by the end of 6 minutes, 18,000 feet at the end of 7 minutes, and 23,500 feet in 8 minutes; at 9 minutes it has advanced to only 24,000 feet, because in the last minute it was stopped by a cop. That is one way to describe the motion. Another way is by means of a graph. If we plot the time horizontally and the distance vertically, we obtain a curve something like that shown in Fig. 8\u20131. As the time increases, the distance increases, at first very slowly and then more rapidly, and very slowly again for a little while at 4 minutes; then it increases again for a few minutes and finally, at 9 minutes, appears to have stopped increasing. These observations can be made from the graph, without a table. Obviously, for a complete description one would have to know where the car is at the half-minute marks, too, but we suppose that the graph means something, that the car has some position at all the intermediate times. The motion of a car is complicated. For another example we take something that moves in a simpler manner, following more simple laws: a falling ball. Table 8\u20132 gives the time in seconds and the distance in feet for a falling body. At zero seconds the ball starts out at zero feet, and at the end of 1 second it has fallen 16 feet. At the end of 2 seconds, it has fallen 64 feet, at the end of 3 seconds, 144 feet, and so on; if the tabulated numbers are plotted, we get the nice parabolic curve shown in Fig. 8\u20132. The formula for this curve can be written as s=16 t 2 . (8.1) This formula enables us to calculate the distances at any time. You might say there ought to be a formula for the first graph too. Actually, one may write such a formula abstractly, as s=f(t), (8.2) meaning that s is some quantity depending on t or, in mathematical phraseology, s is a function of t . Since we do not know what the function is, there is no way we can write it in definite algebraic form. We have now seen two examples of motion, adequately described with very simple ideas, no subtleties. However, there are subtleties\u2014several of them. In the first place, what do we mean by time and space? It turns out that these deep philosophical questions have to be analyzed very carefully in physics, and this is not so easy to do. The theory of relativity shows that our ideas of space and time are not as simple as one might think at first sight. However, for our present purposes, for the accuracy that we need at first, we need not be very careful about defining things precisely. Perhaps you say, \u201cThat\u2019s a terrible thing\u2014I learned that in science we have to define everything precisely.\u201d We cannot define anything precisely! If we attempt to, we get into that paralysis of thought that comes to philosophers, who sit opposite each other, one saying to the other, \u201cYou don\u2019t know what you are talking about!\u201d The second one says, \u201cWhat do you mean by know? What do you mean by talking? What do you mean by you?,\u201d and so on. In order to be able to talk constructively, we just have to agree that we are talking about roughly the same thing. You know as much about time as we need for the present, but remember that there are some subtleties that have to be discussed; we shall discuss them later. Another subtlety involved, and already mentioned, is that it should be possible to imagine that the moving point we are observing is always located somewhere. (Of course when we are looking at it, there it is, but maybe when we look away it isn\u2019t there.) It turns out that in the motion of atoms, that idea also is false\u2014we cannot find a marker on an atom and watch it move. That subtlety we shall have to get around in quantum mechanics. But we are first going to learn what the problems are before introducing the complications, and then we shall be in a better position to make corrections, in the light of the more recent knowledge of the subject. We shall, therefore, take a simple point of view about time and space. We know what these concepts are in a rough way, and those who have driven a car know what speed means. Even though we know roughly what \u201cspeed\u201d means, there are still some rather deep subtleties; consider that the learned Greeks were never able to adequately describe problems involving velocity. The subtlety comes when we try to comprehend exactly what is meant by \u201cspeed.\u201d The Greeks got very confused about this, and a new branch of mathematics had to be discovered beyond the geometry and algebra of the Greeks, Arabs, and Babylonians. As an illustration of the difficulty, try to solve this problem by sheer algebra: A balloon is being inflated so that the volume of the balloon is increasing at the rate of 100 cm\u00b3 per second; at what speed is the radius increasing when the volume is 1000 cm\u00b3? The Greeks were somewhat confused by such problems, being helped, of course, by some very confusing Greeks. To show that there were difficulties in reasoning about speed at the time, Zeno produced a large number of paradoxes, of which we shall mention one to illustrate his point that there are obvious difficulties in thinking about motion. \u201cListen,\u201d he says, \u201cto the following argument: Achilles runs 10 times as fast as a tortoise, nevertheless he can never catch the tortoise. For, suppose that they start in a race where the tortoise is 100 meters ahead of Achilles; then when Achilles has run the 100 meters to the place where the tortoise was, the tortoise has proceeded 10 meters, having run one-tenth as fast. Now, Achilles has to run another 10 meters to catch up with the tortoise, but on arriving at the end of that run, he finds that the tortoise is still 1 meter ahead of him; running another meter, he finds the tortoise 10 centimeters ahead, and so on, ad infinitum. Therefore, at any moment the tortoise is always ahead of Achilles and Achilles can never catch up with the tortoise.\u201d What is wrong with that? It is that a finite amount of time can be divided into an infinite number of pieces, just as a length of line can be divided into an infinite number of pieces by dividing repeatedly by two. And so, although there are an infinite number of steps (in the argument) to the point at which Achilles reaches the tortoise, it doesn\u2019t mean that there is an infinite amount of time. We can see from this example that there are indeed some subtleties in reasoning about speed. In order to get to the subtleties in a clearer fashion, we remind you of a joke which you surely must have heard. At the point where the lady in the car is caught by a cop, the cop comes up to her and says, \u201cLady, you were going 60 miles an hour!\u201d She says, \u201cThat\u2019s impossible, sir, I was travelling for only seven minutes. It is ridiculous\u2014how can I go 60 miles an hour when I wasn\u2019t going an hour?\u201d How would you answer her if you were the cop? Of course, if you were really the cop, then no subtleties are involved; it is very simple: you say, \u201cTell that to the judge!\u201d But let us suppose that we do not have that escape and we make a more honest, intellectual attack on the problem, and try to explain to this lady what we mean by the idea that she was going 60 miles an hour. Just what do we mean? We say, \u201cWhat we mean, lady, is this: if you kept on going the same way as you are going now, in the next hour you would go 60 miles.\u201d She could say, \u201cWell, my foot was off the accelerator and the car was slowing down, so if I kept on going that way it would not go 60 miles.\u201d Or consider the falling ball and suppose we want to know its speed at the time three seconds if the ball kept on going the way it is going. What does that mean\u2014kept on accelerating, going faster? No\u2014kept on going with the same velocity. But that is what we are trying to define! For if the ball keeps on going the way it is going, it will just keep on going the way it is going. Thus we need to define the velocity better. What has to be kept the same? The lady can also argue this way: \u201cIf I kept on going the way I\u2019m going for one more hour, I would run into that wall at the end of the street!\u201d It is not so easy to say what we mean. Many physicists think that measurement is the only definition of anything. Obviously, then, we should use the instrument that measures the speed\u2014the speedometer\u2014and say, \u201cLook, lady, your speedometer reads 60 .\u201d So she says, \u201cMy speedometer is broken and didn\u2019t read at all.\u201d Does that mean the car is standing still? We believe that there is something to measure before we build the speedometer. Only then can we say, for example, \u201cThe speedometer isn\u2019t working right,\u201d or \u201cthe speedometer is broken.\u201d That would be a meaningless sentence if the velocity had no meaning independent of the speedometer. So we have in our minds, obviously, an idea that is independent of the speedometer, and the speedometer is meant only to measure this idea. So let us see if we can get a better definition of the idea. We say, \u201cYes, of course, before you went an hour, you would hit that wall, but if you went one second, you would go 88 feet; lady, you were going 88 feet per second, and if you kept on going, the next second it would be 88 feet, and the wall down there is farther away than that.\u201d She says, \u201cYes, but there\u2019s no law against going 88 feet per second! There is only a law against going 60 miles an hour.\u201d \u201cBut,\u201d we reply, \u201cit\u2019s the same thing.\u201d If it is the same thing, it should not be necessary to go into this circumlocution about 88 feet per second. In fact, the falling ball could not keep going the same way even one second because it would be changing speed, and we shall have to define speed somehow. Now we seem to be getting on the right track; it goes something like this: If the lady kept on going for another 1/1000 of an hour, she would go 1/1000 of 60 miles. In other words, she does not have to keep on going for the whole hour; the point is that for a moment she is going at that speed. Now what that means is that if she went just a little bit more in time, the extra distance she goes would be the same as that of a car that goes at a steady speed of 60 miles an hour. Perhaps the idea of the 88 feet per second is right; we see how far she went in the last second, divide by 88 feet, and if it comes out 1 the speed was 60 miles an hour. In other words, we can find the speed in this way: We ask, how far do we go in a very short time? We divide that distance by the time, and that gives the speed. But the time should be made as short as possible, the shorter the better, because some change could take place during that time. If we take the time of a falling body as an hour, the idea is ridiculous. If we take it as a second, the result is pretty good for a car, because there is not much change in speed, but not for a falling body; so in order to get the speed more and more accurately, we should take a smaller and smaller time interval. What we should do is take a millionth of a second, find out how far the car has gone, and divide that distance by a millionth of a second. The result gives the distance per second, which is what we mean by the velocity, so we can define it that way. That is a successful answer for the lady, or rather, that is the definition that we are going to use. The foregoing definition involves a new idea, an idea that was not available to the Greeks in a general form. That idea was to take an infinitesimal distance and the corresponding infinitesimal time, form the ratio, and watch what happens to that ratio as the time that we use gets smaller and smaller and smaller. In other words, take a limit of the distance travelled divided by the time required, as the time taken gets smaller and smaller, ad infinitum. This idea was invented by Newton and by Leibniz, independently, and is the beginning of a new branch of mathematics, called the differential calculus. Calculus was invented in order to describe motion, and its first application was to the problem of defining what is meant by going \u201c 60 miles an hour.\u201d Let us try to define velocity a little better. Suppose that in a short time, \u03f5 , the car or other body goes a short distance x ; then the velocity, v , is defined as v=x/\u03f5, / an approximation that becomes better and better as the \u03f5 is taken smaller and smaller. If a mathematical expression is desired, we can say that the velocity equals the limit as the \u03f5 is made to go smaller and smaller in the expression x/\u03f5 , or v= lim \u03f5\u21920 x \u03f5 . (8.3) We cannot do the same thing with the lady in the car, because the table is incomplete. We know only where she was at intervals of one minute; we can get a rough idea that she was going 5000 ft/min during the 7 th minute, but we do not know, at exactly the moment 7 minutes, whether she had been speeding up and the speed was 4900 ft/min at the beginning of the 6 th minute, and is now 5100 ft/min, or something else, because we do not have the exact details in between. So only if the table were completed with an infinite number of entries could we really calculate the velocity from such a table. On the other hand, when we have a complete mathematical formula, as in the case of a falling body (Eq. 8.1), then it is possible to calculate the velocity, because we can calculate the position at any time whatsoever. Let us take as an example the problem of determining the velocity of the falling ball at the particular time 5 seconds. One way to do this is to see from Table 8\u20132 what it did in the 5 th second; it went 400\u2212256=144 ft, so it is going 144 ft/sec; however, that is wrong, because the speed is changing; on the average it is 144 ft/sec during this interval, but the ball is speeding up and is really going faster than 144 ft/sec. We want to find out exactly how fast. The technique involved in this process is the following: We know where the ball was at 5 sec. At 5.1 sec, the distance that it has gone all together is 16(5.1 ) 2 =416.16 ft (see Eq. 8.1). At 5 sec it had already fallen 400 ft; in the last tenth of a second it fell 416.16\u2212400=16.16 ft. Since 16.16 ft in 0.1 sec is the same as 161.6 ft/sec, that is the speed more or less, but it is not exactly correct. Is that the speed at 5 , or at 5.1 , or halfway between at 5.05 sec, or when is that the speed? Never mind\u2014the problem was to find the speed at 5 seconds, and we do not have exactly that; we have to do a better job. So, we take one-thousandth of a second more than 5 sec, or 5.001 sec, and calculate the total fall as s=16(5.001 ) 2 =16(25.010001) =400.160016 ft. In the last 0.001 sec the ball fell 0.160016 ft, and if we divide this number by 0.001 sec we obtain the speed as 160.016 ft/sec. That is closer, very close, but it is still not exact. It should now be evident what we must do to find the speed exactly. To perform the mathematics we state the problem a little more abstractly: to find the velocity at a special time, t 0 , which in the original problem was 5 sec. Now the distance at t 0 , which we call s 0 , is 16 t 2 0 , or 400 ft in this case. In order to find the velocity, we ask, \u201cAt the time t 0 +(a little bit) , or t 0 +\u03f5 , where is the body?\u201d The new position is 16( t 0 +\u03f5 ) 2 =16 t 2 0 +32 t 0 \u03f5+16 \u03f5 2 . So it is farther along than it was before, because before it was only 16 t 2 0 . This distance we shall call s 0 +(a little bit more) , or s 0 +x (if x is the extra bit). Now if we subtract the distance at t 0 from the distance at t 0 +\u03f5 , we get x , the extra distance gone, as x=32 t 0 \u22c5\u03f5+16 \u03f5 2 . Our first approximation to the velocity is v= x \u03f5 =32 t 0 +16\u03f5. (8.4) The true velocity is the value of this ratio, x/\u03f5 , when \u03f5 becomes vanishingly small. In other words, after forming the ratio, we take the limit as \u03f5 gets smaller and smaller, that is, approaches 0 . The equation reduces to, v(at time t 0 )=32 t 0 . ( ) In our problem, t 0 =5 sec, so the solution is v= 32\u00d75= 160 ft/sec. A few lines above, where we took \u03f5 as 0.1 and 0.001 sec successively, the value we got for v was a little more than this, but now we see that the actual velocity is precisely 160 ft/sec. The procedure we have just carried out is performed so often in mathematics that for convenience special notations have been assigned to our quantities \u03f5 and x . In this notation, the \u03f5 used above becomes \u0394t and x becomes \u0394s . This \u0394t means \u201can extra bit of t ,\u201d and carries an implication that it can be made smaller. The prefix \u0394 is not a multiplier, any more than sin\u03b8 means s\u22c5i\u22c5n\u22c5\u03b8 \u2014it simply defines a time increment, and reminds us of its special character. \u0394s has an analogous meaning for the distance s . Since \u0394 is not a factor, it cannot be cancelled in the ratio \u0394s/\u0394t to give s/t , any more than the ratio sin\u03b8/sin2\u03b8 can be reduced to 1/2 by cancellation. In this notation, velocity is equal to the limit of \u0394s/\u0394t when \u0394t gets smaller, or v= lim \u0394t\u21920 \u0394s \u0394t . (8.5) This is really the same as our previous expression (8.3) with \u03f5 and x , but it has the advantage of showing that something is changing, and it keeps track of what is changing. Incidentally, to a good approximation we have another law, which says that the change in distance of a moving point is the velocity times the time interval, or \u0394s=v\u0394t . This statement is true only if the velocity is not changing during that time interval, and this condition is true only in the limit as \u0394t goes to 0 . Physicists like to write it ds=vdt , because by dt they mean \u0394t in circumstances in which it is very small; with this understanding, the expression is valid to a close approximation. If \u0394t is too long, the velocity might change during the interval, and the approximation would become less accurate. For a time dt , approaching zero, ds=vdt precisely. In this notation we can write (8.5) as v= lim \u0394t\u21920 \u0394s \u0394t = ds dt . \u0394 d The quantity ds/dt which we found above is called the \u201cderivative of s with respect to t \u201d (this language helps to keep track of what was changed), and the complicated process of finding it is called finding a derivative, or differentiating. The ds \u2019s and dt \u2019s which appear separately are called differentials. To familiarize you with the words, we say we found the derivative of the function 16 t 2 , or the derivative (with respect to t ) of 16 t 2 is 32t . When we get used to the words, the ideas are more easily understood. For practice, let us find the derivative of a more complicated function. We shall consider the formula s=A t 3 +Bt+C , which might describe the motion of a point. The letters A , B , and C represent constant numbers, as in the familiar general form of a quadratic equation. Starting from the formula for the motion, we wish to find the velocity at any time. To find the velocity in the more elegant manner, we change t to t+\u0394t and note that s is then changed to s+some \u0394s ; then we find the \u0394s in terms of \u0394t . That is to say, s+\u0394s =A(t+\u0394t ) 3 +B(t+\u0394t)+C =A t 3 +Bt+C+3A t 2 \u0394t+B\u0394t +3At(\u0394t ) 2 +A(\u0394t ) 3 , but since s=A t 3 +Bt+C, 3 we find that \u0394s=3A t 2 \u0394t+B\u0394t+3At(\u0394t ) 2 +A(\u0394t ) 3 . 2 3 But we do not want \u0394s \u2014we want \u0394s divided by \u0394t . We divide the preceding equation by \u0394t , getting \u0394s \u0394t =3A t 2 +B+3At(\u0394t)+A(\u0394t ) 2 . \u0394 As \u0394t goes toward 0 the limit of \u0394s/\u0394t is ds/dt and is equal to ds dt =3A t 2 +B. d This is the fundamental process of calculus, differentiating functions. The process is even more simple than it appears. Observe that when these expansions contain any term with a square or a cube or any higher power of \u0394t , such terms may be dropped at once, since they will go to 0 when the limit is taken. After a little practice the process gets easier because one knows what to leave out. There are many rules or formulas for differentiating various types of functions. These can be memorized, or can be found in tables. A short list is found in Table 8\u20133. Now we have to discuss the inverse problem. Suppose that instead of a table of distances, we have a table of speeds at different times, starting from zero. For the falling ball, such speeds and times are shown in Table 8\u20134. A similar table could be constructed for the velocity of the car, by recording the speedometer reading every minute or half-minute. If we know how fast the car is going at any time, can we determine how far it goes? This problem is just the inverse of the one solved above; we are given the velocity and asked to find the distance. How can we find the distance if we know the speed? If the speed of the car is not constant, and the lady goes sixty miles an hour for a moment, then slows down, speeds up, and so on, how can we determine how far she has gone? That is easy. We use the same idea, and express the distance in terms of infinitesimals. Let us say, \u201cIn the first second her speed was such and such, and from the formula \u0394s=v\u0394t we can calculate how far the car went the first second at that speed.\u201d Now in the next second her speed is nearly the same, but slightly different; we can calculate how far she went in the next second by taking the new speed times the time. We proceed similarly for each second, to the end of the run. We now have a number of little distances, and the total distance will be the sum of all these little pieces. That is, the distance will be the sum of the velocities times the times, or s=\u2211v\u0394t , where the Greek letter \u2211 (sigma) is used to denote addition. To be more precise, it is the sum of the velocity at a certain time, let us say the i -th time, multiplied by \u0394t . s= \u2211 i v( t i )\u0394t. (8.6) The rule for the times is that t i+1 = t i +\u0394t . However, the distance we obtain by this method will not be correct, because the velocity changes during the time interval \u0394t . If we take the times short enough, the sum is precise, so we take them smaller and smaller until we obtain the desired accuracy. The true s is s= lim \u0394t\u21920 \u2211 i v( t i )\u0394t. (8.7) The mathematicians have invented a symbol for this limit, analogous to the symbol for the differential. The \u0394 turns into a d to remind us that the time is as small as it can be; the velocity is then called v at the time t , and the addition is written as a sum with a great \u201c s ,\u201d \u222b (from the Latin summa), which has become distorted and is now unfortunately just called an integral sign. Thus we write s=\u222bv(t)dt. (8.8) This process of adding all these terms together is called integration, and it is the opposite process to differentiation. The derivative of this integral is v , so one operator ( d ) undoes the other ( \u222b ). One can get formulas for integrals by taking the formulas for derivatives and running them backwards, because they are related to each other inversely. Thus one can work out his own table of integrals by differentiating all sorts of functions. For every formula with a differential, we get an integral formula if we turn it around. Every function can be differentiated analytically, i.e., the process can be carried out algebraically, and leads to a definite function. But it is not possible in a simple manner to write an analytical value for any integral at will. You can calculate it, for instance, by doing the above sum, and then doing it again with a finer interval \u0394t and again with a finer interval until you have it nearly right. In general, given some particular function, it is not possible to find, analytically, what the integral is. One may always try to find a function which, when differentiated, gives some desired function; but one may not find it, and it may not exist, in the sense of being expressible in terms of functions that have already been given names. The next step in developing the equations of motion is to introduce another idea which goes beyond the concept of velocity to that of change of velocity, and we now ask, \u201cHow does the velocity change?\u201d In previous chapters we have discussed cases in which forces produce changes in velocity. You may have heard with great excitement about some car that can get from rest to 60 miles an hour in ten seconds flat. From such a performance we can see how fast the speed changes, but only on the average. What we shall now discuss is the next level of complexity, which is how fast the velocity is changing. In other words, by how many feet per second does the velocity change in a second, that is, how many feet per second, per second? We previously derived the formula for the velocity of a falling body as v=32t , which is charted in Table 8\u20134, and now we want to find out how much the velocity changes per second; this quantity is called the acceleration. Acceleration is defined as the time rate of change of velocity. From the preceding discussion we know enough already to write the acceleration as the derivative dv/dt , in the same way that the velocity is the derivative of the distance. If we now differentiate the formula v=32t we obtain, for a falling body, a= dv dt =32. (8.9) [To differentiate the term 32t we can utilize the result obtained in a previous problem, where we found that the derivative of Bt is simply B (a constant). So by letting B=32 , we have at once that the derivative of 32t is 32 .] This means that the velocity of a falling body is changing by 32 feet per second, per second always. We also see from Table 8\u20134 that the velocity increases by 32 ft/sec in each second. This is a very simple case, for accelerations are usually not constant. The reason the acceleration is constant here is that the force on the falling body is constant, and Newton\u2019s law says that the acceleration is proportional to the force. As a further example, let us find the acceleration in the problem we have already solved for the velocity. Starting with s=A t 3 +Bt+C 3 we obtained, for v=ds/dt , v=3A t 2 +B. 2 Since acceleration is the derivative of the velocity with respect to the time, we need to differentiate the last expression above. Recall the rule that the derivative of the two terms on the right equals the sum of the derivatives of the individual terms. To differentiate the first of these terms, instead of going through the fundamental process again we note that we have already differentiated a quadratic term when we differentiated 16 t 2 , and the effect was to double the numerical coefficient and change the t 2 to t ; let us assume that the same thing will happen this time, and you can check the result yourself. The derivative of 3A t 2 will then be 6At . Next we differentiate B , a constant term; but by a rule stated previously, the derivative of B is zero; hence this term contributes nothing to the acceleration. The final result, therefore, is a= dv/dt= 6At . For reference, we state two very useful formulas, which can be obtained by integration. If a body starts from rest and moves with a constant acceleration, g , its velocity v at any time t is given by v=gt. t The distance it covers in the same time is s= 1 2 g t 2 . 1 Various mathematical notations are used in writing derivatives. Since velocity is ds/dt and acceleration is the time derivative of the velocity, we can also write a= d dt ( ds dt )= d 2 s d t 2 , (8.10) which are common ways of writing a second derivative. We have another law that the velocity is equal to the integral of the acceleration. This is just the opposite of a=dv/dt ; we have already seen that distance is the integral of the velocity, so distance can be found by twice integrating the acceleration. In the foregoing discussion the motion was in only one dimension, and space permits only a brief discussion of motion in three dimensions. Consider a particle P which moves in three dimensions in any manner whatsoever. At the beginning of this chapter, we opened our discussion of the one-dimensional case of a moving car by observing the distance of the car from its starting point at various times. We then discussed velocity in terms of changes of these distances with time, and acceleration in terms of changes in velocity. We can treat three-dimensional motion analogously. It will be simpler to illustrate the motion on a two-dimensional diagram, and then extend the ideas to three dimensions. We establish a pair of axes at right angles to each other, and determine the position of the particle at any moment by measuring how far it is from each of the two axes. Thus each position is given in terms of an x -distance and a y -distance, and the motion can be described by constructing a table in which both these distances are given as functions of time. (Extension of this process to three dimensions requires only another axis, at right angles to the first two, and measuring a third distance, the z -distance. The distances are now measured from coordinate planes instead of lines.) Having constructed a table with x - and y -distances, how can we determine the velocity? We first find the components of velocity in each direction. The horizontal part of the velocity, or x -component, is the derivative of the x -distance with respect to the time, or v x =dx/dt. (8.11) Similarly, the vertical part of the velocity, or y -component, is v y =dy/dt. (8.12) In the third dimension, v z =dz/dt. (8.13) Now, given the components of velocity, how can we find the velocity along the actual path of motion? In the two-dimensional case, consider two successive positions of the particle, separated by a short distance \u0394s and a short time interval t 2 \u2212 t 1 =\u0394t . In the time \u0394t the particle moves horizontally a distance \u0394x\u2248 v x \u0394t , and vertically a distance \u0394y\u2248 v y \u0394t . (The symbol \u201c \u2248 \u201d is read \u201cis approximately.\u201d) The actual distance moved is approximately \u0394s\u2248 (\u0394x ) 2 +(\u0394y ) 2 \u2212 \u2212 \u2212 \u2212 \u2212 \u2212 \u2212 \u2212 \u2212 \u2212 \u2212 \u2212 \u221a , (8.14) as shown in Fig. 8\u20133. The approximate velocity during this interval can be obtained by dividing by \u0394t and by letting \u0394t go to 0 , as at the beginning of the chapter. We then get the velocity as v= ds dt = (dx/dt ) 2 +(dy/dt ) 2 \u2212 \u2212 \u2212 \u2212 \u2212 \u2212 \u2212 \u2212 \u2212 \u2212 \u2212 \u2212 \u2212 \u2212 \u2212 \u2212 \u221a = v 2 x + v 2 y \u2212 \u2212 \u2212 \u2212 \u2212 \u2212 \u221a . (8.15) For three dimensions the result is v= v 2 x + v 2 y + v 2 z \u2212 \u2212 \u2212 \u2212 \u2212 \u2212 \u2212 \u2212 \u2212 \u2212 \u221a . (8.16) In the same way as we defined velocities, we can define accelerations: we have an x -component of acceleration a x , which is the derivative of v x , the x -component of the velocity (that is, a x = d 2 x/d t 2 , the second derivative of x with respect to t ), and so on. Let us consider one nice example of compound motion in a plane. We shall take a motion in which a ball moves horizontally with a constant velocity u , and at the same time goes vertically downward with a constant acceleration \u2212g ; what is the motion? We can say dx/dt= v x = u . Since the velocity v x is constant, x=ut, (8.17) and since the downward acceleration \u2212g is constant, the distance y the object falls can be written as y=\u2212 1 2 g t 2 . (8.18) What is the curve of its path, i.e., what is the relation between y and x ? We can eliminate t from Eq. (8.18), since t=x/u . When we make this substitution we find that y=\u2212 g 2 u 2 x 2 . (8.19) This relation between y and x may be considered as the equation of the path of the moving ball. When this equation is plotted we obtain a curve that is called a parabola; any freely falling body that is shot out in any direction will travel in a parabola, as shown in Fig. 8\u20134."
    },
    {
        "input": "The Laws of Thermodynamics",
        "output": "So far we have been discussing the properties of matter from the atomic point of view, trying to understand roughly what will happen if we suppose that things are made of atoms obeying certain laws. However, there are a number of relationships among the properties of substances which can be worked out without consideration of the detailed structure of the materials. The determination of the relationships among the various properties of materials, without knowing their internal structure, is the subject of thermodynamics. Historically, thermodynamics was developed before an understanding of the internal structure of matter was achieved. To give an example: we know from the kinetic theory that the pressure of a gas is caused by molecular bombardment, and we know that if we heat a gas, so that the bombardment increases, the pressure must increase. Conversely, if the piston in a container of the gas is moved inward against the force of bombardment, the energy of the molecules bombarding the piston will increase, and consequently the temperature will increase. So, on the one hand, if we increase the temperature at a given volume, we increase the pressure. On the other hand, if we compress the gas, we will find that the temperature will rise. From the kinetic theory, one can derive a quantitative relationship between these two effects, but instinctively one might guess that they are related in some necessary fashion which is independent of the details of the collisions. Let us consider another example. Many people are familiar with this interesting property of rubber: If we take a rubber band and pull it, it gets warm. If one puts it between his lips, for example, and pulls it out, he can feel a distinct warming, and this warming is reversible in the sense that if he relaxes the rubber band quickly while it is between his lips, it is distinctly cooled. That means that when we stretch a rubber band it heats, and when we release the tension of the band it cools. Now our instincts might suggest that if we heated a band, it might pull: that the fact that pulling a band heats it might imply that heating a band should cause it to contract. And, in fact, if we apply a gas flame to a rubber band holding a weight, we will see that the band contracts abruptly (Fig. 44\u20131). So it is true that when we heat a rubber band it pulls, and this fact is definitely related to the fact that when we release the tension of it, it cools. The internal machinery of rubber that causes these effects is quite complicated. We will describe it from a molecular point of view to some extent, although our main purpose in this chapter is to understand the relationship of these effects independently of the molecular model. Nevertheless, we can show from the molecular model that the effects are closely related. One way to understand the behavior of rubber is to recognize that this substance consists of an enormous tangle of long chains of molecules, a kind of \u201cmolecular spaghetti,\u201d with one extra complication: between the chains there are cross-links\u2014like spaghetti that is sometimes welded together where it crosses another piece of spaghetti\u2014a grand tangle. When we pull out such a tangle, some of the chains tend to line up along the direction of the pull. At the same time, the chains are in thermal motion, so they hit each other continually. It follows that such a chain, if stretched, would not by itself remain stretched, because it would be hit from the sides by the other chains and other molecules, and would tend to kink up again. So the real reason why a rubber band tends to contract is this: when one pulls it out, the chains are lengthwise, and the thermal agitations of the molecules on the sides of the chains tend to kink the chains up, and make them shorten. One can then appreciate that if the chains are held stretched and the temperature is increased, so that the vigor of the bombardment on the sides of the chains is also increased, the chains tend to pull in, and they are able to pull a stronger weight when heated. If, after being stretched for a time, a rubber band is allowed to relax, each chain becomes soft, and the molecules striking it lose energy as they pound into the relaxing chain. So the temperature falls. We have seen how these two processes, contraction when heated and cooling during relaxation, can be related by the kinetic theory, but it would be a tremendous challenge to determine from the theory the precise relationship between the two. We would have to know how many collisions there were each second and what the chains look like, and we would have to take account of all kinds of other complications. The detailed mechanism is so complex that we cannot, by kinetic theory, really determine exactly what happens; still, a definite relation between the two effects we observe can be worked out without knowing anything about the internal machinery! The whole subject of thermodynamics depends essentially upon the following kind of consideration: because a rubber band is \u201cstronger\u201d at higher temperatures than it is at lower temperatures, it ought to be possible to lift weights, and to move them around, and thus to do work with heat. In fact, we have already seen experimentally that a heated rubber band can lift a weight. The study of the way that one does work with heat is the beginning of the science of thermodynamics. Can we make an engine which uses the heating effect on a rubber band to do work? One can make a silly looking engine that does just this. It consists of a bicycle wheel in which all the spokes are rubber bands (Fig. 44\u20132). If one heats the rubber bands on one side of the wheel with a pair of heat lamps, they become \u201cstronger\u201d than the rubber bands on the other side. The center of gravity of the wheel will be pulled to one side, away from the bearing, so that the wheel turns. As it turns, cool rubber bands move toward the heat, and the heated bands move away from the heat and cool, so that the wheel turns slowly so long as the heat is applied. The efficiency of this engine is extremely low. Four hundred watts of power pour into the two lamps, but it is just possible to lift a fly with such an engine! An interesting question, however, is whether we can get heat to do the work in more efficient ways. In fact, the science of thermodynamics began with an analysis, by the great engineer Sadi Carnot, of the problem of how to build the best and most efficient engine, and this constitutes one of the few famous cases in which engineering has contributed fundamentally to physical theory. Another example that comes to mind is the more recent analysis of information theory by Claude Shannon. These two analyses, incidentally, turn out to be closely related. Now the way a steam engine ordinarily operates is that heat from a fire boils some water, and the steam so formed expands and pushes on a piston which makes a wheel go around. So the steam pushes the piston\u2014what then? One has to finish the job: a stupid way to complete the cycle would be to let the steam escape into the air, for then one has to keep supplying water. It is cheaper\u2014more efficient\u2014to let the steam go into another box, where it is condensed by cool water, and then pump the water back into the boiler, so that it circulates continuously. Heat is thus supplied to the engine and converted into work. Now would it be better to use alcohol? What property should a substance have so that it makes the best possible engine? That was the question to which Carnot addressed himself, and one of the by-products was the discovery of the type of relationship that we have just explained above. The results of thermodynamics are all contained implicitly in certain apparently simple statements called the laws of thermodynamics. At the time when Carnot lived, the first law of thermodynamics, the conservation of energy, was not known. Carnot\u2019s arguments were so carefully drawn, however, that they are valid even though the first law was not known in his time! Some time afterwards, Clapeyron made a simpler derivation that could be understood more easily than Carnot\u2019s very subtle reasoning. But it turned out that Clapeyron assumed, not the conservation of energy in general, but that heat was conserved according to the caloric theory, which was later shown to be false. So it has often been said that Carnot\u2019s logic was wrong. But his logic was quite correct. Only Clapeyron\u2019s simplified version, that everybody read, was incorrect. The so-called second law of thermodynamics was thus discovered by Carnot before the first law! It would be interesting to give Carnot\u2019s argument that did not use the first law, but we shall not do so because we want to learn physics, not history. We shall use the first law from the start, in spite of the fact that a great deal can be done without it. Let us begin by stating the first law, the conservation of energy: if one has a system and puts heat into it, and does work on it, then its energy is increased by the heat put in and the work done. We can write this as follows: The heat Q put into the system, plus the work W done on the system, is the increase in the energy U of the system; the latter energy is sometimes called the internal energy: Change in U=Q+W. (44.1) The change in U can be represented as adding a little heat \u0394Q and adding a little work \u0394W : \u0394U=\u0394Q+\u0394W, (44.2) which is a differential form of the same law. We know that very well, from an earlier chapter. Now, what about the second law of thermodynamics? We know that if we do work against friction, say, the work lost to us is equal to the heat produced. If we do work in a room at temperature T , and we do the work slowly enough, the room temperature does not change much, and we have converted work into heat at a given temperature. What about the reverse possibility? Is it possible to convert the heat back into work at a given temperature? The second law of thermodynamics asserts that it is not. It would be very convenient to be able to convert heat into work merely by reversing a process like friction. If we consider only the conservation of energy, we might think that heat energy, such as that in the vibrational motions of molecules, might provide a goodly supply of useful energy. But Carnot assumed that it is impossible to extract the energy of heat at a single temperature. In other words, if the whole world were at the same temperature, one could not convert any of its heat energy into work: while the process of making work go into heat can take place at a given temperature, one cannot reverse it to get the work back again. Specifically, Carnot assumed that heat cannot be taken in at a certain temperature and converted into work with no other change in the system or the surroundings. That last phrase is very important. Suppose we have a can of compressed air at a certain temperature, and we let the air expand. It can do work; it can make hammers go, for example. It cools off a little in the expansion, but if we had a big sea, like the ocean, at a given temperature\u2014a heat reservoir\u2014we could warm it up again. So we have taken the heat out of the sea, and we have done work with the compressed air. But Carnot was not wrong, because we did not leave everything as it was. If we recompress the air that we let expand, we will find we are doing extra work, and when we are finished we will discover that we not only got no work out of the system at temperature T , but we actually put some in. We must talk only about situations in which the net result of the whole process is to take heat away and convert it into work, just as the net result of the process of doing work against friction is to take work and convert it into heat. If we move in a circle, we can bring the system back precisely to its starting point, with the net result that we did work against friction and produced heat. Can we reverse the process? Turn a switch, so that everything goes backwards, so the friction does work against us, and cools the sea? According to Carnot: no! So let us suppose that this is impossible. If it were possible it would mean, among other things, that we could take heat out of a cold body and put it into a hot body at no cost, as it were. Now we know it is natural that a hot thing can warm up a cool thing; if we simply put a hot body and a cold one together, and change nothing else, our experience assures us that it is not going to happen that the hot one gets hotter, and the cold one gets colder! But if we could obtain work by extracting the heat out of the ocean, say, or from anything else at a single temperature, then that work could be converted back into heat by friction at some other temperature. For instance, the other arm of a working machine could be rubbing something that is already hot. The net result would be to take heat from a \u201ccold\u201d body, the ocean, and to put it into a hot body. Now, the hypothesis of Carnot, the second law of thermodynamics, is sometimes stated as follows: heat cannot, of itself, flow from a cold to a hot object. But, as we have just seen, these two statements are equivalent: first, that one cannot devise a process whose only result is to convert heat to work at a single temperature, and second, that one cannot make heat flow by itself from a cold to a hot place. We shall mostly use the first form. Carnot\u2019s analysis of heat engines is quite similar to the argument that we gave about weight-lifting engines in our discussion of the conservation of energy in Chapter 4. In fact, that argument was patterned after Carnot\u2019s argument about heat engines, and so the present treatment will sound very much the same. Suppose we build a heat engine that has a \u201cboiler\u201d somewhere at a temperature T 1 . A certain heat Q 1 is taken from the boiler, the steam engine does some work W , and it then delivers some heat Q 2 into a \u201ccondenser\u201d at another temperature T 2 (Fig. 44\u20133). Carnot did not say how much heat, because he did not know the first law, and he did not use the law that Q 2 was equal to Q 1 because he did not believe it. Although everybody thought that, according to the caloric theory, the heats Q 1 and Q 2 would have to be the same, Carnot did not say they were the same\u2014that is part of the cleverness of his argument. If we do use the first law, we find that the heat delivered, Q 2 , is the heat Q 1 that was put in minus the work W that was done: Q 2 = Q 1 \u2212W. (44.3) (If we have some kind of cyclic process where water is pumped back into the boiler after it is condensed, we will say that we have heat Q 1 absorbed and work W done, during each cycle, for a certain amount of water that goes around the cycle.) Now we shall build another engine, and see if we cannot get more work from the same amount of heat being delivered at the temperature T 1 , with the condenser still at the temperature T 2 . We shall use the same amount of heat Q 1 from the boiler, and we shall try to get more work than we did out of the steam engine, perhaps by using another fluid, such as alcohol. Now we must analyze our engines. One thing is clear: we will lose something if the engines contain devices in which there is friction. The best engine will be a frictionless engine. We assume, then, the same idealization that we did when we studied the conservation of energy; that is, a perfectly frictionless engine. We must also consider the analog of frictionless motion, \u201cfrictionless\u201d heat transfer. If we put a hot object at a high temperature against a cold object, so that the heat flows, then it is not possible to make that heat flow in a reverse direction by a very small change in the temperature of either object. But when we have a practically frictionless machine, if we push it with a little force one way, it goes that way, and if we push it with a little force the other way, it goes the other way. We need to find the analog of frictionless motion: heat transfer whose direction we can reverse with only a tiny change. If the difference in temperature is finite, that is impossible, but if one makes sure that heat flows always between two things at essentially the same temperature, with just an infinitesimal difference to make it flow in the desired direction, the flow is said to be reversible (Fig. 44\u20134). If we heat the object on the left a little, heat will flow to the right; if we cool it a little, heat will flow to the left. So we find that the ideal engine is a so-called reversible engine, in which every process is reversible in the sense that, by minor changes, infinitesimal changes, we can make the engine go in the opposite direction. That means that nowhere in the machine must there be any appreciable friction, and nowhere in the machine must there be any place where the heat of the reservoirs, or the flame of the boiler, is in direct contact with something definitely cooler or warmer. Let us now consider an idealized engine in which all the processes are reversible. To show that such a thing is possible in principle, we will give an example of an engine cycle which may or may not be practical, but which is at least reversible, in the sense of Carnot\u2019s idea. Suppose that we have a gas in a cylinder equipped with a frictionless piston. The gas is not necessarily a perfect gas. The fluid does not even have to be a gas, but to be specific let us say we do have a perfect gas. Also, suppose that we have two heat pads, T 1 and T 2 \u2014great big things that have definite temperatures, T 1 and T 2 . We will suppose in this case that T 1 is higher than T 2 . Let us first heat the gas and at the same time expand it, while it is in contact with the heat pad at T 1 . As we do this, pulling the piston out very slowly as the heat flows into the gas, we will make sure that the temperature of the gas never gets very far from T 1 . If we pull the piston out too fast, the temperature of the gas will fall too much below T 1 and then the process will not be quite reversible, but if we pull it out slowly enough, the temperature of the gas will never depart much from T 1 . On the other hand, if we push the piston back slowly, the temperature would be only infinitesimally higher than T 1 , and the heat would pour back. We see that such an isothermal (constant-temperature) expansion, done slowly and gently enough, is a reversible process. To understand what we are doing, we shall use a plot (Fig. 44\u20136) of the pressure of the gas against its volume. As the gas expands, the pressure falls. The curve marked (1) tells us how the pressure and volume change if the temperature is kept fixed at the value T 1 . For an ideal gas this curve would be PV=Nk T 1 . During an isothermal expansion the pressure falls as the volume increases until we stop at the point b . At the same time, a certain heat Q 1 must flow into the gas from the reservoir, for if the gas were expanded without being in contact with the reservoir it would cool off, as we already know. Having completed the isothermal expansion, stopping at the point b , let us take the cylinder away from the reservoir and continue the expansion. This time we permit no heat to enter the cylinder. Again we perform the expansion slowly, so there is no reason why we cannot reverse it, and we again assume there is no friction. The gas continues to expand and the temperature falls, since there is no longer any heat entering the cylinder. We let the gas expand, following the curve marked (2), until the temperature falls to T 2 , at the point marked c . This kind of expansion, made without adding heat, is called an adiabatic expansion. For an ideal gas, we already know that curve (2) has the form P V \u03b3 =constant , where \u03b3 is a constant greater than 1 , so that the adiabatic curve has a more negative slope than the isothermal curve. The gas cylinder has now reached the temperature T 2 , so that if we put it on the heat pad at temperature T 2 there will be no irreversible changes. Now we slowly compress the gas while it is in contact with the reservoir at T 2 , following the curve marked (3) (Fig. 44\u20135, Step 3). Because the cylinder is in contact with the reservoir, the temperature does not rise, but heat Q 2 flows from the cylinder into the reservoir at the temperature T 2 . Having compressed the gas isothermally along curve (3) to the point d , we remove the cylinder from the heat pad at temperature T 2 and compress it still further, without letting any heat flow out. The temperature will rise, and the pressure will follow the curve marked (4). If we carry out each step properly, we can return to the point a at temperature T 1 where we started, and repeat the cycle. We see that on this diagram we have carried the gas around a complete cycle, and during one cycle we have put Q 1 in at temperature T 1 , and have removed Q 2 at temperature T 2 . Now the point is that this cycle is reversible, so that we could represent all the steps the other way around. We could have gone backwards instead of forwards: we could have started at point a , at temperature T 1 , expanded along the curve (4), expanded further at the temperature T 2 , absorbing heat Q 2 , and so on, going around the cycle backward. If we go around the cycle in one direction, we must do work on the gas; if we go in the other direction, the gas does work on us. Incidentally, it is easy to find out what the total amount of work is, because the work during any expansion is the pressure times the change in volume, \u222bPdV . On this particular diagram, we have plotted P vertically and V horizontally. So if we call the vertical distance y and the horizontal distance x , this is \u222bydx \u2014in other words, the area under the curve. So the area under each of the numbered curves is a measure of the work done by or on the gas in the corresponding step. It is easy to see that the net work done is the shaded area of the picture. Now that we have given a single example of a reversible machine, we shall suppose that other such engines are also possible. Let us assume that we have a reversible engine A which takes Q 1 at T 1 , does work W , and delivers some heat at T 2 . Now let us assume we have any other engine B , made by man, already designed or not yet invented, made of rubber bands, steam, or whatever, reversible or not, which is designed so that it takes in the same amount of heat Q 1 at T 1 , and rejects the heat at the lower temperature T 2 (Fig. 44\u20137). Assume that engine B does some work, W \u2032 . Now we shall show that W \u2032 is not greater than W \u2014that no engine can do more work than a reversible one. Why? Suppose that, indeed, W \u2032 were bigger than W . Then we could take the heat Q 1 out of the reservoir at T 1 , and with engine B we could do work W \u2032 and deliver some heat to the reservoir at T 2 ; we do not care how much. That done, we could save some of the work W \u2032 , which is supposed to be greater than W ; we could use a part of it, W , and save the remainder, W \u2032 \u2212W , for useful work. With the work W we could run engine A backwards because it is a reversible engine. It will absorb some heat from the reservoir at T 2 and deliver Q 1 back to the reservoir at T 1 . After this double cycle, the net result would be that we would have put everything back the way it was before, and we would have done some excess work, namely W \u2032 \u2212W , and all we would have done would be to extract energy from the reservoir at T 2 ! We were careful to restore the heat Q 1 to the reservoir at T 1 . So that reservoir can be small and \u201cinside\u201d our combined machine A+B , whose net effect is therefore to extract a net heat W \u2032 \u2212W from the reservoir at T 2 and convert it into work. But to obtain useful work from a reservoir at a single temperature with no other changes is impossible according to Carnot\u2019s postulate; it cannot be done. Therefore no engine which absorbs a given amount of heat from a higher temperature T 1 and delivers it at the temperature T 2 can do more work than a reversible engine operating under the same temperature conditions. Now suppose that engine B is also reversible. Then, of course, not only must W \u2032 be not greater than W , but now we can reverse the argument and show that W cannot be greater than W \u2032 . So, if both engines are reversible they must both do the same amount of work, and we thus come to Carnot\u2019s brilliant conclusion: that if an engine is reversible, it makes no difference how it is designed, because the amount of work one will obtain if the engine absorbs a given amount of heat at temperature T 1 and delivers heat at some other temperature T 2 does not depend on the design of the engine. It is a property of the world, not a property of a particular engine. If we could find out what the law is that determines how much work we obtain when we absorb the heat Q 1 at T 1 and deliver heat at T 2 , this quantity would be a universal thing, independent of the substance. Of course if we knew the properties of a particular substance, we could work it out and then say that all other substances must give the same amount of work in a reversible engine. That is the key idea, the clue by which we can find the relationship between how much, for instance, a rubber band contracts when we heat it, and how much it cools when we let it contract. Imagine that we put that rubber band in a reversible machine, and that we make it go around a reversible cycle. The net result, the total amount of work done, is that universal function, that great function which is independent of substance. So we see that a substance\u2019s properties must be limited in a certain way; one cannot make up anything he wants, or he would be able to invent a substance which he could use to produce more than the maximum allowable work when he carried it around a reversible cycle. This principle, this limitation, is the only real rule that comes out of the thermodynamics. Now we shall try to find the law which determines the work W as a function of Q 1 , T 1 , and T 2 . It is clear that W is proportional to Q 1 , for if we consider two reversible engines in parallel, both working together and both double engines, the combination is also a reversible engine. If each one absorbed heat Q 1 , the two together absorb 2 Q 1 and the work done is 2W , and so on. So it is not unreasonable that W is proportional to Q 1 . Now the next important step is to find this universal law. We can, and will, do so by studying a reversible engine with the one particular substance whose laws we know, a perfect gas. It is also possible to obtain the rule by a purely logical argument, using no particular substance at all. This is one of the very beautiful pieces of reasoning in physics and we are reluctant not to show it to you, so for those who would like to see it we shall discuss it in just a moment. But first we shall use the much less abstract and simpler method of direct calculation for a perfect gas. We need only obtain formulas for Q 1 and Q 2 (for W is just Q 1 \u2212 Q 2 ), the heats exchanged with the reservoirs during the isothermal expansion or contraction. For example, how much heat Q 1 is absorbed from the reservoir at temperature T 1 during the isothermal expansion [marked (1) in Fig. 44\u20136] from point a , at pressure p a , volume V a , temperature T 1 , to point b with pressure p b , volume V b , and the same temperature T 1 ? For a perfect gas each molecule has an energy that depends only on the temperature, and since the temperature and the number of molecules are the same at a and at b , the internal energy is the same. There is no change in U ; all the work done by the gas, W= \u222b b a pdV, b during the expansion is energy Q 1 taken from the reservoir. During the expansion, pV=Nk T 1 , or p= Nk T 1 V N k T or Q 1 = \u222b b a pdV= \u222b b a Nk T 1 dV V (44.4) or Q 1 =Nk T 1 ln V b V a V is the heat taken from the reservoir at T 1 . In the same way, for the compression at T 2 [curve (3) of Fig. 44\u20136] the heat delivered to the reservoir at T 2 is Q 2 =Nk T 2 ln V c V d . (44.5) To finish our analysis we need only find a relation between V c / V d and V b / V a . This we do by noting that (2) is an adiabatic expansion from b to c , during which p V \u03b3 is a constant. Since pV=NkT , we can write this as (pV) V \u03b3\u22121 =const or, in terms of T and V , as T V \u03b3\u22121 =const , or T 1 V \u03b3\u22121 b = T 2 V \u03b3\u22121 c . (44.6) Likewise, since (4), the compression from d to a , is also adiabatic, we find T 1 V \u03b3\u22121 a = T 2 V \u03b3\u22121 d . (44.6a) If we divide this equation by the previous one, we find that V b / V a must equal V c / V d , so the ln \u2019s in (44.4) and (44.5) are equal, and that Q 1 T 1 = Q 2 T 2 . (44.7) This is the relation we were seeking. Although proved for a perfect gas engine, we know it must be true for any reversible engine at all. Now we shall see how this universal law could also be obtained by logical argument, without knowing the properties of any specific substances, as follows. Suppose that we have three engines and three temperatures, let us say T 1 , T 2 , and T 3 . Let one engine absorb heat Q 1 from the temperature T 1 and do a certain amount of work W 13 , and let it deliver heat Q 3 to the temperature T 3 (Fig. 44\u20138). Let another engine run backwards between T 2 and T 3 . Suppose that we let the second engine be of such a size that it will absorb the same heat Q 3 , and deliver the heat Q 2 . We will have to put a certain amount of work, W 32 , into it\u2014negative because the engine is running backwards. When the first machine goes through a cycle, it absorbs heat Q 1 and delivers Q 3 at the temperature T 3 ; then the second machine takes the same heat Q 3 out of the reservoir at the temperature T 3 and delivers it into the reservoir at temperature T 2 . Therefore the net result of the two machines in tandem is to take the heat Q 1 from T 1 , and deliver Q 2 at T 2 . The two machines are thus equivalent to a third one, which absorbs Q 1 at T 1 , does work W 12 , and delivers heat Q 2 at T 2 , because W 12 = W 13 \u2212 W 32 , as one can immediately show from the first law, as follows: W 13 \u2212 W 32 =( Q 1 \u2212 Q 3 )\u2212( Q 2 \u2212 Q 3 ) = Q 1 \u2212 Q 2 = W 12 . (44.8) We can now obtain the laws which relate the efficiencies of the engines, because there clearly must be some kind of relationship between the efficiencies of engines running between the temperatures T 1 and T 3 , and between T 2 and T 3 , and between T 1 and T 2 . We can make the argument very clear in the following way: We have just seen that we can always relate the heat absorbed at T 1 to the heat delivered at T 2 by finding the heat delivered at some other temperature T 3 . Therefore we can get all the engines\u2019 properties if we introduce a standard temperature, analyzing everything with that standard temperature. In other words, if we knew the efficiency of an engine running between a certain temperature T and a certain arbitrary standard temperature, then we could work out the efficiency for any other difference in temperature. Because we assume we are using only reversible engines, we can work from the initial temperature down to the standard temperature and back up to the final temperature again. We shall define the standard temperature arbitrarily as one degree. We shall also adopt a special symbol for the heat which is delivered at this standard temperature: we shall call it Q S . In other words, when a reversible engine absorbs the heat Q at temperature T , it will deliver, at the unit temperature, a heat Q S . If one engine, absorbing heat Q 1 at T 1 , delivers the heat Q S at one degree, and if an engine absorbing heat Q 2 at temperature T 2 will also deliver the same heat Q S at one degree, then it follows that an engine which absorbs heat Q 1 at the temperature T 1 will deliver heat Q 2 if it runs between T 1 and T 2 , as we have already proved by considering engines running between three temperatures. So all we really have to do is to find how much heat Q 1 we need to put in at the temperature T 1 in order to deliver a certain amount of heat Q S at the unit temperature. If we discover that, we have everything. The heat Q , of course, is a function of the temperature T . It is easy to see that the heat must increase as the temperature increases, for we know that it takes work to run an engine backwards and deliver heat at a higher temperature. It is also easy to see that the heat Q 1 must be proportional to Q S . So the great law is something like this: for a given amount of heat Q S delivered at one degree from an engine running at temperature T degrees, the heat Q absorbed must be that amount Q S times some increasing function of the temperature: Q= Q S f(T). (44.9) At this stage we are not going to try to find the formula for the above increasing function of the temperature in terms of our familiar mercury temperature scale, but instead we shall define temperature by a new scale. At one time \u201cthe temperature\u201d was defined arbitrarily by dividing the expansion of water into even degrees of a certain size. But when one then measures temperature with a mercury thermometer, one finds that the degrees are no longer even. But now we can make a definition of temperature which is independent of any particular substance. We can use that function f(T) , which does not depend on what device we use, because the efficiency of these reversible engines is independent of their working substances. Since the function we found is rising with temperature, we will define the function itself as the temperature, measured in units of the standard one-degree temperature, as follows: Q=ST, (44.10) where Q S =S\u22c5 1 \u2218 . (44.11) This means that we can tell how hot an object is by finding out how much heat is absorbed by a reversible engine working between the temperature of the object and the unit temperature (Fig. 44\u20139). If seven times more heat is taken out of a boiler than is delivered at a one-degree condenser, the temperature of the boiler will be called seven degrees, and so forth. So, by measuring how much heat is absorbed at different temperatures, we determine the temperature. The temperature defined in this way is called the absolute thermodynamic temperature, and it is independent of the substance. We shall use this definition exclusively from now on.1 Now we see that when we have two engines, one working between T 1 and one degree, the other working between T 2 and one degree, delivering the same heat at unit temperature, then the heats absorbed must be related by Q 1 T 1 =S= Q 2 T 2 . (44.12) But that means that if we have a single engine running between T 1 and T 2 , then the result of the whole analysis, the grand finale, is that Q 1 is to T 1 as Q 2 is to T 2 , if the engine absorbs energy Q 1 at temperature T 1 and delivers heat Q 2 at temperature T 2 . Whenever the engine is reversible, this relationship between the heats must follow. That is all there is to it: that is the center of the universe of thermodynamics. If this is all there is to thermodynamics, why is it considered such a difficult subject? In doing a problem involving a given mass of some substance, the condition of the substance at any moment can be described by telling what its temperature is and what its volume is. If we know the temperature and volume of a substance, and that the pressure is some function of the temperature and volume, then we know the internal energy. One could say, \u201cI do not want to do it that way. Tell me the temperature and the pressure, and I will tell you the volume. I can think of the volume as a function of temperature and pressure, and the internal energy as a function of temperature and pressure, and so on.\u201d That is why thermodynamics is hard, because everyone uses a different approach. If we could only sit down once and decide on our variables, and stick to them, it would be fairly easy. Now we start to make deductions. Just as F=ma is the center of the universe in mechanics, and it goes on and on and on after that, in the same way the principle just found is all there is to thermodynamics. But can one make conclusions out of it? We begin. To obtain our first conclusion, we shall combine both laws, the law of conservation of energy and this law which relates the heats Q 2 and Q 1 , and we can easily obtain the efficiency of a reversible engine. From the first law, we have W= Q 1 \u2212 Q 2 . According to our new principle, Q 2 = T 2 T 1 Q 1 , T so the work becomes W= Q 1 (1\u2212 T 2 T 1 )= Q 1 T 1 \u2212 T 2 T 1 , (44.13) which tells us the efficiency of the engine\u2014how much work we get out of so much heat. The efficiency of an engine is proportional to the difference in the temperatures between which the engine runs, divided by the higher temperature: Efficiency= W Q 1 = T 1 \u2212 T 2 T 1 . (44.14) The efficiency cannot be greater than unity and the absolute temperature cannot be less than zero, absolute zero. So, since T 2 must be positive, the efficiency is always less than unity. That is our first conclusion. Equation (44.7) or (44.12) can be interpreted in a special way. Working always with reversible engines, a heat Q 1 at temperature T 1 is \u201cequivalent\u201d to Q 2 at T 2 if Q 1 / T 1 = Q 2 / T 2 , in the sense that as one is absorbed the other is delivered. This suggests that if we call Q/T something, we can say: in a reversible process as much Q/T is absorbed as is liberated; there is no gain or loss of Q/T . This Q/T is called entropy, and we say \u201cthere is no net change in entropy in a reversible cycle.\u201d If T is 1 \u2218 , then the entropy is Q S / 1 \u2218 or, as we symbolized it, Q S / 1 \u2218 =S . Actually, S is the letter usually used for entropy, and it is numerically equal to the heat (which we have called Q S ) delivered to a 1 \u2218 -reservoir (entropy is not itself a heat, it is heat divided by a temperature, hence it is measured in joules per degree). Now it is interesting that besides the pressure, which is a function of the temperature and the volume, and the internal energy, which is a function of temperature and volume, we have found another quantity which is a function of the condition, i.e., the entropy of the substance. Let us try to explain how we compute it, and what we mean when we call it a \u201cfunction of the condition.\u201d Consider the system in two different conditions, much as we had in the experiment where we did the adiabatic and isothermal expansions. (Incidentally, there is no need that a heat engine have only two reservoirs, it could have three or four different temperatures at which it takes in and delivers heats, and so on.) We can move around on a pV diagram all over the place, and go from one condition to another. In other words, we could say the gas is in a certain condition a , and then it goes over to some other condition, b , and we will require that this transition, made from a to b , be reversible. Now suppose that all along the path from a to b we have little reservoirs at different temperatures, so that the heat dQ removed from the substance at each little step is delivered to each reservoir at the temperature corresponding to that point on the path. Then let us connect all these reservoirs, by reversible heat engines, to a single reservoir at the unit temperature. When we are finished carrying the substance from a to b , we shall bring all the reservoirs back to their original condition. Any heat dQ that has been absorbed from the substance at temperature T has now been converted by a reversible machine, and a certain amount of entropy dS has been delivered at the unit temperature as follows: dS=dQ/T. (44.15) Let us compute the total amount of entropy which has been delivered. The entropy difference, or the entropy needed to go from a to b by this particular reversible transformation, is the total entropy, the total of the entropy taken out of the little reservoirs, and delivered at the unit temperature: S b \u2212 S a = \u222b b a dQ T . (44.16) The question is, does the entropy difference depend upon the path taken? There is more than one way to go from a to b . Remember that in the Carnot cycle we could go from a to c in Fig. 44\u20136 by first expanding isothermally and then adiabatically; or we could first expand adiabatically and then isothermally. So the question is whether the entropy change which occurs when we go from a to b in Fig. 44\u201310 is the same on one route as it is on another. It must be the same, because if we went all the way around the cycle, going forward on one path and backward on another, we would have a reversible engine, and there would be no loss of heat to the reservoir at unit temperature. In a totally reversible cycle, no heat must be taken from the reservoir at the unit temperature, so the entropy needed to go from a to b is the same over one path as it is over another. It is independent of path, and depends only on the endpoints. We can, therefore, say that there is a certain function, which we call the entropy of the substance, that depends only on the condition, i.e., only on the volume and temperature. We can find a function S(V,T) which has the property that if we compute the change in entropy, as the substance is moved along any reversible path, in terms of the heat rejected at unit temperature, then \u0394S=\u222b dQ T , (44.17) where dQ is the heat removed from the substance at temperature T . This total entropy change is the difference between the entropy calculated at the initial and final points: \u0394S=S( V b , T b )\u2212S( V a , T a )= \u222b b a dQ T . (44.18) This expression does not completely define the entropy, but rather only the difference of entropy between two different conditions. Only if we can evaluate the entropy for one special condition can we really define S absolutely. For a long time it was believed that absolute entropy meant nothing\u2014that only differences could be defined\u2014but finally Nernst proposed what he called the heat theorem, which is also called the third law of thermodynamics. It is very simple. We will say what it is, but we will not explain why it is true. Nernst\u2019s postulate states simply that the entropy of any object at absolute zero is zero. We know of one case of T and V , namely T=0 , where S is zero; and so we can get the entropy at any other point. To give an illustration of these ideas, let us calculate the entropy of a perfect gas. In an isothermal (and therefore reversible) expansion, \u222bdQ/T is Q/T , since T is constant. Therefore (from 44.4) the change in entropy is S( V a ,T)\u2212S( V b ,T)=Nkln V a V b , V so S(V,T)=NklnV plus some function of T only. How does S depend on T ? We know that for a reversible adiabatic expansion, no heat is exchanged. Thus the entropy does not change even though V changes, provided that T changes also, such that T V \u03b3\u22121 =constant . Can you see that this implies that S(V,T)=Nk[lnV+ 1 \u03b3\u22121 lnT]+a, 1 where a is some constant independent of both V and T ? [ a is called the chemical constant. It depends on the gas in question, and may be determined experimentally from the Nernst theorem by measuring the heat liberated in cooling and condensing the gas until it is brought to a solid (or for helium, a liquid) at 0 \u2218 , by integrating \u222bdQ/T . It can also be determined theoretically by means of Planck\u2019s constant and quantum mechanics, but we shall not study it in this course.] Now we shall remark on some of the properties of the entropy of things. We first remember that if we go along a reversible cycle from a to b , then the entropy of the substance will change by S b \u2212 S a . And we remember that as we go along the path, the entropy\u2014the heat delivered at unit temperature\u2014increases according to the rule dS=dQ/T , where dQ is the heat we remove from the substance when its temperature is T . We already know that if we have a reversible cycle, the total entropy of everything is not changed, because the heat Q 1 absorbed at T 1 and the heat Q 2 delivered at T 2 correspond to equal and opposite changes in entropy, so that the net change in the entropy is zero. So for a reversible cycle there is no change in the entropy of anything, including the reservoirs. This rule may look like the conservation of energy again, but it is not; it applies only to reversible cycles. If we include irreversible cycles there is no law of conservation of entropy. We shall give two examples. First, suppose that we do irreversible work on an object by friction, generating a heat Q on some object at temperature T . The entropy is increased by Q/T . The heat Q is equal to the work, and thus when we do a certain amount of work by friction against an object whose temperature is T , the entropy of the whole world increases by W/T . Another example of irreversibility is this: If we put together two objects that are at different temperatures, say T 1 and T 2 , a certain amount of heat will flow from one to the other by itself. Suppose, for instance, we put a hot stone in cold water. Then when a certain heat \u0394Q is transferred from T 1 to T 2 , how much does the entropy of the hot stone change? It decreases by \u0394Q/ T 1 . How much does the water entropy change? It increases by \u0394Q/ T 2 . The heat will, of course, flow only from the higher temperature T 1 to the lower temperature T 2 , so that \u0394Q is positive if T 1 is greater than T 2 . So the change in entropy of the whole world is positive, and it is the difference of the two fractions: \u0394S= \u0394Q T 2 \u2212 \u0394Q T 1 . (44.19) So the following proposition is true: in any process that is irreversible, the entropy of the whole world is increased. Only in reversible processes does the entropy remain constant. Since no process is absolutely reversible, there is always at least a small gain in the entropy; a reversible process is an idealization in which we have made the gain of entropy minimal. Unfortunately, we are not going to enter into the field of thermodynamics very far. Our purpose is only to illustrate the principal ideas involved and the reasons why it is possible to make such arguments, but we will not use thermodynamics very much in this course. Thermodynamics is used very often by engineers and, particularly, by chemists. So we must learn our thermodynamics in practice in chemistry or engineering. Because it is not worthwhile duplicating everything, we shall just give some discussion of the origin of the theory, rather than much detail for special applications. The two laws of thermodynamics are often stated this way: First law: the energy of the universe is always constant. Second law: the entropy of the universe is always increasing. That is not a very good statement of the second law; it does not say, for example, that in a reversible cycle the entropy stays the same, and it does not say exactly what the entropy is. It is just a clever way of remembering the two laws, but it does not really tell us exactly where we stand. We have summarized the laws discussed in this chapter in Table 44\u20131. In the next chapter we shall apply these laws to discover the relationship between the heat generated in the expansion of a rubber band, and the extra tension when it is heated."
    },
    {
        "input": "Operators",
        "output": "All the things we have done so far in quantum mechanics could be handled with ordinary algebra, although we did from time to time show you some special ways of writing quantum-mechanical quantities and equations. We would like now to talk some more about some interesting and useful mathematical ways of describing quantum-mechanical things. There are many ways of approaching the subject of quantum mechanics, and most books use a different approach from the one we have taken. As you go on to read other books you might not see right away the connections of what you will find in them to what we have been doing. Although we will also be able to get a few useful results, the main purpose of this chapter is to tell you about some of the different ways of writing the same physics. Knowing them you should be able to understand better what other people are saying. When people were first working out classical mechanics they always wrote all the equations in terms of x -, y -, and z -components. Then someone came along and pointed out that all of the writing could be made much simpler by inventing the vector notation. It\u2019s true that when you come down to figuring something out you often have to convert the vectors back to their components. But it\u2019s generally much easier to see what\u2019s going on when you work with vectors and also easier to do many of the calculations. In quantum mechanics we were able to write many things in a simpler way by using the idea of the \u201cstate vector.\u201d The state vector |\u03c8\u27e9 has, of course, nothing to do with geometric vectors in three dimensions but is an abstract symbol that stands for a physical state, identified by the \u201clabel,\u201d or \u201cname,\u201d \u03c8 . The idea is useful because the laws of quantum mechanics can be written as algebraic equations in terms of these symbols. For instance, our fundamental law that any state can be made up from a linear combination of base states is written as |\u03c8\u27e9= \u2211 i Ci|i\u27e9, where the Ci are a set of ordinary (complex) numbers\u2014the amplitudes Ci=\u27e8i|\u03c8\u27e9 \u2014while |1\u27e9 , |2\u27e9 , |3\u27e9 , and so on, stand for the base states in some base, or representation. If you take some physical state and do something to it\u2014like rotating it, or like waiting for the time \u0394t \u2014you get a different state. We say, \u201cperforming an operation on a state produces a new state.\u201d We can express the same idea by an equation: |\u03d5\u27e9= \u02c6 A |\u03c8\u27e9. An operation on a state produces another state. The operator \u02c6 A stands for some particular operation. When this operation is performed on any state, say |\u03c8\u27e9 , it produces some other state |\u03d5\u27e9 . What does Eq. (20.2) mean? We define it this way. If you multiply the equation by \u27e8i| and expand |\u03c8\u27e9 according to Eq. (20.1), you get \u27e8i|\u03d5\u27e9= \u2211 j \u27e8i| \u02c6 A |j\u27e9\u27e8j|\u03c8\u27e9. (The states |j\u27e9 are from the same set as |i\u27e9 .) This is now just an algebraic equation. The numbers \u27e8i|\u03d5\u27e9 give the amount of each base state you will find in |\u03d5\u27e9 , and it is given in terms of a linear superposition of the amplitudes \u27e8j|\u03c8\u27e9 that you find |\u03c8\u27e9 in each base state. The numbers \u27e8i| \u02c6 A |j\u27e9 are just the coefficients which tell how much of \u27e8j|\u03c8\u27e9 goes into each sum. The operator \u02c6 A is described numerically by the set of numbers, or \u201cmatrix,\u201d Aij\u2261\u27e8i| \u02c6 A |j\u27e9. So Eq. (20.2) is a high-class way of writing Eq. (20.3). Actually it is a little more than that; something more is implied. In Eq. (20.2) we do not make any reference to a set of base states. Equation (20.3) is an image of Eq. (20.2) in terms of some set of base states. But, as you know, you may use any set you wish. And this idea is implied in Eq. (20.2). The operator way of writing avoids making any particular choice. Of course, when you want to get definite you have to choose some set. When you make your choice, you use Eq. (20.3). So the operator equation (20.2) is a more abstract way of writing the algebraic equation (20.3). It\u2019s similar to the difference between writing c=a\u00d7b instead of cx =aybz\u2212azby, cy =azbx\u2212axbz, cz =axby\u2212aybx. The first way is much handier. When you want results, however, you will eventually have to give the components with respect to some set of axes. Similarly, if you want to be able to say what you really mean by \u02c6 A , you will have to be ready to give the matrix Aij in terms of some set of base states. So long as you have in mind some set |i\u27e9 , Eq. (20.2) means just the same as Eq. (20.3). (You should remember also that once you know a matrix for one particular set of base states you can always calculate the corresponding matrix that goes with any other base. You can transform the matrix from one \u201crepresentation\u201d to another.) The operator equation in (20.2) also allows a new way of thinking. If we imagine some operator \u02c6 A , we can use it with any state |\u03c8\u27e9 to create a new state \u02c6 A |\u03c8\u27e9 . Sometimes a \u201cstate\u201d we get this way may be very peculiar\u2014it may not represent any physical situation we are likely to encounter in nature. (For instance, we may get a state that is not normalized to represent one electron.) In other words, we may at times get \u201cstates\u201d that are mathematically artificial. Such artificial \u201cstates\u201d may still be useful, perhaps as the mid-point of some calculation. We have already shown you many examples of quantum-mechanical operators. We have had the rotation operator \u02c6 R y(\u03b8) which takes a state |\u03c8\u27e9 and produces a new state, which is the old state as seen in a rotated coordinate system. We have had the parity (or inversion) operator \u02c6 P , which makes a new state by reversing all coordinates. We have had the operators \u02c6 \u03c3 x , \u02c6 \u03c3 y , and \u02c6 \u03c3 z for spin one-half particles. The operator \u02c6 J z was defined in Chapter 17 in terms of the rotation operator for a small angle \u03f5 . \u02c6 R z(\u03f5)=1+ i \u210f \u03f5 \u02c6 J z. This just means, of course, that \u02c6 R z(\u03f5)|\u03c8\u27e9=|\u03c8\u27e9+ i \u210f \u03f5 \u02c6 J z|\u03c8\u27e9. In this example, \u02c6 J z|\u03c8\u27e9 is \u210f/i\u03f5 times the state you get if you rotate |\u03c8\u27e9 by the small angle \u03f5 and then subtract the original state. It represents a \u201cstate\u201d which is the difference of two states. One more example. We had an operator \u02c6 p x \u2014called the momentum operator (x -component) defined in an equation like (20.6). If \u02c6 D x(L) is the operator which displaces a state along x by the distance L , then \u02c6 p x is defined by \u02c6 D x(\u03b4)=1+ i \u210f \u03b4 \u02c6 p x, where \u03b4 is a small displacement. Displacing the state |\u03c8\u27e9 along x by a small distance \u03b4 gives a new state |\u03c8\u2032\u27e9 . We are saying that this new state is the old state plus a small new piece i \u210f \u03b4 \u02c6 p x|\u03c8\u27e9. The operators we are talking about work on a state vector like |\u03c8\u27e9 , which is an abstract description of a physical situation. They are quite different from algebraic operators which work on mathematical functions. For instance, d/dx is an \u201coperator\u201d that works on f(x) by changing it to a new function f\u2032(x)=df/dx . Another example is the algebraic operator \u22072 . You can see why the same word is used in both cases, but you should keep in mind that the two kinds of operators are different. A quantum-mechanical operator \u02c6 A does not work on an algebraic function, but on a state vector like |\u03c8\u27e9 . Both kinds of operators are used in quantum mechanics and often in similar kinds of equations, as you will see a little later. When you are first learning the subject it is well to keep the distinction always in mind. Later on, when you are more familiar with the subject, you will find that it is less important to keep any sharp distinction between the two kinds of operators. You will, indeed, find that most books generally use the same notation for both! We\u2019ll go on now and look at some useful things you can do with operators. But first, one special remark. Suppose we have an operator \u02c6 A whose matrix in some base is Aij\u2261\u27e8i| \u02c6 A |j\u27e9 . The amplitude that the state \u02c6 A |\u03c8\u27e9 is also in some other state |\u03d5\u27e9 is \u27e8\u03d5| \u02c6 A |\u03c8\u27e9 . Is there some meaning to the complex conjugate of this amplitude? You should be able to show that \u27e8\u03d5| \u02c6 A |\u03c8\u27e9\u2217=\u27e8\u03c8| \u02c6 A \u2020|\u03d5\u27e9, where \u02c6 A \u2020 (read \u201cA dagger\u201d) is an operator whose matrix elements are A \u2020 ij =(Aji)\u2217. To get the i,j element of A\u2020 you go to the j,i element of A (the indexes are reversed) and take its complex conjugate. The amplitude that the state \u02c6 A \u2020|\u03d5\u27e9 is in |\u03c8\u27e9 is the complex conjugate of the amplitude that \u02c6 A |\u03c8\u27e9 is in |\u03d5\u27e9 . The operator \u02c6 A \u2020 is called the \u201cHermitian adjoint\u201d of \u02c6 A . Many important operators of quantum mechanics have the special property that when you take the Hermitian adjoint, you get the same operator back. If \u02c6 B is such an operator, then \u02c6 B \u2020= \u02c6 B , and it is called a \u201cself-adjoint\u201d or \u201cHermitian,\u201d operator. So far we have reminded you mainly of what you already know. Now we would like to discuss a new question. How would you find the average energy of a system\u2014say, an atom? If an atom is in a particular state of definite energy and you measure the energy, you will find a certain energy E . If you keep repeating the measurement on each one of a whole series of atoms which are all selected to be in the same state, all the measurements will give E , and the \u201caverage\u201d of your measurements will, of course, be just E . Now, however, what happens if you make the measurement on some state |\u03c8\u27e9 which is not a stationary state? Since the system does not have a definite energy, one measurement would give one energy, the same measurement on another atom in the same state would give a different energy, and so on. What would you get for the average of a whole series of energy measurements? We can answer the question by projecting the state |\u03c8\u27e9 onto the set of states of definite energy. To remind you that this is a special base set, we\u2019ll call the states |\u03b7i\u27e9 . Each of the states |\u03b7i\u27e9 has a definite energy Ei . In this representation, |\u03c8\u27e9= \u2211 i Ci|\u03b7i\u27e9. When you make an energy measurement and get some number Ei , you have found that the system was in the state \u03b7i . But you may get a different number for each measurement. Sometimes you will get E1 , sometimes E2 , sometimes E3 , and so on. The probability that you observe the energy E1 is just the probability of finding the system in the state |\u03b71\u27e9 , which is, of course, just the absolute square of the amplitude C1=\u27e8\u03b71|\u03c8\u27e9 . The probability of finding each of the possible energies Ei is Pi=|Ci|2. How are these probabilities related to the mean value of a whole sequence of energy measurements? Let\u2019s imagine that we get a series of measurements like this: E1 , E7 , E11 , E9 , E1 , E10 , E7 , E2 , E3 , E9 , E6 , E4 , and so on. We continue for, say, a thousand measurements. When we are finished we add all the energies and divide by one thousand. That\u2019s what we mean by the average. There\u2019s also a short-cut to adding all the numbers. You can count up how many times you get E1 , say that is N1 , and then count up the number of times you get E2 , call that N2 , and so on. The sum of all the energies is certainly just N1E1+N2E2+N3E3+\u22ef= \u2211 i NiEi. The average energy is this sum divided by the total number of measurements which is just the sum of all the Ni 's, which we can call N ; Eav= \u2211iNiEi N . We are almost there. What we mean by the probability of something happening is just the number of times we expect it to happen divided by the total number of tries. The ratio N i /N should\u2014for large N \u2014be very near to P i , the probability of finding the state | \u03b7 i \u27e9 , although it will not be exactly P i because of the statistical fluctuations. Let\u2019s write the predicted (or \u201cexpected\u201d) average energy as \u27e8E \u27e9 av ; then we can say that \u27e8E \u27e9 av = \u2211 i P i E i . (20.13) The same arguments apply for any measurement. The average value of a measured quantity A should be equal to \u27e8A \u27e9 av = \u2211 i P i A i , \u2211 where A i are the various possible values of the observed quantity, and P i is the probability of getting that value. Let\u2019s go back to our quantum-mechanical state |\u03c8\u27e9 . Its average energy is \u27e8E \u27e9 av = \u2211 i | C i | 2 E i = \u2211 i C \u2217 i C i E i . (20.14) Now watch this trickery! First, we write the sum as \u2211 i \u27e8\u03c8| \u03b7 i \u27e9 E i \u27e8 \u03b7 i |\u03c8\u27e9. (20.15) Next we treat the left-hand \u27e8\u03c8| as a common \u201cfactor.\u201d We can take this factor out of the sum, and write it as \u27e8\u03c8|{ \u2211 i | \u03b7 i \u27e9 E i \u27e8 \u03b7 i |\u03c8\u27e9}. { \u2211 } This expression has the form \u27e8\u03c8|\u03d5\u27e9, \u27e8 \u03c8 | \u03d5 \u27e9 where |\u03d5\u27e9 is some \u201ccooked-up\u201d state defined by |\u03d5\u27e9= \u2211 i | \u03b7 i \u27e9 E i \u27e8 \u03b7 i |\u03c8\u27e9. (20.16) It is, in other words, the state you get if you take each base state | \u03b7 i \u27e9 in the amount E i \u27e8 \u03b7 i |\u03c8\u27e9 . Now remember what we mean by the states | \u03b7 i \u27e9 . They are supposed to be the stationary states\u2014by which we mean that for each one, H ^ | \u03b7 i \u27e9= E i | \u03b7 i \u27e9. Since E i is just a number, the right-hand side is the same as | \u03b7 i \u27e9 E i , and the sum in Eq. (20.16) is the same as \u2211 i H ^ | \u03b7 i \u27e9\u27e8 \u03b7 i |\u03c8\u27e9. Now i appears only in the famous combination that contracts to unity, so \u2211 i H ^ | \u03b7 i \u27e9\u27e8 \u03b7 i |\u03c8\u27e9= H ^ \u2211 i | \u03b7 i \u27e9\u27e8 \u03b7 i |\u03c8\u27e9= H ^ |\u03c8\u27e9. Magic! Equation (20.16) is the same as |\u03d5\u27e9= H ^ |\u03c8\u27e9. (20.17) The average energy of the state |\u03c8\u27e9 can be written very prettily as \u27e8E \u27e9 av =\u27e8\u03c8| H ^ |\u03c8\u27e9. (20.18) To get the average energy you operate on |\u03c8\u27e9 with H ^ , and then multiply by \u27e8\u03c8| . A simple result. Our new formula for the average energy is not only pretty. It is also useful, because now we don\u2019t need to say anything about any particular set of base states. We don\u2019t even have to know all of the possible energy levels. When we go to calculate, we\u2019ll need to describe our state in terms of some set of base states, but if we know the Hamiltonian matrix H ij for that set we can get the average energy. Equation (20.18) says that for any set of base states |i\u27e9 , the average energy can be calculated from \u27e8E \u27e9 av = \u2211 ij \u27e8\u03c8|i\u27e9\u27e8i| H ^ |j\u27e9\u27e8j|\u03c8\u27e9, (20.19) where the amplitudes \u27e8i| H ^ |j\u27e9 are just the elements of the matrix H ij . Let\u2019s check this result for the special case that the states |i\u27e9 are the definite energy states. For them, H ^ |j\u27e9= E j |j\u27e9 , so \u27e8i| H ^ |j\u27e9= E j \u03b4 ij and \u27e8E \u27e9 av = \u2211 ij \u27e8\u03c8|i\u27e9 E j \u03b4 ij \u27e8j|\u03c8\u27e9= \u2211 i E i \u27e8\u03c8|i\u27e9\u27e8i|\u03c8\u27e9, \u2211 \u2211 which is right. Equation (20.19) can, incidentally, be extended to other physical measurements which you can express as an operator. For instance, L ^ z is the operator of the z -component of the angular momentum L . The average of the z -component for the state |\u03c8\u27e9 is \u27e8 L z \u27e9 av =\u27e8\u03c8| L ^ z |\u03c8\u27e9. One way to prove it is to think of some situation in which the energy is proportional to the angular momentum. Then all the arguments go through in the same way. In summary, if a physical observable A is related to a suitable quantum-mechanical operator A ^ , the average value of A for the state |\u03c8\u27e9 is given by \u27e8A \u27e9 av =\u27e8\u03c8| A ^ |\u03c8\u27e9. (20.20) By this we mean that \u27e8A \u27e9 av =\u27e8\u03c8|\u03d5\u27e9, (20.21) with |\u03d5\u27e9= A ^ |\u03c8\u27e9. (20.22) Suppose we want the average energy of an atom in a state described by a wave function \u03c8(r) ; How do we find it? Let\u2019s first think of a one-dimensional situation with a state |\u03c8\u27e9 defined by the amplitude \u27e8x|\u03c8\u27e9=\u03c8(x) . We are asking for the special case of Eq. (20.19) applied to the coordinate representation. Following our usual procedure, we replace the states |i\u27e9 and |j\u27e9 by |x\u27e9 and | x \u2032 \u27e9 , and change the sums to integrals. We get \u27e8E \u27e9 av =\u222c\u27e8\u03c8|x\u27e9\u27e8x| H ^ | x \u2032 \u27e9\u27e8 x \u2032 |\u03c8\u27e9dxd x \u2032 . (20.23) This integral can, if we wish, be written in the following way: \u222b\u27e8\u03c8|x\u27e9\u27e8x|\u03d5\u27e9dx, (20.24) with \u27e8x|\u03d5\u27e9=\u222b\u27e8x| H ^ | x \u2032 \u27e9\u27e8 x \u2032 |\u03c8\u27e9d x \u2032 . (20.25) The integral over x \u2032 in (20.25) is the same one we had in Chapter 16\u2014see Eq. (16.50) and Eq. (16.52)\u2014and is equal to \u2212 \u210f 2 2m d 2 d x 2 \u03c8(x)+V(x)\u03c8(x). 2 2 We can therefore write \u27e8x|\u03d5\u27e9={\u2212 \u210f 2 2m d 2 d x 2 +V(x)}\u03c8(x). (20.26) Remember that \u27e8\u03c8|x\u27e9= \u27e8x|\u03c8 \u27e9 \u2217 = \u03c8 \u2217 (x) ; using this equality, the average energy in Eq. (20.23) can be written as \u27e8E \u27e9 av =\u222b \u03c8 \u2217 (x){\u2212 \u210f 2 2m d 2 d x 2 +V(x)}\u03c8(x)dx. (20.27) Given a wave function \u03c8(x) , you can get the average energy by doing this integral. You can begin to see how we can go back and forth from the state-vector ideas to the wave-function ideas. The quantity in the braces of Eq. (20.27) is an algebraic operator.1 We will write it as H ^ H ^ =\u2212 \u210f 2 2m d 2 d x 2 +V(x). 2 2 With this notation Eq. (20.23) becomes \u27e8E \u27e9 av =\u222b \u03c8 \u2217 (x) H ^ \u03c8(x)dx. (20.28) The algebraic operator H ^ defined here is, of course, not identical to the quantum-mechanical operator H ^ . The new operator works on a function of position \u03c8(x)=\u27e8x|\u03c8\u27e9 to give a new function of x , \u03d5(x)=\u27e8x|\u03d5\u27e9 ; while H ^ operates on a state vector |\u03c8\u27e9 to give another state vector |\u03d5\u27e9 , without implying the coordinate representation or any particular representation at all. Nor is H ^ strictly the same as H ^ even in the coordinate representation. If we choose to work in the coordinate representation, we would interpret H ^ in terms of a matrix \u27e8x| H ^ | x \u2032 \u27e9 which depends somehow on the two \u201cindices\u201d x and x \u2032 ; that is, we expect\u2014according to Eq. (20.25)\u2014that \u27e8x|\u03d5\u27e9 is related to all the amplitudes \u27e8x|\u03c8\u27e9 by an integration. On the other hand, we find that H ^ is a differential operator. We have already worked out in Section 16\u20135 the connection between \u27e8x| H ^ | x \u2032 \u27e9 and the algebraic operator H ^ . We should make one qualification on our results. We have been assuming that the amplitude \u03c8(x)=\u27e8x|\u03c8\u27e9 is normalized. By this we mean that the scale has been chosen so that \u222b|\u03c8(x) | 2 dx=1; \u222b so the probability of finding the electron somewhere is unity. If you should choose to work with a \u03c8(x) which is not normalized you should write \u27e8E \u27e9 av = \u222b \u03c8 \u2217 (x) H ^ \u03c8(x)dx \u222b \u03c8 \u2217 (x)\u03c8(x)dx . (20.29) It\u2019s the same thing. Notice the similarity in form between Eq. (20.28) and Eq. (20.18). These two ways of writing the same result appear often when you work with the x -representation. You can go from the first form to the second with any A ^ which is a local operator, where a local operator is one which in the integral \u222b\u27e8x| A ^ | x \u2032 \u27e9\u27e8 x \u2032 |\u03c8\u27e9d x \u2032 \u222b can be written as A ^ \u03c8(x) , where A ^ is a differential algebraic operator. There are, however, operators for which this is not true. For them you must work with the basic equations in (20.21) and (20.22). You can easily extend the derivation to three dimensions. The result is that2 \u27e8E \u27e9 av =\u222b \u03c8 \u2217 (r) H ^ \u03c8(r)dV, (20.30) with H ^ =\u2212 \u210f 2 2m \u2207 2 +V(r), (20.31) and with the understanding that \u222b|\u03c8 | 2 dV=1. (20.32) The same equations can be extended to systems with several electrons in a fairly obvious way, but we won\u2019t bother to write down the results. With Eq. (20.30) we can calculate the average energy of an atomic state even without knowing its energy levels. All we need is the wave function. It\u2019s an important law. We\u2019ll tell you about one interesting application. Suppose you want to know the ground-state energy of some system\u2014say the helium atom, but it\u2019s too hard to solve Schr\u00f6dinger\u2019s equation for the wave function, because there are too many variables. Suppose, however, that you take a guess at the wave function\u2014pick any function you like\u2014and calculate the average energy. That is, you use Eq. (20.29)\u2014generalized to three dimensions-to find what the average energy would be if the atom were really in the state described by this wave function. This energy will certainly be higher than the ground-state energy which is the lowest possible energy the atom can have.3 Now pick another function and calculate its average energy. If it is lower than your first choice you are getting closer to the true ground-state energy. If you keep on trying all sorts of artificial states you will be able to get lower and lower energies, which come closer and closer to the ground-state energy. If you are clever, you will try some functions which have a few adjustable parameters. When you calculate the energy it will be expressed in terms of these parameters. By varying the parameters to give the lowest possible energy, you are trying out a whole class of functions at once. Eventually you will find that it is harder and harder to get lower energies and you will begin to be convinced that you are fairly close to the lowest possible energy. The helium atom has been solved in just this way\u2014not by solving a differential equation, but by making up a special function with a lot of adjustable parameters which are eventually chosen to give the lowest possible value for the average energy. What is the average value of the position of an electron in an atom? For any particular state |\u03c8\u27e9 what is the average value of the coordinate x ? We\u2019ll work in one dimension and let you extend the ideas to three dimensions or to systems with more than one particle: We have a state described by \u03c8(x) , and we keep measuring x over and over again. What is the average? It is \u222bxP(x)dx, \u222b where P(x)dx is the probability of finding the electron in a little element dx at x . Suppose the probability density P(x) varies with x as shown in Fig. 20\u20131. The electron is most likely to be found near the peak of the curve. The average value of x is also somewhere near the peak. It is, in fact, just the center of gravity of the area under the curve. We have seen earlier that P(x) is just |\u03c8(x) | 2 = \u03c8 \u2217 (x)\u03c8(x) , so we can write the average of x as \u27e8x \u27e9 av =\u222b \u03c8 \u2217 (x)x\u03c8(x)dx. (20.33) Our equation for \u27e8x \u27e9 av has the same form as Eq. (20.28). For the average energy, the energy operator H ^ appears between the two \u03c8 \u2019s, for the average position there is just x . (If you wish you can consider x to be the algebraic operator \u201cmultiply by x .\u201d) We can carry the parallelism still further, expressing the average position in a form which corresponds to Eq. (20.18). Suppose we just write \u27e8x \u27e9 av =\u27e8\u03c8|\u03b1\u27e9 (20.34) with |\u03b1\u27e9= x ^ |\u03c8\u27e9, (20.35) and then see if we can find the operator x ^ which generates the state |\u03b1\u27e9 , which will make Eq. (20.34) agree with Eq. (20.33). That is, we must find a |\u03b1\u27e9 , so that \u27e8\u03c8|\u03b1\u27e9=\u27e8x \u27e9 av =\u222b\u27e8\u03c8|x\u27e9x\u27e8x|\u03c8\u27e9dx. (20.36) First, let\u2019s expand \u27e8\u03c8|\u03b1\u27e9 in the x -representation. It is \u27e8\u03c8|\u03b1\u27e9=\u222b\u27e8\u03c8|x\u27e9\u27e8x|\u03b1\u27e9dx. (20.37) Now compare the integrals in the last two equations. You see that in the x -representation \u27e8x|\u03b1\u27e9=x\u27e8x|\u03c8\u27e9. (20.38) Operating on |\u03c8\u27e9 with x ^ to get |\u03b1\u27e9 is equivalent to multiplying \u03c8(x)=\u27e8x|\u03c8\u27e9 by x to get \u03b1(x)=\u27e8x|\u03b1\u27e9 . We have a definition of x ^ in the coordinate representation.4 [We have not bothered to try to get the x -representation of the matrix of the operator x ^ . If you are ambitious you can try to show that \u27e8x| x ^ | x \u2032 \u27e9=x\u03b4(x\u2212 x \u2032 ). (20.39) You can then work out the amusing result that x ^ |x\u27e9=x|x\u27e9. (20.40) The operator x ^ has the interesting property that when it works on the base states |x\u27e9 it is equivalent to multiplying by x .] Do you want to know the average value of x 2 ? It is \u27e8 x 2 \u27e9 av =\u222b \u03c8 \u2217 (x) x 2 \u03c8(x)dx. (20.41) Or, if you prefer you can write \u27e8 x 2 \u27e9 av =\u27e8\u03c8| \u03b1 \u2032 \u27e9 2 \u2032 with | \u03b1 \u2032 \u27e9= x ^ 2 |\u03c8\u27e9. (20.42) By x ^ 2 we mean x ^ x ^ \u2014the two operators are used one after the other. With the second form you can calculate \u27e8 x 2 \u27e9 av , using any representation (base-states) you wish. If you want the average of x n , or of any polynomial in x , you can see how to get it. Now we would like to calculate the mean momentum of an electron\u2014again, we\u2019ll stick to one dimension. Let P(p)dp be the probability that a measurement will give a momentum between p and p+dp . Then \u27e8p \u27e9 av =\u222bpP(p)dp. (20.43) Now we let \u27e8p|\u03c8\u27e9 be the amplitude that the state |\u03c8\u27e9 is in a definite momentum state |p\u27e9 . This is the same amplitude we called \u27e8momp|\u03c8\u27e9 in Section 16\u20133 and is a function of p just as \u27e8x|\u03c8\u27e9 is a function of x . There we chose to normalize the amplitude so that P(p)= 1 2\u03c0\u210f |\u27e8p|\u03c8\u27e9 | 2 . (20.44) We have, then, \u27e8p \u27e9 av =\u222b\u27e8\u03c8|p\u27e9p\u27e8p|\u03c8\u27e9 dp 2\u03c0\u210f . (20.45) The form is quite similar to what we had for \u27e8x \u27e9 av . If we want, we can play exactly the same game we did with \u27e8x \u27e9 av . First, we can write the integral above as \u222b\u27e8\u03c8|p\u27e9\u27e8p|\u03b2\u27e9 dp 2\u03c0\u210f . (20.46) You should now recognize this equation as just the expanded form of the amplitude \u27e8\u03c8|\u03b2\u27e9 \u2014expanded in terms of the base states of definite momentum. From Eq. (20.45) the state |\u03b2\u27e9 is defined in the momentum representation by \u27e8p|\u03b2\u27e9=p\u27e8p|\u03c8\u27e9 (20.47) That is, we can now write \u27e8p \u27e9 av =\u27e8\u03c8|\u03b2\u27e9 (20.48) with |\u03b2\u27e9= p ^ |\u03c8\u27e9, (20.49) where the operator p ^ is defined in terms of the p -representation by Eq. (20.47). [Again, you can if you wish show that the matrix form of p ^ is \u27e8p| p ^ | p \u2032 \u27e9=p\u03b4(p\u2212 p \u2032 ), (20.50) and that p ^ |p\u27e9=p|p\u27e9. (20.51) It works out the same as for x .] Now comes an interesting question. We can write \u27e8p \u27e9 av , as we have done in Eqs. (20.45) and (20.48), and we know the meaning of the operator p ^ in the momentum representation. But how should we interpret p ^ in the coordinate representation? That is what we will need to know if we have some wave function \u03c8(x) , and we want to compute its average momentum. Let\u2019s make clear what we mean. If we start by saying that \u27e8p \u27e9 av is given by Eq. (20.48), we can expand that equation in terms of the p -representation to get back to Eq. (20.46). If we are given the p -description of the state\u2014namely the amplitude \u27e8p|\u03c8\u27e9 , which is an algebraic function of the momentum p \u2014we can get \u27e8p|\u03b2\u27e9 from Eq. (20.47) and proceed to evaluate the integral. The question now is: What do we do if we are given a description of the state in the x -representation, namely the wave function \u03c8(x)=\u27e8x|\u03c8\u27e9 ? Well, let\u2019s start by expanding Eq. (20.48) in the x -representation. It is \u27e8p \u27e9 av =\u222b\u27e8\u03c8|x\u27e9\u27e8x|\u03b2\u27e9dx. (20.52) Now, however, we need to know what the state |\u03b2\u27e9 is in the x -representation. If we can find it, we can carry out the integral. So our problem is to find the function \u03b2(x)=\u27e8x|\u03b2\u27e9 . We can find it in the following way. In Section 16\u20133 we saw how \u27e8p|\u03b2\u27e9 was related to \u27e8x|\u03b2\u27e9 . According to Eq. (16.24), \u27e8p|\u03b2\u27e9=\u222b e \u2212ipx/\u210f \u27e8x|\u03b2\u27e9dx. (20.53) If we know \u27e8p|\u03b2\u27e9 we can solve this equation for \u27e8x|\u03b2\u27e9 . What we want, of course, is to express the result somehow in terms of \u03c8(x)=\u27e8x|\u03c8\u27e9 , which we are assuming to be known. Suppose we start with Eq. (20.47) and again use Eq. (16.24) to write \u27e8p|\u03b2\u27e9=p\u27e8p|\u03c8\u27e9=p\u222b e \u2212ipx/\u210f \u03c8(x)dx. (20.54) Since the integral is over x we can put the p inside the integral and write \u27e8p|\u03b2\u27e9=\u222b e \u2212ipx/\u210f p\u03c8(x)dx. (20.55) Compare this with (20.53). You would say that \u27e8x|\u03b2\u27e9 is equal to p\u03c8(x) . No, No! The wave function \u27e8x|\u03b2\u27e9=\u03b2(x) can depend only on x \u2014not on p . That\u2019s the whole problem. However, some ingenious fellow discovered that the integral in (20.55) could be integrated by parts. The derivative of e \u2212ipx/\u210f with respect to x is (\u2212i/\u210f)p e \u2212ipx/\u210f , so the integral in (20.55) is equivalent to \u2212 \u210f i \u222b d dx ( e \u2212ipx/\u210f )\u03c8(x)dx. \u222b If we integrate by parts, it becomes \u2212 \u210f i [ e \u2212ipx/\u210f \u03c8(x) ] +\u221e \u2212\u221e + \u210f i \u222b e \u2212ipx/\u210f d\u03c8 dx dx. \u222b So long as we are considering bound states, so that \u03c8(x) goes to zero at x=\u00b1\u221e , the bracket is zero and we have \u27e8p|\u03b2\u27e9= \u210f i \u222b e \u2212ipx/\u210f d\u03c8 dx dx. (20.56) Now compare this result with Eq. (20.53). You see that \u27e8x|\u03b2\u27e9= \u210f i d dx \u03c8(x). (20.57) We have the necessary piece to be able to complete Eq. (20.52). The answer is \u27e8p \u27e9 av =\u222b \u03c8 \u2217 (x) \u210f i d dx \u03c8(x)dx. (20.58) We have found how Eq. (20.48) looks in the coordinate representation. Now you should begin to see an interesting pattern developing. When we asked for the average energy of the state |\u03c8\u27e9 we said it was \u27e8E \u27e9 av =\u27e8\u03c8|\u03d5\u27e9, with |\u03d5\u27e9= H ^ |\u03c8\u27e9. The same thing is written in the coordinate world as \u27e8E \u27e9 av =\u222b \u03c8 \u2217 (x)\u03d5(x)dx, with \u03d5(x)= H ^ \u03c8(x). \u222b Here H ^ is an algebraic operator which works on a function of x . When we asked about the average value of x , we found that it could also be written \u27e8x \u27e9 av =\u27e8\u03c8|\u03b1\u27e9, with |\u03b1\u27e9= x ^ |\u03c8\u27e9. In the coordinate world the corresponding equations are \u27e8x \u27e9 av =\u222b \u03c8 \u2217 (x)\u03b1(x)dx, with \u03b1(x)=x\u03c8(x). \u222b When we asked about the average value of p , we wrote \u27e8p \u27e9 av =\u27e8\u03c8|\u03b2\u27e9, with |\u03b2\u27e9= p ^ |\u03c8\u27e9. In the coordinate world the equivalent equations were \u27e8p \u27e9 av =\u222b \u03c8 \u2217 (x)\u03b2(x)dx, with \u03b2(x)= \u210f i d dx \u03c8(x). \u222b In each of our three examples we start with the state |\u03c8\u27e9 and produce another (hypothetical) state by a quantum-mechanical operator. In the coordinate representation we generate the corresponding wave function by operating on the wave function \u03c8(x) with an algebraic operator. There are the following one-to-one correspondences (for one-dimensional problems): H ^ x ^ p ^ x \u2192 H ^ =\u2212 \u210f 2 2m d 2 d x 2 +V(x), \u2192x, \u2192 P ^ x = \u210f i \u2202 \u2202x . (20.59) In this list, we have introduced the symbol P ^ x for the algebraic operator (\u210f/i)\u2202/\u2202x : P ^ x = \u210f i \u2202 \u2202x , (20.60) and we have inserted the x subscript on P ^ to remind you that we have been working only with the x -component of momentum. You can easily extend the results to three dimensions. For the other components of the momentum, p ^ y p ^ z \u2192 P ^ y = \u210f i \u2202 \u2202y , \u2192 P ^ z = \u210f i \u2202 \u2202z . If you want, you can even think of an operator of the vector momentum and write p ^ \u2192 P ^ = \u210f i ( e x \u2202 \u2202x + e y \u2202 \u2202y + e z \u2202 \u2202z ), \u210f \u2202 \u2202 \u2202 where e x , e y , and e z are the unit vectors in the three directions. It looks even more elegant if we write p ^ \u2192 P ^ = \u210f i \u2207. (20.61) Our general result is that for at least some quantum-mechanical operators, there are corresponding algebraic operators in the coordinate representation. We summarize our results so far\u2014extended to three dimensions\u2014in Table 20\u20131. For each operator we have the two equivalent forms:5 |\u03d5\u27e9= A ^ |\u03c8\u27e9 (20.62) or \u03d5(r)= A ^ \u03c8(r). (20.63) We will now give a few illustrations of the use of these ideas. The first one is just to point out the relation between P ^ and H ^ . If we use P ^ x twice, we get P ^ x P ^ x =\u2212 \u210f 2 \u2202 2 \u2202 x 2 . 2 This means that we can write the equality H ^ = 1 2m { P ^ x P ^ x + P ^ y P ^ y + P ^ z P ^ z }+V(r). 1 Or, using the vector notation, H ^ = 1 2m P ^ \u22c5 P ^ +V(r). (20.64) (In an algebraic operator, any term without the operator symbol ( ^ ) means just a straight multiplication.) This equation is nice because it\u2019s easy to remember if you haven\u2019t forgotten your classical physics. Everyone knows that the energy is (nonrelativistically) just the kinetic energy p 2 /2m plus the potential energy, and H ^ is the operator of the total energy. This result has impressed people so much that they try to teach students all about classical physics before quantum mechanics. (We think differently!) But such parallels are often misleading. For one thing, when you have operators, the order of various factors is important; but that is not true for the factors in a classical equation. In Chapter 17 we defined an operator p ^ x in terms of the displacement operator D ^ x by [see Eq. (17.27)] | \u03c8 \u2032 \u27e9= D ^ x (\u03b4)|\u03c8\u27e9=(1+ i \u210f p ^ x \u03b4)|\u03c8\u27e9, (20.65) where \u03b4 is a small displacement. We should show you that this is equivalent to our new definition. According to what we have just worked out, this equation should mean the same as \u03c8 \u2032 (x)=\u03c8(x)+ \u2202\u03c8 \u2202x \u03b4. \u2202 \u03c8 But the right-hand side is just the Taylor expansion of \u03c8(x+\u03b4) , which is certainly what you get if you displace the state to the left by \u03b4 (or shift the coordinates to the right by the same amount). Our two definitions of p ^ agree! Let\u2019s use this fact to show something else. Suppose we have a bunch of particles which we label 1 , 2 , 3 , \u2026, in some complicated system. (To keep things simple we\u2019ll stick to one dimension.) The wave function describing the state is a function of all the coordinates x 1 , x 2 , x 3 , \u2026 We can write it as \u03c8( x 1 , x 2 , x 3 ,\u2026) . Now displace the system (to the left) by \u03b4 . The new wave function \u03c8 \u2032 ( x 1 , x 2 , x 3 ,\u2026)=\u03c8( x 1 +\u03b4, x 2 +\u03b4, x 3 +\u03b4,\u2026) \u2032 can be written as \u03c8 \u2032 ( x 1 , x 2 , x 3 ,\u2026)=\u03c8( x 1 , x 2 , x 3 ,\u2026) +{\u03b4 \u2202\u03c8 \u2202 x 1 +\u03b4 \u2202\u03c8 \u2202 x 2 +\u03b4 \u2202\u03c8 \u2202 x 3 +\u22ef}. (20.66) According to Eq. (20.65) the operator of the momentum of the state |\u03c8\u27e9 (let\u2019s call it the total momentum) is equal to P ^ total = \u210f i { \u2202 \u2202 x 1 + \u2202 \u2202 x 2 + \u2202 \u2202 x 3 +\u22ef}. \u210f \u2202 \u2202 \u2202 But this is just the same as P ^ total = P ^ x 1 + P ^ x 2 + P ^ x 3 +\u22ef. (20.67) The operators of momentum obey the rule that the total momentum is the sum of the momenta of all the parts. Everything holds together nicely, and many of the things we have been saying are consistent with each other. Let\u2019s for fun look at another operation\u2014the operation of orbital angular momentum. In Chapter 17 we defined an operator J ^ z in terms of R ^ z (\u03d5) , the operator of a rotation by the angle \u03d5 about the z -axis. We consider here a system described simply by a single wave function \u03c8(r) , which is a function of coordinates only, and does not take into account the fact that the electron may have its spin either up or down. That is, we want for the moment to disregard intrinsic angular momentum and think about only the orbital part. To keep the distinction clear, we\u2019ll call the orbital operator L ^ z , and define it in terms of the operator of a rotation by an infinitesimal angle \u03f5 by R ^ z (\u03f5)|\u03c8\u27e9=(1+ i \u210f \u03f5 L ^ z )|\u03c8\u27e9. i (Remember, this definition applies only to a state |\u03c8\u27e9 which has no internal spin variables, but depends only on the coordinates r=x,y,z .) If we look at the state |\u03c8\u27e9 in a new coordinate system, rotated about the z -axis by the small angle \u03f5 , we see a new state | \u03c8 \u2032 \u27e9= R ^ z (\u03f5)|\u03c8\u27e9. If we choose to describe the state |\u03c8\u27e9 in the coordinate representation\u2014that is, by its wave function \u03c8(r) , we would expect to be able to write \u03c8 \u2032 (r)=(1+ i \u210f \u03f5 L ^ z )\u03c8(r). (20.68) What is L ^ z ? Well, a point P at x and y in the new coordinate system (really x \u2032 and y \u2032 , but we will drop the primes) was formerly at x\u2212\u03f5y and y+\u03f5x , as you can see from Fig. 20\u20132. Since the amplitude for the electron to be at P isn\u2019t changed by the rotation of the coordinates we can write \u03c8 \u2032 (x,y,z) =\u03c8(x\u2212\u03f5y,y+\u03f5x,z) =\u03c8(x,y,z)\u2212\u03f5y \u2202\u03c8 \u2202x +\u03f5x \u2202\u03c8 \u2202y (remembering that \u03f5 is a small angle). This means that L ^ z = \u210f i (x \u2202 \u2202y \u2212y \u2202 \u2202x ). (20.69) That\u2019s our answer. But notice. It is equivalent to L ^ z =x P ^ y \u2212y P ^ x . (20.70) Returning to our quantum-mechanical operators, we can write L ^ z =x p ^ y \u2212y p ^ x . (20.71) This formula is easy to remember because it looks like the familiar formula of classical mechanics; it is the z -component of L=r\u00d7p. (20.72) One of the fun parts of this operator business is that many classical equations get carried over into a quantum-mechanical form. Which ones don\u2019t? There had better be some that don\u2019t come out right, because if everything did, then there would be nothing different about quantum mechanics. There would be no new physics. Here is one equation which is different. In classical physics x p x \u2212 p x x=0. 0. What is it in quantum mechanics? x ^ p ^ x \u2212 p ^ x x ^ =? Let\u2019s work it out in the x -representation. So that we\u2019ll know what we are doing we put in some wave function \u03c8(x) . We have x P ^ x \u03c8(x)\u2212 P ^ x x\u03c8(x), or x \u210f i \u2202 \u2202x \u03c8(x)\u2212 \u210f i \u2202 \u2202x x\u03c8(x). \u210f \u2202 \u210f \u2202 Remember now that the derivatives operate on everything to the right. We get x \u210f i \u2202\u03c8 \u2202x \u2212 \u210f i \u03c8(x)\u2212 \u210f i x \u2202\u03c8 \u2202x =\u2212 \u210f i \u03c8(x). (20.73) The answer is not zero. The whole operation is equivalent simply to multiplication by \u2212\u210f/i : x ^ p ^ x \u2212 p ^ x x ^ =\u2212 \u210f i . (20.74) If Planck\u2019s constant were zero, the classical and quantum results would be the same, and there would be no quantum mechanics to learn! Incidentally, if any two operators A ^ and B ^ , when taken together like this: A ^ B ^ \u2212 B ^ A ^ , do not give zero, we say that \u201cthe operators do not commute.\u201d And an equation such as (20.74) is called a \u201ccommutation rule.\u201d You can see that the commutation rule for p x and y is p ^ x y ^ \u2212 y ^ p ^ x =0. There is another very important commutation rule that has to do with angular momenta. It is L ^ x L ^ y \u2212 L ^ y L ^ x =i\u210f L ^ z . (20.75) You can get some practice with x ^ and p ^ operators by proving it for yourself. It is interesting to notice that operators which do not commute can also occur in classical physics. We have already seen this when we have talked about rotation in space. If you rotate something, such as a book, by 90 \u2218 around x and then 90 \u2218 around y , you get something different from rotating first by 90 \u2218 around y and then by 90 \u2218 around x . It is, in fact, just this property of space that is responsible for Eq. (20.75). Now we want to show you something else. How do averages change with time? Suppose for the moment that we have an operator A ^ , which does not itself have time in it in any obvious way. We mean an operator like x ^ or p ^ . (We exclude things like, say, the operator of some external potential that was being varied with time, such as V(x,t) .) Now suppose we calculate \u27e8A \u27e9 av , in some state |\u03c8\u27e9 , which is \u27e8A \u27e9 av =\u27e8\u03c8| A ^ |\u03c8\u27e9. (20.76) How will \u27e8A \u27e9 av , depend on time? Why should it? One reason might be that the operator itself depended explicitly on time\u2014for instance, if it had to do with a time-varying potential like V(x,t) . But even if the operator does not depend on t , say, for example, the operator A ^ = x ^ , the corresponding average may depend on time. Certainly the average position of a particle could be moving. How does such a motion come out of Eq. (20.76) if A ^ has no time dependence? Well, the state |\u03c8\u27e9 might be changing with time. For nonstationary states we have often shown a time dependence explicitly by writing a state as |\u03c8(t)\u27e9 . We want to show that the rate of change of \u27e8A \u27e9 av , is given by a new operator we will call A \u02d9 ^ . Remember that A ^ is an operator, so that putting a dot over the A does not here mean taking the time derivative, but is just a way of writing a new operator A \u02d9 ^ which is defined by d dt \u27e8A \u27e9 av =\u27e8\u03c8| A \u02d9 ^ |\u03c8\u27e9. (20.77) Our problem is to find the operator A \u02d9 ^ . First, we know that the rate of change of a state is given by the Hamiltonian. Specifically, i\u210f d dt |\u03c8(t)\u27e9= H ^ |\u03c8(t)\u27e9. (20.78) This is just the abstract way of writing our original definition of the Hamiltonian: i\u210f d C i dt = \u2211 j H ij C j . (20.79) If we take the complex conjugate of Eq. (20.78), it is equivalent to \u2212i\u210f d dt \u27e8\u03c8(t)|=\u27e8\u03c8(t)| H ^ . (20.80) Next, see what happens if we take the derivatives with respect to t of Eq. (20.76). Since each \u03c8 depends on t , we have d dt \u27e8A \u27e9 av =( d dt \u27e8\u03c8|) A ^ |\u03c8\u27e9+\u27e8\u03c8| A ^ ( d dt |\u03c8\u27e9). (20.81) Finally, using the two equations in (20.78) and (20.80) to replace the derivatives, we get d dt \u27e8A \u27e9 av = i \u210f {\u27e8\u03c8| H ^ A ^ |\u03c8\u27e9\u2212\u27e8\u03c8| A ^ H ^ |\u03c8\u27e9}. d i This equation is the same as d dt \u27e8A \u27e9 av = i \u210f \u27e8\u03c8| H ^ A ^ \u2212 A ^ H ^ |\u03c8\u27e9. d i Comparing this equation with Eq. (20.77), you see that A \u02d9 ^ = i \u210f ( H ^ A ^ \u2212 A ^ H ^ ). (20.82) That is our interesting proposition, and it is true for any operator A ^ . Incidentally, if the operator A ^ should itself be time dependent, we would have had A \u02d9 ^ = i \u210f ( H ^ A ^ \u2212 A ^ H ^ )+ \u2202 A ^ \u2202t . (20.83) Let us try out Eq. (20.82) on some example to see whether it really makes sense. For instance, what operator corresponds to x \u02d9 ^ ? We say it should be x \u02d9 ^ = i \u210f ( H ^ x ^ \u2212 x ^ H ^ ). (20.84) What is this? One way to find out is to work it through in the coordinate representation using the algebraic operator for H ^ . In this representation the commutator is H ^ x {\u2212 \u210f 2 2m d 2 d x 2 +V(x)}x \u2212x H ^ = \u2212x{\u2212 \u210f 2 2m d 2 d x 2 +V(x)}. If you operate with this on any wave function \u03c8(x) and work out all of the derivatives where you can, you end up after a little work with \u2212 \u210f 2 m d\u03c8 dx . 2 But this is just the same as \u2212i \u210f m P ^ x \u03c8, \u210f so we find that H ^ x ^ \u2212 x ^ H ^ =\u2212i \u210f m p ^ x (20.85) or that x \u02d9 ^ = p ^ x m . (20.86) A pretty result. It means that if the mean value of x is changing with time the drift of the center of gravity is the same as the mean momentum divided by m . Exactly like classical mechanics. Another example. What is the rate of change of the average momentum of a state? Same game. Its operator is p \u02d9 ^ = i \u210f ( H ^ p ^ \u2212 p ^ H ^ ). (20.87) Again you can work it out in the x representation. Remember that p ^ becomes d/dx , and this means that you will be taking the derivative of the potential energy V (in the H ^ )\u2014but only in the second term. It turns out that it is the only term which does not cancel, and you find that H ^ P ^ \u2212 P ^ H ^ =i\u210f dV dx d V or that p \u02d9 ^ =\u2212 dV dx . (20.88) Again the classical result. The right-hand side is the force, so we have derived Newton\u2019s law! But remember\u2014these are the laws for the operators which give the average quantities. They do not describe what goes on in detail inside an atom. Quantum mechanics has the essential difference that p ^ x ^ is not equal to x ^ p ^ . They differ by a little bit\u2014by the small number i\u210f . But the whole wondrous complications of interference, waves, and all, result from the little fact that x ^ p ^ \u2212 p ^ x ^ is not quite zero. The history of this idea is also interesting. Within a period of a few months in 1926, Heisenberg and Schr\u00f6dinger independently found correct laws to describe atomic mechanics. Schr\u00f6dinger invented his wave function \u03c8(x) and found his equation. Heisenberg, on the other hand, found that nature could be described by classical equations, except that xp\u2212px should be equal to i\u210f , which he could make happen by defining them in terms of special kinds of matrices. In our language he was using the energy-representation, with its matrices. Both Heisenberg\u2019s matrix algebra and Schr\u00f6dinger\u2019s differential equation explained the hydrogen atom. A few months later Schr\u00f6dinger was able to show that the two theories were equivalent\u2014as we have seen here. But the two different mathematical forms of quantum mechanics were discovered independently."
    },
    {
        "input": "Field Energy and Field Momentum",
        "output": "It is clear that the energy of matter is not conserved. When an object radiates light it loses energy. However, the energy lost is possibly describable in some other form, say in the light. Therefore the theory of the conservation of energy is incomplete without a consideration of the energy which is associated with the light or, in general, with the electromagnetic field. We take up now the law of conservation of energy and, also, of momentum for the fields. Certainly, we cannot treat one without the other, because in the relativity theory they are different aspects of the same four-vector. Very early in Volume I, we discussed the conservation of energy; we said then merely that the total energy in the world is constant. Now we want to extend the idea of the energy conservation law in an important way\u2014in a way that says something in detail about how energy is conserved. The new law will say that if energy goes away from a region, it is because it flows away through the boundaries of that region. It is a somewhat stronger law than the conservation of energy without such a restriction. To see what the statement means, let\u2019s look at how the law of the conservation of charge works. We described the conservation of charge by saying that there is a current density j and a charge density \u03c1 , and that when the charge decreases at some place there must be a flow of charge away from that place. We call that the conservation of charge. The mathematical form of the conservation law is \u2207\u22c5j=\u2212 \u2202\u03c1 \u2202t . (27.1) This law has the consequence that the total charge in the world is always constant\u2014there is never any net gain or loss of charge. However, the total charge in the world could be constant in another way. Suppose that there is some charge Q 1 near some point (1) while there is no charge near some point (2) some distance away (Fig. 27\u20131). Now suppose that, as time goes on, the charge Q 1 were to gradually fade away and that simultaneously with the decrease of Q 1 some charge Q 2 would appear near point (2) , and in such a way that at every instant the sum of Q 1 and Q 2 was a constant. In other words, at any intermediate state the amount of charge lost by Q 1 would be added to Q 2 . Then the total amount of charge in the world would be conserved. That\u2019s a \u201cworld-wide\u201d conservation, but not what we will call a \u201clocal\u201d conservation, because in order for the charge to get from (1) to (2) , it didn\u2019t have to appear anywhere in the space between point (1) and point (2) . Locally, the charge was just \u201clost.\u201d There is a difficulty with such a \u201cworld-wide\u201d conservation law in the theory of relativity. The concept of \u201csimultaneous moments\u201d at distant points is one which is not equivalent in different systems. Two events that are simultaneous in one system are not simultaneous for another system moving past. For \u201cworld-wide\u201d conservation of the kind described, it is necessary that the charge lost from Q 1 should appear simultaneously in Q 2 . Otherwise there would be some moments when the charge was not conserved. There seems to be no way to make the law of charge conservation relativistically invariant without making it a \u201clocal\u201d conservation law. As a matter of fact, the requirement of the Lorentz relativistic invariance seems to restrict the possible laws of nature in surprising ways. In modern quantum field theory, for example, people have often wanted to alter the theory by allowing what we call a \u201cnonlocal\u201d interaction\u2014where something here has a direct effect on something there\u2014but we get in trouble with the relativity principle. \u201cLocal\u201d conservation involves another idea. It says that a charge can get from one place to another only if there is something happening in the space between. To describe the law we need not only the density of charge, \u03c1 , but also another kind of quantity, namely j , a vector giving the rate of flow of charge across a surface. Then the flow is related to the rate of change of the density by Eq. (27.1). This is the more extreme kind of a conservation law. It says that charge is conserved in a special way\u2014conserved \u201clocally.\u201d It turns out that energy conservation is also a local process. There is not only an energy density in a given region of space but also a vector to represent the rate of flow of the energy through a surface. For example, when a light source radiates, we can find the light energy moving out from the source. If we imagine some mathematical surface surrounding the light source, the energy lost from inside the surface is equal to the energy that flows out through the surface. We want now to write quantitatively the conservation of energy for electromagnetism. To do that, we have to describe how much energy there is in any volume element of space, and also the rate of energy flow. Suppose we think first only of the electromagnetic field energy. We will let u represent the energy density in the field (that is, the amount of energy per unit volume in space) and let the vector S represent the energy flux of the field (that is, the flow of energy per unit time across a unit area perpendicular to the flow). Then, in perfect analogy with the conservation of charge, Eq. (27.1), we can write the \u201clocal\u201d law of energy conservation in the field as \u2202u \u2202t =\u2212\u2207\u22c5S. (27.2) Of course, this law is not true in general; it is not true that the field energy is conserved. Suppose you are in a dark room and then turn on the light switch. All of a sudden the room is full of light, so there is energy in the field, although there wasn\u2019t any energy there before. Equation (27.2) is not the complete conservation law, because the field energy alone is not conserved, only the total energy in the world\u2014there is also the energy of matter. The field energy will change if there is some work being done by matter on the field or by the field on matter. However, if there is matter inside the volume of interest, we know how much energy it has: Each particle has the energy m 0 c 2 / 1\u2212 v 2 / c 2 \u2212 \u2212 \u2212 \u2212 \u2212 \u2212 \u2212 \u2212 \u221a . The total energy of the matter is just the sum of all the particle energies, and the flow of this energy through a surface is just the sum of the energy carried by each particle that crosses the surface. We want now to talk only about the energy of the electromagnetic field. So we must write an equation which says that the total field energy in a given volume decreases either because field energy flows out of the volume or because the field loses energy to matter (or gains energy, which is just a negative loss). The field energy inside a volume V is \u222b V udV, \u222b and its rate of decrease is minus the time derivative of this integral. The flow of field energy out of the volume V is the integral of the normal component of S over the surface \u03a3 that encloses V , \u222b \u03a3 S\u22c5nda. \u222b So \u2212 d dt \u222b V udV= \u222b \u03a3 S\u22c5nda+ \u239b \u239d work done on matter inside V \u239e \u23a0 . (27.3) We have seen before that the field does work on each unit volume of matter at the rate E\u22c5j . [The force on a particle is F=q(E+v\u00d7B) , and the rate of doing work is F\u22c5v=qE\u22c5v . If there are N particles per unit volume, the rate of doing work per unit volume is NqE\u22c5v , but Nqv=j .] So the quantity E\u22c5j must be equal to the loss of energy per unit time and per unit volume by the field. Equation (27.3) then becomes \u2212 d dt \u222b V udV= \u222b \u03a3 S\u22c5nda+ \u222b V E\u22c5jdV. (27.4) This is our conservation law for energy in the field. We can convert it into a differential equation like Eq. (27.2) if we can change the second term to a volume integral. That is easy to do with Gauss\u2019 theorem. The surface integral of the normal component of S is the integral of its divergence over the volume inside. So Eq. (27.3) is equivalent to \u2212 \u222b V \u2202u \u2202t dV= \u222b V \u2207\u22c5SdV+ \u222b V E\u22c5jdV, \u222b \u222b \u222b where we have put the time derivative of the first term inside the integral. Since this equation is true for any volume, we can take away the integrals and we have the energy equation for the electromagnetic fields: \u2212 \u2202u \u2202t =\u2207\u22c5S+E\u22c5j. (27.5) Now this equation doesn\u2019t do us a bit of good unless we know what u and S are. Perhaps we should just tell you what they are in terms of E and B , because all we really want is the result. However, we would rather show you the kind of argument that was used by Poynting in 1884 to obtain formulas for S and u , so you can see where they come from. (You won\u2019t, however, need to learn this derivation for our later work.) The idea is to suppose that there is a field energy density u and a flux S that depend only upon the fields E and B . (For example, we know that in electrostatics, at least, the energy density can be written 1 2 \u03f5 0 E\u22c5E .) Of course, the u and S might depend on the potentials or something else, but let\u2019s see what we can work out. We can try to rewrite the quantity E\u22c5j in such a way that it becomes the sum of two terms: one that is the time derivative of one quantity and another that is the divergence of a second quantity. The first quantity would then be u and the second would be S (with suitable signs). Both quantities must be written in terms of the fields only; that is, we want to write our equality as E\u22c5j=\u2212 \u2202u \u2202t \u2212\u2207\u22c5S. (27.6) The left-hand side must first be expressed in terms of the fields only. How can we do that? By using Maxwell\u2019s equations, of course. From Maxwell\u2019s equation for the curl of B , j= \u03f5 0 c 2 \u2207\u00d7B\u2212 \u03f5 0 \u2202E \u2202t . \u2202 E Substituting this in (27.6) we will have only E \u2019s and B \u2019s: E\u22c5j= \u03f5 0 c 2 E\u22c5(\u2207\u00d7B)\u2212 \u03f5 0 E\u22c5 \u2202E \u2202t . (27.7) We are already partly finished. The last term is a time derivative\u2014it is (\u2202/\u2202t)( 1 2 \u03f5 0 E\u22c5E) . So 1 2 \u03f5 0 E\u22c5E is at least one part of u . It\u2019s the same thing we found in electrostatics. Now, all we have to do is to make the other term into the divergence of something. Notice that the first term on the right-hand side of (27.7) is the same as (\u2207\u00d7B)\u22c5E. (27.8) And, as you know from vector algebra, (a\u00d7b)\u22c5c is the same as a\u22c5(b\u00d7c) ; so our term is also the same as \u2207\u22c5(B\u00d7E) (27.9) and we have the divergence of \u201csomething,\u201d just as we wanted. Only that\u2019s wrong! We warned you before that \u2207 is \u201clike\u201d a vector, but not \u201cexactly\u201d the same. The reason it is not is because there is an additional convention from calculus: when a derivative operator is in front of a product, it works on everything to the right. In Eq. (27.7), the \u2207 operates only on B , not on E . But in the form (27.9), the normal convention would say that \u2207 operates on both B and E . So it\u2019s not the same thing. In fact, if we work out the components of \u2207\u22c5(B\u00d7E) we can see that it is equal to E\u22c5(\u2207\u00d7B) plus some other terms. It\u2019s like what happens when we take a derivative of a product in algebra. For instance, d dx (fg)= df dx g+f dg dx . d d f d Rather than working out all the components of \u2207\u22c5(B\u00d7E) , we would like to show you a trick that is very useful for this kind of problem. It is a trick that allows you to use all the rules of vector algebra on expressions with the \u2207 operator, without getting into trouble. The trick is to throw out\u2014for a while at least\u2014the rule of the calculus notation about what the derivative operator works on. You see, ordinarily, the order of terms is used for two separate purposes. One is for calculus: f(d/dx)g is not the same as g(d/dx)f ; and the other is for vectors: a\u00d7b is different from b\u00d7a . We can, if we want, choose to abandon momentarily the calculus rule. Instead of saying that a derivative operates on everything to the right, we make a new rule that doesn\u2019t depend on the order in which terms are written down. Then we can juggle terms around without worrying. Here is our new convention: we show, by a subscript, what a differential operator works on; the order has no meaning. Suppose we let the operator D stand for \u2202/\u2202x . Then D f means that only the derivative of the variable quantity f is taken. Then D f f= \u2202f \u2202x . \u2202 f But if we have D f fg , it means D f fg=( \u2202f \u2202x )g. \u2202 f But notice now that according to our new rule, f D f g means the same thing. We can write the same thing any which way: D f fg=g D f f=f D f g=fg D f . D f D f f D f D You see, the D f can even come after everything. (It\u2019s surprising that such a handy notation is never taught in books on mathematics or physics.) You may wonder: What if I want to write the derivative of fg ? I want the derivative of both terms. That\u2019s easy, you just say so; you write D f (fg)+ D g (fg) . That is just g(\u2202f/\u2202x)+f(\u2202g/\u2202x) , which is what you mean in the old notation by \u2202(fg)/\u2202x . You will see that it is now going to be very easy to work out a new expression for \u2207\u22c5(B\u00d7E) . We start by changing to the new notation; we write \u2207\u22c5(B\u00d7E)= \u2207 B \u22c5(B\u00d7E)+ \u2207 E \u22c5(B\u00d7E). (27.10) The moment we do that we don\u2019t have to keep the order straight any more. We always know that \u2207 E operates on E only, and \u2207 B operates on B only. In these circumstances, we can use \u2207 as though it were an ordinary vector. (Of course, when we are finished, we will want to return to the \u201cstandard\u201d notation that everybody usually uses.) So now we can do the various things like interchanging dots and crosses and making other kinds of rearrangements of the terms. For instance, the middle term of Eq. (27.10) can be rewritten as E\u22c5 \u2207 B \u00d7B . (You remember that a\u22c5b\u00d7c=b\u22c5c\u00d7a .) And the last term is the same as B\u22c5E\u00d7 \u2207 E . It looks freakish, but it is all right. Now if we try to go back to the ordinary convention, we have to arrange that the \u2207 operates only on its \u201cown\u201d variable. The first one is already that way, so we can just leave off the subscript. The second one needs some rearranging to put the \u2207 in front of the E , which we can do by reversing the cross product and changing sign: B\u22c5(E\u00d7 \u2207 E )=\u2212B\u22c5( \u2207 E \u00d7E). ( \u2207 ) ( \u2207 ) Now it is in a conventional order, so we can return to the usual notation. Equation (27.10) is equivalent to \u2207\u22c5(B\u00d7E)=E\u22c5(\u2207\u00d7B)\u2212B\u22c5(\u2207\u00d7E). (27.11) (A quicker way would have been to use components in this special case, but it was worth taking the time to show you the mathematical trick. You probably won\u2019t see it anywhere else, and it is very good for unlocking vector algebra from the rules about the order of terms with derivatives.) We now return to our energy conservation discussion and use our new result, Eq. (27.11), to transform the \u2207\u00d7B term of Eq. (27.7). That energy equation becomes E\u22c5j= \u03f5 0 c 2 \u2207\u22c5(B\u00d7E)+ \u03f5 0 c 2 B\u22c5(\u2207\u00d7E)\u2212 \u2202 \u2202t ( 1 2 \u03f5 0 E\u22c5E). (27.12) Now you see, we\u2019re almost finished. We have one term which is a nice derivative with respect to t to use for u and another that is a beautiful divergence to represent S . Unfortunately, there is the center term left over, which is neither a divergence nor a derivative with respect to t . So we almost made it, but not quite. After some thought, we look back at the differential equations of Maxwell and discover that \u2207\u00d7E is, fortunately, equal to \u2212\u2202B/\u2202t , which means that we can turn the extra term into something that is a pure time derivative: B\u22c5(\u2207\u00d7E)=B\u22c5(\u2212 \u2202B \u2202t )=\u2212 \u2202 \u2202t ( B\u22c5B 2 ). \u2202 B \u2202 B B Now we have exactly what we want. Our energy equation reads E\u22c5j= \u2207\u22c5( \u03f5 0 c 2 B\u00d7E)\u2212 \u2202 \u2202t ( \u03f5 0 c 2 2 B\u22c5B+ \u03f5 0 2 E\u22c5E), (27.13) which is exactly like Eq. (27.6), if we make the definitions u= \u03f5 0 2 E\u22c5E+ \u03f5 0 c 2 2 B\u22c5B (27.14) and S= \u03f5 0 c 2 E\u00d7B. (27.15) (Reversing the cross product makes the signs come out right.) Our program was successful. We have an expression for the energy density that is the sum of an \u201celectric\u201d energy density and a \u201cmagnetic\u201d energy density, whose forms are just like the ones we found in statics when we worked out the energy in terms of the fields. Also, we have found a formula for the energy flow vector of the electromagnetic field. This new vector, S= \u03f5 0 c 2 E\u00d7B , is called \u201cPoynting\u2019s vector,\u201d after its discoverer. It tells us the rate at which the field energy moves around in space. The energy which flows through a small area da per second is S\u22c5nda , where n is the unit vector perpendicular to da . (Now that we have our formulas for u and S , you can forget the derivations if you want.) Before we take up some applications of the Poynting formulas [Eqs. (27.14) and (27.15)], we would like to say that we have not really \u201cproved\u201d them. All we did was to find a possible \u201c u \u201d and a possible \u201c S .\u201d How do we know that by juggling the terms around some more we couldn\u2019t find another formula for \u201c u \u201d and another formula for \u201c S \u201d? The new S and the new u would be different, but they would still satisfy Eq. (27.6). It\u2019s possible. It can be done, but the forms that have been found always involve various derivatives of the field (and always with second-order terms like a second derivative or the square of a first derivative). There are, in fact, an infinite number of different possibilities for u and S , and so far no one has thought of an experimental way to tell which one is right! People have guessed that the simplest one is probably the correct one, but we must say that we do not know for certain what is the actual location in space of the electromagnetic field energy. So we too will take the easy way out and say that the field energy is given by Eq. (27.14). Then the flow vector S must be given by Eq. (27.15). It is interesting that there seems to be no unique way to resolve the indefiniteness in the location of the field energy. It is sometimes claimed that this problem can be resolved by using the theory of gravitation in the following argument. In the theory of gravity, all energy is the source of gravitational attraction. Therefore the energy density of electricity must be located properly if we are to know in which direction the gravity force acts. As yet, however, no one has done such a delicate experiment that the precise location of the gravitational influence of electromagnetic fields could be determined. That electromagnetic fields alone can be the source of gravitational force is an idea it is hard to do without. It has, in fact, been observed that light is deflected as it passes near the sun\u2014we could say that the sun pulls the light down toward it. Do you not want to allow that the light pulls equally on the sun? Anyway, everyone always accepts the simple expressions we have found for the location of electromagnetic energy and its flow. And although sometimes the results obtained from using them seem strange, nobody has ever found anything wrong with them\u2014that is, no disagreement with experiment. So we will follow the rest of the world\u2014besides, we believe that it is probably perfectly right. We should make one further remark about the energy formula. In the first place, the energy per unit volume in the field is very simple: It is the electrostatic energy plus the magnetic energy, if we write the electrostatic energy in terms of E 2 and the magnetic energy as B 2 . We found two such expressions as possible expressions for the energy when we were doing static problems. We also found a number of other formulas for the energy in the electrostatic field, such as \u03c1\u03d5 , which is equal to the integral of E\u22c5E in the electrostatic case. However, in an electrodynamic field the equality failed, and there was no obvious choice as to which was the right one. Now we know which is the right one. Similarly, we have found the formula for the magnetic energy that is correct in general. The right formula for the energy density of dynamic fields is Eq. (27.14). Our formula for the energy flow vector S is something quite new. We want now to see how it works in some special cases and also to see whether it checks out with anything that we knew before. The first example we will take is light. In a light wave we have an E vector and a B vector at right angles to each other and to the direction of the wave propagation. (See Fig. 27\u20132.) In an electromagnetic wave, the magnitude of B is equal to 1/c times the magnitude of E , and since they are at right angles, |E\u00d7B|= E 2 c . 2 Therefore, for light, the flow of energy per unit area per second is S= \u03f5 0 c E 2 . (27.16) For a light wave in which E= E 0 cos\u03c9(t\u2212x/c) , the average rate of energy flow per unit area, \u27e8S \u27e9 av \u2014which is called the \u201cintensity\u201d of the light\u2014is the mean value of the square of the electric field times \u03f5 0 c : Intensity=\u27e8S \u27e9 av = \u03f5 0 c\u27e8 E 2 \u27e9 av . (27.17) Believe it or not, we have already derived this result in Section 31\u20135 of Vol. I, when we were studying light. We can believe that it is right because it also checks against something else. When we have a light beam, there is an energy density in space given by Eq. (27.14). Using cB=E for a light wave, we get that u= \u03f5 0 2 E 2 + \u03f5 0 c 2 2 ( E 2 c 2 )= \u03f5 0 E 2 . 2 2 But E varies in space, so the average energy density is \u27e8u \u27e9 av = \u03f5 0 \u27e8 E 2 \u27e9 av . (27.18) Now the wave travels at the speed c , so we should think that the energy that goes through a square meter in a second is c times the amount of energy in one cubic meter. So we would say that \u27e8S \u27e9 av = \u03f5 0 c\u27e8 E 2 \u27e9 av . 2 And it\u2019s right; it is the same as Eq. (27.17). Now we take another example. Here is a rather curious one. We look at the energy flow in a capacitor that we are charging slowly. (We don\u2019t want frequencies so high that the capacitor is beginning to look like a resonant cavity, but we don\u2019t want dc either.) Suppose we use a circular parallel plate capacitor of our usual kind, as shown in Fig. 27\u20133. There is a nearly uniform electric field inside which is changing with time. At any instant the total electromagnetic energy inside is u times the volume. If the plates have a radius a and a separation h , the total energy between the plates is U=( \u03f5 0 2 E 2 )(\u03c0 a 2 h). (27.19) This energy changes when E changes. When the capacitor is being charged, the volume between the plates is receiving energy at the rate dU dt = \u03f5 0 \u03c0 a 2 hE E \u02d9 . (27.20) So there must be a flow of energy into that volume from somewhere. Of course you know that it must come in on the charging wires\u2014not at all! It can\u2019t enter the space between the plates from that direction, because E is perpendicular to the plates; E\u00d7B must be parallel to the plates. You remember, of course, that there is a magnetic field that circles around the axis when the capacitor is charging. We discussed that in Chapter 23. Using the last of Maxwell\u2019s equations, we found that the magnetic field at the edge of the capacitor is given by 2\u03c0a c 2 B= E \u02d9 \u22c5\u03c0 a 2 , or B= a 2 c 2 E \u02d9 . a Its direction is shown in Fig. 27\u20133. So there is an energy flow proportional to E\u00d7B that comes in all around the edges, as shown in the figure. The energy isn\u2019t actually coming down the wires, but from the space surrounding the capacitor. Let\u2019s check whether or not the total amount of flow through the whole surface between the edges of the plates checks with the rate of change of the energy inside\u2014it had better; we went through all that work proving Eq. (27.15) to make sure, but let\u2019s see. The area of the surface is 2\u03c0ah , and S= \u03f5 0 c 2 E\u00d7B is in magnitude \u03f5 0 c 2 E( a 2 c 2 E \u02d9 ), ( ) so the total flux of energy is \u03c0 a 2 h \u03f5 0 E E \u02d9 . It does check with Eq. (27.20). But it tells us a peculiar thing: that when we are charging a capacitor, the energy is not coming down the wires; it is coming in through the edges of the gap. That\u2019s what this theory says! How can that be? That\u2019s not an easy question, but here is one way of thinking about it. Suppose that we had some charges above and below the capacitor and far away. When the charges are far away, there is a weak but enormously spread-out field that surrounds the capacitor. (See Fig. 27\u20134.) Then, as the charges come together, the field gets stronger nearer to the capacitor. So the field energy which is way out moves toward the capacitor and eventually ends up between the plates. As another example, we ask what happens in a piece of resistance wire when it is carrying a current. Since the wire has resistance, there is an electric field along it, driving the current. Because there is a potential drop along the wire, there is also an electric field just outside the wire, parallel to the surface. (See Fig. 27\u20135.) There is, in addition, a magnetic field which goes around the wire because of the current. The E and B are at right angles; therefore there is a Poynting vector directed radially inward, as shown in the figure. There is a flow of energy into the wire all around. It is, of course, equal to the energy being lost in the wire in the form of heat. So our \u201ccrazy\u201d theory says that the electrons are getting their energy to generate heat because of the energy flowing into the wire from the field outside. Intuition would seem to tell us that the electrons get their energy from being pushed along the wire, so the energy should be flowing down (or up) along the wire. But the theory says that the electrons are really being pushed by an electric field, which has come from some charges very far away, and that the electrons get their energy for generating heat from these fields. The energy somehow flows from the distant charges into a wide area of space and then inward to the wire. Finally, in order to really convince you that this theory is obviously nuts, we will take one more example\u2014an example in which an electric charge and a magnet are at rest near each other\u2014both sitting quite still. Suppose we take the example of a point charge sitting near the center of a bar magnet, as shown in Fig. 27\u20136. Everything is at rest, so the energy is not changing with time. Also, E and B are quite static. But the Poynting vector says that there is a flow of energy, because there is an E\u00d7B that is not zero. If you look at the energy flow, you find that it just circulates around and around. There isn\u2019t any change in the energy anywhere\u2014everything which flows into one volume flows out again. It is like incompressible water flowing around. So there is a circulation of energy in this so-called static condition. How absurd it gets! Perhaps it isn\u2019t so terribly puzzling, though, when you remember that what we called a \u201cstatic\u201d magnet is really a circulating permanent current. In a permanent magnet the electrons are spinning permanently inside. So maybe a circulation of the energy outside isn\u2019t so queer after all. You no doubt begin to get the impression that the Poynting theory at least partially violates your intuition as to where energy is located in an electromagnetic field. You might believe that you must revamp all your intuitions, and, therefore have a lot of things to study here. But it seems really not necessary. You don\u2019t need to feel that you will be in great trouble if you forget once in a while that the energy in a wire is flowing into the wire from the outside, rather than along the wire. It seems to be only rarely of value, when using the idea of energy conservation, to notice in detail what path the energy is taking. The circulation of energy around a magnet and a charge seems, in most circumstances, to be quite unimportant. It is not a vital detail, but it is clear that our ordinary intuitions are quite wrong. Next we would like to talk about the momentum in the electromagnetic field. Just as the field has energy, it will have a certain momentum per unit volume. Let us call that momentum density g . Of course, momentum has various possible directions, so that g must be a vector. Let\u2019s talk about one component at a time; first, we take the x -component. Since each component of momentum is conserved we should be able to write down a law that looks something like this: \u2212 \u2202 \u2202t ( momentum of matter ) x = \u2202 g x \u2202t + ( momentum outflow ) x . \u2202 The left side is easy. The rate-of-change of the momentum of matter is just the force on it. For a particle, it is F=q(E+v\u00d7B) ; for a distribution of charges, the force per unit volume is (\u03c1E+j\u00d7B) . The \u201cmomentum outflow\u201d term, however, is strange. It cannot be the divergence of a vector because it is not a scalar; it is, rather, an x -component of some vector. Anyway, it should probably look something like \u2202a \u2202x + \u2202b \u2202y + \u2202c \u2202z , \u2202 \u2202 b \u2202 because the x -momentum could be flowing in any one of the three directions. In any case, whatever a , b , and c are, the combination is supposed to equal the outflow of the x -momentum. Now the game would be to write \u03c1E+j\u00d7B in terms only of E and B \u2014eliminating \u03c1 and j by using Maxwell\u2019s equations\u2014and then to juggle terms and make substitutions to get it into a form that looks like \u2202 g x \u2202t + \u2202a \u2202x + \u2202b \u2202y + \u2202c \u2202z . \u2202 Then, by identifying terms, we would have expressions for g x , a , b , and c . It\u2019s a lot of work, and we are not going to do it. Instead, we are only going to find an expression for g , the momentum density\u2014and by a different route. There is an important theorem in mechanics which is this: whenever there is a flow of energy in any circumstance at all (field energy or any other kind of energy), the energy flowing through a unit area per unit time, when multiplied by 1/ c 2 , is equal to the momentum per unit volume in the space. In the special case of electrodynamics, this theorem gives the result that g is 1/ c 2 times the Poynting vector: g= 1 c 2 S. (27.21) So the Poynting vector gives not only energy flow but, if you divide by c 2 , also the momentum density. The same result would come out of the other analysis we suggested, but it is more interesting to notice this more general result. We will now give a number of interesting examples and arguments to convince you that the general theorem is true. First example: Suppose that we have a lot of particles in a box\u2014let\u2019s say N per cubic meter\u2014and that they are moving along with some velocity v . Now let\u2019s consider an imaginary plane surface perpendicular to v . The energy flow through a unit area of this surface per second is equal to Nv , the number which flow through the surface per second, times the energy carried by each one. The energy in each particle is m 0 c 2 / 1\u2212 v 2 / c 2 \u2212 \u2212 \u2212 \u2212 \u2212 \u2212 \u2212 \u2212 \u221a . So the energy flow per second is Nv m 0 c 2 1\u2212 v 2 / c 2 \u2212 \u2212 \u2212 \u2212 \u2212 \u2212 \u2212 \u2212 \u221a . 2 But the momentum of each particle is m 0 v/ 1\u2212 v 2 / c 2 \u2212 \u2212 \u2212 \u2212 \u2212 \u2212 \u2212 \u2212 \u221a , so the density of momentum is N m 0 v 1\u2212 v 2 / c 2 \u2212 \u2212 \u2212 \u2212 \u2212 \u2212 \u2212 \u2212 \u221a , m v which is just 1/ c 2 times the energy flow\u2014as the theorem says. So the theorem is true for a bunch of particles. It is also true for light. When we studied light in Volume I, we saw that when the energy is absorbed from a light beam, a certain amount of momentum is delivered to the absorber. We have, in fact, shown in Chapter 34 of Vol. I that the momentum is 1/c times the energy absorbed [Eq. (34.24) of Vol. I]. If we let U be the energy arriving at a unit area per second, then the momentum arriving at a unit area per second is U/c . But the momentum is travelling at the speed c , so its density in front of the absorber must be U/ c 2 . So again the theorem is right. Finally we will give an argument due to Einstein which demonstrates the same thing once more. Suppose that we have a railroad car on wheels (assumed frictionless) with a certain big mass M . At one end there is a device which will shoot out some particles or light (or anything, it doesn\u2019t make any difference what it is), which are then stopped at the opposite end of the car. There was some energy originally at one end\u2014say the energy U indicated in Fig. 27\u20137(a)\u2014and then later it is at the opposite end, as shown in Fig. 27\u20137(c). The energy U has been displaced the distance L , the length of the car. Now the energy U has the mass U/ c 2 , so if the car stayed still, the center of gravity of the car would be moved. Einstein didn\u2019t like the idea that the center of gravity of an object could be moved by fooling around only on the inside, so he assumed that it is impossible to move the center of gravity by doing anything inside. But if that is the case, when we moved the energy U from one end to the other, the whole car must have recoiled some distance x , as shown in part (c) of the figure. You can see, in fact, that the total mass of the car, times x , must equal the mass of the energy moved, U/ c 2 times L (assuming that U/ c 2 is much less than M ): Mx= U c 2 L. (27.22) Let\u2019s now look at the special case of the energy being carried by a light flash. (The argument would work as well for particles, but we will follow Einstein, who was interested in the problem of light.) What causes the car to be moved? Einstein argued as follows: When the light is emitted there must be a recoil, some unknown recoil with momentum p . It is this recoil which makes the car roll backward. The recoil velocity v of the car will be this momentum divided by the mass of the car: v= p M . p The car moves with this velocity until the light energy U gets to the opposite end. Then, when it hits, it gives back its momentum and stops the car. If x is small, then the time the car moves is nearly equal to L/c ; so we have that x=vt=v L c = p M L c . L L Putting this x in Eq. (27.22), we get that p= U c . U Again we have the relation of energy and momentum for light, from which the argument above shows the momentum density is g= U c 2 . (27.23) You may well wonder: What is so important about the center-of-gravity theorem? Maybe it is wrong. Perhaps, but then we would also lose the conservation of angular momentum. Suppose that our boxcar is moving along a track at some speed v and that we shoot some light energy from the top to the bottom of the car\u2014say, from A to B in Fig. 27\u20138. Now we look at the angular momentum of the system about the point P . Before the energy U leaves A , it has the mass m=U/ c 2 and the velocity v , so it has the angular momentum mv r A . When it arrives at B , it has the same mass and, if the linear momentum of the whole boxcar is not to change, it must still have the velocity v . Its angular momentum about P is then mv r B . The angular momentum will be changed unless the right recoil momentum was given to the car when the light was emitted\u2014that is, unless the light carries the momentum U/c . It turns out that the angular momentum conservation and the theorem of center-of-gravity are closely related in the relativity theory. So the conservation of angular momentum would also be destroyed if our theorem were not true. At any rate, it does turn out to be a true general law, and in the case of electrodynamics we can use it to get the momentum in the field. We will mention two further examples of momentum in the electromagnetic field. We pointed out in Section 26\u20132 the failure of the law of action and reaction when two charged particles were moving on orthogonal trajectories. The forces on the two particles don\u2019t balance out, so the action and reaction are not equal; therefore the net momentum of the matter must be changing. It is not conserved. But the momentum in the field is also changing in such a situation. If you work out the amount of momentum given by the Poynting vector, it is not constant. However, the change of the particle momenta is just made up by the field momentum, so the total momentum of particles plus field is conserved. Finally, another example is the situation with the magnet and the charge, shown in Fig. 27\u20136. We were unhappy to find that energy was flowing around in circles, but now, since we know that energy flow and momentum are proportional, we know also that there is momentum circulating in the space. But a circulating momentum means that there is angular momentum. So there is angular momentum in the field. Do you remember the paradox we described in Section 17\u20134 about a solenoid and some charges mounted on a disc? It seemed that when the current turned off, the whole disc should start to turn. The puzzle was: Where did the angular momentum come from? The answer is that if you have a magnetic field and some charges, there will be some angular momentum in the field. It must have been put there when the field was built up. When the field is turned off, the angular momentum is given back. So the disc in the paradox would start rotating. This mystic circulating flow of energy, which at first seemed so ridiculous, is absolutely necessary. There is really a momentum flow. It is needed to maintain the conservation of angular momentum in the whole world."
    },
    {
        "input": "Electromagnetic Radiation",
        "output": "The most dramatic moments in the development of physics are those in which great syntheses take place, where phenomena which previously had appeared to be different are suddenly discovered to be but different aspects of the same thing. The history of physics is the history of such syntheses, and the basis of the success of physical science is mainly that we are able to synthesize. Perhaps the most dramatic moment in the development of physics during the 19th century occurred to J. C. Maxwell one day in the 1860s, when he combined the laws of electricity and magnetism with the laws of the behavior of light. As a result, the properties of light were partly unravelled\u2014that old and subtle stuff that is so important and mysterious that it was felt necessary to arrange a special creation for it when writing Genesis. Maxwell could say, when he was finished with his discovery, \u201cLet there be electricity and magnetism, and there is light!\u201d For this culminating moment there was a long preparation in the gradual discovery and unfolding of the laws of electricity and magnetism. This story we shall reserve for detailed study next year. However, the story is, briefly, as follows. The gradually discovered properties of electricity and magnetism, of electric forces of attraction and repulsion, and of magnetic forces, showed that although these forces were rather complex, they all fell off inversely as the square of the distance. We know, for example, that the simple Coulomb law for stationary charges is that the electric force field varies inversely as the square of the distance. As a consequence, for sufficiently great distances there is very little influence of one system of charges on another. Maxwell noted that the equations or the laws that had been discovered up to this time were mutually inconsistent when he tried to put them all together, and in order for the whole system to be consistent, he had to add another term to his equations. With this new term there came an amazing prediction, which was that a part of the electric and magnetic fields would fall off much more slowly with the distance than the inverse square, namely, inversely as the first power of the distance! And so he realized that electric currents in one place can affect other charges far away, and he predicted the basic effects with which we are familiar today\u2014radio transmission, radar, and so on. It seems a miracle that someone talking in Europe can, with mere electrical influences, be heard thousands of miles away in Los Angeles. How is it possible? It is because the fields do not vary as the inverse square, but only inversely as the first power of the distance. Finally, then, even light itself was recognized to be electric and magnetic influences extending over vast distances, generated by an almost incredibly rapid oscillation of the electrons in the atoms. All these phenomena we summarize by the word radiation or, more specifically, electromagnetic radiation, there being one or two other kinds of radiation also. Almost always, radiation means electromagnetic radiation. And thus is the universe knit together. The atomic motions of a distant star still have sufficient influence at this great distance to set the electrons in our eye in motion, and so we know about the stars. If this law did not exist, we would all be literally in the dark about the exterior world! And the electric surgings in a galaxy five billion light years away\u2014which is the farthest object we have found so far\u2014can still influence in a significant and detectable way the currents in the great \u201cdish\u201d in front of a radio telescope. And so it is that we see the stars and the galaxies. This remarkable phenomenon is what we shall discuss in the present chapter. At the beginning of this course in physics we outlined a broad picture of the world, but we are now better prepared to understand some aspects of it, and so we shall now go over some parts of it again in greater detail. We begin by describing the position of physics at the end of the 19th century. All that was then known about the fundamental laws can be summarized as follows. First, there were laws of forces: one force was the law of gravitation, which we have written down several times; the force on an object of mass m , due to another of mass M , is given by F=GmMer/r2, where er is a unit vector directed from m to M , and r is the distance between them. Next, the laws of electricity and magnetism, as known at the end of the 19th century, are these: the electrical forces acting on a charge q can be described by two fields, called E and B , and the velocity v of the charge q , by the equation F=q(E+v\u00d7B). (28.2) To complete this law, we have to say what the formulas for E and B are in a given circumstance: if a number of charges are present, E and the B are each the sum of contributions, one from each individual charge. So if we can find the E and B produced by a single charge, we need only to add all the effects from all the charges in the universe to get the total E and B ! This is the principle of superposition. What is the formula for the electric and magnetic field produced by one individual charge? It turns out that this is very complicated, and it takes a great deal of study and sophistication to appreciate it. But that is not the point. We write down the law now only to impress the reader with the beauty of nature, so to speak, i.e., that it is possible to summarize all the fundamental knowledge on one page, with notations that he is now familiar with. This law for the fields of an individual charge is complete and accurate, so far as we know (except for quantum mechanics) but it looks rather complicated. We shall not study all the pieces now; we only write it down to give an impression, to show that it can be written, and so that we can see ahead of time roughly what it looks like. As a matter of fact, the most useful way to write the correct laws of electricity and magnetism is not the way we shall now write them, but involves what are called field equations, which we shall learn about next year. But the mathematical notations for these are different and new, and so we write the law in an inconvenient form for calculation, but in notations that we now know. The electric field, E , is given by E= \u2212q 4\u03c0 \u03f5 0 [ e r \u2032 r \u20322 + r \u2032 c d dt ( e r \u2032 r \u20322 )+ 1 c 2 d 2 d t 2 e r \u2032 ]. (28.3) What do the various terms tell us? Take the first term, E=\u2212q e r \u2032 /4\u03c0 \u03f5 0 r \u20322 . That, of course, is Coulomb\u2019s law, which we already know: q is the charge that is producing the field; e r is the unit vector in the direction from the point P where E is measured, r is the distance from P to q . But, Coulomb\u2019s law is wrong. The discoveries of the 19th century showed that influences cannot travel faster than a certain fundamental speed c , which we now call the speed of light. It is not correct that the first term is Coulomb\u2019s law, not only because it is not possible to know where the charge is now and at what distance it is now, but also because the only thing that can affect the field at a given place and time is the behavior of the charges in the past. How far in the past? The time delay, or retarded time, so-called, is the time it takes, at speed c , to get from the charge to the field point P . The delay is r \u2032 /c . So to allow for this time delay, we put a little prime on r , meaning how far away it was when the information now arriving at P left q . Just for a moment suppose that the charge carried a light, and that the light could only come to P at the speed c . Then when we look at q , we would not see where it is now, of course, but where it was at some earlier time. What appears in our formula is the apparent direction e r \u2032 \u2014the direction it used to be\u2014the so-called retarded direction\u2014and at the retarded distance r \u2032 . That would be easy enough to understand, too, but it is also wrong. The whole thing is much more complicated. There are several more terms. The next term is as though nature were trying to allow for the fact that the effect is retarded, if we might put it very crudely. It suggests that we should calculate the delayed Coulomb field and add a correction to it, which is its rate of change times the time delay that we use. Nature seems to be attempting to guess what the field at the present time is going to be, by taking the rate of change and multiplying by the time that is delayed. But we are not yet through. There is a third term\u2014the second derivative, with respect to t , of the unit vector in the direction of the charge. Now the formula is finished, and that is all there is to the electric field from an arbitrarily moving charge. The magnetic field is given by B=\u2212 e r \u2032 \u00d7E/c. (28.4) We have written these down only for the purpose of showing the beauty of nature or, in a way, the power of mathematics. We do not pretend to understand why it is possible to write so much in such a small space, but (28.3) and (28.4) contain the machinery by which electric generators work, how light operates, all the phenomena of electricity and magnetism. Of course, to complete the story we also need to know something about the behavior of the materials involved\u2014the properties of matter\u2014which are not described properly by (28.3). To finish with our description of the world of the 19th century we must mention one other great synthesis which occurred in that century, one with which Maxwell had a great deal to do also, and that was the synthesis of the phenomena of heat and mechanics. We shall study that subject soon. What had to be added in the 20th century was that the dynamical laws of Newton were found to be all wrong, and quantum mechanics had to be introduced to correct them. Newton\u2019s laws are approximately valid when the scale of things is sufficiently large. These quantum-mechanical laws, combined with the laws of electricity, have only recently been combined to form a set of laws called quantum electrodynamics. In addition, there were discovered a number of new phenomena, of which the first was radioactivity, discovered by Becquerel in 1896\u2014he just sneaked it in under the 19th century. This phenomenon of radioactivity was followed up to produce our knowledge of nuclei and new kinds of forces that are not gravitational and not electrical, but new particles with different interactions, a subject which has still not been unravelled. For those purists who know more (the professors who happen to be reading this), we should add that when we say that (28.3) is a complete expression of the knowledge of electrodynamics, we are not being entirely accurate. There was a problem that was not quite solved at the end of the 19th century. When we try to calculate the field from all the charges including the charge itself that we want the field to act on, we get into trouble trying to find the distance, for example, of a charge from itself, and dividing something by that distance, which is zero. The problem of how to handle the part of this field which is generated by the very charge on which we want the field to act is not yet solved today. So we leave it there; we do not have a complete solution to that puzzle yet, and so we shall avoid the puzzle for as long as we can. That, then, is a summary of the world picture. Now let us use it to discuss the phenomena called radiation. To discuss these phenomena, we must select from Eq. (28.3) only that piece which varies inversely as the distance and not as the square of the distance. It turns out that when we finally do find that piece, it is so simple in its form that it is legitimate to study optics and electrodynamics in an elementary way by taking it as \u201cthe law\u201d of the electric field produced by a moving charge far away. We shall take it temporarily as a given law which we will learn about in detail next year. Of the terms appearing in (28.3), the first one evidently goes inversely as the square of the distance, and the second is only a correction for delay, so it is easy to show that both of them vary inversely as the square of the distance. All of the effects we are interested in come from the third term, which is not very complicated, after all. What this term says is: look at the charge and note the direction of the unit vector (we can project the end of it onto the surface of a unit sphere). As the charge moves around, the unit vector wiggles, and the acceleration of that unit vector is what we are looking for. That is all. Thus E= \u2212q 4\u03c0 \u03f5 0 c 2 d 2 e r \u2032 d t 2 (28.5) is a statement of the laws of radiation, because that is the only important term when we get far enough away that the fields are varying inversely as the distance. (The parts that go as the square have fallen off so much that we are not interested in them.) Now we can go a little bit further in studying (28.5) to see what it means. Suppose a charge is moving in any manner whatsoever, and we are observing it from a distance. We imagine for a moment that in a sense it is \u201clit up\u201d (although it is light that we are trying to explain); we imagine it as a little white dot. Then we would see this white dot running around. But we don\u2019t see exactly how it is running around right now, because of the delay that we have been talking about. What counts is how it was moving earlier. The unit vector e r \u2032 is pointed toward the apparent position of the charge. Of course, the end of e r \u2032 goes on a slight curve, so that its acceleration has two components. One is the transverse piece, because the end of it goes up and down, and the other is a radial piece because it stays on a sphere. It is easy to demonstrate that the latter is much smaller and varies as the inverse square of r when r is very great. This is easy to see, for when we imagine that we move a given source farther and farther away, then the wigglings of e r \u2032 look smaller and smaller, inversely as the distance, but the radial component of acceleration is varying much more rapidly than inversely as the distance. So for practical purposes all we have to do is project the motion on a plane at unit distance. Therefore we find the following rule: Imagine that we look at the moving charge and that everything we see is delayed\u2014like a painter trying to paint a scene on a screen at a unit distance. A real painter, of course, does not take into account the fact that light is going at a certain speed, but paints the world as he sees it. We want to see what his picture would look like. So we see a dot, representing the charge, moving about in the picture. The acceleration of that dot is proportional to the electric field. That is all\u2014all we need. Thus Eq. (28.5) is the complete and correct formula for radiation; even relativity effects are all contained in it. However, we often want to apply it to a still simpler circumstance in which the charges are moving only a small distance at a relatively slow rate. Since they are moving slowly, they do not move an appreciable distance from where they start, so that the delay time is practically constant. Then the law is still simpler, because the delay time is fixed. Thus we imagine that the charge is executing a very tiny motion at an effectively constant distance. The delay at the distance r is r/c . Then our rule becomes the following: If the charged object is moving in a very small motion and it is laterally displaced by the distance x(t) , then the angle that the unit vector e r \u2032 is displaced is x/r , and since r is practically constant, the x -component of d 2 e r \u2032 /d t 2 is simply the acceleration of x itself at an earlier time divided by r , and so finally we get the law we want, which is E x (t)= \u2212q 4\u03c0 \u03f5 0 c 2 r a x (t\u2212 r c ). (28.6) Only the component a x , perpendicular to the line of sight, is important. Let us see why that is. Evidently, if the charge is moving in and out straight at us, the unit vector in that direction does not wiggle at all, and it has no acceleration. So it is only the sidewise motion which is important, only the acceleration that we see projected on the screen. As our fundamental \u201claw\u201d of electromagnetic radiation, we are going to assume that (28.6) is true, i.e., that the electric field produced by an accelerating charge which is moving nonrelativistically at a very large distance r approaches that form. The electric field varies inversely as r and is proportional to the acceleration of the charge, projected onto the \u201cplane of sight,\u201d and this acceleration is not today\u2019s acceleration, but the acceleration that it had at an earlier time, the amount of delay being a time, r/c . In the remainder of this chapter we shall discuss this law so that we can understand it better physically, because we are going to use it to understand all of the phenomena of light and radio propagation, such as reflection, refraction, interference, diffraction, and scattering. It is the central law, and is all we need. All the rest of Eq. (28.3) was written down only to set the stage, so that we could appreciate where (28.6) fits and how it comes about. We shall discuss (28.3) further next year. In the meantime, we shall accept it as true, but not just on a theoretical basis. We may devise a number of experiments which illustrate the character of the law. In order to do so, we need an accelerating charge. It should be a single charge, but if we can make a great many charges move together, all the same way, we know that the field will be the sum of the effects of each of the individual charges; we just add them together. As an example, consider two pieces of wire connected to a generator, as shown in Fig. 28\u20131. The idea is that the generator makes a potential difference, or a field, which pulls electrons away from piece A and pushes them into B at one moment, and then, an infinitesimal time later, it reverses the effect and pulls the electrons out of B and pumps them back into A ! So in these two wires charges, let us say, are accelerating upward in wire A and upward in wire B for one moment, and a moment later they are accelerating downward in wire A and downward in wire B . The fact that we need two wires and a generator is merely that this is a way of doing it. The net result is that we merely have a charge accelerating up and down as though A and B were one single wire. A wire that is very short compared with the distance light travels in one oscillation period is called an electric dipole oscillator. Thus we have the circumstance that we need to apply our law, which tells us that this charge makes an electric field, and so we need an instrument to detect an electric field, and the instrument we use is the same thing\u2014a pair of wires like A and B ! If an electric field is applied to such a device, it will produce a force which will pull the electrons up on both wires or down on both wires. This signal is detected by means of a rectifier mounted between A and B , and a tiny, fine wire carries the information into an amplifier, where it is amplified so we can hear the audiofrequency tone with which the radiofrequency is modulated. When this probe feels an electric field, there will be a loud noise coming out of the loudspeaker, and when there is no electric field driving it, there will be no noise. Because the room in which the waves we are measuring has other objects in it, our electric field will shake electrons in these other objects; the electric field makes these other charges go up and down, and in going up and down, these also produce an effect on our probe. Thus for a successful experiment we must hold things fairly close together, so that the influences from the walls and from ourselves\u2014the reflected waves\u2014are relatively small. So the phenomena will not turn out to appear to be precisely and perfectly in accord with Eq. (28.6), but will be close enough that we shall be able to appreciate the law. Now we turn the generator on and hear the audio signal. We find a strong field when the detector D is parallel to the generator G at point 1 (Fig. 28\u20132). We find the same amount of field also at any other azimuth angle about the axis of G , because it has no directional effects. On the other hand, when the detector is at 3 the field is zero. That is all right, because our formula said that the field should be the acceleration of the charge projected perpendicular to the line of sight. Therefore when we look down on G , the charge is moving toward and away from D , and there is no effect. So that checks the first rule, that there is no effect when the charge is moving directly toward us. Secondly, the formula says that the electric field should be perpendicular to r and in the plane of G and r ; so if we put D at 1 but rotate it 90 \u2218 , we should get no signal. And this is just what we find, the electric field is indeed vertical, and not horizontal. When we move D to some intermediate angle, we see that the strongest signal occurs when it is oriented as shown, because although G is vertical, it does not produce a field that is simply parallel to itself\u2014it is the projection of the acceleration perpendicular to the line of sight that counts. The signal is weaker at 2 than it is at 1 , because of the projection effect. Next, we may test what happens when we have two sources side by side several wavelengths apart (Fig. 28\u20133). The law is that the two sources should add their effects at point 1 when both of the sources are connected to the same generator and are both moving up and down the same way, so that the total electric field is the sum of the two and is twice as strong as it was before. Now comes an interesting possibility. Suppose we make the charges in S 1 and S 2 both accelerate up and down, but delay the timing of S 2 so that they are 180 \u2218 out of phase. Then the field produced by S 1 will be in one direction and the field produced by S 2 will be in the opposite direction at any instant, and therefore we should get no effect at point 1 . The phase of oscillation is neatly adjustable by means of a pipe which is carrying the signal to S 2 . By changing the length of this pipe we change the time it takes the signal to arrive at S 2 and thus we change the phase of that oscillation. By adjusting this length, we can indeed find a place where there is no more signal left, in spite of the fact that both S 1 and S 2 are moving! The fact that they are both moving can be checked, because if we cut one out, we can see the motion of the other. So the two of them together can produce zero if everything is adjusted correctly. Now, it is very interesting to show that the addition of the two fields is in fact a vector addition. We have just checked it for up and down motion, but let us check two nonparallel directions. First, we restore S 1 and S 2 to the same phase; that is, they are again moving together. But now we turn S 1 through 90 \u2218 , as shown in Fig. 28\u20134. Now we should have at point 1 the sum of two effects, one of which is vertical and the other horizontal. The electric field is the vector sum of these two in-phase signals\u2014they are both strong at the same time and go through zero together; the total field should be a signal R at 45 \u2218 . If we turn D to get the maximum noise, it should be at about 45 \u2218 , and not vertical. And if we turn it at right angles to that direction, we should get zero, which is easy to measure. Indeed, we observe just such behavior! Now, how about the retardation? How can we demonstrate that the signal is retarded? We could, with a great deal of equipment, measure the time at which it arrives, but there is another, very simple way. Referring again to Fig. 28\u20133, suppose that S 1 and S 2 are in phase. They are both shaking together, and they produce equal electric fields at point 1 . But suppose we go to a certain place 2 which is closer to S 2 and farther from S 1 . Then, in accordance with the principle that the acceleration should be retarded by an amount equal to r/c , if the retardations are not equal, the signals are no longer in phase. Thus it should be possible to find a position at which the distances of D from S 1 and S 2 differ by some amount \u0394 , in such a manner that there is no net signal. That is, the distance \u0394 is to be the distance light goes in one-half an oscillation of the generator. We may go still further, and find a point where the difference is greater by a whole cycle; that is to say, the signal from the first antenna reaches point 3 with a delay in time that is greater than that of the second antenna by just the length of time it takes for the electric current to oscillate once, and therefore the two electric fields produced at 3 are in phase again. At point 3 the signal is strong again. This completes our discussion of the experimental verification of some of the important features of Eq. (28.6). Of course we have not really checked the 1/r variation of the electric field strength, or the fact that there is also a magnetic field that goes along with the electric field. To do so would require rather sophisticated techniques and would hardly add to our understanding at this point. In any case, we have checked those features that are of the greatest importance for our later applications, and we shall come back to study some of the other properties of electromagnetic waves next year."
    },
    {
        "input": "Rotation In Space",
        "output": "In this chapter we shall discuss one of the most remarkable and amusing consequences of mechanics, the behavior of a rotating wheel. In order to do this we must first extend the mathematical formulation of rotational motion, the principles of angular momentum, torque, and so on, to three-dimensional space. We shall not use these equations in all their generality and study all their consequences, because this would take many years, and we must soon turn to other subjects. In an introductory course we can present only the fundamental laws and apply them to a very few situations of special interest. First, we notice that if we have a rotation in three dimensions, whether of a rigid body or any other system, what we deduced for two dimensions is still right. That is, it is still true that xFy\u2212yFx is the torque \u201cin the xy -plane,\u201d or the torque \u201caround the z -axis.\u201d It also turns out that this torque is still equal to the rate of change of xpy\u2212ypx , for if we go back over the derivation of Eq. (18.15) from Newton\u2019s laws we see that we did not have to assume that the motion was in a plane; when we differentiate xpy\u2212ypx , we get xFy\u2212yFx , so this theorem is still right. The quantity xpy\u2212ypx , then, we call the angular momentum belonging to the xy -plane, or the angular momentum about the z -axis. This being true, we can use any other pair of axes and get another equation. For instance, we can use the yz -plane, and it is clear from symmetry that if we just substitute y for x and z for y , we would find yFz\u2212zFy for the torque and ypz\u2212zpy would be the angular momentum associated with the yz -plane. Of course we could have another plane, the zx -plane, and for this we would find zFx\u2212xFz=d/dt(zpx\u2212xpz) . That these three equations can be deduced for the motion of a single particle is quite clear. Furthermore, if we added such things as xpy\u2212ypx together for many particles and called it the total angular momentum, we would have three kinds for the three planes xy , yz , and zx , and if we did the same with the forces, we would talk about the torque in the planes xy , yz , and zx also. Thus we would have laws that the external torque associated with any plane is equal to the rate of change of the angular momentum associated with that plane. This is just a generalization of what we wrote in two dimensions. But now one may say, \u201cAh, but there are more planes; after all, can we not take some other plane at some angle, and calculate the torque on that plane from the forces? Since we would have to write another set of equations for every such plane, we would have a lot of equations!\u201d Interestingly enough, it turns out that if we were to work out the combination x\u2032Fy\u2032\u2212y\u2032Fx\u2032 for another plane, measuring the x\u2032 , Fy\u2032 , etc., in that plane, the result can be written as some combination of the three expressions for the xy -, yz - and zx -planes. There is nothing new. In other words, if we know what the three torques in the xy -, yz -, and zx -planes are, then the torque in any other plane, and correspondingly the angular momentum also, can be written as some combination of these: six percent of one and ninety-two percent of another, and so on. This property we shall now analyze. Suppose that in the xyz -axes, Joe has worked out all his torques and his angular momenta in his planes. But Moe has axes x\u2032,y\u2032,z\u2032 in some other direction. To make it a little easier, we shall suppose that only the x - and y -axes have been turned. Moe\u2019s x\u2032 and y\u2032 are new, but his z\u2032 happens to be the same. That is, he has new planes, let us say, for yz and zx . He therefore has new torques and angular momenta which he would work out. For example, his torque in the x\u2032y\u2032 -plane would be equal to x\u2032Fy\u2032\u2212y\u2032Fx\u2032 and so forth. What we must now do is to find the relationship between the new torques and the old torques, so we will be able to make a connection from one set of axes to the other. Someone may say, \u201cThat looks just like what we did with vectors.\u201d And indeed, that is exactly what we are intending to do. Then he may say, \u201cWell, isn\u2019t torque just a vector?\u201d It does turn out to be a vector, but we do not know that right away without making an analysis. So in the following steps we shall make the analysis. We shall not discuss every step in detail, since we only want to illustrate how it works. The torques calculated by Joe are \u03c4xy =x Fy \u2212y Fx , \u03c4yz =y Fz \u2212z Fy , \u03c4zx =z Fx \u2212x Fz . We digress at this point to note that in such cases as this one may get the wrong sign for some quantity if the coordinates are not handled in the right way. Why not write \u03c4yz=zFy\u2212yFz ? The problem arises from the fact that a coordinate system may be either \u201cright-handed\u201d or \u201cleft-handed.\u201d Having chosen (arbitrarily) a sign for, say \u03c4xy , then the correct expressions for the other two quantities may always be found by interchanging the letters xyz in either order or Moe now calculates the torques in his system: \u03c4x\u2032y\u2032 =x\u2032 Fy\u2032 \u2212y\u2032 Fx\u2032 , \u03c4y\u2032z\u2032 =y\u2032 Fz\u2032 \u2212z\u2032 Fy\u2032 , \u03c4z\u2032x\u2032 =z\u2032 Fx\u2032 \u2212x\u2032 Fz\u2032 . Now we suppose that one coordinate system is rotated by a fixed angle \u03b8 , such that the z - and z\u2032 -axes are the same. (This angle \u03b8 has nothing to do with rotating objects or what is going on inside the coordinate system. It is merely the relationship between the axes used by one man and the axes used by the other, and is supposedly constant.) Thus the coordinates of the two systems are related by x\u2032 =x cos\u03b8+y sin\u03b8, y\u2032 =y cos\u03b8\u2212x sin\u03b8, z\u2032 =z . Likewise, because force is a vector it transforms into the new system in the same way as do x , y , and z , since a thing is a vector if and only if the various components transform in the same way as x , y , and z : Fx\u2032 =Fx cos\u03b8+Fy sin\u03b8, Fy\u2032 =Fy cos\u03b8\u2212Fx sin\u03b8, Fz\u2032 =Fz . Now we can find out how the torque transforms by merely substituting for x \u2032 , y \u2032 , and z \u2032 the expressions (20.3), and for F x \u2032 , F y \u2032 , F z \u2032 those given by (20.4), all into (20.2). So, we have a rather long string of terms for \u03c4 x \u2032 y \u2032 and (rather surprisingly at first) it turns out that it comes right down to x F y \u2212y F x , which we recognize to be the torque in the xy -plane: \u03c4 x \u2032 y \u2032 = \u2212 (xcos\u03b8+ysin\u03b8)( F y cos\u03b8\u2212 F x sin\u03b8) (ycos\u03b8\u2212xsin\u03b8)( F x cos\u03b8+ F y sin\u03b8) = \u2212 + + x F y ( cos 2 \u03b8+ sin 2 \u03b8) y F x ( sin 2 \u03b8+ cos 2 \u03b8) x F x (\u2212sin\u03b8cos\u03b8+sin\u03b8cos\u03b8) y F y (sin\u03b8cos\u03b8\u2212sin\u03b8cos\u03b8) =x F y \u2212y F x = \u03c4 xy . (20.5) That result is clear, for if we only turn our axes in the plane, the twist around z in that plane is no different than it was before, because it is the same plane! What will be more interesting is the expression for \u03c4 y \u2032 z \u2032 , because that is a new plane. We now do exactly the same thing with the y \u2032 z \u2032 -plane, and it comes out as follows: \u03c4 y \u2032 z \u2032 = (ycos\u03b8\u2212xsin\u03b8) F z \u2212 z( F y cos\u03b8\u2212 F x sin\u03b8) =(y F z \u2212z F y )cos\u03b8+(z F x \u2212x F z )sin\u03b8 = \u03c4 yz cos\u03b8+ \u03c4 zx sin\u03b8. (20.6) Finally, we do it for z \u2032 x \u2032 : \u03c4 z \u2032 x \u2032 = z( F x cos\u03b8+ F y sin\u03b8) \u2212(xcos\u03b8+ysin\u03b8) F z =(z F x \u2212x F z )cos\u03b8\u2212(y F z \u2212z F y )sin\u03b8 = \u03c4 zx cos\u03b8\u2212 \u03c4 yz sin\u03b8. (20.7) We wanted to get a rule for finding torques in new axes in terms of torques in old axes, and now we have the rule. How can we ever remember that rule? If we look carefully at (20.5), (20.6), and (20.7), we see that there is a close relationship between these equations and the equations for x , y , and z . If, somehow, we could call \u03c4 xy the z -component of something, let us call it the z -component of \u03c4 , then it would be all right; we would understand (20.5) as a vector transformation, since the z -component would be unchanged, as it should be. Likewise, if we associate with the yz -plane the x -component of our newly invented vector, and with the zx -plane, the y -component, then these transformation expressions would read \u03c4 z \u2032 \u03c4 x \u2032 \u03c4 y \u2032 = \u03c4 z = \u03c4 x = \u03c4 y , cos\u03b8+ \u03c4 y cos\u03b8\u2212 \u03c4 x sin\u03b8, sin\u03b8, (20.8) which is just the rule for vectors! Therefore we have proved that we may identify the combination of x F y \u2212y F x with what we ordinarily call the z -component of a certain artificially invented vector. Although a torque is a twist on a plane, and it has no a priori vector character, mathematically it does behave like a vector. This vector is at right angles to the plane of the twist, and its length is proportional to the strength of the twist. The three components of such a quantity will transform like a real vector. So we represent torques by vectors; with each plane on which the torque is supposed to be acting, we associate a line at right angles, by a rule. But \u201cat right angles\u201d leaves the sign unspecified. To get the sign right, we must adopt a rule which will tell us that if the torque were in a certain sense on the xy -plane, then the axis that we want to associate with it is in the \u201cup\u201d z -direction. That is, somebody has to define \u201cright\u201d and \u201cleft\u201d for us. Supposing that the coordinate system is x , y , z in a right-hand system, then the rule will be the following: if we think of the twist as if we were turning a screw having a right-hand thread, then the direction of the vector that we will associate with that twist is in the direction that the screw would advance. Why is torque a vector? It is a miracle of good luck that we can associate a single axis with a plane, and therefore that we can associate a vector with the torque; it is a special property of three-dimensional space. In two dimensions, the torque is an ordinary scalar, and there need be no direction associated with it. In three dimensions, it is a vector. If we had four dimensions, we would be in great difficulty, because (if we had time, for example, as the fourth dimension) we would not only have planes like xy , yz , and zx , we would also have tx -, ty -, and tz -planes. There would be six of them, and one cannot represent six quantities as one vector in four dimensions. We will be living in three dimensions for a long time, so it is well to notice that the foregoing mathematical treatment did not depend upon the fact that x was position and F was force; it only depended on the transformation laws for vectors. Therefore if, instead of x , we used the x -component of some other vector, it is not going to make any difference. In other words, if we were to calculate a x b y \u2212 a y b x , where a and b are vectors, and call it the z -component of some new quantity c , then these new quantities form a vector c . We need a mathematical notation for the relationship of the new vector, with its three components, to the vectors a and b . The notation that has been devised for this is c=a\u00d7b . We have then, in addition to the ordinary scalar product in the theory of vector analysis, a new kind of product, called the vector product. Thus, if c=a\u00d7b , this is the same as writing c x c y c z = a y = a z = a x b z b x b y \u2212 a z \u2212 a x \u2212 a y b y b z b x , , . (20.9) If we reverse the order of a and b , calling a , b and b , a , we would have the sign of c reversed, because c z would be b x a y \u2212 b y a x . Therefore the cross product is unlike ordinary multiplication, where ab=ba ; for the cross product, b\u00d7a=\u2212a\u00d7b . From this, we can prove at once that if a=b , the cross product is zero. Thus, a\u00d7a=0 . The cross product is very important for representing the features of rotation, and it is important that we understand the geometrical relationship of the three vectors a , b , and c . Of course the relationship in components is given in Eq. (20.9) and from that one can determine what the relationship is in geometry. The answer is, first, that the vector c is perpendicular to both a and b . (Try to calculate c\u22c5a , and see if it does not reduce to zero.) Second, the magnitude of c turns out to be the magnitude of a times the magnitude of b times the sine of the angle between the two. In which direction does c point? Imagine that we turn a into b through an angle less than 180 \u2218 ; a screw with a right-hand thread turning in this way will advance in the direction of c . The fact that we say a right-hand screw instead of a left-hand screw is a convention, and is a perpetual reminder that if a and b are \u201chonest\u201d vectors in the ordinary sense, the new kind of \u201cvector\u201d which we have created by a\u00d7b is artificial, or slightly different in its character from a and b , because it was made up with a special rule. If a and b are called ordinary vectors, we have a special name for them, we call them polar vectors. Examples of such vectors are the coordinate r , force F , momentum p , velocity v , electric field E , etc.; these are ordinary polar vectors. Vectors which involve just one cross product in their definition are called axial vectors or pseudo vectors. Examples of pseudo vectors are, of course, torque \u03c4 and the angular momentum L . It also turns out that the angular velocity \u03c9 is a pseudo vector, as is the magnetic field B . In order to complete the mathematical properties of vectors, we should know all the rules for their multiplication, using dot and cross products. In our applications at the moment, we will need very little of this, but for the sake of completeness we shall write down all of the rules for vector multiplication so that we can use the results later. These are (a) (b) (c) (d) (e) (f) a\u00d7(b+c) (\u03b1a)\u00d7b a\u22c5(b\u00d7c) a\u00d7(b\u00d7c) a\u00d7a a\u22c5(a\u00d7b) =a\u00d7b+a\u00d7c, =\u03b1(a\u00d7b), =(a\u00d7b)\u22c5c, =b(a\u22c5c)\u2212c(a\u22c5b), =0, =0. (20.10) Now let us ask whether any equations in physics can be written using the cross product. The answer, of course, is that a great many equations can be so written. For instance, we see immediately that the torque is equal to the position vector cross the force: \u03c4=r\u00d7F. (20.11) This is a vector summary of the three equations \u03c4 x =y F z \u2212z F y , etc. By the same token, the angular momentum vector, if there is only one particle present, is the distance from the origin multiplied by the vector momentum: L=r\u00d7p. (20.12) For three-dimensional space rotation, the dynamical law analogous to the law F=dp/dt of Newton, is that the torque vector is the rate of change with time of the angular momentum vector: \u03c4=dL/dt. (20.13) If we sum (20.13) over many particles, the external torque on a system is the rate of change of the total angular momentum: \u03c4 ext =d L tot /dt. (20.14) Another theorem: If the total external torque is zero, then the total vector angular momentum of the system is a constant. This is called the law of conservation of angular momentum. If there is no torque on a given system, its angular momentum cannot change. What about angular velocity? Is it a vector? We have already discussed turning a solid object about a fixed axis, but for a moment suppose that we are turning it simultaneously about two axes. It might be turning about an axis inside a box, while the box is turning about some other axis. The net result of such combined motions is that the object simply turns about some new axis! The wonderful thing about this new axis is that it can be figured out this way. If the rate of turning in the xy -plane is written as a vector in the z -direction whose length is equal to the rate of rotation in the plane, and if another vector is drawn in the y -direction, say, which is the rate of rotation in the zx -plane, then if we add these together as a vector, the magnitude of the result tells us how fast the object is turning, and the direction tells us in what plane, by the rule of the parallelogram. That is to say, simply, angular velocity is a vector, where we draw the magnitudes of the rotations in the three planes as projections at right angles to those planes.1 As a simple application of the use of the angular velocity vector, we may evaluate the power being expended by the torque acting on a rigid body. The power, of course, is the rate of change of work with time; in three dimensions, the power turns out to be P=\u03c4\u22c5\u03c9 . All the formulas that we wrote for plane rotation can be generalized to three dimensions. For example, if a rigid body is turning about a certain axis with angular velocity \u03c9 , we might ask, \u201cWhat is the velocity of a point at a certain radial position r ?\u201d We shall leave it as a problem for the student to show that the velocity of a particle in a rigid body is given by v=\u03c9\u00d7r , where \u03c9 is the angular velocity and r is the position. Also, as another example of cross products, we had a formula for Coriolis force, which can also be written using cross products: F c =2mv\u00d7\u03c9 . That is, if a particle is moving with velocity v in a coordinate system which is, in fact, rotating with angular velocity \u03c9 , and we want to think in terms of the rotating coordinate system, then we have to add the pseudo force F c . Let us now return to the law of conservation of angular momentum. This law may be demonstrated with a rapidly spinning wheel, or gyroscope, as follows (see Fig. 20\u20131). If we sit on a swivel chair and hold the spinning wheel with its axis horizontal, the wheel has an angular momentum about the horizontal axis. Angular momentum around a vertical axis cannot change because of the (frictionless) pivot of the chair, so if we turn the axis of the wheel into the vertical, then the wheel would have angular momentum about the vertical axis, because it is now spinning about this axis. But the system (wheel, ourself, and chair) cannot have a vertical component, so we and the chair have to turn in the direction opposite to the spin of the wheel, to balance it. First let us analyze in more detail the thing we have just described. What is surprising, and what we must understand, is the origin of the forces which turn us and the chair around as we turn the axis of the gyroscope toward the vertical. Figure 20\u20132 shows the wheel spinning rapidly about the y -axis. Therefore its angular velocity is about that axis and, it turns out, its angular momentum is likewise in that direction. Now suppose that we wish to rotate the wheel about the x -axis at a small angular velocity \u03a9 ; what forces are required? After a short time \u0394t , the axis has turned to a new position, tilted at an angle \u0394\u03b8 with the horizontal. Since the major part of the angular momentum is due to the spin on the axis (very little is contributed by the slow turning), we see that the angular momentum vector has changed. What is the change in angular momentum? The angular momentum does not change in magnitude, but it does change in direction by an amount \u0394\u03b8 . The magnitude of the vector \u0394L is thus \u0394L= L 0 \u0394\u03b8 , so that the torque, which is the time rate of change of the angular momentum, is \u03c4=\u0394L/\u0394t= L 0 \u0394\u03b8/\u0394t= L 0 \u03a9 . Taking the directions of the various quantities into account, we see that \u03c4=\u03a9\u00d7 L 0 . (20.15) Thus, if \u03a9 and L 0 are both horizontal, as shown in the figure, \u03c4 is vertical. To produce such a torque, horizontal forces F and \u2212F must be applied at the ends of the axle. How are these forces applied? By our hands, as we try to rotate the axis of the wheel into the vertical direction. But Newton\u2019s Third Law demands that equal and opposite forces (and equal and opposite torques) act on us. This causes us to rotate in the opposite sense about the vertical axis z . This result can be generalized for a rapidly spinning top. In the familiar case of a spinning top, gravity acting on its center of mass furnishes a torque about the point of contact with the floor (see Fig. 20\u20133). This torque is in the horizontal direction, and causes the top to precess with its axis moving in a circular cone about the vertical. If \u03a9 is the (vertical) angular velocity of precession, we again find that \u03c4=dL/dt=\u03a9\u00d7 L 0 . d L / d \u03a9 L Thus, when we apply a torque to a rapidly spinning top, the direction of the precessional motion is in the direction of the torque, or at right angles to the forces producing the torque. We may now claim to understand the precession of gyroscopes, and indeed we do, mathematically. However, this is a mathematical thing which, in a sense, appears as a \u201cmiracle.\u201d It will turn out, as we go to more and more advanced physics, that many simple things can be deduced mathematically more rapidly than they can be really understood in a fundamental or simple sense. This is a strange characteristic, and as we get into more and more advanced work there are circumstances in which mathematics will produce results which no one has really been able to understand in any direct fashion. An example is the Dirac equation, which appears in a very simple and beautiful form, but whose consequences are hard to understand. In our particular case, the precession of a top looks like some kind of a miracle involving right angles and circles, and twists and right-hand screws. What we should try to do is to understand it in a more physical way. How can we explain the torque in terms of the real forces and the accelerations? We note that when the wheel is precessing, the particles that are going around the wheel are not really moving in a plane because the wheel is precessing (see Fig. 20\u20134). As we explained previously (Fig. 19\u20134), the particles which are crossing through the precession axis are moving in curved paths, and this requires application of a lateral force. This is supplied by our pushing on the axle, which then communicates the force to the rim through the spokes. \u201cWait,\u201d someone says, \u201cwhat about the particles that are going back on the other side?\u201d It does not take long to decide that there must be a force in the opposite direction on that side. The net force that we have to apply is therefore zero. The forces balance out, but one of them must be applied at one side of the wheel, and the other must be applied at the other side of the wheel. We could apply these forces directly, but because the wheel is solid we are allowed to do it by pushing on the axle, since forces can be carried up through the spokes. What we have so far proved is that if the wheel is precessing, it can balance the torque due to gravity or some other applied torque. But all we have shown is that this is a solution of an equation. That is, if the torque is given, and if we get the spinning started right, then the wheel will precess smoothly and uniformly. But we have not proved (and it is not true) that a uniform precession is the most general motion a spinning body can undergo as the result of a given torque. The general motion involves also a \u201cwobbling\u201d about the mean precession. This \u201cwobbling\u201d is called nutation. Some people like to say that when one exerts a torque on a gyroscope, it turns and it precesses, and that the torque produces the precession. It is very strange that when one suddenly lets go of a gyroscope, it does not fall under the action of gravity, but moves sidewise instead! Why is it that the downward force of the gravity, which we know and feel, makes it go sidewise? All the formulas in the world like (20.15) are not going to tell us, because (20.15) is a special equation, valid only after the gyroscope is precessing nicely. What really happens, in detail, is the following. If we were to hold the axis absolutely fixed, so that it cannot precess in any manner (but the top is spinning) then there is no torque acting, not even a torque from gravity, because it is balanced by our fingers. But if we suddenly let go, then there will instantaneously be a torque from gravity. Anyone in his right mind would think that the top would fall, and that is what it starts to do, as can be seen if the top is not spinning too fast. The gyro actually does fall, as we would expect. But as soon as it falls, it is then turning, and if this turning were to continue, a torque would be required. In the absence of a torque in this direction, the gyro begins to \u201cfall\u201d in the direction opposite that of the missing force. This gives the gyro a component of motion around the vertical axis, as it would have in steady precession. But the actual motion \u201covershoots\u201d the steady precessional velocity, and the axis actually rises again to the level from which it started. The path followed by the end of the axle is a cycloid (the path followed by a pebble that is stuck in the tread of an automobile tire). Ordinarily, this motion is too quick for the eye to follow, and it damps out quickly because of the friction in the gimbal bearings, leaving only the steady precessional drift (Fig. 20\u20135). The slower the wheel spins, the more obvious the nutation is. When the motion settles down, the axis of the gyro is a little bit lower than it was at the start. Why? (These are the more complicated details, but we bring them in because we do not want the reader to get the idea that the gyroscope is an absolute miracle. It is a wonderful thing, but it is not a miracle.) If we were holding the axis absolutely horizontally, and suddenly let go, then the simple precession equation would tell us that it precesses, that it goes around in a horizontal plane. But that is impossible! Although we neglected it before, it is true that the wheel has some moment of inertia about the precession axis, and if it is moving about that axis, even slowly, it has a weak angular momentum about the axis. Where did it come from? If the pivots are perfect, there is no torque about the vertical axis. How then does it get to precess if there is no change in the angular momentum? The answer is that the cycloidal motion of the end of the axis damps down to the average, steady motion of the center of the equivalent rolling circle. That is, it settles down a little bit low. Because it is low, the spin angular momentum now has a small vertical component, which is exactly what is needed for the precession. So you see it has to go down a little, in order to go around. It has to yield a little bit to the gravity; by turning its axis down a little bit, it maintains the rotation about the vertical axis. That, then, is the way a gyroscope works. Before we leave the subject of rotations in three dimensions, we shall discuss, at least qualitatively, a few effects that occur in three-dimensional rotations that are not self-evident. The main effect is that, in general, the angular momentum of a rigid body is not necessarily in the same direction as the angular velocity. Consider a wheel that is fastened onto a shaft in a lopsided fashion, but with the axis through the center of gravity, to be sure (Fig. 20\u20136). When we spin the wheel around the axis, anybody knows that there will be shaking at the bearings because of the lopsided way we have it mounted. Qualitatively, we know that in the rotating system there is centrifugal force acting on the wheel, trying to throw its mass as far as possible from the axis. This tends to line up the plane of the wheel so that it is perpendicular to the axis. To resist this tendency, a torque is exerted by the bearings. If there is a torque exerted by the bearings, there must be a rate of change of angular momentum. How can there be a rate of change of angular momentum when we are simply turning the wheel about the axis? Suppose we break the angular velocity \u03c9 into components \u03c9 1 and \u03c9 2 perpendicular and parallel to the plane of the wheel. What is the angular momentum? The moments of inertia about these two axes are different, so the angular momentum components, which (in these particular, special axes only) are equal to the moments of inertia times the corresponding angular velocity components, are in a different ratio than are the angular velocity components. Therefore the angular momentum vector is in a direction in space not along the axis. When we turn the object, we have to turn the angular momentum vector in space, so we must exert torques on the shaft. Although it is much too complicated to prove here, there is a very important and interesting property of the moment of inertia which is easy to describe and to use, and which is the basis of our above analysis. This property is the following: Any rigid body, even an irregular one like a potato, possesses three mutually perpendicular axes through the CM, such that the moment of inertia about one of these axes has the greatest possible value for any axis through the CM, the moment of inertia about another of the axes has the minimum possible value, and the moment of inertia about the third axis is intermediate between these two (or equal to one of them). These axes are called the principal axes of the body, and they have the important property that if the body is rotating about one of them, its angular momentum is in the same direction as the angular velocity. For a body having axes of symmetry, the principal axes are along the symmetry axes. If we take the x -, y -, and z -axes along the principal axes, and call the corresponding principal moments of inertia A , B , and C , we may easily evaluate the angular momentum and the kinetic energy of rotation of the body for any angular velocity \u03c9 . If we resolve \u03c9 into components \u03c9 x , \u03c9 y , and \u03c9 z along the x -, y -, z -axes, and use unit vectors i , j , k , also along x , y , z , we may write the angular momentum as L=A \u03c9 x i+B \u03c9 y j+C \u03c9 z k. (20.16) The kinetic energy of rotation is KE = 1 2 (A \u03c9 2 x +B \u03c9 2 y +C \u03c9 2 z ) = 1 2 L\u22c5\u03c9. (20.17) (20.18)"
    },
    {
        "input": "Quantum Behavior",
        "output": "\u201cQuantum mechanics\u201d is the description of the behavior of matter and light in all its details and, in particular, of the happenings on an atomic scale. Things on a very small scale behave like nothing that you have any direct experience about. They do not behave like waves, they do not behave like particles, they do not behave like clouds, or billiard balls, or weights on springs, or like anything that you have ever seen. Newton thought that light was made up of particles, but then it was discovered that it behaves like a wave. Later, however (in the beginning of the twentieth century), it was found that light did indeed sometimes behave like a particle. Historically, the electron, for example, was thought to behave like a particle, and then it was found that in many respects it behaved like a wave. So it really behaves like neither. Now we have given up. We say: \u201cIt is like neither.\u201d There is one lucky break, however\u2014electrons behave just like light. The quantum behavior of atomic objects (electrons, protons, neutrons, photons, and so on) is the same for all, they are all \u201cparticle waves,\u201d or whatever you want to call them. So what we learn about the properties of electrons (which we shall use for our examples) will apply also to all \u201cparticles,\u201d including photons of light. The gradual accumulation of information about atomic and small-scale behavior during the first quarter of the 20th century, which gave some indications about how small things do behave, produced an increasing confusion which was finally resolved in 1926 and 1927 by Schr\u00f6dinger, Heisenberg, and Born. They finally obtained a consistent description of the behavior of matter on a small scale. We take up the main features of that description in this chapter. Because atomic behavior is so unlike ordinary experience, it is very difficult to get used to, and it appears peculiar and mysterious to everyone\u2014both to the novice and to the experienced physicist. Even the experts do not understand it the way they would like to, and it is perfectly reasonable that they should not, because all of direct, human experience and of human intuition applies to large objects. We know how large objects will act, but things on a small scale just do not act that way. So we have to learn about them in a sort of abstract or imaginative fashion and not by connection with our direct experience. In this chapter we shall tackle immediately the basic element of the mysterious behavior in its most strange form. We choose to examine a phenomenon which is impossible, absolutely impossible, to explain in any classical way, and which has in it the heart of quantum mechanics. In reality, it contains the only mystery. We cannot make the mystery go away by \u201cexplaining\u201d how it works. We will just tell you how it works. In telling you how it works we will have told you about the basic peculiarities of all quantum mechanics. To try to understand the quantum behavior of electrons, we shall compare and contrast their behavior, in a particular experimental setup, with the more familiar behavior of particles like bullets, and with the behavior of waves like water waves. We consider first the behavior of bullets in the experimental setup shown diagrammatically in Fig. 1\u20131. We have a machine gun that shoots a stream of bullets. It is not a very good gun, in that it sprays the bullets (randomly) over a fairly large angular spread, as indicated in the figure. In front of the gun we have a wall (made of armor plate) that has in it two holes just about big enough to let a bullet through. Beyond the wall is a backstop (say a thick wall of wood) which will \u201cabsorb\u201d the bullets when they hit it. In front of the backstop we have an object which we shall call a \u201cdetector\u201d of bullets. It might be a box containing sand. Any bullet that enters the detector will be stopped and accumulated. When we wish, we can empty the box and count the number of bullets that have been caught. The detector can be moved back and forth (in what we will call the x -direction). With this apparatus, we can find out experimentally the answer to the question: \u201cWhat is the probability that a bullet which passes through the holes in the wall will arrive at the backstop at the distance x from the center?\u201d First, you should realize that we should talk about probability, because we cannot say definitely where any particular bullet will go. A bullet which happens to hit one of the holes may bounce off the edges of the hole, and may end up anywhere at all. By \u201cprobability\u201d we mean the chance that the bullet will arrive at the detector, which we can measure by counting the number which arrive at the detector in a certain time and then taking the ratio of this number to the total number that hit the backstop during that time. Or, if we assume that the gun always shoots at the same rate during the measurements, the probability we want is just proportional to the number that reach the detector in some standard time interval. For our present purposes we would like to imagine a somewhat idealized experiment in which the bullets are not real bullets, but are indestructible bullets\u2014they cannot break in half. In our experiment we find that bullets always arrive in lumps, and when we find something in the detector, it is always one whole bullet. If the rate at which the machine gun fires is made very low, we find that at any given moment either nothing arrives, or one and only one\u2014exactly one\u2014bullet arrives at the backstop. Also, the size of the lump certainly does not depend on the rate of firing of the gun. We shall say: \u201cBullets always arrive in identical lumps.\u201d What we measure with our detector is the probability of arrival of a lump. And we measure the probability as a function of x . The result of such measurements with this apparatus (we have not yet done the experiment, so we are really imagining the result) are plotted in the graph drawn in part (c) of Fig. 1\u20131. In the graph we plot the probability to the right and x vertically, so that the x -scale fits the diagram of the apparatus. We call the probability P 12 because the bullets may have come either through hole 1 or through hole 2 . You will not be surprised that P 12 is large near the middle of the graph but gets small if x is very large. You may wonder, however, why P 12 has its maximum value at x=0 . We can understand this fact if we do our experiment again after covering up hole 2 , and once more while covering up hole 1 . When hole 2 is covered, bullets can pass only through hole 1 , and we get the curve marked P 1 in part (b) of the figure. As you would expect, the maximum of P 1 occurs at the value of x which is on a straight line with the gun and hole 1 . When hole 1 is closed, we get the symmetric curve P 2 drawn in the figure. P 2 is the probability distribution for bullets that pass through hole 2 . Comparing parts (b) and (c) of Fig. 1\u20131, we find the important result that P 12 = P 1 + P 2 . (1.1) The probabilities just add together. The effect with both holes open is the sum of the effects with each hole open alone. We shall call this result an observation of \u201cno interference,\u201d for a reason that you will see later. So much for bullets. They come in lumps, and their probability of arrival shows no interference. Now we wish to consider an experiment with water waves. The apparatus is shown diagrammatically in Fig. 1\u20132. We have a shallow trough of water. A small object labeled the \u201cwave source\u201d is jiggled up and down by a motor and makes circular waves. To the right of the source we have again a wall with two holes, and beyond that is a second wall, which, to keep things simple, is an \u201cabsorber,\u201d so that there is no reflection of the waves that arrive there. This can be done by building a gradual sand \u201cbeach.\u201d In front of the beach we place a detector which can be moved back and forth in the x -direction, as before. The detector is now a device which measures the \u201cintensity\u201d of the wave motion. You can imagine a gadget which measures the height of the wave motion, but whose scale is calibrated in proportion to the square of the actual height, so that the reading is proportional to the intensity of the wave. Our detector reads, then, in proportion to the energy being carried by the wave\u2014or rather, the rate at which energy is carried to the detector. With our wave apparatus, the first thing to notice is that the intensity can have any size. If the source just moves a very small amount, then there is just a little bit of wave motion at the detector. When there is more motion at the source, there is more intensity at the detector. The intensity of the wave can have any value at all. We would not say that there was any \u201clumpiness\u201d in the wave intensity. Now let us measure the wave intensity for various values of x (keeping the wave source operating always in the same way). We get the interesting-looking curve marked I 12 in part (c) of the figure. We have already worked out how such patterns can come about when we studied the interference of electric waves in Volume I. In this case we would observe that the original wave is diffracted at the holes, and new circular waves spread out from each hole. If we cover one hole at a time and measure the intensity distribution at the absorber we find the rather simple intensity curves shown in part (b) of the figure. I 1 is the intensity of the wave from hole 1 (which we find by measuring when hole 2 is blocked off) and I 2 is the intensity of the wave from hole 2 (seen when hole 1 is blocked). The intensity I 12 observed when both holes are open is certainly not the sum of I 1 and I 2 . We say that there is \u201cinterference\u201d of the two waves. At some places (where the curve I 12 has its maxima) the waves are \u201cin phase\u201d and the wave peaks add together to give a large amplitude and, therefore, a large intensity. We say that the two waves are \u201cinterfering constructively\u201d at such places. There will be such constructive interference wherever the distance from the detector to one hole is a whole number of wavelengths larger (or shorter) than the distance from the detector to the other hole. At those places where the two waves arrive at the detector with a phase difference of \u03c0 (where they are \u201cout of phase\u201d) the resulting wave motion at the detector will be the difference of the two amplitudes. The waves \u201cinterfere destructively,\u201d and we get a low value for the wave intensity. We expect such low values wherever the distance between hole 1 and the detector is different from the distance between hole 2 and the detector by an odd number of half-wavelengths. The low values of I 12 in Fig. 1\u20132 correspond to the places where the two waves interfere destructively. You will remember that the quantitative relationship between I 1 , I 2 , and I 12 can be expressed in the following way: The instantaneous height of the water wave at the detector for the wave from hole 1 can be written as (the real part of) h 1 e i\u03c9t , where the \u201camplitude\u201d h 1 is, in general, a complex number. The intensity is proportional to the mean squared height or, when we use the complex numbers, to the absolute value squared | h 1 | 2 . Similarly, for hole 2 the height is h 2 e i\u03c9t and the intensity is proportional to | h 2 | 2 . When both holes are open, the wave heights add to give the height ( h 1 + h 2 ) e i\u03c9t and the intensity | h 1 + h 2 | 2 . Omitting the constant of proportionality for our present purposes, the proper relations for interfering waves are I 1 =| h 1 | 2 , I 2 =| h 2 | 2 , I 12 =| h 1 + h 2 | 2 . (1.2) You will notice that the result is quite different from that obtained with bullets (Eq. 1.1). If we expand | h 1 + h 2 | 2 we see that | h 1 + h 2 | 2 =| h 1 | 2 +| h 2 | 2 +2| h 1 || h 2 |cos\u03b4, (1.3) where \u03b4 is the phase difference between h 1 and h 2 . In terms of the intensities, we could write I 12 = I 1 + I 2 +2 I 1 I 2 \u2212 \u2212 \u2212 \u2212 \u221a cos\u03b4. (1.4) The last term in (1.4) is the \u201cinterference term.\u201d So much for water waves. The intensity can have any value, and it shows interference. Now we imagine a similar experiment with electrons. It is shown diagrammatically in Fig. 1\u20133. We make an electron gun which consists of a tungsten wire heated by an electric current and surrounded by a metal box with a hole in it. If the wire is at a negative voltage with respect to the box, electrons emitted by the wire will be accelerated toward the walls and some will pass through the hole. All the electrons which come out of the gun will have (nearly) the same energy. In front of the gun is again a wall (just a thin metal plate) with two holes in it. Beyond the wall is another plate which will serve as a \u201cbackstop.\u201d In front of the backstop we place a movable detector. The detector might be a geiger counter or, perhaps better, an electron multiplier, which is connected to a loudspeaker. We should say right away that you should not try to set up this experiment (as you could have done with the two we have already described). This experiment has never been done in just this way. The trouble is that the apparatus would have to be made on an impossibly small scale to show the effects we are interested in. We are doing a \u201cthought experiment,\u201d which we have chosen because it is easy to think about. We know the results that would be obtained because there are many experiments that have been done, in which the scale and the proportions have been chosen to show the effects we shall describe. The first thing we notice with our electron experiment is that we hear sharp \u201cclicks\u201d from the detector (that is, from the loudspeaker). And all \u201cclicks\u201d are the same. There are no \u201chalf-clicks.\u201d We would also notice that the \u201cclicks\u201d come very erratically. Something like: click \u2026.. click-click \u2026 click \u2026\u2026.. click \u2026. click-click \u2026\u2026 click \u2026, etc., just as you have, no doubt, heard a geiger counter operating. If we count the clicks which arrive in a sufficiently long time\u2014say for many minutes\u2014and then count again for another equal period, we find that the two numbers are very nearly the same. So we can speak of the average rate at which the clicks are heard (so-and-so-many clicks per minute on the average). As we move the detector around, the rate at which the clicks appear is faster or slower, but the size (loudness) of each click is always the same. If we lower the temperature of the wire in the gun, the rate of clicking slows down, but still each click sounds the same. We would notice also that if we put two separate detectors at the backstop, one or the other would click, but never both at once. (Except that once in a while, if there were two clicks very close together in time, our ear might not sense the separation.) We conclude, therefore, that whatever arrives at the backstop arrives in \u201clumps.\u201d All the \u201clumps\u201d are the same size: only whole \u201clumps\u201d arrive, and they arrive one at a time at the backstop. We shall say: \u201cElectrons always arrive in identical lumps.\u201d Just as for our experiment with bullets, we can now proceed to find experimentally the answer to the question: \u201cWhat is the relative probability that an electron \u2018lump\u2019 will arrive at the backstop at various distances x from the center?\u201d As before, we obtain the relative probability by observing the rate of clicks, holding the operation of the gun constant. The probability that lumps will arrive at a particular x is proportional to the average rate of clicks at that x . The result of our experiment is the interesting curve marked P 12 in part (c) of Fig. 1\u20133. Yes! That is the way electrons go. Now let us try to analyze the curve of Fig. 1\u20133 to see whether we can understand the behavior of the electrons. The first thing we would say is that since they come in lumps, each lump, which we may as well call an electron, has come either through hole 1 or through hole 2 . Let us write this in the form of a \u201cProposition\u201d: Proposition A: Each electron either goes through hole 1 or it goes through hole 2 . Assuming Proposition A, all electrons that arrive at the backstop can be divided into two classes: (1) those that come through hole 1 , and (2) those that come through hole 2 . So our observed curve must be the sum of the effects of the electrons which come through hole 1 and the electrons which come through hole 2 . Let us check this idea by experiment. First, we will make a measurement for those electrons that come through hole 1 . We block off hole 2 and make our counts of the clicks from the detector. From the clicking rate, we get P 1 . The result of the measurement is shown by the curve marked P 1 in part (b) of Fig. 1\u20133. The result seems quite reasonable. In a similar way, we measure P 2 , the probability distribution for the electrons that come through hole 2 . The result of this measurement is also drawn in the figure. The result P 12 obtained with both holes open is clearly not the sum of P 1 and P 2 , the probabilities for each hole alone. In analogy with our water-wave experiment, we say: \u201cThere is interference.\u201d For electrons: P 12 \u2260 P 1 + P 2 . (1.5) How can such an interference come about? Perhaps we should say: \u201cWell, that means, presumably, that it is not true that the lumps go either through hole 1 or hole 2 , because if they did, the probabilities should add. Perhaps they go in a more complicated way. They split in half and \u2026\u201d But no! They cannot, they always arrive in lumps \u2026 \u201cWell, perhaps some of them go through 1 , and then they go around through 2 , and then around a few more times, or by some other complicated path \u2026 then by closing hole 2 , we changed the chance that an electron that started out through hole 1 would finally get to the backstop \u2026\u201d But notice! There are some points at which very few electrons arrive when both holes are open, but which receive many electrons if we close one hole, so closing one hole increased the number from the other. Notice, however, that at the center of the pattern, P 12 is more than twice as large as P 1 + P 2 . It is as though closing one hole decreased the number of electrons which come through the other hole. It seems hard to explain both effects by proposing that the electrons travel in complicated paths. It is all quite mysterious. And the more you look at it the more mysterious it seems. Many ideas have been concocted to try to explain the curve for P 12 in terms of individual electrons going around in complicated ways through the holes. None of them has succeeded. None of them can get the right curve for P 12 in terms of P 1 and P 2 . Yet, surprisingly enough, the mathematics for relating P 1 and P 2 to P 12 is extremely simple. For P 12 is just like the curve I 12 of Fig. 1\u20132, and that was simple. What is going on at the backstop can be described by two complex numbers that we can call \u03d5 1 and \u03d5 2 (they are functions of x , of course). The absolute square of \u03d5 1 gives the effect with only hole 1 open. That is, P 1 =| \u03d5 1 | 2 . The effect with only hole 2 open is given by \u03d5 2 in the same way. That is, P 2 =| \u03d5 2 | 2 . And the combined effect of the two holes is just P 12 =| \u03d5 1 + \u03d5 2 | 2 . The mathematics is the same as that we had for the water waves! (It is hard to see how one could get such a simple result from a complicated game of electrons going back and forth through the plate on some strange trajectory.) We conclude the following: The electrons arrive in lumps, like particles, and the probability of arrival of these lumps is distributed like the distribution of intensity of a wave. It is in this sense that an electron behaves \u201csometimes like a particle and sometimes like a wave.\u201d Incidentally, when we were dealing with classical waves we defined the intensity as the mean over time of the square of the wave amplitude, and we used complex numbers as a mathematical trick to simplify the analysis. But in quantum mechanics it turns out that the amplitudes must be represented by complex numbers. The real parts alone will not do. That is a technical point, for the moment, because the formulas look just the same. Since the probability of arrival through both holes is given so simply, although it is not equal to ( P 1 + P 2 ) , that is really all there is to say. But there are a large number of subtleties involved in the fact that nature does work this way. We would like to illustrate some of these subtleties for you now. First, since the number that arrives at a particular point is not equal to the number that arrives through 1 plus the number that arrives through 2 , as we would have concluded from Proposition A, undoubtedly we should conclude that Proposition A is false. It is not true that the electrons go either through hole 1 or hole 2 . But that conclusion can be tested by another experiment. We shall now try the following experiment. To our electron apparatus we add a very strong light source, placed behind the wall and between the two holes, as shown in Fig. 1\u20134. We know that electric charges scatter light. So when an electron passes, however it does pass, on its way to the detector, it will scatter some light to our eye, and we can see where the electron goes. If, for instance, an electron were to take the path via hole 2 that is sketched in Fig. 1\u20134, we should see a flash of light coming from the vicinity of the place marked A in the figure. If an electron passes through hole 1 , we would expect to see a flash from the vicinity of the upper hole. If it should happen that we get light from both places at the same time, because the electron divides in half \u2026 Let us just do the experiment! Here is what we see: every time that we hear a \u201cclick\u201d from our electron detector (at the backstop), we also see a flash of light either near hole 1 or near hole 2 , but never both at once! And we observe the same result no matter where we put the detector. From this observation we conclude that when we look at the electrons we find that the electrons go either through one hole or the other. Experimentally, Proposition A is necessarily true. What, then, is wrong with our argument against Proposition A? Why isn\u2019t P 12 just equal to P 1 + P 2 ? Back to experiment! Let us keep track of the electrons and find out what they are doing. For each position ( x -location) of the detector we will count the electrons that arrive and also keep track of which hole they went through, by watching for the flashes. We can keep track of things this way: whenever we hear a \u201cclick\u201d we will put a count in Column 1 if we see the flash near hole 1 , and if we see the flash near hole 2 , we will record a count in Column 2 . Every electron which arrives is recorded in one of two classes: those which come through 1 and those which come through 2 . From the number recorded in Column 1 we get the probability P \u2032 1 that an electron will arrive at the detector via hole 1 ; and from the number recorded in Column 2 we get P \u2032 2 , the probability that an electron will arrive at the detector via hole 2 . If we now repeat such a measurement for many values of x , we get the curves for P \u2032 1 and P \u2032 2 shown in part (b) of Fig. 1\u20134. Well, that is not too surprising! We get for P \u2032 1 something quite similar to what we got before for P 1 by blocking off hole 2 ; and P \u2032 2 is similar to what we got by blocking hole 1 . So there is not any complicated business like going through both holes. When we watch them, the electrons come through just as we would expect them to come through. Whether the holes are closed or open, those which we see come through hole 1 are distributed in the same way whether hole 2 is open or closed. But wait! What do we have now for the total probability, the probability that an electron will arrive at the detector by any route? We already have that information. We just pretend that we never looked at the light flashes, and we lump together the detector clicks which we have separated into the two columns. We must just add the numbers. For the probability that an electron will arrive at the backstop by passing through either hole, we do find P \u2032 12 = P \u2032 1 + P \u2032 2 . That is, although we succeeded in watching which hole our electrons come through, we no longer get the old interference curve P 12 , but a new one, P \u2032 12 , showing no interference! If we turn out the light P 12 is restored. We must conclude that when we look at the electrons the distribution of them on the screen is different than when we do not look. Perhaps it is turning on our light source that disturbs things? It must be that the electrons are very delicate, and the light, when it scatters off the electrons, gives them a jolt that changes their motion. We know that the electric field of the light acting on a charge will exert a force on it. So perhaps we should expect the motion to be changed. Anyway, the light exerts a big influence on the electrons. By trying to \u201cwatch\u201d the electrons we have changed their motions. That is, the jolt given to the electron when the photon is scattered by it is such as to change the electron\u2019s motion enough so that if it might have gone to where P 12 was at a maximum it will instead land where P 12 was a minimum; that is why we no longer see the wavy interference effects. You may be thinking: \u201cDon\u2019t use such a bright source! Turn the brightness down! The light waves will then be weaker and will not disturb the electrons so much. Surely, by making the light dimmer and dimmer, eventually the wave will be weak enough that it will have a negligible effect.\u201d O.K. Let\u2019s try it. The first thing we observe is that the flashes of light scattered from the electrons as they pass by does not get weaker. It is always the same-sized flash. The only thing that happens as the light is made dimmer is that sometimes we hear a \u201cclick\u201d from the detector but see no flash at all. The electron has gone by without being \u201cseen.\u201d What we are observing is that light also acts like electrons, we knew that it was \u201cwavy,\u201d but now we find that it is also \u201clumpy.\u201d It always arrives\u2014or is scattered\u2014in lumps that we call \u201cphotons.\u201d As we turn down the intensity of the light source we do not change the size of the photons, only the rate at which they are emitted. That explains why, when our source is dim, some electrons get by without being seen. There did not happen to be a photon around at the time the electron went through. This is all a little discouraging. If it is true that whenever we \u201csee\u201d the electron we see the same-sized flash, then those electrons we see are always the disturbed ones. Let us try the experiment with a dim light anyway. Now whenever we hear a click in the detector we will keep a count in three columns: in Column (1) those electrons seen by hole 1 , in Column (2) those electrons seen by hole 2 , and in Column (3) those electrons not seen at all. When we work up our data (computing the probabilities) we find these results: Those \u201cseen by hole 1 \u201d have a distribution like P \u2032 1 ; those \u201cseen by hole 2 \u201d have a distribution like P \u2032 2 (so that those \u201cseen by either hole 1 or 2 \u201d have a distribution like P \u2032 12 ); and those \u201cnot seen at all\u201d have a \u201cwavy\u201d distribution just like P 12 of Fig. 1\u20133! If the electrons are not seen, we have interference! That is understandable. When we do not see the electron, no photon disturbs it, and when we do see it, a photon has disturbed it. There is always the same amount of disturbance because the light photons all produce the same-sized effects and the effect of the photons being scattered is enough to smear out any interference effect. Is there not some way we can see the electrons without disturbing them? We learned in an earlier chapter that the momentum carried by a \u201cphoton\u201d is inversely proportional to its wavelength ( p=h/\u03bb ). Certainly the jolt given to the electron when the photon is scattered toward our eye depends on the momentum that photon carries. Aha! If we want to disturb the electrons only slightly we should not have lowered the intensity of the light, we should have lowered its frequency (the same as increasing its wavelength). Let us use light of a redder color. We could even use infrared light, or radiowaves (like radar), and \u201csee\u201d where the electron went with the help of some equipment that can \u201csee\u201d light of these longer wavelengths. If we use \u201cgentler\u201d light perhaps we can avoid disturbing the electrons so much. Let us try the experiment with longer waves. We shall keep repeating our experiment, each time with light of a longer wavelength. At first, nothing seems to change. The results are the same. Then a terrible thing happens. You remember that when we discussed the microscope we pointed out that, due to the wave nature of the light, there is a limitation on how close two spots can be and still be seen as two separate spots. This distance is of the order of the wavelength of light. So now, when we make the wavelength longer than the distance between our holes, we see a big fuzzy flash when the light is scattered by the electrons. We can no longer tell which hole the electron went through! We just know it went somewhere! And it is just with light of this color that we find that the jolts given to the electron are small enough so that P \u2032 12 begins to look like P 12 \u2014that we begin to get some interference effect. And it is only for wavelengths much longer than the separation of the two holes (when we have no chance at all of telling where the electron went) that the disturbance due to the light gets sufficiently small that we again get the curve P 12 shown in Fig. 1\u20133. In our experiment we find that it is impossible to arrange the light in such a way that one can tell which hole the electron went through, and at the same time not disturb the pattern. It was suggested by Heisenberg that the then new laws of nature could only be consistent if there were some basic limitation on our experimental capabilities not previously recognized. He proposed, as a general principle, his uncertainty principle, which we can state in terms of our experiment as follows: \u201cIt is impossible to design an apparatus to determine which hole the electron passes through, that will not at the same time disturb the electrons enough to destroy the interference pattern.\u201d If an apparatus is capable of determining which hole the electron goes through, it cannot be so delicate that it does not disturb the pattern in an essential way. No one has ever found (or even thought of) a way around the uncertainty principle. So we must assume that it describes a basic characteristic of nature. The complete theory of quantum mechanics which we now use to describe atoms and, in fact, all matter, depends on the correctness of the uncertainty principle. Since quantum mechanics is such a successful theory, our belief in the uncertainty principle is reinforced. But if a way to \u201cbeat\u201d the uncertainty principle were ever discovered, quantum mechanics would give inconsistent results and would have to be discarded as a valid theory of nature. \u201cWell,\u201d you say, \u201cwhat about Proposition A? Is it true, or is it not true, that the electron either goes through hole 1 or it goes through hole 2 ?\u201d The only answer that can be given is that we have found from experiment that there is a certain special way that we have to think in order that we do not get into inconsistencies. What we must say (to avoid making wrong predictions) is the following. If one looks at the holes or, more accurately, if one has a piece of apparatus which is capable of determining whether the electrons go through hole 1 or hole 2 , then one can say that it goes either through hole 1 or hole 2 . But, when one does not try to tell which way the electron goes, when there is nothing in the experiment to disturb the electrons, then one may not say that an electron goes either through hole 1 or hole 2 . If one does say that, and starts to make any deductions from the statement, he will make errors in the analysis. This is the logical tightrope on which we must walk if we wish to describe nature successfully. If the motion of all matter\u2014as well as electrons\u2014must be described in terms of waves, what about the bullets in our first experiment? Why didn\u2019t we see an interference pattern there? It turns out that for the bullets the wavelengths were so tiny that the interference patterns became very fine. So fine, in fact, that with any detector of finite size one could not distinguish the separate maxima and minima. What we saw was only a kind of average, which is the classical curve. In Fig. 1\u20135 we have tried to indicate schematically what happens with large-scale objects. Part (a) of the figure shows the probability distribution one might predict for bullets, using quantum mechanics. The rapid wiggles are supposed to represent the interference pattern one gets for waves of very short wavelength. Any physical detector, however, straddles several wiggles of the probability curve, so that the measurements show the smooth curve drawn in part (b) of the figure. We will now write a summary of the main conclusions of our experiments. We will, however, put the results in a form which makes them true for a general class of such experiments. We can write our summary more simply if we first define an \u201cideal experiment\u201d as one in which there are no uncertain external influences, i.e., no jiggling or other things going on that we cannot take into account. We would be quite precise if we said: \u201cAn ideal experiment is one in which all of the initial and final conditions of the experiment are completely specified.\u201d What we will call \u201can event\u201d is, in general, just a specific set of initial and final conditions. (For example: \u201can electron leaves the gun, arrives at the detector, and nothing else happens.\u201d) Now for our summary. Summary The probability of an event in an ideal experiment is given by the square of the absolute value of a complex number \u03d5 which is called the probability amplitude: P \u03d5 P =probability, =probability amplitude, =|\u03d5 | 2 . (1.6) When an event can occur in several alternative ways, the probability amplitude for the event is the sum of the probability amplitudes for each way considered separately. There is interference: \u03d5 P = \u03d5 1 + \u03d5 2 , =| \u03d5 1 + \u03d5 2 | 2 . (1.7) If an experiment is performed which is capable of determining whether one or another alternative is actually taken, the probability of the event is the sum of the probabilities for each alternative. The interference is lost: P= P 1 + P 2 . (1.8) One might still like to ask: \u201cHow does it work? What is the machinery behind the law?\u201d No one has found any machinery behind the law. No one can \u201cexplain\u201d any more than we have just \u201cexplained.\u201d No one will give you any deeper representation of the situation. We have no ideas about a more basic mechanism from which these results can be deduced. We would like to emphasize a very important difference between classical and quantum mechanics. We have been talking about the probability that an electron will arrive in a given circumstance. We have implied that in our experimental arrangement (or even in the best possible one) it would be impossible to predict exactly what would happen. We can only predict the odds! This would mean, if it were true, that physics has given up on the problem of trying to predict exactly what will happen in a definite circumstance. Yes! physics has given up. We do not know how to predict what would happen in a given circumstance, and we believe now that it is impossible\u2014that the only thing that can be predicted is the probability of different events. It must be recognized that this is a retrenchment in our earlier ideal of understanding nature. It may be a backward step, but no one has seen a way to avoid it. We make now a few remarks on a suggestion that has sometimes been made to try to avoid the description we have given: \u201cPerhaps the electron has some kind of internal works\u2014some inner variables\u2014that we do not yet know about. Perhaps that is why we cannot predict what will happen. If we could look more closely at the electron, we could be able to tell where it would end up.\u201d So far as we know, that is impossible. We would still be in difficulty. Suppose we were to assume that inside the electron there is some kind of machinery that determines where it is going to end up. That machine must also determine which hole it is going to go through on its way. But we must not forget that what is inside the electron should not be dependent on what we do, and in particular upon whether we open or close one of the holes. So if an electron, before it starts, has already made up its mind (a) which hole it is going to use, and (b) where it is going to land, we should find P 1 for those electrons that have chosen hole 1 , P 2 for those that have chosen hole 2 , and necessarily the sum P 1 + P 2 for those that arrive through the two holes. There seems to be no way around this. But we have verified experimentally that that is not the case. And no one has figured a way out of this puzzle. So at the present time we must limit ourselves to computing probabilities. We say \u201cat the present time,\u201d but we suspect very strongly that it is something that will be with us forever\u2014that it is impossible to beat that puzzle\u2014that this is the way nature really is. This is the way Heisenberg stated the uncertainty principle originally: If you make the measurement on any object, and you can determine the x -component of its momentum with an uncertainty \u0394p , you cannot, at the same time, know its x -position more accurately than \u0394x\u2265\u210f/2\u0394p , where \u210f is a definite fixed number given by nature. It is called the \u201creduced Planck constant,\u201d and is approximately 1.05\u00d7 10 \u221234 joule-seconds. The uncertainties in the position and momentum of a particle at any instant must have their product greater than or equal to half the reduced Planck constant. This is a special case of the uncertainty principle that was stated above more generally. The more general statement was that one cannot design equipment in any way to determine which of two alternatives is taken, without, at the same time, destroying the pattern of interference. Let us show for one particular case that the kind of relation given by Heisenberg must be true in order to keep from getting into trouble. We imagine a modification of the experiment of Fig. 1\u20133, in which the wall with the holes consists of a plate mounted on rollers so that it can move freely up and down (in the x -direction), as shown in Fig. 1\u20136. By watching the motion of the plate carefully we can try to tell which hole an electron goes through. Imagine what happens when the detector is placed at x=0 . We would expect that an electron which passes through hole 1 must be deflected downward by the plate to reach the detector. Since the vertical component of the electron momentum is changed, the plate must recoil with an equal momentum in the opposite direction. The plate will get an upward kick. If the electron goes through the lower hole, the plate should feel a downward kick. It is clear that for every position of the detector, the momentum received by the plate will have a different value for a traversal via hole 1 than for a traversal via hole 2 . So! Without disturbing the electrons at all, but just by watching the plate, we can tell which path the electron used. Now in order to do this it is necessary to know what the momentum of the screen is, before the electron goes through. So when we measure the momentum after the electron goes by, we can figure out how much the plate\u2019s momentum has changed. But remember, according to the uncertainty principle we cannot at the same time know the position of the plate with an arbitrary accuracy. But if we do not know exactly where the plate is, we cannot say precisely where the two holes are. They will be in a different place for every electron that goes through. This means that the center of our interference pattern will have a different location for each electron. The wiggles of the interference pattern will be smeared out. We shall show quantitatively in the next chapter that if we determine the momentum of the plate sufficiently accurately to determine from the recoil measurement which hole was used, then the uncertainty in the x -position of the plate will, according to the uncertainty principle, be enough to shift the pattern observed at the detector up and down in the x -direction about the distance from a maximum to its nearest minimum. Such a random shift is just enough to smear out the pattern so that no interference is observed. The uncertainty principle \u201cprotects\u201d quantum mechanics. Heisenberg recognized that if it were possible to measure the momentum and the position simultaneously with a greater accuracy, the quantum mechanics would collapse. So he proposed that it must be impossible. Then people sat down and tried to figure out ways of doing it, and nobody could figure out a way to measure the position and the momentum of anything\u2014a screen, an electron, a billiard ball, anything\u2014with any greater accuracy. Quantum mechanics maintains its perilous but still correct existence."
    },
    {
        "input": "More Two-State Systems",
        "output": "We continue our discussion of two-state systems. At the end of the last chapter we were talking about a spin one-half particle in a magnetic field. We described the spin state by giving the amplitude C1 that the z -component of spin angular momentum is +\u210f/2 and the amplitude C2 that it is \u2212\u210f/2 . In earlier chapters we have called these base states |+\u27e9 and |\u2212\u27e9 . We will now go back to that notation, although we may occasionally find it convenient to use |+\u27e9 or |1\u27e9 , and |\u2212\u27e9 or |2\u27e9 , interchangeably. We saw in the last chapter that when a spin one-half particle with a magnetic moment \u03bc is in a magnetic field B=(Bx,By,Bz) , the amplitudes C+ (=C1 ) and C\u2212 (=C2 ) are connected by the following differential equations: i\u210f dC+ dt =\u2212\u03bc[BzC++(Bx\u2212iBy)C\u2212], i\u210f dC\u2212 dt =\u2212\u03bc[(Bx+iBy)C+\u2212BzC\u2212]. In other words, the Hamiltonian matrix Hij is H11 =\u2212\u03bcBz, H12 =\u2212\u03bc(Bx\u2212iBy), H21 =\u2212\u03bc(Bx+iBy), H22 =+\u03bcBz. And Eqs. (11.1) are, of course, the same as i\u210f dCi dt = \u2211 j HijCj, where i and j take on the values + and \u2212 (or 1 and 2 ). The two-state system of the electron spin is so important that it is very useful to have a neater way of writing things. We will now make a little mathematical digression to show you how people usually write the equations of a two-state system. It is done this way: First, note that each term in the Hamiltonian is proportional to \u03bc and to some component of B ; we can then\u2014purely formally\u2014write that Hij=\u2212\u03bc[\u03c3 x ij Bx+\u03c3 y ij By+\u03c3 z ij Bz]. There is no new physics here; this equation just means that the coefficients \u03c3 x ij , \u03c3 y ij , and \u03c3 z ij \u2014there are 4\u00d73=12 of them\u2014can be figured out so that (11.4) is identical with (11.2). Let\u2019s see what they have to be. We start with Bz . Since Bz appears only in H11 and H22 , everything will be O.K. if \u03c3 z 11 =1, \u03c3 z 12 =0, \u03c3 z 21 =0, \u03c3 z 22 =\u22121. We often write the matrix Hij as a little table like this: Hij= i\u2193 j\u2192 ( H11 H12 H21 H22 ). For the Hamiltonian of a spin one-half particle in the magnetic field Bz , this is the same as Hij= i\u2193 j\u2192 ( \u2212\u03bcBz \u2212\u03bc(Bx\u2212iBy) \u2212\u03bc(Bx+iBy) +\u03bcBz ). In the same way, we can write the coefficients \u03c3 z ij as the matrix \u03c3 z ij = i\u2193 j\u2192 ( 1 0 0 \u22121 ). Working with the coefficients of Bx , we get that the terms of \u03c3x have to be \u03c3 x 11 =0, \u03c3 x 12 =1, \u03c3 x 21 =1, \u03c3 x 22 =0. Or, in shorthand, \u03c3 x ij =( 0 1 1 0 ). Finally, looking at By , we get \u03c3 y 11 =0, \u03c3 y 12 =\u2212i, \u03c3 y 21 =i, \u03c3 y 22 =0; or \u03c3 y ij =( 0 \u2212i i 0 ). With these three sigma matrices, Eqs. (11.2) and (11.4) are identical. To leave room for the subscripts i and j , we have shown which \u03c3 goes with which component of B by putting x , y , and z as superscripts. Usually, however, the i and j are omitted\u2014it\u2019s easy to imagine they are there\u2014and the x , y , z are written as subscripts. Then Eq. (11.4) is written H=\u2212\u03bc[\u03c3xBx+\u03c3yBy+\u03c3zBz]. Because the sigma matrices are so important\u2014they are used all the time by the professionals\u2014we have gathered them together in Table 11\u20131. (Anyone who is going to work in quantum physics really has to memorize them.) They are also called the Pauli spin matrices after the physicist who invented them. In the table we have included one more two-by-two matrix which is needed if we want to be able to take care of a system which has two spin states of the same energy, or if we want to choose a different zero energy. For such situations we must add E0C+ to the first equation in (11.1) and E0C\u2212 to the second equation. We can include this in the new notation if we define the unit matrix \u201c1 \u201d as \u03b4ij , 1=\u03b4ij=( 1 0 0 1 ), and rewrite Eq. (11.8) as H=E0\u03b4ij\u2212\u03bc(\u03c3xBx+\u03c3yBy+\u03c3zBz). Usually, it is understood that any constant like E0 is automatically to be multiplied by the unit matrix; then one writes simply H=E0\u2212\u03bc(\u03c3xBx+\u03c3yBy+\u03c3zBz). One reason the spin matrices are useful is that any two-by-two matrix at all can be written in terms of them. Any matrix you can write has four numbers in it, say, M=( a b c d ). It can always be written as a linear combination of four matrices. For example, M=a( 1 0 0 0 )+b( 0 1 0 0 )+c( 0 0 1 0 )+d( 0 0 0 1 ). There are many ways of doing it, but one special way is to say that M is a certain amount of \u03c3x , plus a certain amount of \u03c3y , and so on, like this: M=\u03b11+\u03b2\u03c3x+\u03b3\u03c3y+\u03b4\u03c3z, where the \u201camounts\u201d \u03b1 , \u03b2 , \u03b3 , and \u03b4 may, in general, be complex numbers. Since any two-by-two matrix can be represented in terms of the unit matrix and the sigma matrices, we have all that we ever need for any two-state system. No matter what the two-state system\u2014the ammonia molecule, the magenta dye, anything\u2014the Hamiltonian equation can be written in terms of the sigmas. Although the sigmas seem to have a geometrical significance in the physical situation of an electron in a magnetic field, they can also be thought of as just useful matrices, which can be used for any two-state problem. For instance, in one way of looking at things a proton and a neutron can be thought of as the same particle in either of two states. We say the nucleon (proton or neutron) is a two-state system\u2014in this case, two states with respect to its charge. When looked at that way, the |1\u27e9 state can represent the proton and the |2\u27e9 state can represent the neutron. People say that the nucleon has two \u201cisotopic-spin\u201d states. Since we will be using the sigma matrices as the \u201carithmetic\u201d of the quantum mechanics of two-state systems, let\u2019s review quickly the conventions of matrix algebra. By the \u201csum\u201d of any two or more matrices we mean just what was obvious in Eq. (11.4). In general, if we \u201cadd\u201d two matrices A and B , the \u201csum\u201d C means that each term Cij is given by Cij=Aij+Bij. Each term of C is the sum of the terms in the same slots of A and B . In Section 5\u20136 we have already encountered the idea of a matrix \u201cproduct.\u201d The same idea will be useful in dealing with the sigma matrices. In general, the \u201cproduct\u201d of two matrices A and B (in that order) is defined to be a matrix C whose elements are Cij= \u2211 k AikBkj. It is the sum of products of terms taken in pairs from the i th row of A and the j th column of B . If the matrices are written out in tabular form as in Fig. 11-1, there is a good \u201csystem\u201d for getting the terms of the product matrix. Suppose you are calculating C23 . You run your left index finger along the second row of A and your right index finger down the third column of B , multiplying each pair and adding as you go. We have tried to indicate how to do it in the figure. It is, of course, particularly simple for two-by-two matrices. For instance, if we multiply \u03c3x times \u03c3x , we get \u03c3 2 x =\u03c3x\u22c5\u03c3x=( 0 1 1 0 )\u22c5( 0 1 1 0 )=( 1 0 0 1 ), which is just the unit matrix 1 . Or, for another example, let\u2019s work out \u03c3x\u03c3y : \u03c3x\u03c3y=( 0 1 1 0 )\u22c5( 0 \u2212i i 0 )=( i 0 0 \u2212i ). Referring to Table 11\u20131, you see that the product is just i times the matrix \u03c3z . (Remember that a number times a matrix just multiplies each term of the matrix.) Since the products of the sigmas taken two at a time are important\u2014as well as rather amusing\u2014we have listed them all in Table 11\u20132. You can work them out as we have done for \u03c3 2 x and \u03c3x\u03c3y . There\u2019s another very important and interesting point about these \u03c3 matrices. We can imagine, if we wish, that the three matrices \u03c3x , \u03c3y , and \u03c3z are analogous to the three components of a vector\u2014it is sometimes called the \u201csigma vector\u201d and is written \u03c3 . It is really a \u201cmatrix vector\u201d or a \u201cvector matrix.\u201d It is three different matrices\u2014one matrix associated with each axis, x , y , and z . With it, we can write the Hamiltonian of the system in a nice form which works in any coordinate system: H=\u2212\u03bc\u03c3\u22c5B. Although we have written our three matrices in the representation in which \u201cup\u201d and \u201cdown\u201d are in the z -direction\u2014so that \u03c3z has a particular simplicity\u2014we could figure out what the matrices would look like in some other representation. Although it takes a lot of algebra, you can show that they change among themselves like the components of a vector. (We won\u2019t, however, worry about proving it right now. You can check it if you want.) You can use \u03c3 in different coordinate systems as though it is a vector. You remember that the H is related to energy in quantum mechanics. It is, in fact, just equal to the energy in the simple situation where there is only one state. Even for two-state systems of the electron spin, when we write the Hamiltonian as in Eq. (11.13), it looks very much like the classical formula for the energy of a little magnet with magnetic moment \u03bc in a magnetic field B . Classically, we would say U=\u2212\u03bc\u22c5B, (11.14) where \u03bc is the property of the object and B is an external field. We can imagine that Eq. (11.14) can be converted to (11.13) if we replace the classical energy by the Hamiltonian and the classical \u03bc by the matrix \u03bc\u03c3 . Then, after this purely formal substitution, we interpret the result as a matrix equation. It is sometimes said that to each quantity in classical physics there corresponds a matrix in quantum mechanics. It is really more correct to say that the Hamiltonian matrix corresponds to the energy, and any quantity that can be defined via energy has a corresponding matrix. For example, the magnetic moment can be defined via energy by saying that the energy in an external field B is \u2212\u03bc\u22c5B . This defines the magnetic moment vector \u03bc . Then we look at the formula for the Hamiltonian of a real (quantum) object in a magnetic field and try to identify whatever the matrices are that correspond to the various quantities in the classical formula. That\u2019s the trick by which sometimes classical quantities have their quantum counterparts. You may try, if you want, to understand how a classical vector is equal to a matrix \u03bc\u03c3 , and maybe you will discover something\u2014but don\u2019t break your head on it. That\u2019s not the idea\u2014they are not equal. Quantum mechanics is a different kind of a theory to represent the world. It just happens that there are certain correspondences which are hardly more than mnemonic devices\u2014things to remember with. That is, you remember Eq. (11.14) when you learn classical physics; then if you remember the correspondence \u03bc\u2192\u03bc\u03c3 , you have a handle for remembering Eq. (11.13). Of course, nature knows the quantum mechanics, and the classical mechanics is only an approximation; so there is no mystery in the fact that in classical mechanics there is some shadow of quantum mechanical laws\u2014which are truly the ones underneath. To reconstruct the original object from the shadow is not possible in any direct way, but the shadow does help you to remember what the object looks like. Equation (11.13) is the truth, and Eq. (11.14) is the shadow. Because we learn classical mechanics first, we would like to be able to get the quantum formula from it, but there is no sure-fire scheme for doing that. We must always go back to the real world and discover the correct quantum mechanical equations. When they come out looking like something in classical physics, we are in luck. If the warnings above seem repetitious and appear to you to be belaboring self-evident truths about the relation of classical physics to quantum physics, please excuse the conditioned reflexes of a professor who has usually taught quantum mechanics to students who hadn\u2019t heard about Pauli spin matrices until they were in graduate school. Then they always seemed to be hoping that, somehow, quantum mechanics could be seen to follow as a logical consequence of classical mechanics which they had learned thoroughly years before. (Perhaps they wanted to avoid having to learn something new.) You have learned the classical formula, Eq. (11.14), only a few months ago\u2014and then with warnings that it was inadequate\u2014so maybe you will not be so unwilling to take the quantum formula, Eq. (11.13), as the basic truth. While we are on the subject of mathematical notation, we would like to describe still another way of writing things\u2014a way which is used very often because it is so compact. It follows directly from the notation introduced in Chapter 8. If we have a system in a state |\u03c8(t)\u27e9 , which varies with time, we can\u2014as we did in Eq. (8.34)\u2014write the amplitude that the system would be in the state |i\u27e9 at t+\u0394t as \u27e8i|\u03c8(t+\u0394t)\u27e9= \u2211 j \u27e8i|U(t+\u0394t,t)|j\u27e9\u27e8j|\u03c8(t)\u27e9 \u2211 The matrix element \u27e8i|U(t+\u0394t,t)|j\u27e9 is the amplitude that the base state |j\u27e9 will be converted into the base state |i\u27e9 in the time interval \u0394t . We then defined H ij by writing \u27e8i|U(t+\u0394t,t)|j\u27e9= \u03b4 ij \u2212 i \u210f H ij (t)\u0394t, i and we showed that the amplitudes C i (t)=\u27e8i|\u03c8(t)\u27e9 were related by the differential equations i\u210f d C i dt = \u2211 j H ij C j . (11.15) If we write out the amplitudes C i explicitly, the same equation appears as i\u210f d dt \u27e8i|\u03c8\u27e9= \u2211 j H ij \u27e8j|\u03c8\u27e9. (11.16) Now the matrix elements H ij are also amplitudes which we can write as \u27e8i|H|j\u27e9 ; our differential equation looks like this: i\u210f d dt \u27e8i|\u03c8\u27e9= \u2211 j \u27e8i|H|j\u27e9\u27e8j|\u03c8\u27e9. (11.17) We see that \u2212i/\u210f\u27e8i|H|j\u27e9dt is the amplitude that\u2014under the physical conditions described by H \u2014a state |j\u27e9 will, during the time dt , \u201cgenerate\u201d the state |i\u27e9 . (All of this is implicit in the discussion of Section 8\u20134.) Now following the ideas of Section 8\u20132, we can drop out the common term \u27e8i| in Eq. (11.17)\u2014since it is true for any state |i\u27e9 \u2014and write that equation simply as i\u210f d dt |\u03c8\u27e9= \u2211 j H|j\u27e9\u27e8j|\u03c8\u27e9. (11.18) Or, going one step further, we can also remove the j and write i\u210f d dt |\u03c8\u27e9=H|\u03c8\u27e9. (11.19) In Chapter 8 we pointed out that when things are written this way, the H in H|j\u27e9 or H|\u03c8\u27e9 is called an operator. From now on we will put the little hat ( ^ ) over an operator to remind you that it is an operator and not just a number. We will write H ^ |\u03c8\u27e9 . Although the two equations (11.18) and (11.19) mean exactly the same thing as Eq. (11.17) or Eq. (11.15), we can think about them in a different way. For instance, we would describe Eq. (11.18) in this way: \u201cThe time derivative of the state vector |\u03c8\u27e9 times i\u210f is equal to what you get by operating with the Hamiltonian operator H ^ on each base state, multiplying by the amplitude \u27e8j|\u03c8\u27e9 that \u03c8 is in the state j , and summing over all j .\u201d Or Eq. (11.19) is described this way. \u201cThe time derivative (times i\u210f ) of a state |\u03c8\u27e9 is equal to what you get if you operate with the Hamiltonian H ^ on the state vector |\u03c8\u27e9 .\u201d It\u2019s just a shorthand way of saying what is in Eq. (11.17), but, as you will see, it can be a great convenience. If we wish, we can carry the \u201cabstraction\u201d idea one more step. Equation (11.19) is true for any state |\u03c8\u27e9 . Also the left-hand side, i\u210fd/dt , is also an operator\u2014it\u2019s the operation \u201cdifferentiate by t and multiply by i\u210f .\u201d Therefore, Eq. (11.19) can also be thought of as an equation between operators\u2014the operator equation i\u210f d dt = H ^ . d The Hamiltonian operator (within a constant) produces the same result as does d/dt when acting on any state. Remember that this equation\u2014as well as Eq. (11.19)\u2014is not a statement that the H ^ operator is just the identical operation as i\u210fd/dt . The equations are the dynamical law of nature\u2014the law of motion\u2014for a quantum system. Just to get some practice with these ideas, we will show you another way we could get to Eq. (11.18). You know that we can write any state |\u03c8\u27e9 in terms of its projections into some base set [see Eq. (8.8)], |\u03c8\u27e9= \u2211 i |i\u27e9\u27e8i|\u03c8\u27e9. (11.20) How does |\u03c8\u27e9 change with time? Well, just take its derivative: d dt |\u03c8\u27e9= d dt \u2211 i |i\u27e9\u27e8i|\u03c8\u27e9. (11.21) Now the base states |i\u27e9 do not change with time (at least we are always taking them as definite fixed states), but the amplitudes \u27e8i|\u03c8\u27e9 are numbers which may vary. So Eq. (11.21) becomes d dt |\u03c8\u27e9= \u2211 i |i\u27e9 d dt \u27e8i|\u03c8\u27e9. (11.22) Since we know d\u27e8i|\u03c8\u27e9/dt from Eq. (11.16), we get d dt |\u03c8\u27e9 =\u2212 i \u210f \u2211 i |i\u27e9 \u2211 j H ij \u27e8j|\u03c8\u27e9 =\u2212 i \u210f \u2211 ij |i\u27e9\u27e8i|H|j\u27e9\u27e8j|\u03c8\u27e9 =\u2212 i \u210f \u2211 j H|j\u27e9\u27e8j|\u03c8\u27e9. This is Eq. (11.18) all over again. So we have many ways of looking at the Hamiltonian. We can think of the set of coefficients H ij as just a bunch of numbers, or we can think of the \u201camplitudes\u201d \u27e8i|H|j\u27e9 , or we can think of the \u201cmatrix\u201d H ij , or we can think of the \u201coperator\u201d H ^ . It all means the same thing. Now let\u2019s go back to our two-state systems. If we write the Hamiltonian in terms of the sigma matrices (with suitable numerical coefficients like B x , etc.), we can clearly also think of \u03c3 x ij as an amplitude \u27e8i| \u03c3 x |j\u27e9 or, for short, as the operator \u03c3 ^ x . If we use the operator idea, we can write the equation of motion of a state |\u03c8\u27e9 in a magnetic field as i\u210f d dt |\u03c8\u27e9=\u2212\u03bc( B x \u03c3 ^ x + B y \u03c3 ^ y + B z \u03c3 ^ z )|\u03c8\u27e9. (11.23) When we want to \u201cuse\u201d such an equation we will normally have to express |\u03c8\u27e9 in terms of base vectors (just as we have to find the components of space vectors when we want specific numbers). So we will usually want to put Eq. (11.23) in the somewhat expanded form: i\u210f d dt |\u03c8\u27e9=\u2212\u03bc \u2211 i ( B x \u03c3 ^ x + B y \u03c3 ^ y + B z \u03c3 ^ z )|i\u27e9\u27e8i|\u03c8\u27e9. (11.24) Now you will see why the operator idea is so neat. To use Eq. (11.24) we need to know what happens when the \u03c3 ^ operators work on each of the base states. Let\u2019s find out. Suppose we have \u03c3 ^ z |+\u27e9 ; it is some vector |?\u27e9 , but what? Well, let\u2019s multiply it on the left by \u27e8+| ; we have \u27e8+| \u03c3 ^ z |+\u27e9= \u03c3 z 11 =1 (using Table 11\u20131). So we know that \u27e8+|?\u27e9=1. (11.25) Now let\u2019s multiply \u03c3 ^ z |+\u27e9 on the left by \u27e8\u2212| . We get \u27e8\u2212| \u03c3 ^ z |+\u27e9= \u03c3 z 21 =0; so \u27e8\u2212|?\u27e9=0. (11.26) There is only one state vector that satisfies both (11.25) and (11.26); it is |+\u27e9 . We discover then that \u03c3 ^ z |+\u27e9=|+\u27e9. (11.27) By this kind of argument you can easily show that all of the properties of the sigma matrices can be described in the operator notation by the set of rules given in Table 11\u20133. If we have products of sigma matrices, they go over into products of operators. When two operators appear together as a product, you carry out first the operation with the operator which is farthest to the right. For instance, by \u03c3 ^ x \u03c3 ^ y |+\u27e9 we are to understand \u03c3 ^ x ( \u03c3 ^ y |+\u27e9) . From Table 11\u20133, we get \u03c3 ^ y |+\u27e9=i|\u2212\u27e9 , so \u03c3 ^ x \u03c3 ^ y |+\u27e9= \u03c3 ^ x (i|\u2212\u27e9). (11.28) Now any number\u2014like i \u2014just moves through an operator (operators work only on state vectors); so Eq. (11.28) is the same as \u03c3 ^ x \u03c3 ^ y |+\u27e9=i \u03c3 ^ x |\u2212\u27e9=i|+\u27e9. If you do the same thing for \u03c3 ^ x \u03c3 ^ y |\u2212\u27e9 , you will find that \u03c3 ^ x \u03c3 ^ y |\u2212\u27e9=\u2212i|\u2212\u27e9. Looking at Table 11\u20133, you see that \u03c3 ^ x \u03c3 ^ y operating on |+\u27e9 or |\u2212\u27e9 gives just what you get if you operate with \u03c3 ^ z and multiply by i . We can, therefore, say that the operation \u03c3 ^ x \u03c3 ^ y is identical with the operation i \u03c3 ^ z and write this statement as an operator equation: \u03c3 ^ x \u03c3 ^ y =i \u03c3 ^ z . (11.29) Notice that this equation is identical with one of our matrix equations of Table 11\u20132. So again we see the correspondence between the matrix and operator points of view. Each of the equations in Table 11\u20132 can, therefore, also be considered as equations about the sigma operators. You can check that they do indeed follow from Table 11\u20133. It is best, when working with these things, not to keep track of whether a quantity like \u03c3 or H is an operator or a matrix. All the equations are the same either way, so Table 11\u20132 is for sigma operators, or for sigma matrices, as you wish. We can now write our two-state equation in various forms, for example, either as i\u210f d C i dt = \u2211 j H ij C j d C or i\u210f d|\u03c8\u27e9 dt = H ^ |\u03c8\u27e9. (11.30) They both mean the same thing. For a spin one-half particle in a magnetic field, the Hamiltonian H is given by Eq. (11.8) or by Eq. (11.13). If the field is in the z -direction, then\u2014as we have seen several times by now\u2014the solution is that the state |\u03c8\u27e9 , whatever it is, precesses around the z -axis (just as if you were to take the physical object and rotate it bodily around the z -axis) at an angular velocity equal to twice the magnetic field times \u03bc/\u210f . The same is true, of course, for a magnetic field along any other direction, because the physics is independent of the coordinate system. If we have a situation where the magnetic field varies from time to time in a complicated way, then we can analyze the situation in the following way. Suppose you start with the spin in the +z -direction and you have an x -magnetic field. The spin starts to turn. Then if the x -field is turned off, the spin stops turning. Now if a z -field is turned on, the spin precesses about z , and so on. So depending on how the fields vary in time, you can figure out what the final state is\u2014along what axis it will point. Then you can refer that state back to the original |+\u27e9 and |\u2212\u27e9 with respect to z by using the projection formulas we had in Chapter 10 (or Chapter 6). If the state ends up with its spin in the direction (\u03b8,\u03d5) , it will have an up-amplitude cos(\u03b8/2) e \u2212i\u03d5/2 and a down-amplitude sin(\u03b8/2) e +i\u03d5/2 . That solves any problem. It is a word description of the solution of the differential equations. The solution just described is sufficiently general to take care of any two-state system. Let\u2019s take our example of the ammonia molecule\u2014including the effects of an electric field. If we describe the system in terms of the states |I\u27e9 and |II\u27e9 , the equations (9.38) and (9.39) look like this: i\u210f d C I dt i\u210f d C II dt =+A C I +\u03bcE C II , =\u2212A C II +\u03bcE C I . (11.31) You say, \u201cNo, I remember there was an E 0 in there.\u201d Well, we have shifted the origin of energy to make the E 0 zero. (You can always do that by changing both amplitudes by the same factor\u2014 e i E 0 t/\u210f \u2014and get rid of any constant energy.) Now if corresponding equations always have the same solutions, then we really don\u2019t have to do it twice. If we look at these equations and look at Eq. (11.1), then we can make the following identification. Let\u2019s call |I\u27e9 the state |+\u27e9 and |II\u27e9 the state |\u2212\u27e9 . That does not mean that we are lining-up the ammonia in space, or that |+\u27e9 and |\u2212\u27e9 has anything to do with the z -axis. It is purely artificial. We have an artificial space that we might call the \u201cammonia molecule representative space,\u201d or something\u2014a three-dimensional \u201cdiagram\u201d in which being \u201cup\u201d corresponds to having the molecule in the state |I\u27e9 and being \u201cdown\u201d along this false z -axis represents having a molecule in the state |II\u27e9 . Then, the equations will be identified as follows. First of all, you see that the Hamiltonian can be written in terms of the sigma matrices as H=+A \u03c3 z +\u03bcE \u03c3 x . (11.32) Or, putting it another way, \u03bc B z in Eq. (11.1) corresponds to \u2212A in Eq. (11.32), and \u03bc B x corresponds to \u2212\u03bcE . In our \u201cmodel\u201d space, then, we have a constant B field along the z -direction. If we have an electric field E which is changing with time, then we have a B field along the x -direction which varies in proportion. So the behavior of an electron in a magnetic field with a constant component in the z -direction and an oscillating component in the x -direction is mathematically analogous and corresponds exactly to the behavior of an ammonia molecule in an oscillating electric field. Unfortunately, we do not have the time to go any further into the details of this correspondence, or to work out any of the technical details. We only wished to make the point that all systems of two states can be made analogous to a spin one-half object precessing in a magnetic field. There are a number of other two-state systems which are interesting to study, and the first new one we would like to talk about is the photon. To describe a photon we must first give its vector momentum. For a free photon, the frequency is determined by the momentum, so we don\u2019t have to say also what the frequency is. After that, though, we still have a property called the polarization. Imagine that there is a photon coming at you with a definite monochromatic frequency (which will be kept the same throughout all this discussion so that we don\u2019t have a variety of momentum states). Then there are two directions of polarization. In the classical theory, light can be described as having an electric field which oscillates horizontally or an electric field which oscillates vertically (for instance); these two kinds of light are called x -polarized and y -polarized light. The light can also be polarized in some other direction, which can be made up from the superposition of a field in the x -direction and one in the y -direction. Or if you take the x - and the y -components out of phase by 90 \u2218 , you get an electric field that rotates\u2014the light is elliptically polarized. (This is just a quick reminder of the classical theory of polarized light that we studied in Chapter 33, Vol. I.) Now, however, suppose we have a single photon\u2014just one. There is no electric field that we can discuss in the same way. All we have is one photon. But a photon has to have the analog of the classical phenomena of polarization. There must be at least two different kinds of photons. At first, you might think there should be an infinite variety\u2014after all, the electric vector can point in all sorts of directions. We can, however, describe the polarization of a photon as a two-state system. A photon can be in the state |x\u27e9 or in the state |y\u27e9 . By |x\u27e9 we mean the polarization state of each one of the photons in a beam of light which classically is x -polarized light. On the other hand, by |y\u27e9 we mean the polarization state of each of the photons in a y -polarized beam. And we can take |x\u27e9 and |y\u27e9 as our base states of a photon of given momentum pointing at you\u2014in what we will call the z -direction. So there are two base states |x\u27e9 and |y\u27e9 , and they are all that are needed to describe any photon at all. For example, if we have a piece of polaroid set with its axis to pass light polarized in what we call the x -direction, and we send in a photon which we know is in the state |y\u27e9 , it will be absorbed by the polaroid. If we send in a photon which we know is in the state |x\u27e9 , it will come right through as |x\u27e9 . If we take a piece of calcite which takes a beam of polarized light and splits it into an |x\u27e9 beam and a |y\u27e9 beam, that piece of calcite is the complete analog of a Stern-Gerlach apparatus which splits a beam of silver atoms into the two states |+\u27e9 and |\u2212\u27e9 . So everything we did before with particles and Stern-Gerlach apparatuses, we can do again with light and pieces of calcite. And what about light filtered through a piece of polaroid set at an angle \u03b8 ? Is that another state? Yes, indeed, it is another state. Let\u2019s call the axis of the polaroid x \u2032 to distinguish it from the axes of our base states. See Fig. 11-2. A photon that comes out will be in the state | x \u2032 \u27e9 . However, any state can be represented as a linear combination of base states, and the formula for the combination is, here, | x \u2032 \u27e9=cos\u03b8|x\u27e9+sin\u03b8|y\u27e9. (11.33) That is, if a photon comes through a piece of polaroid set at the angle \u03b8 (with respect to x ), it can still be resolved into |x\u27e9 and |y\u27e9 beams\u2014by a piece of calcite, for example. Or you can, if you wish, just analyze it into x - and y -components in your imagination. Either way, you will find the amplitude cos\u03b8 to be in the |x\u27e9 state and the amplitude sin\u03b8 to be in the |y\u27e9 state. Now we ask this question: Suppose a photon is polarized in the x \u2032 -direction by a piece of polaroid set at the angle \u03b8 and arrives at a polaroid at the angle zero\u2014as in Fig. 11-3; what will happen? With what probability will it get through? The answer is the following. After it gets through the first polaroid, it is definitely in the state | x \u2032 \u27e9 . The second polaroid will let the photon through if it is in the state |x\u27e9 (but absorb it if it is the state |y\u27e9 ). So we are asking with what probability does the photon appear to be in the state |x\u27e9 ? We get that probability from the absolute square of amplitude \u27e8x| x \u2032 \u27e9 that a photon in the state | x \u2032 \u27e9 is also in the state |x\u27e9 . What is \u27e8x| x \u2032 \u27e9 ? Just multiply Eq. (11.33) by \u27e8x| to get \u27e8x| x \u2032 \u27e9=cos\u03b8\u27e8x|x\u27e9+sin\u03b8\u27e8x|y\u27e9. \u2032 Now \u27e8x|y\u27e9=0 , from the physics\u2014as they must be if |x\u27e9 and |y\u27e9 are base states\u2014and \u27e8x|x\u27e9=1 . So we get \u27e8x| x \u2032 \u27e9=cos\u03b8, \u2032 and the probability is cos 2 \u03b8 . For example, if the first polaroid is set at 30 \u2218 , a photon will get through 3/4 of the time, and 1/4 of the time it will heat the polaroid by being absorbed therein. Now let us see what happens classically in the same situation. We would have a beam of light with an electric field which is varying in some way or another\u2014say \u201cunpolarized.\u201d After it gets through the first polaroid, the electric field is oscillating in the x \u2032 -direction with a size E ; we would draw the field as an oscillating vector with a peak value E 0 in a diagram like Fig. 11-4. Now when the light arrives at the second polaroid, only the x -component, E 0 cos\u03b8 , of the electric field gets through. The intensity is proportional to the square of the field and, therefore, to E 2 0 cos 2 \u03b8 . So the energy coming through is cos 2 \u03b8 weaker than the energy which was entering the last polaroid. The classical picture and the quantum picture give similar results. If you were to throw 10 billion photons at the second polaroid, and the average probability of each one going through is, say, 3/4 , you would expect 3/4 of 10 billion would get through. Likewise, the energy that they would carry would be 3/4 of the energy that you attempted to put through. The classical theory says nothing about the statistics of the thing\u2014it simply says that the energy that comes through will be precisely 3/4 of the energy which you were sending in. That is, of course, impossible if there is only one photon. There is no such thing as 3/4 of a photon. It is either all there, or it isn\u2019t there at all. Quantum mechanics tells us it is all there 3/4 of the time. The relation of the two theories is clear. What about the other kinds of polarization? For example, right-hand circular polarization? In the classical theory, right-hand circular polarization has equal components in x and y which are 90 \u2218 out of phase. In the quantum theory, a right-hand circularly polarized (RHC) photon has equal amplitudes to be polarized |x\u27e9 or |y\u27e9 , and the amplitudes are 90 \u2218 out of phase. Calling a RHC photon a state |R\u27e9 and a LHC photon a state |L\u27e9 , we can write (see Vol. I, Section 33-1) |R\u27e9 |L\u27e9 = 1 2 \u2013 \u221a (|x\u27e9+i|y\u27e9), = 1 2 \u2013 \u221a (|x\u27e9\u2212i|y\u27e9). (11.34) \u2014the 1/ 2 \u2013 \u221a is put in to get normalized states. With these states you can calculate any filtering or interference effects you want, using the laws of quantum theory. If you want, you can also choose |R\u27e9 and |L\u27e9 as base states and represent everything in terms of them. You only need to show first that \u27e8R|L\u27e9=0 \u2014which you can do by taking the conjugate form of the first equation above [see Eq. (8.13)] and multiplying it by the other. You can resolve light into x - and y -polarizations, or into x \u2032 - and y \u2032 -polarizations, or into right and left polarizations as a basis. Just as an example, let\u2019s try to turn our formulas around. Can we represent the state |x\u27e9 as a linear combination of right and left? Yes, here it is: |x\u27e9 |y\u27e9 = 1 2 \u2013 \u221a (|R\u27e9+|L\u27e9), =\u2212 i 2 \u2013 \u221a (|R\u27e9\u2212|L\u27e9). (11.35) Proof: Add and subtract the two equations in (11.34). It is easy to go from one base to the other. One curious point has to be made, though. If a photon is right circularly polarized, it shouldn\u2019t have anything to do with the x - and y -axes. If we were to look at the same thing from a coordinate system turned at some angle about the direction of flight, the light would still be right circularly polarized\u2014and similarly for left. The right and left circularly polarized light are the same for any such rotation; the definition is independent of any choice of the x -direction (except that the photon direction is given). Isn\u2019t that nice\u2014it doesn\u2019t take any axes to define it. Much better than x and y . On the other hand, isn\u2019t it rather a miracle that when you add the right and left together you can find out which direction x was? If \u201cright\u201d and \u201cleft\u201d do not depend on x in any way, how is it that we can put them back together again and get x ? We can answer that question in part by writing out the state | R \u2032 \u27e9 , which represents a photon RHC polarized in the frame x \u2032 , y \u2032 . In that frame, you would write | R \u2032 \u27e9= 1 2 \u2013 \u221a (| x \u2032 \u27e9+i| y \u2032 \u27e9). 1 How does such a state look in the frame x,y ? Just substitute | x \u2032 \u27e9 from Eq. (11.33) and the corresponding | y \u2032 \u27e9 \u2014we didn\u2019t write it down, but it is (\u2212sin\u03b8)|x\u27e9+(cos\u03b8)|y\u27e9 . Then | R \u2032 \u27e9 = 1 2 \u2013 \u221a [cos\u03b8|x\u27e9+sin\u03b8|y\u27e9\u2212isin\u03b8|x\u27e9+icos\u03b8|y\u27e9] = 1 2 \u2013 \u221a [(cos\u03b8\u2212isin\u03b8)|x\u27e9+i(cos\u03b8\u2212isin\u03b8)|y\u27e9] = 1 2 \u2013 \u221a (|x\u27e9+i|y\u27e9)(cos\u03b8\u2212isin\u03b8). The first term is just |R\u27e9 , and the second is e \u2212i\u03b8 ; our result is that | R \u2032 \u27e9= e \u2212i\u03b8 |R\u27e9. (11.36) The states | R \u2032 \u27e9 and |R\u27e9 are the same except for the phase factor e \u2212i\u03b8 . If you work out the same thing for | L \u2032 \u27e9 , you get that1 | L \u2032 \u27e9= e +i\u03b8 |L\u27e9. (11.37) Now you see what happens. If we add |R\u27e9 and |L\u27e9 , we get something different from what we get when we add | R \u2032 \u27e9 and | L \u2032 \u27e9 . For instance, an x -polarized photon is [Eq. (11.35)] the sum of |R\u27e9 and |L\u27e9 , but a y -polarized photon is the sum with the phase of one shifted 90 \u2218 backward and the other 90 \u2218 forward. That is just what we would get from the sum of | R \u2032 \u27e9 and | L \u2032 \u27e9 for the special angle \u03b8= 90 \u2218 , and that\u2019s right. An x -polarization in the prime frame is the same as a y -polarization in the original frame. So it is not exactly true that a circularly polarized photon looks the same for any set of axes. Its phase (the phase relation of the right and left circularly polarized states) keeps track of the x -direction. We will now describe a two-state system in the world of the strange particles\u2014a system for which quantum mechanics gives a most remarkable prediction. To describe it completely would involve us in a lot of stuff about strange particles, so we will, unfortunately, have to cut some corners. We can only give an outline of how a certain discovery was made\u2014to show you the kind of reasoning that was involved. It begins with the discovery by Gell-Mann and Nishijima of the concept of strangeness and of a new law of conservation of strangeness. It was when Gell-Mann and Pais were analyzing the consequences of these new ideas that they came across the prediction of a most remarkable phenomenon we are going to describe. First, though, we have to tell you a little about \u201cstrangeness.\u201d We must begin with what are called the strong interactions of nuclear particles. These are the interactions which are responsible for the strong nuclear forces\u2014as distinct, for instance, from the relatively weaker electromagnetic interactions. The interactions are \u201cstrong\u201d in the sense that if two particles get close enough to interact at all, they interact in a big way and produce other particles very easily. The nuclear particles have also what is called a \u201cweak interaction\u201d by which certain things can happen, such as beta decay, but always very slowly on a nuclear time scale\u2014the weak interactions are many, many orders of magnitude weaker than the strong interactions and even much weaker than electromagnetic interactions. When the strong interactions were being studied with the big accelerators, people were surprised to find that certain things that \u201cshould\u201d happen\u2014that were expected to happen\u2014did not occur. For instance, in some interactions a particle of a certain type did not appear when it was expected. Gell-Mann and Nishijima noticed that many of these peculiar happenings could be explained at once by inventing a new conservation law: the conservation of strangeness. They proposed that there was a new kind of attribute associated with each particle\u2014which they called its \u201cstrangeness\u201d number\u2014and that in any strong interaction the \u201cquantity of strangeness\u201d is conserved. Suppose, for instance, that a high-energy negative K-meson\u2014with, say, an energy of many GeV\u2014collides with a proton. Out of the interaction may come many other particles: \u03c0 -mesons, K-mesons, lambda particles, sigma particles\u2014any of the mesons or baryons listed in Table 2\u20132 of Vol. I. It is observed, however, that only certain combinations appear, and never others. Now certain conservation laws were already known to apply. First, energy and momentum are always conserved. The total energy and momentum after an event must be the same as before the event. Second, there is the conservation of electric charge which says that the total charge of the outgoing particles must be equal to the total charge carried by the original particles. In our example of a K-meson and a proton coming together, the following reactions do occur: or K \u2212 +p\u2192p+ K \u2212 + \u03c0 + + \u03c0 \u2212 + \u03c0 0 K \u2212 +p\u2192 \u03a3 \u2212 + \u03c0 + . (11.38) We would never get: or K \u2212 +p\u2192p+ K \u2212 + \u03c0 + K \u2212 +p\u2192 \u039b 0 + \u03c0 + , (11.39) because of the conservation of charge. It was also known that the number of baryons is conserved. The number of baryons out must be equal to the number of baryons in. For this law, an antiparticle of a baryon is counted as minus one baryon. This means that we can\u2014and do\u2014see or K \u2212 +p\u2192 \u039b 0 + \u03c0 0 K \u2212 +p\u2192p+ K \u2212 +p+ p \u00af \u00af \u00af (11.40) (where p \u00af \u00af \u00af is the antiproton, which carries a negative charge). But we never see or K \u2212 +p\u2192 K \u2212 + \u03c0 + + \u03c0 0 K \u2212 +p\u2192p+ K \u2212 +n (11.41) (even when there is plenty of energy), because baryons would not be conserved. These laws, however, do not explain the strange fact that the following reactions\u2014which do not immediately appear to be especially different from some of those in (11.38) or (11.40)\u2014are also never observed: or or K \u2212 +p\u2192p+ K \u2212 +K 0 K \u2212 +p\u2192p+ \u03c0 \u2212 K \u2212 +p\u2192 \u039b 0 +K 0 . (11.42) The explanation is the conservation of strangeness. With each particle goes a number\u2014its strangeness S \u2014and there is a law that in any strong interaction, the total strangeness out must equal the total strangeness that went in. The proton and antiproton ( p , p \u00af \u00af \u00af ), the neutron and antineutron ( n , n \u00af \u00af \u00af ), and the \u03c0 -mesons ( \u03c0 + , \u03c0 0 , \u03c0 \u2212 ) all have the strangeness number zero; the K + and K 0 mesons have strangeness +1 ; the K \u2212 and K \u00af \u00af \u00af \u00af 0 (the anti- K 0 ),3 the \u039b 0 and the \u03a3 -particles ( + , 0 , \u2212 ) have strangeness \u22121 . There is also a particle with strangeness \u22122 \u2014the \u039e -particle (capital \u201cksi\u201d)\u2014and perhaps others as yet unknown. We have made a list of these strangenesses in Table 11\u20134. Let\u2019s see how the strangeness conservation works in some of the reactions we have written down. If we start with a K \u2212 and a proton, we have a total strangeness of (\u22121+0)=\u22121 . The conservation of strangeness says that the strangeness of products after the reaction must also add up to \u22121 . You see that that is so for the reactions of (11.38) and (11.40). But in the reactions of (11.42) the strangeness of the right-hand side is zero in each case. Such reactions do not conserve strangeness, and do not occur. Why? Nobody knows. Nobody knows any more than what we have just told you about this. Nature just works that way. Now let\u2019s look at the following reaction: a \u03c0 \u2212 hits a proton. You might, for instance, get a \u039b 0 particle plus a neutral K-particle\u2014two neutral particles. Now which neutral K do you get? Since the \u039b -particle has a strangeness \u22121 and the \u03c0 and p + have a strangeness zero, and since this is a fast production reaction, the strangeness must not change. The K-particle must have strangeness +1 \u2014it must therefore be the K 0 . The reaction is \u03c0 \u2212 +p\u2192 \u039b 0 +K 0 , 0 with S=0+0=\u22121++1(conserved). ( conserved ) If the K \u00af \u00af \u00af \u00af 0 were there instead of the K 0 , the strangeness on the right would be \u22122 \u2014which nature does not permit, since the strangeness on the left side is zero. On the other hand, a K \u00af \u00af \u00af \u00af 0 can be produced in other reactions, such as n+p\u2192n+n+ K \u00af \u00af \u00af \u00af 0 + K + , S=0+0=0+0+\u22121++1 or K \u2212 +p\u2192n+ K \u00af \u00af \u00af \u00af 0 , S=\u22121+0=0+\u22121. You may be thinking, \u201cThat\u2019s all a lot of stuff, because how do you know whether it is a K \u00af \u00af \u00af \u00af 0 or a K 0 ? They look exactly the same. They are antiparticles of each other, so they have exactly the same mass, and both have zero electric charge. How do you distinguish them?\u201d By the reactions they produce. For example, a K \u00af \u00af \u00af \u00af 0 can interact with matter to produce a \u039b -particle, like this: K \u00af \u00af \u00af \u00af 0 +p\u2192 \u039b 0 + \u03c0 + , 0 but a K 0 cannot. There is no way a K 0 can produce a \u039b -particle when it interacts with ordinary matter (protons and neutrons).4 So the experimental distinction between the K 0 and the K \u00af \u00af \u00af \u00af 0 would be that one of them will and one of them will not produce \u039b 's. One of the predictions of the strangeness theory is then this\u2014if, in an experiment with high-energy pions, a \u039b -particle is produced with a neutral K-meson, then that neutral K-meson going into other pieces of matter will never produce a \u039b . The experiment might run something like this. You send a beam of \u03c0 \u2212 -mesons into a large hydrogen bubble chamber. A \u03c0 \u2212 track disappears, but somewhere else a pair of tracks appear (a proton and a \u03c0 \u2212 ) indicating that a \u039b -particle has disintegrated5 \u2014see Fig. 11-5. Then you know that there is a K 0 somewhere which you cannot see. You can, however, figure out where it is going by using the conservation of momentum and energy. [It could reveal itself later by disintegrating into two charged particles, as shown in Fig. 11-5(a).] As the K 0 goes flying along, it may interact with one of the hydrogen nuclei (protons), producing perhaps some other particles. The prediction of the strangeness theory is that it will never produce a \u039b -particle in a simple reaction like, say, K 0 +p\u2192 \u039b 0 + \u03c0 + , 0 although a K \u00af \u00af \u00af \u00af 0 can do just that. That is, in a bubble chamber a K \u00af \u00af \u00af \u00af 0 might produce the event sketched in Fig. 11-5(b)\u2014in which the \u039b 0 is seen because it decays\u2014but a K 0 will not. That\u2019s the first part of our story. That\u2019s the conservation of strangeness. The conservation of strangeness is, however, not perfect. There are very slow disintegrations of the strange particles\u2014decays taking a long6 time like 10 \u221210 second in which the strangeness is not conserved. These are called the \u201cweak\u201d decays. For example, the K 0 disintegrates into a pair of \u03c0 -mesons ( + and \u2212 ) with a lifetime of 10 \u221210 second. That was, in fact, the way K-particles were first seen. Notice that the decay reaction K 0 \u2192 \u03c0 + + \u03c0 \u2212 0 + does not conserve strangeness, so it cannot go \u201cfast\u201d by the strong interaction; it can only go through the weak decay process. Now the K \u00af \u00af \u00af \u00af 0 also disintegrates in the same way\u2014into a \u03c0 + and a \u03c0 \u2212 \u2014and also with the same lifetime K \u00af \u00af \u00af \u00af 0 \u2192 \u03c0 \u2212 + \u03c0 + . Again we have a weak decay because it does not conserve strangeness. There is a principle that for any reaction there is the corresponding reaction with \u201cmatter\u201d replaced by \u201cantimatter\u201d and vice versa. Since the K \u00af \u00af \u00af \u00af 0 is the antiparticle of the K 0 , it should decay into the antiparticles of the \u03c0 + and \u03c0 \u2212 , but the antiparticle of a \u03c0 + is the \u03c0 \u2212 . (Or, if you prefer, vice versa. It turns out that for the \u03c0 -mesons it doesn\u2019t matter which one you call \u201cmatter.\u201d) So as a consequence of the weak decays, the K 0 and K \u00af \u00af \u00af \u00af 0 can go into the same final products. When \u201cseen\u201d through their decays\u2014as in a bubble chamber\u2014they look like the same particle. Only their strong interactions are different. At last we are ready to describe the work of Gell-Mann and Pais. They first noticed that since the K 0 and the K \u00af \u00af \u00af \u00af 0 can both turn into states of two \u03c0 -mesons there must be some amplitude that a K 0 can turn into a K \u00af \u00af \u00af \u00af 0 , and also that a K \u00af \u00af \u00af \u00af 0 can turn into a K 0 . Writing the reactions as one does in chemistry, we would have K 0 \u21cc \u03c0 \u2212 + \u03c0 + \u21cc K \u00af \u00af \u00af \u00af 0 . (11.43) These reactions imply that there is some amplitude per unit time, say \u2212i/\u210f times \u27e8 K \u00af \u00af \u00af \u00af 0 |W|K 0 \u27e9 , that a K 0 will turn into a K \u00af \u00af \u00af \u00af 0 through the weak interaction responsible for the decay into two \u03c0 -mesons. And there is the corresponding amplitude \u27e8K 0 |W| K \u00af \u00af \u00af \u00af 0 \u27e9 for the reverse process. Because matter and antimatter behave in exactly the same way, these two amplitudes are numerically equal; we\u2019ll call them both A : \u27e8 K \u00af \u00af \u00af \u00af 0 |W|K 0 \u27e9=\u27e8K 0 |W| K \u00af \u00af \u00af \u00af 0 \u27e9=A. (11.44) Now\u2014said Gell-Mann and Pais\u2014here is an interesting situation. What people have been calling two distinct states of the world\u2014the K 0 and the K \u00af \u00af \u00af \u00af 0 \u2014should really be considered as one two-state system, because there is an amplitude to go from one state to the other. For a complete treatment, one would, of course, have to deal with more than two states, because there are also the states of 2\u03c0 's, and so on; but since they were mainly interested in the relation of K 0 and K \u00af \u00af \u00af \u00af 0 , they did not have to complicate things and could make the approximation of a two-state system. The other states were taken into account to the extent that their effects appeared implicitly in the amplitudes of Eq. (11.44). Accordingly, Gell-Mann and Pais analyzed the neutral particle as a two-state system. They began by choosing as their two base states the states |K 0 \u27e9 and | K \u00af \u00af \u00af \u00af 0 \u27e9 . (From here on, the story goes very much as it did for the ammonia molecule.) Any state |\u03c8\u27e9 of the neutral K-particle could then be described by giving the amplitudes that it was in either base state. We\u2019ll call these amplitudes C + =\u27e8K 0 |\u03c8\u27e9, C \u2212 =\u27e8 K \u00af \u00af \u00af \u00af 0 |\u03c8\u27e9. (11.45) The next step was to write the Hamiltonian equations for this two-state system. If there were no coupling between the K 0 and the K \u00af \u00af \u00af \u00af 0 , the equations would be simply i\u210f d C + dt i\u210f d C \u2212 dt = E 0 C + , = E 0 C \u2212 . (11.46) But since there is the amplitude \u27e8K 0 |W| K \u00af \u00af \u00af \u00af 0 \u27e9 for the K \u00af \u00af \u00af \u00af 0 to turn into a K 0 there should be the additional term \u27e8K 0 |W| K \u00af \u00af \u00af \u00af 0 \u27e9 C \u2212 =A C \u2212 added to the right-hand side of the first equation. And similarly, the term A C + should be inserted in the equation for the rate of change of C \u2212 . But that\u2019s not all. When the two-pion effect is taken into account there is an additional amplitude for the K 0 to turn into itself through the process K 0 \u2192 \u03c0 \u2212 + \u03c0 + \u2192K 0 . 0 + 0 The additional amplitude, which we would write \u27e8K 0 |W|K 0 \u27e9 , is just equal to the amplitude \u27e8 K \u00af \u00af \u00af \u00af 0 |W|K 0 \u27e9 , since the amplitudes to go to and from a pair of \u03c0 -mesons are identical for the K 0 and the K \u00af \u00af \u00af \u00af 0 . If you wish, the argument can be written out in detail like this. First write7 \u27e8 K \u00af \u00af \u00af \u00af 0 |W|K 0 \u27e9=\u27e8 K \u00af \u00af \u00af \u00af 0 |W|2\u03c0\u27e9\u27e82\u03c0|W|K 0 \u27e9 and \u27e8K 0 |W|K 0 \u27e9=\u27e8K 0 |W|2\u03c0\u27e9\u27e82\u03c0|W|K 0 \u27e9. 0 0 0 0 Because of the symmetry of matter and antimatter \u27e82\u03c0|W|K 0 \u27e9=\u27e82\u03c0|W| K \u00af \u00af \u00af \u00af 0 \u27e9, and also \u27e8K 0 |W|2\u03c0\u27e9=\u27e8 K \u00af \u00af \u00af \u00af 0 |W|2\u03c0\u27e9. It then follows that \u27e8K 0 |W|K 0 \u27e9=\u27e8 K \u00af \u00af \u00af \u00af 0 |W|K 0 \u27e9 , and also that \u27e8 K \u00af \u00af \u00af \u00af 0 |W|K 0 \u27e9=\u27e8K 0 |W| K \u00af \u00af \u00af \u00af 0 \u27e9 , as we said earlier. Anyway, there are the two additional amplitudes \u27e8K 0 |W|K 0 \u27e9 and \u27e8 K \u00af \u00af \u00af \u00af 0 |W| K \u00af \u00af \u00af \u00af 0 \u27e9 , both equal to A , which should be included in the Hamiltonian equations. The first gives a term A C + on the right-hand side of the equation for d C + /dt , and the second gives a new term A C \u2212 in the equation for d C \u2212 /dt . Reasoning this way, Gell-Mann and Pais concluded that the Hamiltonian equations for the K 0 K \u00af \u00af \u00af \u00af 0 system should be i\u210f d C + dt i\u210f d C \u2212 dt = E 0 C + +A C \u2212 +A C + , = E 0 C \u2212 +A C + +A C \u2212 . (11.47) We must now correct something we have said in earlier chapters: that two amplitudes like \u27e8K 0 |W| K \u00af \u00af \u00af \u00af 0 \u27e9 and \u27e8 K \u00af \u00af \u00af \u00af 0 |W|K 0 \u27e9 which are the reverse of each other, are always complex conjugates. That was true when we were talking about particles that did not decay. But if particles can decay\u2014and can, therefore, become \u201clost\u201d\u2014the two amplitudes are not necessarily complex conjugates. So the equality of (11.44) does not mean that the amplitudes are real numbers; they are in fact complex numbers. The coefficient A is, therefore, complex; and we can\u2019t just incorporate it into the energy E 0 . Having played often with electron spins and such, our heroes knew that the Hamiltonian equations of (11.47) meant that there was another pair of base states which could also be used to represent the K-particle system and which would have especially simple behaviors. They said, \u201cLet\u2019s take the sum and difference of these two equations. Also, let\u2019s measure all our energies from E 0 , and use units for energy and time that make \u210f=1 .\u201d (That\u2019s what modern theoretical physicists always do. It doesn\u2019t change the physics but makes the equations take on a simple form.) Their result: i d dt ( C + + C \u2212 ) i d dt ( C + \u2212 C \u2212 ) =2A( C + + C \u2212 ), =0. (11.48) It is apparent that the combinations of amplitudes ( C + + C \u2212 ) and ( C + \u2212 C \u2212 ) act independently from each other (corresponding, of course, to the stationary states we have been studying earlier). So they concluded that it would be more convenient to use a different representation for the K-particle. They defined the two states | K 1 \u27e9 | K 2 \u27e9 = 1 2 \u2013 \u221a (|K 0 \u27e9+| K \u00af \u00af \u00af \u00af 0 \u27e9), = 1 2 \u2013 \u221a (|K 0 \u27e9\u2212| K \u00af \u00af \u00af \u00af 0 \u27e9). (11.49) They said that instead of thinking of the K 0 and K \u00af \u00af \u00af \u00af 0 mesons, we can equally well think in terms of the two \u201cparticles\u201d (that is, \u201cstates\u201d) K 1 and K 2 . (These correspond, of course, to the states we have usually called |I\u27e9 and |II\u27e9 . We are not using our old notation because we want now to follow the notation of the original authors\u2014and the one you will see in physics seminars.) Now Gell-Mann and Pais didn\u2019t do all this just to get different names for the particles\u2014there is also some strange new physics in it. Suppose that C 1 and C 2 are the amplitudes that some state |\u03c8\u27e9 will be either a K 1 or a K 2 meson: C 1 =\u27e8 K 1 |\u03c8\u27e9, C 2 =\u27e8 K 2 |\u03c8\u27e9. \u27e8 | \u03c8 \u27e9 \u27e8 | \u03c8 \u27e9 From the equations of (11.49), C 1 C 2 = 1 2 \u2013 \u221a ( C + + C \u2212 ), = 1 2 \u2013 \u221a ( C + \u2212 C \u2212 ). (11.50) Then the Eqs. (11.48) become i d C 1 dt =2A C 1 ,i d C 2 dt =0. (11.51) The solutions are C 1 (t)= C 1 (0) e \u2212i2At , C 2 (t)= C 2 (0), (11.52) where, of course, C 1 (0) and C 2 (0) are the amplitudes at t=0 . These equations say that if a neutral K-particle starts out in the state | K 1 \u27e9 at t=0 [then C 1 (0)=1 and C 2 (0)=0 ], the amplitudes at the time t are C 1 (t)= e \u2212i2At , C 2 (t)=0. i 2 A t Remembering that A is a complex number, it is convenient to take 2A=\u03b1\u2212i\u03b2 . (Since the imaginary part of 2A turns out to be negative, we write it as minus i\u03b2 .) With this substitution, C 1 (t) reads C 1 (t)= C 1 (0) e \u2212\u03b2t e \u2212i\u03b1t . (11.53) The probability of finding a K 1 particle at t is the absolute square of this amplitude, which is e \u22122\u03b2t . And, from Eqs. (11.52), the probability of finding the K 2 state at any time is zero. That means that if you make a K-particle in the state | K 1 \u27e9 , the probability of finding it in the same state decreases exponentially with time\u2014but you will never find it in state | K 2 \u27e9 . Where does it go? It disintegrates into two \u03c0 -mesons with the mean life \u03c4=1/2\u03b2 which is, experimentally, 10 \u221210 sec. We made provisions for that when we said that A was complex. On the other hand, Eq. (11.52) says that if we make a K-particle completely in the K 2 state, it stays that way forever. Well, that\u2019s not really true. It is observed experimentally to disintegrate into three \u03c0 -mesons, but 600 times slower than the two-pion decay we have described. So there are some other small terms we have left out in our approximation. But so long as we are considering only the two-pion decay, the K 2 lasts \u201cforever.\u201d Now to finish the story of Gell-Mann and Pais. They went on to consider what happens when a K-particle is produced with a \u039b 0 particle in a strong interaction. Since it must then have a strangeness of +1 , it must be produced in the K 0 state. So at t=0 it is neither a K 1 nor a K 2 but a mixture. The initial conditions are C + (0)=1, C \u2212 (0)=0. ( ) ( ) But that means\u2014from Eq. (11.50)\u2014that C 1 (0)= 1 2 \u2013 \u221a , C 2 (0)= 1 2 \u2013 \u221a , 1 1 and\u2014from Eqs. (11.52) and (11.53)\u2014that C 1 (t)= 1 2 \u2013 \u221a e \u2212\u03b2t e \u2212i\u03b1t , C 2 (t)= 1 2 \u2013 \u221a . (11.54) Now remember that K 0 and K \u00af \u00af \u00af \u00af 0 are each linear combinations of K 1 and K 2 . In Eqs. (11.54) the amplitudes have been chosen so that at t=0 the K \u00af \u00af \u00af \u00af 0 parts cancel each other out by interference, leaving only a K 0 state. But the | K 1 \u27e9 state changes with time, and the | K 2 \u27e9 state does not. After t=0 the interference of C 1 and C 2 will give finite amplitudes for both K 0 and K \u00af \u00af \u00af \u00af 0 . What does all this mean? Let\u2019s go back and think of the experiment we sketched in Fig. 11-5. A \u03c0 \u2212 meson has produced a \u039b 0 particle and a K 0 meson which is tooting along through the hydrogen in the chamber. As it goes along, there is some small but uniform chance that it will collide with a hydrogen nucleus. At first, we thought that strangeness conservation would prevent the K-particle from making a \u039b 0 in such an interaction. Now, however, we see that that is not right. For although our K-particle starts out as a K 0 \u2014which cannot make a \u039b 0 \u2014it does not stay this way. After a while, there is some amplitude that it will have flipped to the K \u00af \u00af \u00af \u00af 0 state. We can, therefore, sometimes expect to see a \u039b 0 produced along the K-particle track. The chance of this happening is given by the amplitude C \u2212 , which we can [by using Eq. (11.50) backwards] relate to C 1 and C 2 . The relation is C \u2212 = 1 2 \u2013 \u221a ( C 1 \u2212 C 2 )= 1 2 ( e \u2212\u03b2t e \u2212i\u03b1t \u22121). (11.55) As our K-particle goes along, the probability that it will \u201cact like\u201d a K \u00af \u00af \u00af \u00af 0 is equal to | C \u2212 | 2 , which is | C \u2212 | 2 = 1 4 (1+ e \u22122\u03b2t \u22122 e \u2212\u03b2t cos\u03b1t). (11.56) A complicated and strange result! This, then, is the remarkable prediction of Gell-Mann and Pais: when a K 0 is produced, the chance that it will turn into a K \u00af \u00af \u00af \u00af 0 \u2014as it can demonstrate by being able to produce a \u039b 0 \u2014varies with time according to Eq. (11.56). This prediction came from using only sheer logic and the basic principles of the quantum mechanics\u2014with no knowledge at all of the inner workings of the K-particle. Since nobody knows anything about the inner machinery, that is as far as Gell-Mann and Pais could go. They could not give any theoretical values for \u03b1 and \u03b2 . And nobody has been able to do so to this date. They were able to give a value of \u03b2 obtained from the experimentally observed rate of decay into two \u03c0 's ( 2\u03b2= 10 10 sec \u22121 ), but they could say nothing about \u03b1 . We have plotted the function of Eq. (11.56) for two values of \u03b1 in Fig. 11-6. You can see that the form depends very much on the ratio of \u03b1 to \u03b2 . There is no K \u00af \u00af \u00af \u00af 0 probability at first; then it builds up. If \u03b1 is large, the probability would have large oscillations. If \u03b1 is small, there will be little or no oscillation\u2014the probability will just rise smoothly to 1/4 . Now, typically, the K-particle will be travelling at a constant speed near the speed of light. The curves of Fig. 11-6 then also represent the probability along the track of observing a K \u00af \u00af \u00af \u00af 0 \u2014with typical distances of several centimeters. You can see why this prediction is so remarkably peculiar. You produce a single particle and instead of just disintegrating, it does something else. Sometimes it disintegrates, and other times it turns into a different kind of a particle. Its characteristic probability of producing an effect varies in a strange way as it goes along. There is nothing else quite like it in nature. And this most remarkable prediction was made solely by arguments about the interference of amplitudes. If there is any place where we have a chance to test the main principles of quantum mechanics in the purest way\u2014does the superposition of amplitudes work or doesn\u2019t it?\u2014this is it. In spite of the fact that this effect has been predicted now for several years, there is no experimental determination that is very clear. There are some rough results which indicate that the \u03b1 is not zero, and that the effect really occurs\u2014they indicate that \u03b1 is between 2\u03b2 and 4\u03b2 . That\u2019s all there is, experimentally. It would be very beautiful to check out the curve exactly to see if the principle of superposition really still works in such a mysterious world as that of the strange particles\u2014with unknown reasons for the decays, and unknown reasons for the strangeness. The analysis we have just described is very characteristic of the way quantum mechanics is being used today in the search for an understanding of the strange particles. All the complicated theories that you may hear about are no more and no less than this kind of elementary hocus-pocus using the principles of superposition and other principles of quantum mechanics of that level. Some people claim that they have theories by which it is possible to calculate the \u03b2 and \u03b1 , or at least the \u03b1 given the \u03b2 , but these theories are completely useless. For instance, the theory that predicts the value of \u03b1 , given the \u03b2 , tells us that the value of \u03b1 should be infinite. The set of equations with which they originally start involves two \u03c0 -mesons and then goes from the two \u03c0 \u2019s back to a K 0 , and so on. When it\u2019s all worked out, it does indeed produce a pair of equations like the ones we have here; but because there are an infinite number of states of two \u03c0 's, depending on their momenta, integrating over all the possibilities gives an \u03b1 which is infinite. But nature\u2019s \u03b1 is not infinite. So the dynamical theories are wrong. It is really quite remarkable that the phenomena which can be predicted at all in the world of the strange particles come from the principles of quantum mechanics at the level at which you are learning them now. We have finished with all the two-state systems we wanted to talk about. In the following chapters we will go on to study systems with more states. The extension to N -state systems of the ideas we have worked out for two states is pretty straightforward. It goes like this. If a system has N distinct states, we can represent any state |\u03c8(t)\u27e9 as a linear combination of any set of base states |i\u27e9 , where i=1 , 2 , 3 , \u2026 , N ; |\u03c8(t)\u27e9= \u2211 all i |i\u27e9 C i (t). (11.57) The coefficients C i (t) are the amplitudes \u27e8i|\u03c8(t)\u27e9 . The behavior of the amplitudes C i with time is governed by the equations i\u210f d C i (t) dt = \u2211 j H ij C j , (11.58) where the energy matrix H ij describes the physics of the problem. It looks the same as for two states. Only now, both i and j must range over all N base states, and the energy matrix H ij \u2014or, if you prefer, the Hamiltonian\u2014is an N by N matrix with N 2 numbers. As before, H \u2217 ij = H ji \u2014so long as particles are conserved\u2014and the diagonal elements H ii are real numbers. We have found a general solution for the C \u2019s of a two-state system when the energy matrix is constant (doesn\u2019t depend on t ). It is also not difficult to solve Eq. (11.58) for an N -state system when H is not time dependent. Again, we begin by looking for a possible solution in which the amplitudes all have the same time dependence. We try C i = a i e \u2212(i/\u210f)Et . (11.59) When these C i \u2019s are substituted into (11.58), the derivatives d C i (t)/dt become just (\u2212i/\u210f)E C i . Canceling the common exponential factor from all terms, we get E a i = \u2211 j H ij a j . (11.60) This is a set of N linear algebraic equations for the N unknowns a 1 , a 2 , \u2026 , a N , and there is a solution only if you are lucky\u2014only if the determinant of the coefficients of all the a 's is zero. But it\u2019s not necessary to be that sophisticated; you can just start to solve the equations any way you want, and you will find that they can be solved only for certain values of E . (Remember that E is the only adjustable thing we have in the equations.) If you want to be formal, however, you can write Eq. (11.60) as \u2211 j ( H ij \u2212 \u03b4 ij E) a j =0. (11.61) Then you can use the rule\u2014if you know it\u2014that these equations will have a solution only for those values of E for which Det ( H ij \u2212 \u03b4 ij E)=0. (11.62) Each term of the determinant is just H ij , except that E is subtracted from every diagonal element. That is, (11.62) means just Det \u239b \u239d \u239c \u239c \u239c \u239c \u239c \u239c H 11 \u2212E H 21 H 31 \u2026 H 12 H 22 \u2212E H 32 \u2026 H 13 H 23 H 33 \u2212E \u2026 \u2026 \u2026 \u2026 \u2026 \u239e \u23a0 \u239f \u239f \u239f \u239f \u239f \u239f =0. (11.63) This is, of course, just a special way of writing an algebraic equation for E which is the sum of a bunch of products of all the terms taken a certain way. These products will give all the powers of E up to E N . So we have an N th order polynomial equal to zero, and there are, in general, N roots. (We must remember, however, that some of them may be multiple roots\u2014meaning that two or more roots are equal.) Let\u2019s call the N roots E I , E II , E III ,\u2026, E n ,\u2026, E N . (11.64) (We will use n to represent the n th Roman numeral, so that n takes on the values I , II , \u2026 , N .) It may be that some of these energies are equal\u2014say E II = E III \u2014but we will still choose to call them by different names. The equations (11.60)\u2014or (11.61)\u2014have one solution for each value of E . If you put any one of the E 's\u2014say E n \u2014into (11.60) and solve for the a i , you get a set which belongs to the energy E n . We will call this set a i (n) . Using these a i (n) in Eq. (11.59), we have the amplitudes C i (n) that the definite energy states are in the base state |i\u27e9 . Letting |n\u27e9 stand for the state vector of the definite energy state at t=0 , we can write C i (n)=\u27e8i|n\u27e9 e \u2212(i/\u210f) E n t , ( i / \u210f ) E with \u27e8i|n\u27e9= a i (n). (11.65) The complete definite energy state | \u03c8 n (t)\u27e9 can then be written as | \u03c8 n (t)\u27e9= \u2211 i |i\u27e9 a i (n) e \u2212(i/\u210f) E n t , \u2211 ( ) or | \u03c8 n (t)\u27e9=|n\u27e9 e \u2212(i/\u210f) E n t . (11.66) The state vectors |n\u27e9 describe the configuration of the definite energy states, but have the time dependence factored out. Then they are constant vectors which can be used as a new base set if we wish. Each of the states |n\u27e9 has the property\u2014as you can easily show\u2014that when operated on by the Hamiltonian operator H ^ it gives just E n times the same state: H ^ |n\u27e9= E n |n\u27e9. (11.67) The energy E n is, then, a number which is a characteristic of the Hamiltonian operator H ^ . As we have seen, a Hamiltonian will, in general, have several characteristic energies. In the mathematician\u2019s world these would be called the \u201ccharacteristic values\u201d of the matrix H ij . Physicists usually call them the \u201ceigenvalues\u201d of H ^ . (\u201cEigen\u201d is the German word for \u201ccharacteristic\u201d or \u201cproper.\u201d) With each eigenvalue of H ^ \u2014in other words, for each energy\u2014there is the state of definite energy, which we have called the \u201cstationary state.\u201d Physicists usually call the states |n\u27e9 \u201cthe eigenstates of H ^ .\u201d Each eigenstate corresponds to a particular eigenvalue E n . Now, generally, the states |n\u27e9 \u2014of which there are N \u2014can also be used as a base set. For this to be true, all of the states must be orthogonal, meaning that for any two of them, say |n\u27e9 and |m\u27e9 , \u27e8n|m\u27e9=0. (11.68) This will be true automatically if all the energies are different. Also, we can multiply all the a i (n) by a suitable factor so that all the states are normalized\u2014by which we mean that \u27e8n|n\u27e9=1 (11.69) for all n . When it happens that Eq. (11.63) accidentally has two (or more) roots with the same energy, there are some minor complications. First, there are still two different sets of a i 's which go with the two equal energies, but the states they give may not be orthogonal. Suppose you go through the normal procedure and find two stationary states with equal energies\u2014let\u2019s call them |\u03bc\u27e9 and |\u03bd\u27e9 . Then it will not necessarily be so that they are orthogonal\u2014if you are unlucky, \u27e8\u03bc|\u03bd\u27e9\u22600. \u27e8 | \u27e9 \u2260 It is, however, always true that you can cook up two new states, which we will call | \u03bc \u2032 \u27e9 and | \u03bd \u2032 \u27e9 , that have the same energies and are also orthogonal, so that \u27e8 \u03bc \u2032 | \u03bd \u2032 \u27e9=0. (11.70) You can do this by making | \u03bc \u2032 \u27e9 and | \u03bd \u2032 \u27e9 a suitable linear combination of |\u03bc\u27e9 and |\u03bd\u27e9 , with the coefficients chosen to make it come out so that Eq. (11.70) is true. It is always convenient to do this. We will generally assume that this has been done so that we can always assume that our proper energy states |n\u27e9 are all orthogonal. We would like, for fun, to prove that when two of the stationary states have different energies they are indeed orthogonal. For the state |n\u27e9 with the energy E n , we have that H ^ |n\u27e9= E n |n\u27e9. (11.71) This operator equation really means that there is an equation between numbers. Filling the missing parts, it means the same as \u2211 j \u27e8i| H ^ |j\u27e9\u27e8j|n\u27e9= E n \u27e8i|n\u27e9. (11.72) If we take the complex conjugate of this equation, we get \u2211 j \u27e8i| H ^ |j \u27e9 \u2217 \u27e8j|n \u27e9 \u2217 = E \u2217 n \u27e8i|n \u27e9 \u2217 . (11.73) Remember now that the complex conjugate of an amplitude is the reverse amplitude, so (11.73) can be rewritten as \u2211 j \u27e8n|j\u27e9\u27e8j| H ^ |i\u27e9= E \u2217 n \u27e8n|i\u27e9. (11.74) Since this equation is valid for any i , its \u201cshort form\u201d is \u27e8n| H ^ = E \u2217 n \u27e8n|, (11.75) which is called the adjoint to Eq. (11.71). Now we can easily prove that E n is a real number. We multiply Eq. (11.71) by \u27e8n| to get \u27e8n| H ^ |n\u27e9= E n , (11.76) since \u27e8n|n\u27e9=1 . Then we multiply Eq. (11.75) on the right by |n\u27e9 to get \u27e8n| H ^ |n\u27e9= E \u2217 n . (11.77) Comparing (11.76) with (11.77) it is clear that E n = E \u2217 n , (11.78) which means that E n is real. We can erase the star on E n in Eq. (11.75). Finally we are ready to show that the different energy states are orthogonal. Let |n\u27e9 and |m\u27e9 be any two of the definite energy base states. Using Eq. (11.75) for the state m , and multiplying it by |n\u27e9 , we get that \u27e8m| H ^ |n\u27e9= E m \u27e8m|n\u27e9. But if we multiply (11.71) by \u27e8m| , we get \u27e8m| H ^ |n\u27e9= E n \u27e8m|n\u27e9. Since the left sides of these two equations are equal, the right sides are, also: E m \u27e8m|n\u27e9= E n \u27e8m|n\u27e9. (11.79) If E m = E n the equation does not tell us anything. But if the energies of the two states |m\u27e9 and |n\u27e9 are different ( E m \u2260 E n ), Eq. (11.79) says that \u27e8m|n\u27e9 must be zero, as we wanted to prove. The two states are necessarily orthogonal so long as E n and E m are numerically different."
    },
    {
        "input": "Optics: The Principle of Least Time",
        "output": "This is the first of a number of chapters on the subject of electromagnetic radiation. Light, with which we see, is only one small part of a vast spectrum of the same kind of thing, the various parts of this spectrum being distinguished by different values of a certain quantity which varies. This variable quantity could be called the \u201cwavelength.\u201d As it varies in the visible spectrum, the light apparently changes color from red to violet. If we explore the spectrum systematically, from long wavelengths toward shorter ones, we would begin with what are usually called radiowaves. Radiowaves are technically available in a wide range of wavelengths, some even longer than those used in regular broadcasts; regular broadcasts have wavelengths corresponding to about 500 meters. Then there are the so-called \u201cshort waves,\u201d i.e., radar waves, millimeter waves, and so on. There are no actual boundaries between one range of wavelengths and another, because nature did not present us with sharp edges. The number associated with a given name for the waves are only approximate and, of course, so are the names we give to the different ranges. Then, a long way down through the millimeter waves, we come to what we call the infrared, and thence to the visible spectrum. Then going in the other direction, we get into a region which is called the ultraviolet. Where the ultraviolet stops, the x-rays begin, but we cannot define precisely where this is; it is roughly at 10 \u22128 m, or 10 \u22122 \u03bc m. These are \u201csoft\u201d x-rays; then there are ordinary x-rays and very hard x-rays; then \u03b3 -rays, and so on, for smaller and smaller values of this dimension called the wavelength. Within this vast range of wavelengths, there are three or more regions of approximation which are especially interesting. In one of these, a condition exists in which the wavelengths involved are very small compared with the dimensions of the equipment available for their study; furthermore, the photon energies, using the quantum theory, are small compared with the energy sensitivity of the equipment. Under these conditions we can make a rough first approximation by a method called geometrical optics. If, on the other hand, the wavelengths are comparable to the dimensions of the equipment, which is difficult to arrange with visible light but easier with radiowaves, and if the photon energies are still negligibly small, then a very useful approximation can be made by studying the behavior of the waves, still disregarding the quantum mechanics. This method is based on the classical theory of electromagnetic radiation, which will be discussed in a later chapter. Next, if we go to very short wavelengths, where we can disregard the wave character but the photons have a very large energy compared with the sensitivity of our equipment, things get simple again. This is the simple photon picture, which we will describe only very roughly. The complete picture, which unifies the whole thing into one model, will not be available to us for a long time. In this chapter our discussion is limited to the geometrical optics region, in which we forget about the wavelength and the photon character of the light, which will all be explained in due time. We do not even bother to say what the light is, but just find out how it behaves on a large scale compared with the dimensions of interest. All this must be said in order to emphasize the fact that what we are going to talk about is only a very crude approximation; this is one of the chapters that we shall have to \u201cunlearn\u201d again. But we shall very quickly unlearn it, because we shall almost immediately go on to a more accurate method. Although geometrical optics is just an approximation, it is of very great importance technically and of great interest historically. We shall present this subject more historically than some of the others in order to give some idea of the development of a physical theory or physical idea. First, light is, of course, familiar to everybody, and has been familiar since time immemorial. Now one problem is, by what process do we see light? There have been many theories, but it finally settled down to one, which is that there is something which enters the eye\u2014which bounces off objects into the eye. We have heard that idea so long that we accept it, and it is almost impossible for us to realize that very intelligent men have proposed contrary theories\u2014that something comes out of the eye and feels for the object, for example. Some other important observations are that, as light goes from one place to another, it goes in straight lines, if there is nothing in the way, and that the rays do not seem to interfere with one another. That is, light is crisscrossing in all directions in the room, but the light that is passing across our line of vision does not affect the light that comes to us from some object. This was once a most powerful argument against the corpuscular theory; it was used by Huygens. If light were like a lot of arrows shooting along, how could other arrows go through them so easily? Such philosophical arguments are not of much weight. One could always say that light is made up of arrows which go through each other! The discussion above gives enough of the basic idea of geometrical optics\u2014now we have to go a little further into the quantitative features. Thus far we have light going only in straight lines between two points; now let us study the behavior of light when it hits various materials. The simplest object is a mirror, and the law for a mirror is that when the light hits the mirror, it does not continue in a straight line, but bounces off the mirror into a new straight line, which changes when we change the inclination of the mirror. The question for the ancients was, what is the relation between the two angles involved? This is a very simple relation, discovered long ago. The light striking a mirror travels in such a way that the two angles, between each beam and the mirror, are equal. For some reason it is customary to measure the angles from the normal to the mirror surface. Thus the so-called law of reflection is \u03b8 i = \u03b8 r . (26.1) That is a simple enough proposition, but a more difficult problem is encountered when light goes from one medium into another, for example from air into water; here also, we see that it does not go in a straight line. In the water the ray is at an inclination to its path in the air; if we change the angle \u03b8 i so that it comes down more nearly vertically, then the angle of \u201cbreakage\u201d is not as great. But if we tilt the beam of light at quite an angle, then the deviation angle is very large. The question is, what is the relation of one angle to the other? This also puzzled the ancients for a long time, and here they never found the answer! It is, however, one of the few places in all of Greek physics that one may find any experimental results listed. Claudius Ptolemy made a list of the angle in water for each of a number of different angles in air. Table 26\u20131 shows the angles in the air, in degrees, and the corresponding angle as measured in the water. (Ordinarily it is said that Greek scientists never did any experiments. But it would be impossible to obtain this table of values without knowing the right law, except by experiment. It should be noted, however, that these do not represent independent careful measurements for each angle but only some numbers interpolated from a few measurements, for they all fit perfectly on a parabola.) This, then, is one of the important steps in the development of physical law: first we observe an effect, then we measure it and list it in a table; then we try to find the rule by which one thing can be connected with another. The above numerical table was made in 140 a.d., but it was not until 1621 that someone finally found the rule connecting the two angles! The rule, found by Willebrord Snell, a Dutch mathematician, is as follows: if \u03b8 i is the angle in air and \u03b8 r is the angle in the water, then it turns out that the sine of \u03b8 i is equal to some constant multiple of the sine of \u03b8 r : sin \u03b8 i =nsin \u03b8 r . (26.2) For water the number n is approximately 1.33 . Equation (26.2) is called Snell\u2019s law; it permits us to predict how the light is going to bend when it goes from air into water. Table 26\u20132 shows the angles in air and in water according to Snell\u2019s law. Note the remarkable agreement with Ptolemy\u2019s list. Now in the further development of science, we want more than just a formula. First we have an observation, then we have numbers that we measure, then we have a law which summarizes all the numbers. But the real glory of science is that we can find a way of thinking such that the law is evident. The first way of thinking that made the law about the behavior of light evident was discovered by Fermat in about 1650, and it is called the principle of least time, or Fermat\u2019s principle. His idea is this: that out of all possible paths that it might take to get from one point to another, light takes the path which requires the shortest time. Let us first show that this is true for the case of the mirror, that this simple principle contains both the law of straight-line propagation and the law for the mirror. So, we are growing in our understanding! Let us try to find the solution to the following problem. In Fig. 26\u20133 are shown two points, A and B , and a plane mirror, M M \u2032 . What is the way to get from A to B in the shortest time? The answer is to go straight from A to B ! But if we add the extra rule that the light has to strike the mirror and come back in the shortest time, the answer is not so easy. One way would be to go as quickly as possible to the mirror and then go to B , on the path ADB . Of course, we then have a long path DB . If we move over a little to the right, to E , we slightly increase the first distance, but we greatly decrease the second one, and so the total path length, and therefore the travel time, is less. How can we find the point C for which the time is the shortest? We can find it very nicely by a geometrical trick. We construct on the other side of M M \u2032 an artificial point B \u2032 , which is the same distance below the plane M M \u2032 as the point B is above the plane. Then we draw the line E B \u2032 . Now because BFM is a right angle and BF=F B \u2032 , EB is equal to E B \u2032 . Therefore the sum of the two distances, AE+EB , which is proportional to the time it will take if the light travels with constant velocity, is also the sum of the two lengths AE+E B \u2032 . Therefore the problem becomes, when is the sum of these two lengths the least? The answer is easy: when the line goes through point C as a straight line from A to B \u2032 ! In other words, we have to find the point where we go toward the artificial point, and that will be the correct one. Now if AC B \u2032 is a straight line, then angle BCF is equal to angle B \u2032 CF and thence to angle ACM . Thus the statement that the angle of incidence equals the angle of reflection is equivalent to the statement that the light goes to the mirror in such a way that it comes back to the point B in the least possible time. Originally, the statement was made by Hero of Alexandria that the light travels in such a way that it goes to the mirror and to the other point in the shortest possible distance, so it is not a modern theory. It was this that inspired Fermat to suggest to himself that perhaps refraction operated on a similar basis. But for refraction, light obviously does not use the path of shortest distance, so Fermat tried the idea that it takes the shortest time. Before we go on to analyze refraction, we should make one more remark about the mirror. If we have a source of light at the point B and it sends light toward the mirror, then we see that the light which goes to A from the point B comes to A in exactly the same manner as it would have come to A if there were an object at B \u2032 , and no mirror. Now of course the eye detects only the light which enters it physically, so if we have an object at B and a mirror which makes the light come into the eye in exactly the same manner as it would have come into the eye if the object were at B \u2032 , then the eye-brain system interprets that, assuming it does not know too much, as being an object at B \u2032 . So the illusion that there is an object behind the mirror is merely due to the fact that the light which is entering the eye is entering in exactly the same manner, physically, as it would have entered had there been an object back there (except for the dirt on the mirror, and our knowledge of the existence of the mirror, and so on, which is corrected in the brain). Now let us demonstrate that the principle of least time will give Snell\u2019s law of refraction. We must, however, make an assumption about the speed of light in water. We shall assume that the speed of light in water is lower than the speed of light in air by a certain factor, n . In Fig. 26\u20134, our problem is again to go from A to B in the shortest time. To illustrate that the best thing to do is not just to go in a straight line, let us imagine that a beautiful girl has fallen out of a boat, and she is screaming for help in the water at point B . The line marked x is the shoreline. We are at point A on land, and we see the accident, and we can run and can also swim. But we can run faster than we can swim. What do we do? Do we go in a straight line? (Yes, no doubt!) However, by using a little more intelligence we would realize that it would be advantageous to travel a little greater distance on land in order to decrease the distance in the water, because we go so much slower in the water. (Following this line of reasoning out, we would say the right thing to do is to compute very carefully what should be done!) At any rate, let us try to show that the final solution to the problem is the path ACB , and that this path takes the shortest time of all possible ones. If it is the shortest path, that means that if we take any other, it will be longer. So, if we were to plot the time it takes against the position of point X , we would get a curve something like that shown in Fig. 26\u20135, where point C corresponds to the shortest of all possible times. This means that if we move the point X to points near C , in the first approximation there is essentially no change in time because the slope is zero at the bottom of the curve. So our way of finding the law will be to consider that we move the place by a very small amount, and to demand that there be essentially no change in time. (Of course there is an infinitesimal change of a second order; we ought to have a positive increase for displacements in either direction from C .) So we consider a nearby point X and we calculate how long it would take to go from A to B by the two paths, and compare the new path with the old path. It is very easy to do. We want the difference, of course, to be nearly zero if the distance XC is short. First, look at the path on land. If we draw a perpendicular XE , we see that this path is shortened by the amount EC . Let us say we gain by not having to go that extra distance. On the other hand, in the water, by drawing a corresponding perpendicular, CF , we find that we have to go the extra distance XF , and that is what we lose. Or, in time, we gain the time it would have taken to go the distance EC , but we lose the time it would have taken to go the distance XF . Those times must be equal since, in the first approximation, there is to be no change in time. But supposing that in the water the speed is 1/n times as fast as in air, then we must have EC=n\u22c5XF. (26.3) Therefore we see that when we have the right point, XCsinEXC=n\u22c5XCsinXCF or, cancelling the common hypotenuse length XC and noting that EXC=ECN= \u03b8 i and XCF\u2248BC N \u2032 = \u03b8 r (when X is near C), we have sin \u03b8 i =nsin \u03b8 r . (26.4) So we see that to get from one point to another in the least time when the ratio of speeds is n , the light should enter at such an angle that the ratio of the sines of the angles \u03b8 i and \u03b8 r is the ratio of the speeds in the two media. Now let us consider some of the interesting consequences of the principle of least time. First is the principle of reciprocity. If to go from A to B we have found the path of the least time, then to go in the opposite direction (assuming that light goes at the same speed in any direction), the shortest time will be the same path, and therefore, if light can be sent one way, it can be sent the other way. An example of interest is a glass block with plane parallel faces, set at an angle to a light beam. Light, in going through the block from a point A to a point B (Fig. 26\u20136) does not go through in a straight line, but instead it decreases the time in the block by making the angle in the block less inclined, although it loses a little bit in the air. The beam is simply displaced parallel to itself because the angles in and out are the same. A third interesting phenomenon is the fact that when we see the sun setting, it is already below the horizon! It does not look as though it is below the horizon, but it is (Fig. 26\u20137). The earth\u2019s atmosphere is thin at the top and dense at the bottom. Light travels more slowly in air than it does in a vacuum, and so the light of the sun can get to point S beyond the horizon more quickly if, instead of just going in a straight line, it avoids the dense regions where it goes slowly by getting through them at a steeper tilt. When it appears to go below the horizon, it is actually already well below the horizon. Another example of this phenomenon is the mirage that one often sees while driving on hot roads. One sees \u201cwater\u201d on the road, but when he gets there, it is as dry as the desert! The phenomenon is the following. What we are really seeing is the sky light \u201creflected\u201d on the road: light from the sky, heading for the road, can end up in the eye, as shown in Fig. 26\u20138. Why? The air is very hot just above the road but it is cooler up higher. Hotter air is more expanded than cooler air and is thinner, and this decreases the speed of light less. That is to say, light goes faster in the hot region than in the cool region. Therefore, instead of the light deciding to come in the straightforward way, it also has a least-time path by which it goes into the region where it goes faster for awhile, in order to save time. So, it can go in a curve. As another important example of the principle of least time, suppose that we would like to arrange a situation where we have all the light that comes out of one point, P , collected back together at another point, P \u2032 (Fig. 26\u20139). That means, of course, that the light can go in a straight line from P to P \u2032 . That is all right. But how can we arrange that not only does it go straight, but also so that the light starting out from P toward Q also ends up at P \u2032 ? We want to bring all the light back to what we call a focus. How? If the light always takes the path of least time, then certainly it should not want to go over all these other paths. The only way that the light can be perfectly satisfied to take several adjacent paths is to make those times exactly equal! Otherwise, it would select the one of least time. Therefore the problem of making a focusing system is merely to arrange a device so that it takes the same time for the light to go on all the different paths! This is easy to do. Suppose that we had a piece of glass in which light goes slower than it does in the air (Fig. 26\u201310). Now consider a ray which goes in air in the path PQ P \u2032 . That is a longer path than from P directly to P \u2032 and no doubt takes a longer time. But if we were to insert a piece of glass of just the right thickness (we shall later figure out how thick) it might exactly compensate the excess time that it would take the light to go at an angle! In those circumstances we can arrange that the time the light takes to go straight through is the same as the time it takes to go in the path PQ P \u2032 . Likewise, if we take a ray PR R \u2032 P \u2032 which is partly inclined, it is not quite as long as PQ P \u2032 , and we do not have to compensate as much as for the straight one, but we do have to compensate somewhat. We end up with a piece of glass that looks like Fig. 26\u201310. With this shape, all the light which comes from P will go to P \u2032 . This, of course, is well known to us, and we call such a device a converging lens. In the next chapter we shall actually calculate what shape the lens has to have to make a perfect focus. Take another example: suppose we wish to arrange some mirrors so that the light from P always goes to P \u2032 (Fig. 26\u201311). On any path, it goes to some mirror and comes back, and all times must be equal. Here the light always travels in air, so the time and the distance are proportional. Therefore the statement that all the times are the same is the same as the statement that the total distance is the same. Thus the sum of the two distances r 1 and r 2 must be a constant. An ellipse is that curve which has the property that the sum of the distances from two points is a constant for every point on the ellipse; thus we can be sure that the light from one focus will come to the other. The same principle works for gathering the light of a star. The great 200 -inch Palomar telescope is built on the following principle. Imagine a star billions of miles away; we would like to cause all the light that comes in to come to a focus. Of course we cannot draw the rays that go all the way up to the star, but we still want to check whether the times are equal. Of course we know that when the various rays have arrived at some plane K K \u2032 , perpendicular to the rays, all the times in this plane are equal (Fig. 26\u201312). The rays must then come down to the mirror and proceed toward P \u2032 in equal times. That is, we must find a curve which has the property that the sum of the distances X X \u2032 + X \u2032 P \u2032 is a constant, no matter where X is chosen. An easy way to find it is to extend the length of the line X X \u2032 down to a plane L L \u2032 . Now if we arrange our curve so that A \u2032 A \u2032\u2032 = A \u2032 P \u2032 , B \u2032 B \u2032\u2032 = B \u2032 P \u2032 , C \u2032 C \u2032\u2032 = C \u2032 P \u2032 , and so on, we will have our curve, because then of course, A A \u2032 + A \u2032 P \u2032 =A A \u2032 + A \u2032 A \u2032\u2032 will be constant. Thus our curve is the locus of all points equidistant from a line and a point. Such a curve is called a parabola; the mirror is made in the shape of a parabola. The above examples illustrate the principle upon which such optical devices can be designed. The exact curves can be calculated using the principle that, to focus perfectly, the travel times must be exactly equal for all light rays, as well as being less than for any other nearby path. We shall discuss these focusing optical devices further in the next chapter; let us now discuss the further development of the theory. When a new theoretical principle is developed, such as the principle of least time, our first inclination might be to say, \u201cWell, that is very pretty; it is delightful; but the question is, does it help at all in understanding the physics?\u201d Someone may say, \u201cYes, look at how many things we can now understand!\u201d Another says, \u201cVery well, but I can understand mirrors, too. I need a curve such that every tangent plane makes equal angles with the two rays. I can figure out a lens, too, because every ray that comes to it is bent through an angle given by Snell\u2019s law.\u201d Evidently the statement of least time and the statement that angles are equal on reflection, and that the sines of the angles are proportional on refraction, are the same. So is it merely a philosophical question, or one of beauty? There can be arguments on both sides. However, the importance of a powerful principle is that it predicts new things. It is easy to show that there are a number of new things predicted by Fermat\u2019s principle. First, suppose that there are three media, glass, water, and air, and we perform a refraction experiment and measure the index n for one medium against another. Let us call n 12 the index of air ( 1 ) against water ( 2 ); n 13 the index of air ( 1 ) against glass ( 3 ). If we measured water against glass, we should find another index, which we shall call n 23 . But there is no a priori reason why there should be any connection between n 12 , n 13 , and n 23 . On the other hand, according to the idea of least time, there is a definite relationship. The index n 12 is the ratio of two things, the speed in air to the speed in water; n 13 is the ratio of the speed in air to the speed in glass; n 23 is the ratio of the speed in water to the speed in glass. Therefore we cancel out the air, and get n 23 = v 2 v 3 = v 1 / v 3 v 1 / v 2 = n 13 n 12 . (26.5) In other words, we predict that the index for a new pair of materials can be obtained from the indexes of the individual materials, both against air or against vacuum. So if we measure the speed of light in all materials, and from this get a single number for each material, namely its index relative to vacuum, called n i ( n 1 is the speed in vacuum relative to the speed in air, etc.), then our formula is easy. The index for any two materials i and j is n ij = v i v j = n j n i . (26.6) Using only Snell\u2019s law, there is no basis for a prediction of this kind.1 But of course this prediction works. The relation (26.5) was known very early, and was a very strong argument for the principle of least time. Another argument for the principle of least time, another prediction, is that if we measure the speed of light in water, it will be lower than in air. This is a prediction of a completely different type. It is a brilliant prediction, because all we have so far measured are angles; here we have a theoretical prediction which is quite different from the observations from which Fermat deduced the idea of least time. It turns out, in fact, that the speed in water is slower than the speed in air, by just the proportion that is needed to get the right index! Actually, we must make the statement of the principle of least time a little more accurately. It was not stated correctly above. It is incorrectly called the principle of least time and we have gone along with the incorrect description for convenience, but we must now see what the correct statement is. Suppose we had a mirror as in Fig. 26\u20133. What makes the light think it has to go to the mirror? The path of least time is clearly AB . So some people might say, \u201cSometimes it is a maximum time.\u201d It is not a maximum time, because certainly a curved path would take a still longer time! The correct statement is the following: a ray going in a certain particular path has the property that if we make a small change (say a one percent shift) in the ray in any manner whatever, say in the location at which it comes to the mirror, or the shape of the curve, or anything, there will be no first-order change in the time; there will be only a second-order change in the time. In other words, the principle is that light takes a path such that there are many other paths nearby which take almost exactly the same time. The following is another difficulty with the principle of least time, and one which people who do not like this kind of a theory could never stomach. With Snell\u2019s theory we can \u201cunderstand\u201d light. Light goes along, it sees a surface, it bends because it does something at the surface. The idea of causality, that it goes from one point to another, and another, and so on, is easy to understand. But the principle of least time is a completely different philosophical principle about the way nature works. Instead of saying it is a causal thing, that when we do one thing, something else happens, and so on, it says this: we set up the situation, and light decides which is the shortest time, or the extreme one, and chooses that path. But what does it do, how does it find out? Does it smell the nearby paths, and check them against each other? The answer is, yes, it does, in a way. That is the feature which is, of course, not known in geometrical optics, and which is involved in the idea of wavelength; the wavelength tells us approximately how far away the light must \u201csmell\u201d the path in order to check it. It is hard to demonstrate this fact on a large scale with light, because the wavelengths are so terribly short. But with radiowaves, say 3 -cm waves, the distances over which the radiowaves are checking are larger. If we have a source of radiowaves, a detector, and a slit, as in Fig. 26\u201313, the rays of course go from S to D because it is a straight line, and if we close down the slit it is all right\u2014they still go. But now if we move the detector aside to D \u2032 , the waves will not go through the wide slit from S to D \u2032 , because they check several paths nearby, and say, \u201cNo, my friend, those all correspond to different times.\u201d On the other hand, if we prevent the radiation from checking the paths by closing the slit down to a very narrow crack, then there is but one path available, and the radiation takes it! With a narrow slit, more radiation reaches D \u2032 than reaches it with a wide slit! One can do the same thing with light, but it is hard to demonstrate on a large scale. The effect can be seen under the following simple conditions. Find a small, bright light, say an unfrosted bulb in a street light far away or the reflection of the sun in a curved automobile bumper. Then put two fingers in front of one eye, so as to look through the crack, and squeeze the light to zero very gently. You will see that the image of the light, which was a little dot before, becomes quite elongated, and even stretches into a long line. The reason is that the fingers are very close together, and the light which is supposed to come in a straight line is spread out at an angle, so that when it comes into the eye it comes in from several directions. Also you will notice, if you are very careful, side maxima, a lot of fringes along the edges too. Furthermore, the whole thing is colored. All of this will be explained in due time, but for the present it is a demonstration that light does not always go in straight lines, and it is one that is very easily performed. Finally, we give a very crude view of what actually happens, how the whole thing really works, from what we now believe is the correct, quantum-dynamically accurate viewpoint, but of course only qualitatively described. In following the light from A to B in Fig. 26\u20133, we find that the light does not seem to be in the form of waves at all. Instead the rays seem to be made up of photons, and they actually produce clicks in a photon counter, if we are using one. The brightness of the light is proportional to the average number of photons that come in per second, and what we calculate is the chance that a photon gets from A to B , say by hitting the mirror. The law for that chance is the following very strange one. Take any path and find the time for that path; then make a complex number, or draw a little complex vector, \u03c1 e i\u03b8 , whose angle \u03b8 is proportional to the time. The number of turns per second is the frequency of the light. Now take another path; it has, for instance, a different time, so the vector for it is turned through a different angle\u2014the angle being always proportional to the time. Take all the available paths and add on a little vector for each one; then the answer is that the chance of arrival of the photon is proportional to the square of the length of the final vector, from the beginning to the end! Now let us show how this implies the principle of least time for a mirror. We consider all rays, all possible paths ADB , AEB , ACB , etc., in Fig. 26\u20133. The path ADB makes a certain small contribution, but the next path, AEB , takes a quite different time, so its angle \u03b8 is quite different. Let us say that point C corresponds to minimum time, where if we change the paths the times do not change. So for awhile the times do change, and then they begin to change less and less as we get near point C (Fig. 26\u201314). So the arrows which we have to add are coming almost exactly at the same angle for awhile near C , and then gradually the time begins to increase again, and the phases go around the other way, and so on. Eventually, we have quite a tight knot. The total probability is the distance from one end to the other, squared. Almost all of that accumulated probability occurs in the region where all the arrows are in the same direction (or in the same phase). All the contributions from the paths which have very different times as we change the path, cancel themselves out by pointing in different directions. That is why, if we hide the extreme parts of the mirror, it still reflects almost exactly the same, because all we did was to take out a piece of the diagram inside the spiral ends, and that makes only a very small change in the light. So this is the relationship between the ultimate picture of photons with a probability of arrival depending on an accumulation of arrows, and the principle of least time."
    },
    {
        "input": "Newtons Laws of Dynamics",
        "output": "The discovery of the laws of dynamics, or the laws of motion, was a dramatic moment in the history of science. Before Newton\u2019s time, the motions of things like the planets were a mystery, but after Newton there was complete understanding. Even the slight deviations from Kepler\u2019s laws, due to the perturbations of the planets, were computable. The motions of pendulums, oscillators with springs and weights in them, and so on, could all be analyzed completely after Newton\u2019s laws were enunciated. So it is with this chapter: before this chapter we could not calculate how a mass on a spring would move; much less could we calculate the perturbations on the planet Uranus due to Jupiter and Saturn. After this chapter we will be able to compute not only the motion of the oscillating mass, but also the perturbations on the planet Uranus produced by Jupiter and Saturn! Galileo made a great advance in the understanding of motion when he discovered the principle of inertia: if an object is left alone, is not disturbed, it continues to move with a constant velocity in a straight line if it was originally moving, or it continues to stand still if it was just standing still. Of course this never appears to be the case in nature, for if we slide a block across a table it stops, but that is because it is not left to itself\u2014it is rubbing against the table. It required a certain imagination to find the right rule, and that imagination was supplied by Galileo. Of course, the next thing which is needed is a rule for finding how an object changes its speed if something is affecting it. That is, the contribution of Newton. Newton wrote down three laws: The First Law was a mere restatement of the Galilean principle of inertia just described. The Second Law gave a specific way of determining how the velocity changes under different influences called forces. The Third Law describes the forces to some extent, and we shall discuss that at another time. Here we shall discuss only the Second Law, which asserts that the motion of an object is changed by forces in this way: the time-rate-of-change of a quantity called momentum is proportional to the force. We shall state this mathematically shortly, but let us first explain the idea. Momentum is not the same as velocity. A lot of words are used in physics, and they all have precise meanings in physics, although they may not have such precise meanings in everyday language. Momentum is an example, and we must define it precisely. If we exert a certain push with our arms on an object that is light, it moves easily; if we push just as hard on another object that is much heavier in the usual sense, then it moves much less rapidly. Actually, we must change the words from \u201clight\u201d and \u201cheavy\u201d to less massive and more massive, because there is a difference to be understood between the weight of an object and its inertia. (How hard it is to get it going is one thing, and how much it weighs is something else.) Weight and inertia are proportional, and on the earth\u2019s surface are often taken to be numerically equal, which causes a certain confusion to the student. On Mars, weights would be different but the amount of force needed to overcome inertia would be the same. We use the term mass as a quantitative measure of inertia, and we may measure mass, for example, by swinging an object in a circle at a certain speed and measuring how much force we need to keep it in the circle. In this way we find a certain quantity of mass for every object. Now the momentum of an object is a product of two parts: its mass and its velocity. Thus Newton\u2019s Second Law may be written mathematically this way: F= d dt (mv). Now there are several points to be considered. In writing down any law such as this, we use many intuitive ideas, implications, and assumptions which are at first combined approximately into our \u201claw.\u201d Later we may have to come back and study in greater detail exactly what each term means, but if we try to do this too soon we shall get confused. Thus at the beginning we take several things for granted. First, that the mass of an object is constant; it isn\u2019t really, but we shall start out with the Newtonian approximation that mass is constant, the same all the time, and that, further, when we put two objects together, their masses add. These ideas were of course implied by Newton when he wrote his equation, for otherwise it is meaningless. For example, suppose the mass varied inversely as the velocity; then the momentum would never change in any circumstance, so the law means nothing unless you know how the mass changes with velocity. At first we say, it does not change. Then there are some implications concerning force. As a rough approximation we think of force as a kind of push or pull that we make with our muscles, but we can define it more accurately now that we have this law of motion. The most important thing to realize is that this relationship involves not only changes in the magnitude of the momentum or of the velocity but also in their direction. If the mass is constant, then Eq. (9.1) can also be written as F=m dv dt =ma. The acceleration a is the rate of change of the velocity, and Newton\u2019s Second Law says more than that the effect of a given force varies inversely as the mass; it says also that the direction of the change in the velocity and the direction of the force are the same. Thus we must understand that a change in a velocity, or an acceleration, has a wider meaning than in common language: The velocity of a moving object can change by its speeding up, slowing down (when it slows down, we say it accelerates with a negative acceleration), or changing its direction of motion. An acceleration at right angles to the velocity was discussed in Chapter 7. There we saw that an object moving in a circle of radius R with a certain speed v along the circle falls away from a straightline path by a distance equal to 1 2 (v2/R)t2 if t is very small. Thus the formula for acceleration at right angles to the motion is a=v2/R, and a force at right angles to the velocity will cause an object to move in a curved path whose radius of curvature can be found by dividing the force by the mass to get the acceleration, and then using (9.3). In order to make our language more precise, we shall make one further definition in our use of the words speed and velocity. Ordinarily we think of speed and velocity as being the same, and in ordinary language they are the same. But in physics we have taken advantage of the fact that there are two words and have chosen to use them to distinguish two ideas. We carefully distinguish velocity, which has both magnitude and direction, from speed, which we choose to mean the magnitude of the velocity, but which does not include the direction. We can formulate this more precisely by describing how the x -, y -, and z -coordinates of an object change with time. Suppose, for example, that at a certain instant an object is moving as shown in Fig. 9\u20131. In a given small interval of time \u0394t it will move a certain distance \u0394x in the x -direction, \u0394y in the y -direction, and \u0394z in the z -direction. The total effect of these three coordinate changes is a displacement \u0394s along the diagonal of a parallelepiped whose sides are \u0394x , \u0394y , and \u0394z . In terms of the velocity, the displacement \u0394x is the x -component of the velocity times \u0394t , and similarly for \u0394y and \u0394z : \u0394x =vx\u0394t, \u0394y =vy\u0394t, \u0394z =vz\u0394t. In Eq. (9.4) we have resolved the velocity into components by telling how fast the object is moving in the x -direction, the y -direction, and the z -direction. The velocity is completely specified, both as to magnitude and direction, if we give the numerical values of its three rectangular components: vx =dx/dt, vy =dy/dt, vz =dz/dt. On the other hand, the speed of the object is ds/dt=|v|= \u221a v 2 x +v 2 y +v 2 z . Next, suppose that, because of the action of a force, the velocity changes to some other direction and a different magnitude, as shown in Fig. 9\u20132. We can analyze this apparently complex situation rather simply if we evaluate the changes in the x -, y -, and z -components of velocity. The change in the component of the velocity in the x -direction in a time \u0394t is \u0394vx=ax\u0394t , where ax is what we call the x -component of the acceleration. Similarly, we see that \u0394vy=ay\u0394t and \u0394vz=az\u0394t . In these terms, we see that Newton\u2019s Second Law, in saying that the force is in the same direction as the acceleration, is really three laws, in the sense that the component of the force in the x -, y -, or z -direction is equal to the mass times the rate of change of the corresponding component of velocity: Fx =m(dvx /dt)=m(d2x /dt2)=max , Fy =m(dvy /dt)=m(d2y /dt2)=may , Fz =m(dvz /dt)=m(d2z /dt2)=maz . Just as the velocity and acceleration have been resolved into components by projecting a line segment representing the quantity, and its direction onto three coordinate axes, so, in the same way, a force in a given direction is represented by certain components in the x -, y -, and z -directions: Fx =Fcos(x ,F), Fy =Fcos(y ,F), Fz =Fcos(z ,F), where F is the magnitude of the force and (x,F) represents the angle between the x -axis and the direction of F , etc. Newton\u2019s Second Law is given in complete form in Eq. (9.7). If we know the forces on an object and resolve them into x -, y -, and z -components, then we can find the motion of the object from these equations. Let us consider a simple example. Suppose there are no forces in the y - and z -directions, the only force being in the x -direction, say vertically. Equation (9.7) tells us that there would be changes in the velocity in the vertical direction, but no changes in the horizontal direction. This was demonstrated with a special apparatus in Chapter 7 (see Fig. 7\u20133). A falling body moves horizontally without any change in horizontal motion, while it moves vertically the same way as it would move if the horizontal motion were zero. In other words, motions in the x -, y -, and z -directions are independent if the forces are not connected. In order to use Newton\u2019s laws, we have to have some formula for the force; these laws say pay attention to the forces. If an object is accelerating, some agency is at work; find it. Our program for the future of dynamics must be to find the laws for the force. Newton himself went on to give some examples. In the case of gravity he gave a specific formula for the force. In the case of other forces he gave some part of the information in his Third Law, which we will study in the next chapter, having to do with the equality of action and reaction. Extending our previous example, what are the forces on objects near the earth\u2019s surface? Near the earth\u2019s surface, the force in the vertical direction due to gravity is proportional to the mass of the object and is nearly independent of height for heights small compared with the earth\u2019s radius R : F= GmM/R2= mg , where g=GM/R2 is called the acceleration of gravity. Thus the law of gravity tells us that weight is proportional to mass; the force is in the vertical direction and is the mass times g . Again we find that the motion in the horizontal direction is at constant velocity. The interesting motion is in the vertical direction, and Newton\u2019s Second Law tells us mg=m(d2x/dt2). Cancelling the m \u2019s, we find that the acceleration in the x -direction is constant and equal to g . This is of course the well known law of free fall under gravity, which leads to the equations vx =v0 +gt, x =x0 +v0t+ 1 2 gt2. As another example, let us suppose that we have been able to build a gadget (Fig. 9\u20133) which applies a force proportional to the distance and directed oppositely\u2014a spring. If we forget about gravity, which is of course balanced out by the initial stretch of the spring, and talk only about excess forces, we see that if we pull the mass down, the spring pulls up, while if we push it up the spring pulls down. This machine has been designed carefully so that the force is greater, the more we pull it up, in exact proportion to the displacement from the balanced condition, and the force upward is similarly proportional to how far we pull down. If we watch the dynamics of this machine, we see a rather beautiful motion\u2014up, down, up, down, \u2026 The question is, will Newton\u2019s equations correctly describe this motion? Let us see whether we can exactly calculate how it moves with this periodic oscillation, by applying Newton\u2019s law (9.7). In the present instance, the equation is \u2212kx=m(dvx/dt). Here we have a situation where the velocity in the x -direction changes at a rate proportional to x . Nothing will be gained by retaining numerous constants, so we shall imagine either that the scale of time has changed or that there is an accident in the units, so that we happen to have k/m=1 . Thus we shall try to solve the equation dvx/dt=\u2212x. To proceed, we must know what vx is, but of course we know that the velocity is the rate of change of the position. Now let us try to analyze just what Eq. (9.12) means. Suppose that at a given time t the object has a certain velocity vx and position x . What is the velocity and what is the position at a slightly later time t+\u03f5 ? If we can answer this question our problem is solved, for then we can start with the given condition and compute how it changes for the first instant, the next instant, the next instant, and so on, and in this way we gradually evolve the motion. To be specific, let us suppose that at the time t=0 we are given that x=1 and vx=0 . Why does the object move at all? Because there is a force on it when it is at any position except x=0 . If x>0 , that force is upward. Therefore the velocity which is zero starts to change, because of the law of motion. Once it starts to build up some velocity the object starts to move up, and so on. Now at any time t , if \u03f5 is very small, we may express the position at time t+\u03f5 in terms of the position at time t and the velocity at time t to a very good approximation as x(t+\u03f5)=x(t)+\u03f5vx(t). The smaller the \u03f5 , the more accurate this expression is, but it is still usefully accurate even if \u03f5 is not vanishingly small. Now what about the velocity? In order to get the velocity later, the velocity at the time t+\u03f5 , we need to know how the velocity changes, the acceleration. And how are we going to find the acceleration? That is where the law of dynamics comes in. The law of dynamics tells us what the acceleration is. It says the acceleration is \u2212x . vx(t+\u03f5) =vx(t)+\u03f5ax(t) =vx(t)\u2212\u03f5x(t). Equation (9.14) is merely kinematics; it says that a velocity changes because of the presence of acceleration. But Eq. (9.15) is dynamics, because it relates the acceleration to the force; it says that at this particular time for this particular problem, you can replace the acceleration by \u2212x(t) . Therefore, if we know both the x and v at a given time, we know the acceleration, which tells us the new velocity, and we know the new position\u2014this is how the machinery works. The velocity changes a little bit because of the force, and the position changes a little bit because of the velocity. Now let us really solve the problem. Suppose that we take \u03f5=0.100 sec. After we do all the work if we find that this is not small enough we may have to go back and do it again with \u03f5=0.010 sec. Starting with our initial value x(0)=1.00 , what is x(0.1) ? It is the old position x(0) plus the velocity (which is zero) times 0.10 sec. Thus x(0.1) is still 1.00 because it has not yet started to move. But the new velocity at 0.10 sec will be the old velocity v(0)=0 plus \u03f5 times the acceleration. The acceleration is \u2212x(0)=\u22121.00 . Thus v(0.1)=0.00\u22120.10\u00d71.00=\u22120.10. Now at 0.20 sec x(0.2) =x(0.1)+\u03f5v(0.1) =1.00\u22120.10\u00d70.10=0.99 and v(0.2) =v(0.1)+\u03f5a(0.1) =\u22120.10\u22120.10\u00d71.00=\u22120.20. And so, on and on and on, we can calculate the rest of the motion, and that is just what we shall do. However, for practical purposes there are some little tricks by which we can increase the accuracy. If we continued this calculation as we have started it, we would find the motion only rather crudely because \u03f5=0.100 sec is rather crude, and we would have to go to a very small interval, say \u03f5=0.01 . Then to go through a reasonable total time interval would take a lot of cycles of computation. So we shall organize the work in a way that will increase the precision of our calculations, using the same coarse interval \u03f5=0.10 sec. This can be done if we make a subtle improvement in the technique of the analysis. Notice that the new position is the old position plus the time interval \u03f5 times the velocity. But the velocity when? The velocity at the beginning of the time interval is one velocity and the velocity at the end of the time interval is another velocity. Our improvement is to use the velocity halfway between. If we know the speed now, but the speed is changing, then we are not going to get the right answer by going at the same speed as now. We should use some speed between the \u201cnow\u201d speed and the \u201cthen\u201d speed at the end of the interval. The same considerations also apply to the velocity: to compute the velocity changes, we should use the acceleration midway between the two times at which the velocity is to be found. Thus the equations that we shall actually use will be something like this: the position later is equal to the position before plus \u03f5 times the velocity at the time in the middle of the interval. Similarly, the velocity at this halfway point is the velocity at a time \u03f5 before (which is in the middle of the previous interval) plus \u03f5 times the acceleration at the time t . That is, we use the equations x(t+\u03f5) v(t+\u03f5/2) a(t) =x(t)+\u03f5v(t+\u03f5/2), =v(t\u2212\u03f5/2)+\u03f5a(t), =\u2212x(t). (9.16) There remains only one slight problem: what is v(\u03f5/2) ? At the start, we are given v(0) , not v(\u2212\u03f5/2) . To get our calculation started, we shall use a special equation, namely, v(\u03f5/2)=v(0)+(\u03f5/2)a(0) . Now we are ready to carry through our calculation. For convenience, we may arrange the work in the form of a table, with columns for the time, the position, the velocity, and the acceleration, and the in-between lines for the velocity, as shown in Table 9\u20131. Such a table is, of course, just a convenient way of representing the numerical values obtained from the set of equations (9.16), and in fact the equations themselves need never be written. We just fill in the various spaces in the table one by one. This table now gives us a very good idea of the motion: it starts from rest, first picks up a little upward (negative) velocity and it loses some of its distance. The acceleration is then a little bit less but it is still gaining speed. But as it goes on it gains speed more and more slowly, until as it passes x=0 at about t=1.50 sec we can confidently predict that it will keep going, but now it will be on the other side; the position x will become negative, the acceleration therefore positive. Thus the speed decreases. It is interesting to compare these numbers with the function x=cost , which is done in Fig. 9\u20134. The agreement is within the three significant figure accuracy of our calculation! We shall see later that x=cost is the exact mathematical solution of our equation of motion, but it is an impressive illustration of the power of numerical analysis that such an easy calculation should give such precise results. The above analysis is very nice for the motion of an oscillating spring, but can we analyze the motion of a planet around the sun? Let us see whether we can arrive at an approximation to an ellipse for the orbit. We shall suppose that the sun is infinitely heavy, in the sense that we shall not include its motion. Suppose a planet starts at a certain place and is moving with a certain velocity; it goes around the sun in some curve, and we shall try to analyze, by Newton\u2019s laws of motion and his law of gravitation, what the curve is. How? At a given moment it is at some position in space. If the radial distance from the sun to this position is called r , then we know that there is a force directed inward which, according to the law of gravity, is equal to a constant times the product of the sun\u2019s mass and the planet\u2019s mass divided by the square of the distance. To analyze this further we must find out what acceleration will be produced by this force. We shall need the components of the acceleration along two directions, which we call x and y . Thus if we specify the position of the planet at a given moment by giving x and y (we shall suppose that z is always zero because there is no force in the z -direction and, if there is no initial velocity v z , there will be nothing to make z other than zero), the force is directed along the line joining the planet to the sun, as shown in Fig. 9\u20135. From this figure we see that the horizontal component of the force is related to the complete force in the same manner as the horizontal distance x is to the complete hypotenuse r , because the two triangles are similar. Also, if x is positive, F x is negative. That is, F x /|F|=\u2212x/r , or F x = \u2212|F|x/r= \u2212GMmx/ r 3 . Now we use the dynamical law to find that this force component is equal to the mass of the planet times the rate of change of its velocity in the x -direction. Thus we find the following laws: m(d v x /dt) m(d v y /dt) r =\u2212GMmx/ r 3 , =\u2212GMmy/ r 3 , = x 2 + y 2 \u2212 \u2212 \u2212 \u2212 \u2212 \u2212 \u221a . (9.17) This, then, is the set of equations we must solve. Again, in order to simplify the numerical work, we shall suppose that the unit of time, or the mass of the sun, has been so adjusted (or luck is with us) that GM\u22611 . For our specific example we shall suppose that the initial position of the planet is at x=0.500 and y=0.000 , and that the velocity is all in the y -direction at the start, and is of magnitude 1.630 . Now how do we make the calculation? We again make a table with columns for the time, the x -position, the x -velocity v x , and the x -acceleration a x ; then, separated by a double line, three columns for position, velocity, and acceleration in the y -direction. In order to get the accelerations we are going to need Eq. (9.17); it tells us that the acceleration in the x -direction is \u2212x/ r 3 , and the acceleration in the y -direction is \u2212y/ r 3 , and that r is the square root of x 2 + y 2 . Thus, given x and y , we must do a little calculating on the side, taking the square root of the sum of the squares to find r and then, to get ready to calculate the two accelerations, it is useful also to evaluate 1/ r 3 . This work can be done rather easily by using a table of squares, cubes, and reciprocals: then we need only multiply x by 1/ r 3 , which we do on a slide rule. Our calculation thus proceeds by the following steps, using time intervals \u03f5=0.100 : Initial values at t=0 : x(0) v x (0) =0.500 =0.000 y(0) v y (0) =0.000 =+1.630 From these we find: r(0) a x (0) =0.500 =\u22124.000 1/ r 3 (0) a y (0) =8.000 =0.000 Thus we may calculate the velocities v x (0.05) and v y (0.05) : v x (0.05) v y (0.05) =0.000\u22124.000\u00d70.050=\u22120.200; =1.630+0.000\u00d70.050=1.630. Now our main calculations begin: x(0.1) y(0.1) r(0.1) 1/ r 3 (0.1) a x (0.1) a y (0.1) v x (0.15) v y (0.15) x(0.2) y(0.2) =0.500\u22120.20\u00d70.1 =0.0+1.63\u00d70.1 = 0.480 2 + 0.163 2 \u2212 \u2212 \u2212 \u2212 \u2212 \u2212 \u2212 \u2212 \u2212 \u2212 \u2212 \u2212 \u221a =7.677 =\u22120.480\u00d77.677 =\u22120.163\u00d77.677 =\u22120.200\u22123.685\u00d70.1 =1.630\u22121.250\u00d70.1 =0.480\u22120.568\u00d70.1 =0.163+1.505\u00d70.1 etc. =0.480 =0.163 =0.507 =\u22123.685 =\u22121.250 =\u22120.568 =1.505 =0.423 =0.313 In this way we obtain the values given in Table 9\u20132, and in 20 steps or so we have chased the planet halfway around the sun! In Fig. 9\u20136 are plotted the x - and y -coordinates given in Table 9\u20132. The dots represent the positions at the succession of times a tenth of a unit apart; we see that at the start the planet moves rapidly and at the end it moves slowly, and so the shape of the curve is determined. Thus we see that we really do know how to calculate the motion of planets! Now let us see how we can calculate the motion of Neptune, Jupiter, Uranus, or any other planet. If we have a great many planets, and let the sun move too, can we do the same thing? Of course we can. We calculate the force on a particular planet, let us say planet number i , which has a position x i , y i , z i ( i=1 may represent the sun, i=2 Mercury, i=3 Venus, and so on). We must know the positions of all the planets. The force acting on one is due to all the other bodies which are located, let us say, at positions x j , y j , z j . Therefore the equations are m i d v ix dt m i d v iy dt m i d v iz dt = \u2211 j=1 N \u2212 G m i m j ( x i \u2212 x j ) r 3 ij , = \u2211 j=1 N \u2212 G m i m j ( y i \u2212 y j ) r 3 ij , = \u2211 j=1 N \u2212 G m i m j ( z i \u2212 z j ) r 3 ij . (9.18) Further, we define r ij as the distance between the two planets i and j ; this is equal to r ij = ( x i \u2212 x j ) 2 +( y i \u2212 y j ) 2 +( z i \u2212 z j ) 2 \u2212 \u2212 \u2212 \u2212 \u2212 \u2212 \u2212 \u2212 \u2212 \u2212 \u2212 \u2212 \u2212 \u2212 \u2212 \u2212 \u2212 \u2212 \u2212 \u2212 \u2212 \u2212 \u2212 \u2212 \u2212 \u2212 \u2212 \u221a . (9.19) Also, \u2211 means a sum over all values of j \u2014all other bodies\u2014except, of course, for j=i . Thus all we have to do is to make more columns, lots more columns. We need nine columns for the motions of Jupiter, nine for the motions of Saturn, and so on. Then when we have all initial positions and velocities we can calculate all the accelerations from Eq. (9.18) by first calculating all the distances, using Eq. (9.19). How long will it take to do it? If you do it at home, it will take a very long time! But in modern times we have machines which do arithmetic very rapidly; a very good computing machine may take 1 microsecond, that is, a millionth of a second, to do an addition. To do a multiplication takes longer, say 10 microseconds. It may be that in one cycle of calculation, depending on the problem, we may have 30 multiplications, or something like that, so one cycle will take 300 microseconds. That means that we can do 3000 cycles of computation per second. In order to get an accuracy, of, say, one part in a billion, we would need 4\u00d7 10 5 cycles to correspond to one revolution of a planet around the sun. That corresponds to a computation time of 130 seconds or about two minutes. Thus it takes only two minutes to follow Jupiter around the sun, with all the perturbations of all the planets correct to one part in a billion, by this method! (It turns out that the error varies about as the square of the interval \u03f5 . If we make the interval a thousand times smaller, it is a million times more accurate. So, let us make the interval 10,000 times smaller.) So, as we said, we began this chapter not knowing how to calculate even the motion of a mass on a spring. Now, armed with the tremendous power of Newton\u2019s laws, we can not only calculate such simple motions but also, given only a machine to handle the arithmetic, even the tremendously complex motions of the planets, to as high a degree of precision as we wish!"
    },
    {
        "input": "Work and Potential Energy (Conclusion)",
        "output": "In the preceding chapter we have presented a great many new ideas and results that play a central role in physics. These ideas are so important that it seems worthwhile to devote a whole chapter to a closer examination of them. In the present chapter we shall not repeat the \u201cproofs\u201d or the specific tricks by which the results were obtained, but shall concentrate instead upon a discussion of the ideas themselves. In learning any subject of a technical nature where mathematics plays a role, one is confronted with the task of understanding and storing away in the memory a huge body of facts and ideas, held together by certain relationships which can be \u201cproved\u201d or \u201cshown\u201d to exist between them. It is easy to confuse the proof itself with the relationship which it establishes. Clearly, the important thing to learn and to remember is the relationship, not the proof. In any particular circumstance we can either say \u201cit can be shown that\u201d such and such is true, or we can show it. In almost all cases, the particular proof that is used is concocted, first of all, in such form that it can be written quickly and easily on the chalkboard or on paper, and so that it will be as smooth-looking as possible. Consequently, the proof may look deceptively simple, when in fact, the author might have worked for hours trying different ways of calculating the same thing until he has found the neatest way, so as to be able to show that it can be shown in the shortest amount of time! The thing to be remembered, when seeing a proof, is not the proof itself, but rather that it can be shown that such and such is true. Of course, if the proof involves some mathematical procedures or \u201ctricks\u201d that one has not seen before, attention should be given not to the trick exactly, but to the mathematical idea involved. It is certain that in all the demonstrations that are made in a course such as this, not one has been remembered from the time when the author studied freshman physics. Quite the contrary: he merely remembers that such and such is true, and to explain how it can be shown he invents a demonstration at the moment it is needed. Anyone who has really learned a subject should be able to follow a similar procedure, but it is no use remembering the proofs. That is why, in this chapter, we shall avoid the proofs of the various statements made previously, and merely summarize the results. The first idea that has to be digested is work done by a force. The physical word \u201cwork\u201d is not the word in the ordinary sense of \u201cWorkers of the world unite!,\u201d but is a different idea. Physical work is expressed as \u222bF\u22c5ds , called \u201cthe line integral of F dot ds ,\u201d which means that if the force, for instance, is in one direction and the object on which the force is working is displaced in a certain direction, then only the component of force in the direction of the displacement does any work. If, for instance, the force were constant and the displacement were a finite distance \u0394s , then the work done in moving the object through that distance is only the component of force along \u0394s times \u0394s . The rule is \u201cforce times distance,\u201d but we really mean only the component of force in the direction of the displacement times \u0394s or, equivalently, the component of displacement in the direction of force times F . It is evident that no work whatsoever is done by a force which is at right angles to the displacement. Now if the vector displacement \u0394s is resolved into components, in other words, if the actual displacement is \u0394s and we want to consider it effectively as a component of displacement \u0394x in the x -direction, \u0394y in the y -direction, and \u0394z in the z -direction, then the work done in carrying an object from one place to another can be calculated in three parts, by calculating the work done along x , along y , and along z . The work done in going along x involves only that component of force, namely F x , and so on, so the work is F x \u0394x+ F y \u0394y+ F z \u0394z . When the force is not constant, and we have a complicated curved motion, then we must resolve the path into a lot of little \u0394s \u2019s, add the work done in carrying the object along each \u0394s , and take the limit as \u0394s goes to zero. This is the meaning of the \u201cline integral.\u201d Everything we have just said is contained in the formula W=\u222bF\u22c5ds . It is all very well to say that it is a marvelous formula, but it is another thing to understand what it means, or what some of the consequences are. The word \u201cwork\u201d in physics has a meaning so different from that of the word as it is used in ordinary circumstances that it must be observed carefully that there are some peculiar circumstances in which it appears not to be the same. For example, according to the physical definition of work, if one holds a hundred-pound weight off the ground for a while, he is doing no work. Nevertheless, everyone knows that he begins to sweat, shake, and breathe harder, as if he were running up a flight of stairs. Yet running upstairs is considered as doing work (in running downstairs, one gets work out of the world, according to physics), but in simply holding an object in a fixed position, no work is done. Clearly, the physical definition of work differs from the physiological definition, for reasons we shall briefly explore. It is a fact that when one holds a weight he has to do \u201cphysiological\u201d work. Why should he sweat? Why should he need to consume food to hold the weight up? Why is the machinery inside him operating at full throttle, just to hold the weight up? Actually, the weight could be held up with no effort by just placing it on a table; then the table, quietly and calmly, without any supply of energy, is able to maintain the same weight at the same height! The physiological situation is something like the following. There are two kinds of muscles in the human body and in other animals: one kind, called striated or skeletal muscle, is the type of muscle we have in our arms, for example, which is under voluntary control; the other kind, called smooth muscle, is like the muscle in the intestines or, in the clam, the greater adductor muscle that closes the shell. The smooth muscles work very slowly, but they can hold a \u201cset\u201d; that is to say, if the clam tries to close its shell in a certain position, it will hold that position, even if there is a very great force trying to change it. It will hold a position under load for hours and hours without getting tired because it is very much like a table holding up a weight, it \u201csets\u201d into a certain position, and the molecules just lock there temporarily with no work being done, no effort being generated by the clam. The fact that we have to generate effort to hold up a weight is simply due to the design of striated muscle. What happens is that when a nerve impulse reaches a muscle fiber, the fiber gives a little twitch and then relaxes, so that when we hold something up, enormous volleys of nerve impulses are coming in to the muscle, large numbers of twitches are maintaining the weight, while the other fibers relax. We can see this, of course: when we hold a heavy weight and get tired, we begin to shake. The reason is that the volleys are coming irregularly, and the muscle is tired and not reacting fast enough. Why such an inefficient scheme? We do not know exactly why, but evolution has not been able to develop fast smooth muscle. Smooth muscle would be much more effective for holding up weights because you could just stand there and it would lock in; there would be no work involved and no energy would be required. However, it has the disadvantage that it is very slow-operating. Returning now to physics, we may ask why we want to calculate the work done. The answer is that it is interesting and useful to do so, since the work done on a particle by the resultant of all the forces acting on it is exactly equal to the change in kinetic energy of that particle. That is, if an object is being pushed, it picks up speed, and \u0394( v 2 )= 2 m F\u22c5\u0394s. 2 Another interesting feature of forces and work is this: suppose that we have a sloping or a curved track, and a particle that must move along the track, but without friction. Or we may have a pendulum with a string and a weight; the string constrains the weight to move in a circle about the pivot point. The pivot point may be changed by having the string hit a peg, so that the path of the weight is along two circles of different radii. These are examples of what we call fixed, frictionless constraints. In motion with a fixed frictionless constraint, no work is done by the constraint because the forces of constraint are always at right angles to the motion. By the \u201cforces of constraint\u201d we mean those forces which are applied to the object directly by the constraint itself\u2014the contact force with the track, or the tension in the string. The forces involved in the motion of a particle on a slope moving under the influence of gravity are quite complicated, since there is a constraint force, a gravitational force, and so on. However, if we base our calculation of the motion on conservation of energy and the gravitational force alone, we get the right result. This seems rather strange, because it is not strictly the right way to do it\u2014we should use the resultant force. Nevertheless, the work done by the gravitational force alone will turn out to be the change in the kinetic energy, because the work done by the constraint part of the force is zero (Fig. 14\u20131). The important feature here is that if a force can be analyzed as the sum of two or more \u201cpieces\u201d then the work done by the resultant force in going along a certain curve is the sum of the works done by the various \u201ccomponent\u201d forces into which the force is analyzed. Thus if we analyze the force as being the vector sum of several effects, gravitational plus constraint forces, etc., or the x -component of all forces and the y -component of all forces, or any other way that we wish to split it up, then the work done by the net force is equal to the sum of the works done by all the parts into which we have divided the force in making the analysis. In nature there are certain forces, that of gravity, for example, which have a very remarkable property which we call \u201cconservative\u201d (no political ideas involved, it is again one of those \u201ccrazy words\u201d). If we calculate how much work is done by a force in moving an object from one point to another along some curved path, in general the work depends upon the curve, but in special cases it does not. If it does not depend upon the curve, we say that the force is a conservative force. In other words, if the integral of the force times the distance in going from position 1 to position 2 in Fig. 14\u20132 is calculated along curve A and then along B , we get the same number of joules, and if this is true for this pair of points on every curve, and if the same proposition works no matter which pair of points we use, then we say the force is conservative. In such circumstances, the work integral going from 1 to 2 can be evaluated in a simple manner, and we can give a formula for the result. Ordinarily it is not this easy, because we also have to specify the curve, but when we have a case where the work does not depend on the curve, then, of course, the work depends only upon the positions of 1 and 2 . To demonstrate this idea, consider the following. We take a \u201cstandard\u201d point P , at an arbitrary location (Fig. 14\u20132). Then, the work line-integral from 1 to 2 , which we want to calculate, can be evaluated as the work done in going from 1 to P plus the work done in going from P to 2 , because the forces are conservative and the work does not depend upon the curve. Now, the work done in going from position P to a particular position in space is a function of that position in space. Of course it really depends on P also, but we hold the arbitrary point P fixed permanently for the analysis. If that is done, then the work done in going from point P to point 2 is some function of the final position of 2 . It depends upon where 2 is; if we go to some other point we get a different answer. We shall call this function of position \u2212U(x,y,z) , and when we wish to refer to some particular point 2 whose coordinates are ( x 2 , y 2 , z 2 ) , we shall write U(2) , as an abbreviation for U( x 2 , y 2 , z 2 ) . The work done in going from point 1 to point P can be written also by going the other way along the integral, reversing all the ds \u2019s. That is, the work done in going from 1 to P is minus the work done in going from the point P to 1 : \u222b P 1 F\u22c5ds= \u222b 1 P F\u22c5(\u2212ds)=\u2212 \u222b 1 P F\u22c5ds. P 1 1 Thus the work done in going from P to 1 is \u2212U(1) , and from P to 2 the work is \u2212U(2) . Therefore the integral from 1 to 2 is equal to \u2212U(2) plus [ \u2212U(1) backwards], or +U(1)\u2212U(2) : U(1)=\u2212 \u222b 1 P F\u22c5ds,U(2)=\u2212 \u222b 2 P F\u22c5ds, \u222b 2 1 F\u22c5ds=U(1)\u2212U(2). (14.1) The quantity U(2)\u2212U(1) is called the change in the potential energy, and we call U the potential energy. We shall say that when the object is located at position 2 , it has potential energy U(2) and at position 1 it has potential energy U(1) . If it is located at position P , it has zero potential energy. If we had used any other point, say Q , instead of P , it would turn out (and we shall leave it to you to demonstrate) that the potential energy is changed only by the addition of a constant. Since the conservation of energy depends only upon changes, it does not matter if we add a constant to the potential energy. Thus the point P is arbitrary. Now, we have the following two propositions: (1) that the work done by a force is equal to the change in kinetic energy of the particle, but (2) mathematically, for a conservative force, the work done is minus the change in a function U which we call the potential energy. As a consequence of these two, we arrive at the proposition that if only conservative forces act, the kinetic energy T plus the potential energy U remains constant: T+U=constant. (14.2) Let us now discuss the formulas for the potential energy for a number of cases. If we have a gravitational field that is uniform, if we are not going to heights comparable with the radius of the earth, then the force is a constant vertical force and the work done is simply the force times the vertical distance. Thus U(z)=mgz, (14.3) and the point P which corresponds to zero potential energy happens to be any point in the plane z=0 . We could also have said that the potential energy is mg(z\u22126) if we had wanted to\u2014all the results would, of course, be the same in our analysis except that the value of the potential energy at z=0 would be \u22126mg . It makes no difference, because only differences in potential energy count. The energy needed to compress a linear spring a distance x from an equilibrium point is U(x)= 1 2 k x 2 , (14.4) and the zero of potential energy is at the point x=0 , the equilibrium position of the spring. Again we could add any constant we wish. The potential energy of gravitation for point masses M and m , a distance r apart, is U(r)=\u2212GMm/r. (14.5) The constant has been chosen here so that the potential is zero at infinity. Of course the same formula applies to electrical charges, because it is the same law: U(r)= q 1 q 2 /4\u03c0 \u03f5 0 r. (14.6) Now let us actually use one of these formulas, to see whether we understand what it means. Question: How fast do we have to shoot a rocket away from the earth in order for it to leave? Solution: The kinetic plus potential energy must be a constant; when it \u201cleaves,\u201d it will be millions of miles away, and if it is just barely able to leave, we may suppose that it is moving with zero speed out there, just barely going. Let a be the radius of the earth, and M its mass. The kinetic plus potential energy is then initially given by 1 2 m v 2 \u2212GmM/a . At the end of the motion the two energies must be equal. The kinetic energy is taken to be zero at the end of the motion, because it is supposed to be just barely drifting away at essentially zero speed, and the potential energy is GmM divided by infinity, which is zero. So everything is zero on one side and that tells us that the square of the velocity must be 2GM/a . But GM/ a 2 is what we call the acceleration of gravity, g . Thus v 2 =2ga. 2 At what speed must a satellite travel in order to keep going around the earth? We worked this out long ago and found that v 2 =GM/a . Therefore to go away from the earth, we need 2 \u2013 \u221a times the velocity we need to just go around the earth near its surface. We need, in other words, twice as much energy (because energy goes as the square of the velocity) to leave the earth as we do to go around it. Therefore the first thing that was done historically with satellites was to get one to go around the earth, which requires a speed of five miles per second. The next thing was to send a satellite away from the earth permanently; this required twice the energy, or about seven miles per second. Now, continuing our discussion of the characteristics of potential energy, let us consider the interaction of two molecules, or two atoms, two oxygen atoms for instance. When they are very far apart, the force is one of attraction, which varies as the inverse seventh power of the distance, and when they are very close the force is a very large repulsion. If we integrate the inverse seventh power to find the work done, we find that the potential energy U , which is a function of the radial distance between the two oxygen atoms, varies as the inverse sixth power of the distance for large distances. If we sketch the curve of the potential energy U(r) as in Fig. 14\u20133, we thus start out at large r with an inverse sixth power, but if we come in sufficiently near we reach a point d where there is a minimum of potential energy. The minimum of potential energy at r=d means this: if we start at d and move a small distance, a very small distance, the work done, which is the change in potential energy when we move this distance, is nearly zero, because there is very little change in potential energy at the bottom of the curve. Thus there is no force at this point, and so it is the equilibrium point. Another way to see that it is the equilibrium point is that it takes work to move away from d in either direction. When the two oxygen atoms have settled down, so that no more energy can be liberated from the force between them, they are in the lowest energy state, and they will be at this separation d . This is the way an oxygen molecule looks when it is cold. When we heat it up, the atoms shake and move farther apart, and we can in fact break them apart, but to do so takes a certain amount of work or energy, which is the potential energy difference between r=d and r=\u221e . When we try to push the atoms very close together the energy goes up very rapidly, because they repel each other. The reason we bring this out is that the idea of force is not particularly suitable for quantum mechanics; there the idea of energy is most natural. We find that although forces and velocities \u201cdissolve\u201d and disappear when we consider the more advanced forces between nuclear matter and between molecules and so on, the energy concept remains. Therefore we find curves of potential energy in quantum mechanics books, but very rarely do we ever see a curve for the force between two molecules, because by that time people who are doing analyses are thinking in terms of energy rather than of force. Next we note that if several conservative forces are acting on an object at the same time, then the potential energy of the object is the sum of the potential energies from each of the separate forces. This is the same proposition that we mentioned before, because if the force can be represented as a vector sum of forces, then the work done by the total force is the sum of the works done by the partial forces, and it can therefore be analyzed as changes in the potential energies of each of them separately. Thus the total potential energy is the sum of all the little pieces. We could generalize this to the case of a system of many objects interacting with one another, like Jupiter, Saturn, Uranus, etc., or oxygen, nitrogen, carbon, etc., which are acting with respect to one another in pairs due to forces all of which are conservative. In these circumstances the kinetic energy in the entire system is simply the sum of the kinetic energies of all of the particular atoms or planets or whatever, and the potential energy of the system is the sum, over the pairs of particles, of the potential energy of mutual interaction of a single pair, as though the others were not there. (This is really not true for molecular forces, and the formula is somewhat more complicated; it certainly is true for Newtonian gravitation, and it is true as an approximation for molecular forces. For molecular forces there is a potential energy, but it is sometimes a more complicated function of the positions of the atoms than simply a sum of terms from pairs.) In the special case of gravity, therefore, the potential energy is the sum, over all the pairs i and j , of \u2212G m i m j / r ij , as was indicated in Eq. (13.14). Equation (13.14) expressed mathematically the following proposition: that the total kinetic energy plus the total potential energy does not change with time. As the various planets wheel about, and turn and twist and so on, if we calculate the total kinetic energy and the total potential energy we find that the total remains constant. We have spent a considerable time discussing conservative forces; what about nonconservative forces? We shall take a deeper view of this than is usual, and state that there are no nonconservative forces! As a matter of fact, all the fundamental forces in nature appear to be conservative. This is not a consequence of Newton\u2019s laws. In fact, so far as Newton himself knew, the forces could be nonconservative, as friction apparently is. When we say friction apparently is, we are taking a modern view, in which it has been discovered that all the deep forces, the forces between the particles at the most fundamental level, are conservative. If, for example, we analyze a system like that great globular star cluster that we saw a picture of, with the thousands of stars all interacting, then the formula for the total potential energy is simply one term plus another term, etc., summed over all pairs of stars, and the kinetic energy is the sum of the kinetic energies of all the individual stars. But the globular cluster as a whole is drifting in space too, and, if we were far enough away from it and did not see the details, could be thought of as a single object. Then if forces were applied to it, some of those forces might end up driving it forward as a whole, and we would see the center of the whole thing moving. On the other hand, some of the forces can be, so to speak, \u201cwasted\u201d in increasing the kinetic or potential energy of the \u201cparticles\u201d inside. Let us suppose, for instance, that the action of these forces expands the whole cluster and makes the particles move faster. The total energy of the whole thing is really conserved, but seen from the outside with our crude eyes which cannot see the confusion of motions inside, and just thinking of the kinetic energy of the motion of the whole object as though it were a single particle, it would appear that energy is not conserved, but this is due to a lack of appreciation of what it is that we see. And that, it turns out, is the case: the total energy of the world, kinetic plus potential, is a constant when we look closely enough. When we study matter in the finest detail at the atomic level, it is not always easy to separate the total energy of a thing into two parts, kinetic energy and potential energy, and such separation is not always necessary. It is almost always possible to do it, so let us say that it is always possible, and that the potential-plus-kinetic energy of the world is constant. Thus the total potential-plus-kinetic energy inside the whole world is constant, and if the \u201cworld\u201d is a piece of isolated material, the energy is constant if there are no external forces. But as we have seen, some of the kinetic and potential energy of a thing may be internal, for instance the internal molecular motions, in the sense that we do not notice it. We know that in a glass of water everything is jiggling around, all the parts are moving all the time, so there is a certain kinetic energy inside, which we ordinarily may not pay any attention to. We do not notice the motion of the atoms, which produces heat, and so we do not call it kinetic energy, but heat is primarily kinetic energy. Internal potential energy may also be in the form, for instance, of chemical energy: when we burn gasoline energy is liberated because the potential energies of the atoms in the new atomic arrangement are lower than in the old arrangement. It is not strictly possible to treat heat as being pure kinetic energy, for a little of the potential gets in, and vice versa for chemical energy, so we put the two together and say that the total kinetic and potential energy inside an object is partly heat, partly chemical energy, and so on. Anyway, all these different forms of internal energy are sometimes considered as \u201clost\u201d energy in the sense described above; this will be made clearer when we study thermodynamics. As another example, when friction is present it is not true that kinetic energy is lost, even though a sliding object stops and the kinetic energy seems to be lost. The kinetic energy is not lost because, of course, the atoms inside are jiggling with a greater amount of kinetic energy than before, and although we cannot see that, we can measure it by determining the temperature. Of course if we disregard the heat energy, then the conservation of energy theorem will appear to be false. Another situation in which energy conservation appears to be false is when we study only part of a system. Naturally, the conservation of energy theorem will appear not to be true if something is interacting with something else on the outside and we neglect to take that interaction into account. In classical physics potential energy involved only gravitation and electricity, but now we have nuclear energy and other energies also. Light, for example, would involve a new form of energy in the classical theory, but we can also, if we want to, imagine that the energy of light is the kinetic energy of a photon, and then our formula (14.2) would still be right. We shall now discuss a few of the ideas associated with potential energy and with the idea of a field. Suppose we have two large objects A and B and a third very small one which is attracted gravitationally by the two, with some resultant force F . We have already noted in Chapter 12 that the gravitational force on a particle can be written as its mass, m , times another vector, C , which is dependent only upon the position of the particle: F=mC. F C We can analyze gravitation, then, by imagining that there is a certain vector C at every position in space which \u201cacts\u201d upon a mass which we may place there, but which is there itself whether we actually supply a mass for it to \u201cact\u201d on or not. C has three components, and each of those components is a function of (x,y,z) , a function of position in space. Such a thing we call a field, and we say that the objects A and B generate the field, i.e., they \u201cmake\u201d the vector C . When an object is put in a field, the force on it is equal to its mass times the value of the field vector at the point where the object is put. We can also do the same with the potential energy. Since the potential energy, the integral of (\u2212force)\u22c5(ds) can be written as m times the integral of (\u2212field)\u22c5(ds) , a mere change of scale, we see that the potential energy U(x,y,z) of an object located at a point (x,y,z) in space can be written as m times another function which we may call the potential \u03a8 . The integral \u222bC\u22c5ds=\u2212\u03a8 , just as \u222bF\u22c5ds=\u2212U ; there is only a scale factor between the two: U =\u2212\u222bF\u22c5ds =\u2212m\u222bC\u22c5ds=m\u03a8. (14.7) By having this function \u03a8(x,y,z) at every point in space, we can immediately calculate the potential energy of an object at any point in space, namely, U(x,y,z)=m\u03a8(x,y,z) \u2014rather a trivial business, it seems. But it is not really trivial, because it is sometimes much nicer to describe the field by giving the value of \u03a8 everywhere in space instead of having to give C . Instead of having to write three complicated components of a vector function, we can give instead the scalar function \u03a8 . Furthermore, it is much easier to calculate \u03a8 than any given component of C when the field is produced by a number of masses, for since the potential is a scalar we merely add, without worrying about direction. Also, the field C can be recovered easily from \u03a8 , as we shall shortly see. Suppose we have point masses m 1 , m 2 , \u2026 at the points 1 , 2 , \u2026 and we wish to know the potential \u03a8 at some arbitrary point p . This is simply the sum of the potentials at p due to the individual masses taken one by one: \u03a8(p)= \u2211 i \u2212 G m i r ip ,i=1, 2, \u2026 (14.8) In the last chapter we used this formula, that the potential is the sum of the potentials from all the different objects, to calculate the potential due to a spherical shell of matter by adding the contributions to the potential at a point from all parts of the shell. The result of this calculation is shown graphically in Fig. 14\u20134. It is negative, having the value zero at r=\u221e and varying as 1/r down to the radius a , and then is constant inside the shell. Outside the shell the potential is \u2212Gm/r , where m is the mass of the shell, which is exactly the same as it would have been if all the mass were located at the center. But it is not everywhere exactly the same, for inside the shell the potential turns out to be \u2212Gm/a , and is a constant! When the potential is constant, there is no field, or when the potential energy is constant there is no force, because if we move an object from one place to another anywhere inside the sphere the work done by the force is exactly zero. Why? Because the work done in moving the object from one place to the other is equal to minus the change in the potential energy (or, the corresponding field integral is the change of the potential). But the potential energy is the same at any two points inside, so there is zero change in potential energy, and therefore no work is done in going between any two points inside the shell. The only way the work can be zero for all directions of displacement is that there is no force at all. This gives us a clue as to how we can obtain the force or the field, given the potential energy. Let us suppose that the potential energy of an object is known at the position (x,y,z) and we want to know what the force on the object is. It will not do to know the potential at only this one point, as we shall see; it requires knowledge of the potential at neighboring points as well. Why? How can we calculate the x -component of the force? (If we can do this, of course, we can also find the y - and z -components, and we will then know the whole force.) Now, if we were to move the object a small distance \u0394x , the work done by the force on the object would be the x -component of the force times \u0394x , if \u0394x is sufficiently small, and this should equal the change in potential energy in going from one point to the other: \u0394W=\u2212\u0394U= F x \u0394x. (14.9) We have merely used the formula \u222bF\u22c5ds=\u2212\u0394U , but for a very short path. Now we divide by \u0394x and so find that the force is F x =\u2212\u0394U/\u0394x. (14.10) Of course this is not exact. What we really want is the limit of (14.10) as \u0394x gets smaller and smaller, because it is only exactly right in the limit of infinitesimal \u0394x . This we recognize as the derivative of U with respect to x , and we would be inclined, therefore, to write \u2212dU/dx . But U depends on x , y , and z , and the mathematicians have invented a different symbol to remind us to be very careful when we are differentiating such a function, so as to remember that we are considering that only x varies, and y and z do not vary. Instead of a d they simply make a \u201cbackwards 6 ,\u201d or \u2202 . (A \u2202 should have been used in the beginning of calculus because we always want to cancel that d , but we never want to cancel a \u2202 !) So they write \u2202U/\u2202x , and furthermore, in moments of duress, if they want to be very careful, they put a line beside it with a little yz at the bottom ( \u2202U/\u2202x | yz ), which means \u201cTake the derivative of U with respect to x , keeping y and z constant.\u201d Most often we leave out the remark about what is kept constant because it is usually evident from the context, so we usually do not use the line with the y and z . However, always use a \u2202 instead of a d as a warning that it is a derivative with some other variables kept constant. This is called a partial derivative; it is a derivative in which we vary only x . Therefore, we find that the force in the x -direction is minus the partial derivative of U with respect to x : F x =\u2212\u2202U/\u2202x. (14.11) In a similar way, the force in the y -direction can be found by differentiating U with respect to y , keeping x and z constant, and the third component, of course, is the derivative with respect to z , keeping y and x constant: F y =\u2212\u2202U/\u2202y, F z =\u2212\u2202U/\u2202z. (14.12) This is the way to get from the potential energy to the force. We get the field from the potential in exactly the same way: C x =\u2212\u2202\u03a8/\u2202x, C y =\u2212\u2202\u03a8/\u2202y, C z =\u2212\u2202\u03a8/\u2202z. (14.13) Incidentally, we shall mention here another notation, which we shall not actually use for quite a while: Since C is a vector and has x -, y -, and z -components, the symbolized \u2202/\u2202x , \u2202/\u2202y , and \u2202/\u2202z which produce the x -, y -, and z -components are something like vectors. The mathematicians have invented a glorious new symbol, \u2207 , called \u201cgrad\u201d or \u201cgradient\u201d, which is not a quantity but an operator that makes a vector from a scalar. It has the following \u201ccomponents\u201d: The x -component of this \u201cgrad\u201d is \u2202/\u2202x , the y -component is \u2202/\u2202y , and the z -component is \u2202/\u2202z , and then we have the fun of writing our formulas this way: F=\u2212\u2207U,C=\u2212\u2207\u03a8. (14.14) Using \u2207 gives us a quick way of testing whether we have a real vector equation or not, but actually Eqs. (14.14) mean precisely the same as Eqs. (14.11), (14.12) and (14.13); it is just another way of writing them, and since we do not want to write three equations every time, we just write \u2207U instead. One more example of fields and potentials has to do with the electrical case. In the case of electricity the force on a stationary object is the charge times the electric field: F=qE . (In general, of course, the x -component of force in an electrical problem has also a part which depends on the magnetic field. It is easy to show from Eq. (12.11) that the force on a particle due to magnetic fields is always at right angles to its velocity, and also at right angles to the field. Since the force due to magnetism on a moving charge is at right angles to the velocity, no work is done by the magnetism on the moving charge because the motion is at right angles to the force. Therefore, in calculating theorems of kinetic energy in electric and magnetic fields we can disregard the contribution from the magnetic field, since it does not change the kinetic energy.) We suppose that there is only an electric field. Then we can calculate the energy, or work done, in the same way as for gravity, and calculate a quantity \u03d5 which is minus the integral of E\u22c5ds , from the arbitrary fixed point to the point where we make the calculation, and then the potential energy in an electric field is just charge times this quantity \u03d5 : \u03d5(r)=\u2212\u222bE\u22c5ds, U=q\u03d5. Let us take, as an example, the case of two parallel metal plates, each with a surface charge of \u00b1\u03c3 per unit area. This is called a parallel-plate capacitor. We found previously that there is zero force outside the plates and that there is a constant electric field between them, directed from + to \u2212 and of magnitude \u03c3/ \u03f5 0 (Fig. 14\u20135). We would like to know how much work would be done in carrying a charge from one plate to the other. The work would be the (force)\u22c5(ds) integral, which can be written as charge times the potential value at plate 1 minus that at plate 2 : W= \u222b 2 1 F\u22c5ds=q( \u03d5 1 \u2212 \u03d5 2 ). 2 We can actually work out the integral because the force is constant, and if we call the separation of the plates d , then the integral is easy: \u222b 2 1 F\u22c5ds= q\u03c3 \u03f5 0 \u222b 2 1 dx= q\u03c3d \u03f5 0 . 2 2 The difference in potential, \u0394\u03d5=\u03c3d/ \u03f5 0 , is called the voltage difference, and \u03d5 is measured in volts. When we say a pair of plates is charged to a certain voltage, what we mean is that the difference in electrical potential of the two plates is so-and-so many volts. For a capacitor made of two parallel plates carrying a surface charge \u00b1\u03c3 , the voltage, or difference in potential, of the pair of plates is \u03c3d/ \u03f5 0 ."
    },
    {
        "input": "Refractive Index of Dense Materials",
        "output": "We want now to discuss the phenomenon of the refraction of light\u2014and also, therefore, the absorption of light\u2014by dense materials. In Chapter 31 of Volume I we discussed the theory of the index of refraction, but because of our limited mathematical abilities at that time, we had to restrict ourselves to finding the index only for materials of low density, like gases. The physical principles that produced the index were, however, made clear. The electric field of the light wave polarizes the molecules of the gas, producing oscillating dipole moments. The acceleration of the oscillating charges radiates new waves of the field. This new field, interfering with the old field, produces a changed field which is equivalent to a phase shift of the original wave. Because this phase shift is proportional to the thickness of the material, the effect is equivalent to having a different phase velocity in the material. When we looked at the subject before, we neglected the complications that arise from such effects as the new wave changing the fields at the oscillating dipoles. We assumed that the forces on the charges in the atoms came just from the incoming wave, whereas, in fact, their oscillations are driven not only by the incoming wave but also by the radiated waves of all the other atoms. It would have been difficult for us at that time to include this effect, so we studied only the rarefied gas, where such effects are not important. Now, however, we will find that it is very easy to treat the problem by the use of differential equations. This method obscures the physical origin of the index (as coming from the re-radiated waves interfering with the original waves), but it makes the theory for dense materials much simpler. This chapter will bring together a large number of pieces from our earlier work. We\u2019ve taken up practically everything we will need, so there are relatively few really new ideas to be introduced. Since you may need to refresh your memory about what we are going to need, we give in Table 32\u20131 a list of the equations we are going to use, together with a reference to the place where each can be found. In most instances, we will not take the time to give the physical arguments again, but will just use the equations. We begin by recalling the machinery of the index of refraction for a gas. We suppose that there are N particles per unit volume and that each particle behaves as a harmonic oscillator. We use a model of an atom or molecule in which the electron is bound with a force proportional to its displacement (as though the electron were held in place by a spring). We emphasized that this was not a legitimate classical model of an atom, but we will show later that the correct quantum mechanical theory gives results equivalent to this model (in simple cases). In our earlier treatment, we did not include the possibility of a damping force in the atomic oscillators, but we will do so now. Such a force corresponds to a resistance to the motion, that is, to a force proportional to the velocity of the electron. Then the equation of motion is F=qeE=m( \u00a8 x +\u03b3 \u02d9 x +\u03c9 2 0 x), where x is the displacement parallel to the direction of E . (We are assuming an isotropic oscillator whose restoring force is the same in all directions. Also, we are taking, for the moment, a linearly polarized wave, so that E doesn\u2019t change direction.) If the electric field acting on the atom varies sinusoidally with time, we write E=E0ei\u03c9t. The displacement will then oscillate with the same frequency, and we can let x=x0ei\u03c9t. Substituting \u02d9 x =i\u03c9x and \u00a8 x =\u2212\u03c92x , we can solve for x in terms of E : x= qe/m \u2212\u03c92+i\u03b3\u03c9+\u03c9 2 0 E. Knowing the displacement, we can calculate the acceleration \u00a8 x and find the radiated wave responsible for the index. This was the way we computed the index in Chapter 31 of Volume I. Now, however, we want to take a different approach. The induced dipole moment p of an atom is qex or, using Eq. (32.3), p= q 2 e /m \u2212\u03c92+i\u03b3\u03c9+\u03c9 2 0 E. Since p is proportional to E , we write p=\u03f50\u03b1(\u03c9)E, where \u03b1 is called the atomic polarizability.1 With this definition, we have \u03b1= q 2 e /m\u03f50 \u2212\u03c92+i\u03b3\u03c9+\u03c9 2 0 . The quantum mechanical solution for the motions of electrons in atoms gives a similar answer except with the following modifications. The atoms have several natural frequencies, each frequency with its own dissipation constant \u03b3 . Also the effective \u201cstrength\u201d of each mode is different, which we can represent by multiplying the polarizability for each frequency by a strength factor f , which is a number we expect to be of the order of 1 . Representing the three parameters \u03c9 0 , \u03b3 , and f by \u03c9 0k , \u03b3 k , and f k for each mode of oscillation, and summing over the various modes, we modify Eq. (32.6) to read \u03b1(\u03c9)= q 2 e \u03f5 0 m \u2211 k f k \u2212 \u03c9 2 +i \u03b3 k \u03c9+ \u03c9 2 0k . (32.7) If N is the number of atoms per unit volume in the material, the polarization P is just Np= \u03f5 0 N\u03b1E , and is proportional to E : P= \u03f5 0 N\u03b1(\u03c9)E. (32.8) In other words, when there is a sinusoidal electric field acting in a material, there is an induced dipole moment per unit volume which is proportional to the electric field\u2014with a proportionality constant \u03b1 that, we emphasize, depends upon the frequency. At very high frequencies, \u03b1 is small; there is not much response. However, at low frequencies there can be a strong response. Also, the proportionality constant is a complex number, which means that the polarization does not exactly follow the electric field, but may be shifted in phase to some extent. At any rate, there is a polarization per unit volume whose magnitude is proportional to the strength of the electric field. The existence of polarization in matter means that there are polarization charges and currents inside of the material, and these must be put into the complete Maxwell equations in order to find the fields. We are going to solve Maxwell\u2019s equations this time in a situation in which the charges and currents are not zero, as in a vacuum, but are given implicitly by the polarization vector. Our first step is to find explicitly the charge density \u03c1 and current density j , averaged over a small volume of the same size we had in mind when we defined P . Then the \u03c1 and j we need can be obtained from the polarization. We have seen in Chapter 10 that when the polarization P varies from place to place, there is a charge density given by \u03c1 pol =\u2212\u2207\u22c5P. (32.9) At that time, we were dealing with static fields, but the same formula is valid also for time-varying fields. However, when P varies with time, there are charges in motion, so there is also a polarization current. Each of the oscillating charges contributes a current equal to its charge q e , times its velocity v . With N such charges per unit volume, the current density j is j=N q e v. j N Since we know that v=dx/dt , then j=N q e (dx/dt) , which is just dP/dt . Therefore the current density from the varying polarization is j pol = \u2202P \u2202t . (32.10) Our problem is now direct and simple. We write Maxwell\u2019s equations with the charge density and current density expressed in terms of P , using Eqs. (32.9) and (32.10). (We assume that there are no other currents and charges in the material.) We then relate P to E with Eq. (32.8), and we solve the equation for E and B \u2014looking for the wave solutions. Before we do this, we would like to make an historical note. Maxwell originally wrote his equations in a form which was different from the one we have been using. Because the equations were written in this different form for many years\u2014and are still written that way by many people\u2014we will explain the difference. In the early days, the mechanism of the dielectric constant was not fully and clearly appreciated. The nature of atoms was not understood, nor that there was a polarization of the material. So people did not appreciate that there was a contribution to the charge density \u03c1 from \u2207\u22c5P . They thought only in terms of charges that were not bound to atoms (such as the charges that flow in wires or are rubbed off surfaces). Today, we prefer to let \u03c1 represent the total charge density, including the part from the bound atomic charges. If we call that part \u03c1 pol , we can write \u03c1= \u03c1 pol + \u03c1 other , + where \u03c1 other is the charge density considered by Maxwell and refers to the charges not bound to individual atoms. We would then write \u2207\u22c5E= \u03c1 pol + \u03c1 other \u03f5 0 . + Substituting \u03c1 pol from Eq. (32.9), \u2207\u22c5E= \u03c1 other \u03f5 0 \u2212 1 \u03f5 0 \u2207\u22c5P \u03c1 1 or \u2207\u22c5( \u03f5 0 E+P)= \u03c1 other . (32.11) The current density in the Maxwell equations for \u2207\u00d7B also has, in general, contributions from bound atomic currents. We can therefore write j= j pol + j other , j j j and the Maxwell equation becomes c 2 \u2207\u00d7B= j other \u03f5 0 + j pol \u03f5 0 + \u2202E \u2202t . (32.12) Using Eq. (32.10), we get \u03f5 0 c 2 \u2207\u00d7B= j other + \u2202 \u2202t ( \u03f5 0 E+P). (32.13) Now you can see that if we were to define a new vector D by D= \u03f5 0 E+P, (32.14) the two field equations would become \u2207\u22c5D= \u03c1 other (32.15) and \u03f5 0 c 2 \u2207\u00d7B= j other + \u2202D \u2202t . (32.16) These are actually the forms that Maxwell used for dielectrics. His two remaining equations were \u2207\u00d7E=\u2212 \u2202B \u2202t , \u2202 B and \u2207\u22c5B=0, \u2207 B 0 which are the same as we have been using. Maxwell and the other early workers also had a problem with magnetic materials (which we will take up soon). Because they did not know about the circulating currents responsible for atomic magnetism, they used a current density that was missing still another part. Instead of Eq. (32.16), they actually wrote \u2207\u00d7H= j \u2032 + \u2202D \u2202t , (32.17) where H differs from \u03f5 0 c 2 B because it includes the effects of atomic currents. (Then j \u2032 represents what is left of the currents.) So Maxwell had four field vectors\u2014 E , D , B , and H \u2014the D and H were hidden ways of not paying attention to what was going on inside the material. You will find the equations written this way in many places. To solve the equations, it is necessary to relate D and H to the other fields, and people used to write D=\u03f5EandB=\u03bcH. (32.18) However, these relations are only approximately true for some materials and even then only if the fields are not changing rapidly with time. (For sinusoidally varying fields one often can write the equations this way by making \u03f5 and \u03bc complex functions of the frequency, but not for an arbitrary time variation of the fields.) So there used to be all kinds of cheating in solving the equations. We think the right way is to keep the equations in terms of the fundamental quantities as we now understand them\u2014and that\u2019s how we have done it. We want now to find out what kind of electromagnetic waves can exist in a dielectric material in which there are no extra charges other than those bound in atoms. So we take \u03c1=\u2212\u2207\u22c5P and j=\u2202P/\u2202t . Maxwell\u2019s equations then become (a)\u2207\u22c5E=\u2212 \u2207\u22c5P \u03f5 0 (b) c 2 \u2207\u00d7B= \u2202 \u2202t ( P \u03f5 0 +E) (c)\u2207\u00d7E=\u2212 \u2202B \u2202t (d)\u2207\u22c5B=0 (32.19) We can solve these equations as we have done before. We start by taking the curl of Eq. (32.19c): \u2207\u00d7(\u2207\u00d7E)=\u2212 \u2202 \u2202t \u2207\u00d7B. \u2202 Next, we make use of the vector identity \u2207\u00d7(\u2207\u00d7E)=\u2207(\u2207\u22c5E)\u2212 \u2207 2 E, 2 and also substitute for \u2207\u00d7B , using Eq. (32.19b); we get \u2207(\u2207\u22c5E)\u2212 \u2207 2 E=\u2212 1 \u03f5 0 c 2 \u2202 2 P \u2202 t 2 \u2212 1 c 2 \u2202 2 E \u2202 t 2 . 2 2 Using Eq. (32.19a) for \u2207\u22c5E , we get \u2207 2 E \u2212 1 c 2 \u2202 2 E \u2202 t 2 = \u2212 1 \u03f5 0 \u2207(\u2207\u22c5P)+ 1 \u03f5 0 c 2 \u2202 2 P \u2202 t 2 . (32.20) So instead of the wave equation, we now get that the d\u2019Alembertian of E is equal to two terms involving the polarization P . Since P depends on E , however, Eq. (32.20) can still have wave solutions. We will now limit ourselves to isotropic dielectrics, so that P is always in the same direction as E . Let\u2019s try to find a solution for a wave going in the z -direction. Then, the electric field might vary as e i(\u03c9t\u2212kz) . We will also suppose that the wave is polarized in the x -direction\u2014that the electric field has only an x -component. We write E x = E 0 e i(\u03c9t\u2212kz) . (32.21) You know that any function of (z\u2212vt) represents a wave that travels with the speed v . The exponent of Eq. (32.21) can be written as \u2212ik(z\u2212 \u03c9 k t), ( ) so, Eq. (32.21) represents a wave with the phase velocity v ph =\u03c9/k. / k The index of refraction n is defined (see Chapter 31, Vol. I) by letting v ph = c n . c Thus Eq. (32.21) becomes E x = E 0 e i\u03c9(t\u2212nz/c) . i ( / ) So we can find n by finding what value of k is required if Eq. (32.21) is to satisfy the proper field equations, and then using n= kc \u03c9 . (32.22) In an isotropic material, there will be only an x -component of the polarization; then P has no variation with the x -coordinate, so \u2207\u22c5P=0 , and we get rid of the first term on the right-hand side of Eq. (32.20). Also, since we are assuming a linear dielectric, P x will vary as e i\u03c9t , and \u2202 2 P x /\u2202 t 2 =\u2212 \u03c9 2 P x . The Laplacian in Eq. (32.20) becomes simply \u2202 2 E x /\u2202 z 2 =\u2212 k 2 E x , so we get \u2212 k 2 E x + \u03c9 2 c 2 E x =\u2212 \u03c9 2 \u03f5 0 c 2 P x . (32.23) Now let us assume for the moment that since E is varying sinusoidally, we can set P proportional to E , as in Eq. (32.8). (We\u2019ll come back to discuss this assumption later.) We write P x = \u03f5 0 N\u03b1 E x . P N E Then E x drops out of Eq. (32.23), and we find k 2 = \u03c9 2 c 2 (1+N\u03b1). (32.24) We have found that a wave like Eq. (32.21), with the wave number k given by Eq. (32.24), will satisfy the field equations. Using Eq. (32.22), the index n is given by n 2 =1+N\u03b1. (32.25) Let\u2019s compare this formula with what we obtained in our theory of the index of a gas (Chapter 31, Vol. I). There, we got Eq. (31.19), which is n=1+ 1 2 N q 2 e m \u03f5 0 1 \u2212 \u03c9 2 + \u03c9 2 0 . (32.26) Taking \u03b1 from Eq. (32.6), Eq. (32.25) would give us n 2 =1+ N q 2 e m \u03f5 0 1 \u2212 \u03c9 2 +i\u03b3\u03c9+ \u03c9 2 0 . (32.27) First, we have the new term in i\u03b3\u03c9 , because we are including the dissipation of the oscillators. Second, the left-hand side is n instead of n 2 , and there is an extra factor of 1/2 . But notice that if N is small enough so that n is close to one (as it is for a gas), then Eq. (32.27) says that n 2 is one plus a small number: n 2 =1+\u03f5 . We can then write n= 1+\u03f5 \u2212 \u2212 \u2212 \u2212 \u221a \u22481+\u03f5/2 , and the two expressions are equivalent. Thus our new method gives for a gas the same result we found earlier. Now you might think that Eq. (32.27) should give the index of refraction for dense materials also. It needs to be modified, however, for several reasons. First, the derivation of this equation assumes that the polarizing field on each atom is the field E x . That assumption is not right, however, because in dense materials there is also the field produced by other atoms in the vicinity, which may be comparable to E x . We considered a similar problem when we studied the static fields in dielectrics. (See Chapter 11.) You will remember that we estimated the field at a single atom by imagining that it sat in a spherical hole in the surrounding dielectric. The field in such a hole\u2014which we called the local field\u2014is increased over the average field E by the amount P/3 \u03f5 0 . (Remember, however, that this result is only strictly true in isotropic materials\u2014including the special case of a cubic crystal.) The same arguments will hold for the electric field in a wave, so long as the wavelength of the wave is much longer than the spacing between atoms. Limiting ourselves to such cases, we write E local =E+ P 3 \u03f5 0 . (32.28) This local field is the one that should be used for E in Eq. (32.3); that is, Eq. (32.8) should be rewritten: P= \u03f5 0 N\u03b1 E local . (32.29) Using E local from Eq. (32.28), we find P= \u03f5 0 N\u03b1(E+ P 3 \u03f5 0 ) P or P= N\u03b1 1\u2212(N\u03b1/3) \u03f5 0 E. (32.30) In other words, for dense materials P is still proportional to E (for sinusoidal fields). However, the constant of proportionality is not \u03f5 0 N\u03b1 , as we wrote below Eq. (32.23), but should be \u03f5 0 N\u03b1/[1\u2212(N\u03b1/3)] . So we should correct Eq. (32.25) to read n 2 =1+ N\u03b1 1\u2212(N\u03b1/3) . (32.31) It will be more convenient if we rewrite this equation as 3 n 2 \u22121 n 2 +2 =N\u03b1, (32.32) which is algebraically equivalent. This is known as the Clausius-Mossotti equation. There is another complication in dense materials. Because neighboring atoms are so close, there are strong interactions between them. The internal modes of oscillation are, therefore, modified. The natural frequencies of the atomic oscillations are spread out by the interactions, and they are usually quite heavily damped\u2014the resistance coefficient becomes quite large. So the \u03c9 0 \u2019s and \u03b3 \u2019s of the solid will be quite different from those of the free atoms. With these reservations, we can still represent \u03b1 , at least approximately, by Eq. (32.7). We have then that 3 n 2 \u22121 n 2 +2 = N q 2 e m \u03f5 0 \u2211 k f k \u2212 \u03c9 2 +i \u03b3 k \u03c9+ \u03c9 2 0k . (32.33) One final complication. If the dense material is a mixture of several components, each will contribute to the polarization. The total \u03b1 will be the sum of the contributions from each component of the mixture [except for the inaccuracy of the local field approximation, Eq. (32.28), in ordered crystals\u2014effects we discussed when analyzing ferroelectrics]. Writing N j as the number of atoms of each component per unit volume, we should replace Eq. (32.32) by 3( n 2 \u22121 n 2 +2 )= \u2211 j N j \u03b1 j , (32.34) where each \u03b1 j will be given by an expression like Eq. (32.7). Equation (32.34) completes our theory of the index of refraction. The quantity 3( n 2 \u22121)/( n 2 +2) is given by some complex function of frequency, which is the mean atomic polarizability \u03b1(\u03c9) . The precise evaluation of \u03b1(\u03c9) (that is, finding f k , \u03b3 k and \u03c9 0k ) in dense substances is a difficult problem of quantum mechanics. It has been done from first principles only for a few especially simple substances. We want to look now at the consequences of our result, Eq. (32.33). First, we notice that \u03b1 is complex, so the index n is going to be a complex number. What does that mean? Let\u2019s say that we write n as the sum of a real and an imaginary part: n= n R \u2212i n I , (32.35) where n R and n I are real functions of \u03c9 . We write i n I with a minus sign, so that n I will be a positive quantity in all ordinary optical materials. (In ordinary inactive materials\u2014that are not, like lasers, light sources themselves\u2014 \u03b3 is a positive number, and that makes the imaginary part of n negative.) Our plane wave of Eq. (32.21) is written in terms of n as E x = E 0 e i\u03c9(t\u2212nz/c) . i ( / ) Writing n as in Eq. (32.35), we would have E x = E 0 e \u2212\u03c9 n I z/c e i\u03c9(t\u2212 n R z/c) . (32.36) The term e i\u03c9(t\u2212 n R z/c) represents a wave travelling with the speed c/ n R , so n R represents what we normally think of as the index of refraction. But the amplitude of this wave is E 0 e \u2212\u03c9 n I z/c , / which decreases exponentially with z . A graph of the strength of the electric field at some instant as a function of z is shown in Fig. 32\u20131, for n I \u2248 n R /2\u03c0 . The imaginary part of the index represents the attenuation of the wave due to the energy losses in the atomic oscillators. The intensity of the wave is proportional to the square of the amplitude, so Intensity\u221d e \u22122\u03c9 n I z/c . 2 / This is often written as Intensity\u221d e \u2212\u03b2z . \u03b2 where \u03b2=2\u03c9 n I /c is called the absorption coefficient. Thus we have in Eq. (32.33) not only the theory of the index of refraction of materials, but the theory of their absorption of light as well. In what we usually consider to be transparent material, the quantity c/\u03c9 n I \u2014which has the dimensions of a length\u2014is quite large in comparison with the thickness of the material. There is another prediction of our theory of the index of refraction that we can check against experiment. Suppose we consider a mixture of two materials. The index of the mixture is not the average of the two indexes, but should be given in terms of the sum of the two polarizabilities, as in Eq. (32.34). If we ask about the index of, say, a sugar solution, the total polarizability is the sum of the polarizability of the water and that of the sugar. Each must, of course, be calculated using for N the number per unit volume of the molecules of the particular kind. In other words, if a given solution has N 1 molecules of water, whose polarizability is \u03b1 1 , and N 2 molecules of sucrose (C 12 H 22 O 11 ), whose polarizability is \u03b1 2 , we should have that 3( n 2 \u22121 n 2 +2 )= N 1 \u03b1 1 + N 2 \u03b1 2 . (32.37) We can use this formula to test our theory against experiment by measuring the index for various concentrations of sucrose in water. We are making several assumptions here, however. Our formula assumes that there is no chemical action when the sucrose is dissolved and that the disturbances to the individual atomic oscillators are not too different for various concentrations. So our result is certainly only approximate. Anyway, let\u2019s see how good it is. We have picked the example of a sugar solution because there is a good table of measurements of the index of refraction in the Handbook of Chemistry and Physics and also because sugar is a molecular crystal that goes into solution without ionizing or otherwise changing its chemical state. We give in the first three columns of Table 32\u20132 the data from the handbook. Column A is the percent of sucrose by weight, column B is the measured density (g/cm 3 ), and column C is the measured index of refraction for light whose wavelength is 589.3 millimicrons. For pure sugar we have taken the measured index of sugar crystals. The crystals are not isotropic, so the measured index is different along different directions. The handbook gives three values: n 1 =1.5376, n 2 =1.5651, n 3 =1.5705. 1.5376 1.5651 1.5705. We have taken the average. Now we could try to compute n for each concentration, but we don\u2019t know what value to take for \u03b1 1 or \u03b1 2 . Let\u2019s test the theory this way: We will assume that the polarizability of water ( \u03b1 1 ) is the same at all concentrations and compute the polarizability of sucrose by using the experiment of values for n and solving Eq. (32.37) for \u03b1 2 . If the theory is correct, we should get the same \u03b1 2 for all concentrations. First, we need to know N 1 and N 2 : let\u2019s express them in terms of Avogadro\u2019s number, N 0 . Let\u2019s take one liter ( 1000 cm 3 ) for our unit of volume. Then N i / N 0 is the weight per liter divided by the gram-molecular weight. And the weight per liter is the density (multiplied by 1000 to get grams per liter) times the fractional weight of either the sucrose or the water. In this way, we get N 2 / N 0 and N 1 / N 0 as in columns D and E of the table. In column F we have computed 3( n 2 \u22121)/( n 2 +2) from the experimental values of n in column C. For pure water, 3( n 2 \u22121)/( n 2 +2) is 0.617 , which is equal to just N 1 \u03b1 1 . We can then fill in the rest of Column G, since for each row G/E may be in the same ratio\u2014namely, 0.617:55.5 . Subtracting column G from column F, we get the contribution N 2 \u03b1 2 of the sucrose, shown in column H. Dividing these entries by the values of N 2 / N 0 in column D, we get the value of N 0 \u03b1 2 shown in column J. From our theory we would expect all the values of N 0 \u03b1 2 to be the same. They are not exactly equal, but pretty close. We can conclude that our ideas are fairly correct. Even more, we find that the polarizability of the sugar molecule doesn\u2019t seem to depend much on its surroundings\u2014its polarizability is nearly the same in a dilute solution as it is in the crystal. The theory we have worked out in this chapter for solid materials can also be applied to good conductors, like metals, with very little modification. In metals some of the electrons have no binding force holding them to any particular atom; it is these \u201cfree\u201d electrons which are responsible for the conductivity. There are other electrons which are bound, and the theory above is directly applicable to them. Their influence, however, is usually swamped by the effects of the conduction electrons. We will consider now only the effects of the free electrons. If there is no restoring force on an electron\u2014but still some resistance to its motion\u2014its equation of motion differs from Eq. (32.1) only because the term in \u03c9 2 0 x is lacking. So all we have to do is set \u03c9 2 0 =0 in the rest of our derivations\u2014except that there is one more difference. The reason that we had to distinguish between the average field and the local field in a dielectric is that in an insulator each of the dipoles is fixed in position, so that it has a definite relationship to the position of the others. But because the conduction electrons in a metal move around all over the place, the field on them on the average is just the average field E . So the correction we made to Eq. (32.8) by using Eq. (32.28) should not be made for conduction electrons. Therefore the formula for the index of refraction for metals should look like Eq. (32.27), except with \u03c9 0 set equal to zero, namely, n 2 =1+ N q 2 e m \u03f5 0 1 \u2212 \u03c9 2 +i\u03b3\u03c9 . (32.38) This is only the contribution from the conduction electrons, which we will assume is the major term for metals. Now we even know how to find what value to use for \u03b3 , because it is related to the conductivity of the metal. In Chapter 43 of Volume I we discussed how the conductivity of a metal comes from the diffusion of the free electrons through the crystal. The electrons go on a jagged path from one scattering to the next, and between scatterings they move freely except for an acceleration due to any average electric field (as shown in Fig. 32\u20132). We found in Chapter 43 of Volume I that the average drift velocity is just the acceleration times the average time \u03c4 between collisions. The acceleration is q e E/m , so v drift = q e E m \u03c4. (32.39) This formula assumed that E was constant, so that v drift was a steady velocity. Since there is no average acceleration, the drag force is equal to the applied force. We have defined \u03b3 by saying that \u03b3mv is the drag force [see Eq. (32.1)], which is q e E ; therefore we have that \u03b3= 1 \u03c4 . (32.40) Although we cannot easily measure \u03c4 directly, we can determine it by measuring the conductivity of the metal. It is found experimentally that an electric field E in a metal produces a current with the density j proportional to E (for isotropic materials): j=\u03c3E. j E The proportionality constant \u03c3 is called the conductivity. This is just what we expect from Eq. (32.39) if we set j=N q e v drift . j N Then \u03c3= N q 2 e m \u03c4. (32.41) So \u03c4 \u2014and therefore \u03b3 \u2014can be related to the observed electrical conductivity. Using Eqs. (32.40) and (32.41), we can rewrite our formula for the index, Eq. (32.38), in the following form: n 2 =1+ \u03c3/ \u03f5 0 i\u03c9(1+i\u03c9\u03c4) , (32.42) where \u03c4= 1 \u03b3 = m\u03c3 N q 2 e . (32.43) This is a convenient formula for the index of refraction of metals. Our result, Eq. (32.42), for the index of refraction for metals predicts quite different characteristics for wave propagation at different frequencies. Let\u2019s first see what happens at very low frequencies. If \u03c9 is small enough, we can approximate Eq. (32.42) by n 2 =\u2212i \u03c3 \u03f5 0 \u03c9 . (32.44) Now, as you can check by taking the square,2 \u2212i \u2212 \u2212 \u221a = 1\u2212i 2 \u2013 \u221a ; 1 i so for low frequencies, n= \u03c3/2 \u03f5 0 \u03c9 \u2212 \u2212 \u2212 \u2212 \u2212 \u2212 \u221a (1\u2212i). (32.45) The real and imaginary parts of n have the same magnitude. With such a large imaginary part to n , the wave is rapidly attenuated in the metal. Referring to Eq. (32.36), the amplitude of a wave going in the z-direction decreases as exp[\u2212 \u03c3\u03c9/2 \u03f5 0 c 2 \u2212 \u2212 \u2212 \u2212 \u2212 \u2212 \u2212 \u221a z]. (32.46) Let\u2019s write this as e \u2212z/\u03b4 , (32.47) where \u03b4 is then the distance in which the wave amplitude decreases by the factor e \u22121 =1/2.72 \u2014or roughly one-third. The amplitude of such a wave as a function of z is shown in Fig. 32\u20133. Since electromagnetic waves will penetrate into a metal only this distance, \u03b4 is called the skin depth. It is given by \u03b4= 2 \u03f5 0 c 2 /\u03c3\u03c9 \u2212 \u2212 \u2212 \u2212 \u2212 \u2212 \u2212 \u221a . (32.48) Now what do we mean by \u201clow\u201d frequencies? Looking at Eq. (32.42), we see that it can be approximated by Eq. (32.44) only if \u03c9\u03c4 is much less than one and if \u03c9 \u03f5 0 /\u03c3 is also much less than one\u2014that is, our low-frequency approximation applies when \u03c9\u226a 1 \u03c4 1 and \u03c9\u226a \u03c3 \u03f5 0 . (32.49) Let\u2019s see what frequencies these correspond to for a typical metal like copper. We compute \u03c4 by using Eq. (32.43), and \u03c3/ \u03f5 0 , by using the measured conductivity. We take the following data from a handbook: \u03c3=5.76\u00d7 10 7 (ohm\u22c5meter) \u22121 , atomic weight=63.5 grams, density=8.9 grams\u22c5cm \u22123 , Avogadro\u2019s number= 6.02\u00d7 10 23 (gram atomic weight) \u22121 . If we assume that there is one free electron per atom, then the number of electrons per cubic meter is N=8.5\u00d7 10 28 meter \u22123 . 28 3 Using q e \u03f5 0 m =1.6\u00d7 10 \u221219 coulomb, =8.85\u00d7 10 \u221212 farad\u22c5 meter \u22121 , =9.11\u00d7 10 \u221231 kg, we get \u03c4 1 \u03c4 \u03c3 \u03f5 0 =2.4\u00d7 10 \u221214 sec, =4.1\u00d7 10 13 sec \u22121 , =6.5\u00d7 10 18 sec \u22121 . So for frequencies less than about 10 12 cycles per second, copper will have the \u201clow-frequency\u201d behavior we describe (that means for waves whose free-space wavelength is longer than 0.3 millimeters\u2014very short radio waves!). For these waves, the skin depth in copper is \u03b4= 0.028 m 2 \u22c5 sec \u22121 \u03c9 \u2212 \u2212 \u2212 \u2212 \u2212 \u2212 \u2212 \u2212 \u2212 \u2212 \u2212 \u2212 \u2212 \u221a For microwaves of 10,000 megacycles per second ( 3 -cm waves) \u03b4=6.7\u00d7 10 \u22125 cm. 5 The wave penetrates a very small distance. We can see from this why in studying cavities (or waveguides) we needed to worry only about the fields inside the cavity, and not in the metal or outside the cavity. Also, we see why the losses in a cavity are reduced by a thin plating of silver or gold. The losses come from the current, which are appreciable only in a thin layer equal to the skin depth. Suppose we look now at the index of a metal like copper at high frequencies. For very high frequencies \u03c9\u03c4 is much greater than one, and Eq. (32.42) is well approximated by n 2 =1\u2212 \u03c3 \u03f5 0 \u03c9 2 \u03c4 . (32.50) For waves of high frequencies the index of a metal becomes real\u2014and less than one! This is also evident from Eq. (32.38) if the dissipation term with \u03b3 is neglected, as can be done for very large \u03c9 . Equation (32.38) gives n 2 =1\u2212 N q 2 e m \u03f5 0 \u03c9 2 , (32.51) which is, of course, the same as Eq. (32.50). We have seen before the quantity N q 2 e /m \u03f5 0 , which we called the square of the plasma frequency (Section 7\u20133): \u03c9 2 p = N q 2 e \u03f5 0 m , 2 so we can write Eq. (32.50) or Eq. (32.51) as n 2 =1\u2212( \u03c9 p \u03c9 ) 2 . \u03c9 The plasma frequency is a kind of \u201ccritical\u201d frequency. For \u03c9< \u03c9 p the index of a metal has an imaginary part, and waves are attenuated; but for \u03c9\u226b \u03c9 p the index is real, and the metal becomes transparent. You know, of course, that metals are reasonably transparent to x-rays. But some metals are even transparent in the ultraviolet. In Table 32\u20133 we give for several metals the experimental observed wavelength at which they begin to become transparent. In the second column we give the calculated critical wavelength \u03bb p =2\u03c0c/ \u03c9 p . Considering that the experimental wavelength is not too well defined, the fit of the theory is fairly good. You may wonder why the plasma frequency \u03c9 p should have anything to do with the propagation of electromagnetic waves in metals. The plasma frequency came up in Chapter 7 as the natural frequency of density oscillations of the free electrons. (A clump of electrons is repelled by electric forces, and the inertia of the electrons leads to an oscillation of density.) So longitudinal plasma waves are resonant at \u03c9 p . But we are now talking about transverse electromagnetic waves, and we have found that transverse waves are absorbed for frequencies below \u03c9 p . (It\u2019s an interesting and not accidental coincidence.) Although we have been talking about wave propagation in metals, you appreciate by this time the universality of the phenomena of physics\u2014that it doesn\u2019t make any difference whether the free electrons are in a metal or whether they are in the plasma of the ionosphere of the earth, or in the atmosphere of a star. To understand radio propagation in the ionosphere, we can use the same expressions\u2014using, of course, the proper values for N and \u03c4 . We can see now why long radio waves are absorbed or reflected by the ionosphere, whereas short waves go right through. (Short waves must be used for communication with satellites.) We have talked about the high- and low-frequency extremes for wave propagation in metals. For the in-between frequencies the full-blown formula of Eq. (32.42) must be used. In general, the index will have real and imaginary parts; the wave is attenuated as it propagates into the metal. For very thin layers, metals are somewhat transparent even at optical frequencies. As an example, special goggles for people who work around high-temperature furnaces are made by evaporating a thin layer of gold on glass. The visible light is transmitted fairly well\u2014with a strong green tinge\u2014but the infrared is strongly absorbed. Finally, it cannot have escaped the reader that many of these formulas resemble in some ways those for the dielectric constant \u03ba discussed in Chapter 10. The dielectric constant \u03ba measures the response of the material to a constant field, that is, for \u03c9=0 . If you look carefully at the definition of n and \u03ba you see that \u03ba is simply the limit of n 2 as \u03c9\u21920 . Indeed, placing \u03c9=0 and n 2 =\u03ba in equations of this chapter will reproduce the equations of the theory of the dielectric constant of Chapter 11."
    },
    {
        "input": "Conservation of Energy",
        "output": "In this chapter, we begin our more detailed study of the different aspects of physics, having finished our description of things in general. To illustrate the ideas and the kind of reasoning that might be used in theoretical physics, we shall now examine one of the most basic laws of physics, the conservation of energy. There is a fact, or if you wish, a law, governing all natural phenomena that are known to date. There is no known exception to this law\u2014it is exact so far as we know. The law is called the conservation of energy. It states that there is a certain quantity, which we call energy, that does not change in the manifold changes which nature undergoes. That is a most abstract idea, because it is a mathematical principle; it says that there is a numerical quantity which does not change when something happens. It is not a description of a mechanism, or anything concrete; it is just a strange fact that we can calculate some number and when we finish watching nature go through her tricks and calculate the number again, it is the same. (Something like the bishop on a red square, and after a number of moves\u2014details unknown\u2014it is still on some red square. It is a law of this nature.) Since it is an abstract idea, we shall illustrate the meaning of it by an analogy. Imagine a child, perhaps \u201cDennis the Menace,\u201d who has blocks which are absolutely indestructible, and cannot be divided into pieces. Each is the same as the other. Let us suppose that he has 28 blocks. His mother puts him with his 28 blocks into a room at the beginning of the day. At the end of the day, being curious, she counts the blocks very carefully, and discovers a phenomenal law\u2014no matter what he does with the blocks, there are always 28 remaining! This continues for a number of days, until one day there are only 27 blocks, but a little investigating shows that there is one under the rug\u2014she must look everywhere to be sure that the number of blocks has not changed. One day, however, the number appears to change\u2014there are only 26 blocks. Careful investigation indicates that the window was open, and upon looking outside, the other two blocks are found. Another day, careful count indicates that there are 30 blocks! This causes considerable consternation, until it is realized that Bruce came to visit, bringing his blocks with him, and he left a few at Dennis\u2019 house. After she has disposed of the extra blocks, she closes the window, does not let Bruce in, and then everything is going along all right, until one time she counts and finds only 25 blocks. However, there is a box in the room, a toy box, and the mother goes to open the toy box, but the boy says \u201cNo, do not open my toy box,\u201d and screams. Mother is not allowed to open the toy box. Being extremely curious, and somewhat ingenious, she invents a scheme! She knows that a block weighs three ounces, so she weighs the box at a time when she sees 28 blocks, and it weighs 16 ounces. The next time she wishes to check, she weighs the box again, subtracts sixteen ounces and divides by three. She discovers the following: ( number of blocks seen ) + (weight of box)\u221216 ounces 3 ounces =constant. There then appear to be some new deviations, but careful study indicates that the dirty water in the bathtub is changing its level. The child is throwing blocks into the water, and she cannot see them because it is so dirty, but she can find out how many blocks are in the water by adding another term to her formula. Since the original height of the water was 6 inches and each block raises the water a quarter of an inch, this new formula would be: ( number of blocks seen ) + (weight of box)\u221216 ounces 3 ounces + (height of water)\u22126 inches 1/4 inch =constant. In the gradual increase in the complexity of her world, she finds a whole series of terms representing ways of calculating how many blocks are in places where she is not allowed to look. As a result, she finds a complex formula, a quantity which has to be computed, which always stays the same in her situation. What is the analogy of this to the conservation of energy? The most remarkable aspect that must be abstracted from this picture is that there are no blocks. Take away the first terms in (4.1) and (4.2) and we find ourselves calculating more or less abstract things. The analogy has the following points. First, when we are calculating the energy, sometimes some of it leaves the system and goes away, or sometimes some comes in. In order to verify the conservation of energy, we must be careful that we have not put any in or taken any out. Second, the energy has a large number of different forms, and there is a formula for each one. These are: gravitational energy, kinetic energy, heat energy, elastic energy, electrical energy, chemical energy, radiant energy, nuclear energy, mass energy. If we total up the formulas for each of these contributions, it will not change except for energy going in and out. It is important to realize that in physics today, we have no knowledge of what energy is. We do not have a picture that energy comes in little blobs of a definite amount. It is not that way. However, there are formulas for calculating some numerical quantity, and when we add it all together it gives \u201c28 \u201d\u2014always the same number. It is an abstract thing in that it does not tell us the mechanism or the reasons for the various formulas. Conservation of energy can be understood only if we have the formula for all of its forms. I wish to discuss the formula for gravitational energy near the surface of the Earth, and I wish to derive this formula in a way which has nothing to do with history but is simply a line of reasoning invented for this particular lecture to give you an illustration of the remarkable fact that a great deal about nature can be extracted from a few facts and close reasoning. It is an illustration of the kind of work theoretical physicists become involved in. It is patterned after a most excellent argument by Mr. Carnot on the efficiency of steam engines.1 Consider weight-lifting machines\u2014machines which have the property that they lift one weight by lowering another. Let us also make a hypothesis: that there is no such thing as perpetual motion with these weight-lifting machines. (In fact, that there is no perpetual motion at all is a general statement of the law of conservation of energy.) We must be careful to define perpetual motion. First, let us do it for weight-lifting machines. If, when we have lifted and lowered a lot of weights and restored the machine to the original condition, we find that the net result is to have lifted a weight, then we have a perpetual motion machine because we can use that lifted weight to run something else. That is, provided the machine which lifted the weight is brought back to its exact original condition, and furthermore that it is completely self-contained\u2014that it has not received the energy to lift that weight from some external source\u2014like Bruce\u2019s blocks. A very simple weight-lifting machine is shown in Fig. 4\u20131. This machine lifts weights three units \u201cstrong.\u201d We place three units on one balance pan, and one unit on the other. However, in order to get it actually to work, we must lift a little weight off the left pan. On the other hand, we could lift a one-unit weight by lowering the three-unit weight, if we cheat a little by lifting a little weight off the other pan. Of course, we realize that with any actual lifting machine, we must add a little extra to get it to run. This we disregard, temporarily. Ideal machines, although they do not exist, do not require anything extra. A machine that we actually use can be, in a sense, almost reversible: that is, if it will lift the weight of three by lowering a weight of one, then it will also lift nearly the weight of one the same amount by lowering the weight of three. We imagine that there are two classes of machines, those that are not reversible, which includes all real machines, and those that are reversible, which of course are actually not attainable no matter how careful we may be in our design of bearings, levers, etc. We suppose, however, that there is such a thing\u2014a reversible machine\u2014which lowers one unit of weight (a pound or any other unit) by one unit of distance, and at the same time lifts a three-unit weight. Call this reversible machine, Machine A . Suppose this particular reversible machine lifts the three-unit weight a distance X . Then suppose we have another machine, Machine B , which is not necessarily reversible, which also lowers a unit weight a unit distance, but which lifts three units a distance Y . We can now prove that Y is not higher than X ; that is, it is impossible to build a machine that will lift a weight any higher than it will be lifted by a reversible machine. Let us see why. Let us suppose that Y were higher than X . We take a one-unit weight and lower it one unit height with Machine B , and that lifts the three-unit weight up a distance Y . Then we could lower the weight from Y to X , obtaining free power, and use the reversible Machine A , running backwards, to lower the three-unit weight a distance X and lift the one-unit weight by one unit height. This will put the one-unit weight back where it was before, and leave both machines ready to be used again! We would therefore have perpetual motion if Y were higher than X , which we assumed was impossible. With those assumptions, we thus deduce that Y is not higher than X , so that of all machines that can be designed, the reversible machine is the best. We can also see that all reversible machines must lift to exactly the same height. Suppose that B were really reversible also. The argument that Y is not higher than X is, of course, just as good as it was before, but we can also make our argument the other way around, using the machines in the opposite order, and prove that X is not higher than Y . This, then, is a very remarkable observation because it permits us to analyze the height to which different machines are going to lift something without looking at the interior mechanism. We know at once that if somebody makes an enormously elaborate series of levers that lift three units a certain distance by lowering one unit by one unit distance, and we compare it with a simple lever which does the same thing and is fundamentally reversible, his machine will lift it no higher, but perhaps less high. If his machine is reversible, we also know exactly how high it will lift. To summarize: every reversible machine, no matter how it operates, which drops one pound one foot and lifts a three-pound weight always lifts it the same distance, X . This is clearly a universal law of great utility. The next question is, of course, what is X ? Suppose we have a reversible machine which is going to lift this distance X , three for one. We set up three balls in a rack which does not move, as shown in Fig. 4\u20132. One ball is held on a stage at a distance one foot above the ground. The machine can lift three balls, lowering one by a distance 1 . Now, we have arranged that the platform which holds three balls has a floor and two shelves, exactly spaced at distance X , and further, that the rack which holds the balls is spaced at distance X , (a). First we roll the balls horizontally from the rack to the shelves, (b), and we suppose that this takes no energy because we do not change the height. The reversible machine then operates: it lowers the single ball to the floor, and it lifts the rack a distance X , (c). Now we have ingeniously arranged the rack so that these balls are again even with the platforms. Thus we unload the balls onto the rack, (d); having unloaded the balls, we can restore the machine to its original condition. Now we have three balls on the upper three shelves and one at the bottom. But the strange thing is that, in a certain way of speaking, we have not lifted two of them at all because, after all, there were balls on shelves 2 and 3 before. The resulting effect has been to lift one ball a distance 3X . Now, if 3X exceeds one foot, then we can lower the ball to return the machine to the initial condition, (f), and we can run the apparatus again. Therefore 3X cannot exceed one foot, for if 3X exceeds one foot we can make perpetual motion. Likewise, we can prove that one foot cannot exceed 3X , by making the whole machine run the opposite way, since it is a reversible machine. Therefore 3X is neither greater nor less than a foot, and we discover then, by argument alone, the law that X= 1 3 foot. The generalization is clear: one pound falls a certain distance in operating a reversible machine; then the machine can lift p pounds this distance divided by p . Another way of putting the result is that three pounds times the height lifted, which in our problem was X , is equal to one pound times the distance lowered, which is one foot in this case. If we take all the weights and multiply them by the heights at which they are now, above the floor, let the machine operate, and then multiply all the weights by all the heights again, there will be no change. (We have to generalize the example where we moved only one weight to the case where when we lower one we lift several different ones\u2014but that is easy.) We call the sum of the weights times the heights gravitational potential energy\u2014the energy which an object has because of its relationship in space, relative to the earth. The formula for gravitational energy, then, so long as we are not too far from the earth (the force weakens as we go higher) is ( gravitational potential energy for one object )=(weight)\u00d7(height). It is a very beautiful line of reasoning. The only problem is that perhaps it is not true. (After all, nature does not have to go along with our reasoning.) For example, perhaps perpetual motion is, in fact, possible. Some of the assumptions may be wrong, or we may have made a mistake in reasoning, so it is always necessary to check. It turns out experimentally, in fact, to be true. The general name of energy which has to do with location relative to something else is called potential energy. In this particular case, of course, we call it gravitational potential energy. If it is a question of electrical forces against which we are working, instead of gravitational forces, if we are \u201clifting\u201d charges away from other charges with a lot of levers, then the energy content is called electrical potential energy. The general principle is that the change in the energy is the force times the distance that the force is pushed, and that this is a change in energy in general: ( change in energy )=(force)\u00d7( distance force acts through ). We will return to many of these other kinds of energy as we continue the course. The principle of the conservation of energy is very useful for deducing what will happen in a number of circumstances. In high school we learned a lot of laws about pulleys and levers used in different ways. We can now see that these \u201claws\u201d are all the same thing, and that we did not have to memorize 75 rules to figure it out. A simple example is a smooth inclined plane which is, happily, a three-four-five triangle (Fig. 4\u20133). We hang a one-pound weight on the inclined plane with a pulley, and on the other side of the pulley, a weight W . We want to know how heavy W must be to balance the one pound on the plane. How can we figure that out? If we say it is just balanced, it is reversible and so can move up and down, and we can consider the following situation. In the initial circumstance, (a), the one pound weight is at the bottom and weight W is at the top. When W has slipped down in a reversible way, (b), we have a one-pound weight at the top and the weight W the slant distance, or five feet, from the plane in which it was before. We lifted the one-pound weight only three feet and we lowered W pounds by five feet. Therefore W= 3 5 of a pound. Note that we deduced this from the conservation of energy, and not from force components. Cleverness, however, is relative. It can be deduced in a way which is even more brilliant, discovered by Stevinus and inscribed on his tombstone.2 Figure 4\u20134 explains that it has to be 3 5 of a pound, because the chain does not go around. It is evident that the lower part of the chain is balanced by itself, so that the pull of the five weights on one side must balance the pull of three weights on the other, or whatever the ratio of the legs. You see, by looking at this diagram, that W must be 3 5 of a pound. (If you get an epitaph like that on your gravestone, you are doing fine.) Let us now illustrate the energy principle with a more complicated problem, the screw jack shown in Fig. 4\u20135. A handle 20 inches long is used to turn the screw, which has 10 threads to the inch. We would like to know how much force would be needed at the handle to lift one ton (2000 pounds). If we want to lift the ton one inch, say, then we must turn the handle around ten times. When it goes around once it goes approximately 126 inches. The handle must thus travel 1260 inches, and if we used various pulleys, etc., we would be lifting our one ton with an unknown smaller weight W applied to the end of the handle. So we find out that W is about 1.6 pounds. This is a result of the conservation of energy. Take now the somewhat more complicated example shown in Fig. 4\u20136. A rod or bar, 8 feet long, is supported at one end. In the middle of the bar is a weight of 60 pounds, and at a distance of two feet from the support there is a weight of 100 pounds. How hard do we have to lift the end of the bar in order to keep it balanced, disregarding the weight of the bar? Suppose we put a pulley at one end and hang a weight on the pulley. How big would the weight W have to be in order for it to balance? We imagine that the weight falls any arbitrary distance\u2014to make it easy for ourselves suppose it goes down 4 inches\u2014how high would the two load weights rise? The center rises 2 inches, and the point a quarter of the way from the fixed end lifts 1 inch. Therefore, the principle that the sum of the heights times the weights does not change tells us that the weight W times 4 inches down, plus 60 pounds times 2 inches up, plus 100 pounds times 1 inch has to add up to nothing: \u22124W+(2)(60)+(1)(100)=0, W=55 lb. Thus we must have a 55 -pound weight to balance the bar. In this way we can work out the laws of \u201cbalance\u201d\u2014the statics of complicated bridge arrangements, and so on. This approach is called the principle of virtual work, because in order to apply this argument we had to imagine that the structure moves a little\u2014even though it is not really moving or even movable. We use the very small imagined motion to apply the principle of conservation of energy. To illustrate another type of energy we consider a pendulum (Fig. 4\u20137). If we pull the mass aside and release it, it swings back and forth. In its motion, it loses height in going from either end to the center. Where does the potential energy go? Gravitational energy disappears when it is down at the bottom; nevertheless, it will climb up again. The gravitational energy must have gone into another form. Evidently it is by virtue of its motion that it is able to climb up again, so we have the conversion of gravitational energy into some other form when it reaches the bottom. We must get a formula for the energy of motion. Now, recalling our arguments about reversible machines, we can easily see that in the motion at the bottom must be a quantity of energy which permits it to rise a certain height, and which has nothing to do with the machinery by which it comes up or the path by which it comes up. So we have an equivalence formula something like the one we wrote for the child\u2019s blocks. We have another form to represent the energy. It is easy to say what it is. The kinetic energy at the bottom equals the weight times the height that it could go, corresponding to its velocity: K.E.=WH . What we need is the formula which tells us the height by some rule that has to do with the motion of objects. If we start something out with a certain velocity, say straight up, it will reach a certain height; we do not know what it is yet, but it depends on the velocity\u2014there is a formula for that. Then to find the formula for kinetic energy for an object moving with velocity V , we must calculate the height that it could reach, and multiply by the weight. We shall soon find that we can write it this way: K.E.=WV2/2g. Of course, the fact that motion has energy has nothing to do with the fact that we are in a gravitational field. It makes no difference where the motion came from. This is a general formula for various velocities. Both (4.3) and (4.6) are approximate formulas, the first because it is incorrect when the heights are great, i.e., when the heights are so high that gravity is weakening; the second, because of the relativistic correction at high speeds. However, when we do finally get the exact formula for the energy, then the law of conservation of energy is correct. We can continue in this way to illustrate the existence of energy in other forms. First, consider elastic energy. If we pull down on a spring, we must do some work, for when we have it down, we can lift weights with it. Therefore in its stretched condition it has a possibility of doing some work. If we were to evaluate the sums of weights times heights, it would not check out\u2014we must add something else to account for the fact that the spring is under tension. Elastic energy is the formula for a spring when it is stretched. How much energy is it? If we let go, the elastic energy, as the spring passes through the equilibrium point, is converted to kinetic energy and it goes back and forth between compressing or stretching the spring and kinetic energy of motion. (There is also some gravitational energy going in and out, but we can do this experiment \u201csideways\u201d if we like.) It keeps going until the losses\u2014Aha! We have cheated all the way through by putting on little weights to move things or saying that the machines are reversible, or that they go on forever, but we can see that things do stop, eventually. Where is the energy when the spring has finished moving up and down? This brings in another form of energy: heat energy. Inside a spring or a lever there are crystals which are made up of lots of atoms, and with great care and delicacy in the arrangement of the parts one can try to adjust things so that as something rolls on something else, none of the atoms do any jiggling at all. But one must be very careful. Ordinarily when things roll, there is bumping and jiggling because of the irregularities of the material, and the atoms start to wiggle inside. So we lose track of that energy; we find the atoms are wiggling inside in a random and confused manner after the motion slows down. There is still kinetic energy, all right, but it is not associated with visible motion. What a dream! How do we know there is still kinetic energy? It turns out that with thermometers you can find out that, in fact, the spring or the lever is warmer, and that there is really an increase of kinetic energy by a definite amount. We call this form of energy heat energy, but we know that it is not really a new form, it is just kinetic energy\u2014internal motion. (One of the difficulties with all these experiments with matter that we do on a large scale is that we cannot really demonstrate the conservation of energy and we cannot really make our reversible machines, because every time we move a large clump of stuff, the atoms do not remain absolutely undisturbed, and so a certain amount of random motion goes into the atomic system. We cannot see it, but we can measure it with thermometers, etc.) There are many other forms of energy, and of course we cannot describe them in any more detail just now. There is electrical energy, which has to do with pushing and pulling by electric charges. There is radiant energy, the energy of light, which we know is a form of electrical energy because light can be represented as wigglings in the electromagnetic field. There is chemical energy, the energy which is released in chemical reactions. Actually, elastic energy is, to a certain extent, like chemical energy, because chemical energy is the energy of the attraction of the atoms, one for the other, and so is elastic energy. Our modern understanding is the following: chemical energy has two parts, kinetic energy of the electrons inside the atoms, so part of it is kinetic, and electrical energy of interaction of the electrons and the protons\u2014the rest of it, therefore, is electrical. Next we come to nuclear energy, the energy which is involved with the arrangement of particles inside the nucleus, and we have formulas for that, but we do not have the fundamental laws. We know that it is not electrical, not gravitational, and not purely kinetic, but we do not know what it is. It seems to be an additional form of energy. Finally, associated with the relativity theory, there is a modification of the laws of kinetic energy, or whatever you wish to call it, so that kinetic energy is combined with another thing called mass energy. An object has energy from its sheer existence. If I have a positron and an electron, standing still doing nothing\u2014never mind gravity, never mind anything\u2014and they come together and disappear, radiant energy will be liberated, in a definite amount, and the amount can be calculated. All we need know is the mass of the object. It does not depend on what it is\u2014we make two things disappear, and we get a certain amount of energy. The formula was first found by Einstein; it is E=mc2 . It is obvious from our discussion that the law of conservation of energy is enormously useful in making analyses, as we have illustrated in a few examples without knowing all the formulas. If we had all the formulas for all kinds of energy, we could analyze how many processes should work without having to go into the details. Therefore conservation laws are very interesting. The question naturally arises as to what other conservation laws there are in physics. There are two other conservation laws which are analogous to the conservation of energy. One is called the conservation of linear momentum. The other is called the conservation of angular momentum. We will find out more about these later. In the last analysis, we do not understand the conservation laws deeply. We do not understand the conservation of energy. We do not understand energy as a certain number of little blobs. You may have heard that photons come out in blobs and that the energy of a photon is Planck\u2019s constant times the frequency. That is true, but since the frequency of light can be anything, there is no law that says that energy has to be a certain definite amount. Unlike Dennis\u2019 blocks, there can be any amount of energy, at least as presently understood. So we do not understand this energy as counting something at the moment, but just as a mathematical quantity, which is an abstract and rather peculiar circumstance. In quantum mechanics it turns out that the conservation of energy is very closely related to another important property of the world, things do not depend on the absolute time. We can set up an experiment at a given moment and try it out, and then do the same experiment at a later moment, and it will behave in exactly the same way. Whether this is strictly true or not, we do not know. If we assume that it is true, and add the principles of quantum mechanics, then we can deduce the principle of the conservation of energy. It is a rather subtle and interesting thing, and it is not easy to explain. The other conservation laws are also linked together. The conservation of momentum is associated in quantum mechanics with the proposition that it makes no difference where you do the experiment, the results will always be the same. As independence in space has to do with the conservation of momentum, independence of time has to do with the conservation of energy, and finally, if we turn our apparatus, this too makes no difference, and so the invariance of the world to angular orientation is related to the conservation of angular momentum. Besides these, there are three other conservation laws, that are exact so far as we can tell today, which are much simpler to understand because they are in the nature of counting blocks. The first of the three is the conservation of charge, and that merely means that you count how many positive, minus how many negative electrical charges you have, and the number is never changed. You may get rid of a positive with a negative, but you do not create any net excess of positives over negatives. Two other laws are analogous to this one\u2014one is called the conservation of baryons. There are a number of strange particles, a neutron and a proton are examples, which are called baryons. In any reaction whatever in nature, if we count how many baryons are coming into a process, the number of baryons3 which come out will be exactly the same. There is another law, the conservation of leptons. We can say that the group of particles called leptons are: electron, muon, and neutrino. There is an antielectron which is a positron, that is, a \u22121 lepton. Counting the total number of leptons in a reaction reveals that the number in and out never changes, at least so far as we know at present. These are the six conservation laws, three of them subtle, involving space and time, and three of them simple, in the sense of counting something. With regard to the conservation of energy, we should note that available energy is another matter\u2014there is a lot of jiggling around in the atoms of the water of the sea, because the sea has a certain temperature, but it is impossible to get them herded into a definite motion without taking energy from somewhere else. That is, although we know for a fact that energy is conserved, the energy available for human utility is not conserved so easily. The laws which govern how much energy is available are called the laws of thermodynamics and involve a concept called entropy for irreversible thermodynamic processes. Finally, we remark on the question of where we can get our supplies of energy today. Our supplies of energy are from the sun, rain, coal, uranium, and hydrogen. The sun makes the rain, and the coal also, so that all these are from the sun. Although energy is conserved, nature does not seem to be interested in it; she liberates a lot of energy from the sun, but only one part in two billion falls on the earth. Nature has conservation of energy, but does not really care; she spends a lot of it in all directions. We have already obtained energy from uranium; we can also get energy from hydrogen, but at present only in an explosive and dangerous condition. If it can be controlled in thermonuclear reactions, it turns out that the energy that can be obtained from 10 quarts of water per second is equal to all of the electrical power generated in the United States. With 150 gallons of running water a minute, you have enough fuel to supply all the energy which is used in the United States today! Therefore it is up to the physicist to figure out how to liberate us from the need for having energy. It can be done."
    },
    {
        "input": "Rotation in Two Dimensions",
        "output": "In the previous chapters we have been studying the mechanics of points, or small particles whose internal structure does not concern us. For the next few chapters we shall study the application of Newton\u2019s laws to more complicated things. When the world becomes more complicated, it also becomes more interesting, and we shall find that the phenomena associated with the mechanics of a more complex object than just a point are really quite striking. Of course these phenomena involve nothing but combinations of Newton\u2019s laws, but it is sometimes hard to believe that only F=ma is at work. The more complicated objects we deal with can be of several kinds: water flowing, galaxies whirling, and so on. The simplest \u201ccomplicated\u201d object to analyze, at the start, is what we call a rigid body, a solid object that is turning as it moves about. However, even such a simple object may have a most complex motion, and we shall therefore first consider the simplest aspects of such motion, in which an extended body rotates about a fixed axis. A given point on such a body then moves in a plane perpendicular to this axis. Such rotation of a body about a fixed axis is called plane rotation or rotation in two dimensions. We shall later generalize the results to three dimensions, but in doing so we shall find that, unlike the case of ordinary particle mechanics, rotations are subtle and hard to understand unless we first get a solid grounding in two dimensions. The first interesting theorem concerning the motion of complicated objects can be observed at work if we throw an object made of a lot of blocks and spokes, held together by strings, into the air. Of course we know it goes in a parabola, because we studied that for a particle. But now our object is not a particle; it wobbles and it jiggles, and so on. It does go in a parabola though; one can see that. What goes in a parabola? Certainly not the point on the corner of the block, because that is jiggling about; neither is it the end of the wooden stick, or the middle of the wooden stick, or the middle of the block. But something goes in a parabola, there is an effective \u201ccenter\u201d which moves in a parabola. So our first theorem about complicated objects is to demonstrate that there is a mean position which is mathematically definable, but not necessarily a point of the material itself, which goes in a parabola. That is called the theorem of the center of the mass, and the proof of it is as follows. We may consider any object as being made of lots of little particles, the atoms, with various forces among them. Let i represent an index which defines one of the particles. (There are millions of them, so i goes to 1023, or something.) Then the force on the ith particle is, of course, the mass times the acceleration of that particle: Fi=mi(d2ri/dt2). In the next few chapters our moving objects will be ones in which all the parts are moving at speeds very much slower than the speed of light, and we shall use the nonrelativistic approximation for all quantities. In these circumstances the mass is constant, so that Fi=d2(miri)/dt2. If we now add the force on all the particles, that is, if we take the sum of all the Fi \u2019s for all the different indexes, we get the total force, F . On the other side of the equation, we get the same thing as though we added before the differentiation: \u2211 i Fi=F= d2(\u2211imiri) dt2 . Therefore the total force is the second derivative of the masses times their positions, added together. Now the total force on all the particles is the same as the external force. Why? Although there are all kinds of forces on the particles because of the strings, the wigglings, the pullings and pushings, and the atomic forces, and who knows what, and we have to add all these together, we are rescued by Newton\u2019s Third Law. Between any two particles the action and reaction are equal, so that when we add all the equations together, if any two particles have forces between them it cancels out in the sum; therefore the net result is only those forces which arise from other particles which are not included in whatever object we decide to sum over. So if Eq. (18.3) is the sum over a certain number of the particles, which together are called \u201cthe object,\u201d then the external force on the total object is equal to the sum of all the forces on all its constituent particles. Now it would be nice if we could write Eq. (18.3) as the total mass times some acceleration. We can. Let us say M is the sum of all the masses, i.e., the total mass. Then if we define a certain vector R to be R= \u2211 i miri/M, Eq. (18.3) will be simply F=d2(MR)/dt2=M(d2R/dt2), since M is a constant. Thus we find that the external force is the total mass times the acceleration of an imaginary point whose location is R . This point is called the center of mass of the body. It is a point somewhere in the \u201cmiddle\u201d of the object, a kind of average r in which the different ri \u2019s have weights or importances proportional to the masses. We shall discuss this important theorem in more detail in a later chapter, and we shall therefore limit our remarks to two points: First, if the external forces are zero, if the object were floating in empty space, it might whirl, and jiggle, and twist, and do all kinds of things. But the center of mass, this artificially invented, calculated position, somewhere in the middle, will move with a constant velocity. In particular, if it is initially at rest, it will stay at rest. So if we have some kind of a box, perhaps a space ship, with people in it, and we calculate the location of the center of mass and find it is standing still, then the center of mass will continue to stand still if no external forces are acting on the box. Of course, the space ship may move a little in space, but that is because the people are walking back and forth inside; when one walks toward the front, the ship goes toward the back so as to keep the average position of all the masses in exactly the same place. Is rocket propulsion therefore absolutely impossible because one cannot move the center of mass? No; but of course we find that to propel an interesting part of the rocket, an uninteresting part must be thrown away. In other words, if we start with a rocket at zero velocity and we spit some gas out the back end, then this little blob of gas goes one way as the rocket ship goes the other, but the center of mass is still exactly where it was before. So we simply move the part that we are interested in against the part we are not interested in. The second point concerning the center of mass, which is the reason we introduced it into our discussion at this time, is that it may be treated separately from the \u201cinternal\u201d motions of an object, and may therefore be ignored in our discussion of rotation. Now let us discuss rotations. Of course an ordinary object does not simply rotate, it wobbles, shakes, and bends, so to simplify matters we shall discuss the motion of a nonexistent ideal object which we call a rigid body. This means an object in which the forces between the atoms are so strong, and of such character, that the little forces that are needed to move it do not bend it. Its shape stays essentially the same as it moves about. If we wish to study the motion of such a body, and agree to ignore the motion of its center of mass, there is only one thing left for it to do, and that is to turn. We have to describe that. How? Suppose there is some line in the body which stays put (perhaps it includes the center of mass and perhaps not), and the body is rotating about this particular line as an axis. How do we define the rotation? That is easy enough, for if we mark a point somewhere on the object, anywhere except on the axis, we can always tell exactly where the object is, if we only know where this point has gone to. The only thing needed to describe the position of that point is an angle. So rotation consists of a study of the variations of the angle with time. In order to study rotation, we observe the angle through which a body has turned. Of course, we are not referring to any particular angle inside the object itself; it is not that we draw some angle on the object. We are talking about the angular change of the position of the whole thing, from one time to another. First, let us study the kinematics of rotations. The angle will change with time, and just as we talked about position and velocity in one dimension, we may talk about angular position and angular velocity in plane rotation. In fact, there is a very interesting relationship between rotation in two dimensions and one-dimensional displacement, in which almost every quantity has its analog. First, we have the angle \u03b8 which defines how far the body has gone around; this replaces the distance s , which defines how far it has gone along. In the same manner, we have a velocity of turning, \u03c9=d\u03b8/dt , which tells us how much the angle changes in a second, just as v=ds/dt describes how fast a thing moves, or how far it moves in a second. If the angle is measured in radians, then the angular velocity \u03c9 will be so and so many radians per second. The greater the angular velocity, the faster the object is turning, the faster the angle changes. We can go on: we can differentiate the angular velocity with respect to time, and we can call \u03b1= d\u03c9/dt= d2\u03b8/dt2 the angular acceleration. That would be the analog of the ordinary acceleration. Now of course we shall have to relate the dynamics of rotation to the laws of dynamics of the particles of which the object is made, so we must find out how a particular particle moves when the angular velocity is such and such. To do this, let us take a certain particle which is located at a distance r from the axis and say it is in a certain location P(x,y) at a given instant, in the usual manner (Fig. 18\u20131). If at a moment \u0394t later the angle of the whole object has turned through \u0394\u03b8 , then this particle is carried with it. It is at the same radius away from O as it was before, but is carried to Q . The first thing we would like to know is how much the distance x changes and how much the distance y changes. If OP is called r , then the length PQ is r\u0394\u03b8 , because of the way angles are defined. The change in x , then, is simply the projection of r\u0394\u03b8 in the x -direction: \u0394x=\u2212PQsin\u03b8=\u2212r\u0394\u03b8\u22c5(y/r)=\u2212y\u0394\u03b8. Similarly, \u0394y=+x\u0394\u03b8. If the object is turning with a given angular velocity \u03c9 , we find, by dividing both sides of (18.6) and (18.7) by \u0394t , that the velocity of the particle is vx=\u2212\u03c9yandvy=+\u03c9x. Of course if we want to find the magnitude of the velocity, we just write v= \u221a v 2 x +v 2 y = \u221a \u03c92y2+\u03c92x2 =\u03c9 \u221a x2+y2 =\u03c9r. It should not be mysterious that the value of the magnitude of this velocity is \u03c9r ; in fact, it should be self-evident, because the distance that it moves is r\u0394\u03b8 and the distance it moves per second is r\u0394\u03b8/\u0394t , or r\u03c9 . Let us now move on to consider the dynamics of rotation. Here a new concept, force, must be introduced. Let us inquire whether we can invent something which we shall call the torque (L. torquere, to twist) which bears the same relationship to rotation as force does to linear movement. A force is the thing that is needed to make linear motion, and the thing that makes something rotate is a \u201crotary force\u201d or a \u201ctwisting force,\u201d i.e., a torque. Qualitatively, a torque is a \u201ctwist\u201d; what is a torque quantitatively? We shall get to the theory of torques quantitatively by studying the work done in turning an object, for one very nice way of defining a force is to say how much work it does when it acts through a given displacement. We are going to try to maintain the analogy between linear and angular quantities by equating the work that we do when we turn something a little bit when there are forces acting on it, to the torque times the angle it turns through. In other words, the definition of the torque is going to be so arranged that the theorem of work has an absolute analog: force times distance is work, and torque times angle is going to be work. That tells us what torque is. Consider, for instance, a rigid body of some kind with various forces acting on it, and an axis about which the body rotates. Let us at first concentrate on one force and suppose that this force is applied at a certain point (x,y) . How much work would be done if we were to turn the object through a very small angle? That is easy. The work done is \u0394W=Fx\u0394x+Fy\u0394y. We need only to substitute Eqs. (18.6) and (18.7) for \u0394x and \u0394y to obtain \u0394W=(xFy\u2212yFx)\u0394\u03b8. That is, the amount of work that we have done is, in fact, equal to the angle through which we have turned the object, multiplied by a strange-looking combination of the force and the distance. This \u201cstrange combination\u201d is what we call the torque. So, defining the change in work as the torque times the angle, we now have the formula for torque in terms of the forces. (Obviously, torque is not a completely new idea independent of Newtonian mechanics\u2014torque must have a definite definition in terms of the force.) When there are several forces acting, the work that is done is, of course, the sum of the works done by all the forces, so that \u0394W will be a whole lot of terms, all added together, for all the forces, each of which is proportional, however, to \u0394\u03b8 . We can take the \u0394\u03b8 outside and therefore can say that the change in the work is equal to the sum of all the torques due to all the different forces that are acting, times \u0394\u03b8 . This sum we might call the total torque, \u03c4 . Thus torques add by the ordinary laws of algebra, but we shall later see that this is only because we are working in a plane. It is like one-dimensional kinematics, where the forces simply add algebraically, but only because they are all in the same direction. It is more complicated in three dimensions. Thus, for two-dimensional rotation, \u03c4i=xiFyi\u2212yiFxi and \u03c4=\u2211\u03c4i. It must be emphasized that the torque is about a given axis. If a different axis is chosen, so that all the xi and yi are changed, the value of the torque is (usually) changed too. Now we pause briefly to note that our foregoing introduction of torque, through the idea of work, gives us a most important result for an object in equilibrium: if all the forces on an object are in balance both for translation and rotation, not only is the net force zero, but the total of all the torques is also zero, because if an object is in equilibrium, no work is done by the forces for a small displacement. Therefore, since \u0394W=\u03c4\u0394\u03b8=0 , the sum of all the torques must be zero. So there are two conditions for equilibrium: that the sum of the forces is zero, and that the sum of the torques is zero. Prove that it suffices to be sure that the sum of torques about any one axis (in two dimensions) is zero. Now let us consider a single force, and try to figure out, geometrically, what this strange thing x F y \u2212y F x amounts to. In Fig. 18\u20132 we see a force F acting at a point r . When the object has rotated through a small angle \u0394\u03b8 , the work done, of course, is the component of force in the direction of the displacement times the displacement. In other words, it is only the tangential component of the force that counts, and this must be multiplied by the distance r\u0394\u03b8 . Therefore we see that the torque is also equal to the tangential component of force (perpendicular to the radius) times the radius. That makes sense in terms of our ordinary idea of the torque, because if the force were completely radial, it would not put any \u201ctwist\u201d on the body; it is evident that the twisting effect should involve only the part of the force which is not pulling out from the center, and that means the tangential component. Furthermore, it is clear that a given force is more effective on a long arm than near the axis. In fact, if we take the case where we push right on the axis, we are not twisting at all! So it makes sense that the amount of twist, or torque, is proportional both to the radial distance and to the tangential component of the force. There is still a third formula for the torque which is very interesting. We have just seen that the torque is the force times the radius times the sine of the angle \u03b1 , in Fig. 18\u20132. But if we extend the line of action of the force and draw the line OS , the perpendicular distance to the line of action of the force (the lever arm of the force) we notice that this lever arm is shorter than r in just the same proportion as the tangential part of the force is less than the total force. Therefore the formula for the torque can also be written as the magnitude of the force times the length of the lever arm. The torque is also often called the moment of the force. The origin of this term is obscure, but it may be related to the fact that \u201cmoment\u201d is derived from the Latin movimentum, and that the capability of a force to move an object (using the force on a lever or crowbar) increases with the length of the lever arm. In mathematics \u201cmoment\u201d means weighted by how far away it is from an axis. Although we have so far considered only the special case of a rigid body, the properties of torques and their mathematical relationships are interesting also even when an object is not rigid. In fact, we can prove a very remarkable theorem: just as external force is the rate of change of a quantity p , which we call the total momentum of a collection of particles, so the external torque is the rate of change of a quantity L which we call the angular momentum of the group of particles. To prove this, we shall suppose that there is a system of particles on which there are some forces acting and find out what happens to the system as a result of the torques due to these forces. First, of course, we should consider just one particle. In Fig. 18\u20133 is one particle of mass m , and an axis O ; the particle is not necessarily rotating in a circle about O , it may be moving in an ellipse, like a planet going around the sun, or in some other curve. It is moving somehow, and there are forces on it, and it accelerates according to the usual formula that the x -component of force is the mass times the x -component of acceleration, etc. But let us see what the torque does. The torque equals x F y \u2212y F x , and the force in the x - or y -direction is the mass times the acceleration in the x - or y -direction: \u03c4 =x F y \u2212y F x =xm( d 2 y/d t 2 )\u2212ym( d 2 x/d t 2 ). (18.14) Now, although this does not appear to be the derivative of any simple quantity, it is in fact the derivative of the quantity xm(dy/dt)\u2212ym(dx/dt) : d dt [ = \u2212 = xm( dy dt )\u2212ym( dx dt )] xm( d 2 y d t 2 )+( dx dt )m( dy dt ) ym( d 2 x d t 2 )\u2212( dy dt )m( dx dt ) xm( d 2 y d t 2 )\u2212ym( d 2 x d t 2 ). (18.15) So it is true that the torque is the rate of change of something with time! So we pay attention to the \u201csomething,\u201d we give it a name: we call it L , the angular momentum: L =xm(dy/dt)\u2212ym(dx/dt) =x p y \u2212y p x . (18.16) Although our present discussion is nonrelativistic, the second form for L given above is relativistically correct. So we have found that there is also a rotational analog for the momentum, and that this analog, the angular momentum, is given by an expression in terms of the components of linear momentum that is just like the formula for torque in terms of the force components! Thus, if we want to know the angular momentum of a particle about an axis, we take only the component of the momentum that is tangential, and multiply it by the radius. In other words, what counts for angular momentum is not how fast it is going away from the origin, but how much it is going around the origin. Only the tangential part of the momentum counts for angular momentum. Furthermore, the farther out the line of the momentum extends, the greater the angular momentum. And also, because the geometrical facts are the same whether the quantity is labeled p or F , it is true that there is a lever arm (not the same as the lever arm of the force on the particle!) which is obtained by extending the line of the momentum and finding the perpendicular distance to the axis. Thus the angular momentum is the magnitude of the momentum times the momentum lever arm. So we have three formulas for angular momentum, just as we have three formulas for the torque: L =x p y \u2212y p x =r p tang =p\u22c5lever arm. (18.17) Like torque, angular momentum depends upon the position of the axis about which it is to be calculated. Before proceeding to a treatment of more than one particle, let us apply the above results to a planet going around the sun. In which direction is the force? The force is toward the sun. What, then, is the torque on the object? Of course, this depends upon where we take the axis, but we get a very simple result if we take it at the sun itself, for the torque is the force times the lever arm, or the component of force perpendicular to r , times r . But there is no tangential force, so there is no torque about an axis at the sun! Therefore, the angular momentum of the planet going around the sun must remain constant. Let us see what that means. The tangential component of velocity, times the mass, times the radius, will be constant, because that is the angular momentum, and the rate of change of the angular momentum is the torque, and, in this problem, the torque is zero. Of course since the mass is also a constant, this means that the tangential velocity times the radius is a constant. But this is something we already knew for the motion of a planet. Suppose we consider a small amount of time \u0394t . How far will the planet move when it moves from P to Q (Fig. 18\u20133)? How much area will it sweep through? Disregarding the very tiny area Q Q \u2032 P compared with the much larger area OPQ , it is simply half the base PQ times the height, OR . In other words, the area that is swept through in unit time will be equal to the velocity times the lever arm of the velocity (times one-half). Thus the rate of change of area is proportional to the angular momentum, which is constant. So Kepler\u2019s law about equal areas in equal times is a word description of the statement of the law of conservation of angular momentum, when there is no torque produced by the force. Now we shall go on to consider what happens when there is a large number of particles, when an object is made of many pieces with many forces acting between them and on them from the outside. Of course, we already know that, about any given fixed axis, the torque on the i th particle (which is the force on the i th particle times the lever arm of that force) is equal to the rate of change of the angular momentum of that particle, and that the angular momentum of the i th particle is its momentum times its momentum lever arm. Now suppose we add the torques \u03c4 i for all the particles and call it the total torque \u03c4 . Then this will be the rate of change of the sum of the angular momenta of all the particles L i , and that defines a new quantity which we call the total angular momentum L . Just as the total momentum of an object is the sum of the momenta of all the parts, so the angular momentum is the sum of the angular momenta of all the parts. Then the rate of change of the total L is the total torque: \u03c4=\u2211 \u03c4 i =\u2211 d L i dt = dL dt . (18.18) Now it might seem that the total torque is a complicated thing. There are all those internal forces and all the outside forces to be considered. But, if we take Newton\u2019s law of action and reaction to say, not simply that the action and reaction are equal, but also that they are directed exactly oppositely along the same line (Newton may or may not actually have said this, but he tacitly assumed it), then the two torques on the reacting objects, due to their mutual interaction, will be equal and opposite because the lever arms for any axis are equal. Therefore the internal torques balance out pair by pair, and so we have the remarkable theorem that the rate of change of the total angular momentum about any axis is equal to the external torque about that axis! \u03c4=\u2211 \u03c4 i = \u03c4 ext =dL/dt. (18.19) Thus we have a very powerful theorem concerning the motion of large collections of particles, which permits us to study the overall motion without having to look at the detailed machinery inside. This theorem is true for any collection of objects, whether they form a rigid body or not. One extremely important case of the above theorem is the law of conservation of angular momentum: if no external torques act upon a system of particles, the angular momentum remains constant. A special case of great importance is that of a rigid body, that is, an object of a definite shape that is just turning around. Consider an object that is fixed in its geometrical dimensions, and which is rotating about a fixed axis. Various parts of the object bear the same relationship to one another at all times. Now let us try to find the total angular momentum of this object. If the mass of one of its particles is m i , and its position or location is at ( x i , y i ) , then the problem is to find the angular momentum of that particle, because the total angular momentum is the sum of the angular momenta of all such particles in the body. For an object going around in a circle, the angular momentum, of course, is the mass times the velocity times the distance from the axis, and the velocity is equal to the angular velocity times the distance from the axis: L i = m i v i r i = m i r 2 i \u03c9, (18.20) or, summing over all the particles i , we get L=I\u03c9, (18.21) where I= \u2211 i m i r 2 i . (18.22) This is the analog of the law that the momentum is mass times velocity. Velocity is replaced by angular velocity, and we see that the mass is replaced by a new thing which we call the moment of inertia I , which is analogous to the mass. Equations (18.21) and (18.22) say that a body has inertia for turning which depends, not just on the masses, but on how far away they are from the axis. So, if we have two objects of the same mass, when we put the masses farther away from the axis, the inertia for turning will be higher. This is easily demonstrated by the apparatus shown in Fig. 18\u20134, where a weight M is kept from falling very fast because it has to turn the large weighted rod. At first, the masses m are close to the axis, and M speeds up at a certain rate. But when we change the moment of inertia by putting the two masses m much farther away from the axis, then we see that M accelerates much less rapidly than it did before, because the body has much more inertia against turning. The moment of inertia is the inertia against turning, and is the sum of the contributions of all the masses, times their distances squared, from the axis. There is one important difference between mass and moment of inertia which is very dramatic. The mass of an object never changes, but its moment of inertia can be changed. If we stand on a frictionless rotatable stand with our arms outstretched, and hold some weights in our hands as we rotate slowly, we may change our moment of inertia by drawing our arms in, but our mass does not change. When we do this, all kinds of wonderful things happen, because of the law of the conservation of angular momentum: If the external torque is zero, then the angular momentum, the moment of inertia times omega, remains constant. Initially, we were rotating with a large moment of inertia I 1 at a low angular velocity \u03c9 1 , and the angular momentum was I 1 \u03c9 1 . Then we changed our moment of inertia by pulling our arms in, say to a smaller value I 2 . Then the product I\u03c9 , which has to stay the same because the total angular momentum has to stay the same, was I 2 \u03c9 2 . So I 1 \u03c9 1 = I 2 \u03c9 2 . That is, if we reduce the moment of inertia, we have to increase the angular velocity."
    },
    {
        "input": "The Kinetic Theory of Gases",
        "output": "With this chapter we begin a new subject which will occupy us for some time. It is the first part of the analysis of the properties of matter from the physical point of view, in which, recognizing that matter is made out of a great many atoms, or elementary parts, which interact electrically and obey the laws of mechanics, we try to understand why various aggregates of atoms behave the way they do. It is obvious that this is a difficult subject, and we emphasize at the beginning that it is in fact an extremely difficult subject, and that we have to deal with it differently than we have dealt with the other subjects so far. In the case of mechanics and in the case of light, we were able to begin with a precise statement of some laws, like Newton\u2019s laws, or the formula for the field produced by an accelerating charge, from which a whole host of phenomena could be essentially understood, and which would produce a basis for our understanding of mechanics and of light from that time on. That is, we may learn more later, but we do not learn different physics, we only learn better methods of mathematical analysis to deal with the situation. We cannot use this approach effectively in studying the properties of matter. We can discuss matter only in a most elementary way; it is much too complicated a subject to analyze directly from its specific basic laws, which are none other than the laws of mechanics and electricity. But these are a bit too far away from the properties we wish to study; it takes too many steps to get from Newton\u2019s laws to the properties of matter, and these steps are, in themselves, fairly complicated. We will now start to take some of these steps, but while many of our analyses will be quite accurate, they will eventually get less and less accurate. We will have only a rough understanding of the properties of matter. One of the reasons that we have to perform the analysis so imperfectly is that the mathematics of it requires a deep understanding of the theory of probability; we are not going to want to know where every atom is actually moving, but rather, how many move here and there on the average, and what the odds are for different effects. So this subject involves a knowledge of the theory of probability, and our mathematics is not yet quite ready and we do not want to strain it too hard. Secondly, and more important from a physical standpoint, the actual behavior of the atoms is not according to classical mechanics, but according to quantum mechanics, and a correct understanding of the subject cannot be attained until we understand quantum mechanics. Here, unlike the case of billiard balls and automobiles, the difference between the classical mechanical laws and the quantum-mechanical laws is very important and very significant, so that many things that we will deduce by classical physics will be fundamentally incorrect. Therefore there will be certain things to be partially unlearned; however, we shall indicate in every case when a result is incorrect, so that we will know just where the \u201cedges\u201d are. One of the reasons for discussing quantum mechanics in the preceding chapters was to give an idea as to why, more or less, classical mechanics is incorrect in the various directions. Why do we deal with the subject now at all? Why not wait half a year, or a year, until we know the mathematics of probability better, and we learn a little quantum mechanics, and then we can do it in a more fundamental way? The answer is that it is a difficult subject, and the best way to learn is to do it slowly! The first thing to do is to get some idea, more or less, of what ought to happen in different circumstances, and then, later, when we know the laws better, we will formulate them better. Anyone who wants to analyze the properties of matter in a real problem might want to start by writing down the fundamental equations and then try to solve them mathematically. Although there are people who try to use such an approach, these people are the failures in this field; the real successes come to those who start from a physical point of view, people who have a rough idea where they are going and then begin by making the right kind of approximations, knowing what is big and what is small in a given complicated situation. These problems are so complicated that even an elementary understanding, although inaccurate and incomplete, is worthwhile having, and so the subject will be one that we shall go over again and again, each time with more and more accuracy, as we go through our course in physics. Another reason for beginning the subject right now is that we have already used many of these ideas in, for example, chemistry, and we have even heard of some of them in high school. It is interesting to know the physical basis for these things. As an interesting example, we all know that equal volumes of gases, at the same pressure and temperature, contain the same number of molecules. The law of multiple proportions, that when two gases combine in a chemical reaction the volumes needed always stand in simple integral proportions, was understood ultimately by Avogadro to mean that equal volumes have equal numbers of atoms. Now why do they have equal numbers of atoms? Can we deduce from Newton\u2019s laws that the number of atoms should be equal? We shall address ourselves to that specific matter in this chapter. In succeeding chapters, we shall discuss various other phenomena involving pressures, volumes, temperature, and heat. We shall also find that the subject can be attacked from a nonatomic point of view, and that there are many interrelationships of the properties of substances. For instance, when we compress something, it heats; if we heat it, it expands. There is a relationship between these two facts which can be deduced independently of the machinery underneath. This subject is called thermodynamics. The deepest understanding of thermodynamics comes, of course, from understanding the actual machinery underneath, and that is what we shall do: we shall take the atomic viewpoint from the beginning and use it to understand the various properties of matter and the laws of thermodynamics. Let us, then, discuss the properties of gases from the standpoint of Newton\u2019s laws of mechanics. First, we know that a gas exerts a pressure, and we must clearly understand what this is due to. If our ears were a few times more sensitive, we would hear a perpetual rushing noise. Evolution has not developed the ear to that point, because it would be useless if it were so much more sensitive\u2014we would hear a perpetual racket. The reason is that the eardrum is in contact with the air, and air is a lot of molecules in perpetual motion and these bang against the eardrums. In banging against the eardrums they make an irregular tattoo\u2014boom, boom, boom\u2014which we do not hear because the atoms are so small, and the sensitivity of the ear is not quite enough to notice it. The result of this perpetual bombardment is to push the drum away, but of course there is an equal perpetual bombardment of atoms on the other side of the eardrum, so the net force on it is zero. If we were to take the air away from one side, or change the relative amounts of air on the two sides, the eardrum would then be pushed one way or the other, because the amount of bombardment on one side would be greater than on the other. We sometimes feel this uncomfortable effect when we go up too fast in an elevator or an airplane, especially if we also have a bad cold (when we have a cold, inflammation closes the tube which connects the air on the inside of the eardrum with the outside air through the throat, so that the two pressures cannot readily equalize). In considering how to analyze the situation quantitatively, we imagine that we have a volume of gas in a box, at one end of which is a piston which can be moved (Fig. 39\u20131). We would like to find out what force on the piston results from the fact that there are atoms in this box. The volume of the box is V , and as the atoms move around inside the box with various velocities they bang against the piston. Suppose there is nothing, a vacuum, on the outside of the piston. What of it? If the piston were left alone, and nobody held onto it, each time it got banged it would pick up a little momentum and it would gradually get pushed out of the box. So in order to keep it from being pushed out of the box, we have to hold it with a force F . The problem is, how much force? One way of expressing the force is to talk about the force per unit area: if A is the area of the piston, then the force on the piston will be written as a number times the area. We define the pressure, then, as equal to the force that we have to apply on a piston, divided by the area of the piston: P=F/A. To make sure we understand the idea (we have to derive it for another purpose anyway), the differential work dW done on the gas in compressing it by moving the piston in a differential amount \u2212dx would be the force times the distance that we compress it, which, according to (39.1), would be the pressure times the area, times the distance, which is equal to minus the pressure times the change in the volume: dW=F(\u2212dx)=\u2212PAdx=\u2212PdV. (The area A times the distance dx is the volume change.) The minus sign is there because, as we compress it, we decrease the volume; if we think about it we can see that if a gas is compressed, work is done on it. How much force do we have to apply to balance the banging of the molecules? The piston receives from each collision a certain amount of momentum. A certain amount of momentum per second will pour into the piston, and it will start to move. To keep it from moving, we must pour back into it the same amount of momentum per second from our force. Of course, the force is the amount of momentum per second that we must pour in. There is another way to put it: if we let go of the piston it will pick up speed because of the bombardments; with each collision we get a little more speed, and the speed thus accelerates. The rate at which the piston picks up speed, or accelerates, is proportional to the force on it. So we see that the force, which we already have said is the pressure times the area, is equal to the momentum per second delivered to the piston by the colliding molecules. To calculate the momentum per second is easy\u2014we can do it in two parts: first, we find the momentum delivered to the piston by one particular atom in a collision with the piston, then we have to multiply by the number of collisions per second that the atoms have with the wall. The force will be the product of these two factors. Now let us see what the two factors are: In the first place, we shall suppose that the piston is a perfect \u201creflector\u201d for the atoms. If it is not, the whole theory is wrong, and the piston will start to heat up and things will change, but eventually, when equilibrium has set in, the net result is that the collisions are effectively perfectly elastic. On the average, every particle that comes in leaves with the same energy. So we shall imagine that the gas is in a steady condition, and we lose no energy to the piston because the piston is standing still. In those circumstances, if a particle comes in with a certain speed, it comes out with the same speed and, we will say, with the same mass. If v is the velocity of an atom, and vx is the x -component of v , then mvx is the x -component of momentum \u201cin\u201d; but we also have an equal component of momentum \u201cout,\u201d and so the total momentum delivered to the piston by the particle, in one collision, is 2mvx , because it is \u201creflected.\u201d Now, we need the number of collisions made by the atoms in a second, or in a certain amount of time dt ; then we divide by dt . How many atoms are hitting? Let us suppose that there are N atoms in the volume V , or n=N/V in each unit volume. To find how many atoms hit the piston, we note that, given a certain amount of time t , if a particle has a certain velocity toward the piston it will hit during the time t , provided it is close enough. If it is too far away, it goes only part way toward the piston in the time t , but does not reach the piston. Therefore it is clear that only those molecules which are within a distance vxt from the piston are going to hit the piston in the time t . Thus the number of collisions in a time t is equal to the number of atoms which are in the region within a distance vxt , and since the area of the piston is A , the volume occupied by the atoms which are going to hit the piston is vxtA . But the number of atoms that are going to hit the piston is that volume times the number of atoms per unit volume, nvxtA . Of course we do not want the number that hit in a time t , we want the number that hit per second, so we divide by the time t , to get nvxA . (This time t could be made very short; if we feel we want to be more elegant, we call it dt , then differentiate, but it is the same thing.) So we find that the force is F=nvxA\u22c52mvx. See, the force is proportional to the area, if we keep the particle density fixed as we change the area! The pressure is then P=2nmv 2 x . Now we notice a little trouble with this analysis: First, all the molecules do not have the same velocity, and they do not move in the same direction. So, all the v 2 x \u2019s are different! So what we must do, of course, is to take an average of the v 2 x \u2019s, since each one makes its own contribution. What we want is the square of vx , averaged over all the molecules: P=nm\u27e8v 2 x \u27e9. Did we forget to include the factor 2 ? No; of all the atoms, only half are headed toward the piston. The other half are headed the other way, so the number of atoms per unit volume that are hitting the piston is only n/2 . Now as the atoms bounce around, it is clear that there is nothing special about the \u201cx -direction\u201d; the atoms may also be moving up and down, back and forth, in and out. Therefore it is going to be true that \u27e8v 2 x \u27e9 , the average motion of the atoms in one direction, and the average in the other two directions, are all going to be equal: \u27e8v 2 x \u27e9=\u27e8v 2 y \u27e9=\u27e8v 2 z \u27e9. It is only a matter of rather tricky mathematics to notice, therefore, that they are each equal to one-third of their sum, which is of course the square of the magnitude of the velocity: \u27e8v 2 x \u27e9= 1 3 \u27e8v 2 x +v 2 y +v 2 z \u27e9=\u27e8v2\u27e9/3. This has the advantage that we do not have to worry about any particular direction, and so we write our pressure formula again in this form: P=( 2 3 )n\u27e8mv2/2\u27e9. The reason we wrote the last factor as \u27e8mv2/2\u27e9 is that this is the kinetic energy of the center-of-mass motion of the molecule. We find, therefore, that PV=N( 2 3 )\u27e8mv2/2\u27e9. With this equation we can calculate how much the pressure is, if we know the speeds. As a very simple example let us take helium gas, or any other gas, like mercury vapor, or potassium vapor of high enough temperature, or argon, in which all the molecules are single atoms, for which we may suppose that there is no internal motion in the atom. If we had a complex molecule, there might be some internal motion, mutual vibrations, or something. We suppose that we may disregard that; this is actually a serious matter that we will have to come back to, but it turns out to be all right. We suppose that the internal motion of the atoms can be disregarded, and therefore, for this purpose, that the kinetic energy of the center-of-mass motion is all the energy there is. So for a monatomic gas, the kinetic energy is the total energy. In general, we are going to call U the total energy (it is sometimes called the total internal energy\u2014we may wonder why, since there is no external energy to a gas), i.e., all the energy of all the molecules in the gas, or the object, whatever it is. For a monatomic gas we will suppose that the total energy U is equal to a number of atoms times the average kinetic energy of each, because we are disregarding any possibility of excitation or motion inside the atoms themselves. Then, in these circumstances, we would have PV= 2 3 U. (39.10) Incidentally, we can stop here and find the answer to the following question: Suppose that we take a can of gas and compress the gas slowly, how much pressure do we need to squeeze the volume down? It is easy to find out, since the pressure is 2 3 the energy divided by V . As we squeeze it down, we do work on the gas and we thereby increase the energy U . So we are going to have some kind of a differential equation: If we start out in a given circumstance with a certain energy and a certain volume, we then know the pressure. Now we start to squeeze, but the moment we do, the energy U increases and the volume V decreases, so the pressure goes up. So, we have to solve a differential equation, and we will solve it in a moment. We must first emphasize, however, that as we are compressing this gas, we are supposing that all the work goes into increasing the energy of the atoms inside. We may ask, \u201cIsn\u2019t that necessary? Where else could it go?\u201d It turns out that it can go another place. There are what we call \u201cheat leaks\u201d through the walls: the hot (i.e., fast-moving) atoms that bombard the walls, heat the walls, and energy goes away. We shall suppose for the present that this is not the case. For somewhat wider generality, although we are still making some very special assumptions about our gas, we shall write, not PV= 2 3 U , but PV=(\u03b3\u22121)U. (39.11) It is written (\u03b3\u22121) times U for conventional reasons, because we will deal with a few other cases later where the number in front of U will not be 2 3 , but will be a different number. So, in order to do the thing in general, we call it \u03b3\u22121 , because people have been calling it that for almost one hundred years. This \u03b3 , then, is 5 3 for a monatomic gas like helium, because 5 3 \u22121 is 2 3 . We have already noticed that when we compress a gas the work done is \u2212PdV . A compression in which there is no heat energy added or removed is called an adiabatic compression, from the Greek a (not) + dia (through) + bainein (to go). (The word adiabatic is used in physics in several ways, and it is sometimes hard to see what is common about them.) That is, for an adiabatic compression all the work done goes into changing the internal energy. That is the key\u2014that there are no other losses of energy\u2014for then we have PdV=\u2212dU . But since U=PV/(\u03b3\u22121) , we may write dU=(PdV+VdP)/(\u03b3\u22121). (39.12) So we have PdV=\u2212(PdV+VdP)/(\u03b3\u22121) , or, rearranging the terms, \u03b3PdV=\u2212VdP , or (\u03b3dV/V)+(dP/P)=0. (39.13) Fortunately, assuming that \u03b3 is constant, as it is for a monatomic gas, we can integrate this: it gives \u03b3lnV+lnP=lnC , where lnC is the constant of integration. If we take the exponential of both sides, we get the law P V \u03b3 =C (a constant). (39.14) In other words, under adiabatic conditions, where the temperature rises as we compress because no heat is being lost, the pressure times the volume to the 5 3 power is a constant for a monatomic gas! Although we derived it theoretically, this is, in fact, the way monatomic gases behave experimentally. We may give one other example of the kinetic theory of a gas, one which is not used in chemistry so much, but is used in astronomy. We have a large number of photons in a box in which the temperature is very high. (The box is, of course, the gas in a very hot star. The sun is not hot enough; there are still too many atoms, but at still higher temperatures in certain very hot stars, we may neglect the atoms and suppose that the only objects that we have in the box are photons.) Now then, a photon has a certain momentum p . (We always find that we are in terrible trouble when we do kinetic theory: p is the pressure, but p is the momentum; v is the volume, but v is the velocity; T is the temperature, but T is the kinetic energy or the time or the torque; one must keep one\u2019s wits about one!) This p is momentum, it is a vector. Going through the same analysis as before, it is the x -component of the vector p which generates the \u201ckick,\u201d and twice the x -component of the vector p is the momentum which is given in the kick. Thus 2 p x replaces 2m v x , and in evaluating the number of collisions, v x is still v x , so when we get all the way through, we find that the pressure in Eq. (39.4) is, instead, P=2n p x v x . (39.15) Then, in the averaging, it becomes n times the average of p x v x (the same factor of 2 ) and, finally, putting in the other two directions, we find PV=N\u27e8p\u22c5v\u27e9/3. (39.16) This checks with the formula (39.9), because the momentum is mv ; it is a little more general, that is all. The pressure times the volume is the total number of atoms times 1 3 (p\u22c5v) , averaged. Now, for photons, what is p\u22c5v ? The momentum and the velocity are in the same direction, and the velocity is the speed of light, so this is the momentum of each of the objects, times the speed of light. The momentum times the speed of light of every photon is its energy: E=pc , so these terms are the energies of each of the photons, and we should, of course, take an average energy, times the number of photons. So we have 1 3 of the energy inside the gas: PV=U/3 (photon gas). (39.17) For photons, then, since we have 1 3 in front, (\u03b3\u22121) in (39.11) is 1 3 , or \u03b3= 4 3 , and we have discovered that radiation in a box obeys the law P V 4/3 =C. (39.18) So we know the compressibility of radiation! That is what is used in an analysis of the contribution of radiation pressure in a star, that is how we calculate it, and how it changes when we compress it. What wonderful things are already within our power! So far we have not dealt with temperature; we have purposely been avoiding the temperature. As we compress a gas, we know that the energy of the molecules increases, and we are used to saying that the gas gets hotter; we would like to understand what this has to do with the temperature. If we try to do the experiment, not adiabatically but at what we call constant temperature, what are we doing? We know that if we take two boxes of gas and let them sit next to each other long enough, even if at the start they were at what we call different temperatures, they will in the end come to the same temperature. Now what does that mean? That means that they get to a condition that they would get to if we left them alone long enough! What we mean by equal temperature is just that\u2014the final condition when things have been sitting around interacting with each other long enough. Let us consider, now, what happens if we have two gases in containers separated by a movable piston as in Fig. 39\u20132 (just for simplicity we shall take two monatomic gases, say helium and neon). In container (1) the atoms have mass m 1 , velocity v 1 , and there are n 1 per unit volume, and in the other container the atoms have mass m 2 , velocity v 2 , there are n 2 atoms per unit volume. What are the conditions for equilibrium? Obviously, the bombardment from the left side must be such that it moves the piston to the right and compresses the other gas until its pressure builds up, and the thing will thus slosh back and forth, and will gradually come to rest at a place where the pressures are equal on both sides. So we can arrange that the pressures are equal; that just means that the internal energies per unit volume are equal, or that the numbers n times the average kinetic energies on each side are equal. What we have to try to prove, eventually, is that the numbers themselves are equal. So far, all we know is that the numbers times the kinetic energies are equal, n 1 \u27e8 m 1 v 2 1 /2\u27e9= n 2 \u27e8 m 2 v 2 2 /2\u27e9, 2 2 from (39.8), because the pressures are equal. We must realize that this is not the only condition over the long run, but something else must happen more slowly as the true complete equilibrium corresponding to equal temperatures sets in. To see the idea, suppose that the pressure on the left side were developed by having a very high density but a low velocity. By having a large n and a small v , we can get the same pressure as by having a small n and a large v . The atoms may be moving slowly but be packed nearly solidly, or there may be fewer but they are hitting harder. Will it stay like that forever? At first we might think so, but then we think again and find we have forgotten one important point. That is, that the intermediate piston does not receive a steady pressure; it wiggles, just like the eardrum that we were first talking about, because the bangings are not absolutely uniform. There is not a perpetual, steady pressure, but a tattoo\u2014the pressure varies, and so the thing jiggles. Suppose that the atoms on the right side are not jiggling much, but those on the left are few and far between and very energetic. The piston will, now and then, get a big impulse from the left, and will be driven against the slow atoms on the right, giving them more speed. (As each atom collides with the piston, it either gains or loses energy, depending upon whether the piston is moving one way or the other when the atom strikes it.) So, as a result of the collisions, the piston finds itself jiggling, jiggling, jiggling, and this shakes the other gas\u2014it gives energy to the other atoms, and they build up faster motions, until they balance the jiggling that the piston is giving to them. The system comes to some equilibrium where the piston is moving at such a mean square speed that it picks up energy from the atoms at about the same rate as it puts energy back into them. So the piston picks up a certain mean irregularity in speed, and it is our problem to find it. When we do find it, we can solve our problem better, because the gases will adjust their velocities until the rate at which they are trying to pour energy into each other through the piston will become equal. It is quite difficult to figure out the details of the piston in this particular circumstance; although it is ideally simple to understand, it turns out to be a little harder to analyze. Before we analyze that, let us analyze another problem in which we have a box of gas but now we have two different kinds of molecules in it, having masses m 1 and m 2 , velocities v 1 and v 2 , and so forth; there is now a much more intimate relationship. If all of the No. 2 molecules are standing still, that condition is not going to last, because they get kicked by the No. 1 molecules and so pick up speed. If they are all going much faster than the No. 1 molecules, then maybe that will not last either\u2014they will pass the energy back to the No. 1 molecules. So when both gases are in the same box, the problem is to find the rule that determines the relative speeds of the two. This is still a very difficult problem, but we will solve it as follows. First we consider the following sub-problem (again this is one of those cases where\u2014never mind the derivation\u2014in the end the result is very simple to remember, but the derivation is just ingenious). Let us suppose that we have two molecules, of different mass, colliding, and that the collision is viewed in the center-of-mass (CM) system. In order to remove a complication, we look at the collision in the CM. As we know from the laws of collision, by the conservation of momentum and energy, after the molecules collide the only way they can move is such that each maintains its own original speed\u2014and they just change their direction. So we have an average collision that looks like that in Fig. 39\u20133. Suppose, for a moment, that we watch all the collisions with the CM at rest. Suppose we imagine that they are all initially moving horizontally. Of course, after the first collision some of them are moving at an angle. In other words, if they were all going horizontally, then at least some would later be moving vertically. Now in some other collision, they would be coming in from another direction, and then they would be twisted at still another angle. So even if they were completely organized in the beginning, they would get sprayed around at all angles, and then the sprayed ones would get sprayed some more, and sprayed some more, and sprayed some more. Ultimately, what will be the distribution? Answer: It will be equally likely to find any pair moving in any direction in space. After that further collisions could not change the distribution. They are equally likely to go in all directions, but how do we say that? There is of course no likelihood that they will go in any specific direction, because a specific direction is too exact, so we have to talk about per unit \u201csomething.\u201d The idea is that any area on a sphere centered at a collision point will have just as many molecules going through it as go through any other equal area on the sphere. So the result of the collisions will be to distribute the directions so that equal areas on a sphere will have equal probabilities. Incidentally, if we just want to discuss the original direction and some other direction an angle \u03b8 from it, it is an interesting property that the differential area of a sphere of unit radius is sin\u03b8d\u03b8 times 2\u03c0 (see Fig. 32\u20131). And sin\u03b8d\u03b8 is the same as the differential of \u2212cos\u03b8 . So what it means is that the cosine of the angle \u03b8 between any two directions is equally likely to be anything from \u22121 to +1 . Next, we have to worry about the actual case, where we do not have the collision in the CM system, but we have two atoms which are coming together with vector velocities v 1 and v 2 . What happens now? We can analyze this collision with the vector velocities v 1 and v 2 in the following way: We first say that there is a certain CM; the velocity of the CM is given by the \u201caverage\u201d velocity, with weights proportional to the masses, so the velocity of the CM is v CM =( m 1 v 1 + m 2 v 2 )/( m 1 + m 2 ) . If we watch this collision in the CM system, then we see a collision just like that in Fig. 39\u20133, with a certain relative velocity w coming in. The relative velocity is just v 1 \u2212 v 2 . Now the idea is that, first, the whole CM is moving, and in the CM there is a relative velocity w , and the molecules collide and come off in some new direction. All this happens while the CM keeps right on moving, without any change. Now then, what is the distribution resulting from this? From our previous argument we conclude this: that at equilibrium, all directions for w are equally likely, relative to the direction of the motion of the CM.1 There will be no particular correlation, in the end, between the direction of the motion of the relative velocity and that of the motion of the CM. Of course, if there were, the collisions would spray it about, so it is all sprayed around. So the cosine of the angle between w and v CM is zero on the average. That is, \u27e8w\u22c5 v CM \u27e9=0. (39.19) But w\u22c5 v CM can be expressed in terms of v 1 and v 2 as well: w\u22c5 v CM = ( v 1 \u2212 v 2 )\u22c5( m 1 v 1 + m 2 v 2 ) m 1 + m 2 = ( m 1 v 2 1 \u2212 m 2 v 2 2 )+( m 2 \u2212 m 1 )( v 1 \u22c5 v 2 ) m 1 + m 2 . (39.20) First, let us look at the v 1 \u22c5 v 2 ; what is the average of v 1 \u22c5 v 2 ? That is, what is the average of the component of velocity of one molecule in the direction of another? Surely there is just as much likelihood of finding any given molecule moving one way as another. The average of the velocity v 2 in any direction is zero. Certainly, then, in the direction of v 1 , v 2 has zero average. So, the average of v 1 \u22c5 v 2 is zero! Therefore, we conclude that the average of m 1 v 2 1 must be equal to the average of m 2 v 2 2 . That is, the average kinetic energy of the two must be equal: \u27e8 1 2 m 1 v 2 1 \u27e9=\u27e8 1 2 m 2 v 2 2 \u27e9. (39.21) If we have two kinds of atoms in a gas, it can be shown, and we presume to have shown it, that the average of the kinetic energy of one is the same as the average of the kinetic energy of the other, when they are both in the same gas in the same box in equilibrium. That means that the heavy ones will move slower than the light ones; this is easily shown by experimentation with \u201catoms\u201d of different masses in an air trough. Now we would like to go one step further, and say that if we have two different gases separated in a box, they will also have equal average kinetic energy when they have finally come to equilibrium, even though they are not in the same box. We can make the argument in a number of ways. One way is to argue that if we have a fixed partition with a tiny hole in it (Fig. 39\u20134) so that one gas could leak out through the holes while the other could not, because the molecules are too big, and these had attained equilibrium, then we know that in one part, where they are mixed, they have the same average kinetic energy, but some come through the hole without loss of kinetic energy, so the average kinetic energy in the pure gas and in the mixture must be the same. That is not too satisfactory, because maybe there are no holes, for this kind of molecule, that separate one kind from the other. Let us now go back to the piston problem. We can give an argument which shows that the kinetic energy of this piston must also be 1 2 m 2 v 2 2 . Actually, that would be the kinetic energy due to the purely horizontal motion of the piston, so, forgetting its up and down motion, it will have to be the same as 1 2 m 2 v 2 2 x . Likewise, from the equilibrium on the other side, we can prove that the kinetic energy of the piston is 1 2 m 1 v 2 1 x . Although this is not in the middle of the gas, but is on one side of the gas, we can still make the argument, although it is a little more difficult, that the average kinetic energy of the piston and of the gas molecules are equal as a result of all the collisions. If this still does not satisfy us, we may make an artificial example by which the equilibrium is generated by an object which can be hit on all sides. Suppose that we have a short rod with a ball on each end sticking through the piston, on a frictionless sliding universal joint. Each ball is round, like one of the molecules, and can be hit on all sides. This whole object has a certain total mass, m . Now, we have the gas molecules with mass m 1 and mass m 2 as before. The result of the collisions, by the analysis that was made before, is that the kinetic energy of m because of collisions with the molecules on one side must be 1 2 m 1 v 2 1 , on the average. Likewise, because of the collisions with molecules on the other side, it has to be 1 2 m 2 v 2 2 on the average. So, therefore, both sides have to have the same kinetic energy when they are in thermal equilibrium. So, although we only proved it for a mixture of gases, it is easily extended to the case where there are two different, separate gases at the same temperature. Thus when we have two gases at the same temperature, the mean kinetic energy of the CM motions are equal. The mean molecular kinetic energy is a property only of the \u201ctemperature.\u201d Being a property of the \u201ctemperature,\u201d and not of the gas, we can use it as a definition of the temperature. The mean kinetic energy of a molecule is thus some function of the temperature. But who is to tell us what scale to use for the temperature? We may arbitrarily define the scale of temperature so that the mean energy is linearly proportional to the temperature. The best way to do it would be to call the mean energy itself \u201cthe temperature.\u201d That would be the simplest possible function. Unfortunately, the scale of temperature has been chosen differently, so instead of calling it temperature directly we use a constant conversion factor between the energy of a molecule and a degree of absolute temperature called a degree Kelvin. The constant of proportionality is k=1.38\u00d7 10 \u221223 joule for every degree Kelvin.2 So if T is absolute temperature, our definition says that the mean molecular kinetic energy is 3 2 kT . (The 3 2 is put in as a matter of convenience, so as to get rid of it somewhere else.) We point out that the kinetic energy associated with the component of motion in any particular direction is only 1 2 kT . The three independent directions that are involved make it 3 2 kT . Now, of course, we can put our definition of temperature into Eq. (39.9) and so find the law for the pressure of gases as a function of the temperature: it is that the pressure times the volume is equal to the total number of atoms times the universal constant k , times the temperature: PV=NkT. (39.22) Furthermore, at the same temperature and pressure and volume, the number of atoms is determined; it too is a universal constant! So equal volumes of different gases, at the same pressure and temperature, have the same number of molecules, because of Newton\u2019s laws. That is an amazing conclusion! In practice, when dealing with molecules, because the numbers are so large, the chemists have artificially chosen a specific number, a very large number, and called it something else. They have a number which they call a mole. A mole is merely a handy number. Why they did not choose 10 24 objects, so it would come out even, is a historical question. They happened to choose, for the convenient number of objects on which they standardize, N 0 =6.02\u00d7 10 23 objects, and this is called a mole of objects. So instead of measuring the number of molecules in units, they measure in terms of numbers of moles.3 In terms of N 0 we can write the number of moles, times the number of atoms in a mole, times kT , and if we want to, we can take the number of atoms in a mole times k , which is a mole\u2019s worth of k , and call it something else, and we do\u2014we call it R . A mole\u2019s worth of k is 8.317 joules: R= N 0 k=8.317 J \u22c5 mole \u22121 \u22c5 \u2218 K \u22121 . Thus we also find the gas law written as the number of moles (also called N ) times RT , or the number of atoms, times kT : PV=NRT. (39.23) It is the same thing, just a different scale for measuring numbers. We use 1 as a unit, and chemists use 6\u00d7 10 23 as a unit! We now make one more remark about our gas law, and that has to do with the law for objects other than monatomic molecules. We have dealt only with the CM motion of the atoms of a monatomic gas. What happens if there are forces present? First, consider the case that the piston is held by a horizontal spring, and there are forces on it. The exchange of jiggling motion between atoms and piston at any moment does not depend on where the piston is at that moment, of course. The equilibrium conditions are the same. No matter where the piston is, its speed of motion must be such that it passes energy to the molecules in just the right way. So it makes no difference about the spring. The speed at which the piston has to move, on the average, is the same. So our theorem, that the mean value of the kinetic energy in one direction is 1 2 kT , is true whether there are forces present or not. Consider, for example, a diatomic molecule composed of atoms m A and m B . What we have proved is that the motion of the CM of part A and that of part B are such that \u27e8 1 2 m A v 2 A \u27e9=\u27e8 1 2 m B v 2 B \u27e9= 3 2 kT . How can this be, if they are held together? Although they are held together, when they are spinning and turning in there, when something hits them, exchanging energy with them, the only thing that counts is how fast they are moving. That alone determines how fast they exchange energy in collisions. At the particular instant, the force is not an essential point. Therefore the same principle is right, even when there are forces. Let us prove, finally, that the gas law is consistent also with a disregard of the internal motion. We did not really include the internal motions before; we just treated a monatomic gas. But we shall now show that an entire object, considered as a single body of total mass M , has a velocity of the CM such that \u27e8 1 2 M v 2 CM \u27e9= 3 2 kT. (39.24) In other words, we can consider either the separate pieces or the whole thing! Let us see the reason for that: The mass of the diatomic molecule is M= m A + m B , and the velocity of the center of mass is equal to v CM =( m A v A + m B v B )/M . Now we need \u27e8 v 2 CM \u27e9 . If we square v CM , we get v 2 CM = m 2 A v 2 A +2 m A m B v A \u22c5 v B + m 2 B v 2 B M 2 . 2 2 2 2 Now we multiply 1 2 M and take the average, and thus we get \u27e8 1 2 M v 2 CM \u27e9 = m A 3 2 kT+ m A m B \u27e8 v A \u22c5 v B \u27e9+ m B 3 2 kT M = 3 2 kT+ m A m B \u27e8 v A \u22c5 v B \u27e9 M . (We have used the fact that ( m A + m B )/M=1 .) Now what is \u27e8 v A \u22c5 v B \u27e9 ? (It had better be zero!) To find out, let us use our assumption that the relative velocity, w= v A \u2212 v B is not any more likely to point in one direction than in another\u2014that is, that its average component in any direction is zero. Thus we assume that \u27e8w\u22c5 v CM \u27e9=0. \u27e8 \u27e9 But what is w\u22c5 v CM ? It is w\u22c5 v CM = ( v A \u2212 v B )\u22c5( m A v A + m B v B ) M = m A v 2 A +( m B \u2212 m A )( v A \u22c5 v B )\u2212 m B v 2 B M . Therefore, since \u27e8 m A v 2 A \u27e9=\u27e8 m B v 2 B \u27e9 , the first and last terms cancel out on the average, and we are left with ( m B \u2212 m A )\u27e8 v A \u22c5 v B \u27e9=0. ( ) \u27e8 \u27e9 Thus if m A \u2260 m B , we find that \u27e8 v A \u22c5 v B \u27e9=0 , and therefore that the bodily motion of the entire molecule, regarded as a single particle of mass M , has a kinetic energy, on the average, equal to 3 2 kT . Incidentally, we have also proved at the same time that the average kinetic energy of the internal motions of the diatomic molecule, disregarding the bodily motion of the CM, is 3 2 kT ! For, the total kinetic energy of the parts of the molecule is 1 2 m A v 2 A + 1 2 m B v 2 B , whose average is 3 2 kT+ 3 2 kT , or 3kT . The kinetic energy of the center-of-mass motion is 3 2 kT , so the average kinetic energy of the rotational and vibratory motions of the two atoms inside the molecule is the difference, 3 2 kT . The theorem concerning the average energy of the CM motion is general: for any object considered as a whole, with forces present or no, for every independent direction of motion that there is, the average kinetic energy in that motion is 1 2 kT . These \u201cindependent directions of motion\u201d are sometimes called the degrees of freedom of the system. The number of degrees of freedom of a molecule composed of r atoms is 3r , since each atom needs three coordinates to define its position. The entire kinetic energy of the molecule can be expressed either as the sum of the kinetic energies of the separate atoms, or as the sum of the kinetic energy of the CM motion plus the kinetic energy of the internal motions. The latter can sometimes be expressed as a sum of rotational kinetic energy of the molecule and vibrational energy, but this is an approximation. Our theorem, applied to the r -atom molecule, says that the molecule will have, on the average, 3rkT/2 joules of kinetic energy, of which 3 2 kT is kinetic energy of the center-of-mass motion of the entire molecule, and the rest, 3 2 (r\u22121)kT , is internal vibrational and rotational kinetic energy."
    },
    {
        "input": "The Flow of Dry Water",
        "output": "The subject of the flow of fluids, and particularly of water, fascinates everybody. We can all remember, as children, playing in the bathtub or in mud puddles with the strange stuff. As we get older, we watch streams, waterfalls, and whirlpools, and we are fascinated by this substance which seems almost alive relative to solids. The behavior of fluids is in many ways very unexpected and interesting\u2014it is the subject of this chapter and the next. The efforts of a child trying to dam a small stream flowing in the street and his surprise at the strange way the water works its way out has its analog in our attempts over the years to understand the flow of fluids. We have tried to dam the water up\u2014in our understanding\u2014by getting the laws and the equations that describe the flow. We will describe these attempts in this chapter. In the next chapter, we will describe the unique way in which water has broken through the dam and escaped our attempts to understand it. We suppose that the elementary properties of water are already known to you. The main property that distinguishes a fluid from a solid is that a fluid cannot maintain a shear stress for any length of time. If a shear is applied to a fluid, it will move under the shear. Thicker liquids like honey move less easily than fluids like air or water. The measure of the ease with which a fluid yields is its viscosity. In this chapter we will consider only situations in which the viscous effects can be ignored. The effects of viscosity will be taken up in the next chapter. We begin by considering hydrostatics, the theory of liquids at rest. When liquids are at rest, there are no shear forces (even for viscous liquids). The law of hydrostatics, therefore, is that the stresses are always normal to any surface inside the fluid. The normal force per unit area is called the pressure. From the fact that there is no shear in a static fluid it follows that the pressure stress is the same in all directions (Fig. 40-1). We will let you entertain yourself by proving that if there is no shear on any plane in a fluid, the pressure must be the same in any direction. The pressure in a fluid may vary from place to place. For example, in a static fluid at the earth\u2019s surface the pressure will vary with height because of the weight of the fluid. If the density \u03c1 of the fluid is considered constant, and if the pressure at some arbitrary zero level is called p0 (Fig. 40-2), then the pressure at a height h above this point is p=p0\u2212\u03c1gh , where g is the gravitational force per unit mass. The combination p+\u03c1gh is, therefore, a constant in the static fluid. This relation is familiar to you, but we will now derive a more general result of which it is a special case. If we take a small cube of water, what is the net force on it from the pressure? Since the pressure at any place is the same in all directions, there can be a net force per unit volume only because the pressure varies from one point to another. Suppose that the pressure is varying in the x -direction\u2014and we take the coordinate directions parallel to the cube edges. The pressure on the face at x gives the force p\u0394y\u0394z (Fig. 40-3), and the pressure on the face at x+\u0394x gives the force \u2212[p+(\u2202p/\u2202x)\u0394x]\u0394y\u0394z , so that the resultant force is \u2212(\u2202p/\u2202x)\u0394x\u0394y\u0394z . If we take the remaining pairs of faces of the cube, we easily see that the pressure force per unit volume is \u2212\u2207p . If there are other forces in addition\u2014such as gravity\u2014then the pressure must balance them to give equilibrium. Let\u2019s take a circumstance in which such an additional force can be described by a potential energy, as would be true in the case of gravitation; we will let \u03d5 stand for the potential energy per unit mass. (For gravity, for instance, \u03d5 is just gz .) The force per unit mass is given in terms of the potential by \u2212\u2207\u03d5 , and if \u03c1 is the density of the fluid, the force per unit volume is \u2212\u03c1\u2207\u03d5 . For equilibrium this force per unit volume added to the pressure force per unit volume must give zero: \u2212\u2207p\u2212\u03c1\u2207\u03d5=0. Equation (40.1) is the equation of hydrostatics. In general, it has no solution. If the density varies in space in an arbitrary way, there is no way for the forces to be in balance, and the fluid cannot be in static equilibrium. Convection currents will start up. We can see this from the equation since the pressure term is a pure gradient, whereas for variable \u03c1 the other term is not. Only when \u03c1 is a constant is the potential term a pure gradient. Then the equation has a solution p+\u03c1\u03d5=const. Another possibility which allows hydrostatic equilibrium is for \u03c1 to be a function only of p . However, we will leave the subject of hydrostatics because it is not nearly so interesting as the situation when fluids are in motion. First, we will discuss fluid motions in a purely abstract, theoretical way and then consider special examples. To describe the motion of a fluid, we must give its properties at every point. For example, at different places, the water (let us call the fluid \u201cwater\u201d) is moving with different velocities. To specify the character of the flow, therefore, we must give the three components of velocity at every point and for any time. If we can find the equations that determine the velocity, then we would know how the liquid moves at all times. The velocity, however, is not the only property that the fluid has which varies from point to point. We have just discussed the variation of the pressure from point to point. And there are still other variables. There may also be a variation of density from point to point. In addition, the fluid may be a conductor and carry an electric current whose density j varies from point to point in magnitude and direction. There may be a temperature which varies from point to point, or a magnetic field, and so on. So the number of fields needed to describe the complete situation will depend on how complicated the problem is. There are interesting phenomena when currents and magnetism play a dominant part in determining the behavior of the fluid; the subject is called magnetohydrodynamics, and great attention is being paid to it at the present time. However, we are not going to consider these more complicated situations because there are already interesting phenomena at a lower level of complexity, and even the more elementary level will be complicated enough. We will take the situation where there is no magnetic field and no conductivity, and we will not worry about the temperature because we will suppose that the density and pressure determine in a unique manner the temperature at any point. As a matter of fact, we will reduce the complexity of our work by making the assumption that the density is a constant\u2014we imagine that the fluid is essentially incompressible. Putting it another way, we are supposing that the variations of pressure are so small that the changes in density produced thereby are negligible. If that is not the case, we would encounter phenomena additional to the ones we will be discussing here\u2014for example, the propagation of sound or of shock waves. We have already discussed the propagation of sound and shocks to some extent, so we will now isolate our consideration of hydrodynamics from these other phenomena by making the approximation that the density \u03c1 is a constant. It is easy to determine when the approximation of constant \u03c1 is a good one. We can say that if the velocities of flow are much less than the speed of a sound wave in the fluid, we do not have to worry about variations in density. The escape that water makes in our attempts to understand it is not related to the approximation of constant density. The complications that do permit the escape will be discussed in the next chapter. In the general theory of fluids one must begin with an equation of state for the fluid which connects the pressure to the density. In our approximation this equation of state is simply \u03c1=const. This then is the first relation for our variables. The next relation expresses the conservation of matter\u2014if matter flows away from a point, there must be a decrease in the amount left behind. If the fluid velocity is v , then the mass which flows in a unit time across a unit area of surface is the component of \u03c1v normal to the surface. We have had a similar relation in electricity. We also know from electricity that the divergence of such a quantity gives the rate of decrease of the density per unit time. In the same way, the equation \u2207\u22c5(\u03c1v)=\u2212 \u2202\u03c1 \u2202t expresses the conservation of mass for a fluid; it is the hydrodynamic equation of continuity. In our approximation, which is the incompressible fluid approximation, \u03c1 is a constant, and the equation of continuity is simply \u2207\u22c5v=0. The fluid velocity v \u2014like the magnetic field B \u2014has zero divergence. (The hydrodynamic equations are often closely analogous to the electrodynamic equations; that\u2019s why we studied electrodynamics first. Some people argue the other way; they think that one should study hydrodynamics first so that it will be easier to understand electricity afterwards. But electrodynamics is really much easier than hydrodynamics.) We will get our next equation from Newton\u2019s law which tells us how the velocity changes because of the forces. The mass of an element of volume of the fluid times its acceleration must be equal to the force on the element. Taking an element of unit volume, and writing the force per unit volume as f , we have \u03c1\u00d7(acceleration)=f. We will write the force density as the sum of three terms. We have already considered the pressure force per unit volume, \u2212\u2207p . Then there are the \u201cexternal\u201d forces which act at a distance\u2014like gravity or electricity. When they are conservative forces with a potential per unit mass, \u03d5 , they give a force density \u2212\u03c1\u2207\u03d5 . (If the external forces are not conservative, we would have to write f ext for the external force per unit volume.) Then there is another \u201cinternal\u201d force per unit volume, which is due to the fact that in a flowing fluid there can also be a shearing stress. This is called the viscous force, which we will write f visc . Our equation of motion is \u03c1\u00d7(acceleration)=\u2212\u2207p\u2212\u03c1\u2207\u03d5+ f visc . (40.4) For this chapter we are going to suppose that the liquid is \u201cthin\u201d in the sense that the viscosity is unimportant, so we will omit f visc . When we drop the viscosity term, we will be making an approximation which describes some ideal stuff rather than real water. John von Neumann was well aware of the tremendous difference between what happens when you don\u2019t have the viscous terms and when you do, and he was also aware that, during most of the development of hydrodynamics until about 1900, almost the main interest was in solving beautiful mathematical problems with this approximation which had almost nothing to do with real fluids. He characterized the theorist who made such analyses as a man who studied \u201cdry water.\u201d Such analyses leave out an essential property of the fluid. It is because we are leaving this property out of our calculations in this chapter that we have given it the title \u201cThe Flow of Dry Water.\u201d We are postponing a discussion of real water to the next chapter. If we leave out f visc , we have in Eq. (40.4) everything we need except an expression for the acceleration. You might think that the formula for the acceleration of a fluid particle would be very simple, for it seems obvious that if v is the velocity of a fluid particle at some place in the fluid, the acceleration would just be \u2202v/\u2202t . It is not\u2014and for a rather subtle reason. The derivative \u2202v/\u2202t , is the rate at which the velocity v(x,y,z,t) changes at a fixed point in space. What we need is how fast the velocity changes for a particular piece of fluid. Imagine that we mark one of the drops of water with a colored speck so we can watch it. In a small interval of time \u0394t , this drop will move to a different location. If the drop is moving along some path as sketched in Fig. 40-4, it might in \u0394t move from P 1 to P 2 . In fact, it will move in the x -direction by an amount v x \u0394t , in the y -direction by the amount v y \u0394t , and in the z -direction by the amount v z \u0394t . We see that, if v(x,y,z,t) is the velocity of the fluid particle which is at (x,y,z) at the time t , then the velocity of the same particle, at the time t+\u0394t is given by v(x+\u0394x,y+\u0394y,z+\u0394z,t+\u0394t) \u2014with \u0394x= v x \u0394t,\u0394y= v y \u0394t,and\u0394z= v z \u0394t. From the definition of the partial derivatives\u2014recall Eq. (2.7)\u2014we have, to first order, that v(x+ v x \u0394t,y+ v y \u0394t,z+ v z \u0394t,t+\u0394t)= v(x,y,z,t)+ \u2202v \u2202x v x \u0394t+ \u2202v \u2202y v y \u0394t+ \u2202v \u2202z v z \u0394t+ \u2202v \u2202t \u0394t. The acceleration \u0394v/\u0394t is v x \u2202v \u2202x + v y \u2202v \u2202y + v z \u2202v \u2202z + \u2202v \u2202t . We can write this symbolically\u2014treating \u2207 as a vector\u2014as (v\u22c5\u2207)v+ \u2202v \u2202t . (40.5) Note that there can be an acceleration even though \u2202v/\u2202t=0 so that velocity at a given point is not changing. As an example, water flowing in a circle at a constant speed is accelerating even though the velocity at a given point is not changing. The reason is, of course, that the velocity of a particular piece of water which is initially at one point on the circle has a different direction a moment later; there is a centripetal acceleration. The rest of our theory is just mathematical\u2014finding solutions of the equation of motion we get by putting the acceleration (40.5) into Eq. (40.4). We get \u2202v \u2202t +(v\u22c5\u2207)v=\u2212 \u2207p \u03c1 \u2212\u2207\u03d5, (40.6) where viscosity has been omitted. We can rearrange this equation by using the following identity from vector analysis: (v\u22c5\u2207)v=(\u2207\u00d7v)\u00d7v+ 1 2 \u2207(v\u22c5v). 1 If we now define a new vector field \u03a9 , as the curl of v , \u03a9=\u2207\u00d7v, (40.7) the vector identity can be written as (v\u22c5\u2207)v=\u03a9\u00d7v+ 1 2 \u2207 v 2 , 1 and our equation of motion (40.6) becomes \u2202v \u2202t +\u03a9\u00d7v+ 1 2 \u2207 v 2 =\u2212 \u2207p \u03c1 \u2212\u2207\u03d5. (40.8) You can verify that Eqs. (40.6) and (40.8) are equivalent by checking that the components of the two sides of the equation are equal\u2014and making use of (40.7). The vector field \u03a9 is called the vorticity. If the vorticity is zero everywhere, we say that the flow is irrotational. We have already defined in Section 3-5 a thing called the circulation of a vector field. The circulation around any closed loop in a fluid is the line integral of the fluid velocity, at a given instant of time, around that loop: (Circulation)=\u222ev\u22c5ds. \u222e The circulation per unit area for an infinitesimal loop is then\u2014using Stokes\u2019 theorem\u2014equal to \u2207\u00d7v . So the vorticity \u03a9 is the circulation around a unit area (perpendicular to the direction of \u03a9 ). It also follows that if you put a little piece of dirt\u2014not an infinitesimal point\u2014at any place in the liquid it will rotate with the angular velocity \u03a9/2 . Try to see if you can prove that. You can also check it out that for a bucket of water on a turntable, \u03a9 is equal to twice the local angular velocity of the water. If we are interested only in the velocity field, we can eliminate the pressure from our equations. Taking the curl of both sides of Eq. (40.8), remembering that \u03c1 is a constant and that the curl of any gradient is zero, and using Eq. (40.3), we get \u2202\u03a9 \u2202t +\u2207\u00d7(\u03a9\u00d7v)=0. (40.9) This equation, together with the equations \u03a9=\u2207\u00d7v (40.10) and \u2207\u22c5v=0, (40.11) describes completely the velocity field v . Mathematically speaking, if we know \u03a9 at some time, then we know the curl of the velocity vector, and we also know that its divergence is zero, so given the physical situation we have all we need to determine v everywhere. (It is just like the situation in magnetism where we had \u2207\u22c5B=0 and \u2207\u00d7B=j/ \u03f5 0 c 2 .) Thus, a given \u03a9 determines v just as a given j determines B . Then, knowing v , Eq. (40.9) tells us the rate of change of \u03a9 from which we can get the new \u03a9 for the next instant. Using Eq. (40.10), again we find the new v , and so on. You see how these equations contain all the machinery for calculating the flow. Note, however, that this procedure gives the velocity field only; we have lost all information about the pressure. We point out one special consequence of our equation. If \u03a9=0 everywhere at any time t , \u2202\u03a9/\u2202t also vanishes, so that \u03a9 is still zero everywhere at t+\u0394t . We have a solution to the equation; the flow is permanently irrotational. If a flow was started with zero rotation, it would always have zero rotation. The equations to be solved then are \u2207\u22c5v=0,\u2207\u00d7v=0. \u2207 0 \u2207 0. They are just like the equations for the electrostatic or magnetostatic fields in free space. We will come back to them and look at some special problems later. Now we want to return to the equation of motion, Eq. (40.8), but limit ourselves to situations in which the flow is \u201csteady.\u201d By steady flow we mean that at any one place in the fluid the velocity never changes. The fluid at any point is always replaced by new fluid moving in exactly the same way. The velocity picture always looks the same\u2014 v is a static vector field. In the same way that we drew \u201cfield lines\u201d in magnetostatics, we can now draw lines which are always tangent to the fluid velocity as shown in Fig. 40-5. These lines are called streamlines. For steady flow, they are evidently the actual paths of fluid particles. (In unsteady flow the streamline pattern changes in time, and the streamline pattern at any instant does not represent the path of a fluid particle.) A steady flow does not mean that nothing is happening\u2014atoms in the fluid are moving and changing their velocities. It only means that \u2202v/\u2202t=0 . Then if we take the dot product of v into the equation of motion, the term v\u22c5(\u03a9\u00d7v) drops out, and we are left with v\u22c5\u2207{ p \u03c1 +\u03d5+ 1 2 v 2 }=0. (40.12) This equation says that for a small displacement in the direction of the fluid velocity the quantity inside the brackets doesn\u2019t change. Now in steady flow all displacements are along streamlines, so Eq. (40.12) tells us that for all the points along a streamline, we can write p \u03c1 + 1 2 v 2 +\u03d5=const(streamline). (40.13) This is Bernoulli\u2019s theorem. The constant may in general be different for different streamlines; all we know is that the left-hand side of Eq. (40.13) is the same all along a given streamline. Incidentally, we may notice that for steady irrotational motion for which \u03a9=0 , the equation of motion (40.8) gives us the relation \u2207{ p \u03c1 + 1 2 v 2 +\u03d5}=0, 1 so that p \u03c1 + 1 2 v 2 +\u03d5=const(everywhere). (40.14) It\u2019s just like Eq. (40.13) except that now the constant has the same value throughout the fluid. The theorem of Bernoulli is in fact nothing more than a statement of the conservation of energy. A conservation theorem such as this gives us a lot of information about a flow without our actually having to solve the detailed equations. Bernoulli\u2019s theorem is so important and so simple that we would like to show you how it can be derived in a way that is different from the formal calculations we have just used. Imagine a bundle of adjacent streamlines which form a stream tube as sketched in Fig. 40-6. Since the walls of the tube consist of streamlines, no fluid flows out through the wall. Let\u2019s call the area at one end of the stream tube A 1 , the fluid velocity there v 1 , the density of the fluid \u03c1 1 , and the potential energy \u03d5 1 . At the other end of the tube, we have the corresponding quantities A 2 , v 2 , \u03c1 2 , and \u03d5 2 . Now after a short interval of time \u0394t , the fluid at A 1 has moved a distance v 1 \u0394t , and the fluid at A 2 has moved a distance v 2 \u0394t [Fig. 40-6(b)]. The conservation of mass requires that the mass which enters through A 1 must be equal to the mass which leaves through A 2 . These masses at these two ends must be the same: \u0394M= \u03c1 1 A 1 v 1 \u0394t= \u03c1 2 A 2 v 2 \u0394t. \u0394 M A \u0394 t A \u0394 t So we have the equality \u03c1 1 A 1 v 1 = \u03c1 2 A 2 v 2 . (40.15) This equation tells us that the velocity varies inversely with the area of the stream tube if \u03c1 is constant. Now we calculate the work done by the fluid pressure. The work done on the fluid entering at A 1 is p 1 A 1 v 1 \u0394t , and the work given up at A 2 is p 2 A 2 v 2 \u0394t . The net work on the fluid between A 1 and A 2 is, therefore, p 1 A 1 v 1 \u0394t\u2212 p 2 A 2 v 2 \u0394t, A \u0394 t A \u0394 t which must equal the increase in the energy of a mass \u0394M of fluid in going from A 1 to A 2 . In other words, p 1 A 1 v 1 \u0394t\u2212 p 2 A 2 v 2 \u0394t=\u0394M( E 2 \u2212 E 1 ), (40.16) where E 1 is the energy per unit mass of fluid at A 1 , and E 2 is the energy per unit mass at A 2 . The energy per unit mass of the fluid can be written as E= 1 2 v 2 +\u03d5+U, 1 where 1 2 v 2 is the kinetic energy per unit mass, \u03d5 is the potential energy per unit mass, and U is an additional term which represents the internal energy per unit mass of fluid. The internal energy might correspond, for example, to the thermal energy in a compressible fluid, or to chemical energy. All these quantities can vary from point to point. Using this form for the energies in (40.16), we have p 1 A 1 v 1 \u0394t \u0394M 1 2 v 2 2 + \u03d5 2 + U 2 \u2212 p 2 A 2 v 2 \u0394t \u0394M = \u2212 1 2 v 2 1 \u2212 \u03d5 1 \u2212 U 1 . But we have seen that \u0394M=\u03c1Av\u0394t , so we get p 1 \u03c1 1 + 1 2 v 2 1 + \u03d5 1 + U 1 = p 2 \u03c1 2 + 1 2 v 2 2 + \u03d5 2 + U 2 , (40.17) which is the Bernoulli result with an additional term for the internal energy. If the fluid is incompressible, the internal energy term is the same on both sides, and we get again that Eq. (40.14) holds along any streamline. We consider now some simple examples in which the Bernoulli integral gives us a description of the flow. Suppose we have water flowing out of a hole near the bottom of a tank, as drawn in Fig. 40-7. We take a situation in which the flow speed v out at the hole is much larger than the flow speed near the top of the tank; in other words, we imagine that the diameter of the tank is so large that we can neglect the drop in the liquid level. (We could make a more accurate calculation if we wished.) At the top of the tank the pressure is p 0 , the atmospheric pressure, and the pressure at the sides of the jet is also p 0 . Now we write our Bernoulli equation for a streamline, such as the one shown in the figure. At the top of the tank, we take v equal to zero and we also take the gravity potential \u03d5 to be zero. At the hole v= v out and \u03d5=\u2212gh , so that p 0 = p 0 + 1 2 \u03c1 v 2 out \u2212\u03c1gh, 1 or v out = 2gh \u2212 \u2212 \u2212 \u221a . (40.18) This velocity is just what we would get for something which falls the distance h . It is not too surprising, since the water at the exit gains kinetic energy at the expense of the potential energy of the water at the top. Do not get the idea, however, that you can figure out the rate that the fluid flows out of the tank by multiplying this velocity by the area of the hole. The fluid velocities as the jet leaves the hole are not all parallel to each other but have components inward toward the center of the stream\u2014the jet is converging. After the jet has gone a little way, the contraction stops and the velocities do become parallel. So the total flow is the velocity times the area at that point. In fact, if we have a discharge opening which is just a round hole with a sharp edge, the jet contracts to 62 percent of the area of the hole. The reduced effective area of the discharge varies for different shapes of discharge tubes, and experimental contractions are available as tables of efflux coefficients. If the discharge tube is re-entrant, as shown in Fig. 40-8, it is possible to prove in a most beautiful way that the efflux coefficient is exactly 50 percent. We will give just a hint of how the proof goes. We have used the conservation of energy to get the velocity, Eq. (40.18), but there is also momentum conservation to consider. Since there is an outflow of momentum in the discharge jet, there must be a force applied over the cross section of the discharge tube. Where does the force come from? The force must come from the pressure on the walls. As long as the efflux hole is small and away from the walls, the fluid velocity near the walls of the tank will be very small. Therefore, the pressure on every face is almost exactly the same as the static pressure in a fluid at rest\u2014from Eq. (40.14). Then the static pressure at any point on the side of the tank must be matched by an equal pressure at the point on the opposite wall, except at the points on the wall opposite the charge tube. If we calculate the momentum poured out through the jet by this pressure, we can show that the efflux coefficient is 1/2 . We cannot use this method for a discharge hole like that shown in Fig. 40-7, however, because the velocity increase along the wall right near the discharge area gives a pressure fall which we are not able to calculate. Let\u2019s look at another example\u2014a horizontal pipe with changing cross section, as shown in Fig. 40-9, with water flowing in one end and out the other. The conservation of energy, namely Bernoulli\u2019s formula, says that the pressure is lower in the constricted area where the velocity is higher. We can easily demonstrate this effect by measuring the pressure at different cross sections with small vertical columns of water attached to the flow tube through holes small enough so that they do not disturb the flow. The pressure is then measured by the height of water in these vertical columns. The pressure is found to be less at the constriction than it is on either side. If the area beyond the constriction comes back to the same value it had before the constriction, the pressure rises again. Bernoulli\u2019s formula would predict that the pressure downstream of the constriction should be the same as it was upstream, but actually it is noticeably less. The reason that our prediction is wrong is that we have neglected the frictional, viscous forces which cause a pressure drop along the tube. Despite this pressure drop the pressure is definitely lower at the constriction (because of the increased speed) than it is on either side of it\u2014as predicted by Bernoulli. The speed v 2 must certainly exceed v 1 to get the same amount of water through the narrower tube. So the water accelerates in going from the wide to the narrow part. The force that gives this acceleration comes from the drop in pressure. We can check our results with another simple demonstration. Suppose we have on a tank a discharge tube which throws a jet of water upward as shown in Fig. 40-10. If the efflux velocity were exactly 2gh \u2212 \u2212 \u2212 \u221a , the discharge water should rise to a level even with the surface of the water in the tank. Experimentally, it falls somewhat short. Our prediction is roughly right, but again viscous friction which has not been included in our energy conservation formula has resulted in a loss of energy. Have you ever held two pieces of paper close together and tried to blow them apart? Try it! They come together. The reason, of course, is that the air has a higher speed going through the constricted space between the sheets than it does when it gets outside. The pressure between the sheets is lower than atmospheric pressure, so they come together rather than separating. We saw at the beginning of the last section that if we have an incompressible fluid with no circulation, the flow satisfies the following two equations: \u2207\u22c5v=0,\u2207\u00d7v=0. (40.19) They are the same as the equations of electrostatics or magnetostatics in empty space. The divergence of the electric field is zero when there are no charges, and the curl of the electrostatic field is always zero. The curl of the magnetostatic field is zero if there are no currents, and the divergence of the magnetic field is always zero. Therefore, Eqs. (40.19) have the same solutions as the equations for E in electrostatics or for B in magnetostatics. As a matter of fact, we have already solved the problem of the flow of a fluid past a sphere, as an electrostatic analogy, in Section 12-5. The electrostatic analog is a uniform electric field plus a dipole field. The dipole field is so adjusted that the flow velocity normal to the surface of the sphere is zero. The same problem for the flow past a cylinder can be worked out in a similar way by using a suitable line dipole with a uniform flow field. This solution holds for a situation in which the fluid velocity at large distances is constant\u2014both in magnitude and direction. The solution is sketched in Fig. 40-11(a). There is another solution for the flow around a cylinder when the conditions are such that the fluid at large distances moves in circles around the cylinder. The flow is, then, circular everywhere, as in Fig. 40-11(b). Such a flow has a circulation around the cylinder, although \u2207\u00d7v is still zero in the fluid. How can there be circulation without a curl? We have a circulation around the cylinder because the line integral of v around any loop enclosing the cylinder is not zero. At the same time, the line integral of v around any closed path which does not include the cylinder is zero. We saw the same thing when we found the magnetic field around a wire. The curl of B was zero outside of the wire, although a line integral of B around a path which encloses the wire did not vanish. The velocity field in an irrotational circulation around a cylinder is precisely the same as the magnetic field around a wire. For a circular path with its center at the center of the cylinder, the line integral of the velocity is \u222ev\u22c5ds=2\u03c0rv. \u222e For irrotational flow the integral must be independent of r . Let\u2019s call the constant value C , then we have that v= C 2\u03c0r , (40.20) where v is the tangential velocity, and r is the distance from the axis. There is a nice demonstration of a fluid circulating around a hole. You take a transparent cylindrical tank with a drain hole in the center of the bottom. You fill it with water, stir up some circulation with a stick, and pull the drain plug. You get the pretty effect shown in Fig. 40-12. (You\u2019ve seen a similar thing many times in the bathtub!) Although you put in some \u03c9 at beginning, it soon dies down because of viscosity and the flow becomes irrotational\u2014although still with some circulation around the hole. From the theory, we can calculate the shape of the inner surface of the water. As a particle of the water moves inward it picks up speed. From Eq. (40.20) the tangential velocity goes as 1/r \u2014it\u2019s just from the conservation of angular momentum, like the skater pulling in her arms. Also the radial velocity goes as 1/r . Ignoring the tangential motion, we have water going radially inward toward a hole; from \u2207\u22c5v=0 , it follows that the radial velocity is proportional to 1/r . So the total velocity also increases as 1/r , and the water goes in along equiangular (or \"logarithmic\") spirals. The air-water surface is all at atmospheric pressure, so it must have\u2014from Eq. (40.14)\u2014the property that gz+ 1 2 v 2 =const. 1 But v is proportional to 1/r , so the shape of the surface is (z\u2212 z 0 )= k r 2 . k An interesting point\u2014which is not true in general but is true for incompressible, irrotational flow\u2014is that if we have one solution and a second solution, then the sum is also a solution. This is true because the equations in (40.19) are linear. The complete equations of hydrodynamics, Eqs. (40.9), (40.10), and (40.11), are not linear, which makes a vast difference. For the irrotational flow about the cylinder, however, we can superpose the flow of Fig. 40-11(a) on the flow of Fig. 40-11(b) and get the new flow pattern shown in Fig. 40-11(c). This flow is of special interest. The flow velocity is higher on the upper side of the cylinder than on the lower side. The pressures are therefore lower on the upper side than on the lower side. So when we have a combination of a circulation around a cylinder and a net horizontal flow, there is a net vertical force on the cylinder\u2014it is called a lift force. Of course, if there is no circulation, there is no net force on any body according to our theory of \u201cdry\u201d water. We have already written down the general equations for the flow of an incompressible fluid when there may be vorticity. They are I. II. III. \u2207\u22c5v=0, \u03a9=\u2207\u00d7v, \u2202\u03a9 \u2202t +\u2207\u00d7(\u03a9\u00d7v)=0. The physical content of these equations has been described in words by Helmholtz in terms of three theorems. First, imagine that in the fluid we were to draw vortex lines rather than streamlines. By vortex lines we mean field lines that have the direction of \u03a9 and have a density in any region proportional to the magnitude of \u03a9 . From II the divergence of \u03a9 is always zero (remember\u2014Section 3-7\u2014that the divergence of a curl is always zero). So vortex lines are like lines of B \u2014they never start or stop, and will tend to go in closed loops. Now Helmholtz described III in words by the following statement: the vortex lines move with the fluid. This means that if you were to mark the fluid particles along some vortex lines\u2014by coloring them with ink, for example\u2014then as the fluid moves and carries those particles along, they will always mark the new positions of the vortex lines. In whatever way the atoms of the liquid move, the vortex lines move with them. That is one way to describe the laws. It also suggests a method for solving any problems. Given the initial flow pattern\u2014say v everywhere\u2014then you can calculate \u03a9 . From the v you can also tell where the vortex lines are going to be a little later\u2014they move with the speed v . With the new \u03a9 you can use I and II to find the new v . (That\u2019s just like the problem of finding B , given the currents.) If we are given the flow pattern at one instant we can in principle calculate it for all subsequent times. We have the general solution for nonviscous flow. We would like to show how Helmholtz\u2019s statement\u2014and, therefore, III\u2014can be at least partly understood. It is really just the law of conservation of angular momentum applied to the fluid. Suppose we imagine a small cylinder of the liquid whose axis is parallel to the vortex lines, as in Fig. 40-13(a). At some time later, this same piece of fluid will be somewhere else. Generally it will occupy a cylinder with a different diameter and be in a different place. It may also have a different orientation, say as in Fig. 40-13(b). If, however, the diameter has decreased as shown in Fig. 40-13, the length will have increased to keep the volume constant (since we are assuming an incompressible fluid). Also, since the vortex lines are stuck with the material, their density will go up as the cross-sectional area goes down. The product of the vorticity \u03a9 and area A of the cylinder will remain constant, so according to Helmholtz, we should have \u03a9 2 A 2 = \u03a9 1 A 1 . (40.21) Now notice that with zero viscosity all the forces on the surface of the cylindrical volume (or any volume, for that matter) are perpendicular to the surface. The pressure forces can cause the volume to be moved from place to place, or can cause it to change shape; but with no tangential forces the magnitude of the angular momentum of the material inside cannot change. The angular momentum of the liquid in the little cylinder is its moment of inertia I times the angular velocity of the liquid, which is proportional to the vorticity \u03a9 . For a cylinder, the moment of inertia is proportional to m r 2 . So from the conservation of angular momentum, we would conclude that ( M 1 R 2 1 ) \u03a9 1 =( M 2 R 2 2 ) \u03a9 2 . 2 2 But the mass is the same, M 1 = M 2 , and the areas are proportional to R 2 , so we get again just Eq. (40.21). Helmholtz\u2019s statement\u2014which is equivalent to III\u2014is just a consequence of the fact that in the absence of viscosity the angular momentum of an element of the fluid cannot change. There is a nice demonstration of a moving vortex which is made with the simple apparatus of Fig. 40-14. It is a \u201cdrum\u201d two feet in diameter and two feet long made by stretching a thick rubber sheet over the open end of a cylindrical \u201cbox.\u201d The \u201cbottom\u201d\u2014the drum is tipped on its side\u2014is solid except for a 3 -inch diameter hole. If you give a sharp blow on the rubber diaphragm with your hand, a vortex ring is projected out of the hole. Although the vortex is invisible, you can tell it\u2019s there because it will blow out a candle 10 to 20 feet away. By the delay in the effect, you can tell that \u201csomething\u201d is travelling at a finite speed. You can see better what is going on if you first blow some smoke into the box. Then you see the vortex as a beautiful round \u201csmoke ring.\u201d The smoke ring is a torus-shaped bundle of vortex lines, as shown in Fig. 40-15(a). Since \u03a9=\u2207\u00d7v , these vortex lines represent also a circulation of v as shown in part (b) of the figure. We can understand the forward motion of the ring in the following way: The circulating velocity around the bottom of the ring extends up to the top of the ring, having there a forward motion. Since the lines of \u03a9 move with the fluid, they also move ahead with the velocity v . (Of course, the circulation of v around the top part of the ring is responsible for the forward motion of the vortex lines at the bottom.) We must now mention a serious difficulty. We have already noted that Eq. (40.9) says that, if \u03a9 is initially zero, it will always be zero. This result is a great failure of the theory of \u201cdry\u201d water, because it means that once \u03a9 is zero it is always zero\u2014it is impossible to produce any vorticity under any circumstance. Yet, in our simple demonstration with the drum, we can generate a vortex ring starting with air which was initially at rest. (Certainly, v=0 , \u03a9=0 everywhere in the box before we hit it.) Also, we all know that we can start some vorticity in a lake with a paddle. Clearly, we must go to a theory of \u201cwet\u201d water to get a complete understanding of the behavior of a fluid. Another feature of the dry water theory which is incorrect is the supposition we make regarding the flow at the boundary between it and the surface of a solid. When we discussed the flow past a cylinder\u2014as in Fig. 40-11, for example\u2014we permitted the fluid to slide along the surface of the solid. In our theory, the velocity at a solid surface could have any value depending on how it got started, and we did not consider any \u201cfriction\u201d between the fluid and the solid. It is an experimental fact, however, that the velocity of a real fluid always goes to zero at the surface of a solid object. Therefore, our solution for the cylinder, with or without circulation, is wrong\u2014as is our result regarding the generation of vorticity. We will tell you about the more correct theories in the next chapter."
    },
    {
        "input": "The Theory of Gravitation",
        "output": "In this chapter we shall discuss one of the most far-reaching generalizations of the human mind. While we are admiring the human mind, we should take some time off to stand in awe of a nature that could follow with such completeness and generality such an elegantly simple principle as the law of gravitation. What is this law of gravitation? It is that every object in the universe attracts every other object with a force which for any two bodies is proportional to the mass of each and varies inversely as the square of the distance between them. This statement can be expressed mathematically by the equation F=G m m \u2032 r 2 . If to this we add the fact that an object responds to a force by accelerating in the direction of the force by an amount that is inversely proportional to the mass of the object, we shall have said everything required, for a sufficiently talented mathematician could then deduce all the consequences of these two principles. However, since you are not assumed to be sufficiently talented yet, we shall discuss the consequences in more detail, and not just leave you with only these two bare principles. We shall briefly relate the story of the discovery of the law of gravitation and discuss some of its consequences, its effects on history, the mysteries that such a law entails, and some refinements of the law made by Einstein; we shall also discuss the relationships of the law to the other laws of physics. All this cannot be done in one chapter, but these subjects will be treated in due time in subsequent chapters. The story begins with the ancients observing the motions of planets among the stars, and finally deducing that they went around the sun, a fact that was rediscovered later by Copernicus. Exactly how the planets went around the sun, with exactly what motion, took a little more work to discover. Beginning in the sixteenth century there were great debates as to whether they really went around the sun or not. Tycho Brahe had an idea that was different from anything proposed by the ancients: his idea was that these debates about the nature of the motions of the planets would best be resolved if the actual positions of the planets in the sky were measured sufficiently accurately. If measurement showed exactly how the planets moved, then perhaps it would be possible to establish one or another viewpoint. This was a tremendous idea\u2014that to find something out, it is better to perform some careful experiments than to carry on deep philosophical arguments. Pursuing this idea, Tycho Brahe studied the positions of the planets for many years in his observatory on the island of Hven, near Copenhagen. He made voluminous tables, which were then studied by the mathematician Kepler, after Tycho\u2019s death. Kepler discovered from the data some very beautiful and remarkable, but simple, laws regarding planetary motion. First of all, Kepler found that each planet goes around the sun in a curve called an ellipse, with the sun at a focus of the ellipse. An ellipse is not just an oval, but is a very specific and precise curve that can be obtained by using two tacks, one at each focus, a loop of string, and a pencil; more mathematically, it is the locus of all points the sum of whose distances from two fixed points (the foci) is a constant. Or, if you will, it is a foreshortened circle (Fig. 7\u20131). Kepler\u2019s second observation was that the planets do not go around the sun at a uniform speed, but move faster when they are nearer the sun and more slowly when they are farther from the sun, in precisely this way: Suppose a planet is observed at any two successive times, let us say a week apart, and that the radius vector1 is drawn to the planet for each observed position. The orbital arc traversed by the planet during the week, and the two radius vectors, bound a certain plane area, the shaded area shown in Fig. 7\u20132. If two similar observations are made a week apart, at a part of the orbit farther from the sun (where the planet moves more slowly), the similarly bounded area is exactly the same as in the first case. So, in accordance with the second law, the orbital speed of each planet is such that the radius \u201csweeps out\u201d equal areas in equal times. Finally, a third law was discovered by Kepler much later; this law is of a different category from the other two, because it deals not with only a single planet, but relates one planet to another. This law says that when the orbital period and orbit size of any two planets are compared, the periods are proportional to the 3/2 power of the orbit size. In this statement the period is the time interval it takes a planet to go completely around its orbit, and the size is measured by the length of the greatest diameter of the elliptical orbit, technically known as the major axis. More simply, if the planets went in circles, as they nearly do, the time required to go around the circle would be proportional to the 3/2 power of the diameter (or radius). Thus Kepler\u2019s three laws are: Each planet moves around the sun in an ellipse, with the sun at one focus. The radius vector from the sun to the planet sweeps out equal areas in equal intervals of time. The squares of the periods of any two planets are proportional to the cubes of the semimajor axes of their respective orbits: T\u221d a 3/2 . While Kepler was discovering these laws, Galileo was studying the laws of motion. The problem was, what makes the planets go around? (In those days, one of the theories proposed was that the planets went around because behind them were invisible angels, beating their wings and driving the planets forward. You will see that this theory is now modified! It turns out that in order to keep the planets going around, the invisible angels must fly in a different direction and they have no wings. Otherwise, it is a somewhat similar theory!) Galileo discovered a very remarkable fact about motion, which was essential for understanding these laws. That is the principle of inertia\u2014if something is moving, with nothing touching it and completely undisturbed, it will go on forever, coasting at a uniform speed in a straight line. (Why does it keep on coasting? We do not know, but that is the way it is.) Newton modified this idea, saying that the only way to change the motion of a body is to use force. If the body speeds up, a force has been applied in the direction of motion. On the other hand, if its motion is changed to a new direction, a force has been applied sideways. Newton thus added the idea that a force is needed to change the speed or the direction of motion of a body. For example, if a stone is attached to a string and is whirling around in a circle, it takes a force to keep it in the circle. We have to pull on the string. In fact, the law is that the acceleration produced by the force is inversely proportional to the mass, or the force is proportional to the mass times the acceleration. The more massive a thing is, the stronger the force required to produce a given acceleration. (The mass can be measured by putting other stones on the end of the same string and making them go around the same circle at the same speed. In this way it is found that more or less force is required, the more massive object requiring more force.) The brilliant idea resulting from these considerations is that no tangential force is needed to keep a planet in its orbit (the angels do not have to fly tangentially) because the planet would coast in that direction anyway. If there were nothing at all to disturb it, the planet would go off in a straight line. But the actual motion deviates from the line on which the body would have gone if there were no force, the deviation being essentially at right angles to the motion, not in the direction of the motion. In other words, because of the principle of inertia, the force needed to control the motion of a planet around the sun is not a force around the sun but toward the sun. (If there is a force toward the sun, the sun might be the angel, of course!) From his better understanding of the theory of motion, Newton appreciated that the sun could be the seat or organization of forces that govern the motion of the planets. Newton proved to himself (and perhaps we shall be able to prove it soon) that the very fact that equal areas are swept out in equal times is a precise sign post of the proposition that all deviations are precisely radial\u2014that the law of areas is a direct consequence of the idea that all of the forces are directed exactly toward the sun. Next, by analyzing Kepler\u2019s third law it is possible to show that the farther away the planet, the weaker the forces. If two planets at different distances from the sun are compared, the analysis shows that the forces are inversely proportional to the squares of the respective distances. With the combination of the two laws, Newton concluded that there must be a force, inversely as the square of the distance, directed in a line between the two objects. Being a man of considerable feeling for generalities, Newton supposed, of course, that this relationship applied more generally than just to the sun holding the planets. It was already known, for example, that the planet Jupiter had moons going around it as the moon of the earth goes around the earth, and Newton felt certain that each planet held its moons with a force. He already knew of the force holding us on the earth, so he proposed that this was a universal force\u2014that everything pulls everything else. The next problem was whether the pull of the earth on its people was the \u201csame\u201d as its pull on the moon, i.e., inversely as the square of the distance. If an object on the surface of the earth falls 16 feet in the first second after it is released from rest, how far does the moon fall in the same time? We might say that the moon does not fall at all. But if there were no force on the moon, it would go off in a straight line, whereas it goes in a circle instead, so it really falls in from where it would have been if there were no force at all. We can calculate from the radius of the moon\u2019s orbit (which is about 240,000 miles) and how long it takes to go around the earth (approximately 29 days), how far the moon moves in its orbit in 1 second, and can then calculate how far it falls in one second.2 This distance turns out to be roughly 1/20 of an inch in a second. That fits very well with the inverse square law, because the earth\u2019s radius is 4000 miles, and if something which is 4000 miles from the center of the earth falls 16 feet in a second, something 240,000 miles, or 60 times as far away, should fall only 1/3600 of 16 feet, which also is roughly 1/20 of an inch. Wishing to put this theory of gravitation to a test by similar calculations, Newton made his calculations very carefully and found a discrepancy so large that he regarded the theory as contradicted by facts, and did not publish his results. Six years later a new measurement of the size of the earth showed that the astronomers had been using an incorrect distance to the moon. When Newton heard of this, he made the calculation again, with the corrected figures, and obtained beautiful agreement. This idea that the moon \u201cfalls\u201d is somewhat confusing, because, as you see, it does not come any closer. The idea is sufficiently interesting to merit further explanation: the moon falls in the sense that it falls away from the straight line that it would pursue if there were no forces. Let us take an example on the surface of the earth. An object released near the earth\u2019s surface will fall 16 feet in the first second. An object shot out horizontally will also fall 16 feet; even though it is moving horizontally, it still falls the same 16 feet in the same time. Figure 7\u20133 shows an apparatus which demonstrates this. On the horizontal track is a ball which is going to be driven forward a little distance away. At the same height is a ball which is going to fall vertically, and there is an electrical switch arranged so that at the moment the first ball leaves the track, the second ball is released. That they come to the same depth at the same time is witnessed by the fact that they collide in midair. An object like a bullet, shot horizontally, might go a long way in one second\u2014perhaps 2000 feet\u2014but it will still fall 16 feet if it is aimed horizontally. What happens if we shoot a bullet faster and faster? Do not forget that the earth\u2019s surface is curved. If we shoot it fast enough, then when it falls 16 feet it may be at just the same height above the ground as it was before. How can that be? It still falls, but the earth curves away, so it falls \u201caround\u201d the earth. The question is, how far does it have to go in one second so that the earth is 16 feet below the horizon? In Fig. 7\u20134 we see the earth with its 4000 -mile radius, and the tangential, straight line path that the bullet would take if there were no force. Now, if we use one of those wonderful theorems in geometry, which says that our tangent is the mean proportional between the two parts of the diameter cut by an equal chord, we see that the horizontal distance travelled is the mean proportional between the 16 feet fallen and the 8000 -mile diameter of the earth. The square root of (16/5280)\u00d78000 comes out very close to 5 miles. Thus we see that if the bullet moves at 5 miles a second, it then will continue to fall toward the earth at the same rate of 16 feet each second, but will never get any closer because the earth keeps curving away from it. Thus it was that Mr. Gagarin maintained himself in space while going 25,000 miles around the earth at approximately 5 miles per second. (He took a little longer because he was a little higher.) Any great discovery of a new law is useful only if we can take more out than we put in. Now, Newton used the second and third of Kepler\u2019s laws to deduce his law of gravitation. What did he predict? First, his analysis of the moon\u2019s motion was a prediction because it connected the falling of objects on the earth\u2019s surface with that of the moon. Second, the question is, is the orbit an ellipse? We shall see in a later chapter how it is possible to calculate the motion exactly, and indeed one can prove that it should be an ellipse,3 so no extra fact is needed to explain Kepler\u2019s first law. Thus Newton made his first powerful prediction. The law of gravitation explains many phenomena not previously understood. For example, the pull of the moon on the earth causes the tides, hitherto mysterious. The moon pulls the water up under it and makes the tides\u2014people had thought of that before, but they were not as clever as Newton, and so they thought there ought to be only one tide during the day. The reasoning was that the moon pulls the water up under it, making a high tide and a low tide, and since the earth spins underneath, that makes the tide at one station go up and down every 24 hours. Actually the tide goes up and down in 12 hours. Another school of thought claimed that the high tide should be on the other side of the earth because, so they argued, the moon pulls the earth away from the water! Both of these theories are wrong. It actually works like this: the pull of the moon for the earth and for the water is \u201cbalanced\u201d at the center. But the water which is closer to the moon is pulled more than the average and the water which is farther away from it is pulled less than the average. Furthermore, the water can flow while the more rigid earth cannot. The true picture is a combination of these two things. What do we mean by \u201cbalanced\u201d? What balances? If the moon pulls the whole earth toward it, why doesn\u2019t the earth fall right \u201cup\u201d to the moon? Because the earth does the same trick as the moon, it goes in a circle around a point which is inside the earth but not at its center. The moon does not just go around the earth, the earth and the moon both go around a central position, each falling toward this common position, as shown in Fig. 7\u20135. This motion around the common center is what balances the fall of each. So the earth is not going in a straight line either; it travels in a circle. The water on the far side is \u201cunbalanced\u201d because the moon\u2019s attraction there is weaker than it is at the center of the earth, where it just balances the \u201ccentrifugal force.\u201d The result of this imbalance is that the water rises up, away from the center of the earth. On the near side, the attraction from the moon is stronger, and the imbalance is in the opposite direction in space, but again away from the center of the earth. The net result is that we get two tidal bulges. What else can we understand when we understand gravity? Everyone knows the earth is round. Why is the earth round? That is easy; it is due to gravitation. The earth can be understood to be round merely because everything attracts everything else and so it has attracted itself together as far as it can! If we go even further, the earth is not exactly a sphere because it is rotating, and this brings in centrifugal effects which tend to oppose gravity near the equator. It turns out that the earth should be elliptical, and we even get the right shape for the ellipse. We can thus deduce that the sun, the moon, and the earth should be (nearly) spheres, just from the law of gravitation. What else can you do with the law of gravitation? If we look at the moons of Jupiter we can understand everything about the way they move around that planet. Incidentally, there was once a certain difficulty with the moons of Jupiter that is worth remarking on. These satellites were studied very carefully by R\u00f8mer, who noticed that the moons sometimes seemed to be ahead of schedule, and sometimes behind. (One can find their schedules by waiting a very long time and finding out how long it takes on the average for the moons to go around.) Now they were ahead when Jupiter was particularly close to the earth and they were behind when Jupiter was farther from the earth. This would have been a very difficult thing to explain according to the law of gravitation\u2014it would have been, in fact, the death of this wonderful theory if there were no other explanation. If a law does not work even in one place where it ought to, it is just wrong. But the reason for this discrepancy was very simple and beautiful: it takes a little while to see the moons of Jupiter because of the time it takes light to travel from Jupiter to the earth. When Jupiter is closer to the earth the time is a little less, and when it is farther from the earth, the time is more. This is why moons appear to be, on the average, a little ahead or a little behind, depending on whether they are closer to or farther from the earth. This phenomenon showed that light does not travel instantaneously, and furnished the first estimate of the speed of light. This was done in 1676. If all of the planets pull on each other, the force which controls, let us say, Jupiter in going around the sun is not just the force from the sun; there is also a pull from, say, Saturn. This force is not really strong, since the sun is much more massive than Saturn, but there is some pull, so the orbit of Jupiter should not be a perfect ellipse, and it is not; it is slightly off, and \u201cwobbles\u201d around the correct elliptical orbit. Such a motion is a little more complicated. Attempts were made to analyze the motions of Jupiter, Saturn, and Uranus on the basis of the law of gravitation. The effects of each of these planets on each other were calculated to see whether or not the tiny deviations and irregularities in these motions could be completely understood from this one law. Lo and behold, for Jupiter and Saturn, all was well, but Uranus was \u201cweird.\u201d It behaved in a very peculiar manner. It was not travelling in an exact ellipse, but that was understandable, because of the attractions of Jupiter and Saturn. But even if allowance were made for these attractions, Uranus still was not going right, so the laws of gravitation were in danger of being overturned, a possibility that could not be ruled out. Two men, Adams and Le Verrier, in England and France, independently, arrived at another possibility: perhaps there is another planet, dark and invisible, which men had not seen. This planet, N , could pull on Uranus. They calculated where such a planet would have to be in order to cause the observed perturbations. They sent messages to the respective observatories, saying, \u201cGentlemen, point your telescope to such and such a place, and you will see a new planet.\u201d It often depends on with whom you are working as to whether they pay any attention to you or not. They did pay attention to Le Verrier; they looked, and there planet N was! The other observatory then also looked very quickly in the next few days and saw it too. This discovery shows that Newton\u2019s laws are absolutely right in the solar system; but do they extend beyond the relatively small distances of the nearest planets? The first test lies in the question, do stars attract each other as well as planets? We have definite evidence that they do in the double stars. Figure 7\u20136 shows a double star\u2014two stars very close together (there is also a third star in the picture so that we will know that the photograph was not turned). The stars are also shown as they appeared several years later. We see that, relative to the \u201cfixed\u201d star, the axis of the pair has rotated, i.e., the two stars are going around each other. Do they rotate according to Newton\u2019s laws? Careful measurements of the relative positions of one such double star system are shown in Fig. 7\u20137. There we see a beautiful ellipse, the measures starting in 1862 and going all the way around to 1904 (by now it must have gone around once more). Everything coincides with Newton\u2019s laws, except that the star Sirius A is not at the focus. Why should that be? Because the plane of the ellipse is not in the \u201cplane of the sky.\u201d We are not looking at right angles to the orbit plane, and when an ellipse is viewed at a tilt, it remains an ellipse but the focus is no longer at the same place. Thus we can analyze double stars, moving about each other, according to the requirements of the gravitational law. That the law of gravitation is true at even bigger distances is indicated in Fig. 7\u20138. If one cannot see gravitation acting here, he has no soul. This figure shows one of the most beautiful things in the sky\u2014a globular star cluster. All of the dots are stars. Although they look as if they are packed solid toward the center, that is due to the fallibility of our instruments. Actually, the distances between even the centermost stars are very great and they very rarely collide. There are more stars in the interior than farther out, and as we move outward there are fewer and fewer. It is obvious that there is an attraction among these stars. It is clear that gravitation exists at these enormous dimensions, perhaps 100,000 times the size of the solar system. Let us now go further, and look at an entire galaxy, shown in Fig. 7\u20139. The shape of this galaxy indicates an obvious tendency for its matter to agglomerate. Of course we cannot prove that the law here is precisely inverse square, only that there is still an attraction, at this enormous dimension, that holds the whole thing together. One may say, \u201cWell, that is all very clever but why is it not just a ball?\u201d Because it is spinning and has angular momentum which it cannot give up as it contracts; it must contract mostly in a plane. (Incidentally, if you are looking for a good problem, the exact details of how the arms are formed and what determines the shapes of these galaxies has not been worked out.) It is, however, clear that the shape of the galaxy is due to gravitation even though the complexities of its structure have not yet allowed us to analyze it completely. In a galaxy we have a scale of perhaps 50,000 to 100,000 light years. The earth\u2019s distance from the sun is 8 1 3 light minutes, so you can see how large these dimensions are. Gravity appears to exist at even bigger dimensions, as indicated by Fig. 7\u201310, which shows many \u201clittle\u201d things clustered together. This is a cluster of galaxies, just like a star cluster. Thus galaxies attract each other at such distances that they too are agglomerated into clusters. Perhaps gravitation exists even over distances of tens of millions of light years; so far as we now know, gravity seems to go out forever inversely as the square of the distance. Not only can we understand the nebulae, but from the law of gravitation we can even get some ideas about the origin of the stars. If we have a big cloud of dust and gas, as indicated in Fig. 7\u201311, the gravitational attractions of the pieces of dust for one another might make them form little lumps. Barely visible in the figure are \u201clittle\u201d black spots which may be the beginning of the accumulations of dust and gases which, due to their gravitation, begin to form stars. Whether we have ever seen a star form or not is still debatable. Figure 7\u201312 shows the one piece of evidence which suggests that we have. At the left is a picture of a region of gas with some stars in it taken in 1947, and at the right is another picture, taken only 7 years later, which shows two new bright spots. Has gas accumulated, has gravity acted hard enough and collected it into a ball big enough that the stellar nuclear reaction starts in the interior and turns it into a star? Perhaps, and perhaps not. It is unreasonable that in only seven years we should be so lucky as to see a star change itself into visible form; it is much less probable that we should see two! Gravitation, therefore, extends over enormous distances. But if there is a force between any pair of objects, we ought to be able to measure the force between our own objects. Instead of having to watch the stars go around each other, why can we not take a ball of lead and a marble and watch the marble go toward the ball of lead? The difficulty of this experiment when done in such a simple manner is the very weakness or delicacy of the force. It must be done with extreme care, which means covering the apparatus to keep the air out, making sure it is not electrically charged, and so on; then the force can be measured. It was first measured by Cavendish with an apparatus which is schematically indicated in Fig. 7\u201313. This first demonstrated the direct force between two large, fixed balls of lead and two smaller balls of lead on the ends of an arm supported by a very fine fiber, called a torsion fiber. By measuring how much the fiber gets twisted, one can measure the strength of the force, verify that it is inversely proportional to the square of the distance, and determine how strong it is. Thus, one may accurately determine the coefficient G in the formula F=G m m \u2032 r 2 . \u2032 All the masses and distances are known. You say, \u201cWe knew it already for the earth.\u201d Yes, but we did not know the mass of the earth. By knowing G from this experiment and by knowing how strongly the earth attracts, we can indirectly learn how great is the mass of the earth! This experiment has been called \u201cweighing the earth\u201d by some people, and it can be used to determine the coefficient G of the gravity law. This is the only way in which the mass of the earth can be determined. G turns out to be 6.670\u00d7 10 \u221211 newton\u22c5 m 2 / kg 2 . 2 It is hard to exaggerate the importance of the effect on the history of science produced by this great success of the theory of gravitation. Compare the confusion, the lack of confidence, the incomplete knowledge that prevailed in the earlier ages, when there were endless debates and paradoxes, with the clarity and simplicity of this law\u2014this fact that all the moons and planets and stars have such a simple rule to govern them, and further that man could understand it and deduce how the planets should move! This is the reason for the success of the sciences in following years, for it gave hope that the other phenomena of the world might also have such beautifully simple laws. But is this such a simple law? What about the machinery of it? All we have done is to describe how the earth moves around the sun, but we have not said what makes it go. Newton made no hypotheses about this; he was satisfied to find what it did without getting into the machinery of it. No one has since given any machinery. It is characteristic of the physical laws that they have this abstract character. The law of conservation of energy is a theorem concerning quantities that have to be calculated and added together, with no mention of the machinery, and likewise the great laws of mechanics are quantitative mathematical laws for which no machinery is available. Why can we use mathematics to describe nature without a mechanism behind it? No one knows. We have to keep going because we find out more that way. Many mechanisms for gravitation have been suggested. It is interesting to consider one of these, which many people have thought of from time to time. At first, one is quite excited and happy when he \u201cdiscovers\u201d it, but he soon finds that it is not correct. It was first discovered about 1750. Suppose there were many particles moving in space at a very high speed in all directions and being only slightly absorbed in going through matter. When they are absorbed, they give an impulse to the earth. However, since there are as many going one way as another, the impulses all balance. But when the sun is nearby, the particles coming toward the earth through the sun are partially absorbed, so fewer of them are coming from the sun than are coming from the other side. Therefore, the earth feels a net impulse toward the sun and it does not take one long to see that it is inversely as the square of the distance\u2014because of the variation of the solid angle that the sun subtends as we vary the distance. What is wrong with that machinery? It involves some new consequences which are not true. This particular idea has the following trouble: the earth, in moving around the sun, would impinge on more particles which are coming from its forward side than from its hind side (when you run in the rain, the rain in your face is stronger than that on the back of your head!). Therefore there would be more impulse given the earth from the front, and the earth would feel a resistance to motion and would be slowing up in its orbit. One can calculate how long it would take for the earth to stop as a result of this resistance, and it would not take long enough for the earth to still be in its orbit, so this mechanism does not work. No machinery has ever been invented that \u201cexplains\u201d gravity without also predicting some other phenomenon that does not exist. Next we shall discuss the possible relation of gravitation to other forces. There is no explanation of gravitation in terms of other forces at the present time. It is not an aspect of electricity or anything like that, so we have no explanation. However, gravitation and other forces are very similar, and it is interesting to note analogies. For example, the force of electricity between two charged objects looks just like the law of gravitation: the force of electricity is a constant, with a minus sign, times the product of the charges, and varies inversely as the square of the distance. It is in the opposite direction\u2014likes repel. But is it still not very remarkable that the two laws involve the same function of distance? Perhaps gravitation and electricity are much more closely related than we think. Many attempts have been made to unify them; the so-called unified field theory is only a very elegant attempt to combine electricity and gravitation; but, in comparing gravitation and electricity, the most interesting thing is the relative strengths of the forces. Any theory that contains them both must also deduce how strong the gravity is. If we take, in some natural units, the repulsion of two electrons (nature\u2019s universal charge) due to electricity, and the attraction of two electrons due to their masses, we can measure the ratio of electrical repulsion to the gravitational attraction. The ratio is independent of the distance and is a fundamental constant of nature. The ratio is shown in Fig. 7\u201314. The gravitational attraction relative to the electrical repulsion between two electrons is 1 divided by 4.17\u00d7 10 42 ! The question is, where does such a large number come from? It is not accidental, like the ratio of the volume of the earth to the volume of a flea. We have considered two natural aspects of the same thing, an electron. This fantastic number is a natural constant, so it involves something deep in nature. Where could such a tremendous number come from? Some say that we shall one day find the \u201cuniversal equation,\u201d and in it, one of the roots will be this number. It is very difficult to find an equation for which such a fantastic number is a natural root. Other possibilities have been thought of; one is to relate it to the age of the universe. Clearly, we have to find another large number somewhere. But do we mean the age of the universe in years? No, because years are not \u201cnatural\u201d; they were devised by men. As an example of something natural, let us consider the time it takes light to go across a proton, 10 \u221224 second. If we compare this time with the age of the universe, 2\u00d7 10 10 years, the answer is 10 \u221242 . It has about the same number of zeros going off it, so it has been proposed that the gravitational constant is related to the age of the universe. If that were the case, the gravitational constant would change with time, because as the universe got older the ratio of the age of the universe to the time which it takes for light to go across a proton would be gradually increasing. Is it possible that the gravitational constant is changing with time? Of course the changes would be so small that it is quite difficult to be sure. One test which we can think of is to determine what would have been the effect of the change during the past 10 9 years, which is approximately the age from the earliest life on the earth to now, and one-tenth of the age of the universe. In this time, the gravity constant would have increased by about 10 percent. It turns out that if we consider the structure of the sun\u2014the balance between the weight of its material and the rate at which radiant energy is generated inside it\u2014we can deduce that if the gravity were 10 percent stronger, the sun would be much more than 10 percent brighter\u2014by the sixth power of the gravity constant! If we calculate what happens to the orbit of the earth when the gravity is changing, we find that the earth was then closer in. Altogether, the earth would be about 100 degrees centigrade hotter, and all of the water would not have been in the sea, but vapor in the air, so life would not have started in the sea. So we do not now believe that the gravity constant is changing with the age of the universe. But such arguments as the one we have just given are not very convincing, and the subject is not completely closed. It is a fact that the force of gravitation is proportional to the mass, the quantity which is fundamentally a measure of inertia\u2014of how hard it is to hold something which is going around in a circle. Therefore two objects, one heavy and one light, going around a larger object in the same circle at the same speed because of gravity, will stay together because to go in a circle requires a force which is stronger for a bigger mass. That is, the gravity is stronger for a given mass in just the right proportion so that the two objects will go around together. If one object were inside the other it would stay inside; it is a perfect balance. Therefore, Gagarin or Titov would find things \u201cweightless\u201d inside a space ship; if they happened to let go of a piece of chalk, for example, it would go around the earth in exactly the same way as the whole space ship, and so it would appear to remain suspended before them in space. It is very interesting that this force is exactly proportional to the mass with great precision, because if it were not exactly proportional there would be some effect by which inertia and weight would differ. The absence of such an effect has been checked with great accuracy by an experiment done first by E\u00f6tv\u00f6s in 1909 and more recently by Dicke. For all substances tried, the masses and weights are exactly proportional within 1 part in 1,000,000,000 , or less. This is a remarkable experiment. Another topic deserving discussion is Einstein\u2019s modification of Newton\u2019s law of gravitation. In spite of all the excitement it created, Newton\u2019s law of gravitation is not correct! It was modified by Einstein to take into account the theory of relativity. According to Newton, the gravitational effect is instantaneous, that is, if we were to move a mass, we would at once feel a new force because of the new position of that mass; by such means we could send signals at infinite speed. Einstein advanced arguments which suggest that we cannot send signals faster than the speed of light, so the law of gravitation must be wrong. By correcting it to take the delays into account, we have a new law, called Einstein\u2019s law of gravitation. One feature of this new law which is quite easy to understand is this: In the Einstein relativity theory, anything which has energy has mass\u2014mass in the sense that it is attracted gravitationally. Even light, which has an energy, has a \u201cmass.\u201d When a light beam, which has energy in it, comes past the sun there is an attraction on it by the sun. Thus the light does not go straight, but is deflected. During the eclipse of the sun, for example, the stars which are around the sun should appear displaced from where they would be if the sun were not there, and this has been observed. Finally, let us compare gravitation with other theories. In recent years we have discovered that all mass is made of tiny particles and that there are several kinds of interactions, such as nuclear forces, etc. None of these nuclear or electrical forces has yet been found to explain gravitation. The quantum-mechanical aspects of nature have not yet been carried over to gravitation. When the scale is so small that we need the quantum effects, the gravitational effects are so weak that the need for a quantum theory of gravitation has not yet developed. On the other hand, for consistency in our physical theories it would be important to see whether Newton\u2019s law modified to Einstein\u2019s law can be further modified to be consistent with the uncertainty principle. This last modification has not yet been completed."
    },
    {
        "input": "Electrodynamics in Relativistic Notation",
        "output": "We now discuss the application of the special theory of relativity to electrodynamics. Since we have already studied the special theory of relativity in Chapters 15 through 17 of Vol. I, we will just review quickly the basic ideas. It is found experimentally that the laws of physics are unchanged if we move with uniform velocity. You can\u2019t tell if you are inside a spaceship moving with uniform velocity in a straight line, unless you look outside the spaceship, or at least make an observation having to do with the world outside. Any true law of physics we write down must be arranged so that this fact of nature is built in. The relationship between the space and time of two systems of coordinates, one, S\u2032 , in uniform motion in the x -direction with speed v relative to the other, S , is given by the Lorentz transformation: t\u2032 = t\u2212vx \u221a 1\u2212v2 , y\u2032 =y, x\u2032 = x\u2212vt \u221a 1\u2212v2 , z\u2032 =z. The laws of physics must be such that after a Lorentz transformation, the new form of the laws looks just like the old form. This is just like the principle that the laws of physics don\u2019t depend on the orientation of our coordinate system. In Chapter 11 of Vol. I, we saw that the way to describe mathematically the invariance of physics with respect to rotations was to write our equations in terms of vectors. For example, if we have two vectors A=(Ax,Ay,Az)andB=(Bx,By,Bz), we found that the combination A\u22c5B=AxBx+AyBy+AzBz was not changed if we transformed to a rotated coordinate system. So we know that if we have a scalar product like A\u22c5B on both sides of an equation, the equation will have exactly the same form in all rotated coordinate systems. We also discovered an operator (see Chapter 2), \u2207=( \u2202 \u2202x , \u2202 \u2202y , \u2202 \u2202z ), which, when applied to a scalar function, gave three quantities which transform just like a vector. With this operator we defined the gradient, and in combination with other vectors, the divergence and the Laplacian. Finally we discovered that by taking sums of certain products of pairs of the components of two vectors we could get three new quantities which behaved like a new vector. We called it the cross product of two vectors. Using the cross product with our operator \u2207 we then defined the curl of a vector. Since we will be referring back to what we have done in vector analysis, we have put in Table 25\u20131 a summary of all the important vector operations in three dimensions that we have used in the past. The point is that it must be possible to write the equations of physics so that both sides transform the same way under rotations. If one side is a vector, the other side must also be a vector, and both sides will change together in exactly the same way if we rotate our coordinate system. Similarly, if one side is a scalar, the other side must also be a scalar, so that neither side changes when we rotate coordinates, and so on. Now in the case of special relativity, time and space are inextricably mixed, and we must do the analogous things for four dimensions. We want our equations to remain the same not only for rotations, but also for any inertial frame. That means that our equations should be invariant under the Lorentz transformation of equations (25.1). The purpose of this chapter is to show you how that can be done. Before we get started, however, we want to do something that makes our work a lot easier (and saves some confusion). And that is to choose our units of length and time so that the speed of light c is equal to 1 . You can think of it as taking our unit of time to be the time that it takes light to go one meter (which is about 3\u00d710\u22129 sec). We can even call this time unit \u201cone meter.\u201d Using this unit, all of our equations will show more clearly the space-time symmetry. Also, all the c \u2019s will disappear from our relativistic equations. (If this bothers you, you can always put the c \u2019s back into any equation by replacing every t by ct , or, in general, by sticking in a c wherever it is needed to make the dimensions of the equations come out right.) With this groundwork we are ready to begin. Our program is to do in the four dimensions of space-time all of the things we did with vectors for three dimensions. It is really quite a simple game; we just work by analogy. The only real complication is the notation (we\u2019ve already used up the vector symbol for three dimensions) and one slight twist of signs. First, by analogy with vectors in three dimensions, we define a four-vector as a set of the four quantities at , ax , ay , and az , which transform like t , x , y , and z when we change to a moving coordinate system. There are several different notations people use for a four-vector; we will write a\u03bc , by which we mean the group of four numbers (at,ax,ay,az) \u2014in other words, the subscript \u03bc can take on the four \u201cvalues\u201d t , x , y , z . It will also be convenient, at times, to indicate the three space components by a three-vector, like this: a\u03bc=(at,a) . We have already encountered one four-vector, which consists of the energy and momentum of a particle (Chapter 17, Vol. I): In our new notation we write p\u03bc=(E,p), which means that the four-vector p\u03bc is made up of the energy E and the three components of the three-vector p of a particle. It looks as though the game is really very simple\u2014for each three-vector in physics all we have to do is find what the remaining component should be, and we have a four-vector. To see that this is not the case, consider the velocity vector with components vx= dx dt ,vy= dy dt ,vz= dz dt . The question is: What is the time component? Instinct should give the right answer. Since four-vectors are like t , x , y , z , we would guess that the time component is vt= dt dt =1. This is wrong. The reason is that the t in each denominator is not an invariant when we make a Lorentz transformation. The numerators have the right behavior to make a four-vector, but the dt in the denominator spoils things; it is unsymmetric and is not the same in two different systems. It turns out that the four \u201cvelocity\u201d components which we have written down will become the components of a four-vector if we just divide by \u221a 1\u2212v2 . We can see that that is true because if we start with the momentum four-vector p\u03bc=(E,p)=( m0 \u221a 1\u2212v2 , m0v \u221a 1\u2212v2 ), and divide it by the rest mass m0 , which is an invariant scalar in four dimensions, we have p\u03bc m0 =( 1 \u221a 1\u2212v2 , v \u221a 1\u2212v2 ), which must still be a four-vector. (Dividing by an invariant scalar doesn\u2019t change the transformation properties.) So we can define the \u201cvelocity four-vector\u201d u\u03bc by ut = 1 \u221a 1\u2212v2 , uy = vy \u221a 1\u2212v2 , ux = vx \u221a 1\u2212v2 , uz = vz \u221a 1\u2212v2 , The four-velocity is a useful quantity; we can, for instance, write p\u03bc=m0u\u03bc. This is the typical sort of form an equation which is relativistically correct must have; each side is a four-vector. (The right-hand side is an invariant times a four-vector, which is still a four-vector.) It is an accident of life, if you wish, that under coordinate rotations the distance of a point from the origin does not change. This means mathematically that r2=x2+y2+z2 is an invariant. In other words, after a rotation r\u20322=r2 , or x\u20322+y\u20322+z\u20322=x2+y2+z2. Now the question is: Is there a similar quantity which is invariant under the Lorentz transformation? There is. From Eq. (25.1) you can see that t\u20322\u2212x\u20322=t2\u2212x2. That is pretty nice, except that it depends on a particular choice of the x -direction. We can fix that up by subtracting y2 and z2 . Then any Lorentz transformation plus a rotation will leave the quantity unchanged. So the quantity which is analogous to r2 for three dimensions, in four dimensions is t2\u2212x2\u2212y2\u2212z2. It is an invariant under what is called the \u201ccomplete Lorentz group\u201d\u2014which means for transformation of both translations at constant velocity and rotations. Now since this invariance is an algebraic matter depending only on the transformation rules of Eq. (25.1)\u2014plus rotations\u2014it is true for any four-vector (by definition they all transform the same). So for a four-vector a\u03bc we have that a \u20322 t \u2212a \u20322 x \u2212a \u20322 y \u2212a \u20322 z =a 2 t \u2212a 2 x \u2212a 2 y \u2212a 2 z . We will call this quantity the square of \u201cthe length\u201d of the four-vector a\u03bc . (Sometimes people change the sign of all the terms and call the length a 2 x +a 2 y +a 2 z \u2212a 2 t , so you\u2019ll have to watch out.) Now if we have two vectors a\u03bc and b\u03bc their corresponding components transform in the same way, so the combination atbt\u2212axbx\u2212ayby\u2212azbz is also an invariant (scalar) quantity. (We have in fact already proved this in Chapter 17 of Vol. I.) Clearly this expression is quite analogous to the dot product for vectors. We will, in fact, call it the dot product or scalar product of two four-vectors. It would seem logical to write it as a\u03bc\u22c5b\u03bc , so it would look like a dot product. But, unhappily, it\u2019s not done that way; it is usually written without the dot. So we will follow the convention and write the dot product simply as a\u03bcb\u03bc . So, by definition, a\u03bcb\u03bc=atbt\u2212axbx\u2212ayby\u2212azbz. Whenever you see two identical subscripts together (we will occasionally have to use \u03bd or some other letter instead of \u03bc ) it means that you are to take the four products and sum, remembering the minus sign for the products of the space components. With this convention the invariance of the scalar product under a Lorentz transformation can be written as a \u2032 \u03bc b \u2032 \u03bc =a\u03bcb\u03bc. Since the last three terms in (25.7) are just the scalar dot product in three dimensions, it is often more convenient to write a\u03bcb\u03bc=atbt\u2212a\u22c5b. It is also obvious that the four-dimensional length we described above can be written as a\u03bca\u03bc : a\u03bca\u03bc=a 2 t \u2212a 2 x \u2212a 2 y \u2212a 2 z =a 2 t \u2212a\u22c5a. It will also be convenient to sometimes write this quantity as a 2 \u03bc : a 2 \u03bc \u2261a\u03bca\u03bc. We will now give you an illustration of the usefulness of four-vector dot products. Antiprotons ( \u00af P ) are produced in large accelerators by the reaction P+P\u2192P+P+P+ \u00af P . That is, an energetic proton collides with a proton at rest (for example, in a hydrogen target placed in the beam), and if the incident proton has enough energy, a proton-antiproton pair may be produced, in addition to the two original protons.1 The question is: How much energy must be given to the incident proton to make this reaction energetically possible? The easiest way to get the answer is to consider what the reaction looks like in the center-of-mass (CM) system (see Fig. 25\u20131). We\u2019ll call the incident proton a and its four-momentum p a \u03bc . Similarly, we\u2019ll call the target proton b and its four-momentum p b \u03bc . If the incident proton has just barely enough energy to make the reaction go, the final state\u2014the situation after the collision\u2014will consist of a glob containing three protons and an antiproton at rest in the CM system. If the incident energy were slightly higher, the final state particles would have some kinetic energy and be moving apart; if the incident energy were slightly lower, there would not be enough energy to make the four particles. If we call p c \u03bc the total four-momentum of the whole glob in the final state, conservation of energy and momentum tells us that pa+pb=pc, and Ea+Eb=Ec. Combining these two equations, we can write that p a \u03bc +p b \u03bc =p c \u03bc . Now the important thing is that this is an equation among four-vectors, and is, therefore, true in any inertial frame. We can use this fact to simplify our calculations. We start by taking the \u201clength\u201d of each side of Eq. (25.9); they are, of course, also equal. We get (p a \u03bc +p b \u03bc )(p a \u03bc +p b \u03bc )=p c \u03bc p c \u03bc . Since p c \u03bc p c \u03bc is invariant, we can evaluate it in any coordinate system. In the CM system, the time component of p c \u03bc is the rest energy of four protons, namely 4M , and the space part p is zero; so p c \u03bc =(4M,0) . We have used the fact that the rest mass of an antiproton equals the rest mass of a proton, and we have called this common mass M . Thus, Eq. (25.10) becomes p a \u03bc p a \u03bc +2p a \u03bc p b \u03bc +p b \u03bc p b \u03bc =16M2. Now p a \u03bc p a \u03bc and p b \u03bc p b \u03bc are very easy, since the \u201clength\u201d of the momentum four-vector of any particle is just the mass of the particle squared: p\u03bcp\u03bc=E2\u2212p2=M2. This can be shown by direct calculation or, more cleverly, by noting that for a particle at rest p\u03bc=(M,0) , so p\u03bcp\u03bc=M2 . But since it is an invariant, it is equal to M2 in any frame. Using these results in Eq. (25.11), we have 2p a \u03bc p b \u03bc =14M2 or p a \u03bc p b \u03bc =7M2. Now we can also evaluate p a \u03bc p b \u03bc =p a \u03bc \u2032p b \u03bc \u2032 in the laboratory system. The four-vector p a \u03bc \u2032 can be written (Ea\u2032,pa\u2032) , while p b \u03bc \u2032=(M,0) , since it describes a proton at rest. Thus, p a \u03bc \u2032p b \u03bc \u2032 must also be equal to MEa\u2032 ; and since we know the scalar product is an invariant this must be numerically the same as what we found in (25.12). So we have that Ea\u2032=7M, which is the result we were after. The total energy of the initial proton must be at least 7M (about 6.6 GeV since M=938 MeV) or, subtracting the rest mass M , the kinetic energy must be at least 6M (about 5.6 GeV). The Bevatron accelerator at Berkeley was designed to give about 6.2 GeV of kinetic energy to the protons it accelerates, in order to be able to make antiprotons. Since scalar products are invariant, they are always interesting to evaluate. What about the \u201clength\u201d of the four-velocity u\u03bcu\u03bc ? u\u03bcu\u03bc=u 2 t \u2212u2= 1 1\u2212v2 \u2212 v2 1\u2212v2 =1. Thus, u\u03bc is the unit four-vector. The next thing that we have to discuss is the four-dimensional analog of the gradient. We recall (Chapter 14, Vol. I) that the three differential operators \u2202/\u2202x , \u2202/\u2202y , \u2202/\u2202z transform like a three-vector and are called the gradient. The same scheme ought to work in four dimensions; that is, we might guess that the four-dimensional gradient should be (\u2202/\u2202t,\u2202/\u2202x,\u2202/\u2202y,\u2202/\u2202z) . This is wrong. To see the error, consider a scalar function \u03d5 which depends only on x and t . The change in \u03d5 , if we make a small change \u0394t in t while holding x constant, is \u0394\u03d5= \u2202\u03d5 \u2202t \u0394t. On the other hand, according to a moving observer, \u0394\u03d5= \u2202\u03d5 \u2202x\u2032 \u0394x\u2032+ \u2202\u03d5 \u2202t\u2032 \u0394t\u2032. We can express \u0394x\u2032 and \u0394t\u2032 in terms of \u0394t by using Eq. (25.1). Remembering that we are holding x constant, so that \u0394x=0 , we write \u0394x\u2032=\u2212 v \u221a 1\u2212v2 \u0394t;\u0394t\u2032= \u0394t \u221a 1\u2212v2 . Thus, \u0394\u03d5 = \u2202\u03d5 \u2202x\u2032 (\u2212 v \u221a 1\u2212v2 \u0394t)+ \u2202\u03d5 \u2202t\u2032 ( \u0394t \u221a 1\u2212v2 ) =( \u2202\u03d5 \u2202t\u2032 \u2212v \u2202\u03d5 \u2202x\u2032 ) \u0394t \u221a 1\u2212v2 . Comparing this result with Eq. (25.13), we learn that \u2202\u03d5 \u2202t = 1 \u221a 1\u2212v2 ( \u2202\u03d5 \u2202t\u2032 \u2212v \u2202\u03d5 \u2202x\u2032 ). A similar calculation gives \u2202\u03d5 \u2202x = 1 \u221a 1\u2212v2 ( \u2202\u03d5 \u2202x\u2032 \u2212v \u2202\u03d5 \u2202t\u2032 ). Now we can see that the gradient is rather strange. The formulas for x and t in terms of x \u2032 and t \u2032 [obtained by solving Eq. (25.1)] are: t= t \u2032 +v x \u2032 1\u2212 v 2 \u2212 \u2212 \u2212 \u2212 \u2212 \u221a ,x= x \u2032 +v t \u2032 1\u2212 v 2 \u2212 \u2212 \u2212 \u2212 \u2212 \u221a . \u2032 \u2032 \u2032 \u2032 This is the way a four-vector must transform. But Eqs. (25.14) and (25.15) have a couple of signs wrong! The answer is that instead of the incorrect (\u2202/\u2202t,\u2207) , we must define the four-dimensional gradient operator, which we will call \u2207 \u03bc , by \u2207 \u03bc =( \u2202 \u2202t ,\u2212\u2207) =( \u2202 \u2202t ,\u2212 \u2202 \u2202x ,\u2212 \u2202 \u2202y ,\u2212 \u2202 \u2202z ). (25.16) With this definition, the sign difficulties encountered above go away, and \u2207 \u03bc behaves as a four-vector should. (It\u2019s rather awkward to have those minus signs, but that\u2019s the way the world is.) Of course, what it means to say that \u2207 \u03bc \u201cbehaves like a four-vector\u201d is simply that the four-gradient of a scalar is a four-vector. If \u03d5 is a true scalar invariant field (Lorentz invariant) then \u2207 \u03bc \u03d5 is a four-vector field. All right, now that we have vectors, gradients, and dot products, the next thing is to look for an invariant which is analogous to the divergence of three-dimensional vector analysis. Clearly, the analog is to form the expression \u2207 \u03bc b \u03bc , where b \u03bc is a four-vector field whose components are functions of space and time. We define the divergence of the four-vector b \u03bc =( b t ,b) as the dot product of \u2207 \u03bc and b \u03bc : \u2207 \u03bc b \u03bc = \u2202 \u2202t b t \u2212(\u2212 \u2202 \u2202x ) b x \u2212(\u2212 \u2202 \u2202y ) b y \u2212(\u2212 \u2202 \u2202z ) b z = \u2202 \u2202t b t +\u2207\u22c5b, (25.17) where \u2207\u22c5b is the ordinary three-divergence of the three-vector b . Note that one has to be careful with the signs. Some of the minus signs come from the definition of the scalar product, Eq. (25.7); the others are required because the space components of \u2207 \u03bc are \u2212\u2202/\u2202x , etc., as in Eq. (25.16). The divergence as defined by (25.17) is an invariant and gives the same answer in all coordinate systems which differ by a Lorentz transformation. Let\u2019s look at a physical example in which the four-divergence shows up. We can use it to solve the problem of the fields around a moving wire. We have already seen (Section 13-7) that the electric charge density \u03c1 and the current density j form a four-vector j \u03bc =(\u03c1,j) . If an uncharged wire carries the current j x , then in a frame moving past it with velocity v (along x ), the wire will have the charge and current density [obtained from the Lorentz transformation Eqs. (25.1)] as follows: \u03c1 \u2032 = \u2212v j x 1\u2212 v 2 \u2212 \u2212 \u2212 \u2212 \u2212 \u221a , j \u2032 x = j x 1\u2212 v 2 \u2212 \u2212 \u2212 \u2212 \u2212 \u221a . j j These are just what we found in Chapter 13. We can then use these sources in Maxwell\u2019s equations in the moving system to find the fields. The charge conservation law, Section 13-2, also takes on a simple form in the four-vector notation. Consider the four divergence of j \u03bc : \u2207 \u03bc j \u03bc = \u2202\u03c1 \u2202t +\u2207\u22c5j. (25.18) The law of the conservation of charge says that the outflow of current per unit volume must equal the negative rate of increase of charge density. In other words, that \u2207\u22c5j=\u2212 \u2202\u03c1 \u2202t . \u2202 Putting this into Eq. (25.18), the law of conservation of charge takes on the simple form \u2207 \u03bc j \u03bc =0. (25.19) Since \u2207 \u03bc j \u03bc is an invariant scalar, if it is zero in one frame it is zero in all frames. We have the result that if charge is conserved in one coordinate system, it is conserved in all coordinate systems moving with uniform velocity. As our last example we want to consider the scalar product of the gradient operator \u2207 \u03bc with itself. In three dimensions, such a product gives the Laplacian \u2207 2 =\u2207\u22c5\u2207= \u2202 2 \u2202 x 2 + \u2202 2 \u2202 y 2 + \u2202 2 \u2202 z 2 . 2 2 2 What do we get in four dimensions? That\u2019s easy. Following our rules for dot products and gradients, we get \u2207 \u03bc \u2207 \u03bc = \u2202 \u2202t \u2202 \u2202t = \u2202 2 \u2202 t 2 \u2212(\u2212 \u2202 \u2202x )(\u2212 \u2202 \u2202x ) \u2212(\u2212 \u2202 \u2202y )(\u2212 \u2202 \u2202y ) \u2212(\u2212 \u2202 \u2202z )(\u2212 \u2202 \u2202z ) \u2212 \u2207 2 . This operator, which is the analog of the three-dimensional Laplacian, is called the d\u2019Alembertian and has a special notation: \u25a1 2 =\u2207 \u03bc \u2207 \u03bc = \u2202 2 \u2202 t 2 \u2212 \u2207 2 . (25.20) From its definition it is an invariant scalar operator; if it operates on a four-vector field, it produces a new four-vector field. (Some people define the d\u2019Alembertian with the opposite sign to Eq. (25.20), so you will have to be careful when reading the literature.) We have now found four-dimensional equivalents of most of the three-dimensional quantities we had listed in Table 25\u20131. (We do not yet have the equivalents of the cross product and the curl operation; we won\u2019t get to them until the next chapter.) It may help you remember how they go if we put all the important definitions and results together in one place, so we have made such a summary in Table 25\u20132. We have already encountered the d\u2019Alembertian operator, without giving it that name, in Section 18-6; the differential equations we found there for the potentials can be written in the new notations as: \u25a1 2 \u03d5= \u03c1 \u03f5 0 , \u25a1 2 A= j \u03f5 0 . (25.21) The four quantities on the right-hand side of the two equations in (25.21) are \u03c1 , j x , j y , j z divided by \u03f5 0 , which is a universal constant which will be the same in all coordinate systems if the same unit of charge is used in all frames. So the four quantities \u03c1/ \u03f5 0 , j x / \u03f5 0 , j y / \u03f5 0 , j z / \u03f5 0 also transform as a four-vector. We can write them as j \u03bc / \u03f5 0 . The d\u2019Alembertian doesn\u2019t change when the coordinate system is changed, so the quantities \u03d5 , A x , A y , A z must also transform like a four-vector\u2014which means that they are the components of a four-vector. In short, A \u03bc =(\u03d5,A) ( \u03d5 ) is a four-vector. What we call the scalar and vector potentials are really different aspects of the same physical thing. They belong together. And if they are kept together the relativistic invariance of the world is obvious. We call A \u03bc the four-potential. In the four-vector notation Eqs. (25.21) become simply \u25a1 2 A \u03bc = j \u03bc \u03f5 0 , (25.22) The physics of this equation is just the same as Maxwell\u2019s equations. But there is some pleasure in being able to rewrite them in an elegant form. The pretty form is also meaningful; it shows directly the invariance of electrodynamics under the Lorentz transformation. Remember that Eqs. (25.21) could be deduced from Maxwell\u2019s equations only if we imposed the gauge condition \u2202\u03d5 \u2202t +\u2207\u22c5A=0, (25.23) which just says \u2207 \u03bc A \u03bc =0 ; the gauge condition says that the divergence of the four-vector A \u03bc is zero. This condition is called the Lorenz condition. It is very convenient because it is an invariant condition and therefore Maxwell\u2019s equations stay in the form of Eq. (25.22) for all frames. Although it is implicit in what we have already said, let us write down the transformation laws which give \u03d5 and A in a moving system in terms of \u03d5 and A in a stationary system. Since A \u03bc =(\u03d5,A) is a four-vector, the equations must look just like Eqs. (25.1), except that t is replaced by \u03d5 , and x is replaced by A . Thus, \u03d5 \u2032 A \u2032 x = \u03d5\u2212v A x 1\u2212 v 2 \u2212 \u2212 \u2212 \u2212 \u2212 \u221a , = A x \u2212v\u03d5 1\u2212 v 2 \u2212 \u2212 \u2212 \u2212 \u2212 \u221a , A \u2032 y A \u2032 z = A y , = A z . (25.24) This assumes that the primed coordinate system is moving with speed v in the positive x -direction, as measured in the unprimed coordinate system. We will consider one example of the usefulness of the idea of the four-potential. What are the vector and scalar potentials of a charge q moving with speed v along the x -axis? The problem is easy in a coordinate system moving with the charge, since in this system the charge is standing still. Let\u2019s say that the charge is at the origin of the S \u2032 -frame, as shown in Fig. 25\u20132. The scalar potential in the moving system is then given by \u03d5 \u2032 = q 4\u03c0 \u03f5 0 r \u2032 , (25.25) r \u2032 being the distance from q to the field point, as measured in the moving system. The vector potential A \u2032 is, of course, zero. Now it is straightforward to find \u03d5 and A , the potentials as measured in the stationary coordinates. The inverse relations to Eqs. (25.24) are \u03d5 A x = \u03d5 \u2032 +v A \u2032 x 1\u2212 v 2 \u2212 \u2212 \u2212 \u2212 \u2212 \u221a , = A \u2032 x +v \u03d5 \u2032 1\u2212 v 2 \u2212 \u2212 \u2212 \u2212 \u2212 \u221a , A y A z = A \u2032 y , = A \u2032 z . (25.26) Using the \u03d5 \u2032 given by Eq. (25.25), and A \u2032 =0 , we get \u03d5 = q 4\u03c0 \u03f5 0 1 r \u2032 1\u2212 v 2 \u2212 \u2212 \u2212 \u2212 \u2212 \u221a = q 4\u03c0 \u03f5 0 1 1\u2212 v 2 \u2212 \u2212 \u2212 \u2212 \u2212 \u221a x \u20322 + y \u20322 + z \u20322 \u2212 \u2212 \u2212 \u2212 \u2212 \u2212 \u2212 \u2212 \u2212 \u2212 \u2212 \u221a . This gives us the scalar potential \u03d5 we would see in S , but, unfortunately, expressed in terms of the S \u2032 coordinates. We can get things in terms of t , x , y , z by substituting for t \u2032 , x \u2032 , y \u2032 , and z \u2032 , using (25.1). We get \u03d5= q 4\u03c0 \u03f5 0 1 1\u2212 v 2 \u2212 \u2212 \u2212 \u2212 \u2212 \u221a \u00d7 1 [(x\u2212vt)/ 1\u2212 v 2 \u2212 \u2212 \u2212 \u2212 \u2212 \u221a ] 2 + y 2 + z 2 \u2212 \u2212 \u2212 \u2212 \u2212 \u2212 \u2212 \u2212 \u2212 \u2212 \u2212 \u2212 \u2212 \u2212 \u2212 \u2212 \u2212 \u2212 \u2212 \u2212 \u2212 \u2212 \u2212 \u2212 \u221a . (25.27) Following the same procedure for the components of A , you can show that A=v\u03d5. (25.28) These are the same formulas we derived by a different method in Chapter 21. We have found that the potentials \u03d5 and A taken together form a four-vector which we call A \u03bc , and that the wave equations\u2014the full equations which determine the A \u03bc in terms of the j \u03bc \u2014can be written as in Eq. (25.22). This equation, together with the conservation of charge, Eq. (25.19), gives us the fundamental law of the electromagnetic field: \u25a1 2 A \u03bc = 1 \u03f5 0 j \u03bc ,\u2207 \u03bc j \u03bc =0. (25.29) There, in one tiny space on the page, are all of the Maxwell equations\u2014beautiful and simple. Did we learn anything from writing the equations this way, besides that they are beautiful and simple? In the first place, is it anything different from what we had before when we wrote everything out in all the various components? Can we from this equation deduce something that could not be deduced from the wave equations for the potentials in terms of the charges and currents? The answer is definitely no. The only thing we have been doing is changing the names of things\u2014using a new notation. We have written a square symbol to represent the derivatives, but it still means nothing more nor less than the second derivative with respect to t , minus the second derivative with respect to x , minus the second derivative with respect to y , minus the second derivative with respect to z . And the \u03bc means that we have four equations, one each for \u03bc=t , x , y , or z . What then is the significance of the fact that the equations can be written in this simple form? From the point of view of deducing anything directly, it doesn\u2019t mean anything. Perhaps, though, the simplicity of the equations means that nature also has a certain simplicity. Let us show you something interesting that we have recently discovered: All of the laws of physics can be contained in one equation. That equation is U=0. (25.30) What a simple equation! Of course, it is necessary to know what the symbol means. U is a physical quantity which we will call the \u201cunworldliness\u201d of the situation. And we have a formula for it. Here is how you calculate the unworldliness. You take all of the known physical laws and write them in a special form. For example, suppose you take the law of mechanics, F=ma , and rewrite it as F\u2212ma=0 . Then you can call (F\u2212ma) \u2014which should, of course, be zero\u2014the \u201cmismatch\u201d of mechanics. Next, you take the square of this mismatch and call it U 1 , which can be called the \u201cunworldliness of mechanical effects.\u201d In other words, you take U 1 =(F\u2212ma ) 2 . (25.31) Now you write another physical law, say, \u2207\u22c5E=\u03c1/ \u03f5 0 and define U 2 =(\u2207\u22c5E\u2212 \u03c1 \u03f5 0 ) 2 , \u03c1 2 which you might call \u201cthe Gaussian unworldliness of electricity.\u201d You continue to write U 3 , U 4 , and so on\u2014one for every physical law there is. Finally you call the total unworldliness U of the world the sum of the various unworldlinesses U i from all the subphenomena that are involved; that is, U=\u2211 U i . Then the great \u201claw of nature\u201d is U=0. (25.32) This \u201claw\u201d means, of course, that the sum of the squares of all the individual mismatches is zero, and the only way the sum of a lot of squares can be zero is for each one of the terms to be zero. So the \u201cbeautifully simple\u201d law in Eq. (25.32) is equivalent to the whole series of equations that you originally wrote down. It is therefore absolutely obvious that a simple notation that just hides the complexity in the definitions of symbols is not real simplicity. It is just a trick. The beauty that appears in Eq. (25.32)\u2014just from the fact that several equations are hidden within it\u2014is no more than a trick. When you unwrap the whole thing, you get back where you were before. However, there is more to the simplicity of the laws of electromagnetism written in the form of Eq. (25.29). It means more, just as a theory of vector analysis means more. The fact that the electromagnetic equations can be written in a very particular notation which was designed for the four-dimensional geometry of the Lorentz transformations\u2014in other words, as a vector equation in the four-space\u2014means that it is invariant under the Lorentz transformations. It is because the Maxwell equations are invariant under those transformations that they can be written in a beautiful form. It is no accident that the equations of electrodynamics can be written in the beautifully elegant form of Eq. (25.29). The theory of relativity was developed because it was found experimentally that the phenomena predicted by Maxwell\u2019s equations were the same in all inertial systems. And it was precisely by studying the transformation properties of Maxwell\u2019s equations that Lorentz discovered his transformation as the one which left the equations invariant. There is, however, another reason for writing our equations this way. It has been discovered\u2014after Einstein guessed that it might be so\u2014that all of the laws of physics are invariant under the Lorentz transformation. That is the principle of relativity. Therefore, if we invent a notation which shows immediately when a law is written down whether it is invariant or not, we can be sure that in trying to make new theories we will write only equations which are consistent with the principle of relativity. The fact that the Maxwell equations are simple in this particular notation is not a miracle, because the notation was invented with them in mind. But the interesting physical thing is that every law of physics\u2014the propagation of meson waves or the behavior of neutrinos in beta decay, and so forth\u2014must have this same invariance under the same transformation. Then when you are moving at a uniform velocity in a spaceship, all of the laws of nature transform together in such a way that no new phenomenon will show up. It is because the principle of relativity is a fact of nature that in the notation of four-dimensional vectors the equations of the world will look simple."
    },
    {
        "input": "The Hamiltonian Matrix",
        "output": "Before we begin the main topic of this chapter, we would like to describe a number of mathematical ideas that are used a lot in the literature of quantum mechanics. Knowing them will make it easier for you to read other books or papers on the subject. The first idea is the close mathematical resemblance between the equations of quantum mechanics and those of the scalar product of two vectors. You remember that if \u03c7 and \u03d5 are two states, the amplitude to start in \u03d5 and end up in \u03c7 can be written as a sum over a complete set of base states of the amplitude to go from \u03d5 into one of the base states and then from that base state out again into \u03c7 : \u27e8\u03c7|\u03d5\u27e9= \u2211 all i \u27e8\u03c7|i\u27e9\u27e8i|\u03d5\u27e9. We explained this in terms of a Stern-Gerlach apparatus, but we remind you that there is no need to have the apparatus. Equation (8.1) is a mathematical law that is just as true whether we put the filtering equipment in or not\u2014it is not always necessary to imagine that the apparatus is there. We can think of it simply as a formula for the amplitude \u27e8\u03c7|\u03d5\u27e9 . We would like to compare Eq. (8.1) to the formula for the dot product of two vectors B and A . If B and A are ordinary vectors in three dimensions, we can write the dot product this way: \u2211 all i (B\u22c5ei)(ei\u22c5A), with the understanding that the symbol ei stands for the three unit vectors in the x , y , and z -directions. Then B\u22c5e1 is what we ordinarily call Bx ; B\u22c5e2 is what we ordinarily call By ; and so on. So Eq. (8.2) is equivalent to BxAx+ByAy+BzAz, which is the dot product B\u22c5A . Comparing Eqs. (8.1) and (8.2), we can see the following analogy: The states \u03c7 and \u03d5 correspond to the two vectors B and A . The base states i correspond to the special vectors e i to which we refer all other vectors. Any vector can be represented as a linear combination of the three \u201cbase vectors\u201d e i . Furthermore, if you know the coefficients of each \u201cbase vector\u201d in this combination\u2014that is, its three components\u2014you know everything about a vector. In a similar way, any quantum mechanical state can be described completely by the amplitude \u27e8i|\u03d5\u27e9 to go into the base states; and if you know these coefficients, you know everything there is to know about the state. Because of this close analogy, what we have called a \u201cstate\u201d is often also called a \u201cstate vector.\u201d Since the base vectors e i are all at right angles, we have the relation e i \u22c5 e j = \u03b4 ij . (8.3) This corresponds to the relations (5.25) among the base states i , \u27e8i|j\u27e9= \u03b4 ij . (8.4) You see now why one says that the base states i are all \u201corthogonal.\u201d There is one minor difference between Eq. (8.1) and the dot product. We have that \u27e8\u03d5|\u03c7\u27e9=\u27e8\u03c7|\u03d5 \u27e9 \u2217 . (8.5) But in vector algebra A\u22c5B=B\u22c5A. A B B A With the complex numbers of quantum mechanics we have to keep straight the order of the terms, whereas in the dot product, the order doesn\u2019t matter. Now consider the following vector equation: A= \u2211 i e i ( e i \u22c5A). (8.6) It\u2019s a little unusual, but correct. It means the same thing as A= \u2211 i A i e i = A x e x + A y e y + A z e z . (8.7) Notice, though, that Eq. (8.6) involves a quantity which is different from a dot product. A dot product is just a number, whereas Eq. (8.6) is a vector equation. One of the great tricks of vector analysis was to abstract away from the equations the idea of a vector itself. One might be similarly inclined to abstract a thing that is the analog of a \u201cvector\u201d from the quantum mechanical formula Eq. (8.1)\u2014and one can indeed. We remove the \u27e8\u03c7| from both sides of Eq. (8.1) and write the following equation (don\u2019t get frightened\u2014it\u2019s just a notation and in a few minutes you will find out what the symbols mean): |\u03d5\u27e9= \u2211 i |i\u27e9\u27e8i|\u03d5\u27e9. (8.8) One thinks of the bracket \u27e8\u03c7|\u03d5\u27e9 as being divided into two pieces. The second piece |\u03d5\u27e9 is often called a ket, and the first piece \u27e8\u03c7| is called a bra (put together, they make a \u201cbra-ket\u201d\u2014a notation proposed by Dirac); the half-symbols |\u03d5\u27e9 and \u27e8\u03c7| are also called state vectors. In any case, they are not numbers, and, in general, we want the results of our calculations to come out as numbers; so such \u201cunfinished\u201d quantities are only part-way steps in our calculations. It happens that until now we have written all our results in terms of numbers. How have we managed to avoid vectors? It is amusing to note that even in ordinary vector algebra we could make all equations involve only numbers. For instance, instead of a vector equation like F=ma, F we could always have written C\u22c5F=C\u22c5(ma). ( ) We have then an equation between dot products that is true for any vector C . But if it is true for any C , it hardly makes sense at all to keep writing the C ! Now look at Eq. (8.1). It is an equation that is true for any \u03c7 . So to save writing, we should just leave out the \u03c7 and write Eq. (8.8) instead. It has the same information provided we understand that it should always be \u201cfinished\u201d by \u201cmultiplying on the left by\u201d\u2014which simply means reinserting\u2014some \u27e8\u03c7| on both sides. So Eq. (8.8) means exactly the same thing as Eq. (8.1)\u2014no more, no less. When you want numbers, you put in the \u27e8\u03c7| you want. Maybe you have already wondered about the \u03d5 in Eq. (8.8). Since the equation is true for any \u03d5 , why do we keep it? Indeed, Dirac suggests that the \u03d5 also can just as well be abstracted away, so that we have only |= \u2211 i |i\u27e9\u27e8i|. (8.9) And this is the great law of quantum mechanics! (There is no analog in vector analysis.) It says that if you put in any two states \u03c7 and \u03d5 on the left and right of both sides, you get back Eq. (8.1). It is not really very useful, but it\u2019s a nice reminder that the equation is true for any two states. Let\u2019s look at Eq. (8.8) again; we can think of it in the following way. Any state vector |\u03d5\u27e9 can be represented as a linear combination with suitable coefficients of a set of base \u201cvectors\u201d\u2014or, if you prefer, as a superposition of \u201cunit vectors\u201d in suitable proportions. To emphasize that the coefficients \u27e8i|\u03d5\u27e9 are just ordinary (complex) numbers, suppose we write \u27e8i|\u03d5\u27e9= C i . \u27e8 | \u03d5 \u27e9 Then Eq. (8.8) is the same as |\u03d5\u27e9= \u2211 i |i\u27e9 C i . (8.10) We can write a similar equation for any other state vector, say |\u03c7\u27e9 , with, of course, different coefficients\u2014say D i . Then we have |\u03c7\u27e9= \u2211 i |i\u27e9 D i . (8.11) The D i are just the amplitudes \u27e8i|\u03c7\u27e9 . Suppose we had started by abstracting the \u03d5 from Eq. (8.1). We would have had \u27e8\u03c7|= \u2211 i \u27e8\u03c7|i\u27e9\u27e8i|. (8.12) Remembering that \u27e8\u03c7|i\u27e9=\u27e8i|\u03c7 \u27e9 \u2217 , we can write this as \u27e8\u03c7|= \u2211 i D \u2217 i \u27e8i|. (8.13) Now the interesting thing is that we can just multiply Eq. (8.13) and Eq. (8.10) to get back \u27e8\u03c7|\u03d5\u27e9 . When we do that, we have to be careful of the summation indices, because they are quite distinct in the two equations. Let\u2019s first rewrite Eq. (8.13) as \u27e8\u03c7|= \u2211 j D \u2217 j \u27e8j|, \u2211 \u2217 which changes nothing. Then putting it together with Eq. (8.10), we have \u27e8\u03c7|\u03d5\u27e9= \u2211 ij D \u2217 j \u27e8j|i\u27e9 C i . (8.14) Remember, though, that \u27e8j|i\u27e9= \u03b4 ij , so that in the sum we have left only the terms with j=i . We get \u27e8\u03c7|\u03d5\u27e9= \u2211 i D \u2217 i C i , (8.15) where, of course, D \u2217 i = \u27e8i|\u03c7 \u27e9 \u2217 = \u27e8\u03c7|i\u27e9 , and C i =\u27e8i|\u03d5\u27e9 . Again we see the close analogy with the dot product B\u22c5A= \u2211 i B i A i . \u2211 The only difference is the complex conjugate on D i . So Eq. (8.15) says that if the state vectors \u27e8\u03c7| and |\u03d5\u27e9 are expanded in terms of the base vectors \u27e8i| or |i\u27e9 , the amplitude to go from \u03d5 to \u03c7 is given by the kind of dot product in Eq. (8.15). This equation is, of course, just Eq. (8.1) written with different symbols. So we have just gone in a circle to get used to the new symbols. We should perhaps emphasize again that while space vectors in three dimensions are described in terms of three orthogonal unit vectors, the base vectors |i\u27e9 of the quantum mechanical states must range over the complete set applicable to any particular problem. Depending on the situation, two, or three, or five, or an infinite number of base states may be involved. We have also talked about what happens when particles go through an apparatus. If we start the particles out in a certain state \u03d5 , then send them through an apparatus, and afterward make a measurement to see if they are in state \u03c7 , the result is described by the amplitude \u27e8\u03c7|A|\u03d5\u27e9. (8.16) Such a symbol doesn\u2019t have a close analog in vector algebra. (It is closer to tensor algebra, but the analogy is not particularly useful.) We saw in Chapter 5, Eq. (5.32), that we could write (8.16) as \u27e8\u03c7|A|\u03d5\u27e9= \u2211 ij \u27e8\u03c7|i\u27e9\u27e8i|A|j\u27e9\u27e8j|\u03d5\u27e9. (8.17) This is just an example of the fundamental rule Eq. (8.9), used twice. We also found that if another apparatus B was added in series with A , then we could write \u27e8\u03c7|BA|\u03d5\u27e9= \u2211 ijk \u27e8\u03c7|i\u27e9\u27e8i|B|j\u27e9\u27e8j|A|k\u27e9\u27e8k|\u03d5\u27e9. (8.18) Again, this comes directly from Dirac\u2019s method of writing Eq. (8.9)\u2014remember that we can always place a bar ( | ), which is just like the factor 1 , between B and A . Incidentally, we can think of Eq. (8.17) in another way. Suppose we think of the particle entering apparatus A in the state \u03d5 and coming out of A in the state \u03c8 , (\u201cpsi\u201d). In other words, we could ask ourselves this question: Can we find a \u03c8 such that the amplitude to get from \u03c8 to \u03c7 is always identically and everywhere the same as the amplitude \u27e8\u03c7|A|\u03d5\u27e9 ? The answer is yes. We want Eq. (8.17) to be replaced by \u27e8\u03c7|\u03c8\u27e9= \u2211 i \u27e8\u03c7|i\u27e9\u27e8i|\u03c8\u27e9. (8.19) We can clearly do this if \u27e8i|\u03c8\u27e9= \u2211 j \u27e8i|A|j\u27e9\u27e8j|\u03d5\u27e9=\u27e8i|A|\u03d5\u27e9, (8.20) which determines \u03c8 . \u201cBut it doesn\u2019t determine \u03c8 ,\u201d you say; \u201cit only determines \u27e8i|\u03c8\u27e9 .\u201d However, \u27e8i|\u03c8\u27e9 does determine \u03c8 , because if you have all the coefficients that relate \u03c8 to the base states i , then \u03c8 is uniquely defined. In fact, we can play with our notation and write the last term of Eq. (8.20) as \u27e8i|\u03c8\u27e9= \u2211 j \u27e8i|j\u27e9\u27e8j|A|\u03d5\u27e9. (8.21) Then, since this equation is true for all i , we can write simply |\u03c8\u27e9= \u2211 j |j\u27e9\u27e8j|A|\u03d5\u27e9. (8.22) Then we can say: \u201cThe state \u03c8 is what we get if we start with \u03d5 and go through the apparatus A .\u201d One final example of the tricks of the trade. We start again with Eq. (8.17). Since it is true for any \u03c7 and \u03d5 , we can drop them both! We then get1 A= \u2211 ij |i\u27e9\u27e8i|A|j\u27e9\u27e8j|. (8.23) What does it mean? It means no more, no less, than what you get if you put back the \u03d5 and \u03c7 . As it stands, it is an \u201copen\u201d equation and incomplete. If we multiply it \u201con the right\u201d by |\u03d5\u27e9 , it becomes A|\u03d5\u27e9= \u2211 ij |i\u27e9\u27e8i|A|j\u27e9\u27e8j|\u03d5\u27e9, (8.24) which is just Eq. (8.22) all over again. In fact, we could have just dropped the j \u2019s from that equation and written |\u03c8\u27e9=A|\u03d5\u27e9. (8.25) The symbol A is neither an amplitude, nor a vector; it is a new kind of thing called an operator. It is something which \u201coperates on\u201d a state to produce a new state\u2014Eq. (8.25) says that |\u03c8\u27e9 is what results if A operates on |\u03d5\u27e9 . Again, it is still an open equation until it is completed with some bra like \u27e8\u03c7| to give \u27e8\u03c7|\u03c8\u27e9=\u27e8\u03c7|A|\u03d5\u27e9. (8.26) The operator A is, of course, described completely if we give the matrix of amplitudes \u27e8i|A|j\u27e9 \u2014also written A ij \u2014in terms of any set of base vectors. We have really added nothing new with all of this new mathematical notation. One reason for bringing it all up was to show you the way of writing pieces of equations, because in many books you will find the equations written in the incomplete forms, and there\u2019s no reason for you to be paralyzed when you come across them. If you prefer, you can always add the missing pieces to make an equation between numbers that will look like something more familiar. Also, as you will see, the \u201cbra\u201d and \u201cket\u201d notation is a very convenient one. For one thing, we can from now on identify a state by giving its state vector. When we want to refer to a state of definite momentum p we can say: \u201cthe state |p\u27e9 .\u201d Or we may speak of some arbitrary state |\u03c8\u27e9 . For consistency we will always use the ket, writing |\u03c8\u27e9 , to identify a state. (It is, of course an arbitrary choice; we could equally well have chosen to use the bra, \u27e8\u03c8| .) We have discovered that any state in the world can be represented as a superposition\u2014a linear combination with suitable coefficients\u2014of base states. You may ask, first of all, what base states? Well, there are many different possibilities. You can, for instance, project a spin in the z -direction or in some other direction. There are many, many different representations, which are the analogs of the different coordinate systems one can use to represent ordinary vectors. Next, what coefficients? Well, that depends on the physical circumstances. Different sets of coefficients correspond to different physical conditions. The important thing to know about is the \u201cspace\u201d in which you are working\u2014in other words, what the base states mean physically. So the first thing you have to know about, in general, is what the base states are like. Then you can understand how to describe a situation in terms of these base states. We would like to look ahead a little and speak a bit about what the general quantum mechanical description of nature is going to be\u2014in terms of the now current ideas of physics, anyway. First, one decides on a particular representation for the base states\u2014different representations are always possible. For example, for a spin one-half particle we can use the plus and minus states with respect to the z -axis. But there\u2019s nothing special about the z -axis\u2014you can take any other axis you like. For consistency we\u2019ll always pick the z -axis, however. Suppose we begin with a situation with one electron. In addition to the two possibilities for the spin (\u201cup\u201d and \u201cdown\u201d along the z -direction), there is also the momentum of the electron. We pick a set of base states, each corresponding to one value of the momentum. What if the electron doesn\u2019t have a definite momentum? That\u2019s all right; we\u2019re just saying what the base states are. If the electron hasn\u2019t got a definite momentum, it has some amplitude to have one momentum and another amplitude to have another momentum, and so on. And if it is not necessarily spinning up, it has some amplitude to be spinning up going at this momentum, and some amplitude to be spinning down going at that momentum, and so on. The complete description of an electron, so far as we know, requires only that the base states be described by the momentum and the spin. So one acceptable set of base states |i\u27e9 for a single electron refer to different values of the momentum and whether the spin is up or down. Different mixtures of amplitudes\u2014that is, different combinations of the C \u2019s describe different circumstances. What any particular electron is doing is described by telling with what amplitude it has an up-spin or a down-spin and one momentum or another\u2014for all possible momenta. So you can see what is involved in a complete quantum mechanical description of a single electron. What about systems with more than one electron? Then the base states get more complicated. Let\u2019s suppose that we have two electrons. We have, first of all, four possible states with respect to spin: both electrons spinning up, the first one down and the second one up, the first one up and the second one down, or both down. Also we have to specify that the first electron has the momentum p 1 , and the second electron, the momentum p 2 . The base states for two electrons require the specification of two momenta and two spin characters. With seven electrons, we have to specify seven of each. If we have a proton and an electron, we have to specify the spin direction of the proton and its momentum, and the spin direction of the electron and its momentum. At least that\u2019s approximately true. We do not really know what the correct representation is for the world. It is all very well to start out by supposing that if you specify the spin in the electron and its momentum, and likewise for a proton, you will have the base states; but what about the \u201cguts\u201d of the proton? Let\u2019s look at it this way. In a hydrogen atom which has one proton and one electron, we have many different base states to describe\u2014up and down spins of the proton and electron and the various possible momenta of the proton and electron. Then there are different combinations of amplitudes C i which together describe the character of the hydrogen atom in different states. But suppose we look at the whole hydrogen atom as a \u201cparticle.\u201d If we didn\u2019t know that the hydrogen atom was made out of a proton and an electron, we might have started out and said: \u201cOh, I know what the base states are\u2014they correspond to a particular momentum of the hydrogen atom.\u201d No, because the hydrogen atom has internal parts. It may, therefore, have various states of different internal energy, and describing the real nature requires more detail. The question is: Does a proton have internal parts? Do we have to describe a proton by giving all possible states of protons, and mesons, and strange particles? We don\u2019t know. And even though we suppose that the electron is simple, so that all we have to tell about it is its momentum and its spin, maybe tomorrow we will discover that the electron also has inner gears and wheels. It would mean that our representation is incomplete, or wrong, or approximate\u2014in the same way that a representation of the hydrogen atom which describes only its momentum would be incomplete, because it disregarded the fact that the hydrogen atom could have become excited inside. If an electron could become excited inside and turn into something else like, for instance, a muon, then it would be described not just by giving the states of the new particle, but presumably in terms of some more complicated internal wheels. The main problem in the study of the fundamental particles today is to discover what are the correct representations for the description of nature. At the present time, we guess that for the electron it is enough to specify its momentum and spin. We also guess that there is an idealized proton which has its \u03c0 -mesons, and K-mesons, and so on, that all have to be specified. Several dozen particles\u2014that\u2019s crazy! The question of what is a fundamental particle and what is not a fundamental particle\u2014a subject you hear so much about these days\u2014is the question of what is the final representation going to look like in the ultimate quantum mechanical description of the world. Will the electron\u2019s momentum still be the right thing with which to describe nature? Or even, should the whole question be put this way at all! This question must always come up in any scientific investigation. At any rate, we see a problem\u2014how to find a representation. We don\u2019t know the answer. We don\u2019t even know whether we have the \u201cright\u201d problem, but if we do, we must first attempt to find out whether any particular particle is \u201cfundamental\u201d or not. In the nonrelativistic quantum mechanics\u2014if the energies are not too high, so that you don\u2019t disturb the inner workings of the strange particles and so forth\u2014you can do a pretty good job without worrying about these details. You can just decide to specify the momenta and spins of the electrons and of the nuclei; then everything will be all right. In most chemical reactions and other low-energy happenings, nothing goes on in the nuclei; they don\u2019t get excited. Furthermore, if a hydrogen atom is moving slowly and bumping quietly against other hydrogen atoms\u2014never getting excited inside, or radiating, or anything complicated like that, but staying always in the ground state of energy for internal motion\u2014you can use an approximation in which you talk about the hydrogen atom as one object, or particle, and not worry about the fact that it can do something inside. This will be a good approximation as long as the kinetic energy in any collision is well below 10 electron volts\u2014the energy required to excite the hydrogen atom to a different internal state. We will often be making an approximation in which we do not include the possibility of inner motion, thereby decreasing the number of details that we have to put into our base states. Of course, we then omit some phenomena which would appear (usually) at some higher energy, but by making such approximations we can simplify very much the analysis of physical problems. For example, we can discuss the collision of two hydrogen atoms at low energy\u2014or any chemical process\u2014without worrying about the fact that the atomic nuclei could be excited. To summarize, then, when we can neglect the effects of any internal excited states of a particle we can choose a base set which are the states of definite momentum and z -component of angular momentum. One problem then in describing nature is to find a suitable representation for the base states. But that\u2019s only the beginning. We still want to be able to say what \u201chappens.\u201d If we know the \u201ccondition\u201d of the world at one moment, we would like to know the condition at a later moment. So we also have to find the laws that determine how things change with time. We now address ourselves to this second part of the framework of quantum mechanics\u2014how states change with time. We have already talked about how we can represent a situation in which we put something through an apparatus. Now one convenient, delightful \u201capparatus\u201d to consider is merely a wait of a few minutes; that is, you prepare a state \u03d5 , and then before you analyze it, you just let it sit. Perhaps you let it sit in some particular electric or magnetic field\u2014it depends on the physical circumstances in the world. At any rate, whatever the conditions are, you let the object sit from time t 1 to time t 2 . Suppose that it is let out of your first apparatus in the condition \u03d5 at t 1 . And then it goes through an \u201capparatus,\u201d but the \u201capparatus\u201d consists of just delay until t 2 . During the delay, various things could be going on\u2014external forces applied or other shenanigans\u2014so that something is happening. At the end of the delay, the amplitude to find the thing in some state \u03c7 is no longer exactly the same as it would have been without the delay. Since \u201cwaiting\u201d is just a special case of an \u201capparatus,\u201d we can describe what happens by giving an amplitude with the same form as Eq. (8.17). Because the operation of \u201cwaiting\u201d is especially important, we\u2019ll call it U instead of A , and to specify the starting and finishing times t 1 and t 2 , we\u2019ll write U( t 2 , t 1 ) . The amplitude we want is \u27e8\u03c7|U( t 2 , t 1 )|\u03d5\u27e9. (8.27) Like any other such amplitude, it can be represented in some base system or other by writing it \u2211 ij \u27e8\u03c7|i\u27e9\u27e8i|U( t 2 , t 1 )|j\u27e9\u27e8j|\u03d5\u27e9. (8.28) Then U is completely described by giving the whole set of amplitudes\u2014the matrix \u27e8i|U( t 2 , t 1 )|j\u27e9. (8.29) We can point out, incidentally, that the matrix \u27e8i|U( t 2 , t 1 )|j\u27e9 gives much more detail than may be needed. The high-class theoretical physicist working in high-energy physics considers problems of the following general nature (because it\u2019s the way experiments are usually done). He starts with a couple of particles, like a proton and a proton, coming together from infinity. (In the lab, usually one particle is standing still, and the other comes from an accelerator that is practically at infinity on atomic level.) The things go crash and out come, say, two K-mesons, six \u03c0 -mesons, and two neutrons in certain directions with certain momenta. What\u2019s the amplitude for this to happen? The mathematics looks like this: The \u03d5 -state specifies the spins and momenta of the incoming particles. The \u03c7 would be the question about what comes out. For instance, with what amplitude do you get the six mesons going in such-and-such directions, and the two neutrons going off in these directions, with their spins so-and-so. In other words, \u03c7 would be specified by giving all the momenta, and spins, and so on of the final products. Then the job of the theorist is to calculate the amplitude (8.27). However, he is really only interested in the special case that t 1 is \u2212\u221e and t 2 is +\u221e . (There is no experimental evidence on the details of the process, only on what comes in and what goes out.) The limiting case of U( t 2 , t 1 ) as t 1 \u2192\u2212\u221e and t 2 \u2192+\u221e is called S , and what he wants is \u27e8\u03c7|S|\u03d5\u27e9. \u27e8 | | \u03d5 \u27e9 Or, using the form (8.28), he would calculate the matrix \u27e8i|S|j\u27e9, \u27e8 | | \u27e9 which is called the S -matrix. So if you see a theoretical physicist pacing the floor and saying, \u201cAll I have to do is calculate the S -matrix,\u201d you will know what he is worried about. How to analyze\u2014how to specify the laws for\u2014the S -matrix is an interesting question. In relativistic quantum mechanics for high energies, it is done one way, but in nonrelativistic quantum mechanics it can be done another way, which is very convenient. (This other way can also be done in the relativistic case, but then it is not so convenient.) It is to work out the U -matrix for a small interval of time\u2014in other words for t 2 and t 1 close together. If we can find a sequence of such U \u2019s for successive intervals of time we can watch how things go as a function of time. You can appreciate immediately that this way is not so good for relativity, because you don\u2019t want to have to specify how everything looks \u201csimultaneously\u201d everywhere. But we won\u2019t worry about that\u2014we\u2019re just going to worry about nonrelativistic mechanics. Suppose we think of the matrix U for a delay from t 1 until t 3 which is greater than t 2 . In other words, let\u2019s take three successive times: t 1 less than t 2 less than t 3 . Then we claim that the matrix that goes between t 1 and t 3 is the product in succession of what happens when you delay from t 1 until t 2 and then from t 2 until t 3 . It\u2019s just like the situation when we had two apparatuses B and A in series. We can then write, following the notation of Section 5\u20136, U( t 3 , t 1 )=U( t 3 , t 2 )\u22c5U( t 2 , t 1 ). (8.30) In other words, we can analyze any time interval if we can analyze a sequence of short time intervals in between. We just multiply together all the pieces; that\u2019s the way that quantum mechanics is analyzed nonrelativistically. Our problem, then, is to understand the matrix U( t 2 , t 1 ) for an infinitesimal time interval\u2014for t 2 = t 1 +\u0394t . We ask ourselves this: If we have a state \u03d5 now, what does the state look like an infinitesimal time \u0394t later? Let\u2019s see how we write that out. Call the state at the time t , |\u03c8(t)\u27e9 (we show the time dependence of \u03c8 to be perfectly clear that we mean the condition at the time t ). Now we ask the question: What is the condition after the small interval of time \u0394t later? The answer is |\u03c8(t+\u0394t)\u27e9=U(t+\u0394t,t)|\u03c8(t)\u27e9. (8.31) This means the same as we meant by (8.25), namely, that the amplitude to find \u03c7 at the time t+\u0394t , is \u27e8\u03c7|\u03c8(t+\u0394t)\u27e9=\u27e8\u03c7|U(t+\u0394t,t)|\u03c8(t)\u27e9. (8.32) Since we\u2019re not yet too good at these abstract things, let\u2019s project our amplitudes into a definite representation. If we multiply both sides of Eq. (8.31) by \u27e8i| , we get \u27e8i|\u03c8(t+\u0394t)\u27e9=\u27e8i|U(t+\u0394t,t)|\u03c8(t)\u27e9. (8.33) We can also resolve the |\u03c8(t)\u27e9 into base states and write \u27e8i|\u03c8(t+\u0394t)\u27e9= \u2211 j \u27e8i|U(t+\u0394t,t)|j\u27e9\u27e8j|\u03c8(t)\u27e9. (8.34) We can understand Eq. (8.34) in the following way. If we let C i (t)=\u27e8i|\u03c8(t)\u27e9 stand for the amplitude to be in the base state i at the time t , then we can think of this amplitude (just a number, remember!) varying with time. Each C i becomes a function of t . And we also have some information on how the amplitudes C i vary with time. Each amplitude at (t+\u0394t) is proportional to all of the other amplitudes at t multiplied by a set of coefficients. Let\u2019s call the U -matrix U ij , by which we mean U ij =\u27e8i|U|j\u27e9. \u27e8 | | \u27e9 Then we can write Eq. (8.34) as C i (t+\u0394t)= \u2211 j U ij (t+\u0394t,t) C j (t). (8.35) This, then, is how the dynamics of quantum mechanics is going to look. We don\u2019t know much about the U ij yet, except for one thing. We know that if \u0394t goes to zero, nothing can happen\u2014we should get just the original state. So, U ii \u21921 and U ij \u21920 , if i\u2260j . In other words, U ij \u2192 \u03b4 ij for \u0394t\u21920 . Also, we can suppose that for small \u0394t , each of the coefficients U ij should differ from \u03b4 ij by amounts proportional to \u0394t ; so we can write U ij = \u03b4 ij + K ij \u0394t. (8.36) However, it is usual to take the factor (\u2212i/\u210f) 2 out of the coefficients K ij , for historical and other reasons; we prefer to write U ij (t+\u0394t,t)= \u03b4 ij \u2212 i \u210f H ij (t)\u0394t. (8.37) It is, of course, the same as Eq. (8.36) and, if you wish, just defines the coefficients H ij (t) . The terms H ij are just the derivatives with respect to t 2 of the coefficients U ij ( t 2 , t 1 ) , evaluated at t 2 = t 1 =t . Using this form for U in Eq. (8.35), we have C i (t+\u0394t)= \u2211 j [ \u03b4 ij \u2212 i \u210f H ij (t)\u0394t] C j (t). (8.38) Taking the sum over the \u03b4 ij term, we get just C i (t) , which we can put on the other side of the equation. Then dividing by \u0394t , we have what we recognize as a derivative C i (t+\u0394t)\u2212 C i (t) \u0394t =\u2212 i \u210f \u2211 j H ij (t) C j (t) ( ) ( ) or i\u210f d C i (t) dt = \u2211 j H ij (t) C j (t). (8.39) You remember that C i (t) is the amplitude \u27e8i|\u03c8\u27e9 to find the state \u03c8 in one of the base states i (at the time t ). So Eq. (8.39) tells us how each of the coefficients \u27e8i|\u03c8\u27e9 varies with time. But that is the same as saying that Eq. (8.39) tells us how the state \u03c8 varies with time, since we are describing \u03c8 in terms of the amplitudes \u27e8i|\u03c8\u27e9 . The variation of \u03c8 in time is described in terms of the matrix H ij , which has to include, of course, the things we are doing to the system to cause it to change. If we know the H ij \u2014which contains the physics of the situation and can, in general, depend on the time\u2014we have a complete description of the behavior in time of the system. Equation (8.39) is then the quantum mechanical law for the dynamics of the world. (We should say that we will always take a set of base states which are fixed and do not vary with time. There are people who use base states that also vary. However, that\u2019s like using a rotating coordinate system in mechanics, and we don\u2019t want to get involved in such complications.) The idea, then, is that to describe the quantum mechanical world we need to pick a set of base states i and to write the physical laws by giving the matrix of coefficients H ij . Then we have everything\u2014we can answer any question about what will happen. So we have to learn what the rules are for finding the H \u2019s to go with any physical situation\u2014what corresponds to a magnetic field, or an electric field, and so on. And that\u2019s the hardest part. For instance, for the new strange particles, we have no idea what H ij \u2019s to use. In other words, no one knows the complete H ij for the whole world. (Part of the difficulty is that one can hardly hope to discover the H ij when no one even knows what the base states are!) We do have excellent approximations for nonrelativistic phenomena and for some other special cases. In particular, we have the forms that are needed for the motions of electrons in atoms\u2014to describe chemistry. But we don\u2019t know the full true H for the whole universe. The coefficients H ij are called the Hamiltonian matrix or, for short, just the Hamiltonian. (How Hamilton, who worked in the 1830s, got his name on a quantum mechanical matrix is a tale of history.) It would be much better called the energy matrix, for reasons that will become apparent as we work with it. So the problem is: Know your Hamiltonian! The Hamiltonian has one property that can be deduced right away, namely, that H \u2217 ij = H ji . (8.40) This follows from the condition that the total probability that the system is in some state does not change. If you start with a particle\u2014an object or the world\u2014then you\u2019ve still got it as time goes on. The total probability of finding it somewhere is \u2211 i | C i (t) | 2 , \u2211 2 which must not vary with time. If this is to be true for any starting condition \u03d5 , then Eq. (8.40) must also be true. As our first example, we take a situation in which the physical circumstances are not changing with time; we mean the external physical conditions, so that H is independent of time. Nobody is turning magnets on and off. We also pick a system for which only one base state is required for the description; it is an approximation we could make for a hydrogen atom at rest, or something similar. Equation (8.39) then says i\u210f d C 1 dt = H 11 C 1 . (8.41) Only one equation\u2014that\u2019s all! And if H 11 is constant, this differential equation is easily solved to give C 1 =(const) e \u2212(i/\u210f) H 11 t . (8.42) This is the time dependence of a state with a definite energy E= H 11 . You see why H ij ought to be called the energy matrix. It is the generalization of the energy for more complex situations. Next, to understand a little more about what the equations mean, we look at a system which has two base states. Then Eq. (8.39) reads i\u210f d C 1 dt i\u210f d C 2 dt = H 11 C 1 + H 12 C 2 , = H 21 C 1 + H 22 C 2 . (8.43) If the H \u2019s are again independent of time, you can easily solve these equations. We leave you to try for fun, and we\u2019ll come back and do them later. Yes, you can solve the quantum mechanics without knowing the H \u2019s, so long as they are independent of time. We want now to show you how the dynamical equation of quantum mechanics can be used to describe a particular physical circumstance. We have picked an interesting but simple example in which, by making some reasonable guesses about the Hamiltonian, we can work out some important\u2014and even practical\u2014results. We are going to take a situation describable by two states: the ammonia molecule. The ammonia molecule has one nitrogen atom and three hydrogen atoms located in a plane below the nitrogen so that the molecule has the form of a pyramid, as drawn in Fig. 8\u20131(a). Now this molecule, like any other, has an infinite number of states. It can spin around any possible axis; it can be moving in any direction; it can be vibrating inside, and so on, and so on. It is, therefore, not a two-state system at all. But we want to make an approximation that all other states remain fixed, because they don\u2019t enter into what we are concerned with at the moment. We will consider only that the molecule is spinning around its axis of symmetry (as shown in the figure), that it has zero translational momentum, and that it is vibrating as little as possible. That specifies all conditions except one: there are still the two possible positions for the nitrogen atom\u2014the nitrogen may be on one side of the plane of hydrogen atoms or on the other, as shown in Fig. 8\u20131(a) and (b). So we will discuss the molecule as though it were a two-state system. We mean that there are only two states we are going to really worry about, all other things being assumed to stay put. You see, even if we know that it is spinning with a certain angular momentum around the axis and that it is moving with a certain momentum and vibrating in a definite way, there are still two possible states. We will say that the molecule is in the state |1\u27e9 when the nitrogen is \u201cup,\u201d as in Fig. 8\u20131(a), and is in the state |2\u27e9 when the nitrogen is \u201cdown,\u201d as in (b). The states |1\u27e9 and |2\u27e9 will be taken as the set of base states for our analysis of the behavior of the ammonia molecule. At any moment, the actual state |\u03c8\u27e9 of the molecule can be represented by giving C 1 =\u27e81|\u03c8\u27e9 , the amplitude to be in state |1\u27e9 , and C 2 =\u27e82|\u03c8\u27e9 , the amplitude to be in state |2\u27e9 . Then, using Eq. (8.8) we can write the state vector |\u03c8\u27e9 as |\u03c8\u27e9=|1\u27e9\u27e81|\u03c8\u27e9+|2\u27e9\u27e82|\u03c8\u27e9 | \u03c8 \u27e9 | \u27e9 \u27e8 | \u03c8 \u27e9 | \u27e9 \u27e8 | \u03c8 \u27e9 or |\u03c8\u27e9=|1\u27e9 C 1 +|2\u27e9 C 2 . (8.44) Now the interesting thing is that if the molecule is known to be in some state at some instant, it will not be in the same state a little while later. The two C -coefficients will be changing with time according to the equations (8.43)\u2014which hold for any two-state system. Suppose, for example, that you had made some observation\u2014or had made some selection of the molecules\u2014so that you know that the molecule is initially in the state |1\u27e9 . At some later time, there is some chance that it will be found in state |2\u27e9 . To find out what this chance is, we have to solve the differential equation which tells us how the amplitudes change with time. The only trouble is that we don\u2019t know what to use for the coefficients H ij in Eq. (8.43). There are some things we can say, however. Suppose that once the molecule was in the state |1\u27e9 there was no chance that it could ever get into |2\u27e9 , and vice versa. Then H 12 and H 21 would both be zero, and Eq. (8.43) would read i\u210f d C 1 dt = H 11 C 1 ,i\u210f d C 2 dt = H 22 C 2 . d C d C We can easily solve these two equations; we get C 1 =(const) e \u2212(i/\u210f) H 11 t , C 2 =(const) e \u2212(i/\u210f) H 22 t . (8.45) These are just the amplitudes for stationary states with the energies E 1 = H 11 and E 2 = H 22 . We note, however, that for the ammonia molecule the two states |1\u27e9 and |2\u27e9 have a definite symmetry. If nature is at all reasonable, the matrix elements H 11 and H 22 must be equal. We\u2019ll call them both E 0 , because they correspond to the energy the states would have if H 12 and H 21 were zero. But Eqs. (8.45) do not tell us what ammonia really does. It turns out that it is possible for the nitrogen to push its way through the three hydrogens and flip to the other side. It is quite difficult; to get half-way through requires a lot of energy. How can it get through if it hasn\u2019t got enough energy? There is some amplitude that it will penetrate the energy barrier. It is possible in quantum mechanics to sneak quickly across a region which is illegal energetically. There is, therefore, some small amplitude that a molecule which starts in |1\u27e9 will get to the state |2\u27e9 . The coefficients H 12 and H 21 are not really zero. Again, by symmetry, they should both be the same\u2014at least in magnitude. In fact, we already know that, in general, H ij must be equal to the complex conjugate of H ji , so they can differ only by a phase. It turns out, as you will see, that there is no loss of generality if we take them equal to each other. For later convenience we set them equal to a negative number; we take H 12 = H 21 =\u2212A . We then have the following pair of equations: i\u210f d C 1 dt i\u210f d C 2 dt = E 0 C 1 \u2212A C 2 , = E 0 C 2 \u2212A C 1 . (8.46) (8.47) These equations are simple enough and can be solved in any number of ways. One convenient way is the following. Taking the sum of the two, we get i\u210f d dt ( C 1 + C 2 )=( E 0 \u2212A)( C 1 + C 2 ), d whose solution is C 1 + C 2 =a e \u2212(i/\u210f)( E 0 \u2212A)t . (8.48) Then, taking the difference of (8.46) and (8.47), we find that i\u210f d dt ( C 1 \u2212 C 2 )=( E 0 +A)( C 1 \u2212 C 2 ), d which gives C 1 \u2212 C 2 =b e \u2212(i/\u210f)( E 0 +A)t . (8.49) We have called the two integration constants a and b ; they are, of course, to be chosen to give the appropriate starting condition for any particular physical problem. Now, by adding and subtracting (8.48) and (8.49), we get C 1 and C 2 : C 1 (t) C 2 (t) = a 2 e \u2212(i/\u210f)( E 0 \u2212A)t + b 2 e \u2212(i/\u210f)( E 0 +A)t , = a 2 e \u2212(i/\u210f)( E 0 \u2212A)t \u2212 b 2 e \u2212(i/\u210f)( E 0 +A)t . (8.50) (8.51) They are the same except for the sign of the second term. We have the solutions; now what do they mean? (The trouble with quantum mechanics is not only in solving the equations but in understanding what the solutions mean!) First, notice that if b=0 , both terms have the same frequency \u03c9=( E 0 \u2212A)/\u210f . If everything changes at one frequency, it means that the system is in a state of definite energy\u2014here, the energy ( E 0 \u2212A) . So there is a stationary state of this energy in which the two amplitudes C 1 and C 2 are equal. We get the result that the ammonia molecule has a definite energy ( E 0 \u2212A) if there are equal amplitudes for the nitrogen atom to be \u201cup\u201d and to be \u201cdown.\u201d There is another stationary state possible if a=0 ; both amplitudes then have the frequency ( E 0 +A)/\u210f . So there is another state with the definite energy ( E 0 +A) if the two amplitudes are equal but with the opposite sign; C 2 =\u2212 C 1 . These are the only two states of definite energy. We will discuss the states of the ammonia molecule in more detail in the next chapter; we will mention here only a couple of things. We conclude that because there is some chance that the nitrogen atom can flip from one position to the other, the energy of the molecule is not just E 0 , as we would have expected, but that there are two energy levels ( E 0 +A) and ( E 0 \u2212A) . Every one of the possible states of the molecule, whatever energy it has, is \u201csplit\u201d into two levels. We say every one of the states because, you remember, we picked out one particular state of rotation, and internal energy, and so on. For each possible condition of that kind there is a doublet of energy levels because of the flip-flop of the molecule. Let\u2019s now ask the following question about an ammonia molecule. Suppose that at t=0 , we know that a molecule is in the state |1\u27e9 or, in other words, that C 1 (0)=1 and C 2 (0)=0 . What is the probability that the molecule will be found in the state |2\u27e9 at the time t , or will still be found in state |1\u27e9 at the time t ? Our starting condition tells us what a and b are in Eqs. (8.50) and (8.51). Letting t=0 , we have that C 1 (0)= a+b 2 =1, C 2 (0)= a\u2212b 2 =0. b b Clearly, a=b=1 . Putting these values into the formulas for C 1 (t) and C 2 (t) and rearranging some terms, we have C 1 (t) C 2 (t) = e \u2212(i/\u210f) E 0 t ( e (i/\u210f)At + e \u2212(i/\u210f)At 2 ), = e \u2212(i/\u210f) E 0 t ( e (i/\u210f)At \u2212 e \u2212(i/\u210f)At 2 ). We can rewrite these as C 1 (t) C 2 (t) = e \u2212(i/\u210f) E 0 t cos At \u210f , =i e \u2212(i/\u210f) E 0 t sin At \u210f . (8.52) (8.53) The two amplitudes have a magnitude that varies harmonically with time. The probability that the molecule is found in state |2\u27e9 at the time t is the absolute square of C 2 (t) : | C 2 (t) | 2 = sin 2 At \u210f . (8.54) The probability starts at zero (as it should), rises to one, and then oscillates back and forth between zero and one, as shown in the curve marked P 2 of Fig. 8\u20132. The probability of being in the |1\u27e9 state does not, of course, stay at one. It \u201cdumps\u201d into the second state until the probability of finding the molecule in the first state is zero, as shown by the curve P 1 of Fig. 8\u20132. The probability sloshes back and forth between the two. A long time ago we saw what happens when we have two equal pendulums with a slight coupling. (See Chapter 49, Vol. I.) When we lift one back and let go, it swings, but then gradually the other one starts to swing. Pretty soon the second pendulum has picked up all the energy. Then, the process reverses, and pendulum number one picks up the energy. It is exactly the same kind of a thing. The speed at which the energy is swapped back and forth depends on the coupling between the two pendulums\u2014the rate at which the \u201coscillation\u201d is able to leak across. Also, you remember, with the two pendulums there are two special motions\u2014each with a definite frequency\u2014which we call the fundamental modes. If we pull both pendulums out together, they swing together at one frequency. On the other hand, if we pull one out one way and the other out the other way, there is another stationary mode also at a definite frequency. Well, here we have a similar situation\u2014the ammonia molecule is mathematically like the pair of pendulums. These are the two frequencies\u2014 ( E 0 \u2212A)/\u210f and ( E 0 +A)/\u210f \u2014for when they are oscillating together, or oscillating opposite. The pendulum analogy is not much deeper than the principle that the same equations have the same solutions. The linear equations for the amplitudes (8.39) are very much like the linear equations of harmonic oscillators. (In fact, this is the reason behind the success of our classical theory of the index of refraction, in which we replaced the quantum mechanical atom by a harmonic oscillator, even though, classically, this is not a reasonable view of electrons circulating about a nucleus.) If you pull the nitrogen to one side, then you get a superposition of these two frequencies, and you get a kind of beat note, because the system is not in one or the other states of definite frequency. The splitting of the energy levels of the ammonia molecule is, however, strictly a quantum mechanical effect. The splitting of the energy levels of the ammonia molecule has important practical applications which we will describe in the next chapter. At long last we have an example of a practical physical problem that you can understand with the quantum mechanics!"
    },
    {
        "input": "Curved Space",
        "output": "According to Newton everything attracts everything else with a force inversely proportional to the square of the distance from it, and objects respond to forces with accelerations proportional to the forces. They are Newton\u2019s laws of universal gravitation and of motion. As you know, they account for the motions of balls, planets, satellites, galaxies, and so forth. Einstein had a different interpretation of the law of gravitation. According to him, space and time\u2014which must be put together as space-time\u2014are curved near heavy masses. And it is the attempt of things to go along \u201cstraight lines\u201d in this curved space-time which makes them move the way they do. Now that is a complex idea\u2014very complex. It is the idea we want to explain in this chapter. Our subject has three parts. One involves the effects of gravitation. Another involves the ideas of space-time which we already studied. The third involves the idea of curved space-time. We will simplify our subject in the beginning by not worrying about gravity and by leaving out the time\u2014discussing just curved space. We will talk later about the other parts, but we will concentrate now on the idea of curved space\u2014what is meant by curved space, and, more specifically, what is meant by curved space in this application of Einstein. Now even that much turns out to be somewhat difficult in three dimensions. So we will first reduce the problem still further and talk about what is meant by the words \u201ccurved space\u201d in two dimensions. In order to understand this idea of curved space in two dimensions you really have to appreciate the limited point of view of the character who lives in such a space. Suppose we imagine a bug with no eyes who lives on a plane, as shown in Fig. 42\u20131. He can move only on the plane, and he has no way of knowing that there is anyway to discover any \u201coutside world.\u201d (He hasn\u2019t got your imagination.) We are, of course, going to argue by analogy. We live in a three-dimensional world, and we don\u2019t have any imagination about going off our three-dimensional world in a new direction; so we have to think the thing out by analogy. It is as though we were bugs living on a plane, and there was a space in another direction. That\u2019s why we will first work with the bug, remembering that he must live on his surface and can\u2019t get out. As another example of a bug living in two dimensions, let\u2019s imagine one who lives on a sphere. We imagine that he can walk around on the surface of the sphere, as in Fig. 42\u20132 but that he can\u2019t look \u201cup,\u201d or \u201cdown,\u201d or \u201cout.\u201d Now we want to consider still a third kind of creature. He is also a bug like the others, and also lives on a plane, as our first bug did, but this time the plane is peculiar. The temperature is different at different places. Also, the bug and any rulers he uses are all made of the same material which expands when it is heated. Whenever he puts a ruler somewhere to measure something the ruler expands immediately to the proper length for the temperature at that place. Wherever he puts any object\u2014himself, a ruler, a triangle, or anything\u2014the thing stretches itself because of the thermal expansion. Everything is longer in the hot places than it is in the cold places, and everything has the same coefficient of expansion. We will call the home of our third bug a \u201chot plate,\u201d although we will particularly want to think of a special kind of hot plate that is cold in the center and gets hotter as we go out toward the edges (Fig. 42\u20133). Now we are going to imagine that our bugs begin to study geometry. Although we imagine that they are blind so that they can\u2019t see any \u201coutside\u201d world, they can do a lot with their legs and feelers. They can draw lines, and they can make rulers, and measure off lengths. First, let\u2019s suppose that they start with the simplest idea in geometry. They learn how to make a straight line\u2014defined as the shortest line between two points. Our first bug\u2014see Fig. 42\u20134\u2014learns to make very good lines. But what happens to the bug on the sphere? He draws his straight line as the shortest distance\u2014for him\u2014between two points, as in Fig. 42\u20135. It may look like a curve to us, but he has no way of getting off the sphere and finding out that there is \u201creally\u201d a shorter line. He just knows that if he tries any other path in his world it is always longer than his straight line. So we will let him have his straight line as the shortest arc between two points. (It is, of course an arc of a great circle.) Finally, our third bug\u2014the one in Fig. 42\u20133\u2014will also draw \u201cstraight lines\u201d that look like curves to us. For instance, the shortest distance between A and B in Fig. 42\u20136 would be on a curve like the one shown. Why? Because when his line curves out toward the warmer parts of his hot plate, the rulers get longer (from our omniscient point of view) and it takes fewer \u201cyardsticks\u201d laid end-to-end to get from A to B. So for him the line is straight\u2014he has no way of knowing that there could be someone out in a strange three-dimensional world who would call a different line \u201cstraight.\u201d We think you get the idea now that all the rest of the analysis will always be from the point of view of the creatures on the particular surfaces and not from our point of view. With that in mind let\u2019s see what the rest of their geometries looks like. Let\u2019s assume that the bugs have all learned how to make two lines intersect at right angles. (You can figure out how they could do it.) Then our first bug (the one on the normal plane) finds an interesting fact. If he starts at the point A and makes a line 100 inches long, then makes a right angle and marks off another 100 inches, then makes another right angle and goes another 100 inches, then makes a third right angle and a fourth line 100 inches long, he ends up right at the starting point as shown in Fig. 42\u20137(a). It is a property of his world\u2014one of the facts of his \u201cgeometry.\u201d Then he discovers another interesting thing. If he makes a triangle\u2014a figure with three straight lines\u2014the sum of the angles is equal to 180\u2218, that is, to the sum of two right angles. See Fig. 42\u20137(b). Then he invents the circle. What\u2019s a circle? A circle is made this way: You rush off on straight lines in many many directions from a single point, and lay out a lot of dots that are all the same distance from that point. See Fig. 42\u20137(c). (We have to be careful how we define these things because we\u2019ve got to be able to make the analogs for the other fellows.) Of course, its equivalent to the curve you can make by swinging a ruler around a point. Anyway, our bug learns how to make circles. Then one day he thinks of measuring the distance around a circle. He measures several circles and finds a neat relationship: The distance around is always the same number times the radius r (which is, of course, the distance from the center out to the curve). The circumference and the radius always have the same ratio\u2014approximately 6.283\u2014independent of the size of the circle. Now let\u2019s see what our other bugs have been finding out about their geometries. First, what happens to the bug on the sphere when he tries to make a \u201csquare\u201d? If he follows the prescription we gave above, he would probably think that the result was hardly worth the trouble. He gets a figure like the one shown in Fig. 42\u20138. His endpoint B isn\u2019t on top of the starting point A. It doesn\u2019t work out to a closed figure at all. Get a sphere and try it. A similar thing would happen to our friend on the hot plate. If he lays out four straight lines of equal length\u2014as measured with his expanding rulers\u2014joined by right angles he gets a picture like the one in Fig. 42\u20139. Now suppose that our bugs had each had their own Euclid who had told them what geometry \u201cshould\u201d be like, and that they had checked him out roughly by making crude measurements on a small scale. Then as they tried to make accurate squares on a larger scale they would discover that something was wrong. The point is, that just by geometrical measurements they would discover that something was the matter with their space. We define a curved space to be a space in which the geometry is not what we expect for a plane. The geometry of the bugs on the sphere or on the hot plate is the geometry of a curved space. The rules of Euclidean geometry fail. And it isn\u2019t necessary to be able to lift yourself out of the plane in order to find out that the world that you live in is curved. It isn\u2019t necessary to circumnavigate the globe in order to find out that it is a ball. You can find out that you live on a ball by laying out a square. If the square is very small you will need a lot of accuracy, but if the square is large the measurement can be done more crudely. Let\u2019s take the case of a triangle on a plane. The sum of the angles is 180 degrees. Our friend on the sphere can find triangles that are very peculiar. He can, for example, find triangles which have three right angles. Yes indeed! One is shown in Fig. 42\u201310. Suppose our bug starts at the north pole and makes a straight line all the way down to the equator. Then he makes a right angle and another perfect straight line the same length. Then he does it again. For the very special length he has chosen he gets right back to his starting point, and also meets the first line with a right angle. So there is no doubt that for him this triangle has three right angles, or 270 degrees in the sum. It turns out that for him the sum of the angles of the triangle is always greater than 180 degrees. In fact, the excess (for the special case shown, the extra 90 degrees) is proportional to how much area the triangle has. If a triangle on a sphere is very small, its angles add up to very nearly 180 degrees, only a little bit over. As the triangle gets bigger the discrepancy goes up. The bugs on the hot plate would discover similar difficulties with their triangles. Let\u2019s look next at what our other bugs find out about circles. They make circles and measure their circumferences. For example, the bug on the sphere might make a circle like the one shown in Fig. 42\u201311. And he would discover that the circumference is less than 2\u03c0 times the radius. (You can see that because from the wisdom of our three-dimensional view it is obvious that what he calls the \u201cradius\u201d is a curve which is longer than the true radius of the circle.) Suppose that the bug on the sphere had read Euclid, and decided to predict a radius by dividing the circumference C by 2\u03c0 , taking rpred= C 2\u03c0 . Then he would find that the measured radius was larger than the predicted radius. Pursuing the subject, he might define the difference to be the \u201cexcess radius,\u201d and write rmeas\u2212rpred=rexcess, and study how the excess radius effect depended on the size of the circle. Our bug on the hot plate would discover a similar phenomenon. Suppose he was to draw a circle centered at the cold spot on the plate as in Fig. 42\u201312. If we were to watch him as he makes the circle we would notice that his rulers are short near the center and get longer as they are moved outward\u2014although the bug doesn\u2019t know it, of course. When he measures the circumference the ruler is long all the time, so he, too, finds out that the measured radius is longer than the predicted radius, C/2\u03c0 . The hot-plate bug also finds an \u201cexcess radius effect.\u201d And again the size of the effect depends on the radius of the circle. We will define a \u201ccurved space\u201d as one in which these types of geometrical errors occur: The sum of the angles of a triangle is different from 180 degrees; the circumference of a circle divided by 2\u03c0 is not equal to the radius; the rule for making a square doesn\u2019t give a closed figure. You can think of others. We have given two different examples of curved space: the sphere and the hot plate. But it is interesting that if we choose the right temperature variation as a function of distance on the hot plate, the two geometries will be exactly the same. It is rather amusing. We can make the bug on the hot plate get exactly the same answers as the bug on the ball. For those who like geometry and geometrical problems we\u2019ll tell you how it can be done. If you assume that the length of the rulers (as determined by the temperature) goes in proportion to one plus some constant times the square of the distance away from the origin, then you will find that the geometry of that hot plate is exactly the same in all details1 as the geometry of the sphere. There are, of course, other kinds of geometry. We could ask about the geometry of a bug who lived on a pear, namely something which has a sharper curvature in one place and a weaker curvature in the other place, so that the excess in angles in triangles is more severe when he makes little triangles in one part of his world than when he makes them in another part. In other words, the curvature of a space can vary from place to place. That\u2019s just a generalization of the idea. It can also be imitated by a suitable distribution of temperature on a hot plate. We may also point out that the results could come out with the opposite kind of discrepancies. You could find out, for example, that all triangles when they are made too large have the sum of their angles less than 180 degrees. That may sound impossible, but it isn\u2019t at all. First of all, we could have a hot plate with the temperature decreasing with the distance from the center. Then all the effects would be reversed. But we can also do it purely geometrically by looking at the two-dimensional geometry of the surface of a saddle. Imagine a saddle-shaped surface like the one sketched in Fig. 42\u201313. Now draw a \u201ccircle\u201d on the surface, defined as the locus of all points the same distance from a center. This circle is a curve that oscillates up and down with a scallop effect. So its circumference is larger than you would expect from calculating 2\u03c0rmeas . So C/2\u03c0 is now greater than rmeas . The \u201cexcess radius\u201d would be negative. Spheres and pears and such are all surfaces of positive curvatures; and the others are called surfaces of negative curvature. In general, a two-dimensional world will have a curvature which varies from place to place and may be positive in some places and negative in other places. In general, we mean by a curved space simply one in which the rules of Euclidean geometry break down with one sign of discrepancy or the other. The amount of curvature\u2014defined, say, by the excess radius\u2014may vary from place to place. We might point out that, from our definition of curvature, a cylinder is, surprisingly enough, not curved. If a bug lived on a cylinder, as shown in Fig. 42\u201314, he would find out that triangles, squares, and circles would all have the same behavior they have on a plane. This is easy to see, by just thinking about how all the figures will look if the cylinder is unrolled onto a plane. Then all the geometrical figures can be made to correspond exactly to the way they are in a plane. So there is no way for a bug living on a cylinder (assuming that he doesn\u2019t go all the way around, but just makes local measurements) to discover that his space is curved. In our technical sense, then, we consider that his space is not curved. What we want to talk about is more precisely called intrinsic curvature; that is, a curvature which can be found by measurements only in a local region. (A cylinder has no intrinsic curvature.) This was the sense intended by Einstein when he said that our space is curved. But we as yet only have defined a curved space in two dimensions; we must go onward to see what the idea might mean in three dimensions. We live in three-dimensional space and we are going to consider the idea that three-dimensional space is curved. You say, \u201cBut how can you imagine it being bent in any direction?\u201d Well, we can\u2019t imagine space being bent in any direction because our imagination isn\u2019t good enough. (Perhaps it\u2019s just as well that we can\u2019t imagine too much, so that we don\u2019t get too free of the real world.) But we can still define a curvature without getting out of our three-dimensional world. All we have been talking about in two dimensions was simply an exercise to show how we could get a definition of curvature which didn\u2019t require that we be able to \u201clook in\u201d from the outside. We can determine whether our world is curved or not in a way quite analogous to the one used by the gentlemen who live on the sphere and on the hot plate. We may not be able to distinguish between two such cases but we certainly can distinguish those cases from the flat space, the ordinary plane. How? Easy enough: We lay out a triangle and measure the angles. Or we make a great big circle and measure the circumference and the radius. Or we try to lay out some accurate squares, or try to make a cube. In each case we test whether the laws of geometry work. If they don\u2019t work, we say that our space is curved. If we lay out a big triangle and the sum of its angles exceeds 180 degrees, we can say our space is curved. Or if the measured radius of a circle is not equal to its circumference over 2\u03c0 , we can say our space is curved. You will notice that in three dimensions the situation can be much more complicated than in two. At any one place in two dimensions there is a certain amount of curvature. But in three dimensions there can be several components to the curvature. If we lay out a triangle in some plane, we may get a different answer than if we orient the plane of the triangle in a different way. Or take the example of a circle. Suppose we draw a circle and measure the radius and it doesn\u2019t check with C/2\u03c0 so that there is some excess radius. Now we draw another circle at right angles\u2014as in Fig. 42\u201315. There\u2019s no need for the excess to be exactly the same for both circles. In fact, there might be a positive excess for a circle in one plane, and a defect (negative excess) for a circle in the other plane. Perhaps you are thinking of a better idea: Can\u2019t we get around all of these components by using a sphere in three dimensions? We can specify a sphere by taking all the points that are the same distance from a given point in space. Then we can measure the surface area by laying out a fine scale rectangular grid on the surface of the sphere and adding up all the bits of area. According to Euclid the total area A is supposed to be 4\u03c0 times the square of the radius; so we can define a \u201cpredicted radius\u201d as \u221a A/4\u03c0 . But we can also measure the radius directly by digging a hole to the center and measuring the distance. Again, we can take the measured radius minus the predicted radius and call the difference the radius excess, rexcess=rmeas\u2212( measured area 4\u03c0 )1/2, which would be a perfectly satisfactory measure of the curvature. It has the great advantage that it doesn\u2019t depend upon how we orient a triangle or a circle. But the excess radius of a sphere also has a disadvantage; it doesn\u2019t completely characterize the space. It gives what is called the mean curvature of the three-dimensional world, since there is an averaging effect over the various curvatures. Since it is an average, however, it does not solve completely the problem of defining the geometry. If you know only this number you can\u2019t predict all properties of the geometry of the space, because you can\u2019t tell what would happen with circles of different orientation. The complete definition requires the specification of six \u201ccurvature numbers\u201d at each point. Of course the mathematicians know how to write all those numbers. You can read someday in a mathematics book how to write them all in a high-class and elegant form, but it is first a good idea to know in a rough way what it is that you are trying to write about. For most of our purposes the average curvature will be enough.2 Now comes the main question. Is it true? That is, is the actual physical three-dimensional space we live in curved? Once we have enough imagination to realize the possibility that space might be curved, the human mind naturally gets curious about whether the real world is curved or not. People have made direct geometrical measurements to try to find out, and haven\u2019t found any deviations. On the other hand, by arguments about gravitation, Einstein discovered that space is curved, and we\u2019d like to tell you what Einstein\u2019s law is for the amount of curvature, and also tell you a little bit about how he found out about it. Einstein said that space is curved and that matter is the source of the curvature. (Matter is also the source of gravitation, so gravity is related to the curvature\u2014but that will come later in the chapter.) Let us suppose, to make things a little easier, that the matter is distributed continuously with some density, which may vary, however, as much as you want from place to place.3 The rule that Einstein gave for the curvature is the following: If there is a region of space with matter in it and we take a sphere small enough that the density \u03c1 of matter inside it is effectively constant, then the radius excess for the sphere is proportional to the mass inside the sphere. Using the definition of excess radius, we have Radius excess=rmeas\u2212 \u221a A 4\u03c0 = G 3c2 \u22c5M. Here, G is the gravitational constant (of Newton\u2019s theory), c is the velocity of light, and M=4\u03c0\u03c1r3/3 is the mass of the matter inside the sphere. This is Einstein\u2019s law for the mean curvature of space. Suppose we take the earth as an example and forget that the density varies from point to point\u2014so we won\u2019t have to do any integrals. Suppose we were to measure the surface of the earth very carefully, and then dig a hole to the center and measure the radius. From the surface area we could calculate the predicted radius we would get from setting the area equal to 4\u03c0r2 . When we compared the predicted radius with the actual radius, we would find that the actual radius exceeded the predicted radius by the amount given in Eq. (42.3). The constant G/3c2 is about 2.5\u00d710\u221229 cm per gram, so for each gram of material the measured radius is off by 2.5\u00d710\u221229 cm. Putting in the mass of the earth, which is about 6\u00d71027 grams, it turns out that the earth has 1.5 millimeters more radius than it should have for its surface area.4 Doing the same calculation for the sun, you find that the sun\u2019s radius is one-half a kilometer too long. You should note that the law says that the average curvature above the surface area of the earth is zero. But that does not mean that all the components of the curvature are zero. There may still be\u2014and, in fact, there is\u2014some curvature above the earth. For a circle in a plane there will be an excess radius of one sign for some orientations and of the opposite sign for other orientations. It just turns out that the average over a sphere is zero when there is no mass inside it. Incidentally, it turns out that there is a relation between the various components of the curvature and the variation of the average curvature from place to place. So if you know the average curvature everywhere, you can figure out the details of the curvature components at each place. The average curvature inside the earth varies with altitude, and this means that some curvature components are nonzero both inside the earth and outside. It is that curvature that we see as a gravitational force. Suppose we have a bug on a plane, and suppose that the \u201cplane\u201d has little pimples in the surface. Wherever there is a pimple the bug would conclude that his space had little local regions of curvature. We have the same thing in three dimensions. Wherever there is a lump of matter, our three-dimensional space has a local curvature\u2014a kind of three-dimensional pimple. If we make a lot of bumps on a plane there might be an overall curvature besides all the pimples\u2014the surface might become like a ball. It would be interesting to know whether our space has a net average curvature as well as the local pimples due to the lumps of matter like the earth and the sun. The astrophysicists have been trying to answer that question by making measurements of galaxies at very large distances. For example, if the number of galaxies we see in a spherical shell at a large distance is different from what we would expect from our knowledge of the radius of the shell, we would have a measure of the excess radius of a tremendously large sphere. From such measurements it is hoped to find out whether our whole universe is flat on the average, or round\u2014whether it is \u201cclosed,\u201d like a sphere, or \u201copen\u201d like a plane. You may have heard about the debates that are going on about this subject. There are debates because the astronomical measurements are still completely inconclusive; the experimental data are not precise enough to give a definite answer. Unfortunately, we don\u2019t have the slightest idea about the overall curvature of our universe on a large scale. Now we have to talk about time. As you know from the special theory of relativity, measurements of space and measurements of time are interrelated. And it would be kind of crazy to have something happening to the space, without the time being involved in the same thing. You will remember that the measurement of time depends on the speed at which you move. For instance, if we watch a guy going by in a spaceship we see that things happen more slowly for him than for us. Let\u2019s say he takes off on a trip and returns in 100 seconds flat by our watches; his watch might say that he had been gone for only 95 seconds. In comparison with ours, his watch\u2014and all other processes, like his heart beat\u2014have been running slow. Now let\u2019s consider an interesting problem. Suppose you are the one in the spaceship. We ask you to start off at a given signal and return to your starting place just in time to catch a later signal\u2014at, say, exactly 100 seconds later according to our clock. And you are also asked to make the trip in such a way that your watch will show the longest possible elapsed time. How should you move? You should stand still. If you move at all your watch will read less than 100 sec when you get back. Suppose, however, we change the problem a little. Suppose we ask you to start at point A on a given signal and go to point B (both fixed relative to us), and to do it in such a way that you arrive back just at the time of a second signal (say 100 seconds later according to our fixed clock). Again you are asked to make the trip in the way that lets you arrive with the latest possible reading on your watch. How would you do it? For which path and schedule will your watch show the greatest elapsed time when you arrive? The answer is that you will spend the longest time from your point of view if you make the trip by going at a uniform speed along a straight line. Reason: Any extra motions and any extra-high speeds will make your clock go slower. (Since the time deviations depend on the square of the velocity, what you lose by going extra fast at one place you can never make up by going extra slowly in another place.) The point of all this is that we can use the idea to define \u201ca straight line\u201d in space-time. The analog of a straight line in space is for space-time a motion at uniform velocity in a constant direction. The curve of shortest distance in space corresponds in space-time not to the path of shortest time, but to the one of longest time, because of the funny things that happen to signs of the t -terms in relativity. \u201cStraight-line\u201d motion\u2014the analog of \u201cuniform velocity along a straight line\u201d\u2014is then that motion which takes a watch from one place at one time to another place at another time in the way that gives the longest time reading for the watch. This will be our definition for the analog of a straight line in space-time. Now we are ready to discuss the laws of gravitation. Einstein was trying to generate a theory of gravitation that would fit with the relativity theory that he had developed earlier. He was struggling along until he latched onto one important principle which guided him into getting the correct laws. That principle is based on the idea that when a thing is falling freely everything inside it seems weightless. For example, a satellite in orbit is falling freely in the earth\u2019s gravity, and an astronaut in it feels weightless. This idea, when stated with greater precision, is called Einstein\u2019s principle of equivalence. It depends on the fact that all objects fall with exactly the same acceleration no matter what their mass, or what they are made of. If we have a spaceship that is \u201ccoasting\u201d\u2014so it\u2019s in a free fall\u2014and there is a man inside, then the laws governing the fall of the man and the ship are the same. So if he puts himself in the middle of the ship he will stay there. He doesn\u2019t fall with respect to the ship. That\u2019s what we mean when we say he is \u201cweightless.\u201d Now suppose you are in a rocket ship which is accelerating. Accelerating with respect to what? Let\u2019s just say that its engines are on and generating a thrust so that it is not coasting in a free fall. Also imagine that you are way out in empty space so that there are practically no gravitational forces on the ship. If the ship is accelerating with \u201c 1 g\u201d you will be able to stand on the \u201cfloor\u201d and will feel your normal weight. Also if you let go of a ball, it will \u201cfall\u201d toward the floor. Why? Because the ship is accelerating \u201cupward,\u201d but the ball has no forces on it, so it will not accelerate; it will get left behind. Inside the ship the ball will appear to have a downward acceleration of \u201c 1 g.\u201d Now let\u2019s compare that with the situation in a spaceship sitting at rest on the surface of the earth. Everything is the same! You would be pressed toward the floor, a ball would fall with an acceleration of 1 g, and so on. In fact, how could you tell inside a space ship whether you are sitting on the earth or are accelerating in free space? According to Einstein\u2019s equivalence principle there is no way to tell if you only make measurements of what happens to things inside! To be strictly correct, that is true only for one point inside the ship. The gravitational field of the earth is not precisely uniform, so a freely falling ball has a slightly different acceleration at different places\u2014the direction changes and the magnitude changes. But if we imagine a strictly uniform gravitational field, it is completely imitated in every respect by a system with a constant acceleration. That is the basis of the principle of equivalence. Now we want to use the principle of equivalence for figuring out a strange thing that happens in a gravitational field. We\u2019ll show you something that happens in a rocket ship which you probably wouldn\u2019t have expected to happen in a gravitational field. Suppose we put a clock at the \u201chead\u201d of the rocket ship\u2014that is, at the \u201cfront\u201d end\u2014and we put another identical clock at the \u201ctail,\u201d as in Fig. 42\u201316. Let\u2019s call the two clocks A and B . If we compare these two clocks when the ship is accelerating, the clock at the head seems to run fast relative to the one at the tail. To see that, imagine that the front clock emits a flash of light each second, and that you are sitting at the tail comparing the arrival of the light flashes with the ticks of clock B . Let\u2019s say that the rocket is in the position a of Fig. 42\u201317 when clock A emits a flash, and at the position b when the flash arrives at clock B . Later on the ship will be at position c when the clock A emits its next flash, and at position d when you see it arrive at clock B . The first flash travels the distance L 1 and the second flash travels the shorter distance L 2 . It is a shorter distance because the ship is accelerating and has a higher speed at the time of the second flash. You can see, then, that if the two flashes were emitted from clock A one second apart, they would arrive at clock B with a separation somewhat less than one second, since the second flash doesn\u2019t spend as much time on the way. The same thing will also happen for all the later flashes. So if you were sitting in the tail you would conclude that clock A was running faster than clock B . If you were to do the same thing in reverse\u2014letting clock B emit light and observing it at clock A \u2014you would conclude that B was running slower than A . Everything fits together and there is nothing mysterious about it all. But now let\u2019s think of the rocket ship at rest in the earth\u2019s gravity. The same thing happens. If you sit on the floor with one clock and watch another one which is sitting on a high shelf, it will appear to run faster than the one on the floor! You say, \u201cBut that is wrong. The times should be the same. With no acceleration there\u2019s no reason for the clocks to appear to be out of step.\u201d But they must if the principle of equivalence is right. And Einstein insisted that the principle was right, and went courageously and correctly ahead. He proposed that clocks at different places in a gravitational field must appear to run at different speeds. But if one always appears to be running at a different speed with respect to the other, then so far as the first is concerned the other is running at a different rate. But now you see we have the analog for clocks of the hot ruler we were talking about earlier, when we had the bug on a hot plate. We imagined that rulers and bugs and everything changed lengths in the same way at various temperatures so they could never tell that their measuring sticks were changing as they moved around on the hot plate. It\u2019s the same with clocks in a gravitational field. Every clock we put at a higher level is seen to go faster. Heartbeats go faster, all processes run faster. If they didn\u2019t you would be able to tell the difference between a gravitational field and an accelerating reference system. The idea that time can vary from place to place is a difficult one, but it is the idea Einstein used, and it is correct\u2014believe it or not. Using the principle of equivalence we can figure out how much the speed of a clock changes with height in a gravitational field. We just work out the apparent discrepancy between the two clocks in the accelerating rocket ship. The easiest way to do this is to use the result we found in Chapter 34 of Vol. I for the Doppler effect. There, we found\u2014see Eq. (34.14)\u2014that if v is the relative velocity of a source and a receiver, the received frequency \u03c9 is related to the emitted frequency \u03c9 0 by \u03c9= \u03c9 0 1+v/c 1\u2212 v 2 / c 2 \u2212 \u2212 \u2212 \u2212 \u2212 \u2212 \u2212 \u2212 \u221a . (42.4) Now if we think of the accelerating rocket ship in Fig. 42\u201317 the emitter and receiver are moving with equal velocities at any one instant. But in the time that it takes the light signals to go from clock A to clock B the ship has accelerated. It has, in fact, picked up the additional velocity gt , where g is the acceleration and t is time it takes light to travel the distance H from A to B . This time is very nearly H/c . So when the signals arrive at B , the ship has increased its velocity by gH/c . The receiver always has this velocity with respect to the emitter at the instant the signal left it. So this is the velocity we should use in the Doppler shift formula, Eq. (42.4). Assuming that the acceleration and the length of the ship are small enough that this velocity is much smaller than c , we can neglect the term in v 2 / c 2 . We have that \u03c9= \u03c9 0 (1+ gH c 2 ). (42.5) So for the two clocks in the spaceship we have the relation ( Rate at the receiver )=( Rate of emission )(1+ gH c 2 ), (42.6) where H is the height of the emitter above the receiver. From the equivalence principle the same result must hold for two clocks separated by the height H in a gravitational field with the free fall acceleration g . This is such an important idea we would like to demonstrate that it also follows from another law of physics\u2014from the conservation of energy. We know that the gravitational force on an object is proportional to its mass M , which is related to its total internal energy E by M=E/ c 2 . For instance, the masses of nuclei determined from the energies of nuclear reactions which transmute one nucleus into another agree with the masses obtained from atomic weights. Now think of an atom which has a lowest energy state of total energy E 0 and a higher energy state E 1 , and which can go from the state E 1 to the state E 0 by emitting light. The frequency \u03c9 of the light will be given by \u210f\u03c9= E 1 \u2212 E 0 . (42.7) Now suppose we have such an atom in the state E 1 sitting on the floor, and we carry it from the floor to the height H . To do that we must do some work in carrying the mass m 1 = E 1 / c 2 up against the gravitational force. The amount of work done is E 1 c 2 gH. (42.8) Then we let the atom emit a photon and go into the lower energy state E 0 . Afterward we carry the atom back to the floor. On the return trip the mass is E 0 / c 2 ; we get back the energy E 0 c 2 gH, (42.9) so we have done a net amount of work equal to \u0394U= E 1 \u2212 E 0 c 2 gH. (42.10) When the atom emitted the photon it gave up the energy E 1 \u2212 E 0 . Now suppose that the photon happened to go down to the floor and be absorbed. How much energy would it deliver there? You might at first think that it would deliver just the energy E 1 \u2212 E 0 . But that can\u2019t be right if energy is conserved, as you can see from the following argument. We started with the energy E 1 at the floor. When we finish, the energy at the floor level is the energy E 0 of the atom in its lower state plus the energy E ph received from the photon. In the meantime we have had to supply the additional energy \u0394U of Eq. (42.10). If energy is conserved, the energy we end up with at the floor must be greater than we started with by just the work we have done. Namely, we must have that E ph + E 0 = E 1 +\u0394U, E E E \u0394 U or E ph =( E 1 \u2212 E 0 )+\u0394U. (42.11) It must be that the photon does not arrive at the floor with just the energy E 1 \u2212 E 0 it started with, but with a little more energy. Otherwise some energy would have been lost. If we substitute in Eq. (42.11) the \u0394U we got in Eq. (42.10) we get that the photon arrives at the floor with the energy E ph =( E 1 \u2212 E 0 )(1+ gH c 2 ). (42.12) But a photon of energy E ph has the frequency \u03c9= E ph /\u210f . Calling the frequency of the emitted photon \u03c9 0 \u2014which is by Eq. (42.7) equal to ( E 1 \u2212 E 0 )/\u210f \u2014our result in Eq. (42.12) gives again the relation of (42.5) between the frequency of the photon when it is absorbed on the floor and the frequency with which it was emitted. The same result can be obtained in still another way. A photon of frequency \u03c9 0 has the energy E 0 =\u210f \u03c9 0 . Since the energy E 0 has the relativistic mass E 0 / c 2 the photon has a mass (not rest mass) \u210f \u03c9 0 / c 2 , and is \u201cattracted\u201d by the earth. In falling the distance H it will gain an additional energy (\u210f \u03c9 0 / c 2 )gH , so it arrives with the energy E=\u210f \u03c9 0 (1+ gH c 2 ). H But its frequency after the fall is E/\u210f , giving again the result in Eq. (42.5). Our ideas about relativity, quantum physics, and energy conservation all fit together only if Einstein\u2019s predictions about clocks in a gravitational field are right. The frequency changes we are talking about are normally very small. For instance, for an altitude difference of 20 meters at the earth\u2019s surface the frequency difference is only about two parts in 10 15 . However, just such a change has recently been found experimentally using the M\u00f6ssbauer effect.5 Einstein was perfectly correct. Now we want to relate what we have just been talking about to the idea of curved space-time. We have already pointed out that if the time goes at different rates in different places, it is analogous to the curved space of the hot plate. But it is more than an analogy; it means that space-time is curved. Let\u2019s try to do some geometry in space-time. That may at first sound peculiar, but we have often made diagrams of space-time with distance plotted along one axis and time along the other. Suppose we try to make a rectangle in space-time. We begin by plotting a graph of height H versus t as in Fig. 42\u201318(a). To make the base of our rectangle we take an object which is at rest at the height H 1 and follow its world line for 100 seconds. We get the line BD in part (b) of the figure which is parallel to the t -axis. Now let\u2019s take another object which is 100 feet above the first one at t=0 . It starts at the point A in Fig. 42\u201318(c). Now we follow its world line for 100 seconds as measured by a clock at A . The object goes from A to C , as shown in part (d) of the figure. But notice that since time goes at a different rate at the two heights\u2014we are assuming that there is a gravitational field\u2014the two points C and D are not simultaneous. If we try to complete the square by drawing a line to the point C \u2032 which is 100 feet above D at the same time, as in Fig. 42\u201318(e), the pieces don\u2019t fit. And that\u2019s what we mean when we say that space-time is curved. Let\u2019s consider an interesting little puzzle. We have two identical clocks, A and B , sitting together on the surface of the earth. Now we lift clock A to some height H , hold it there awhile, and return it to the ground so that it arrives at just the instant when clock B has advanced by 100 seconds. Then clock A will read something like 107 seconds, because it was running faster when it was up in the air. Now here is the puzzle. How should we move clock A so that it reads the latest possible time\u2014always assuming that it returns when B reads 100 seconds? You say, \u201cThat\u2019s easy. Just take A as high as you can. Then it will run as fast as possible, and be the latest when you return.\u201d Wrong. You forgot something\u2014we\u2019ve only got 100 seconds to go up and back. If we go very high, we have to go very fast to get there and back in 100 seconds. And you mustn\u2019t forget the effect of special relativity which causes moving clocks to slow down by the factor 1\u2212 v 2 / c 2 \u2212 \u2212 \u2212 \u2212 \u2212 \u2212 \u2212 \u2212 \u221a . This relativity effect works in the direction of making clock A read less time than clock B . You see that we have a kind of game. If we stand still with clock A we get 100 seconds. If we go up slowly to a small height and come down slowly we can get a little more than 100 seconds. If we go a little higher, maybe we can gain a little more. But if we go too high we have to move fast to get there, and we may slow down the clock enough that we end up with less than 100 seconds. What program of height versus time\u2014how high to go and with what speed to get there, carefully adjusted to bring us back to clock B when it has increased by 100 seconds\u2014will give us the largest possible time reading on clock A ? Answer: Find out how fast you have to throw a ball up into the air so that it will fall back to earth in exactly 100 seconds. The ball\u2019s motion\u2014rising fast, slowing down, stopping, and coming back down\u2014is exactly the right motion to make the time the maximum on a wrist watch strapped to the ball. Now consider a slightly different game. We have two points A and B both on the earth\u2019s surface at some distance from one another, as in Fig. 42\u201319. We play the same game that we did earlier to find what we call the straight line. We ask how we should go from A to B so that the time on our moving watch will be the longest\u2014assuming we start at A on a given signal and arrive at B on another signal at B which we will say is 100 seconds later by a fixed clock. Now you say, \u201cWell we found out before that the thing to do is to coast along a straight line at a uniform speed chosen so that we arrive at B exactly 100 seconds later. If we don\u2019t go along a straight line it takes more speed, and our watch is slowed down.\u201d But wait! That was before we took gravity into account. Isn\u2019t it better to curve upward a little bit and then come down? Then during part of the time we are higher up and our watch will run a little faster? It is, indeed. If you solve the mathematical problem of adjusting the curve of the motion so that the elapsed time of the moving watch is the most it can possibly be, you will find that the motion is a parabola\u2014the same curve followed by something that moves on a free ballistic path in the gravitational field, as in Fig. 42\u201319. Therefore the law of motion in a gravitational field can also be stated: An object always moves from one place to another so that a clock carried on it gives a longer time than it would on any other possible trajectory\u2014with, of course, the same starting and finishing conditions. The time measured by a moving clock is often called its \u201cproper time.\u201d In free fall, the trajectory makes the proper time of an object a maximum. Let\u2019s see how this all works out. We begin with Eq. (42.5) which says that the excess rate of the moving watch is \u03c9 0 gH c 2 . (42.13) Besides this, we have to remember that there is a correction of the opposite sign for the speed. For this effect we know that \u03c9= \u03c9 0 1\u2212 v 2 / c 2 \u2212 \u2212 \u2212 \u2212 \u2212 \u2212 \u2212 \u2212 \u221a . Although the principle is valid for any speed, we take an example in which the speeds are always much less than c . Then we can write this equation as \u03c9= \u03c9 0 (1\u2212 v 2 /2 c 2 ), 2 2 and the defect in the rate of our clock is \u2212 \u03c9 0 v 2 2 c 2 . (42.14) Combining the two terms in (42.13) and (42.14) we have that \u0394\u03c9= \u03c9 0 c 2 (gH\u2212 v 2 2 ). (42.15) Such a frequency shift of our moving clock means that if we measure a time dt on a fixed clock, the moving clock will register the time dt[1+( gH c 2 \u2212 v 2 2 c 2 )], (42.16) The total time excess over the trajectory is the integral of the extra term with respect to time, namely 1 c 2 \u222b(gH\u2212 v 2 2 )dt, (42.17) which is supposed to be a maximum. The term gH is just the gravitational potential \u03d5 . Suppose we multiply the whole thing by a constant factor \u2212m c 2 , where m is the mass of the object. The constant won\u2019t change the condition for the maximum, but the minus sign will just change the maximum to a minimum. Equation (42.17) then says that the object will move so that \u222b( m v 2 2 \u2212m\u03d5)dt=a minimum. (42.18) But now the integrand is just the difference of the kinetic and potential energies. And if you look in Chapter 19 of Volume II you will see that when we discussed the principle of least action we showed that Newton\u2019s laws for an object in any potential could be written exactly in the form of Eq. (42.18). Einstein\u2019s form of the equations of motion\u2014that the proper time should be a maximum in curved space-time\u2014gives the same results as Newton\u2019s laws for low velocities. As he was circling around the earth, Gordon Cooper\u2019s watch was reading later than it would have in any other path you could have imagined for his satellite.6 So the law of gravitation can be stated in terms of the ideas of the geometry of space-time in this remarkable way. The particles always take the longest proper time\u2014in space-time a quantity analogous to the \u201cshortest distance.\u201d That\u2019s the law of motion in a gravitational field. The great advantage of putting it this way is that the law doesn\u2019t depend on any coordinates, or any other way of defining the situation. Now let\u2019s summarize what we have done. We have given you two laws for gravity: How the geometry of space-time changes when matter is present\u2014namely, that the curvature expressed in terms of the excess radius is proportional to the mass inside a sphere, Eq. (42.3). How objects move if there are only gravitational forces\u2014namely, that objects move so that their proper time between two end conditions is a maximum. Those two laws correspond to similar pairs of laws we have seen earlier. We originally described motion in a gravitational field in terms of Newton\u2019s inverse square law of gravitation and his laws of motion. Now laws (1) and (2) take their places. Our new pair of laws also correspond to what we have seen in electrodynamics. There we had our law\u2014the set of Maxwell\u2019s equations\u2014which determines the fields produced by charges. It tells how the character of \u201cspace\u201d is changed by the presence of charged matter, which is what law (1) does for gravity. In addition, we had a law about how particles move in the given fields\u2014 d(mv)/dt=q(E+v\u00d7B) . This, for gravity, is done by law (2). In the laws (1) and (2) you have a precise statement of Einstein\u2019s theory of gravitation\u2014although you will usually find it stated in a more complicated mathematical form. We should, however, make one further addition. Just as time scales change from place to place in a gravitational field, so do also the length scales. Rulers change lengths as you move around. It is impossible with space and time so intimately mixed to have something happen with time that isn\u2019t in some way reflected in space. Take even the simplest example: You are riding past the earth. What is \u201ctime\u201d from your point of view is partly space from our point of view. So there must also be changes in space. It is the entire space-time which is distorted by the presence of matter, and this is more complicated than a change only in time scale. However, the rule that we gave in Eq. (42.3) is enough to determine completely all the laws of gravitation, provided that it is understood that this rule about the curvature of space applies not only from one man\u2019s point of view but is true for everybody. Somebody riding by a mass of material sees a different mass content because of the kinetic energy he calculates for its motion past him, and he must include the mass corresponding to that energy. The theory must be arranged so that everybody\u2014no matter how he moves\u2014will, when he draws a sphere, find that the excess radius is G/3 c 2 times the total mass (or, better, G/3 c 4 times the total energy content) inside the sphere. That this law\u2014law (1)\u2014should be true in any moving system is one of the great laws of gravitation, called Einstein\u2019s field equation. The other great law is (2)\u2014that things must move so that the proper time is a maximum\u2014and is called Einstein\u2019s equation of motion. To write these laws in a complete algebraic form, to compare them with Newton\u2019s laws, or to relate them to electrodynamics is difficult mathematically. But it is the way our most complete laws of the physics of gravity look today. Although they gave a result in agreement with Newton\u2019s mechanics for the simple example we considered, they do not always do so. The three discrepancies first derived by Einstein have been experimentally confirmed: The orbit of Mercury is not a fixed ellipse; starlight passing near the sun is deflected twice as much as you would think; and the rates of clocks depend on their location in a gravitational field. Whenever the predictions of Einstein have been found to differ from the ideas of Newtonian mechanics Nature has chosen Einstein\u2019s. Let\u2019s summarize everything that we have said in the following way. First, time and distance rates depend on the place in space you measure them and on the time. This is equivalent to the statement that space-time is curved. From the measured area of a sphere we can define a predicted radius, A/4\u03c0 \u2212 \u2212 \u2212 \u2212 \u2212 \u221a , but the actual measured radius will have an excess over this which is proportional (the constant is G/3 c 2 ) to the total mass contained inside the sphere. This fixes the exact degree of the curvature of space-time. And the curvature must be the same no matter who is looking at the matter or how it is moving. Second, particles move on \u201cstraight lines\u201d (trajectories of maximum proper time) in this curved space-time. This is the content of Einstein\u2019s formulation of the laws of gravitation."
    },
    {
        "input": "Vector Integral Calculus",
        "output": "We found in Chapter 2 that there were various ways of taking derivatives of fields. Some gave vector fields; some gave scalar fields. Although we developed many different formulas, everything in Chapter 2 could be summarized in one rule: the operators \u2202/\u2202x , \u2202/\u2202y , and \u2202/\u2202z are the three components of a vector operator \u2207 . We would now like to get some understanding of the significance of the derivatives of fields. We will then have a better feeling for what a vector field equation means. We have already discussed the meaning of the gradient operation (\u2207 on a scalar). Now we turn to the meanings of the divergence and curl operations. The interpretation of these quantities is best done in terms of certain vector integrals and equations relating such integrals. These equations cannot, unfortunately, be obtained from vector algebra by some easy substitution, so you will just have to learn them as something new. Of these integral formulas, one is practically trivial, but the other two are not. We will derive them and explain their implications. The equations we shall study are really mathematical theorems. They will be useful not only for interpreting the meaning and the content of the divergence and the curl, but also in working out general physical theories. These mathematical theorems are, for the theory of fields, what the theorem of the conservation of energy is to the mechanics of particles. General theorems like these are important for a deeper understanding of physics. You will find, though, that they are not very useful for solving problems\u2014except in the simplest cases. It is delightful, however, that in the beginning of our subject there will be many simple problems which can be solved with the three integral formulas we are going to treat. We will see, however, as the problems get harder, that we can no longer use these simple methods. We take up first an integral formula involving the gradient. The relation contains a very simple idea: Since the gradient represents the rate of change of a field quantity, if we integrate that rate of change, we should get the total change. Suppose we have the scalar field \u03c8(x,y,z) . At any two points (1) and (2) , the function \u03c8 will have the values \u03c8(1) and \u03c8(2) , respectively. [We use a convenient notation, in which (2) represents the point (x2,y2,z2) and \u03c8(2) means the same thing as \u03c8(x2,y2,z2) .] If \u0393 (gamma) is any curve joining (1) and (2) , as in Fig. 3\u20131, the following relation is true: Theorem 1. \u03c8(2)\u2212\u03c8(1)=\u222b (2) (1) along \u0393(\u2207\u03c8)\u22c5ds. The integral is a line integral, from (1) to (2) along the curve \u0393 , of the dot product of \u2207\u03c8 \u2014a vector\u2014with ds \u2014another vector which is an infinitesimal line element of the curve \u0393 (directed away from (1) and toward (2) ). First, we should review what we mean by a line integral. Consider a scalar function f(x,y,z) , and the curve \u0393 joining two points (1) and (2) . We mark off the curve at a number of points and join these points by straight-line segments, as shown in Fig. 3\u20132. Each segment has the length \u0394si , where i is an index that runs 1 , 2 , 3 , \u2026 By the line integral \u222b (2) (1) along \u0393fds we mean the limit of the sum \u2211ifi\u0394si, where fi is the value of the function at the i th segment. The limiting value is what the sum approaches as we add more and more segments (in a sensible way, so that the largest \u0394si\u21920 ). The integral in our theorem, Eq. (3.1), means the same thing, although it looks a little different. Instead of f , we have another scalar\u2014the component of \u2207\u03c8 in the direction of \u0394s . If we write (\u2207\u03c8)t for this tangential component, it is clear that (\u2207\u03c8)t\u0394s=(\u2207\u03c8)\u22c5\u0394s. The integral in Eq. (3.1) means the sum of such terms. Now let\u2019s see why Eq. (3.1) is true. In Chapter 2, we showed that the component of \u2207\u03c8 along a small displacement \u0394R was the rate of change of \u03c8 in the direction of \u0394R . Consider the line segment \u0394s from (1) to point a in Fig. 3\u20132. According to our definition, \u0394\u03c81=\u03c8(a)\u2212\u03c8(1)=(\u2207\u03c8)1\u22c5\u0394s1. Also, we have \u03c8(b)\u2212\u03c8(a)=(\u2207\u03c8)2\u22c5\u0394s2, where, of course, (\u2207\u03c8)1 means the gradient evaluated at the segment \u0394s1 , and (\u2207\u03c8)2 , the gradient evaluated at \u0394s2 . If we add Eqs. (3.3) and (3.4), we get \u03c8(b)\u2212\u03c8(1)=(\u2207\u03c8)1\u22c5\u0394s1+(\u2207\u03c8)2\u22c5\u0394s2. You can see that if we keep adding such terms, we get the result \u03c8(2)\u2212\u03c8(1)=\u2211i(\u2207\u03c8)i\u22c5\u0394si. The left-hand side doesn\u2019t depend on how we choose our intervals\u2014if (1) and (2) are kept always the same\u2014so we can take the limit of the right-hand side. We have therefore proved Eq. (3.1). You can see from our proof that just as the equality doesn\u2019t depend on how the points a b , c , \u2026, are chosen, similarly it doesn\u2019t depend on what we choose for the curve \u0393 to join (1) and (2) . Our theorem is correct for any curve from (1) to (2) . One remark on notation: You will see that there is no confusion if we write, for convenience, (\u2207\u03c8)\u22c5ds=\u2207\u03c8\u22c5ds. With this notation, our theorem is Theorem 1. \u03c8(2)\u2212\u03c8(1)=\u222b (2) (1) any curve from (1) to (2) \u2207\u03c8\u22c5ds. Before we consider our next integral theorem\u2014a theorem about the divergence\u2014we would like to study a certain idea which has an easily understood physical significance in the case of heat flow. We have defined the vector h , which represents the heat that flows through a unit area in a unit time. Suppose that inside a block of material we have some closed surface S which encloses the volume V (Fig. 3\u20133). We would like to find out how much heat is flowing out of this volume. We can, of course, find it by calculating the total heat flow out of the surface S . We write da for the area of an element of the surface. The symbol stands for a two-dimensional differential. If, for instance, the area happened to be in the xy -plane we would have da=dxdy. Later we shall have integrals over volume and for these it is convenient to consider a differential volume that is a little cube. So when we write dV we mean dV=dxdydz. Some people like to write d2a instead of da to remind themselves that it is kind of a second-order quantity. They would also write d3V instead of dV . We will use the simpler notation, and assume that you can remember that an area has two dimensions and a volume has three. The heat flow out through the surface element da is the area times the component of h perpendicular to da . We have already defined n as a unit vector pointing outward at right angles to the surface (Fig. 3\u20133). The component of h that we want is hn=h\u22c5n. The heat flow out through da is then h\u22c5nda. To get the total heat flow through any surface we sum the contributions from all the elements of the surface. In other words, we integrate (3.10) over the whole surface: ( Total heat flow outward through S )=\u222bSh\u22c5nda. We are also going to call this surface integral \u201cthe flux of h through the surface.\u201d Originally the word flux meant flow, so that the surface integral just means the flow of h through the surface. We may think: h is the \u201ccurrent density\u201d of heat flow and the surface integral of it is the total heat current directed out of the surface; that is, the thermal energy per unit time (joules per second). We would like to generalize this idea to the case where the vector does not represent the flow of anything; for instance, it might be the electric field. We can certainly still integrate the normal component of the electric field over an area if we wish. Although it is not the flow of anything, we still call it the \u201cflux.\u201d We say ( Flux of E through the surface S )=\u222bSE\u22c5nda. We generalize the word \u201cflux\u201d to mean the \u201csurface integral of the normal component\u201d of a vector. We will also use the same definition even when the surface considered is not a closed one, as it is here. Returning to the special case of heat flow, let us take a situation in which heat is conserved. For example, imagine some material in which after an initial heating no further heat energy is generated or absorbed. Then, if there is a net heat flow out of a closed surface, the heat content of the volume inside must decrease. So, in circumstances in which heat would be conserved, we say that \u222bSh\u22c5nda=\u2212 dQ dt , where Q is the heat inside the surface. The heat flux out of S is equal to minus the rate of change with respect to time of the total heat Q inside of S . This interpretation is possible because we are speaking of heat flow and also because we supposed that the heat was conserved. We could not, of course, speak of the total heat inside the volume if heat were being generated there. Now we shall point out an interesting fact about the flux of any vector. You may think of the heat flow vector if you wish, but what we say will be true for any vector field C . Imagine that we have a closed surface S that encloses the volume V . We now separate the volume into two parts by some kind of a \u201ccut,\u201d as in Fig. 3\u20134. Now we have two closed surfaces and volumes. The volume V 1 is enclosed in the surface S 1 , which is made up of part of the original surface S a and of the surface of the cut, S ab . The volume V 2 is enclosed by S 2 , which is made up of the rest of the original surface S b and closed off by the cut S ab . Now consider the following question: Suppose we calculate the flux out through surface S 1 and add to it the flux through surface S 2 . Does the sum equal the flux through the whole surface that we started with? The answer is yes. The flux through the part of the surfaces S ab common to both S 1 and S 2 just exactly cancels out. For the flux of the vector C out of V 1 we can write Flux through S 1 = \u222b S a C\u22c5nda+ \u222b S ab C\u22c5 n 1 da, (3.14) and for the flux out of V 2 , Flux through S 2 = \u222b S b C\u22c5nda+ \u222b S ab C\u22c5 n 2 da. (3.15) Note that in the second integral we have written n 1 for the outward normal for S ab when it belongs to S 1 , and n 2 when it belongs to S 2 , as shown in Fig. 3\u20134. Clearly, n 1 =\u2212 n 2 , so that \u222b S ab C\u22c5 n 1 da=\u2212 \u222b S ab C\u22c5 n 2 da. (3.16) If we now add Eqs. (3.14) and (3.15), we see that the sum of the fluxes through S 1 and S 2 is just the sum of two integrals which, taken together, give the flux through the original surface S= S a + S b . We see that the flux through the complete outer surface S can be considered as the sum of the fluxes from the two pieces into which the volume was broken. We can similarly subdivide again\u2014say by cutting V 1 into two pieces. You see that the same arguments apply. So for any way of dividing the original volume, it must be generally true that the flux through the outer surface, which is the original integral, is equal to a sum of the fluxes out of all the little interior pieces. We now take the special case of a small cube1 and find an interesting formula for the flux out of it. Consider a cube whose edges are lined up with the axes as in Fig. 3\u20135. Let us suppose that the coordinates of the corner nearest the origin are x , y , z . Let \u0394x be the length of the cube in the x -direction, \u0394y be the length in the y -direction, and \u0394z be the length in the z -direction. We wish to find the flux of a vector field C through the surface of the cube. We shall do this by making a sum of the fluxes through each of the six faces. First, consider the face marked 1 in the figure. The flux outward on this face is the negative of the x -component of C , integrated over the area of the face. This flux is \u2212\u222b C x dydz. \u222b Since we are considering a small cube, we can approximate this integral by the value of C x at the center of the face\u2014which we call the point (1) \u2014multiplied by the area of the face, \u0394y\u0394z : Flux out of 1=\u2212 C x (1)\u0394y\u0394z. Flux out of ( ) Similarly, for the flux out of face 2 , we write Flux out of 2= C x (2)\u0394y\u0394z. Flux out of ( ) Now C x (1) and C x (2) are, in general, slightly different. If \u0394x is small enough, we can write C x (2)= C x (1)+ \u2202 C x \u2202x \u0394x. \u2202 C There are, of course, more terms, but they will involve (\u0394x ) 2 and higher powers, and so will be negligible if we consider only the limit of small \u0394x . So the flux through face 2 is Flux out of 2=[ C x (1)+ \u2202 C x \u2202x \u0394x]\u0394y\u0394z. \u2202 C Summing the fluxes for faces 1 and 2 , we get Flux out of 1 and 2= \u2202 C x \u2202x \u0394x\u0394y\u0394z. \u2202 C The derivative should really be evaluated at the center of face 1 ; that is, at [x,y+(\u0394y/2),z+(\u0394z/2)] . But in the limit of an infinitesimal cube, we make a negligible error if we evaluate it at the corner (x,y,z) . Applying the same reasoning to each of the other pairs of faces, we have Flux out of 3 and 4= \u2202 C y \u2202y \u0394x\u0394y\u0394z \u2202 C and Flux out of 5 and 6= \u2202 C z \u2202z \u0394x\u0394y\u0394z. \u2202 C The total flux through all the faces is the sum of these terms. We find that \u222b cube C\u22c5nda=( \u2202 C x \u2202x + \u2202 C y \u2202y + \u2202 C z \u2202z )\u0394x\u0394y\u0394z, \u2202 C and the sum of the derivatives is just \u2207\u22c5C . Also, \u0394x\u0394y\u0394z=\u0394V , the volume of the cube. So we can say that for an infinitesimal cube \u222b surface C\u22c5nda=(\u2207\u22c5C)\u0394V. (3.17) We have shown that the outward flux from the surface of an infinitesimal cube is equal to the divergence of the vector multiplied by the volume of the cube. We now see the \u201cmeaning\u201d of the divergence of a vector. The divergence of a vector at the point P is the flux\u2014the outgoing \u201cflow\u201d of C \u2014per unit volume, in the neighborhood of P . We have connected the divergence of C to the flux of C out of each infinitesimal volume. For any finite volume we can use the fact we proved above\u2014that the total flux from a volume is the sum of the fluxes out of each part. We can, that is, integrate the divergence over the entire volume. This gives us the theorem that the integral of the normal component of any vector over any closed surface can also be written as the integral of the divergence of the vector over the volume enclosed by the surface. This theorem is named after Gauss. Gauss\u2019 Theorem \u222b S C\u22c5nda= \u222b V \u2207\u22c5CdV, (3.18) where S is any closed surface and V is the volume inside it. Let\u2019s consider an example of the use of this theorem, just to get familiar with it. Suppose we take again the case of heat flow in, say, a metal. Suppose we have a simple situation in which all the heat has been previously put in and the body is just cooling off. There are no sources of heat, so that heat is conserved. Then how much heat is there inside some chosen volume at any time? It must be decreasing by just the amount that flows out of the surface of the volume. If our volume is a little cube, we would write, following Eq. (3.17), Heat out= \u222b cube h\u22c5nda=\u2207\u22c5h\u0394V. (3.19) But this must equal the rate of loss of the heat inside the cube. If q is the heat per unit volume, the heat in the cube is q\u0394V , and the rate of loss is \u2212 \u2202 \u2202t (q\u0394V)=\u2212 \u2202q \u2202t \u0394V. (3.20) Comparing (3.19) and (3.20), we see that \u2212 \u2202q \u2202t =\u2207\u22c5h. (3.21) Take careful note of the form of this equation; the form appears often in physics. It expresses a conservation law\u2014here the conservation of heat. We have expressed the same physical fact in another way in Eq. (3.13). Here we have the differential form of a conservation equation, while Eq. (3.13) is the integral form. We have obtained Eq. (3.21) by applying Eq. (3.13) to an infinitesimal cube. We can also go the other way. For a big volume V bounded by S , Gauss\u2019 law says that \u222b S h\u22c5nda= \u222b V \u2207\u22c5hdV. (3.22) Using (3.21), the integral on the right-hand side is found to be just \u2212dQ/dt , and again we have Eq. (3.13). Now let\u2019s consider a different case. Imagine that we have a block of material and that inside it there is a very tiny hole in which some chemical reaction is taking place and generating heat. Or we could imagine that there are some wires running into a tiny resistor that is being heated by an electric current. We shall suppose that the heat is generated practically at a point, and let W represent the energy liberated per second at that point. We shall suppose that in the rest of the volume heat is conserved, and that the heat generation has been going on for a long time\u2014so that now the temperature is no longer changing anywhere. The problem is: What does the heat vector h look like at various places in the metal? How much heat flow is there at each point? We know that if we integrate the normal component of h over a closed surface that encloses the source, we will always get W . All the heat that is being generated at the point source must flow out through the surface, since we have supposed that the flow is steady. We have the difficult problem of finding a vector field which, when integrated over any surface, always gives W . We can, however, find the field rather easily by taking a somewhat special surface. We take a sphere of radius R , centered at the source, and assume that the heat flow is radial (Fig. 3\u20136). Our intuition tells us that h should be radial if the block of material is large and we don\u2019t get too close to the edges, and it should also have the same magnitude at all points on the sphere. You see that we are adding a certain amount of guesswork\u2014usually called \u201cphysical intuition\u201d\u2014to our mathematics in order to find the answer. When h is radial and spherically symmetric, the integral of the normal component of h over the area is very simple, because the normal component is just the magnitude of h and is constant. The area over which we integrate is 4\u03c0 R 2 . We have then that \u222b S h\u22c5nda=h\u22c54\u03c0 R 2 (3.23) (where h is the magnitude of h ). This integral should equal W , the rate at which heat is produced at the source. We get h= W 4\u03c0 R 2 , W or h= W 4\u03c0 R 2 e r , (3.24) where, as usual, e r represents a unit vector in the radial direction. Our result says that h is proportional to W and varies inversely as the square of the distance from the source. The result we have just obtained applies to the heat flow in the vicinity of a point source of heat. Let\u2019s now try to find the equations that hold in the most general kind of heat flow, keeping only the condition that heat is conserved. We will be dealing only with what happens at places outside of any sources or absorbers of heat. The differential equation for the conduction of heat was derived in Chapter 2. According to Eq. (2.44), h=\u2212\u03ba\u2207T. (3.25) (Remember that this relationship is an approximate one, but fairly good for some materials like metals.) It is applicable, of course, only in regions of the material where there is no generation or absorption of heat. We derived above another relation, Eq. (3.21), that holds when heat is conserved. If we combine that equation with (3.25), we get \u2212 \u2202q \u2202t =\u2207\u22c5h=\u2212\u2207\u22c5(\u03ba\u2207T), \u2202 or \u2202q \u2202t =\u03ba\u2207\u22c5\u2207T=\u03ba \u2207 2 T, (3.26) if \u03ba is a constant. You remember that q is the amount of heat in a unit volume and \u2207\u22c5\u2207= \u2207 2 is the Laplacian operator \u2207 2 = \u2202 2 \u2202 x 2 + \u2202 2 \u2202 y 2 + \u2202 2 \u2202 z 2 . 2 2 2 If we now make one more assumption we can obtain a very interesting equation. We assume that the temperature of the material is proportional to the heat content per unit volume\u2014that is, that the material has a definite specific heat. When this assumption is valid (as it often is), we can write \u0394q= c v \u0394T \u0394 \u0394 T or \u2202q \u2202t = c v \u2202T \u2202t . (3.27) The rate of change of heat is proportional to the rate of change of temperature. The constant of proportionality c v is, here, the specific heat per unit volume of the material. Using Eq. (3.27) with (3.26), we get \u2202T \u2202t = \u03ba c v \u2207 2 T. (3.28) We find that the time rate of change of T \u2014at every point\u2014is proportional to the Laplacian of T , which is the second derivative of its spatial dependence. We have a differential equation\u2014in x , y , z , and t \u2014for the temperature T . The differential equation (3.28) is called the heat diffusion equation. It is often written as \u2202T \u2202t =D \u2207 2 T, (3.29) where D is called the diffusion constant, and is here equal to \u03ba/ c v . The diffusion equation appears in many physical problems\u2014in the diffusion of gases, in the diffusion of neutrons, and in others. We have already discussed the physics of some of these phenomena in Chapter 43 of Vol. I. Now you have the complete equation that describes diffusion in the most general possible situation. At some later time we will take up ways of solving the diffusion equation to find how the temperature varies in particular cases. We turn back now to consider other theorems about vector fields. We wish now to look at the curl in somewhat the same way we looked at the divergence. We obtained Gauss\u2019 theorem by considering the integral over a surface, although it was not obvious at the beginning that we were going to be dealing with the divergence. How did we know that we were supposed to integrate over a surface in order to get the divergence? It was not at all clear that this would be the result. And so with an apparent equal lack of justification, we shall calculate something else about a vector and show that it is related to the curl. This time we calculate what is called the circulation of a vector field. If C is any vector field, we take its component along a curved line and take the integral of this component all the way around a complete loop. The integral is called the circulation of the vector field around the loop. We have already considered a line integral of \u2207\u03c8 earlier in this chapter. Now we do the same kind of thing for any vector field C . Let \u0393 be any closed loop in space\u2014imaginary, of course. An example is given in Fig. 3\u20137. The line integral of the tangential component of C around the loop is written as \u222e \u0393 C t ds= \u222e \u0393 C\u22c5ds. (3.30) You should note that the integral is taken all the way around, not from one point to another as we did before. The little circle on the integral sign is to remind us that the integral is to be taken all the way around. This integral is called the circulation of the vector field around the curve \u0393 . The name came originally from considering the circulation of a liquid. But the name\u2014like flux\u2014has been extended to apply to any field even when there is no material \u201ccirculating.\u201d Playing the same kind of game we did with the flux, we can show that the circulation around a loop is the sum of the circulations around two partial loops. Suppose we break up our curve of Fig. 3\u20137 into two loops, by joining two points (1) and (2) on the original curve by some line that cuts across as shown in Fig. 3\u20138. There are now two loops, \u0393 1 and \u0393 2 . \u0393 1 is made up of \u0393 a , which is that part of the original curve to the left of (1) and (2) , plus \u0393 ab , the \u201cshort cut.\u201d \u0393 2 is made up of the rest of the original curve plus the short cut. The circulation around \u0393 1 is the sum of an integral along \u0393 a and along \u0393 ab . Similarly, the circulation around \u0393 2 is the sum of two parts, one along \u0393 b and the other along \u0393 ab . The integral along \u0393 ab will have, for the curve \u0393 2 , the opposite sign from what it has for \u0393 1 , because the direction of travel is opposite\u2014we must take both our line integrals with the same \u201csense\u201d of rotation. Following the same kind of argument we used before, you can see that the sum of the two circulations will give just the line integral around the original curve \u0393 . The parts due to \u0393 ab cancel. The circulation around the one part plus the circulation around the second part equals the circulation about the outer line. We can continue the process of cutting the original loop into any number of smaller loops. When we add the circulations of the smaller loops, there is always a cancellation of the parts on their adjacent portions, so that the sum is equivalent to the circulation around the original single loop. Now let us suppose that the original loop is the boundary of some surface. There are, of course, an infinite number of surfaces which all have the original loop as the boundary. Our results will not, however, depend on which surface we choose. First, we break our original loop into a number of small loops that all lie on the surface we have chosen, as in Fig. 3\u20139. No matter what the shape of the surface, if we choose our small loops small enough, we can assume that each of the small loops will enclose an area which is essentially flat. Also, we can choose our small loops so that each is very nearly a square. Now we can calculate the circulation around the big loop \u0393 by finding the circulations around all of the little squares and then taking their sum. How shall we find the circulation for each little square? One question is, how is the square oriented in space? We could easily make the calculation if it had a special orientation. For example, if it were in one of the coordinate planes. Since we have not assumed anything as yet about the orientation of the coordinate axes, we can just as well choose the axes so that the one little square we are concentrating on at the moment lies in the xy -plane, as in Fig. 3\u201310. If our result is expressed in vector notation, we can say that it will be the same no matter what the particular orientation of the plane. We want now to find the circulation of the field C around our little square. It will be easy to do the line integral if we make the square small enough that the vector C doesn\u2019t change much along any one side of the square. (The assumption is better the smaller the square, so we are really talking about infinitesimal squares.) Starting at the point (x,y) \u2014the lower left corner of the figure\u2014we go around in the direction indicated by the arrows. Along the first side\u2014marked (1) \u2014the tangential component is C x (1) and the distance is \u0394x . The first part of the integral is C x (1)\u0394x . Along the second leg, we get C y (2)\u0394y . Along the third, we get \u2212 C x (3)\u0394x , and along the fourth, \u2212 C y (4)\u0394y . The minus signs are required because we want the tangential component in the direction of travel. The whole line integral is then \u222eC\u22c5ds= \u2212 C x (1)\u0394x C x (3)\u0394x + \u2212 C y (2)\u0394y C y (4)\u0394y. (3.31) Now let\u2019s look at the first and third pieces. Together they are [ C x (1)\u2212 C x (3)]\u0394x. (3.32) You might think that to our approximation the difference is zero. That is true to the first approximation. We can be more accurate, however, and take into account the rate of change of C x . If we do, we may write C x (3)= C x (1)+ \u2202 C x \u2202y \u0394y. (3.33) If we included the next approximation, it would involve terms in (\u0394y ) 2 , but since we will ultimately think of the limit as \u0394y\u21920 , such terms can be neglected. Putting (3.33) together with (3.32), we find that [ C x (1)\u2212 C x (3)]\u0394x=\u2212 \u2202 C x \u2202y \u0394x\u0394y. (3.34) The derivative can, to our approximation, be evaluated at (x,y) . Similarly, for the other two terms in the circulation, we may write C y (2)\u0394y\u2212 C y (4)\u0394y= \u2202 C y \u2202x \u0394x\u0394y. (3.35) The circulation around our square is then ( \u2202 C y \u2202x \u2212 \u2202 C x \u2202y )\u0394x\u0394y, (3.36) which is interesting, because the two terms in the parentheses are just the z -component of the curl. Also, we note that \u0394x\u0394y is the area of our square. So we can write our circulation (3.36) as (\u2207\u00d7C ) z \u0394a. ( \u2207 ) But the z -component really means the component normal to the surface element. We can, therefore, write the circulation around a differential square in an invariant vector form: \u222eC\u22c5ds=(\u2207\u00d7C ) n \u0394a=(\u2207\u00d7C)\u22c5n\u0394a. (3.37) Our result is: the circulation of any vector C around an infinitesimal square is the component of the curl of C normal to the surface, times the area of the square. The circulation around any loop \u0393 can now be easily related to the curl of the vector field. We fill in the loop with any convenient surface S , as in Fig. 3\u201311, and add the circulations around a set of infinitesimal squares in this surface. The sum can be written as an integral. Our result is a very useful theorem called Stokes\u2019 theorem (after Mr. Stokes). Stokes\u2019 Theorem \u222e \u0393 C\u22c5ds= \u222b S (\u2207\u00d7C ) n da, (3.38) where S is any surface bounded by \u0393 . We must now speak about a convention of signs. In Fig. 3\u201310 the z -axis would point toward you in a \u201cusual\u201d\u2014that is, \u201cright-handed\u201d\u2014system of axes. When we took our line integral with a \u201cpositive\u201d sense of rotation, we found that the circulation was equal to the z -component of \u2207\u00d7C . If we had gone around the other way, we would have gotten the opposite sign. Now how shall we know, in general, what direction to choose for the positive direction of the \u201cnormal\u201d component of \u2207\u00d7C ? The \u201cpositive\u201d normal must always be related to the sense of rotation, as in Fig. 3\u201310. It is indicated for the general case in Fig. 3\u201311. One way of remembering the relationship is by the \u201cright-hand rule.\u201d If you make the fingers of your right hand go around the curve \u0393 , with the fingertips pointed in the direction of the positive sense of ds , then your thumb points in the direction of the positive normal to the surface S . We would like, now, to consider some consequences of our new theorems. Take first the case of a vector whose curl is everywhere zero. Then Stokes\u2019 theorem says that the circulation around any loop is zero. Now if we choose two points (1) and (2) on a closed curve (Fig. 3\u201312), it follows that the line integral of the tangential component from (1) to (2) is independent of which of the two possible paths is taken. We can conclude that the integral from (1) to (2) can depend only on the location of these points\u2014that is to say, it is some function of position only. The same logic was used in Chapter 14 of Vol. I, where we proved that if the integral around a closed loop of some quantity is always zero, then that integral can be represented as the difference of a function of the position of the two ends. This fact allowed us to invent the idea of a potential. We proved, furthermore, that the vector field was the gradient of this potential function (see Eq. (14.13) of Vol. I). It follows that any vector field whose curl is zero is equal to the gradient of some scalar function. That is, if \u2207\u00d7C=0 , everywhere, there is some \u03c8 (psi) for which C=\u2207\u03c8 \u2014a useful idea. We can, if we wish, describe this special kind of vector field by means of a scalar field. Let\u2019s show something else. Suppose we have any scalar field \u03d5 (phi). If we take its gradient, \u2207\u03d5 , the integral of this vector around any closed loop must be zero. Its line integral from point (1) to point (2) is [\u03d5(2)\u2212\u03d5(1)] . If (1) and (2) are the same points, our Theorem 1, Eq. (3.8), tells us that the line integral is zero: \u222e loop \u2207\u03d5\u22c5ds=0. \u222e Using Stokes\u2019 theorem, we can conclude that \u222b(\u2207\u00d7(\u2207\u03d5) ) n da=0 \u222b over any surface. But if the integral is zero over any surface, the integrand must be zero. So \u2207\u00d7(\u2207\u03d5)=0,always. \u2207 ( \u2207 \u03d5 ) always We proved the same result in Section 2\u20137 by vector algebra. Let\u2019s look now at a special case in which we fill in a small loop \u0393 with a large surface S , as indicated in Fig. 3\u201313. We would like, in fact, to see what happens when the loop shrinks down to a point, so that the surface boundary disappears\u2014the surface becomes closed. Now if the vector C is everywhere finite, the line integral around \u0393 must go to zero as we shrink the loop\u2014the integral is roughly proportional to the circumference of \u0393 , which goes to zero. According to Stokes\u2019 theorem, the surface integral of (\u2207\u00d7C ) n must also vanish. Somehow, as we close the surface we add in contributions that cancel out what was there before. So we have a new theorem: \u222b any closed surface (\u2207\u00d7C ) n da=0. (3.39) Now this is interesting, because we already have a theorem about the surface integral of a vector field. Such a surface integral is equal to the volume integral of the divergence of the vector, according to Gauss\u2019 theorem (Eq. 3.18). Gauss\u2019 theorem, applied to \u2207\u00d7C , says \u222b closed surface (\u2207\u00d7C ) n da= \u222b volume inside \u2207\u22c5(\u2207\u00d7C)dV. (3.40) So we conclude that the second integral must also be zero: \u222b any volume \u2207\u22c5(\u2207\u00d7C)dV=0, (3.41) and this is true for any vector field C whatever. Since Eq. (3.41) is true for any volume, it must be true that at every point in space the integrand is zero. We have \u2207\u22c5(\u2207\u00d7C)=0,always. \u2207 ( \u2207 ) always But this is the same result we got from vector algebra in Section 2\u20137. Now we begin to see how everything fits together. Let us summarize what we have found about the vector calculus. These are really the salient points of Chapters 2 and 3: The operators \u2202/\u2202x , \u2202/\u2202y , and \u2202/\u2202z can be considered as the three components of a vector operator \u2207 , and the formulas which result from vector algebra by treating this operator as a vector are correct: \u2207=( \u2202 \u2202x , \u2202 \u2202y , \u2202 \u2202z ). \u2202 \u2202 \u2202 The difference of the values of a scalar field at two points is equal to the line integral of the tangential component of the gradient of that scalar along any curve at all between the first and second points: \u03c8(2)\u2212\u03c8(1)= \u222b (2) (1) any curve \u2207\u03c8\u22c5ds. (3.42) The surface integral of the normal component of an arbitrary vector over a closed surface is equal to the integral of the divergence of the vector over the volume interior to the surface: \u222b closed surface C\u22c5nda= \u222b volume inside \u2207\u22c5CdV. (3.43) The line integral of the tangential component of an arbitrary vector around a closed loop is equal to the surface integral of the normal component of the curl of that vector over any surface which is bounded by the loop: \u222b boundary C\u22c5ds= \u222b surface (\u2207\u00d7C)\u22c5nda. (3.44)"
    },
    {
        "input": "Waves",
        "output": "Although we have finished our quantitative analyses of waves, this added chapter on the subject is intended to give some appreciation, qualitatively, for various phenomena that are associated with waves, which are too complicated to analyze in detail here. Since we have been dealing with waves for several chapters, more properly the subject might be called \u201csome of the more complex phenomena associated with waves.\u201d The first topic to be discussed concerns the effects that are produced by a source of waves which is moving faster than the wave velocity, or the phase velocity. Let us first consider waves that have a definite velocity, like sound and light. If we have a source of sound which is moving faster than the speed of sound, then something like this happens: Suppose at a given moment a sound wave is generated from the source at point x 1 in Fig. 51\u20131; then, in the next moment, as the source moves to x 2 , the wave from x 1 expands by a radius r 1 smaller than the distance that the source moves; and, of course, another wave starts from x 2 . When the sound source has moved still farther, to x 3 , and a wave is starting there, the wave from x 2 has now expanded to r 2 , and the one from x 1 has expanded to r 3 . Of course the thing is done continuously, not in steps, and therefore, we have a series of wave circles with a common tangent line which goes through the center of the source. We see that instead of a source generating spherical waves, as it would if it were standing still, it generates a wavefront which forms a cone in three dimensions, or a pair of lines in two dimensions. The angle of the cone is very easy to figure out. In a given amount of time the source moves a distance, say x 3 \u2212 x 1 , proportional to v , the velocity of the source. In the meantime the wavefront has moved out a distance r 3 , proportional to c w , the speed of the wave. Therefore it is clear that the half-angle of opening has a sine equal to the ratio of the speed of the waves, divided by the speed of the source, and this sine has a solution only if c w is less than v , or the speed of the object is faster than the speed of the wave: sin\u03b8= c w v . (51.1) Incidentally, although we implied that it is necessary to have a source of sound, it turns out, very interestingly, that once the object is moving faster than the speed of sound, it will make sound. That is, it is not necessary that it have a certain tone vibrational character. Any object moving through a medium faster than the speed at which the medium carries waves will generate waves on each side, automatically, just from the motion itself. This is simple in the case of sound, but it also occurs in the case of light. At first one might think nothing can move faster than the speed of light. However, light in glass has a phase velocity less than the speed of light in a vacuum, and it is possible to shoot a charged particle of very high energy through a block of glass such that the particle velocity is close to the speed of light in a vacuum, while the speed of light in the glass may be only 2 3 the speed of light in the vacuum. A particle moving faster than the speed of light in the medium will produce a conical wave of light with its apex at the source, like the wave wake from a boat (which is from the same effect, as a matter of fact). By measuring the cone angle, we can determine the speed of the particle. This is used technically to determine the speeds of particles as one of the methods of determining their energy in high-energy research. The direction of the light is all that needs to be measured. This light is sometimes called Cherenkov radiation, because it was first observed by Cherenkov. How intense this light should be was analyzed theoretically by Frank and Tamm. The 1958 Nobel Prize for physics was awarded jointly to all three for this work. The corresponding circumstances in the case of sound are illustrated in Fig. 51\u20132, which is a photograph of an object moving through a gas at a speed greater than the speed of sound. The changes in pressure produce a change in refractive index, and with a suitable optical system the edges of the waves can be made visible. We see that the object moving faster than the speed of sound does, indeed, produce a conical wave. But closer inspection reveals that the surface is actually curved. It is straight asymptotically, but it is curved near the apex, and we have now to discuss how that can be, which brings us to the second topic of this chapter. Wave speed often depends on the amplitude, and in the case of sound the speed depends upon the amplitude in the following way. An object moving through the air has to move the air out of the way, so the disturbance produced in this case is some kind of a pressure step, with the pressure higher behind the wavefront than in the undisturbed region not yet reached by the wave (running along at the normal speed, say). But the air that is left behind, after the wavefront passes, has been compressed adiabatically, and therefore the temperature is increased. Now the speed of sound increases with the temperature, so the speed in the region behind the jump is faster than in the air in front. That means that any other disturbance that is made behind this step, say by a continuous pushing of the body, or any other disturbance, will ride faster than the front, the speed increasing with higher pressure. Figure 51\u20133 illustrates the situation, with some little bumps of pressure added to the pressure contour to aid visualization. We see that the higher pressure regions at the rear overtake the front as time goes on, until ultimately the compressional wave develops a sharp front. If the strength is very high, \u201cultimately\u201d means right away; if it is rather weak, it takes a long time; it may be, in fact, that the sound is spreading and dying out before it has time to do this. The sounds we make in talking are extremely weak relative to the atmospheric pressure\u2014only 1 part in a million or so. But for pressure changes of the order of 1 atmosphere, the wave velocity increases by about twenty percent, and the wavefront sharpens up at a correspondingly high rate. In nature nothing happens infinitely rapidly, presumably, and what we call a \u201csharp\u201d front has, actually, a very slight thickness; it is not infinitely steep. The distances over which it is varying are of the order of one mean free path, in which the theory of the wave equation begins to fail because we did not consider the structure of the gas. Now, referring again to Fig. 51\u20132, we see that the curvature can be understood if we appreciate that the pressures near the apex are higher than they are farther back, and so the angle \u03b8 is greater. That is, the curve is the result of the fact that the speed depends upon the strength of the wave. Therefore the wave from an atomic bomb explosion travels much faster than the speed of sound for a while, until it gets so far out that it is weakened to such an extent from spreading that the pressure bump is small compared with atmospheric pressure. The speed of the bump then approaches the speed of sound in the gas into which it is going. (Incidentally, it always turns out that the speed of the shock is higher than the speed of sound in the gas ahead, but is lower than the speed of sound in the gas behind. That is, impulses from the back will arrive at the front, but the front rides into the medium in which it is going faster than the normal speed of signals. So one cannot tell, acoustically, that the shock is coming until it is too late. The light from the bomb arrives first, but one cannot tell that the shock is coming until it arrives, because there is no sound signal coming ahead of it.) This is a very interesting phenomenon, this piling up of waves, and the main point on which it depends is that after a wave is present, the speed of the resulting wave should be higher. Another example of the same phenomenon is the following. Consider water flowing in a long channel with finite width and finite depth. If a piston, or a wall across the channel, is moved along the channel fast enough, water piles up, like snow before a snow plow. Now suppose the situation is as shown in Fig. 51\u20134, with a sudden step in water height somewhere in the channel. It can be demonstrated that long waves in a channel travel faster in deeper water than they do in shallow water. Therefore any new bumps or irregularities in energy supplied by the piston run off forward and pile up at the front. Again, ultimately what we have is just water with a sharp front, theoretically. However, as Fig. 51\u20134 shows, there are complications. Pictured is a wave coming up a channel; the piston is at the far right end of the channel. At first it might have appeared like a well-behaved wave, as one might expect, but farther along the channel, it has become sharper and sharper until the events pictured occurred. There is a terrible churning at the surface, as the pieces of water fall down, but it is essentially a very sharp rise with no disturbance of the water ahead. Actually water is much more complicated than sound. However, just to illustrate a point, we will try to analyze the speed of such a so-called bore, in a channel. The point here is not that this is of any basic importance for our purposes\u2014it is not a great generalization\u2014it is only to illustrate that the laws of mechanics that we already know are capable of explaining the phenomenon. Imagine, for a moment, that the water does look something like Fig. 51\u20135(a), that water at the higher height h 2 is moving with a velocity v , and that the front is moving with velocity u into undisturbed water which is at height h 1 . We would like to determine the speed at which the front moves. In a time \u0394t a vertical plane initially at x 1 moves a distance v\u0394t to x 2 , while the front of the wave has moved u\u0394t . Now we apply the equations of conservation of matter and momentum. First, the former: Per unit channel width, we see that the amount h 2 v\u0394t of matter that has moved past x 1 (shown shaded) is compensated by the other shaded region, which amounts to ( h 2 \u2212 h 1 )u\u0394t . So, dividing by \u0394t , v h 2 =u( h 2 \u2212 h 1 ) . That does not yet give us enough, because although we have h 2 and h 1 , we do not know either u or v ; we are trying to get both of them. Now the next step is to use conservation of momentum. We have not discussed the problems of water pressure, or anything in hydrodynamics, but it is clear anyway that the pressure of water at a given depth is just enough to hold up the column of water above it. Therefore the pressure of water is equal to \u03c1 , the density of water, times g , times the depth below the surface. Since the pressure increases linearly with depth, the average pressure over the plane at x 1 , say, is 1 2 \u03c1g h 2 , which is also the average force per unit width and per unit height pushing the plane toward x 2 . So we multiply by another h 2 to get the total force which is acting on the water pushing from the left. On the other hand, there is pressure in the water on the right also, exerting an opposite force on the region in question, which is, by the same kind of analysis, 1 2 \u03c1g h 2 1 . Now we must balance the forces against the rate of change of the momentum. Thus we have to figure out how much more momentum there is in situation (b) in Fig. 51\u20135 than there was in (a). We see that the additional mass that has acquired the speed v is just \u03c1 h 2 u\u0394t\u2212\u03c1 h 2 v\u0394t (per unit width), and multiplying this by v gives the additional momentum to be equated to the impulse F\u0394t : (\u03c1 h 2 u\u0394t\u2212\u03c1 h 2 v\u0394t)v=( 1 2 \u03c1g h 2 2 \u2212 1 2 \u03c1g h 2 1 )\u0394t. 1 1 If we eliminate v from this equation by substituting v h 2 =u( h 2 \u2212 h 1 ) , already found, and simplify, we get finally that u 2 =g h 2 ( h 1 + h 2 )/2 h 1 . If the height difference is very small, so that h 1 and h 2 are nearly equal, this says that the velocity = gh \u2212 \u2212 \u221a . As we will see later, that is only true provided the wavelength of the wave is longer than the depth of the channel. We could also do the analogous thing for sound waves\u2014including the conservation of internal energy, not the conservation of entropy, because the shock is irreversible. In fact, if one checks the conservation of energy in the bore problem, one finds that energy is not conserved. If the height difference is small, it is almost perfectly conserved, but as soon as the height difference becomes very appreciable, there is a net loss of energy. This is manifested as the falling water and the churning shown in Fig. 51\u20134. In shock waves there is a corresponding apparent loss of energy, from the point of view of adiabatic reactions. The energy in the sound wave, behind the shock, goes into heating of the gas after shock passes, corresponding to churning of the water in the bore. In working it out, three equations for the sound case turn out to be necessary for solution, and the temperature behind the shock is not the same as the temperature in front, as we have seen. If we try to make a bore that is upside down ( h 2 < h 1 ), then we find that the energy loss per second is negative. Since energy is not available from anywhere, that bore cannot then maintain itself; it is unstable. If we were to start a wave of that sort, it would flatten out, because the speed dependence on height that resulted in sharpening in the case we discussed would now have the opposite effect. The next kind of waves to be discussed are the more complicated waves in solids. We have already discussed sound waves in gas and in liquid, and there is a direct analog to a sound wave in a solid. If a sudden push is applied to a solid, it is compressed. It resists the compression, and a wave analogous to sound is started. However there is another kind of wave that is possible in a solid, and which is not possible in a fluid. If a solid is distorted by pushing it sideways (called shearing), then it tries to pull itself back. That is by definition what distinguishes a solid from a liquid: if we distort a liquid (internally), hold it a minute so that it calms down, and then let go, it will stay that way, but if we take a solid and push it, like shearing a piece of \u201cJello,\u201d and let it go, it flies back and starts a shear wave, travelling in the same way the compressions travel. In all cases, the shear wave speed is less than the speed of longitudinal waves. The shear waves are somewhat more analogous, so far as their polarizations are concerned, to light waves. Sound has no polarization, it is just a pressure wave. Light has a characteristic orientation perpendicular to its direction of travel. In a solid, the waves are of both kinds. First, there is a compression wave, analogous to sound, that runs at one speed. If the solid is not crystalline, then a shear wave polarized in any direction will propagate at a characteristic speed. (Of course all solids are crystalline, but if we use a block made up of microcrystals of all orientations, the crystal anisotropies average out.) Another interesting question concerning sound waves is the following: What happens if the wavelength in a solid gets shorter, and shorter, and shorter? How short can it get? It is interesting that it cannot get any shorter than the space between the atoms, because if there is supposed to be a wave in which one point goes up and the next down, etc., the shortest possible wavelength is clearly the atom spacing. In terms of the modes of oscillation, we say that there are longitudinal modes, and transverse modes, long wave modes, short wave modes. As we consider wavelengths comparable to the spacing between the atoms, then the speeds are no longer constant; there is a dispersion effect where the velocity is not independent of the wave number. But, ultimately, the highest mode of transverse waves would be that in which every atom is doing the opposite of neighboring atoms. Now from the point of view of atoms, the situation is like the two pendulums that we were talking about, for which there are two modes, one in which they both go together, and the other in which they go apart. It is possible to analyze the solid waves another way, in terms of a system of coupled harmonic oscillators, like an enormous number of pendulums, with the highest mode such that they oscillate oppositely, and lower modes with different relationships of the timing. The shortest wavelengths are so short that they are not usually available technically. However they are of great interest because, in the theory of thermodynamics of a solid, the heat properties of a solid, for example specific heats, can be analyzed in terms of the properties of the short sound waves. Going to the extreme of sound waves of ever shorter wavelength, one necessarily comes to the individual motions of the atoms; the two things are the same ultimately. A very interesting example of sound waves in a solid, both longitudinal and transverse, are the waves that are in the solid earth. Who makes the noises we do not know, but inside the earth, from time to time, there are earthquakes\u2014some rock slides past some other rock. That is like a little noise. So waves like sound waves start out from such a source very much longer in wavelength than one usually considers in sound waves, but still they are sound waves, and they travel around in the earth. The earth is not homogeneous, however, and the properties, of pressure, density, compressibility, and so on, change with depth, and therefore the speed varies with depth. Then the waves do not travel in straight lines\u2014there is a kind of index of refraction and they go in curves. The longitudinal waves and the transverse waves have different speeds, so there are different solutions for the different speeds. Therefore if we place a seismograph at some location and watch the way the thing jiggles after there has been an earthquake somewhere else, then we do not just get an irregular jiggling. We might get a jiggling, and a quieting down, and then another jiggling\u2014what happens depends upon the location. If it were close enough, we would first receive longitudinal waves from the disturbance, and then, a few moments later, transverse waves, because they travel more slowly. By measuring the time difference between the two, we can tell how far away the earthquake is, if we know enough about the speeds and composition of the interior regions involved. An example of the behavior pattern of waves in the earth is shown in Fig. 51\u20136. The two kinds of waves are represented by different symbols. If there were an earthquake at the place marked \u201csource,\u201d the transverse waves and longitudinal waves would arrive at different times at the station by the most direct routes, and there would also be reflections at discontinuities, resulting in other paths and times. It turns out that there is a core in the earth which does not carry transverse waves. If the station is opposite the source, transverse waves still arrive, but the timing is not right. What happens is that the transverse wave comes to the core, and whenever the transverse waves come to a surface which is oblique, between two materials, two new waves are generated, one transverse and one longitudinal. But inside the core of the earth, a transverse wave is not propagated (or at least, there is no evidence for it, only for a longitudinal wave); it comes out again in both forms and comes to the station. It is from the behavior of these earthquake waves that it has been determined that transverse waves cannot be propagated within the inner circle. This means that the center of the earth is liquid in the sense that it cannot propagate transverse waves. The only way we know what is inside the earth is by studying earthquakes. So, by using a large number of observations of many earthquakes at different stations, the details have been worked out\u2014the speed, the curves, etc. are all known. We know what the speeds of various kinds of waves are at every depth. Knowing that, therefore, it is possible to figure out what the normal modes of the earth are, because we know the speed of propagation of sound waves\u2014in other words, the elastic properties of both kinds of waves at every depth. Suppose the earth were distorted into an ellipsoid and let go. It is just a matter of superposing waves travelling around in the ellipsoid to determine the period and shapes in a free mode. We have figured out that if there is a disturbance, there are a lot of modes, from the lowest, which is ellipsoidal, to higher modes with more structure. The Chilean earthquake of May 1960 made a loud enough \u201cnoise\u201d that the signals went around the earth many times, and new seismographs of great delicacy were made just in time to determine the frequencies of the fundamental modes of the earth and to compare them with the values that were calculated from the theory of sound with the known velocities, as measured from the independent earthquakes. The result of this experiment is illustrated in Fig. 51\u20137, which is a plot of the strength of the signal versus the frequency of its oscillation (a Fourier analysis). Note that at certain particular frequencies there is much more being received than at other frequencies; there are very definite maxima. These are the natural frequencies of the earth, because these are the main frequencies at which the earth can oscillate. In other words, if the entire motion of the earth is made up of many different modes, we would expect to obtain, for each station, irregular bumpings which indicate a superposition of many frequencies. If we analyze this in terms of frequencies, we should be able to find the characteristic frequencies of the earth. The vertical dark lines in the figure are the calculated frequencies, and we find a remarkable agreement, an agreement due to the fact that the theory of sound is right for the inside of the earth. A very curious point is revealed in Fig. 51\u20138, which shows a very careful measurement, with better resolution of the lowest mode, the ellipsoidal mode of the earth. Note that it is not a single maximum, but a double one, 54.7 minutes and 53.1 minutes\u2014slightly different. The reason for the two different frequencies was not known at the time that it was measured, although it may have been found in the meantime. There are at least two possible explanations: One would be that there may be asymmetry in the earth\u2019s distribution, which would result in two similar modes. Another possibility, which is even more interesting, is this: Imagine the waves going around the earth in two directions from the source. The speeds will not be equal because of effects of the rotation of the earth in the equations of motion, which have not been taken into account in making the analysis. Motion in a rotating system is modified by Coriolis forces, and these may cause the observed splitting. Regarding the method by which these quakes have been analyzed, what is obtained on the seismograph is not a curve of amplitude as a function of frequency, but displacement as a function of time, always a very irregular tracing. To find the amount of all the different sine waves for all different frequencies, we know that the trick is to multiply the data by a sine wave of a given frequency and integrate, i.e., average it, and in the average all other frequencies disappear. The figures were thus plots of the integrals found when the data were multiplied by sine waves of different cycles per minute, and integrated. Now, the next waves of interest, that are easily seen by everyone and which are usually used as an example of waves in elementary courses, are water waves. As we shall soon see, they are the worst possible example, because they are in no respects like sound and light; they have all the complications that waves can have. Let us start with long water waves in deep water. If the ocean is considered infinitely deep and a disturbance is made on the surface, waves are generated. All kinds of irregular motions occur, but the sinusoidal type motion, with a very small disturbance, might look like the common smooth ocean waves coming in toward the shore. Now with such a wave, the water, of course, on the average, is standing still, but the wave moves. What is the motion, is it transverse or longitudinal? It must be neither; it is not transverse, nor is it longitudinal. Although the water at a given place is alternately trough or hill, it cannot simply be moving up and down, by the conservation of water. That is, if it goes down, where is the water going to go? The water is essentially incompressible. The speed of compression of waves\u2014that is, sound in the water\u2014is much, much higher, and we are not considering that now. Since water is incompressible on this scale, as a hill comes down the water must move away from the region. What actually happens is that particles of water near the surface move approximately in circles. When smooth swells are coming, a person floating in a tire can look at a nearby object and see it going in a circle. So it is a mixture of longitudinal and transverse, to add to the confusion. At greater depths in the water the motions are smaller circles until, reasonably far down, there is nothing left of the motion (Fig. 51\u20139). To find the velocity of such waves is an interesting problem: it must be some combination of the density of the water, the acceleration of gravity, which is the restoring force that makes the waves, and possibly of the wavelength and of the depth. If we take the case where the depth goes to infinity, it will no longer depend on the depth. Whatever formula we are going to get for the velocity of the phases of the waves must combine the various factors to make the proper dimensions, and if we try this in various ways, we find only one way to combine the density, g , and \u03bb in order to make a velocity, namely, g\u03bb \u2212 \u2212 \u221a , which does not include the density at all. Actually, this formula for the phase velocity is not exactly right, but a complete analysis of the dynamics, which we will not go into, shows that the factors are as we have them, except for 2\u03c0 \u2212 \u2212 \u221a : v phase = g\u03bb/2\u03c0 \u2212 \u2212 \u2212 \u2212 \u2212 \u221a (for gravity waves). It is interesting that the long waves go faster than the short waves. Thus if a boat makes waves far out, because there is some sports-car driver in a motorboat travelling by, then after a while the waves come to shore with slow sloshings at first and then more and more rapid sloshings, because the first waves that come are long. The waves get shorter and shorter as the time goes on, because the velocities go as the square root of the wavelength. One may object, \u201cThat is not right, we must look at the group velocity in order to figure it out!\u201d Of course that is true. The formula for the phase velocity does not tell us what is going to arrive first; what tells us is the group velocity. So we have to work out the group velocity, and it is left as a problem to show it to be one-half of the phase velocity, assuming that the velocity goes as the square root of the wavelength, which is all that is needed. The group velocity also goes as the square root of the wavelength. How can the group velocity go half as fast as the phase? If one looks at the bunch of waves that are made by a boat travelling along, following a particular crest, he finds that it moves forward in the group and gradually gets weaker and dies out in the front, and mystically and mysteriously a weak one in the back works its way forward and gets stronger. In short, the waves are moving through the group while the group is only moving at half the speed that the waves are moving. Because the group velocities and phase velocities are not equal, then the waves that are produced by an object moving through are no longer simply a cone, but it is much more interesting. We can see that in Fig. 51\u201310, which shows the waves produced by an object moving through the water. Note that it is quite different than what we would have for sound, in which the velocity is independent of wavelength, where we would have wavefronts only along the cone, travelling outward. Instead of that, we have waves in the back with fronts moving parallel to the motion of the boat, and then we have little waves on the sides at other angles. This entire pattern of waves can, with ingenuity, be analyzed by knowing only this: that the phase velocity is proportional to the square root of the wavelength. The trick is that the pattern of waves is stationary relative to the (constant-velocity) boat; any other pattern would get lost from the boat. The water waves that we have been considering so far were long waves in which the force of restoration is due to gravitation. But when waves get very short in the water, the main restoring force is capillary attraction, i.e., the energy of the surface, the surface tension. For surface tension waves, it turns out that the phase velocity is v phase = 2\u03c0T/\u03bb\u03c1 \u2212 \u2212 \u2212 \u2212 \u2212 \u2212 \u221a (for ripples), where T is the surface tension and \u03c1 the density. It is the exact opposite: the phase velocity is higher, the shorter the wavelength, when the wavelength gets very small. When we have both gravity and capillary action, as we always do, we get the combination of these two together: v phase = Tk/\u03c1+g/k \u2212 \u2212 \u2212 \u2212 \u2212 \u2212 \u2212 \u2212 \u2212 \u221a , where k=2\u03c0/\u03bb is the wave number. So the velocity of the waves of water is really quite complicated. The phase velocity as a function of the wavelength is shown in Fig. 51\u201311; for very short waves it is fast, for very long waves it is fast, and there is a minimum speed at which the waves can go. The group velocity can be calculated from the formula: it goes to 3 2 the phase velocity for ripples and 1 2 the phase velocity for gravity waves. To the left of the minimum the group velocity is higher than the phase velocity; to the right, the group velocity is less than the phase velocity. There are a number of interesting phenomena associated with these facts. In the first place, since the group velocity is increasing so rapidly as the wavelength goes down, if we make a disturbance there will be a slowest end of the disturbance going at the minimum speed with the corresponding wavelength, and then in front, going at higher speed, will be a short wave and a very long wave. It is very hard to see the long ones, but it is easy to see the short ones in a water tank. So we see that the ripples often used to illustrate simple waves are quite interesting and complicated; they do not have a sharp wavefront at all, as is the case for simple waves like sound and light. The main wave has little ripples which run out ahead. A sharp disturbance in the water does not produce a sharp wave because of the dispersion. First come the very fine waves. Incidentally, if an object moves through the water at a certain speed, a rather complicated pattern results, because all the different waves are going at different speeds. One can demonstrate this with a tray of water and see that the fastest ones are the fine capillary waves. There are slowest waves, of a certain kind, which go behind. By inclining the bottom, one sees that where the depth is lower, the speed is lower. If a wave comes in at an angle to the line of maximum slope, it bends and tends to follow that line. In this way one can show various things, and we conclude that waves are more complicated in water than in air. The speed of long waves in water with circulational motions is slower when the depth is less, faster in deep water. Thus as water comes toward a beach where the depth lessens, the waves go slower. But where the water is deeper, the waves are faster, so we get the effects of shock waves. This time, since the wave is not so simple, the shocks are much more contorted, and the wave over-curves itself, in the familiar way shown in Fig. 51\u201312. This is what happens when waves come into the shore, and the real complexities in nature are well revealed in such a circumstance. No one has yet been able to figure out what shape the wave should take as it breaks. It is easy enough when the waves are small, but when one gets large and breaks, then it is much more complicated. An interesting feature about capillary waves can be seen in the disturbances made by an object moving through the water. From the point of view of the object itself, the water is flowing past, and the waves which ultimately sit around it are always the waves which have just the right speed to stay still with the object in the water. Similarly, around an object in a stream, with the stream flowing by, the pattern of waves is stationary, and at just the right wavelengths to go at the same speed as the water going by. But if the group velocity is less than the phase velocity, then the disturbances propagate out backwards in the stream, because the group velocity is not quite enough to keep up with the stream. If the group velocity is faster than the velocity of the phase, the pattern of waves will appear in front of the object. If one looks closely at objects in a stream, one can see that there are little ripples in front and long \u201cslurps\u201d in the back. Another interesting feature of this sort can be observed in pouring liquids. If milk is poured fast enough out of a bottle, for instance, a large number of lines can be seen crossing both ways in the outgoing stream. They are waves starting from the disturbance at the edges and running out, much like the waves about an object in a stream. There are effects from both sides which produce the crossed pattern. We have investigated some of the interesting properties of waves and the various complications of dependence of phase velocity on wavelength, the speed of the waves on depth, and so forth, that produce the really complex, and therefore interesting, phenomena of nature."
    },
    {
        "input": "The Dependence of Amplitudes on Position",
        "output": "We are now going to discuss how the probability amplitudes of quantum mechanics vary in space. In some of the earlier chapters you may have had a rather uncomfortable feeling that some things were being left out. For example, when we were talking about the ammonia molecule, we chose to describe it in terms of two base states. For one base state we picked the situation in which the nitrogen atom was \u201cabove\u201d the plane of the three hydrogen atoms, and for the other base state we picked the condition in which the nitrogen atom was \u201cbelow\u201d the plane of the three hydrogen atoms. Why did we pick just these two states? Why is it not possible that the nitrogen atom could be at 2 angstroms above the plane of the three hydrogen atoms, or at 3 angstroms, or at 4 angstroms above the plane? Certainly, there are many positions that the nitrogen atom could occupy. Again when we talked about the hydrogen molecular ion, in which there is one electron shared by two protons, we imagined two base states: one for the electron in the neighborhood of proton number one, and the other for the electron in the neighborhood of proton number two. Clearly we were leaving out many details. The electron is not exactly at proton number two but is only in the neighborhood. It could be somewhere above the proton, somewhere below the proton, somewhere to the left of the proton, or somewhere to the right of the proton. We intentionally avoided discussing these details. We said that we were interested in only certain features of the problem, so we were imagining that when the electron was in the vicinity of proton number one, it would take up a certain rather definite condition. In that condition the probability to find the electron would have some rather definite distribution around the proton, but we were not interested in the details. We can also put it another way. In our discussion of a hydrogen molecular ion we chose an approximate description when we described the situation in terms of two base states. In reality there are lots and lots of these states. An electron can take up a condition around a proton in its lowest, or ground, state, but there are also many excited states. For each excited state the distribution of the electron around the proton is different. We ignored these excited states, saying that we were interested in only the conditions of low energy. But it is just these other excited states which give the possibility of various distributions of the electron around the proton. If we want to describe in detail the hydrogen molecular ion, we have to take into account also these other possible base states. We could do this in several ways, and one way is to consider in greater detail states in which the location of the electron in space is more carefully described. We are now ready to consider a more elaborate procedure which will allow us to talk in detail about the position of the electron, by giving a probability amplitude to find the electron anywhere and everywhere in a given situation. This more complete theory provides the underpinning for the approximations we have been making in our earlier discussions. In a sense, our early equations can be derived as a kind of approximation to the more complete theory. You may be wondering why we did not begin with the more complete theory and make the approximations as we went along. We have felt that it would be much easier for you to gain an understanding of the basic machinery of quantum mechanics by beginning with the two-state approximations and working gradually up to the more complete theory than to approach the subject the other way around. For this reason our approach to the subject appears to be in the reverse order to the one you will find in many books. As we go into the subject of this chapter you will notice that we are breaking a rule we have always followed in the past. Whenever we have taken up any subject we have always tried to give a more or less complete description of the physics\u2014showing you as much as we could about where the ideas led to. We have tried to describe the general consequences of a theory as well as describing some specific detail so that you could see where the theory would lead. We are now going to break that rule; we are going to describe how one can talk about probability amplitudes in space and show you the differential equations which they satisfy. We will not have time to go on and discuss many of the obvious implications which come out of the theory. Indeed we will not even be able to get far enough to relate this theory to some of the approximate formulations we have used earlier\u2014for example, to the hydrogen molecule or to the ammonia molecule. For once, we must leave our business unfinished and open-ended. We are approaching the end of our course, and we must satisfy ourselves with trying to give you an introduction to the general ideas and with indicating the connections between what we have been describing and some of the other ways of approaching the subject of quantum mechanics. We hope to give you enough of an idea that you can go off by yourself and by reading books learn about many of the implications of the equations we are going to describe. We must, after all, leave something for the future. Let\u2019s review once more what we have found out about how an electron can move along a line of atoms. When an electron has an amplitude to jump from one atom to the next, there are definite energy states in which the probability amplitude for finding the electron is distributed along the lattice in the form of a traveling wave. For long wavelengths\u2014for small values of the wave number k \u2014the energy of the state is proportional to the square of the wave number. For a crystal lattice with the spacing b , in which the amplitude per unit time for the electron to jump from one atom to the next is iA/\u210f , the energy of the state is related to k (for small kb ) by E=Ak2b2 (see Section 13\u20132). We also saw that groups of such waves with similar energies would make up a wave packet which would behave like a classical particle with a mass meff given by: meff= \u210f2 2Ab2 . Since waves of probability amplitude in a crystal behave like a particle, one might well expect that the general quantum mechanical description of a particle would show the same kind of wave behavior we observed for the lattice. Suppose we were to think of a lattice on a line and imagine that the lattice spacing b were to be made smaller and smaller. In the limit we would be thinking of a case in which the electron could be anywhere along the line. We would have gone over to a continuous distribution of probability amplitudes. We would have the amplitude to find an electron anywhere along the line. This would be one way to describe the motion of an electron in a vacuum. In other words, if we imagine that space can be labeled by an infinity of points all very close together and we can work out the equations that relate the amplitudes at one point to the amplitudes at neighboring points, we will have the quantum mechanical laws of motion of an electron in space. Let\u2019s begin by recalling some of the general principles of quantum mechanics. Suppose we have a particle which can exist in various conditions in a quantum mechanical system. Any particular condition an electron can be found in, we call a \u201cstate,\u201d which we label with a state vector, say |\u03d5\u27e9 . Some other condition would be labeled with another state vector, say |\u03c8\u27e9 . We then introduce the idea of base states. We say that there is a set of states |1\u27e9 , |2\u27e9 , |3\u27e9 , |4\u27e9 , and so on, which have the following properties. First, all of these states are quite distinct\u2014we say they are orthogonal. By this we mean that for any two of the base states |i\u27e9 and |j\u27e9 the amplitude \u27e8i|j\u27e9 that an electron known to be in the state |i\u27e9 is also in the state |j\u27e9 is equal to zero\u2014unless, of course, |i\u27e9 and |j\u27e9 stand for the same state. We represent this symbolically by \u27e8i|j\u27e9=\u03b4ij. You will remember that \u03b4ij=0 if i and j are different, and \u03b4ij=1 if i and j are the same number. Second, the base states |i\u27e9 must be a complete set, so that any state at all can be described in terms of them. That is, any state |\u03d5\u27e9 at all can be described completely by giving all of the amplitudes \u27e8i|\u03d5\u27e9 that a particle in the state |\u03d5\u27e9 will also be found in the state |i\u27e9 . In fact, the state vector |\u03d5\u27e9 is equal to the sum of the base states each multiplied by a coefficient which is the amplitude that the state |\u03d5\u27e9 is also in the state |i\u27e9 : |\u03d5\u27e9= \u2211 i |i\u27e9\u27e8i|\u03d5\u27e9. Finally, if we consider any two states |\u03d5\u27e9 and |\u03c8\u27e9 , the amplitude that the state |\u03c8\u27e9 will also be in the state |\u03d5\u27e9 can be found by first projecting the state |\u03c8\u27e9 into the base states and then projecting from each base state into the state |\u03d5\u27e9 . We write that in the following way: \u27e8\u03d5|\u03c8\u27e9= \u2211 i \u27e8\u03d5|i\u27e9\u27e8i|\u03c8\u27e9. (16.5) The summation is, of course, to be carried out over the whole set of base states |i\u27e9 . In Chapter 13 when we were working out what happens with an electron placed on a linear array of atoms, we chose a set of base states in which the electron was localized at one or other of the atoms in the line. The base state |n\u27e9 represented the condition in which the electron was localized at atom number \u201c n .\u201d (There is, of course, no significance to the fact that we called our base states |n\u27e9 instead of |i\u27e9 .) A little later, we found it convenient to label the base states by the coordinate x n of the atom rather than by the number of the atom in the array. The state | x n \u27e9 is just another way of writing the state |n\u27e9 . Then, following the general rules, any state at all, say |\u03c8\u27e9 is described by giving the amplitudes that an electron in the state |\u03c8\u27e9 is also in one of the states | x n \u27e9 . For convenience we have chosen to let the symbol C n stand for these amplitudes, C n =\u27e8 x n |\u03c8\u27e9. (16.6) Since the base states are associated with a location along the line, we can think of the amplitude C n as a function of the coordinate x and write it as C( x n ) . The amplitudes C( x n ) will, in general, vary with time and are, therefore, also functions of t . We will not generally bother to show explicitly this dependence. In Chapter 13 we then proposed that the amplitudes C( x n ) should vary with time in a way described by the Hamiltonian equation (Eq. 13.3). In our new notation this equation is i\u210f \u2202C( x n ) \u2202t = E 0 C( x n )\u2212AC( x n +b)\u2212AC( x n \u2212b). (16.7) The last two terms on the right-hand side represent the process in which an electron at atom (n+1) or at atom (n\u22121) can feed into atom n . We found that Eq. (16.7) has solutions corresponding to definite energy states, which we wrote as C( x n )= e \u2212iEt/\u210f e ik x n . (16.8) For the low-energy states the wavelengths are large ( k is small), and the energy is related to k by E=( E 0 \u22122A)+A k 2 b 2 , (16.9) or, choosing our zero of energy so that ( E 0 \u22122A)=0 , the energy is given by Eq. (16.1). Let\u2019s see what might happen if we were to let the lattice spacing b go to zero, keeping the wave number k fixed. If that is all that were to happen the last term in Eq. (16.9) would just go to zero and there would be no physics. But suppose A and b are varied together so that as b goes to zero the product A b 2 is kept constant1\u2014using Eq. (16.2) we will write A b 2 as the constant \u210f 2 /2 m eff . Under these circumstances, Eq. (16.9) would be unchanged, but what would happen to the differential equation (16.7)? First we will rewrite Eq. (16.7) as i\u210f \u2202C( x n ) \u2202t =( E 0 \u22122A)C( x n )+ A[2C( x n )\u2212C( x n +b)\u2212C( x n \u2212b)]. (16.10) For our choice of E 0 , the first term drops out. Next, we can think of a continuous function C(x) that goes smoothly through the proper values C( x n ) at each x n . As the spacing b goes to zero, the points x n get closer and closer together, and (if we keep the variation of C(x) fairly smooth) the quantity in the brackets is just proportional to the second derivative of C(x) . We can write\u2014as you can see by making a Taylor expansion of each term\u2014the equality 2C(x)\u2212C(x+b)\u2212C(x\u2212b)\u2248\u2212 b 2 \u2202 2 C(x) \u2202 x 2 . (16.11) In the limit, then, as b goes to zero, keeping b 2 A equal to \u210f 2 /2 m eff , Eq. (16.7) goes over into i\u210f \u2202C(x) \u2202t =\u2212 \u210f 2 2 m eff \u2202 2 C(x) \u2202 x 2 . (16.12) We have an equation which says that the time rate of change of C(x) \u2014the amplitude to find the electron at x \u2014depends on the amplitude to find the electron at nearby points in a way which is proportional to the second derivative of the amplitude with respect to position. The correct quantum mechanical equation for the motion of an electron in free space was first discovered by Schr\u00f6dinger. For motion along a line it has exactly the form of Eq. (16.12) if we replace m eff by m , the free-space mass of the electron. For motion along a line in free space the Schr\u00f6dinger equation is i\u210f \u2202C(x) \u2202t =\u2212 \u210f 2 2m \u2202 2 C(x) \u2202 x 2 . (16.13) We do not intend to have you think we have derived the Schr\u00f6dinger equation but only wish to show you one way of thinking about it. When Schr\u00f6dinger first wrote it down, he gave a kind of derivation based on some heuristic arguments and some brilliant intuitive guesses. Some of the arguments he used were even false, but that does not matter; the only important thing is that the ultimate equation gives a correct description of nature. The purpose of our discussion is then simply to show you that the correct fundamental quantum mechanical equation (16.13) has the same form you get for the limiting case of an electron moving along a line of atoms. This means that we can think of the differential equation in (16.13) as describing the diffusion of a probability amplitude from one point to the next along the line. That is, if an electron has a certain amplitude to be at one point, it will, a little time later, have some amplitude to be at neighboring points. In fact, the equation looks something like the diffusion equations which we have used in Volume I. But there is one main difference: the imaginary coefficient in front of the time derivative makes the behavior completely different from the ordinary diffusion such as you would have for a gas spreading out along a thin tube. Ordinary diffusion gives rise to real exponential solutions, whereas the solutions of Eq. (16.13) are complex waves. Now that you have some idea about how things are going to look, we want to go back to the beginning and study the problem of describing the motion of an electron along a line without having to consider states connected with atoms on a lattice. We want to go back to the beginning and see what ideas we have to use if we want to describe the motion of a free particle in space. Since we are interested in the behavior of a particle, along a continuum, we will be dealing with an infinite number of possible states and, as you will see, the ideas we have developed for dealing with a finite number of states will need some technical modifications. We begin by letting the state vector |x\u27e9 stand for a state in which a particle is located precisely at the coordinate x . For every value x along the line\u2014for instance 1.73 , or 9.67 , or 10.00 \u2014there is the corresponding state. We will take these states |x\u27e9 as our base states and, if we include all the points on the line, we will have a complete set for motion in one dimension. Now suppose we have a different kind of a state, say |\u03c8\u27e9 , in which an electron is distributed in some way along the line. One way of describing this state is to give all the amplitudes that the electron will be also found in each of the base states |x\u27e9 . We must give an infinite set of amplitudes, one for each value of x . We will write these amplitudes as \u27e8x|\u03c8\u27e9 . Each of these amplitudes is a complex number and since there is one such complex number for each value of x , the amplitude \u27e8x|\u03c8\u27e9 is indeed just a function of x . We will also write it as C(x) , C(x)\u2261\u27e8x|\u03c8\u27e9. (16.14) We have already considered such amplitudes which vary in a continuous way with the coordinates when we talked about the variations of amplitude with time in Chapter 7. We showed there, for example, that a particle with a definite momentum should be expected to have a particular variation of its amplitude in space. If a particle has a definite momentum p and a corresponding definite energy E , the amplitude to be found at any position x would look like \u27e8x|\u03c8\u27e9=C(x)\u221d e +ipx/\u210f . (16.15) This equation expresses an important general principle of quantum mechanics which connects the base states corresponding to different positions in space to another system of base states\u2014all the states of definite momentum. The definite momentum states are often more convenient than the states in x for certain kinds of problems. Either set of base states is, of course, equally acceptable for a description of a quantum mechanical situation. We will come back later to the matter of the connection between them. For the moment we want to stick to our discussion of a description in terms of the states |x\u27e9 . Before proceeding, we want to make one small change in notation which we hope will not be too confusing. The function C(x) , defined in Eq. (16.14), will of course have a form which depends on the particular state |\u03c8\u27e9 under consideration. We should indicate that in some way. We could, for example, specify which function C(x) we are talking about by a subscript say, C \u03c8 (x) . Although this would be a perfectly satisfactory notation, it is a little bit cumbersome and is not the one you will find in most books. Most people simply omit the letter C and use the symbol \u03c8 to define the function \u03c8(x)\u2261 C \u03c8 (x)=\u27e8x|\u03c8\u27e9. (16.16) Since this is the notation used by everybody else in the world, you might as well get used to it so that you will not be frightened when you come across it somewhere else. Remember though, that we will now be using \u03c8 in two different ways. In Eq. (16.14), \u03c8 stands for a label we have given to a particular physical state of the electron. On the left-hand side of Eq. (16.16), on the other hand, the symbol \u03c8 is used to define a mathematical function of x which is equal to the amplitude to be associated with each point x along the line. We hope it will not be too confusing once you get accustomed to the idea. Incidentally, the function \u03c8(x) is usually called \u201cthe wave function\u201d\u2014because it more often than not has the form of a complex wave in its variables. Since we have defined \u03c8(x) to be the amplitude that an electron in the state \u03c8 will be found at the location x , we would like to interpret the absolute square of \u03c8 to be the probability of finding an electron at the position x . Unfortunately, the probability of finding a particle exactly at any particular point is zero. The electron will, in general, be smeared out in a certain region of the line, and since, in any small piece of the line, there are an infinite number of points, the probability that it will be at any one of them cannot be a finite number. We can only describe the probability of finding an electron in terms of a probability distribution2 which gives the relative probability of finding the electron at various approximate locations along the line. Let\u2019s let prob(x,\u0394x) stand for the chance of finding the electron in a small interval \u0394x located near x . If we go to a small enough scale in any physical situation, the probability will be varying smoothly from place to place, and the probability of finding the electron in any small finite line segment \u0394x will be proportional to \u0394x . We can modify our definitions to take this into account. We can think of the amplitude \u27e8x|\u03c8\u27e9 as representing a kind of \u201camplitude density\u201d for all the base states |x\u27e9 in a small region. Since the probability of finding an electron in a small interval \u0394x at x should be proportional to the interval \u0394x , we choose our definition of \u27e8x|\u03c8\u27e9 so that the following relation holds: prob(x,\u0394x)=|\u27e8x|\u03c8\u27e9 | 2 \u0394x. 2 The amplitude \u27e8x|\u03c8\u27e9 is therefore proportional to the amplitude that an electron in the state \u03c8 will be found in the base state x and the constant of proportionality is chosen so that the absolute square of the amplitude \u27e8x|\u03c8\u27e9 gives the probability density of finding an electron in any small region. We can write, equivalently, prob(x,\u0394x)=|\u03c8(x) | 2 \u0394x. (16.17) We will now have to modify some of our earlier equations to make them compatible with this new definition of a probability amplitude. Suppose we have an electron in the state |\u03c8\u27e9 and we want to know the amplitude for finding it in a different state |\u03d5\u27e9 which may correspond to a different spread-out condition of the electron. When we were talking about a finite set of discrete states, we would have used Eq. (16.5). Before modifying our definition of the amplitudes we would have written \u27e8\u03d5|\u03c8\u27e9= \u2211 all x \u27e8\u03d5|x\u27e9\u27e8x|\u03c8\u27e9. (16.18) Now if both of these amplitudes are normalized in the same way as we have described above, then a sum of all the states in a small region of x would be equivalent to multiplying by \u0394x , and the sum over all values of x simply becomes an integral. With our modified definitions, the correct form becomes \u27e8\u03d5|\u03c8\u27e9= \u222b all x \u27e8\u03d5|x\u27e9\u27e8x|\u03c8\u27e9dx. (16.19) The amplitude \u27e8x|\u03c8\u27e9 is what we are now calling \u03c8(x) and, in a similar way, we will choose to let the amplitude \u27e8x|\u03d5\u27e9 be represented by \u03d5(x) . Remembering that \u27e8\u03d5|x\u27e9 is the complex conjugate of \u27e8x|\u03d5\u27e9 , we can write Eq. (16.19) as \u27e8\u03d5|\u03c8\u27e9=\u222b \u03d5 \u2217 (x)\u03c8(x)dx. (16.20) With our new definitions everything follows with the same formulas as before if you always replace a summation sign by an integral over x . We should mention one qualification to what we have been saying. Any suitable set of base states must be complete if it is to be used for an adequate description of what is going on. For an electron in one dimension it is not really sufficient to specify only the base states |x\u27e9 , because for each of these states the electron may have a spin which is either up or down. One way of getting a complete set is to take two sets of states in x , one for up spin and the other for down spin. We will, however, not worry about such complications for the time being. Suppose we have an electron in a state |\u03c8\u27e9 which is described by the probability amplitude \u27e8x|\u03c8\u27e9=\u03c8(x) . We know that this represents a state in which the electron is spread out along the line in a certain distribution so that the probability of finding the electron in a small interval dx at the location x is just prob(x,dx)=|\u03c8(x) | 2 dx. 2 What can we say about the momentum of this electron? We might ask what is the probability that this electron has the momentum p ? Let\u2019s start out by calculating the amplitude that the state |\u03c8\u27e9 is in another state |momp\u27e9 which we define to be a state with the definite momentum p . We can find this amplitude by using our basic equation for the resolution of amplitudes, Eq. (16.19). In terms of the state |momp\u27e9 \u27e8momp|\u03c8\u27e9= \u222b +\u221e x=\u2212\u221e \u27e8momp|x\u27e9\u27e8x|\u03c8\u27e9dx. (16.21) And the probability that the electron will be found with the momentum p should be given in terms of the absolute square of this amplitude. We have again, however, a small problem about the normalizations. In general we can only ask about the probability of finding an electron with a momentum in a small range dp at the momentum p . The probability that the momentum is exactly some value p must be zero (unless the state |\u03c8\u27e9 happens to be a state of definite momentum). Only if we ask for the probability of finding the momentum in a small range dp at the momentum p will we get a finite probability. There are several ways the normalizations can be adjusted. We will choose one of them which we think to be the most convenient, although that may not be apparent to you just now. We take our normalizations so that the probability is related to the amplitude by prob(p,dp)=|\u27e8momp|\u03c8\u27e9 | 2 dp 2\u03c0\u210f . (16.22) With this definition the normalization of the amplitude \u27e8momp|x\u27e9 is determined. The amplitude \u27e8momp|x\u27e9 is, of course, just the complex conjugate of the amplitude \u27e8x|momp\u27e9 , which is just the one we have written down in Eq. (16.15). With the normalization we have chosen, it turns out that the proper constant of proportionality in front of the exponential is just 1 . Namely, \u27e8momp|x\u27e9=\u27e8x|momp \u27e9 \u2217 = e \u2212ipx/\u210f . (16.23) Equation (16.21) then becomes \u27e8momp|\u03c8\u27e9= \u222b +\u221e \u2212\u221e e \u2212ipx/\u210f \u27e8x|\u03c8\u27e9dx. (16.24) This equation together with Eq. (16.22) allows us to find the momentum distribution for any state |\u03c8\u27e9 . Let\u2019s look at a particular example\u2014for instance one in which an electron is localized in a certain region around x=0 . Suppose we take a wave function which has the following form: \u03c8(x)=K e \u2212 x 2 /4 \u03c3 2 . (16.25) The probability distribution in x for this wave function is the absolute square, or prob(x,dx)=P(x)dx= K 2 e \u2212 x 2 /2 \u03c3 2 dx. (16.26) The probability density function P(x) is the Gaussian curve shown in Fig. 16\u20131. Most of the probability is concentrated between x=+\u03c3 and x=\u2212\u03c3 . We say that the \u201chalf-width\u201d of the curve is \u03c3 . (More precisely, \u03c3 is equal to the root-mean-square of the coordinate x for something spread out according to this distribution.) We would normally choose the constant K so that the probability density P(x) is not merely proportional to the probability per unit length in x of finding the electron, but has a scale such that P(x)\u0394x is equal to the probability of finding the electron in \u0394x near x . The constant K which does this can be found by requiring that \u222b +\u221e \u2212\u221e P(x)dx=1 , since there must be unit probability that the electron is found somewhere. Here, we get that K=(2\u03c0 \u03c3 2 ) \u22121/4 . [We have used the fact that \u222b +\u221e \u2212\u221e e \u2212 t 2 dt= \u03c0 \u2212 \u2212 \u221a ; see Vol. I, footnote 40-1.] Now let\u2019s find the distribution in momentum. Let\u2019s let \u03d5(p) stand for the amplitude to find the electron with the momentum p , \u03d5(p)\u2261\u27e8momp|\u03c8\u27e9. (16.27) Substituting Eq. (16.25) into Eq. (16.24) we get \u03d5(p)= \u222b +\u221e \u2212\u221e e \u2212ipx/\u210f \u22c5K e \u2212 x 2 /4 \u03c3 2 dx. (16.28) The integral can also be rewritten as K e \u2212 p 2 \u03c3 2 / \u210f 2 \u222b +\u221e \u2212\u221e e \u2212(1/4 \u03c3 2 )(x+2ip \u03c3 2 /\u210f ) 2 dx. (16.29) We can now make the substitution u=x+2ip \u03c3 2 /\u210f , and the integral is \u222b +\u221e \u2212\u221e e \u2212 u 2 /4 \u03c3 2 du=2\u03c3 \u03c0 \u2212 \u2212 \u221a . (16.30) (The mathematicians would probably object to the way we got there, but the result is, nevertheless, correct.) \u03d5(p)=(8\u03c0 \u03c3 2 ) 1/4 e \u2212 p 2 \u03c3 2 / \u210f 2 . (16.31) We have the interesting result that the amplitude function in p has precisely the same mathematical form as the amplitude function in x ; only the width of the Gaussian is different. We can write this as \u03d5(p)=( \u03b7 2 /2\u03c0 \u210f 2 ) \u22121/4 e \u2212 p 2 /4 \u03b7 2 , (16.32) where the half-width \u03b7 of the p -distribution function is related to the half-width \u03c3 of the x -distribution by \u03b7= \u210f 2\u03c3 . (16.33) Our result says: if we make the width of the distribution in x very small by making \u03c3 small, \u03b7 becomes large and the distribution in p is very much spread out. Or, conversely: if we have a narrow distribution in p , it must correspond to a spread-out distribution in x . We can, if we like, consider \u03b7 and \u03c3 to be some measure of the uncertainty in the localization of the momentum and of the position of the electron in the state we are studying. If we call them \u0394p and \u0394x respectively Eq. (16.33) becomes \u0394p\u0394x= \u210f 2 . (16.34) Interestingly enough, it is possible to prove that for any other form of a distribution in x or in p , the product \u0394p\u0394x cannot be smaller than the one we have found here. The Gaussian distribution gives the smallest possible value for the product of the root-mean-square widths. In general, we can say \u0394p\u0394x\u2265 \u210f 2 . (16.35) This is a quantitative statement of the Heisenberg uncertainty principle, which we have discussed qualitatively many times before. We have usually made the approximate statement that the minimum value of the product \u0394p\u0394x is of the same order as \u210f . We return now to the discussion of the modifications of our basic equations which are required when we are dealing with a continuum of base states. When we have a finite number of discrete states, a fundamental condition which must be satisfied by the set of base states is \u27e8i|j\u27e9= \u03b4 ij . (16.36) If a particle is in one base state, the amplitude to be in another base state is 0 . By choosing a suitable normalization, we have defined the amplitude \u27e8i|i\u27e9 to be 1 . These two conditions are described by Eq. (16.36). We want now to see how this relation must be modified when we use the base states |x\u27e9 of a particle on a line. If the particle is known to be in one of the base states |x\u27e9 , what is the amplitude that it will be in another base state | x \u2032 \u27e9 ? If x and x \u2032 are two different locations along the line, then the amplitude \u27e8x| x \u2032 \u27e9 is certainly 0 , so that is consistent with Eq. (16.36). But if x and x \u2032 are equal, the amplitude \u27e8x| x \u2032 \u27e9 will not be 1 , because of the same old normalization problem. To see how we have to patch things up, we go back to Eq. (16.19), and apply this equation to the special case in which the state |\u03d5\u27e9 is just the base state | x \u2032 \u27e9 . We would have then \u27e8 x \u2032 |\u03c8\u27e9=\u222b\u27e8 x \u2032 |x\u27e9\u03c8(x)dx. (16.37) Now the amplitude \u27e8x|\u03c8\u27e9 is just what we have been calling the function \u03c8(x) . Similarly the amplitude \u27e8 x \u2032 |\u03c8\u27e9 , since it refers to the same state |\u03c8\u27e9 , is the same function of the variable x \u2032 , namely \u03c8( x \u2032 ) . We can, therefore, rewrite Eq. (16.37) as \u03c8( x \u2032 )=\u222b\u27e8 x \u2032 |x\u27e9\u03c8(x)dx. (16.38) This equation must be true for any state |\u03c8\u27e9 and, therefore, for any arbitrary function \u03c8(x) . This requirement should completely determine the nature of the amplitude \u27e8x| x \u2032 \u27e9 \u2014which is, of course, just a function that depends on x and x \u2032 . Our problem now is to find a function f(x, x \u2032 ) , which when multiplied into \u03c8(x) , and integrated over all x gives just the quantity \u03c8( x \u2032 ) . It turns out that there is no mathematical function which will do this! At least nothing like what we ordinarily mean by a \u201cfunction.\u201d Suppose we pick x \u2032 to be the special number 0 and define the amplitude \u27e80|x\u27e9 to be some function of x , let\u2019s say f(x) . Then Eq. (16.38) would read as follows: \u03c8(0)=\u222bf(x)\u03c8(x)dx. (16.39) What kind of function f(x) could possibly satisfy this equation? Since the integral must not depend on what values \u03c8(x) takes for values of x other than 0 , f(x) must clearly be 0 for all values of x except 0 . But if f(x) is 0 everywhere, the integral will be 0 , too, and Eq. (16.39) will not be satisfied. So we have an impossible situation: we wish a function to be 0 everywhere but at a point, and still to give a finite integral. Since we can\u2019t find a function that does this, the easiest way out is just to say that the function f(x) is defined by Eq. (16.39). Namely, f(x) is that function which makes (16.39) correct. The function which does this was first invented by Dirac and carries his name. We write it \u03b4(x) . All we are saying is that the function \u03b4(x) has the strange property that if it is substituted for f(x) in the Eq. (16.39), the integral picks out the value that \u03c8(x) takes on when x is equal 0 ; and, since the integral must be independent of \u03c8(x) for all values of x other than 0 , the function \u03b4(x) must be 0 everywhere except at x=0 . Summarizing, we write \u27e80|x\u27e9=\u03b4(x), (16.40) where \u03b4(x) is defined by \u03c8(0)=\u222b\u03b4(x)\u03c8(x)dx. (16.41) Notice what happens if we use the special function \u201c 1 \u201d for the function \u03c8 in Eq. (16.41). Then we have the result 1=\u222b\u03b4(x)dx. (16.42) That is, the function \u03b4(x) has the property that it is 0 everywhere except at x=0 but has a finite integral equal to unity. We must imagine that the function \u03b4(x) has such a fantastic infinity at one point that the total area comes out equal to one. One way of imagining what the Dirac \u03b4 -function is like is to think of a sequence of rectangles\u2014or any other peaked function you care to\u2014which gets narrower and narrower and higher and higher, always keeping a unit area, as sketched in Fig. 16\u20132. The integral of this function from \u2212\u221e to +\u221e is always 1 . If you multiply it by any function \u03c8(x) and integrate the product, you get something which is approximately the value of the function at x=0 , the approximation getting better and better as you use the narrower and narrower rectangles. You can if you wish, imagine the \u03b4 -function in terms of this kind of limiting process. The only important thing, however, is that the \u03b4 -function is defined so that Eq. (16.41) is true for every possible function \u03c8(x) . That uniquely defines the \u03b4 -function. Its properties are then as we have described. If we change the argument of the \u03b4 -function from x to x\u2212 x \u2032 , the corresponding relations are \u03b4(x\u2212 x \u2032 )=0, x \u2032 \u2260x, \u222b\u03b4(x\u2212 x \u2032 )\u03c8(x)dx=\u03c8( x \u2032 ). (16.43) If we use \u03b4(x\u2212 x \u2032 ) for the amplitude \u27e8x| x \u2032 \u27e9 in Eq. (16.38), that equation is satisfied. Our result then is that for our base states in x , the condition corresponding to (16.36) is \u27e8 x \u2032 |x\u27e9=\u03b4(x\u2212 x \u2032 ). (16.44) We have now completed the necessary modifications of our basic equations which are necessary for dealing with the continuum of base states corresponding to the points along a line. The extension to three dimensions is fairly obvious; first we replace the coordinate x by the vector r . Then integrals over x become replaced by integrals over x , y , and z . In other words, they become volume integrals. Finally, the one-dimensional \u03b4 -function must be replaced by just the product of three \u03b4 -functions, one in x , one in y , and the other in z , \u03b4(x\u2212 x \u2032 )\u03b4(y\u2212 y \u2032 )\u03b4(z\u2212 z \u2032 ) . Putting everything together we get the following set of equations for the amplitudes for a particle in three dimensions: \u27e8\u03d5|\u03c8\u27e9=\u222b\u27e8\u03d5|r\u27e9\u27e8r|\u03c8\u27e9dV, \u27e8r|\u03c8\u27e9 \u27e8r|\u03d5\u27e9 =\u03c8(r), =\u03d5(r), \u27e8\u03d5|\u03c8\u27e9=\u222b \u03d5 \u2217 (r)\u03c8(r)dV, \u27e8 r \u2032 |r\u27e9=\u03b4(x\u2212 x \u2032 )\u03b4(y\u2212 y \u2032 )\u03b4(z\u2212 z \u2032 ). (16.45) (16.46) (16.47) (16.48) What happens when there is more than one particle? We will tell you about how to handle two particles and you will easily see what you must do if you want to deal with a larger number. Suppose there are two particles, which we can call particle No. 1 and particle No. 2 . What shall we use for the base states? One perfectly good set can be described by saying that particle 1 is at x 1 and particle 2 is at x 2 , which we can write as | x 1 , x 2 \u27e9 . Notice that describing the position of only one particle does not define a base state. Each base state must define the condition of the entire system. You must not think that each particle moves independently as a wave in three dimensions. Any physical state |\u03c8\u27e9 can be defined by giving all of the amplitudes \u27e8 x 1 , x 2 |\u03c8\u27e9 to find the two particles at x 1 and x 2 . This generalized amplitude is therefore a function of the two sets of coordinates x 1 and x 2 . You see that such a function is not a wave in the sense of an oscillation that moves along in three dimensions. Neither is it generally simply a product of two individual waves, one for each particle. It is, in general, some kind of a wave in the six dimensions defined by x 1 and x 2 . If there are two particles in nature which are interacting, there is no way of describing what happens to one of the particles by trying to write down a wave function for it alone. The famous paradoxes that we considered in earlier chapters\u2014where the measurements made on one particle were claimed to be able to tell what was going to happen to another particle, or were able to destroy an interference\u2014have caused people all sorts of trouble because they have tried to think of the wave function of one particle alone, rather than the correct wave function in the coordinates of both particles. The complete description can be given correctly only in terms of functions of the coordinates of both particles. So far we have just been worrying about how we can describe states which may involve an electron being anywhere at all in space. Now we have to worry about putting into our description the physics of what can happen in various circumstances. As before, we have to worry about how states can change with time. If we have a state |\u03c8\u27e9 which goes over into another state | \u03c8 \u2032 \u27e9 sometime later, we can describe the situation for all times by making the wave function\u2014which is just the amplitude \u27e8r|\u03c8\u27e9 \u2014a function of time as well as a function of the coordinate. A particle in a given situation can then be described by giving a time-varying wave function \u03c8(r,t)=\u03c8(x,y,z,t) . This time-varying wave function describes the evolution of successive states that occur as time develops. This so-called \u201ccoordinate representation\u201d\u2014which gives the projections of the state |\u03c8\u27e9 into the base states |r\u27e9 may not always be the most convenient one to use\u2014but we will consider it first. In Chapter 8 we described how states varied in time in terms of the Hamiltonian H ij . We saw that the time variation of the various amplitudes was given in terms of the matrix equation i\u210f d C i dt = \u2211 j H ij C j . (16.49) This equation says that the time variation of each amplitude C i is proportional to all of the other amplitudes C j , with the coefficients H ij . How would we expect Eq. (16.49) to look when we are using the continuum of base states |x\u27e9 ? Let\u2019s first remember that Eq. (16.49) can also be written as i\u210f d dt \u27e8i|\u03c8\u27e9= \u2211 j \u27e8i| H ^ |j\u27e9\u27e8j|\u03c8\u27e9. d Now it is clear what we should do. For the x -representation we would expect i\u210f \u2202 \u2202t \u27e8x|\u03c8\u27e9=\u222b\u27e8x| H ^ | x \u2032 \u27e9\u27e8 x \u2032 |\u03c8\u27e9d x \u2032 . (16.50) The sum over the base states |j\u27e9 , gets replaced by an integral over x \u2032 . Since \u27e8x| H ^ | x \u2032 \u27e9 should be some function of x and x \u2032 , we can write it as H(x, x \u2032 ) \u2014which corresponds to H ij in Eq. (16.49). Then Eq. (16.50) is the same as i\u210f \u2202 \u2202t \u03c8(x)=\u222bH(x, x \u2032 )\u03c8( x \u2032 )d x \u2032 (16.51) with H(x, x \u2032 )\u2261\u27e8x| H ^ | x \u2032 \u27e9. According to Eq. (16.51), the rate of change of \u03c8 at x would depend on the value of \u03c8 at all other points x \u2032 ; the factor H(x, x \u2032 ) is the amplitude per unit time that the electron will jump from x \u2032 to x . It turns out in nature, however, that this amplitude is zero except for points x \u2032 very close to x . This means\u2014as we saw in the example of the chain of atoms at the beginning of the chapter, Eq. (16.12)\u2014that the right-hand side of Eq. (16.51) can be expressed completely in terms of \u03c8 and the derivatives of \u03c8 with respect to x , all evaluated at the position x . For a particle moving freely in space with no forces, no disturbances, the correct law of physics is \u222bH(x, x \u2032 )\u03c8( x \u2032 )d x \u2032 =\u2212 \u210f 2 2m \u2202 2 \u2202 x 2 \u03c8(x). 2 2 Where did we get that from? Nowhere. It\u2019s not possible to derive it from anything you know. It came out of the mind of Schr\u00f6dinger, invented in his struggle to find an understanding of the experimental observations of the real world. You can perhaps get some clue of why it should be that way by thinking of our derivation of Eq. (16.12) which came from looking at the propagation of an electron in a crystal. Of course, free particles are not very exciting. What happens if we put forces on the particle? Well, if the force of a particle can be described in terms of a scalar potential V(x) \u2014which means we are thinking of electric forces but not magnetic forces\u2014and if we stick to low energies so that we can ignore complexities which come from relativistic motions, then the Hamiltonian which fits the real world gives \u222bH (x, x \u2032 )\u03c8( x \u2032 )d x \u2032 = \u2212 \u210f 2 2m \u2202 2 \u2202 x 2 \u03c8(x)+V(x)\u03c8(x). (16.52) Again, you can get some clue as to the origin of this equation if you go back to the motion of an electron in a crystal, and see how the equations would have to be modified if the energy of the electron varied slowly from one atomic site to the other\u2014as it might do if there were an electric field across the crystal. Then the term E 0 in Eq. (16.7) would vary slowly with position and would correspond to the new term we have added in (16.52). [You may be wondering why we went straight from Eq. (16.51) to Eq. (16.52) instead of just giving you the correct function for the amplitude H(x, x \u2032 )=\u27e8x| H ^ | x \u2032 \u27e9 . We did that because H(x, x \u2032 ) can only be written in terms of strange algebraic functions, although the whole integral on the right-hand side of Eq. (16.51) comes out in terms of things you are used to. If you are really curious, H(x, x \u2032 ) can be written in the following way: H(x, x \u2032 )=\u2212 \u210f 2 2m \u03b4 \u2032\u2032 (x\u2212 x \u2032 )+V(x)\u03b4(x\u2212 x \u2032 ), 2 where \u03b4 \u2032\u2032 means the second derivative of the delta function. This rather strange function can be replaced by a somewhat more convenient algebraic differential operator, which is completely equivalent: H(x, x \u2032 )={\u2212 \u210f 2 2m \u2202 2 \u2202 x 2 +V(x)}\u03b4(x\u2212 x \u2032 ). 2 2 We will not be using these forms, but will work directly with the form in Eq. (16.52).] If we now use the expression we have in (16.52) for the integral in (16.50) we get the following differential equation for \u03c8(x)=\u27e8x|\u03c8\u27e9 : i\u210f \u2202\u03c8 \u2202t =\u2212 \u210f 2 2m \u2202 2 \u2202 x 2 \u03c8(x)+V(x)\u03c8(x). (16.53) It is fairly obvious what we should use instead of Eq. (16.53) if we are interested in motion in three dimensions. The only changes are that \u2202 2 /\u2202 x 2 gets replaced by \u2207 2 = \u2202 2 \u2202 x 2 + \u2202 2 \u2202 y 2 + \u2202 2 \u2202 z 2 , 2 2 2 and V(x) gets replaced by V(x,y,z) . The amplitude \u03c8(x,y,z) for an electron moving in a potential V(x,y,z) obeys the differential equation i\u210f \u2202\u03c8 \u2202t =\u2212 \u210f 2 2m \u2207 2 \u03c8+V\u03c8. (16.54) It is called the Schr\u00f6dinger equation, and was the first quantum-mechanical equation ever known. It was written down by Schr\u00f6dinger before any of the other quantum equations we have described in this book were discovered. Although we have approached the subject along a completely different route, the great historical moment marking the birth of the quantum mechanical description of matter occurred when Schr\u00f6dinger first wrote down his equation in 1926. For many years the internal atomic structure of matter had been a great mystery. No one had been able to understand what held matter together, why there was chemical binding, and especially how it could be that atoms could be stable. Although Bohr had been able to give a description of the internal motion of an electron in a hydrogen atom which seemed to explain the observed spectrum of light emitted by this atom, the reason that electrons moved in this way remained a mystery. Schr\u00f6dinger\u2019s discovery of the proper equations of motion for electrons on an atomic scale provided a theory from which atomic phenomena could be calculated quantitatively, accurately, and in detail. In principle, Schr\u00f6dinger\u2019s equation is capable of explaining all atomic phenomena except those involving magnetism and relativity. It explains the energy levels of an atom, and all the facts of chemical binding. This is, however, true only in principle\u2014the mathematics soon becomes too complicated to solve exactly any but the simplest problems. Only the hydrogen and helium atoms have been calculated to a high accuracy. However, with various approximations, some fairly sloppy, many of the facts of more complicated atoms and of the chemical binding of molecules can be understood. We have shown you some of these approximations in earlier chapters. The Schr\u00f6dinger equation as we have written it does not take into account any magnetic effects. It is possible to take such effects into account in an approximate way by adding some more terms to the equation. However, as we have seen in Volume II, magnetism is essentially a relativistic effect, and so a correct description of the motion of an electron in an arbitrary electromagnetic field can only be discussed in a proper relativistic equation. The correct relativistic equation for the motion of an electron was discovered by Dirac a year after Schr\u00f6dinger brought forth his equation, and takes on quite a different form. We will not be able to discuss it at all here. Before we go on to look at some of the consequences of the Schr\u00f6dinger equation, we would like to show you what it looks like for a system with a large number of particles. We will not be making any use of the equation, but just want to show it to you to emphasize that the wave function \u03c8 is not simply an ordinary wave in space, but is a function of many variables. If there are many particles, the equation becomes i\u210f \u2202\u03c8( r 1 , r 2 , r 3 ,\u2026) \u2202t = \u2211 i \u2212 \u210f 2 2 m i { \u2202 2 \u03c8 \u2202 x 2 i + \u2202 2 \u03c8 \u2202 y 2 i + \u2202 2 \u03c8 \u2202 z 2 i }+V( r 1 , r 2 ,\u2026)\u03c8. (16.55) The potential function V is what corresponds classically to the total potential energy of all the particles. If there are no external forces acting on the particles, the function V is simply the electrostatic energy of interaction of all the particles. That is, if the i th particle carries the charge Z i q e , then the function V is simply3 V( r 1 , r 2 , r 3 ,\u2026)= \u2211 all pairs Z i Z j r ij e 2 . (16.56) In a later chapter we will look in detail at a solution of Schr\u00f6dinger\u2019s equation for a particular example. We would like now, however, to show you how one of the most remarkable consequences of Schr\u00f6dinger\u2019s equation comes about\u2014namely, the surprising fact that a differential equation involving only continuous functions of continuous variables in space can give rise to quantum effects such as the discrete energy levels in an atom. The essential fact to understand is how it can be that an electron which is confined to a certain region of space by some kind of a potential \u201cwell\u201d must necessarily have only one or another of a certain well-defined set of discrete energies. Suppose we think of an electron in a one-dimensional situation in which its potential energy varies with x in a way described by the graph in Fig. 16\u20133. We will assume that this potential is static\u2014it doesn\u2019t vary with time. As we have done so many times before, we would like to look for solutions corresponding to states of definite energy, which means, of definite frequency. Let\u2019s try a solution of the form \u03c8=a(x) e \u2212iEt/\u210f . (16.57) If we substitute this function into the Schr\u00f6dinger equation, we find that the function a(x) must satisfy the following differential equation: d 2 a(x) d x 2 = 2m \u210f 2 [V(x)\u2212E]a(x). (16.58) This equation says that at each x the second derivative of a(x) with respect to x is proportional to a(x) , the coefficient of proportionality being given by the quantity (2m/ \u210f 2 )(V\u2212E) . The second derivative of a(x) is the rate of change of its slope. If the potential V is greater than the energy E of the particle, the rate of change of the slope of a(x) will have the same sign as a(x) . That means that the curve of a(x) will be concave away from the x -axis. That is, it will have, more or less, the character of the positive or negative exponential function, e \u00b1x . This means that in the region to the left of x 1 , in Fig. 16\u20133, where V is greater than the assumed energy E , the function a(x) would have to look like one or another of the curves shown in part (a) of Fig. 16\u20134. If, on the other hand, the potential function V is less than the energy E , the second derivative of a(x) with respect to x has the opposite sign from a(x) itself, and the curve of a(x) will always be concave toward the x -axis like one of the pieces shown in part (b) of Fig. 16\u20134. The solution in such a region has, piece-by-piece, roughly the form of a sinusoidal curve. Now let\u2019s see if we can construct graphically a solution for the function a(x) which corresponds to a particle of energy E a in the potential V shown in Fig. 16\u20133. Since we are trying to describe a situation in which a particle is bound inside the potential well, we want to look for solutions in which the wave amplitude takes on very small values when x is way outside the potential well. We can easily imagine a curve like the one shown in Fig. 16\u20135 which tends toward zero for large negative values of x , and grows smoothly as it approaches x 1 . Since V is equal to E a at x 1 , the curvature of the function becomes zero at this point. Between x 1 and x 2 , the quantity V\u2212 E a is always a negative number, so the function a(x) is always concave toward the axis, and the curvature is larger the larger the difference between E a and V . If we continue the curve into the region between x 1 and x 2 , it should go more or less as shown in Fig. 16\u20135. Now let\u2019s continue this curve into the region to the right of x 2 . There it curves away from the axis and takes off toward large positive values, as drawn in Fig. 16\u20136. For the energy E a we have chosen, the solution for a(x) gets larger and larger with increasing x . In fact, its curvature is also increasing (if the potential continues to stay flat). The amplitude rapidly grows to immense proportions. What does this mean? It simply means that the particle is not \u201cbound\u201d in the potential well. It is infinitely more likely to be found outside of the well, than inside. For the solution we have manufactured, the electron is more likely to be found at x=+\u221e than anywhere else. We have failed to find a solution for a bound particle. Let\u2019s try another energy, say one a little bit higher than E a \u2014say the energy E b in Fig. 16\u20137. If we start with the same conditions on the left, we get the solution drawn in the lower half of Fig. 16\u20137. It looked at first as though it were going to be better, but it ends up just as bad as the solution for E a \u2014except that now a(x) is getting more and more negative as we go toward large values of x . Maybe that\u2019s the clue. Since changing the energy a little bit from E a to E b causes the curve to flip from one side of the axis to the other, perhaps there is some energy lying between E a and E b for which the curve will approach zero for large values of x . There is, indeed, and we have sketched how the solution might look in Fig. 16\u20138. You should appreciate that the solution we have drawn in the figure is a very special one. If we were to raise or lower the energy ever so slightly, the function would go over into curves like one or the other of the two broken-line curves shown in Fig. 16\u20138, and we would not have the proper conditions for a bound particle. We have obtained a result that if a particle is to be bound in a potential well, it can do so only if it has a very definite energy. Does that mean that there is only one energy for a particle bound in a potential well? No. Other energies are possible, but not energies too close to E c . Notice that the wave function we have drawn in Fig. 16\u20138 crosses the axis four times in the region between x 1 and x 2 . If we were to pick an energy quite a bit lower than E c , we could have a solution which crosses the axis only three times, only two times, only once, or not at all. The possible solutions are sketched in Fig. 16\u20139. (There may also be other solutions corresponding to values of the energy higher than the ones shown.) Our conclusion is that if a particle is bound in a potential well, its energy can take on only the certain special values in a discrete energy spectrum. You see how a differential equation can describe the basic fact of quantum physics. We might remark one other thing. If the energy E is above the top of the potential well, then there are no longer any discrete solutions, and any possible energy is permitted. Such solutions correspond to the scattering of free particles by a potential well. We have seen an example of such solutions when we considered the effects of impurity atoms in a crystal."
    },
    {
        "input": "Sound: The Wave Equation",
        "output": "In this chapter we shall discuss the phenomenon of waves. This is a phenomenon which appears in many contexts throughout physics, and therefore our attention should be concentrated on it not only because of the particular example considered here, which is sound, but also because of the much wider application of the ideas in all branches of physics. It was pointed out when we studied the harmonic oscillator that there are not only mechanical examples of oscillating systems but electrical ones as well. Waves are related to oscillating systems, except that wave oscillations appear not only as time-oscillations at one place, but propagate in space as well. We have really already studied waves. When we studied light, in learning about the properties of waves in that subject, we paid particular attention to the interference in space of waves from several sources at different locations and all at the same frequency. There are two important wave phenomena that we have not yet discussed which occur in light, i.e., electromagnetic waves, as well as in any other form of waves. The first of these is the phenomenon of interference in time rather than interference in space. If we have two sources of sound which have slightly different frequencies and if we listen to both at the same time, then sometimes the waves come with the crests together and sometimes with the crest and trough together (see Fig. 47\u20131). The rising and falling of the sound that results is the phenomenon of beats or, in other words, of interference in time. The second phenomenon involves the wave patterns which result when the waves are confined within a given volume and reflect back and forth from walls. These effects could have been discussed, of course, for the case of electromagnetic waves. The reason for not having done this is that by using one example we would not generate the feeling that we are actually learning about many different subjects at the same time. In order to emphasize the general applicability of waves beyond electrodynamics, we consider here a different example, in particular sound waves. Other examples of waves are water waves consisting of long swells that we see coming in to the shore, or the smaller water waves consisting of surface tension ripples. As another example, there are two kinds of elastic waves in solids; a compressional (or longitudinal) wave in which the particles of the solid oscillate back and forth along the direction of propagation of the wave (sound waves in a gas are of this kind), and a transverse wave in which the particles of the solid oscillate in a direction perpendicular to the direction of propagation. Earthquake waves contain elastic waves of both kinds, generated by a motion at some place in the earth\u2019s crust. Still another example of waves is found in modern physics. These are waves which give the probability amplitude of finding a particle at a given place\u2014the \u201cmatter waves\u201d which we have already discussed. Their frequency is proportional to the energy and their wave number is proportional to the momentum. They are the waves of quantum mechanics. In this chapter we shall consider only waves for which the velocity is independent of the wavelength. This is, for example, the case for light in a vacuum. The speed of light is then the same for radiowaves, blue light, green light, or for any other wavelength. Because of this behavior, when we began to describe the wave phenomenon we did not notice at first that we had wave propagation. Instead, we said that if a charge is moved at one place, the electric field at a distance x was proportional to the acceleration, not at the time t , but at the earlier time t\u2212x/c . Therefore if we were to picture the electric field in space at some instant of time, as in Fig. 47\u20132, the electric field at a time t later would have moved the distance ct , as indicated in the figure. Mathematically, we can say that in the one-dimensional example we are taking, the electric field is a function of x\u2212ct . We see that at t=0 , it is some function of x . If we consider a later time, we need only to increase x somewhat to get the same value of the electric field. For example, if the maximum field occurred at x=3 at time zero, then to find the new position of the maximum field at time t we need x\u2212ct=3orx=3+ct. t 3 3 t We see that this kind of function represents the propagation of a wave. Such a function, f(x\u2212ct) , then represents a wave. We may summarize this description of a wave by saying simply that f(x\u2212ct)=f(x+\u0394x\u2212c(t+\u0394t)), f ( ) f ( ( ) ) when \u0394x=c\u0394t . There is, of course, another possibility, i.e., that instead of a source to the left as indicated in Fig. 47\u20132, we have a source on the right, so that the wave propagates toward negative x . Then the wave would be described by g(x+ct) . There is the additional possibility that more than one wave exists in space at the same time, and so the electric field is the sum of the two fields, each one propagating independently. This behavior of electric fields may be described by saying that if f 1 (x\u2212ct) is a wave, and if f 2 (x\u2212ct) is another wave, then their sum is also a wave. This is called the principle of superposition. The same principle is valid in sound. We are familiar with the fact that if a sound is produced, we hear with complete fidelity the same sequence of sounds as was generated. If we had high frequencies travelling faster than low frequencies, a short, sharp noise would be heard as a succession of musical sounds. Similarly, if red light travelled faster than blue light, a flash of white light would be seen first as red, then as white, and finally as blue. We are familiar with the fact that this is not the case. Both sound and light travel with a speed in air which is very nearly independent of frequency. Examples of wave propagation for which this independence is not true will be considered in Chapter 48. In the case of light (electromagnetic waves) we gave a rule which determined the electric field at a point as a result of the acceleration of a charge. One might expect now that what we should do is give a rule whereby some quality of the air, say the pressure, is determined at a given distance from a source in terms of the source motion, delayed by the travel time of the sound. In the case of light this procedure was acceptable because all that we knew was that a charge at one place exerts a force on another charge at another place. The details of propagation from the one place to the other were not absolutely essential. In the case of sound, however, we know that it propagates through the air between the source and the hearer, and it is certainly a natural question to ask what, at any given moment, the pressure of the air is. We would like, in addition, to know exactly how the air moves. In the case of electricity we could accept a rule, since we could say that we do not yet know the laws of electricity, but we cannot make the same remark with regard to sound. We would not be satisfied with a rule stating how the sound pressure moves through the air, because the process ought to be understandable as a consequence of the laws of mechanics. In short, sound is a branch of mechanics, and so it is to be understood in terms of Newton\u2019s laws. The propagation of sound from one place to another is merely a consequence of mechanics and the properties of gases, if it propagates in a gas, or of the properties of liquids or solids, if it propagates through such mediums. Later we shall derive the properties of light and its wave propagation in a similar way from the laws of electrodynamics. We shall give a derivation of the properties of the propagation of sound between the source and the receiver as a consequence of Newton\u2019s laws, and we shall not consider the interaction with the source and the receiver. Ordinarily we emphasize a result rather than a particular derivation of it. In this chapter we take the opposite view. The point here, in a certain sense, is the derivation itself. This problem of explaining new phenomena in terms of old ones, when we know the laws of the old ones, is perhaps the greatest art of mathematical physics. The mathematical physicist has two problems: one is to find solutions, given the equations, and the other is to find the equations which describe a new phenomenon. The derivation here is an example of the second kind of problem. We shall take the simplest example here\u2014the propagation of sound in one dimension. To carry out such a derivation it is necessary first to have some kind of understanding of what is going on. Fundamentally what is involved is that if an object is moved at one place in the air, we observe that there is a disturbance which travels through the air. If we ask what kind of disturbance, we would say that we would expect that the motion of the object produces a change of pressure. Of course, if the object is moved gently, the air merely flows around it, but what we are concerned with is a rapid motion, so that there is not sufficient time for such a flow. Then, with the motion, the air is compressed and a change of pressure is produced which pushes on additional air. This air is in turn compressed, which leads again to an extra pressure, and a wave is propagated. We now want to formulate such a process. We have to decide what variables we need. In our particular problem we would need to know how much the air has moved, so that the air displacement in the sound wave is certainly one relevant variable. In addition we would like to describe how the air density changes as it is displaced. The air pressure also changes, so this is another variable of interest. Then, of course, the air has a velocity, so that we shall have to describe the velocity of the air particles. The air particles also have accelerations\u2014but as we list these many variables we soon realize that the velocity and acceleration would be known if we knew how the air displacement varies with time. As we said, we shall consider the wave in one dimension. We can do this if we are sufficiently far from the source that what we call the wavefronts are very nearly planes. We thus make our argument simpler by taking the least complicated example. We shall then be able to say that the displacement, \u03c7 , depends only on x and t , and not on y and z . Therefore the description of the air is given by \u03c7(x,t) . Is this description complete? It would appear to be far from complete, for we know none of the details of how the air molecules are moving. They are moving in all directions, and this state of affairs is certainly not described by means of this function \u03c7(x,t) . From the point of view of kinetic theory, if we have a higher density of molecules at one place and a lower density adjacent to that place, the molecules would move away from the region of higher density to the one of lower density, so as to equalize this difference. Apparently we would not get an oscillation and there would be no sound. What is necessary to get the sound wave is this situation: as the molecules rush out of the region of higher density and higher pressure, they give momentum to the molecules in the adjacent region of lower density. For sound to be generated, the regions over which the density and pressure change must be much larger than the distance the molecules travel before colliding with other molecules. This distance is the mean free path and the distance between pressure crests and troughs must be much larger than this. Otherwise the molecules would move freely from the crest to the trough and immediately smear out the wave. It is clear that we are going to describe the gas behavior on a scale large compared with the mean free path, and so the properties of the gas will not be described in terms of the individual molecules. The displacement, for example, will be the displacement of the center of mass of a small element of the gas, and the pressure or density will be the pressure or density in this region. We shall call the pressure P and the density \u03c1 , and they will be functions of x and t . We must keep in mind that this description is an approximation which is valid only when these gas properties do not vary too rapidly with distance. The physics of the phenomenon of sound waves thus involves three features: The gas moves and changes the density. The change in density corresponds to a change in pressure. Pressure inequalities generate gas motion. Let us consider II first. For a gas, a liquid, or a solid, the pressure is some function of the density. Before the sound wave arrives, we have equilibrium, with a pressure P 0 and a corresponding density \u03c1 0 . A pressure P in the medium is connected to the density by some characteristic relation P=f(\u03c1) and, in particular, the equilibrium pressure P 0 is given by P 0 =f( \u03c1 0 ) . The changes of pressure in sound from the equilibrium value are extremely small. A convenient unit for measuring pressure is the bar, where 1 bar = 10 5 N/m\u00b2. The pressure of 1 standard atmosphere is very nearly 1 bar: 1 atm =1.0133 bars. In sound we use a logarithmic scale of intensities since the sensitivity of the ear is roughly logarithmic. This scale is the decibel scale, in which the acoustic pressure level for the pressure amplitude P is defined as I( acoustic pressure level )=20 log 10 (P/ P ref ) in dB, (47.1) where the reference pressure P ref =2\u00d7 10 \u221210 bar. A pressure amplitude of P= 10 3 P ref = 2\u00d7 10 \u22127 bar1 corresponds to a moderately intense sound of 60 decibels. We see that the pressure changes in sound are extremely small compared with the equilibrium, or mean, pressure of 1 atm. The displacements and the density changes are correspondingly extremely small. In explosions we do not have such small changes; the excess pressures produced can be greater than 1 atm. These large pressure changes lead to new effects which we shall consider later. In sound we do not often consider acoustic intensity levels over 100 dB; 120 dB is a level which is painful to the ear. Therefore, for sound, if we write P= P 0 + P e ,\u03c1= \u03c1 0 + \u03c1 e , (47.2) we shall always have the pressure change P e very small compared with P 0 and the density change \u03c1 e very small compared with \u03c1 0 . Then P 0 + P e =f( \u03c1 0 + \u03c1 e )=f( \u03c1 0 )+ \u03c1 e f \u2032 ( \u03c1 0 ), (47.3) where P 0 =f( \u03c1 0 ) and f \u2032 ( \u03c1 0 ) stands for the derivative of f(\u03c1) evaluated at \u03c1= \u03c1 0 . We can take the second step in this equality only because \u03c1 e is very small. We find in this way that the excess pressure P e is proportional to the excess density \u03c1 e , and we may call the proportionality factor \u03ba : P e =\u03ba \u03c1 e ,where \u03ba= f \u2032 ( \u03c1 0 )=(dP/d\u03c1 ) 0 .(II) (47.4) The relation we needed for II is this very simple one. Let us now consider I. We shall suppose that the position of a portion of air undisturbed by the sound wave is x and the displacement at the time t due to the sound is \u03c7(x,t) , so that its new position is x+\u03c7(x,t) , as in Fig. 47\u20133. Now the undisturbed position of a nearby portion of air is x+\u0394x , and its new position is x+\u0394x+\u03c7(x+\u0394x,t) . We can now find the density changes in the following way. Since we are limiting ourselves to plane waves, we can take a unit area perpendicular to the x -direction, which is the direction of propagation of the sound wave. The amount of air, per unit area, in \u0394x is then \u03c1 0 \u0394x , where \u03c1 0 is the undisturbed, or equilibrium, air density. This air, when displaced by the sound wave, now lies between x+\u03c7(x,t) and x+\u0394x+\u03c7(x+\u0394x,t) , so that we have the same matter in this interval that was in \u0394x when undisturbed. If \u03c1 is the new density, then \u03c1 0 \u0394x= \u03c1[x+\u0394x+\u03c7(x+\u0394x,t)\u2212x\u2212\u03c7(x,t)]. (47.5) Since \u0394x is small, we can write \u03c7(x+\u0394x,t)\u2212\u03c7(x,t)=(\u2202\u03c7/\u2202x)\u0394x . This derivative is a partial derivative, since \u03c7 depends on the time as well as on x . Our equation then is \u03c1 0 \u0394x=\u03c1( \u2202\u03c7 \u2202x \u0394x+\u0394x) (47.6) or \u03c1 0 =( \u03c1 0 + \u03c1 e ) \u2202\u03c7 \u2202x + \u03c1 0 + \u03c1 e . (47.7) Now in sound waves all changes are small so that \u03c1 e is small, \u03c7 is small, and \u2202\u03c7/\u2202x is also small. Therefore in the relation that we have just found, \u03c1 e =\u2212 \u03c1 0 \u2202\u03c7 \u2202x \u2212 \u03c1 e \u2202\u03c7 \u2202x , (47.8) we can neglect \u03c1 e \u2202\u03c7/\u2202x compared with \u03c1 0 \u2202\u03c7/\u2202x . Thus we get the relation we needed for I: \u03c1 e =\u2212 \u03c1 0 \u2202\u03c7 \u2202x .(I) (47.9) This equation is what we would expect physically. If the displacements vary with x , then there will be density changes. The sign is also right: if the displacement \u03c7 increases with x , so that the air is stretched out, the density must go down. We now need the third equation, which is the equation of the motion produced by the pressure. If we know the relation between the force and the pressure, we can then get the equation of motion. If we take a thin slab of air of length \u0394x and of unit area perpendicular to x , then the mass of air in this slab is \u03c1 0 \u0394x and it has the acceleration \u2202 2 \u03c7/\u2202 t 2 , so the mass times the acceleration for this slab of matter is \u03c1 0 \u0394x( \u2202 2 \u03c7/\u2202 t 2 ) . (It makes no difference for small \u0394x whether the acceleration \u2202 2 \u03c7/\u2202 t 2 is evaluated at an edge of the slab or at some intermediate position.) If now we find the force on this matter for a unit area perpendicular to x , it will then be equal to \u03c1 0 \u0394x( \u2202 2 \u03c7/\u2202 t 2 ) . We have the force in the +x -direction, at x , of amount P(x,t) per unit area, and we have the force in the opposite direction, at x+\u0394x , of amount P(x+\u0394x,t) per unit area (Fig. 47\u20134): P(x,t)\u2212P(x+\u0394x,t) =\u2212 \u2202P \u2202x \u0394x =\u2212 \u2202 P e \u2202x \u0394x, (47.10) since \u0394x is small and since the only part of P which changes is the excess pressure P e . We now have III: \u03c1 0 \u2202 2 \u03c7 \u2202 t 2 =\u2212 \u2202 P e \u2202x ,(III) (47.11) and so we have enough equations to interconnect things and reduce down to one variable, say to \u03c7 . We can eliminate P e from III by using II, so that we get \u03c1 0 \u2202 2 \u03c7 \u2202 t 2 =\u2212\u03ba \u2202 \u03c1 e \u2202x , (47.12) and then we can use I to eliminate \u03c1 e . In this way we find that \u03c1 0 cancels out and that we are left with \u2202 2 \u03c7 \u2202 t 2 =\u03ba \u2202 2 \u03c7 \u2202 x 2 . (47.13) We shall call c 2 s =\u03ba , so that we can write \u2202 2 \u03c7 \u2202 x 2 = 1 c 2 s \u2202 2 \u03c7 \u2202 t 2 . (47.14) This is the wave equation which describes the behavior of sound in matter. We now can see whether this equation really does describe the essential properties of sound waves in matter. We want to deduce that a sound pulse, or disturbance, will move with a constant speed. We want to verify that two different pulses can move through each other\u2014the principle of superposition. We also want to verify that sound can go either to the right or to the left. All these properties should be contained in this one equation. We have remarked that any plane-wave disturbance which moves with a constant velocity v has the form f(x\u2212vt) . Now we have to see whether \u03c7(x,t)=f(x\u2212vt) is a solution of the wave equation. When we calculate \u2202\u03c7/\u2202x , we get the derivative of the function, \u2202\u03c7/\u2202x= f \u2032 (x\u2212vt) . Differentiating once more, we find \u2202 2 \u03c7 \u2202 x 2 = f \u2032\u2032 (x\u2212vt). (47.15) The differentiation of this same function with respect to t gives \u2212v times the derivative of the function, or \u2202\u03c7/\u2202t=\u2212v f \u2032 (x\u2212vt) , and the second time derivative is \u2202 2 \u03c7 \u2202 t 2 = v 2 f \u2032\u2032 (x\u2212vt). (47.16) It is evident that f(x\u2212vt) will satisfy the wave equation provided the wave velocity v is equal to c s . We find, therefore, from the laws of mechanics that any sound disturbance propagates with the velocity c s , and in addition we find that c s = \u03ba 1/2 =(dP/d\u03c1 ) 1/2 0 , 1 / 2 and so we have related the wave velocity to a property of the medium. If we consider a wave travelling in the opposite direction, so that \u03c7(x,t)=g(x+vt) , it is easy to see that such a disturbance also satisfies the wave equation. The only difference between such a wave and one travelling from left to right is in the sign of v , but whether we have x+vt or x\u2212vt as the variable in the function does not affect the sign of \u2202 2 \u03c7/\u2202 t 2 , since it involves only v 2 . It follows that we have a solution for waves propagating in either direction with speed c s . An extremely interesting question is that of superposition. Suppose one solution of the wave equation has been found, say \u03c7 1 . This means that the second derivative of \u03c7 1 with respect to x is equal to 1/ c 2 s times the second derivative of \u03c7 1 with respect to t . Now any other solution \u03c7 2 has this same property. If we superpose these two solutions, we have \u03c7(x,t)= \u03c7 1 (x,t)+ \u03c7 2 (x,t), (47.17) and we wish to verify that \u03c7(x,t) is also a wave, i.e., that \u03c7 satisfies the wave equation. We can easily prove this result, since we have \u2202 2 \u03c7 \u2202 x 2 = \u2202 2 \u03c7 1 \u2202 x 2 + \u2202 2 \u03c7 2 \u2202 x 2 (47.18) and, in addition, \u2202 2 \u03c7 \u2202 t 2 = \u2202 2 \u03c7 1 \u2202 t 2 + \u2202 2 \u03c7 2 \u2202 t 2 . (47.19) It follows that \u2202 2 \u03c7/\u2202 x 2 =(1/ c 2 s ) \u2202 2 \u03c7/\u2202 t 2 , so we have verified the principle of superposition. The proof of the principle of superposition follows from the fact that the wave equation is linear in \u03c7 . We can now expect that a plane light wave propagating in the x -direction, polarized so that the electric field is in the y -direction, will satisfy the wave equation \u2202 2 E y \u2202 x 2 = 1 c 2 \u2202 2 E y \u2202 t 2 , (47.20) where c is the speed of light. This wave equation is one of the consequences of Maxwell\u2019s equations. The equations of electrodynamics will lead to the wave equation for light just as the equations of mechanics lead to the wave equation for sound. Our deduction of the wave equation for sound has given us a formula which connects the wave speed with the rate of change of pressure with the density at the normal pressure: c 2 s =( dP d\u03c1 ) 0 . (47.21) In evaluating this rate of change, it is essential to know how the temperature varies. In a sound wave, we would expect that in the region of compression the temperature would be raised, and that in the region of rarefaction the temperature would be lowered. Newton was the first to calculate the rate of change of pressure with density, and he supposed that the temperature remained unchanged. He argued that the heat was conducted from one region to the other so rapidly that the temperature could not rise or fall. This argument gives the isothermal speed of sound, and it is wrong. The correct deduction was given later by Laplace, who put forward the opposite idea\u2014that the pressure and temperature change adiabatically in a sound wave. The heat flow from the compressed region to the rarefied region is negligible so long as the wavelength is long compared with the mean free path. Under this condition the slight amount of heat flow in a sound wave does not affect the speed, although it gives a small absorption of the sound energy. We can expect correctly that this absorption increases as the wavelength approaches the mean free path, but these wavelengths are smaller by factors of about a million than the wavelengths of audible sound. The actual variation of pressure with density in a sound wave is the one that allows no heat flow. This corresponds to the adiabatic variation, which we found to be P V \u03b3 =const , where V was the volume. Since the density \u03c1 varies inversely with V , the adiabatic connection between P and \u03c1 is P=const \u03c1 \u03b3 , (47.22) from which we get dP/d\u03c1=\u03b3P/\u03c1 . We then have for the speed of sound the relation c 2 s = \u03b3P \u03c1 . (47.23) We can also write c 2 s =\u03b3PV/\u03c1V and make use of the relation PV=NkT . Further, we see that \u03c1V is the mass of gas, which can also be expressed as Nm , or as \u03bc per mole, where m is the mass of a molecule and \u03bc is the molecular weight. In this way we find that c 2 s = \u03b3kT m = \u03b3RT \u03bc , (47.24) from which it is evident that the speed of sound depends only on the gas temperature and not on the pressure or the density. We also have observed that kT= 1 3 m\u27e8 v 2 \u27e9, (47.25) where \u27e8 v 2 \u27e9 is the mean square of the speed of the molecules. It follows that c 2 s =(\u03b3/3)\u27e8 v 2 \u27e9 , or c s =( \u03b3 3 ) 1/2 v av . (47.26) This equation states that the speed of sound is some number which is roughly 1/(3 ) 1/2 times some average speed, v av , of the molecules (the square root of the mean square velocity). In other words, the speed of sound is of the same order of magnitude as the speed of the molecules, and is actually somewhat less than this average speed. Of course we could expect such a result, because a disturbance like a change in pressure is, after all, propagated by the motion of the molecules. However, such an argument does not tell us the precise propagation speed; it could have turned out that sound was carried primarily by the fastest molecules, or by the slowest molecules. It is reasonable and satisfying that the speed of sound is roughly 1 2 of the average molecular speed v av ."
    },
    {
        "input": "The Motion of Charges in Electric and Magnetic Fields",
        "output": "We want now to describe\u2014mainly in a qualitative way\u2014the motions of charges in various circumstances. Most of the interesting phenomena in which charges are moving in fields occur in very complicated situations, with many, many charges all interacting with each other. For instance, when an electromagnetic wave goes through a block of material or a plasma, billions and billions of charges are interacting with the wave and with each other. We will come to such problems later, but now we just want to discuss the much simpler problem of the motions of a single charge in a given field. We can then disregard all other charges\u2014except, of course, those charges and currents which exist somewhere to produce the fields we will assume. We should probably ask first about the motion of a particle in a uniform electric field. At low velocities, the motion is not particularly interesting\u2014it is just a uniform acceleration in the direction of the field. However, if the particle picks up enough energy to become relativistic, then the motion gets more complicated. But we will leave the solution for that case for you to play with. Next, we consider the motion in a uniform magnetic field with zero electric field. We have already solved this problem\u2014one solution is that the particle goes in a circle. The magnetic force qv\u00d7B is always at right angles to the motion, so dp/dt is perpendicular to p and has the magnitude vp/R , where R is the radius of the circle: F=qvB= vp R . The radius of the circular orbit is then R= p qB . (29.1) That is only one possibility. If the particle has a component of its motion along the field direction, that motion is constant, since there can be no component of the magnetic force in the direction of the field. The general motion of a particle in a uniform magnetic field is a constant velocity parallel to B and a circular motion at right angles to B \u2014the trajectory is a cylindrical helix (Fig. 29\u20131). The radius of the helix is given by Eq. (29.1) if we replace p by p \u22a5 , the component of momentum at right angles to the field. A uniform magnetic field is often used in making a \u201cmomentum analyzer,\u201d or \u201cmomentum spectrometer,\u201d for high-energy charged particles. Suppose that charged particles are shot into a uniform magnetic field at the point A in Fig. 29\u20132(a), the magnetic field being perpendicular to the plane of the drawing. Each particle will go into an orbit which is a circle whose radius is proportional to its momentum. If all the particles enter perpendicular to the edge of the field, they will leave the field at a distance x (from A ) which is proportional to their momentum p . A counter placed at some point such as C will detect only those particles whose momentum is in an interval \u0394p near the momentum p=qBx/2 . It is, of course, not necessary that the particles go through 180 \u2218 before they are counted, but the so-called \u201c 180 \u2218 spectrometer\u201d has a special property. It is not necessary that all the particles enter at right angles to the field edge. Figure 29\u20132(b) shows the trajectories of three particles, all with the same momentum but entering the field at different angles. You see that they take different trajectories, but all leave the field very close to the point C . We say that there is a \u201cfocus.\u201d Such a focusing property has the advantage that larger angles can be accepted at A \u2014although some limit is usually imposed, as shown in the figure. A larger angular acceptance usually means that more particles are counted in a given time, decreasing the time required for a given measurement. By varying the magnetic field, or moving the counter along in x , or by using many counters to cover a range of x , the \u201cspectrum\u201d of momenta in the incoming beam can be measured. [By the \u201cmomentum spectrum\u201d f(p) , we mean that the number of particles with momenta between p and (p+dp) is f(p)dp .] Such measurements have been made, for example, to determine the distribution of energies in the \u03b2 -decay of various nuclei. There are many other forms of momentum spectrometers, but we will describe just one more, which has an especially large solid angle of acceptance. It is based on the helical orbits in a uniform field, like the one shown in Fig. 29\u20131. Let\u2019s think of a cylindrical coordinate system\u2014 \u03c1,\u03b8,z \u2014set up with the z -axis along the direction of the field. If a particle is emitted from the origin at some angle \u03b1 with respect to the z -axis, it will move along a spiral whose equation is \u03c1=asinkz,\u03b8=bz, sin k \u03b8 b where a , b , and k are parameters you can easily work out in terms of p , \u03b1 , and the magnetic field B . If we plot the distance \u03c1 from the axis as a function of z for a given momentum, but for several starting angles, we will get curves like the solid ones drawn in Fig. 29\u20133. (Remember that this is just a kind of projection of a helical trajectory.) When the angle between the axis and the starting direction is larger, the peak value of \u03c1 is large but the longitudinal velocity is less, so the trajectories for different angles tend to come to a kind of \u201cfocus\u201d near the point A in the figure. If we put a narrow aperture of A , particles with a range of initial angles can still get through and pass on to the axis, where they can be counted by the long detector D . Particles which leave the source at the origin with a higher momentum but at the same angles, follow the paths shown by the broken lines and do not get through the aperture at A . So the apparatus selects a small interval of momenta. The advantage over the first spectrometer described is that the aperture A \u2014and the aperture A \u2032 \u2014can be an annulus, so that particles which leave the source in a rather large solid angle are accepted. A large fraction of the particles from the source are used\u2014an important advantage for weak sources or for very precise measurements. One pays a price for this advantage, however, because a large volume of uniform magnetic field is required, and this is usually only practical for low-energy particles. One way of making a uniform field, you remember, is to wind a coil on a sphere, with a surface current density proportional to the sine of the angle. You can also show that the same thing is true for an ellipsoid of rotation. So such spectrometers are often made by winding an elliptical coil on a wooden (or aluminum) frame. All that is required is that the current in each interval of axial distance \u0394x be the same, as shown in Fig. 29\u20134. Particle focusing has many applications. For instance, the electrons that leave the cathode in a TV picture tube are brought to a focus at the screen\u2014to make a fine spot. In this case, one wants to take electrons all of the same energy but with different initial angles and bring them together in a small spot. The problem is like focusing light with a lens, and devices which do the corresponding job for particles are also called lenses. One example of an electron lens is sketched in Fig. 29\u20135. It is an \u201celectrostatic\u201d lens whose operation depends on the electric field between two adjacent electrodes. Its operation can be understood by considering what happens to a parallel beam that enters from the left. When the electrons arrive at the region a , they feel a force with a sidewise component and get a certain impulse that bends them toward the axis. You might think that they would get an equal and opposite impulse in the region b , but that is not so. By the time the electrons reach b they have gained energy and so spend less time in the region b . The forces are the same, but the time is shorter, so the impulse is less. In going through the regions a and b , there is a net axial impulse, and the electrons are bent toward a common point. In leaving the high-voltage region, the particles get another kick toward the axis. The force is outward in region c and inward in region d , but the particles stay longer in the latter region, so there is again a net impulse. For distances not too far from the axis, the total impulse through the lens is proportional to the distance from the axis (Can you see why?), and this is just the condition necessary for lens-type focusing. You can use the same arguments to show that there is focusing if the potential of the middle electrode is either positive or negative with respect to the other two. Electrostatic lenses of this type are commonly used in cathode-ray tubes and in some electron microscopes. Another kind of lens\u2014often found in electron microscopes\u2014is the magnetic lens sketched schematically in Fig. 29\u20136. A cylindrically symmetric electromagnet has very sharp circular pole tips which produce a strong, nonuniform field in a small region. Electrons which travel vertically through this region are focused. You can understand the mechanism by looking at the magnified view of the pole-tip region drawn in Fig. 29\u20137. Consider two electrons a and b that leave the source S at some angle with respect to the axis. As electron a reaches the beginning of the field, it is deflected away from you by the horizontal component of the field. But then it will have a lateral velocity, so that when it passes through the strong vertical field, it will get an impulse toward the axis. Its lateral motion is taken out by the magnetic force as it leaves the field, so the net effect is an impulse toward the axis, plus a \u201crotation\u201d about the axis. All the forces on particle b are opposite, so it also is deflected toward the axis. In the figure, the divergent electrons are brought into parallel paths. The action is like a lens with an object at the focal point. Another similar lens upstream can be used to focus the electrons back to a single point, making an image of the source S . You know that electron microscopes can \u201csee\u201d objects too small to be seen by optical microscopes. We discussed in Chapter 30 of Vol. I the basic limitations of any optical system due to diffraction of the lens opening. If a lens opening subtends the angle 2\u03b8 from a source (see Fig. 29\u20138), two neighboring spots at the source cannot be seen as separate if they are closer than about \u03b4\u2248 \u03bb sin\u03b8 , \u03bb where \u03bb is the wavelength of the light. With the best optical microscope, \u03b8 approaches the theoretical limit of 90 \u2218 , so \u03b4 is about equal to \u03bb , or approximately 5000 angstroms. The same limitation would also apply to an electron microscope, but there the wavelength is\u2014for 50 -kilovolt electrons\u2014about 0.05 angstrom. If one could use a lens opening of near 30 \u2218 , it would be possible to see objects only 1 5 of an angstrom apart. Since the atoms in molecules are typically 1 or 2 angstroms apart, we could get photographs of molecules. Biology would be easy; we would have a photograph of the DNA structure. What a tremendous thing that would be! Most of present-day research in molecular biology is an attempt to figure out the shapes of complex organic molecules. If we could only see them! Unfortunately, the best resolving power that has been achieved in an electron microscope is more like 20 angstroms. The reason is that no one has yet designed a lens with a large opening. All lenses have \u201cspherical aberration,\u201d which means that rays at large angles from the axis have a different point of focus than the rays nearer the axis, as shown in Fig. 29\u20139. By special techniques, optical microscope lenses can be made with a negligible spherical aberration, but no one has yet been able to make an electron lens which avoids spherical aberration. In fact, one can show that any electrostatic or magnetic lens of the types we have described must have an irreducible amount of spherical aberration. This aberration\u2014together with diffraction\u2014limits the resolving power of electron microscopes to their present value. The limitation we have mentioned does not apply to electric and magnetic fields which are not axially symmetric or which are not constant in time. Perhaps some day someone will think of a new kind of electron lens that will overcome the inherent aberration of the simple electron lens. Then we will be able to photograph atoms directly. Perhaps one day chemical compounds will be analyzed by looking at the positions of the atoms rather than by looking at the color of some precipitate! Magnetic fields are also used to produce special particle trajectories in high energy particle accelerators. Machines like the cyclotron and synchrotron bring particles to high energies by passing the particles repeatedly through a strong electric field. The particles are held in their cyclic orbits by a magnetic field. We have seen that a particle in a uniform magnetic field will go in a circular orbit. This, however, is true only for a perfectly uniform field. Imagine a field B which is nearly uniform over a large area but which is slightly stronger in one region than in another. If we put a particle of momentum p in this field, it will go in a nearly circular orbit with the radius R=p/qB . The radius of curvature will, however, be slightly smaller in the region where the field is stronger. The orbit is not a closed circle but will \u201cwalk\u201d through the field, as shown in Fig. 29\u201310. We can, if we wish, consider that the slight \u201cerror\u201d in the field produces an extra angular kick which sends the particle off on a new track. If the particles are to make millions of revolutions in an accelerator, some kind of \u201cradial focusing\u201d is needed which will tend to keep the trajectories close to some design orbit. Another difficulty with a uniform field is that the particles do not remain in a plane. If they start out with the slightest angle\u2014or are given a slight angle by any small error in the field\u2014they will go in a helical path that will eventually take them into the magnet pole or the ceiling or floor of the vacuum tank. Some arrangement must be made to inhibit such vertical drifts; the field must provide \u201cvertical focusing\u201d as well as radial focusing. One would, at first, guess that radial focusing could be provided by making a magnetic field which increases with increasing distance from the center of the design path. Then if a particle goes out to a large radius, it will be in a stronger field which will bend it back toward the correct radius. If it goes to too small a radius, the bending will be less, and it will be returned toward the design radius. If a particle is once started at some angle with respect to the ideal circle, it will oscillate about the ideal circular orbit, as shown in Fig. 29\u201311. The radial focusing would keep the particles near the circular path. Actually there is still some radial focusing even with the opposite field slope. This can happen if the radius of curvature of the trajectory does not increase more rapidly than the increase in the distance of the particle from the center of the field. The particle orbits will be as drawn in Fig. 29\u201312. If the gradient of the field is too large, however, the orbits will not return to the design radius but will spiral inward or outward, as shown in Fig. 29\u201313. We usually describe the slope of the field in terms of the \u201crelative gradient\u201d or field index, n : n= dB/B dr/r . (29.2) A guide field gives radial focusing if this relative gradient is greater than \u22121 . A radial field gradient will also produce vertical forces on the particles. Suppose we have a field that is stronger nearer to the center of the orbit and weaker at the outside. A vertical cross section of the magnet at right angles to the orbit might be as shown in Fig. 29\u201314. (For protons the orbits would be coming out of the page.) If the field is to be stronger to the left and weaker to the right, the lines of the magnetic field must be curved as shown. We can see that this must be so by using the law that the circulation of B is zero in free space. If we take coordinates as shown in the figure, then (\u2207\u00d7B ) y = \u2202 B x \u2202z \u2212 \u2202 B z \u2202x =0, \u2202 B \u2202 B or \u2202 B x \u2202z = \u2202 B z \u2202x . (29.3) Since we assume that \u2202 B z /\u2202x is negative, there must be an equal negative \u2202 B x /\u2202z . If the \u201cnominal\u201d plane of the orbit is a plane of symmetry where B x =0 , then the radial component B x will be negative above the plane and positive below. The lines must be curved as shown. Such a field will have vertical focusing properties. Imagine a proton that is travelling more or less parallel to the central orbit but above it. The horizontal component of B will exert a downward force on it. If the proton is below the central orbit, the force is reversed. So there is an effective \u201crestoring force\u201d toward the central orbit. From our arguments there will be vertical focusing, provided that the vertical field decreases with increasing radius; but if the field gradient is positive, there will be \u201cvertical defocusing.\u201d So for vertical focusing, the field index n must be less than zero. We found above that for radial focusing n had to be greater than \u22121 . The two conditions together give the condition that \u22121<n<0 1 0 if the particles are to be kept in stable orbits. In cyclotrons, values very near zero are used; in betatrons and synchrotrons, the value n=\u22120.6 is typically used. Such small values of n give rather \u201cweak\u201d focusing. It is clear that much more effective radial focusing would be given by a large positive gradient ( n\u226b1 ), but then the vertical forces would be strongly defocusing. Similarly, large negative slopes ( n\u226a\u22121 ) would give stronger vertical forces but would cause radial defocusing. It was realized about 10 years ago, however, that a force that alternates between strong focusing and strong defocusing can still have a net focusing force. To explain how alternating-gradient focusing works, we will first describe the operation of a quadrupole lens, which is based on the same principle. Imagine that a uniform negative magnetic field is added to the field of Fig. 29\u201314, with the strength adjusted to make zero field at the orbit. The resulting field\u2014for small displacements from the neutral point\u2014would be like the field shown in Fig. 29\u201315. Such a four-pole magnet is called a \u201cquadrupole lens.\u201d A positive particle that enters (from the reader) to the right or left of the center is pushed back toward the center. If the particle enters above or below, it is pushed away from the center. This is a horizontal focusing lens. If the horizontal gradient is reversed\u2014as can be done by reversing all the polarities\u2014the signs of all the forces are reversed and we have a vertical focusing lens, as in Fig. 29\u201316. For such lenses, the field strength\u2014and therefore the focusing forces\u2014increase linearly with the distance of the lens from the axis. Now imagine that two such lenses are placed in series. If a particle enters with some horizontal displacement from the axis, as shown in Fig. 29\u201317(a), it will be deflected toward the axis in the first lens. When it arrives at the second lens it is closer to the axis, so the force outward is less and the outward deflection is less. There is a net bending toward the axis; the average effect is horizontally focusing. On the other hand, if we look at a particle which enters off the axis in the vertical direction, the path will be as shown in Fig. 29\u201317(b). The particle is first deflected away from the axis, but then it arrives at the second lens with a larger displacement, feels a stronger force, and so is bent toward the axis. Again the net effect is focusing. Thus a pair of quadrupole lenses acts independently for horizontal and vertical motion\u2014very much like an optical lens. Quadrupole lenses are used to form and control beams of particles in much the same way that optical lenses are used for light beams. We should point out that an alternating-gradient system does not always produce focusing. If the gradients are too large (in relation to the particle momentum or to the spacing between the lenses), the net effect can be a defocusing one. You can see how that could happen if you imagine that the spacing between the two lenses of Fig. 29\u201317 were increased, say, by a factor of three or four. Let\u2019s return now to the synchrotron guide magnet. We can consider that it consists of an alternating sequence of \u201cpositive\u201d and \u201cnegative\u201d lenses with a superimposed uniform field. The uniform field serves to bend the particles, on the average, in a horizontal circle (with no effect on the vertical motion), and the alternating lenses act on any particles that might tend to go astray\u2014pushing them always toward the central orbit (on the average). There is a nice mechanical analog which demonstrates that a force which alternates between a \u201cfocusing\u201d force and a \u201cdefocusing\u201d force can have a net \u201cfocusing\u201d effect. Imagine a mechanical \u201cpendulum\u201d which consists of a solid rod with a weight on the end, suspended from a pivot which is arranged to be moved rapidly up and down by a motor driven crank. Such a pendulum has two equilibrium positions. Besides the normal, downward-hanging position, the pendulum is also in equilibrium \u201changing upward\u201d\u2014with its \u201cbob\u201d above the pivot! Such a pendulum is drawn in Fig. 29\u201318. By the following argument you can see that the vertical pivot motion is equivalent to an alternating focusing force. When the pivot is accelerated downward, the \u201cbob\u201d tends to move inward, as indicated in Fig. 29\u201319. When the pivot is accelerated upward, the effect is reversed. The force restoring the \u201cbob\u201d toward the axis alternates, but the average effect is a force toward the axis. So the pendulum will swing back and forth about a neutral position which is just opposite the normal one. There is, of course, a much easier way of keeping a pendulum upside down, and that is by balancing it on your finger! But try to balance two independent sticks on the same finger! Or one stick with your eyes closed! Balancing involves making a correction for what is going wrong. And this is not possible, in general, if there are several things going wrong at once. In a synchrotron there are billions of particles going around together, each one of which may start out with a different \u201cerror.\u201d The kind of focusing we have been describing works on them all. So far we have talked about particles in electric fields only or in magnetic fields only. There are some interesting effects when there are both kinds of fields at the same time. Suppose we have a uniform magnetic field B and an electric field E at right angles. Particles that start out perpendicular to B will move in a curve like the one in Fig. 29\u201320. (The figure is a plane curve, not a helix!) We can understand this motion qualitatively. When the particle (assumed positive) moves in the direction of E , it picks up speed, and so it is bent less by the magnetic field. When it is going against the E -field, it loses speed and is continually bent more by the magnetic field. The net effect is that it has an average \u201cdrift\u201d in the direction of E\u00d7B . We can, in fact, show that the motion is a uniform circular motion superimposed on a uniform sidewise motion at the speed v d =E/B \u2014the trajectory in Fig. 29\u201320 is a cycloid. Imagine an observer who is moving to the right at a constant speed. In his frame our magnetic field gets transformed to a new magnetic field plus an electric field in the downward direction. If he has just the right speed, his total electric field will be zero, and he will see the electron going in a circle. So the motion we see is a circular motion, plus a translation at the drift speed v d =E/B . The motion of electrons in crossed electric and magnetic fields is the basis of the magnetron tubes, i.e., oscillators used for generating microwave energy. There are many other interesting examples of particle motions in electric and magnetic fields\u2014such as the orbits of the electrons and protons trapped in the Van Allen belts\u2014but we do not, unfortunately, have the time to deal with them here."
    },
    {
        "input": "Dielectrics",
        "output": "Here we begin to discuss another of the peculiar properties of matter under the influence of the electric field. In an earlier chapter we considered the behavior of conductors, in which the charges move freely in response to an electric field to such points that there is no field left inside a conductor. Now we will discuss insulators, materials which do not conduct electricity. One might at first believe that there should be no effect whatsoever. However, using a simple electroscope and a parallel-plate capacitor, Faraday discovered that this was not so. His experiments showed that the capacitance of such a capacitor is increased when an insulator is put between the plates. If the insulator completely fills the space between the plates, the capacitance is increased by a factor \u03ba which depends only on the nature of the insulating material. Insulating materials are also called dielectrics; the factor \u03ba is then a property of the dielectric, and is called the dielectric constant. The dielectric constant of a vacuum is, of course, unity. Our problem now is to explain why there is any electrical effect if the insulators are indeed insulators and do not conduct electricity. We begin with the experimental fact that the capacitance is increased and try to reason out what might be going on. Consider a parallel-plate capacitor with some charges on the surfaces of the conductors, let us say negative charge on the top plate and positive charge on the bottom plate. Suppose that the spacing between the plates is d and the area of each plate is A . As we have proved earlier, the capacitance is C= \u03f5 0 A d , (10.1) and the charge and voltage on the capacitor are related by Q=CV. (10.2) Now the experimental fact is that if we put a piece of insulating material like lucite or glass between the plates, we find that the capacitance is larger. That means, of course, that the voltage is lower for the same charge. But the voltage difference is the integral of the electric field across the capacitor; so we must conclude that inside the capacitor, the electric field is reduced even though the charges on the plates remain unchanged. Now how can that be? We have a law due to Gauss that tells us that the flux of the electric field is directly related to the enclosed charge. Consider the Gaussian surface S shown by broken lines in Fig. 10\u20131. Since the electric field is reduced with the dielectric present, we conclude that the net charge inside the surface must be lower than it would be without the material. There is only one possible conclusion, and that is that there must be positive charges on the surface of the dielectric. Since the field is reduced but is not zero, we would expect this positive charge to be smaller than the negative charge on the conductor. So the phenomena can be explained if we could understand in some way that when a dielectric material is placed in an electric field there is positive charge induced on one surface and negative charge induced on the other. We would expect that to happen for a conductor. For example, suppose that we had a capacitor with a plate spacing d , and we put between the plates a neutral conductor whose thickness is b , as in Fig. 10\u20132. The electric field induces a positive charge on the upper surface and a negative charge on the lower surface, so there is no field inside the conductor. The field in the rest of the space is the same as it was without the conductor, because it is the surface density of charge divided by \u03f5 0 ; but the distance over which we have to integrate to get the voltage (the potential difference) is reduced. The voltage is V= \u03c3 \u03f5 0 (d\u2212b). \u03c3 The resulting equation for the capacitance is like Eq. (10.1), with (d\u2212b) substituted for d : C= \u03f5 0 A d[1\u2212(b/d)] . (10.3) The capacitance is increased by a factor which depends upon (b/d) , the proportion of the volume which is occupied by the conductor. This gives us an obvious model for what happens with dielectrics\u2014that inside the material there are many little sheets of conducting material. The trouble with such a model is that it has a specific axis, the normal to the sheets, whereas most dielectrics have no such axis. However, this difficulty can be eliminated if we assume that all insulating materials contain small conducting spheres separated from each other by insulation, as shown in Fig. 10\u20133. The phenomenon of the dielectric constant is explained by the effect of the charges which would be induced on each sphere. This is one of the earliest physical models of dielectrics used to explain the phenomenon that Faraday observed. More specifically, it was assumed that each of the atoms of a material was a perfect conductor, but insulated from the others. The dielectric constant \u03ba would depend on the proportion of space which was occupied by the conducting spheres. This is not, however, the model that is used today. If we follow the above analysis further, we discover that the idea of regions of perfect conductivity and insulation is not essential. Each of the small spheres acts like a dipole, the moment of which is induced by the external field. The only thing that is essential to the understanding of dielectrics is that there are many little dipoles induced in the material. Whether the dipoles are induced because there are tiny conducting spheres or for any other reason is irrelevant. Why should a field induce a dipole moment in an atom if the atom is not a conducting sphere? This subject will be discussed in much greater detail in the next chapter, which will be about the inner workings of dielectric materials. However, we give here one example to illustrate a possible mechanism. An atom has a positive charge on the nucleus, which is surrounded by negative electrons. In an electric field, the nucleus will be attracted in one direction and the electrons in the other. The orbits or wave patterns of the electrons (or whatever picture is used in quantum mechanics) will be distorted to some extent, as shown in Fig. 10\u20134; the center of gravity of the negative charge will be displaced and will no longer coincide with the positive charge of the nucleus. We have already discussed such distributions of charge. If we look from a distance, such a neutral configuration is equivalent, to a first approximation, to a little dipole. It seems reasonable that if the field is not too enormous, the amount of induced dipole moment will be proportional to the field. That is, a small field will displace the charges a little bit and a larger field will displace them further\u2014and in proportion to the field\u2014unless the displacement gets too large. For the remainder of this chapter, it will be supposed that the dipole moment is exactly proportional to the field. We will now assume that in each atom there are charges q separated by a distance \u03b4 , so that q\u03b4 is the dipole moment per atom. (We use \u03b4 because we are already using d for the plate separation.) If there are N atoms per unit volume, there will be a dipole moment per unit volume equal to Nq\u03b4 . This dipole moment per unit volume will be represented by a vector, P . Needless to say, it is in the direction of the individual dipole moments, i.e., in the direction of the charge separation \u03b4 : P=Nq\u03b4. (10.4) In general, P will vary from place to place in the dielectric. However, at any point in the material, P is proportional to the electric field E . The constant of proportionality, which depends on the ease with which the electrons are displaced, will depend on the kinds of atoms in the material. What actually determines how this constant of proportionality behaves, how accurately it is constant for very large fields, and what is going on inside different materials, we will discuss at a later time. For the present, we will simply suppose that there exists a mechanism by which a dipole moment is induced which is proportional to the electric field. Now let us see what this model gives for the theory of a condenser with a dielectric. First consider a sheet of material in which there is a certain dipole moment per unit volume. Will there be on the average any charge density produced by this? Not if P is uniform. If the positive and negative charges being displaced relative to each other have the same average density, the fact that they are displaced does not produce any net charge inside the volume. On the other hand, if P were larger at one place and smaller at another, that would mean that more charge would be moved into some region than away from it; we would then expect to get a volume density of charge. For the parallel-plate condenser, we suppose that P is uniform, so we need to look only at what happens at the surfaces. At one surface the negative charges, the electrons, have effectively moved out a distance \u03b4 ; at the other surface they have moved in, leaving some positive charge effectively out a distance \u03b4 . As shown in Fig. 10\u20135, we will have a surface density of charge, which will be called the surface polarization charge. This charge can be calculated as follows. If A is the area of the plate, the number of electrons that appear at the surface is the product of A and N , the number per unit volume, and the displacement \u03b4 , which we assume here is perpendicular to the surface. The total charge is obtained by multiplying by the electronic charge q e . To get the surface density of the polarization charge induced on the surface, we divide by A . The magnitude of the surface charge density is \u03c3 pol =N q e \u03b4. N \u03b4 But this is just equal to the magnitude P of the polarization vector P , Eq. (10.4): \u03c3 pol =P. (10.5) The surface density of charge is equal to the polarization inside the material. The surface charge is, of course, positive on one surface and negative on the other. Now let us assume that our slab is the dielectric of a parallel-plate capacitor. The plates of the capacitor also have a surface charge, which we will call \u03c3 free , because they can move \u201cfreely\u201d anywhere on the conductor. This is, of course, the charge that we put on when we charged the capacitor. It should be emphasized that \u03c3 pol exists only because of \u03c3 free . If \u03c3 free is removed by discharging the capacitor, then \u03c3 pol will disappear, not by going out on the discharging wire, but by moving back into the material\u2014by the relaxation of the polarization inside the material. We can now apply Gauss\u2019 law to the Gaussian surface S in Fig. 10\u20131. The electric field E in the dielectric is equal to the total surface charge density divided by \u03f5 0 . It is clear that \u03c3 pol and \u03c3 free have opposite signs, so E= \u03c3 free \u2212 \u03c3 pol \u03f5 0 . (10.6) Note that the field E 0 between the metal plate and the surface of the dielectric is higher than the field E ; it corresponds to \u03c3 free alone. But here we are concerned with the field inside the dielectric which, if the dielectric nearly fills the gap, is the field over nearly the whole volume. Using Eq. (10.5), we can write E= \u03c3 free \u2212P \u03f5 0 . (10.7) This equation doesn\u2019t tell us what the electric field is unless we know what P is. Here, however, we are assuming that P depends on E \u2014in fact, that it is proportional to E . This proportionality is usually written as P=\u03c7 \u03f5 0 E. (10.8) The constant \u03c7 (Greek \u201ckhi\u201d) is called the electric susceptibility of the dielectric. Then Eq. (10.7) becomes E= \u03c3 free \u03f5 0 1 (1+\u03c7) , (10.9) which gives us the factor 1/(1+\u03c7) by which the field is reduced. The voltage between the plates is the integral of the electric field. Since the field is uniform, the integral is just the product of E and the plate separation d . We have that V=Ed= \u03c3 free d \u03f5 0 (1+\u03c7) . d The total charge on the capacitor is \u03c3 free A , so that the capacitance defined by (10.2) becomes C= \u03f5 0 A(1+\u03c7) d = \u03ba \u03f5 0 A d . (10.10) We have explained the observed facts. When a parallel-plate capacitor is filled with a dielectric, the capacitance is increased by the factor \u03ba=1+\u03c7, (10.11) which is a property of the material. Our explanation, of course, is not complete until we have explained\u2014as we will do later\u2014how the atomic polarization comes about. Let\u2019s now consider something a little bit more complicated\u2014the situation in which the polarization P is not everywhere the same. As mentioned earlier, if the polarization is not constant, we would expect in general to find a charge density in the volume, because more charge might come into one side of a small volume element than leaves it on the other. How can we find out how much charge is gained or lost from a small volume? First let\u2019s compute how much charge moves across any imaginary surface when the material is polarized. The amount of charge that goes across a surface is just P times the surface area if the polarization is normal to the surface. Of course, if the polarization is tangential to the surface, no charge moves across it. Following the same arguments we have already used, it is easy to see that the charge moved across any surface element is proportional to the component of P perpendicular to the surface. Compare Fig. 10\u20136 with Fig. 10\u20135. We see that Eq. (10.5) should, in the general case, be written \u03c3 pol =P\u22c5n. (10.12) If we are thinking of an imagined surface element inside the dielectric, Eq. (10.12) gives the charge moved across the surface but doesn\u2019t result in a net surface charge, because there are equal and opposite contributions from the dielectric on the two sides of the surface. The displacements of the charges can, however, result in a volume charge density. The total charge displaced out of any volume V by the polarization is the integral of the outward normal component of P over the surface S that bounds the volume (see Fig. 10\u20137). An equal excess charge of the opposite sign is left behind. Denoting the net charge inside V by \u0394 Q pol we write \u0394 Q pol =\u2212 \u222b S P\u22c5nda. (10.13) We can attribute \u0394 Q pol to a volume distribution of charge with the density \u03c1 pol , and so \u0394 Q pol = \u222b V \u03c1 pol dV. (10.14) Combining the two equations yields \u222b V \u03c1 pol dV=\u2212 \u222b S P\u22c5nda. (10.15) We have a kind of Gauss\u2019 theorem that relates the charge density from polarized materials to the polarization vector P . We can see that it agrees with the result we got for the surface polarization charge or the dielectric in a parallel-plate capacitor. Using Eq. (10.15) with the Gaussian surface of Fig. 10\u20131, the surface integral gives P\u0394A , and the charge inside is \u03c3 pol \u0394A , so we get again that \u03c3 pol =P . Just as we did for Gauss\u2019 law of electrostatics, we can convert Eq. (10.15) to a differential form\u2014using Gauss\u2019 mathematical theorem: \u222b S P\u22c5nda= \u222b V \u2207\u22c5PdV. \u222b \u222b We get \u03c1 pol =\u2212\u2207\u22c5P. (10.16) If there is a nonuniform polarization, its divergence gives the net density of charge appearing in the material. We emphasize that this is a perfectly real charge density; we call it \u201cpolarization charge\u201d only to remind ourselves how it got there. Now let\u2019s combine the above result with our theory of electrostatics. The fundamental equation is \u2207\u22c5E= \u03c1 \u03f5 0 . (10.17) The \u03c1 here is the density of all electric charges. Since it is not easy to keep track of the polarization charges, it is convenient to separate \u03c1 into two parts. Again we call \u03c1 pol the charges due to nonuniform polarizations, and call \u03c1 free all the rest. Usually \u03c1 free is the charge we put on conductors, or at known places in space. Equation (10.17) then becomes \u2207\u22c5E= \u03c1 free + \u03c1 pol \u03f5 0 = \u03c1 free \u2212\u2207\u22c5P \u03f5 0 + \u2207 P or \u2207\u22c5(E+ P \u03f5 0 )= \u03c1 free \u03f5 0 . (10.18) Of course, the equation for the curl of E is unchanged: \u2207\u00d7E=0. (10.19) Taking P from Eq. (10.8), we get the simpler equation \u2207\u22c5[(1+\u03c7)E]=\u2207\u22c5(\u03baE)= \u03c1 free \u03f5 0 . (10.20) These are the equations of electrostatics when there are dielectrics. They don\u2019t, of course, say anything new, but they are in a form which is more convenient for computation in cases where \u03c1 free is known and the polarization P is proportional to E . Notice that we have not taken the dielectric \u201cconstant,\u201d \u03ba , out of the divergence. That is because it may not be the same everywhere. If it has everywhere the same value, it can be factored out and the equations are just those of electrostatics with the charge density \u03c1 free divided by \u03ba . In the form we have given, the equations apply to the general case where different dielectrics may be in different places in the field. Then the equations may be quite difficult to solve. There is a matter of some historical importance which should be mentioned here. In the early days of electricity, the atomic mechanism of polarization was not known and the existence of \u03c1 pol was not appreciated. The charge \u03c1 free was considered to be the entire charge density. In order to write Maxwell\u2019s equations in a simple form, a new vector D was defined to be equal to a linear combination of E and P : D= \u03f5 0 E+P. (10.21) As a result, Eqs. (10.18) and (10.19) were written in an apparently very simple form: \u2207\u22c5D= \u03c1 free ,\u2207\u00d7E=0. (10.22) Can one solve these? Only if a third equation is given for the relationship between D and E . When Eq. (10.8) holds, this relationship is D= \u03f5 0 (1+\u03c7)E=\u03ba \u03f5 0 E. (10.23) This equation was usually written D=\u03f5E, (10.24) where \u03f5 is still another constant for describing the dielectric property of materials. It is called the \u201cpermittivity.\u201d (Now you see why we have \u03f5 0 in our equations, it is the \u201cpermittivity of empty space.\u201d) Evidently, \u03f5=\u03ba \u03f5 0 =(1+\u03c7) \u03f5 0 . (10.25) Today we look upon these matters from another point of view, namely, that we have simpler equations in a vacuum, and if we exhibit in every case all the charges, whatever their origin, the equations are always correct. If we separate some of the charges away for convenience, or because we do not want to discuss what is going on in detail, then we can, if we wish, write our equations in any other form that may be convenient. One more point should be emphasized. An equation like D=\u03f5E is an attempt to describe a property of matter. But matter is extremely complicated, and such an equation is in fact not correct. For instance, if E gets too large, then D is no longer proportional to E . For some substances, the proportionality breaks down even with relatively small fields. Also, the \u201cconstant\u201d of proportionality may depend on how fast E changes with time. Therefore this kind of equation is a kind of approximation, like Hooke\u2019s law. It cannot be a deep and fundamental equation. On the other hand, our fundamental equations for E , (10.17) and (10.19), represent our deepest and most complete understanding of electrostatics. We will now prove some rather general theorems for electrostatics in situations where dielectrics are present. We have seen that the capacitance of a parallel-plate capacitor is increased by a definite factor if it is filled with a dielectric. We can show that this is true for a capacitor of any shape, provided the entire region in the neighborhood of the two conductors is filled with a uniform linear dielectric. Without the dielectric, the equations to be solved are \u2207\u22c5 E 0 = \u03c1 free \u03f5 0 and\u2207\u00d7 E 0 =0. \u03c1 With the dielectric present, the first of these equations is modified; we have instead the equations \u2207\u22c5(\u03baE)= \u03c1 free \u03f5 0 and\u2207\u00d7E=0. (10.26) Now since we are taking \u03ba to be everywhere the same, the last two equations can be written as \u2207\u22c5(\u03baE)= \u03c1 free \u03f5 0 and\u2207\u00d7(\u03baE)=0. (10.27) We therefore have the same equations for \u03baE as for E 0 , so they have the solution \u03baE= E 0 . In other words, the field is everywhere smaller, by the factor 1/\u03ba , than in the case without the dielectric. Since the voltage difference is a line integral of the field, the voltage is reduced by this same factor. Since the charge on the electrodes of the capacitor has been taken the same in both cases, Eq. (10.2) tells us that the capacitance, in the case of an everywhere uniform dielectric, is increased by the factor \u03ba . Let us now ask what the force would be between two charged conductors in a dielectric. We consider a liquid dielectric that is homogeneous everywhere. We have seen earlier that one way to obtain the force is to differentiate the energy with respect to the appropriate distance. If the conductors have equal and opposite charges, the energy U= Q 2 /2C , where C is their capacitance. Using the principle of virtual work, any component is given by a differentiation; for example, F x =\u2212 \u2202U \u2202x =\u2212 Q 2 2 \u2202 \u2202x ( 1 C ). (10.28) Since the dielectric increases the capacity by a factor \u03ba , all forces will be reduced by this same factor. One point should be emphasized. What we have said is true only if the dielectric is a liquid. Any motion of conductors that are embedded in a solid dielectric changes the mechanical stress conditions of the dielectric and alters its electrical properties, as well as causing some mechanical energy change in the dielectric. Moving the conductors in a liquid does not change the liquid. The liquid moves to a new place but its electrical characteristics are not changed. Many older books on electricity start with the \u201cfundamental\u201d law that the force between two charges is F= q 1 q 2 4\u03c0 \u03f5 0 \u03ba r 2 , (10.29) a point of view which is thoroughly unsatisfactory. For one thing, it is not true in general; it is true only for a world filled with a liquid. Secondly, it depends on the fact that \u03ba is a constant, which is only approximately true for most real materials. It is much better to start with Coulomb\u2019s law for charges in a vacuum, which is always right (for stationary charges). What does happen in a solid? This is a very difficult problem which has not been solved, because it is, in a sense, indeterminate. If you put charges inside a dielectric solid, there are many kinds of pressures and strains. You cannot deal with virtual work without including also the mechanical energy required to compress the solid, and it is a difficult matter, generally speaking, to make a unique distinction between the electrical forces and the mechanical forces due to the solid material itself. Fortunately, no one ever really needs to know the answer to the question proposed. He may sometimes want to know how much strain there is going to be in a solid, and that can be worked out. But it is much more complicated than the simple result we got for liquids. A surprisingly complicated problem in the theory of dielectrics is the following: Why does a charged object pick up little pieces of dielectric? If you comb your hair on a dry day, the comb readily picks up small scraps of paper. If you thought casually about it, you probably assumed the comb had one charge on it and the paper had the opposite charge on it. But the paper is initially electrically neutral. It hasn\u2019t any net charge, but it is attracted anyway. It is true that sometimes the paper will come up to the comb and then fly away, repelled immediately after it touches the comb. The reason is, of course, that when the paper touches the comb, it picks up some negative charges and then the like charges repel. But that doesn\u2019t answer the original question. Why did the paper come toward the comb in the first place? The answer has to do with the polarization of a dielectric when it is placed in an electric field. There are polarization charges of both signs, which are attracted and repelled by the comb. There is a net attraction, however, because the field nearer the comb is stronger than the field farther away\u2014the comb is not an infinite sheet. Its charge is localized. A neutral piece of paper will not be attracted to either plate inside the parallel plates of a capacitor. The variation of the field is an essential part of the attraction mechanism. As illustrated in Fig. 10\u20138, a dielectric is always drawn from a region of weak field toward a region of stronger field. In fact, one can prove that for small objects the force is proportional to the gradient of the square of the electric field. Why does it depend on the square of the field? Because the induced polarization charges are proportional to the fields, and for given charges the forces are proportional to the field. However, as we have just indicated, there will be a net force only if the square of the field is changing from point to point. So the force is proportional to the gradient of the square of the field. The constant of proportionality involves, among other things, the dielectric constant of the object, and it also depends upon the size and shape of the object. There is a related problem in which the force on a dielectric can be worked out quite accurately. If we have a parallel-plate capacitor with a dielectric slab only partially inserted, as shown in Fig. 10\u20139, there will be a force driving the sheet in. A detailed examination of the force is quite complicated; it is related to nonuniformities in the field near the edges of the dielectric and the plates. However, if we do not look at the details, but merely use the principle of conservation of energy, we can easily calculate the force. We can find the force from the formula we derived earlier. Equation (10.28) is equivalent to F x =\u2212 \u2202U \u2202x =+ V 2 2 \u2202C \u2202x . (10.30) We need only find out how the capacitance varies with the position of the dielectric slab. Let\u2019s suppose that the total length of the plates is L , that the width of the plates is W , that the plate separation and dielectric thickness are d , and that the distance to which the dielectric has been inserted is x . The capacitance is the ratio of the total free charge on the plates to the voltage between the plates. We have seen above that for a given voltage V the surface charge density of free charge is \u03ba \u03f5 0 V/d . So the total charge on the plates is Q= \u03ba \u03f5 0 V d xW+ \u03f5 0 V d (L\u2212x)W, V V from which we get the capacitance: C= \u03f5 0 W d (\u03bax+L\u2212x). (10.31) Using (10.30), we have F x = V 2 2 \u03f5 0 W d (\u03ba\u22121). (10.32) Now this equation is not particularly useful for anything unless you happen to need to know the force in such circumstances. We only wished to show that the theory of energy can often be used to avoid enormous complications in determining the forces on dielectric materials\u2014as there would be in the present case. Our discussion of the theory of dielectrics has dealt only with electrical phenomena, accepting the fact that the material has a polarization which is proportional to the electric field. Why there is such a proportionality is perhaps of greater interest to physics. Once we understand the origin of the dielectric constants from an atomic point of view, we can use electrical measurements of the dielectric constants in varying circumstances to obtain detailed information about atomic or molecular structure. This aspect will be treated in part in the next chapter."
    },
    {
        "input": "PrerequisitesReview Lecture A",
        "output": "These three optional lectures are going to be dull: they go over the same material that we went over before, adding absolutely nothing. So I\u2019m very surprised to see so many people here. Frankly, I had rather hoped there would be fewer of you, and that these lectures wouldn\u2019t be necessary. The purpose of relaxing at this time is to give you time to think about things, to piddle around with the things that you heard about. That\u2019s by all odds the most effective way of learning the physics: it\u2019s not a good idea to come in and listen to some review; it\u2019s better to make up the review for yourself. So I\u2019d advise you\u2014if you\u2019re not too far lost, completely befuddled and confused\u2014that you forget about these lectures and piddle around by yourself, and try to find out what\u2019s interesting without grinding down some particular track. You\u2019ll learn infinitely better and easier and more completely by picking a problem for yourself that you find interesting to fiddle around with\u2014some kind of a thing that you heard that you don\u2019t understand, or you want to analyze further, or want to do some kind of a trick with\u2014that\u2019s the best way to learn something. The lectures that we have been giving so far are a new course, and have been designed to answer a problem we presumed existed: nobody knows how to teach physics, or to educate people\u2014that\u2019s a fact, and if you don\u2019t like the way it\u2019s being done, that\u2019s perfectly natural. It\u2019s impossible to teach satisfactorily: for hundreds of years, even more, people have been trying to figure out how to teach, and nobody has ever figured it out. So if this new course is not satisfactory, that\u2019s not unique. At Caltech we are always changing the courses in the hope of improving them, and this year we changed the physics course again. One of the complaints in the past was that the students who are nearer the top find the whole subject of mechanics dull: they would find themselves grinding along, doing problems, studying reviews, and doing examinations, and there was no time to think about anything; there was no excitement in it; there was no description of its relation to modern physics, or anything like that. And so this set of lectures was designed to be better that way, to a certain extent, to help out those fellows, and to make the subject more interesting, if possible, by connecting it to the rest of the universe. On the other hand, this approach has the disadvantage that it confuses many people, because they don\u2019t know what it is they\u2019re supposed to learn\u2014or, rather, that there\u2019s so much stuff that they can\u2019t learn all of it, and they haven\u2019t got enough intelligence to figure out what is interesting to them, and to pay attention only to that. Therefore, I\u2019m addressing myself to those people who have found the lectures very confusing, very annoying, and irritating, in the sense that they don\u2019t know what to study, and they\u2019re kind of lost. The other people, who don\u2019t feel as lost, shouldn\u2019t be here, so I now give you the opportunity to go out...1 I see nobody has the nerve. Or I guess I\u2019m a great failure, then, if I got everybody lost! (Maybe you\u2019re just here for entertainment.) Now, I am therefore imagining that one of you has come into my office and said, \u201cFeynman, I listened to all the lectures, and I took that midterm exam, and I\u2019m trying to do the problems, and I can\u2019t do anything, and I think I\u2019m in the bottom of the class, and I don\u2019t know what to do.\u201d What would I say to you? The first thing I would point out is this: to come to Caltech is an advantage in certain ways, and in other ways a disadvantage. Some of the ways that it\u2019s an advantage you probably once knew, but now forget, and they have to do with the fact that the school has an excellent reputation, and the reputation is well deserved. There are pretty good courses. (I don\u2019t know about this particular physics course; of course I have my own opinion about it.) The people who have come out the other end of Caltech, when they go into industry, or go to do work in research, and so forth, always say that they got a very good education here, and when they compare themselves with people who have gone to other schools (although many other schools are also very good) they never find themselves behind and missing something; they always feel they went to the best school of them all. So that\u2019s an advantage. But there is also a certain disadvantage: because Caltech has such a good reputation, almost everybody who\u2019s the first or second in his high school class applies here. There are lots of high schools, and all the very best men2 apply. Now, we have tried to figure out a system of selection, with all kinds of tests, so that we get the best of the best. And so you guys have been very carefully picked out from all these schools to come here. But we\u2019re still working on it, because we\u2019ve found a very serious problem: no matter how carefully we select the men, no matter how patiently we make the analysis, when they get here something happens: it always turns out that approximately half of them are below average! Of course you laugh at this because it\u2019s self-evident to the rational mind, but not to the emotional mind\u2014the emotional mind can\u2019t laugh at this. When you\u2019ve lived all the time as number one or number two (or even possibly number three) in high school science, and when you know that everybody who\u2019s below average in the science courses where you came from is a complete idiot, and now you suddenly discover that you are below average\u2014and half of you guys are\u2014it\u2019s a terrible blow, because you imagine that it means you\u2019re as dumb as those guys used to be in high school, relatively. That\u2019s the great disadvantage of Caltech: that this psychological blow is so difficult to take. Of course, I\u2019m not a psychologist; I\u2019m imagining all this. I don\u2019t know how it would really be, of course! The question is what to do if you find you\u2019re below average. There are two possibilities. In the first place, you could find that it\u2019s so difficult and annoying that you have to get out\u2014that\u2019s an emotional problem. You can apply your rational mind to that and point out to yourself what I just pointed out to you: that half of the guys in this place are going to be below average, even though they\u2019re all tops, so it doesn\u2019t mean anything. You see, if you can stick out that nonsense, that funny feeling, for four years, then you\u2019ll go out into the world again, and you\u2019ll discover that the world is just like it used to be\u2014that when, for example, you get a job somewhere, you\u2019ll find you\u2019re Number One Man again, and you\u2019ll get the great pleasure of being the expert they all come running to in this particular plant whenever they can\u2019t figure out how to convert inches to centimeters! It\u2019s true: the men who go out into industry, or go to a small school that doesn\u2019t have an excellent reputation in physics, even if they\u2019ve been in the bottom third, the bottom fifth, the bottom tenth of the class\u2014if they don\u2019t try to drive themselves (and I\u2019ll explain that in a minute), then they\u2019ll find themselves very much in demand, that what they learned here is very useful, and they\u2019re back where they were before: happy, Number One. On the other hand you can make a mistake: some people may drive themselves to a point where they insist they have to become Number One, and in spite of everything they want to go to graduate school and they want to become the best Ph.D. in the best school, even though they\u2019re starting out at the bottom of the class here. Well, they are likely to be disappointed and to make themselves miserable for the rest of their lives being always at the bottom of a very first-rate group, because they picked that group. That\u2019s a problem, and that\u2019s up to you\u2014it depends on your personality. (Remember, I\u2019m talking to the guy who came into my office because he\u2019s in the lowest tenth; I\u2019m not talking to the other fellows who are happy because they happen to be in the upper tenth\u2014that\u2019s a minority anyway!) So, if you can take this psychological blow\u2014if you can say to yourself, \u201cI\u2019m in the lower third of the class, but a third of the guys are in the lower third of the class, because it\u2019s got to be that way! I was the top guy in high school, and I\u2019m still a smart son-of-a-gun. We need scientists in the country, and I\u2019m gonna be a scientist, and when I get out of this school I\u2019ll be all right, damn it! And I\u2019ll be a good scientist!\u201d\u2014then it\u2019ll be true: you will be a good scientist. The only thing is whether you can take the funny feelings during these four years, in spite of the rational arguments. If you find you can\u2019t take the funny feelings, I suppose the best thing to do is to try to go somewhere else. It\u2019s not a point of failure; it\u2019s simply an emotional thing. Even if you\u2019re one of the last couple of guys in the class, it doesn\u2019t mean you\u2019re not any good. You just have to compare yourself to a reasonable group, instead of to this insane collection that we\u2019ve got here at Caltech. Therefore, I am making this review purposely for the people who are lost, so that they have still a chance to stay here a little longer to find out whether or not they can take it, okay? I make now one more point: that this is not a preparation for an examination, or anything like that. I don\u2019t know anything about the examinations\u2014I mean, I have nothing to do with making them up, and I don\u2019t know what\u2019s going to be on them, so there\u2019s no guarantee whatsoever that what\u2019s on the examination is only going to deal with the stuff reviewed in these lectures, or any nonsense of that kind. So, this guy comes into my office and asks me to try to make everything straight that I taught him, and this is the best I can do. The problem is to try to explain the stuff that was being taught. So I start, now, with the review. I would tell this guy, \u201cThe first thing you must learn is the mathematics. And that involves, first, calculus. And in calculus, differentiation.\u201d Now, mathematics is a beautiful subject, and has its ins and outs, too, but we\u2019re trying to figure out what the minimum amount we have to learn for physics purposes are. So the attitude that\u2019s taken here is a \u201cdisrespectful\u201d one towards the mathematics, for sheer efficiency only; I\u2019m not trying to undo mathematics. What we have to do is to learn to differentiate like we know how much is 3 and 5, or how much is 5 times 7, because that kind of work is involved so often that it\u2019s good not to be confounded by it. When you write something down, you should be able to immediately differentiate it without even thinking about it, and without making any mistakes. You\u2019ll find you need to do this operation all the time\u2014not only in physics, but in all the sciences. Therefore differentiation is like the arithmetic you had to learn before you could learn algebra. Incidentally, the same goes for algebra: there\u2019s a lot of algebra. We are assuming that you can do algebra in your sleep, upside down, without making a mistake. We know it isn\u2019t true, so you should also practice algebra: write yourself a lot of expressions, practice them, and don\u2019t make any errors. Errors in algebra, differentiation, and integration are only nonsense; they\u2019re things that just annoy the physics, and annoy your mind while you\u2019re trying to analyze something. You should be able to do calculations as quickly as possible, and with a minimum of errors. That requires nothing but rote practice\u2014that\u2019s the only way to do it. It\u2019s like making yourself a multiplication table, like you did in elementary school: they\u2019d put a bunch of numbers on the board, and you\u2019d go: \u201cThis times that, this times that,\u201d and so on\u2014Bing! Bing! Bing! In the same way you must learn differentiation. Make a card, and on the card write a number of expressions of the following general type: for example, 1+6t 4t2+2t3 (1+2t)3 \u221a 1+5t (t+7t2)1/3 and so on. Write, say, a dozen of these expressions. Then, every once in a while, just take the card out of your pocket, put your finger on an expression, and read out the derivative. In other words, you should be able to see right away: d dt (1+6t) =6 Bing! d dt (4t2+2t3) =8t+6t2 Bing! d dt (1+2t)3 =6(1+2t)2 Bing! See? So the first thing to do is to memorize how to do derivatives\u2014cold. That\u2019s a necessary practice. Now, for differentiating more complicated expressions, the derivative of a sum is easy: it\u2019s simply the sum of the derivatives of each separate summand. It isn\u2019t necessary at this stage in our physics course to know how to differentiate expressions any more complicated than those above, or sums of them, so that in the spirit of this review, I shouldn\u2019t tell you any more. But there is a formula for differentiating complicated expressions, which is usually not given in calculus class in the form that I\u2019m going to give it to you, and it turns out to be very useful. You won\u2019t learn it later, because nobody will ever tell it to you, but it\u2019s a good thing to know how to do. Suppose I want to differentiate the following: 6(1+2t2)(t3\u2212t)2 \u221a t+5t2 (4t)3/2 + \u221a 1+2t t+ \u221a 1+t2 Now, the question is how to do it with dispatch. Here\u2019s how you do it with dispatch. (These are just rules; it\u2019s the level to which I\u2019ve reduced the mathematics, because we\u2019re working with the guys who can barely hold on.) Watch! You write the expression down again, and after each summand you put a bracket: 6(1+2t2)(t3\u2212t)2 \u221a t+5t2 (4t)3/2 \u22c5[ + \u221a 1+2t t+ \u221a 1+t2 \u22c5[ Next, you\u2019re going to write something inside the brackets, such that when you\u2019re all finished, you\u2019ll have the derivative of the original expression. (That\u2019s why you write the expression down again, in case you don\u2019t want to lose it.) Now, you look at each term and you draw a bar\u2014a divider\u2014and you put the term in the denominator: The first term is 1+2t2 that goes in the denominator. The power of the term goes in front (it\u2019s the first power, 1 ), and the derivative of the term (by our practice game), 4t , goes in the numerator. That\u2019s one term: 6(1+2t2)(t3\u2212t)2 \u221a t+5t2 (4t)3/2 \u22c5[1 4t 1+2t2 + \u221a 1+2t t+ \u221a 1+t2 \u22c5[ (What about the 6 ? Forget it! Any number in front doesn\u2019t make any difference: if you wanted to, you could start out, \u201c 6 goes in the denominator; its power, 1 , goes in front; and its derivative, 0 , goes in the numerator.\u201d) Next term: t 3 \u2212t goes in the denominator; the power, +2 , goes in front; the derivative, 3 t 2 \u22121 , goes in the numerator. The next term, t+5 t 2 goes in the denominator; the power, \u22121/2 (the inverse square root is a negative half power), goes in front; the derivative, 1+10t , goes in the numerator. The next term, 4t , goes in the denominator; its power, \u22123/2 , goes in front; its derivative, 4 , goes in the numerator. Close the bracket. That\u2019s one summand: 6(1+2 t 2 )( t 3 \u2212t ) 2 t+5 t 2 \u2212 \u2212 \u2212 \u2212 \u2212 \u2212 \u221a (4t ) 3/2 \u22c5 + 1+2t \u2212 \u2212 \u2212 \u2212 \u2212 \u221a t+ 1+ t 2 \u2212 \u2212 \u2212 \u2212 \u2212 \u221a \u22c5[ [1 4t 1+2 t 2 +2 3 t 2 \u22121 t 3 \u2212t \u2212 1 2 1+10t t+5 t 2 \u2212 3 2 4 4t ] (1.6) Next summand, first term: the power is +1/2 . The object whose power we\u2019re taking is 1+2t , the derivative is 2 . The power of the next term, t+ 1+ t 2 \u2212 \u2212 \u2212 \u2212 \u2212 \u221a , is \u22121 . (You see, it\u2019s a reciprocal.) The term goes in the denominator, and its derivative (this is the only hard one, relatively) has two pieces, because it\u2019s a sum: 1+ 1 2 2t 1+ t 2 \u2212 \u2212 \u2212 \u2212 \u2212 \u221a . Close the bracket: 6(1+2 t 2 )( t 3 \u2212t ) 2 t+5 t 2 \u2212 \u2212 \u2212 \u2212 \u2212 \u2212 \u221a (4t ) 3/2 \u22c5 + 1+2t \u2212 \u2212 \u2212 \u2212 \u2212 \u221a t+ 1+ t 2 \u2212 \u2212 \u2212 \u2212 \u2212 \u221a \u22c5[ 1 2 [1 4t 1+2 t 2 +2 3 t 2 \u22121 t 3 \u2212t \u2212 1 2 1+10t t+5 t 2 \u2212 3 2 4 4t ] 2 (1+2t) \u22121 1+ 1 2 2t 1+ t 2 \u2212 \u2212 \u2212 \u2212 \u2212 \u221a t+ 1+ t 2 \u2212 \u2212 \u2212 \u2212 \u2212 \u221a ] (1.7) That\u2019s the derivative of the original expression. So, you see, that by memorizing this technique, you can differentiate anything\u2014except sines, cosines, logs, and so on, but you can learn the rules for those easily; they\u2019re very simple. And then you can use this technique even when the terms include tangents and everything else. I noticed when I wrote it down you were worried that it was such a complicated expression, but I think you can appreciate now that this is a really powerful method of differentiation because it gives the answer\u2014boom\u2014without any delay, no matter how complicated. The idea here is that the derivative of a function f=k\u22c5 u a \u22c5 v b \u22c5 w c \u2026 with respect to t is df dt =f\u22c5[a du/dt u +b dv/dt v +c dw/dt w +\u2026] (1.8) (where k and a,b,c\u2026 are constants). However, in this physics course, I doubt any of the problems will be that complicated, so we probably won\u2019t have any opportunity to use this. Anyway, that\u2019s the way I differentiate, and I\u2019m pretty good at it now, so there we are. Now, the opposite process is integration. You should equally well learn to integrate as rapidly as possible. Integration is not as easy as differentiation, but you should be able to integrate simple expressions in your head. It isn\u2019t necessary to be able to integrate every expression; for example, (t+7 t 2 ) 1/3 is not possible to integrate in an easy fashion, but the others below are. So, when you choose expressions to practice integration, be careful that they can be done easily: \u222b(1+6t)dt \u222b(4 t 2 +2 t 3 )dt \u222b(1+2t ) 3 dt \u222b 1+5t \u2212 \u2212 \u2212 \u2212 \u2212 \u221a dt \u222b(t+7 t 2 ) 1/3 dt =t+3 t 2 = 4 t 3 3 + t 4 2 = (1+2t ) 4 8 = 2(1+5t ) 3/2 15 =???. (1.9) I have nothing more to tell you about calculus. The rest is up to you: you have to practice differentiation and integration\u2014and, of course, the algebra required to reduce horrors like Eq. (1.7). Practicing algebra and calculus in this dull way\u2014that\u2019s the first thing. The other branch of the mathematics that we\u2019re involved in as a pure mathematical subject is vectors. You first have to know what vectors are, and if you haven\u2019t got a feel for it, I don\u2019t know what to do: we\u2019d have to talk back and forth a while for me to appreciate your difficulty\u2014otherwise I couldn\u2019t explain. A vector is like a push that has a certain direction, or a speed that has a certain direction, or a movement that has a certain direction\u2014and it\u2019s represented on a piece of paper by an arrow in the direction of the thing. For instance, we represent a force on something by an arrow that is pointing in the direction of the force, and the length of the arrow is a measure of the magnitude of the force in some arbitrary scale\u2014a scale, however, which must be maintained for all the forces in the problem. If you make another force twice as strong, you represent that by an arrow twice as long. (See Fig. 1\u20131.) Now, there are operations that can be done with these vectors. That is, if there are two forces acting at the same time on an object\u2014say, two people are pushing on a thing\u2014then the two forces can be represented by two arrows F and F \u2032 . When we draw a diagram of something like this, it is often convenient to place the tails of the arrows where the forces are applied, even though in general there\u2019s no meaning to the location of vectors. (See Fig. 1\u20132.) If we want to know the net resultant force, or total force, that corresponds to adding the vectors, and we can draw this by moving the tail of one onto the head of the other. (They\u2019re still the same vectors after you move them because they have the same direction and the same length.) Then F+ F \u2032 is the vector drawn from the tail of F to the head of F \u2032 (or from the tail of F \u2032 to the head of F ), as shown in Figure 1\u20133. This way of adding vectors is sometimes called the \u201cparallelogram method.\u201d On the other hand, suppose there are two forces acting on an object, but we only know one of them is F \u2032 ; the other one, which we don\u2019t know, we\u2019ll call X . Then, if the total force on the object is known to be F , we have F \u2032 +X=F . And so, X=F\u2212 F \u2032 . Thus to find X you have to take the difference of two vectors, and you can do that in either of two ways: you can take \u2212 F \u2032 , which is a vector in the opposite direction as F \u2032 and add it to F . (See Fig. 1\u20134.) Otherwise F\u2212 F \u2032 , is simply the vector drawn from the head of F \u2032 to the head of F . Now, the disadvantage of the second method is that you may have a tendency to draw the arrow as shown in Figure 1\u20135; although the direction and length of the difference is right, the application of the force is not located at the tail of the arrow\u2014so watch out. In case you\u2019re nervous about it, or there\u2019s any confusion, use the first method. (See Fig. 1\u20136.) We can also project vectors in certain directions. For example, if we would like to know what the force is in the \u2018 x \u2019 direction (called the component of the force in that direction) it\u2019s easy: we just project F down with a right angle onto the x axis, and that gives the component of the force in that direction, which we call F x . Mathematically, F x is the magnitude of F (which I\u2019ll write |F| ) times the cosine of the angle that F makes with the x axis; this comes from the properties of the right triangle. (See Fig. 1\u20137.) F x =|F|cos\u03b8 (1.10) Now, if A and B are added to make C , then the projections that are brought down to form a right angle in a given direction \u2018 x \u2019, evidently add. So the components of the vector sum are the sum of the vector components, and that\u2019s true of components in any direction. (See Fig. 1\u20138.) A+B=C\u21d2 A x + B x = C x . (1.11) Particularly convenient is the description of vectors in terms of their components on perpendicular axes, x and y (and z \u2014there\u2019s three dimensions in the world; I keep forgetting that, because I\u2019m always drawing on a blackboard!). If we have a vector F that is in the x - y plane, and we know its component in the x direction, that doesn\u2019t completely define F , because there are many vectors in the x - y plane that have the same component in the x direction. But if we also know F \u2019s component in the y direction, then F is completely specified. (See Fig. 1\u20139.) The components of F along the x , y , and z axes can be written as F x , F y , and F z ; summing vectors is equivalent to summing their components, so if the components of another vector F \u2032 are F \u2032 x , F \u2032 y , and F \u2032 z , then F+ F \u2032 has the components F x + F \u2032 x , F y + F \u2032 y , and F z + F \u2032 z . That\u2019s the easy part; now it gets a bit more difficult. There\u2019s a way of multiplying two vectors to produce a scalar\u2014a number that is the same in any coordinate system. (In fact, there\u2019s a way of making a scalar out of one vector, and I\u2019ll come back to that.) You see, if the coordinate axes change, then the components change\u2014but the angle between vectors and their magnitudes stay the same. If A and B are vectors, and the angle between them is \u03b8 , I can take the magnitude of A , times the magnitude of B times the cosine of \u03b8 and call this number (\u201c A dot B \u201d). (See Fig. 1\u201310.) That number, called a \u201cdot product\u201d or a \u201cscalar product,\u201d is the same in all coordinate systems: A\u22c5B=|A||B|cos\u03b8 (1.12) It is evident that since |A|cos\u03b8 is the projection of A onto B , A\u22c5B is equal to the projection of A onto B times the magnitude of B . Similarly, since |B|cos\u03b8 is the projection of B onto A , A\u22c5B also equals the projection of B onto A times the magnitude of A . However, I find for myself that A\u22c5B=|A||B|cos\u03b8 is the easiest way to remember what the dot product is; then I can always see the other relations immediately. The trouble is, of course, you have so many ways of saying the same thing that it\u2019s no good to try to remember them all\u2014a point that I\u2019ll make, in a few minutes, more completely. We can also define A\u22c5B in terms of the components of A and B on an arbitrary set of axes. If I were to take three mutually perpendicular axes, x , y , z , in some arbitrary orientation, then A\u22c5B will turn out to be A\u22c5B= A x B x + A y B y + A z B z (1.13) It is not immediately self-evident how you get from |A||B|cos\u03b8 to A x B x + A y B y + A z B z . Although I can prove it when I want to,3 it takes me too long, so I remember them both. When we take the dot product of a vector with itself, \u03b8 is 0 , and the cosine of 0 is 1 , so A\u22c5A=|A||A|cos0=|A | 2 . 2 In terms of components, it's A\u22c5A= A 2 x + A 2 y + A 2 z . 2 2 2 The positive square root of that number is the magnitude of the vector. Now, we can do what\u2019s called differentiating the vectors. The derivative of a vector with respect to time is meaningless unless the vector depends on the time, of course. That means we have to imagine some vector that is different all the time: as time goes on, the vector keeps changing, and we want the rate of change. For example, the vector A(t) might be the position, at time t , of an object that\u2019s flying around. At the next moment, t \u2032 , the object has moved from A(t) to A( t \u2032 ) ; we would like to calculate the rate of change of A at time t . The rule is the following: that in the interval \u0394t= t \u2032 \u2212t , the thing has moved from A(t) to A( t \u2032 ) so the displacement is \u0394A=A( t \u2032 )\u2212A(t) , a difference vector from the old position to the new position. (See Fig. 1\u201311.) Of course, the shorter the interval \u0394t , the closer A( t \u2032 ) is to A(t) . If you divide \u0394A by \u0394t and then take the limit as they both approach zero\u2014that\u2019s the derivative. In this case, where A is position, its derivative is a velocity vector; the velocity vector is in a direction tangent to the curve, because that\u2019s the direction of the displacements; its magnitude you can\u2019t get by looking at this picture, because it depends on how fast the thing is going along the curve. The magnitude of the velocity vector is the speed; it tells you how far the thing moves per unit time. So, that\u2019s a definition of the velocity vector: it\u2019s tangent to the path, and its magnitude is equal to the speed of motion on the path. (See Fig. 1-12.) v(t)= dA dt = lim \u0394t\u21920 \u0394A \u0394t (1.14) Incidentally, it is dangerous to draw both the position vector and the velocity vector in the same diagram, unless you\u2019re being very careful\u2014and since we\u2019re having a little trouble understanding these things, I point out all the possible pitfalls that I can think of, because the next thing you might want to do is add A to v for some purpose. That\u2019s not legitimate, because in order to really draw the velocity vector, you have to know the scale of time: the velocity vector is in a different scale than the position vector; in fact, they have different units. You can\u2019t add positions and velocities together in general\u2014and you can\u2019t add them here. In order for me to actually draw the picture of any vector, I have to make a decision as to the scale. When we talked about forces, we said that so-andso many newtons were going to be represented by 1 inch (or 1 meter, or whatever). And here, we have to say that so-and-so many meters per second is going to be represented by 1 inch. Someone else could draw the picture with position vectors the same lengths as ours, but with the velocity vector one-third as long as ours\u2014he\u2019s just using a different scale for his velocity vector. There\u2019s no unique way to draw the length of a vector because the choice of scale is arbitrary. Now, the velocity in terms of x , y , and z components is very easy, because, for example, the rate of change of the x component of position is equal to the x component of velocity, and so on. This is simply because the derivative is really a difference, and since the components of a difference vector equal the differences of the corresponding components, we have ( \u0394A \u0394t ) x ( \u0394A \u0394t ) y ( \u0394A \u0394t ) z = \u0394 A x \u0394t , = \u0394 A y \u0394t , = \u0394 A z \u0394t , (1.15) and then taking limits we have the components of the derivative: v x = d A x dt , v y = d A y dt , v z = d A z dt . (1.16) This is true for any direction: if I take the component of A(t) in any direction, then the velocity vector component in that direction is the derivative of the component of A(t) in that direction, with one serious warning: the direction must not change with time. You can\u2019t say, \u201cI\u2019m gonna take the component of A in the direction of v ,\u201d or something like that, because v is moving. It\u2019s only true that the derivative of the position component is equal to the velocity component if the direction in which you take the component is itself fixed So equations (1.15) and (1.16) are only true for x , y , z , and other fixed axes; if the axes are turning while you\u2019re trying to take the derivative, the formula is much more complicated. Those are some of the deviations and difficulties of differentiating vectors. Of course, you can differentiate the derivative of a vector, then differentiate that, and so on. I called the derivative of A \u201cvelocity,\u201d but that\u2019s only because A is the position; if A is something else, its derivative is something other than velocity. For example, if A is the momentum, the time derivative of momentum equals the force, so the derivative of A would be the force. And if A were the velocity, the time derivative of the velocity is the acceleration, and so on. What I\u2019ve been telling you is generally true of differentiating vectors, but here I\u2019ve given only the example of positions and velocities. Finally, there\u2019s only one more thing that I have to talk about for vectors, and that is a horrible, complicated thing, called a \u201cline integral\u201d: \u222b z a F\u22c5ds (1.17) We\u2019ll take as an example that you have a certain vector field F , which you want to integrate along a curve S from point a to point z . Now, in order for this line integral to mean something, there must be some way of defining the value of F at every point on S between a and z . If F is defined as the force applied to an object at point a , but you can\u2019t tell me how the force changes as you move along S , at least between a and z , then \u201cthe integral of F along S from a to z \u201d makes no sense. (I said \u201cat least,\u201d because F could be defined anywhere else too, but at least you must define it on the part of the curve that you are integrating along.) In a moment I\u2019ll define the line integral of an arbitrary vector field along an arbitrary curve, but first let\u2019s consider the case where F is constant, and S is a straight-line path from a to z \u2014a displacement vector, which I\u2019ll call s . (See Fig. 1-13.) Then, since F is constant, we can take it outside the integral (just like ordinary integration), and the integral of ds from a to z is just s , so the answer is F\u22c5s . That\u2019s the line integral for a constant force and a straight-line path\u2014the easy case: \u222b z a F\u22c5ds=F\u22c5 \u222b z a ds=F\u22c5s. (1.18) (Remember that F\u22c5s is the component of the force in the direction of the displacement times the magnitude of the displacement; in other words, it\u2019s simply the distance along the line times the component of force in that direction. There are a lot of other ways to look at it, too: it\u2019s the component of the displacement in the direction of the force, times the magnitude of the force; it\u2019s the magnitude of the force times the magnitude of the displacement, times the cosine of the angle between them. These are all equivalent.) More generally, the line integral is defined as follows. First, we break up the integral by dividing S between a and z into N equal segments: \u0394 S 1 ,\u0394 S 2 \u2026\u0394 S N . Then the integral along S is the integral along \u0394 S 1 plus the integral along \u0394 S 2 plus the integral along \u0394 S 3 , and so on. We choose N large so that we can approximate each \u0394 S i by a little displacement vector, \u0394 s i over which F has an approximately constant value F i , (See Fig. 1-14.) Then, by the \u201cconstant force straight-line path\u201d rule, segment \u0394 s i contributes approximately F i \u22c5\u0394 s i to the integral. So, if you add together F i \u22c5\u0394 s i for i equals 1 to N , that\u2019s an excellent approximation to the integral. The integral is exactly equal to this sum only if we take the limit as N goes to infinity: you take the segments as fine as you can; you take them a little finer than that, and you get the correct integral: \u222b z a F\u22c5ds= lim N\u2192\u221e \u2211 i=1 N F i \u22c5\u0394 s i . (1.19) (This integral, of course, depends upon the curve\u2014generally\u2014though sometimes it doesn\u2019t in the physics.) Well, then, that\u2019s all there is to the mathematics that you have to know to do the physics\u2014for now, at least\u2014and these things, most particularly the calculus and the early parts of the vector theory, should become second nature. Some things\u2014like the line integral\u2014may not be second nature now, but they will be, eventually, as you use them more; they aren\u2019t so vital yet, and that\u2019s harder. The things you \u201cgotta get into your head good,\u201d right now, are the calculus, and the little things about taking the components of vectors in various directions. I\u2019ll give one example\u2014just a very simple one\u2014to show how to take components of vectors. Suppose we have a machine of some kind, as illustrated in Figure 1-15: it\u2019s got two rods connected by a pivot (like an elbow joint) with a big weight on it. The end of one rod is connected to the floor by a stationary pivot, and the end of the other rod has a rolling pivot that rolls along the floor in a slot\u2014it\u2019s part of a machine, see, and it\u2019s going choochoog, choo-choog\u2014the roller\u2019s going back and forth, the weight\u2019s going up and down, and so on. Let\u2019s say the weight is 2 kg, the rods are 0.5 meters long, and at a certain moment when the machine is standing still, the distance from the weight to the floor just happens to come out, luckily, to 0.4 meters\u2014so that we have a 3-4-5 triangle, to make the arithmetic easier. (See Fig. 1-16.) (The arithmetic shouldn\u2019t make any difference; the real difficulty is to get the ideas right.) The problem is to figure out what horizontal push P you have to make on the roller in order to hold that weight up. Now, I\u2019m going to make an assumption that we will need in order to do the problem. We make the assumption that when a rod has pivots at both ends, then the net force is always directed along the rod. (It turns out to be true; you may feel it\u2019s self-evident.) It would not necessarily be true if there were a pivot only at one end of the rod, because then I could push the rod sideways. But if there\u2019s a pivot at both ends, I can only push along the rod. So let\u2019s suppose that we know that\u2014that the forces must lie in the directions of the rods. We also know something else from the physics: that the forces are equal and opposite at the ends of the rods. For example, whatever force is exerted by the rod on the roller must also be exerted by that rod, in the opposite direction, on the weight. So, that\u2019s the problem: with these ideas about the properties of rods, we try to figure out what\u2019s the horizontal force on the roller. I think the way I\u2019d like to try to do it is this: the horizontal force exerted on the roller by the rod is a certain component of the net force on it. (Of course, there\u2019s also a vertical component due to the \u201cconfining slot,\u201d which is unknown and uninteresting; it\u2019s part of the net force on the roller, which is exactly opposite the net force on the weight.) Therefore I can get the components of the force exerted on the roller by the rod\u2014in particular, the horizontal component I want\u2014if I can get the components of the force exerted by the rod on the weight. If I call the horizontal force on the weight F x then the horizontal force on the roller is \u2212 F x and the force needed to hold the weight up is equal and opposite to that, so |P|= F x . The vertical force on the weight from the rod, F y , is very easy: it\u2019s simply equal to the weight of the thing, which is 2 kg, times g , the gravitational constant. (Something else you have to know from physics\u2014 g is 9.8, in the mks system.) F y is 2 times g , or 19.6 newtons, so the vertical force on the roller is \u201319.6 newtons. Now, how can I get the horizontal force? Answer: I get it by knowing that the net force must lie along the rod. If F y is 19.6 , and the net force lies along the rod, then how much must F x be? (See Fig. 1-17.) Well, we have the projections of the triangles, which have been designed very nicely, so that the ratio of the horizontal to the vertical sides is 3 to 4 ; that\u2019s the same ratio as F x is to F y , (I don\u2019t care about the net force, F , here; I only need the force in the horizontal direction) and I already know what the vertical force is. So, the magnitude of the horizontal force\u2014unknown\u2014is to 19.6 as 0.3 is to 0.4 . Therefore I multiply 3/4 by 19.6 and I get: F x 19.6 \u2234 F x = 0.3 0.4 . = 0.3 0.4 \u00d719.6=14.7 newtons. (1.20) We conclude that the horizontal force on the roller needed to hold the weight up, is 14.7 newtons. That\u2019s the answer to this problem. Or is it? You see, you can\u2019t do physics just by plugging in the formulas: you\u2019ll never get anywhere without having something else besides knowing the rules, the formulas for projections, and all that stuff; you have to have a certain feeling for the real situation! I\u2019ll make some more remarks about that in a minute, but here, in this particular problem, the difficulty is the following: the net force on the weight is not only from one rod, there\u2019s also a force exerted on it by the other rod, in some direction, and I left that out when I made the analysis\u2014so it\u2019s all wrong! I also have to worry about the force that the rod with the stationary pivot exerts on the weight. Now it\u2019s getting complicated: how can I figure out what that force is? Well, what is the net force of everything on the weight? Just the gravity\u2014it just balances the gravity; there is no force horizontally on the weight. So the clue by which I can find out how much \u201cjuice\u201d there is along the rod with the stationary pivot, is to notice that it must exert just enough horizontally to balance the horizontal force that the other rod is exerting. Therefore, if I were to draw the force that the rod with the stationary pivot exerts, its horizontal component would be exactly opposite the horizontal component that the rod with the roller exerts, and the vertical components would be equal because of the identical 3-4-5 triangles the rods make: both rods are pushing up the same amount because their horizontal components must balance\u2014if the rods were different lengths, you\u2019d have a little more work to do, but it\u2019s the same idea. So, let\u2019s start out with the weight again: the forces from the rods on the weight are the first things to get straightened out. So, let\u2019s look at the forces from the rods on the weight. The reason I keep repeating this to myself is because otherwise I get the signs all mixed up: The force from the weight on the rods is the opposite of the force from the rods on the weight. I always have to start over after I get all balled up like this; I have to think it out again, and make up my mind as to what I want to talk about. So I say, \u201cLook at the forces from the rods on the weight: there\u2019s a force F , which is in the direction of one rod. Then there\u2019s a force F \u2032 in the direction of the other rod. Those are the only two forces, and they are in the directions of the rods.\u201d Now, the net of these two forces\u2014ahhhh! I\u2019m beginning to see the light! The net of these two forces has no horizontal component, and a vertical component of 19.6 newtons. Ah! Let me draw the picture again, since I did it wrong before. (See Fig. 1-18.) The horizontal forces balance, therefore the vertical components add, and the 19.6 newtons is not just the vertical component of the force from one rod, but the total from both; since each rod contributes half, the vertical component from the rod with the roller is only 9.8 newtons. Now when we take the horizontal projection of this force, multiplying it by as we did before, we get the horizontal component of force from the rod with the roller on the weight, and that takes care of that: F x 9.8 \u2234 F x = 0.3 0.4 . = 0.3 0.4 \u00d79.8=7.35 newtons. (1.21) I have a few moments left, so I\u2019d like to make a little speech about the relation of the mathematics to the physics\u2014which, in fact, was well illustrated by this little example. It will not do to memorize the formulas, and to say to yourself, \u201cI know all the formulas; all I gotta do is figure out how to put \u2019em in the problem!\u201d Now, you may succeed with this for a while, and the more you work on memorizing the formulas, the longer you\u2019ll go on with this method\u2014but it doesn\u2019t work in the end. You might say, \u201cI\u2019m not gonna believe him, because I\u2019ve always been successful: that\u2019s the way I\u2019ve always done it; I\u2019m always gonna do it that way.\u201d You are not always going to do it that way: you\u2019re going to flunk\u2014not this year, not next year, but eventually, when you get your job, or something\u2014you\u2019re going to lose along the line somewhere, because physics is an enormously extended thing: there are millions of formulas! It\u2019s impossible to remember all the formulas\u2014it\u2019s impossible! And the great thing that you\u2019re ignoring, the powerful machine that you\u2019re not using, is this: suppose Figure 1-19 is a map of all the physics formulas, all the relations in physics. (It should have more than two dimensions, but let\u2019s suppose it\u2019s like that.) Now, suppose that something happened to your mind, that somehow all the material in some region was erased, and there was a little spot of missing goo in there. The relations of nature are so nice that it is possible, by logic, to \u201ctriangulate\u201d from what is known to what\u2019s in the hole. (See Fig. 1-20.) And you can re-create the things that you\u2019ve forgotten perpetually\u2014if you don\u2019t forget too much, and if you know enough. In other words, there comes a time\u2014which you haven\u2019t quite got to, yet\u2014where you\u2019ll know so many things that as you forget them, you can reconstruct them from the pieces that you can still remember. It is therefore of first-rate importance that you know how to \u201ctriangulate\u201d\u2014that is, to know how to figure something out from what you already know. It is absolutely necessary. You might say, \u201cAh, I don\u2019t care; I\u2019m a good memorizer! I know how to really memorize! In fact, I took a course in memory!\u201d That still doesn\u2019t work! Because the real utility of physicists\u2014both to discover new laws of nature, and to develop new things in industry, and so on\u2014is not to talk about what\u2019s already known, but to do something new\u2014and so they triangulate out from the known things: they make a \u201ctriangulation\u201d that no one has ever made before. (See Fig. 1-21.) In order to learn how to do that, you\u2019ve got to forget the memorizing of formulas, and to try to learn to understand the interrelationships of nature. That\u2019s very much more difficult at the beginning, but it\u2019s the only successful way."
    },
    {
        "input": "Electromagnetic Mass",
        "output": "In bringing together relativity and Maxwell\u2019s equations, we have finished our main work on the theory of electromagnetism. There are, of course, some details we have skipped over and one large area that we will be concerned with in the future\u2014the interaction of electromagnetic fields with matter. But we want to stop for a moment to show you that this tremendous edifice, which is such a beautiful success in explaining so many phenomena, ultimately falls on its face. When you follow any of our physics too far, you find that it always gets into some kind of trouble. Now we want to discuss a serious trouble\u2014the failure of the classical electromagnetic theory. You can appreciate that there is a failure of all classical physics because of the quantum-mechanical effects. Classical mechanics is a mathematically consistent theory; it just doesn\u2019t agree with experience. It is interesting, though, that the classical theory of electromagnetism is an unsatisfactory theory all by itself. There are difficulties associated with the ideas of Maxwell\u2019s theory which are not solved by and not directly associated with quantum mechanics. You may say, \u201cPerhaps there\u2019s no use worrying about these difficulties. Since the quantum mechanics is going to change the laws of electrodynamics, we should wait to see what difficulties there are after the modification.\u201d However, when electromagnetism is joined to quantum mechanics, the difficulties remain. So it will not be a waste of our time now to look at what these difficulties are. Also, they are of great historical importance. Furthermore, you may get some feeling of accomplishment from being able to go far enough with the theory to see everything\u2014including all of its troubles. The difficulty we speak of is associated with the concepts of electromagnetic momentum and energy, when applied to the electron or any charged particle. The concepts of simple charged particles and the electromagnetic field are in some way inconsistent. To describe the difficulty, we begin by doing some exercises with our energy and momentum concepts. First, we compute the energy of a charged particle. Suppose we take a simple model of an electron in which all of its charge q is uniformly distributed on the surface of a sphere of radius a , which we may take to be zero for the special case of a point charge. Now let\u2019s calculate the energy in the electromagnetic field. If the charge is standing still, there is no magnetic field, and the energy per unit volume is proportional to the square of the electric field. The magnitude of the electric field is q/4\u03c0\u03f50r2 , and the energy density is u= \u03f50 2 E2= q2 32\u03c02\u03f50r4 . To get the total energy, we must integrate this density over all space. Using the volume element 4\u03c0r2dr , the total energy, which we will call Uelec , is Uelec=\u222b q2 8\u03c0\u03f50r2 dr. This is readily integrated. The lower limit is a , and the upper limit is \u221e , so Uelec= 1 2 q2 4\u03c0\u03f50 1 a . If we use the electronic charge qe for q and the symbol e2 for q 2 e /4\u03c0\u03f50 , then Uelec= 1 2 e2 a . It is all fine until we set a equal to zero for a point charge\u2014there\u2019s the great difficulty. Because the energy of the field varies inversely as the fourth power of the distance from the center, its volume integral is infinite. There is an infinite amount of energy in the field surrounding a point charge. What\u2019s wrong with an infinite energy? If the energy can\u2019t get out, but must stay there forever, is there any real difficulty with an infinite energy? Of course, a quantity that comes out infinite may be annoying, but what really matters is only whether there are any observable physical effects. To answer that question, we must turn to something else besides the energy. Suppose we ask how the energy changes when we move the charge. Then, if the changes are infinite, we will be in trouble. Suppose an electron is moving at a uniform velocity through space, assuming for a moment that the velocity is low compared with the speed of light. Associated with this moving electron there is a momentum\u2014even if the electron had no mass before it was charged\u2014because of the momentum in the electromagnetic field. We can show that the field momentum is in the direction of the velocity v of the charge and is, for small velocities, proportional to v . For a point P at the distance r from the center of the charge and at the angle \u03b8 with respect to the line of motion (see Fig. 28\u20131) the electric field is radial and, as we have seen, the magnetic field is v\u00d7E/ c 2 . The momentum density, Eq. (27.21), is g= \u03f5 0 E\u00d7B. E B It is directed obliquely toward the line of motion, as shown in the figure, and has the magnitude g= \u03f5 0 v c 2 E 2 sin\u03b8. \u03f5 v The fields are symmetric about the line of motion, so when we integrate over space, the transverse components will sum to zero, giving a resultant momentum parallel to v . The component of g in this direction is gsin\u03b8 , which we must integrate over all space. We take as our volume element a ring with its plane perpendicular to v , as shown in Fig. 28\u20132. Its volume is 2\u03c0 r 2 sin\u03b8d\u03b8dr . The total momentum is then p=\u222b \u03f5 0 v c 2 E 2 sin 2 \u03b82\u03c0 r 2 sin\u03b8d\u03b8dr. \u222b Since E is independent of \u03b8 (for v\u226ac ), we can immediately integrate over \u03b8 ; the integral is \u222b sin 3 \u03b8d\u03b8 =\u2212\u222b(1\u2212 cos 2 \u03b8)d(cos\u03b8) =\u2212cos\u03b8+ cos 3 \u03b8 3 . The limits of \u03b8 are 0 and \u03c0 , so the \u03b8 -integral gives merely a factor of 4/3 , and p= 8\u03c0 3 \u03f5 0 v c 2 \u222b E 2 r 2 dr. \u222b The integral (for v\u226ac ) is the one we have just evaluated to find the energy; it is q 2 /16 \u03c0 2 \u03f5 2 0 a , and p= 2 3 q 2 4\u03c0 \u03f5 0 v a c 2 , 2 or p= 2 3 e 2 a c 2 v. (28.3) The momentum in the field\u2014the electromagnetic momentum\u2014is proportional to v . It is just what we should have for a particle with the mass equal to the coefficient of v . We can, therefore, call this coefficient the electromagnetic mass, m elec , and write it as m elec = 2 3 e 2 a c 2 . (28.4) Where does the mass come from? In our laws of mechanics we have supposed that every object \u201ccarries\u201d a thing we call the mass\u2014which also means that it \u201ccarries\u201d a momentum proportional to its velocity. Now we discover that it is understandable that a charged particle carries a momentum proportional to its velocity. It might, in fact, be that the mass is just the effect of electrodynamics. The origin of mass has until now been unexplained. We have at last in the theory of electrodynamics a grand opportunity to understand something that we never understood before. It comes out of the blue\u2014or rather, from Maxwell and Poynting\u2014that any charged particle will have a momentum proportional to its velocity just from electromagnetic influences. Let\u2019s be conservative and say, for a moment, that there are two kinds of mass\u2014that the total momentum of an object could be the sum of a mechanical momentum and the electromagnetic momentum. The mechanical momentum is the \u201cmechanical\u201d mass, m mech , times v . In experiments where we measure the mass of a particle by seeing how much momentum it has, or how it swings around in an orbit, we are measuring the total mass. We say generally that the momentum is the total mass ( m mech + m elec ) times the velocity. So the observed mass can consist of two pieces (or possibly more if we include other fields): a mechanical piece plus an electromagnetic piece. We know that there is definitely an electromagnetic piece, and we have a formula for it. And there is the thrilling possibility that the mechanical piece is not there at all\u2014that the mass is all electromagnetic. Let\u2019s see what size the electron must have if there is to be no mechanical mass. We can find out by setting the electromagnetic mass of Eq. (28.4) equal to the observed mass m e of an electron. We find a= 2 3 e 2 m e c 2 . (28.5) The quantity r 0 = e 2 m e c 2 (28.6) is called the \u201cclassical electron radius\u201d; it has the numerical value 2.82\u00d7 10 \u221213 cm, about one one-hundred-thousandth of the diameter of an atom. Why is r 0 called the electron radius, rather than our a ? Because we could equally well do the same calculation with other assumed distributions of charges\u2014the charge might be spread uniformly through the volume of a sphere or it might be smeared out like a fuzzy ball. For any particular assumption the factor 2/3 would change to some other fraction. For instance, for a charge uniformly distributed throughout the volume of a sphere, the 2/3 gets replaced by 4/5 . Rather than to argue over which distribution is correct, it was decided to define r 0 as the \u201cnominal\u201d radius. Then different theories could supply their pet coefficients. Let\u2019s pursue our electromagnetic theory of mass. Our calculation was for v\u226ac ; what happens if we go to high velocities? Early attempts led to a certain amount of confusion, but Lorentz realized that the charged sphere would contract into a ellipsoid at high velocities and that the fields would change in accordance with the formulas (26.6) and (26.7) we derived for the relativistic case in Chapter 26. If you carry through the integrals for p in that case, you find that for an arbitrary velocity v , the momentum is altered by the factor 1/ 1\u2212 v 2 / c 2 \u2212 \u2212 \u2212 \u2212 \u2212 \u2212 \u2212 \u2212 \u221a : p= 2 3 e 2 a c 2 v 1\u2212 v 2 / c 2 \u2212 \u2212 \u2212 \u2212 \u2212 \u2212 \u2212 \u2212 \u221a . (28.7) In other words, the electromagnetic mass rises with velocity inversely as 1\u2212 v 2 / c 2 \u2212 \u2212 \u2212 \u2212 \u2212 \u2212 \u2212 \u2212 \u221a \u2014a discovery that was made before the theory of relativity. Early experiments were proposed to measure the changes with velocity in the observed mass of a particle in order to determine how much of the mass was mechanical and how much was electrical. It was believed at the time that the electrical part would vary with velocity, whereas the mechanical part would not. But while the experiments were being done, the theorists were also at work. Soon the theory of relativity was developed, which proposed that no matter what the origin of the mass, it all should vary as m 0 / 1\u2212 v 2 / c 2 \u2212 \u2212 \u2212 \u2212 \u2212 \u2212 \u2212 \u2212 \u221a . Equation (28.7) was the beginning of the theory that mass depended on velocity. Let\u2019s now go back to our calculation of the energy in the field, which led to Eq. (28.2). According to the theory of relativity, the energy U will have the mass U/ c 2 ; Eq. (28.2) then says that the field of the electron should have the mass m \u2032 elec = U elec c 2 = 1 2 e 2 a c 2 , (28.8) which is not the same as the electromagnetic mass, m elec , of Eq. (28.4). In fact, if we just combine Eqs. (28.2) and (28.4), we would write U elec = 3 4 m elec c 2 . 3 This formula was discovered before relativity, and when Einstein and others began to realize that it must always be that U=m c 2 , there was great confusion. The discrepancy between the two formulas for the electromagnetic mass is especially annoying, because we have carefully proved that the theory of electrodynamics is consistent with the principle of relativity. Yet the theory of relativity implies without question that the momentum must be the same as the energy times v/ c 2 . So we are in some kind of trouble; we must have made a mistake. We did not make an algebraic mistake in our calculations, but we have left something out. In deriving our equations for energy and momentum, we assumed the conservation laws. We assumed that all forces were taken into account and that any work done and any momentum carried by other \u201cnonelectrical\u201d machinery was included. Now if we have a sphere of charge, the electrical forces are all repulsive and an electron would tend to fly apart. Because the system has unbalanced forces, we can get all kinds of errors in the laws relating energy and momentum. To get a consistent picture, we must imagine that something holds the electron together. The charges must be held to the sphere by some kind of rubber bands\u2014something that keeps the charges from flying off. It was first pointed out by Poincar\u00e9 that the rubber bands\u2014or whatever it is that holds the electron together\u2014must be included in the energy and momentum calculations. For this reason the extra nonelectrical forces are also known by the more elegant name \u201cthe Poincar\u00e9 stresses.\u201d If the extra forces are included in the calculations, the masses obtained in two ways are changed (in a way that depends on the detailed assumptions). And the results are consistent with relativity; i.e., the mass that comes out from the momentum calculation is the same as the one that comes from the energy calculation. However, both of them contain two contributions: an electromagnetic mass and contribution from the Poincar\u00e9 stresses. Only when the two are added together do we get a consistent theory. It is therefore impossible to get all the mass to be electromagnetic in the way we hoped. It is not a legal theory if we have nothing but electrodynamics. Something else has to be added. Whatever you call them\u2014\u201crubber bands,\u201d or \u201cPoincar\u00e9 stresses,\u201d or something else\u2014there have to be other forces in nature to make a consistent theory of this kind. Clearly, as soon as we have to put forces on the inside of the electron, the beauty of the whole idea begins to disappear. Things get very complicated. You would want to ask: How strong are the stresses? How does the electron shake? Does it oscillate? What are all its internal properties? And so on. It might be possible that an electron does have some complicated internal properties. If we made a theory of the electron along these lines, it would predict odd properties, like modes of oscillation, which haven\u2019t apparently been observed. We say \u201capparently\u201d because we observe a lot of things in nature that still do not make sense. We may someday find out that one of the things we don\u2019t understand today (for example, the muon) can, in fact, be explained as an oscillation of the Poincar\u00e9 stresses. It doesn\u2019t seem likely, but no one can say for sure. There are so many things about fundamental particles that we still don\u2019t understand. Anyway, the complex structure implied by this theory is undesirable, and the attempt to explain all mass in terms of electromagnetism\u2014at least in the way we have described\u2014has led to a blind alley. We would like to think a little more about why we say we have a mass when the momentum in the field is proportional to the velocity. Easy! The mass is the coefficient between momentum and velocity. But we can look at the mass in another way: a particle has mass if you have to exert a force in order to accelerate it. So it may help our understanding if we look a little more closely at where the forces come from. How do we know that there has to be a force? Because we have proved the law of the conservation of momentum for the fields. If we have a charged particle and push on it for awhile, there will be some momentum in the electromagnetic field. Momentum must have been poured into the field somehow. Therefore there must have been a force pushing on the electron in order to get it going\u2014a force in addition to that required by its mechanical inertia, a force due to its electromagnetic interaction. And there must be a corresponding force back on the \u201cpusher.\u201d But where does that force come from? The picture is something like this. We can think of the electron as a charged sphere. When it is at rest, each piece of charge repels electrically each other piece, but the forces all balance in pairs, so that there is no net force. [See Fig. 28\u20133(a).] However, when the electron is being accelerated, the forces will no longer be in balance because of the fact that the electromagnetic influences take time to go from one piece to another. For instance, the force on the piece \u03b1 in Fig. 28\u20133(b) from a piece \u03b2 on the opposite side depends on the position of \u03b2 at an earlier time, as shown. Both the magnitude and direction of the force depend on the motion of the charge. If the charge is accelerating, the forces on various parts of the electron might be as shown in Fig. 28\u20133(c). When all these forces are added up, they don\u2019t cancel out. They would cancel for a uniform velocity, even though it looks at first glance as though the retardation would give an unbalanced force even for a uniform velocity. But it turns out that there is no net force unless the electron is being accelerated. With acceleration, if we look at the forces between the various parts of the electron, action and reaction are not exactly equal, and the electron exerts a force on itself that tries to hold back the acceleration. It holds itself back by its own bootstraps. It is possible, but difficult, to calculate this self-reaction force; however, we don\u2019t want to go into such an elaborate calculation here. We will tell you what the result is for the special case of relatively uncomplicated motion in one dimension, say x . Then, the self-force can be written in a series. The first term in the series depends on the acceleration x \u00a8 , the next term is proportional to x ... , and so on.1 The result is F=\u03b1 e 2 a c 2 x \u00a8 \u2212 2 3 e 2 c 3 x ... +\u03b3 e 2 a c 4 x .... +\u22ef, (28.9) where \u03b1 and \u03b3 are numerical coefficients of the order of 1 . The coefficient \u03b1 of the x \u00a8 term depends on what charge distribution is assumed; if the charge is distributed uniformly on a sphere, then \u03b1=2/3 . So there is a term, proportional to the acceleration, which varies inversely as the radius a of the electron and agrees exactly with the value we got in Eq. (28.4) for m elec . If the charge distribution is chosen to be different, so that \u03b1 is changed, the fraction 2/3 in Eq. (28.4) would be changed in the same way. The term in x ... is independent of the assumed radius a , and also of the assumed distribution of the charge; its coefficient is always 2/3 . The next term is proportional to the radius a , and its coefficient \u03b3 depends on the charge distribution. You will notice that if we let the electron radius a go to zero, the last term (and all higher terms) will go to zero; the second term remains constant, but the first term\u2014the electromagnetic mass\u2014goes to infinity. And we can see that the infinity arises because of the force of one part of the electron on another\u2014because we have allowed what is perhaps a silly thing, the possibility of the \u201cpoint\u201d electron acting on itself. We would like now to discuss how it might be possible to modify Maxwell\u2019s theory of electrodynamics so that the idea of an electron as a simple point charge could be maintained. Many attempts have been made, and some of the theories were even able to arrange things so that all the electron mass was electromagnetic. But all of these theories have died. It is still interesting to discuss some of the possibilities that have been suggested\u2014to see the struggles of the human mind. We started out our theory of electricity by talking about the interaction of one charge with another. Then we made up a theory of these interacting charges and ended up with a field theory. We believe it so much that we allow it to tell us about the force of one part of an electron on another. Perhaps the entire difficulty is that electrons do not act on themselves; perhaps we are making too great an extrapolation from the interaction of separate electrons to the idea that an electron interacts with itself. Therefore some theories have been proposed in which the possibility that an electron acts on itself is ruled out. Then there is no longer the infinity due to the self-action. Also, there is no longer any electromagnetic mass associated with the particle; all the mass is back to being mechanical, but there are new difficulties in the theory. We must say immediately that such theories require a modification of the idea of the electromagnetic field. You remember we said at the start that the force on a particle at any point was determined by just two quantities\u2014 E and B . If we abandon the \u201cself-force\u201d this can no longer be true, because if there is an electron in a certain place, the force isn\u2019t given by the total E and B , but by only those parts due to other charges. So we have to keep track always of how much of E and B is due to the charge on which you are calculating the force and how much is due to the other charges. This makes the theory much more elaborate, but it gets rid of the difficulty of the infinity. So we can, if we want to, say that there is no such thing as the electron acting upon itself, and throw away the whole set of forces in Eq. (28.9). However, we have then thrown away the baby with the bath! Because the second term in Eq. (28.9), the term in x ... , is needed. That force does something very definite. If you throw it away, you\u2019re in trouble again. When we accelerate a charge, it radiates electromagnetic waves, so it loses energy. Therefore, to accelerate a charge, we must require more force than is required to accelerate a neutral object of the same mass; otherwise energy wouldn\u2019t be conserved. The rate at which we do work on an accelerating charge must be equal to the rate of loss of energy by radiation. We have talked about this effect before\u2014it is called the radiation resistance. We still have to answer the question: Where does the extra force, against which we must do this work, come from? When a big antenna is radiating, the forces come from the influence of one part of the antenna current on another. For a single accelerating electron radiating into otherwise empty space, there would seem to be only one place the force could come from\u2014the action of one part of the electron on another part. We found back in Chapter 32 of Vol. I that an oscillating charge radiates energy at the rate dW dt = 2 3 e 2 ( x \u00a8 ) 2 c 3 . (28.10) Let\u2019s see what we get for the rate of doing work on an electron against the bootstrap force of Eq. (28.9). The rate of work is the force times the velocity, or F x \u02d9 : dW dt =\u03b1 e 2 a c 2 x \u00a8 x \u02d9 \u2212 2 3 e 2 c 3 x ... x \u02d9 +\u22ef (28.11) The first term is proportional to d x \u02d9 2 /dt , and therefore just corresponds to the rate of change of the kinetic energy 1 2 m v 2 associated with the electromagnetic mass. The second term should correspond to the radiated power in Eq. (28.10). But it is different. The discrepancy comes from the fact that the term in Eq. (28.11) is generally true, whereas Eq. (28.10) is right only for an oscillating charge. We can show that the two are equivalent if the motion of the charge is periodic. To do that, we rewrite the second term of Eq. (28.11) as \u2212 2 3 e 2 c 3 d dt ( x \u02d9 x \u00a8 )+ 2 3 e 2 c 3 ( x \u00a8 ) 2 , 2 2 which is just an algebraic transformation. If the motion of the electron is periodic, the quantity x \u02d9 x \u00a8 returns periodically to the same value, so that if we take the average of its time derivative, we get zero. The second term, however, is always positive (it\u2019s a square), so its average is also positive. This term gives the net work done and is just equal to Eq. (28.10). The term in x ... of the bootstrap force is required in order to have energy conservation in radiating systems, and we can\u2019t throw it away. It was, in fact, one of the triumphs of Lorentz to show that there is such a force and that it comes from the action of the electron on itself. We must believe in the idea of the action of the electron on itself, and we need the term in x ... . The problem is how we can get that term without getting the first term in Eq. (28.9), which gives all the trouble. We don\u2019t know how. You see that the classical electron theory has pushed itself into a tight corner. There have been several other attempts to modify the laws in order to straighten the thing out. One way, proposed by Born and Infeld, is to change the Maxwell equations in a complicated way so that they are no longer linear. Then the electromagnetic energy and momentum can be made to come out finite. But the laws they suggest predict phenomena which have never been observed. Their theory also suffers from another difficulty we will come to later, which is common to all the attempts to avoid the troubles we have described. The following peculiar possibility was suggested by Dirac. He said: Let\u2019s admit that an electron acts on itself through the second term in Eq. (28.9) but not through the first. He then had an ingenious idea for getting rid of one but not the other. Look, he said, we made a special assumption when we took only the retarded wave solutions of Maxwell\u2019s equations; if we were to take the advanced waves instead, we would get something different. The formula for the self-force would be F=\u03b1 e 2 a c 2 x \u00a8 + 2 3 e 2 c 3 x ... +\u03b3 e 2 a c 4 x .... +\u22ef (28.12) This equation is just like Eq. (28.9) except for the sign of the second term\u2014and some higher terms\u2014of the series. [Changing from retarded to advanced waves is just changing the sign of the delay which, it is not hard to see, is equivalent to changing the sign of t everywhere. The only effect on Eq. (28.9) is to change the sign of all the odd time derivatives.] So, Dirac said, let\u2019s make the new rule that an electron acts on itself by one-half the difference of the retarded and advanced fields which it produces. The difference of Eqs. (28.9) and (28.12), divided by two, is then F=\u2212 2 3 e 2 c 3 x ... +higher terms. 2 In all the higher terms, the radius a appears to some positive power in the numerator. Therefore, when we go to the limit of a point charge, we get only the one term\u2014just what is needed. In this way, Dirac got the radiation resistance force and none of the inertial forces. There is no electromagnetic mass, and the classical theory is saved\u2014but at the expense of an arbitrary assumption about the self-force. The arbitrariness of the extra assumption of Dirac was removed, to some extent at least, by Wheeler and Feynman, who proposed a still stranger theory. They suggest that point charges interact only with other charges, but that the interaction is half through the advanced and half through the retarded waves. It turns out, most surprisingly, that in most situations you won\u2019t see any effects of the advanced waves, but they do have the effect of producing just the radiation reaction force. The radiation resistance is not due to the electron acting on itself, but from the following peculiar effect. When an electron is accelerated at the time t , it shakes all the other charges in the world at a later time t \u2032 =t+r/c (where r is the distance to the other charge), because of the retarded waves. But then these other charges react back on the original electron through their advanced waves, which will arrive at the time t \u2032\u2032 , equal to t \u2032 minus r/c , which is, of course, just t . (They also react back with their retarded waves too, but that just corresponds to the normal \u201creflected\u201d waves.) The combination of the advanced and retarded waves means that at the instant it is accelerated an oscillating charge feels a force from all the charges that are \u201cgoing to\u201d absorb its radiated waves. You see what tight knots people have gotten into in trying to get a theory of the electron! We\u2019ll describe now still another kind of theory, to show the kind of things that people think of when they are stuck. This is another modification of the laws of electrodynamics, proposed by Bopp. You realize that once you decide to change the equations of electromagnetism you can start anywhere you want. You can change the force law for an electron, or you can change the Maxwell equations (as we saw in the examples we have described), or you can make a change somewhere else. One possibility is to change the formulas that give the potentials in terms of the charges and currents. One of our formulas has been that the potentials at some point are given by the current density (or charge) at each other point at an earlier time. Using our four-vector notation for the potentials, we write A \u03bc (1,t)= 1 4\u03c0 \u03f5 0 c 2 \u222b j \u03bc (2,t\u2212 r 12 /c) r 12 d V 2 . (28.13) Bopp\u2019s beautifully simple idea is that: Maybe the trouble is in the 1/r factor in the integral. Suppose we were to start out by assuming only that the potential at one point depends on the charge density at any other point as some function of the distance between the points, say as f( r 12 ) . The total potential at point (1) will then be given by the integral of j \u03bc times this function over all space: A \u03bc (1,t)=\u222b j \u03bc (2,t\u2212 r 12 /c)f( r 12 )d V 2 . \u222b That\u2019s all. No differential equation, nothing else. Well, one more thing. We also ask that the result should be relativistically invariant. So by \u201cdistance\u201d we should take the invariant \u201cdistance\u201d between two points in space-time. This distance squared (within a sign which doesn\u2019t matter) is s 2 12 = c 2 = c 2 ( t 1 \u2212 t 2 ) 2 \u2212 r 2 12 ( t 1 \u2212 t 2 ) 2 \u2212( x 1 \u2212 x 2 ) 2 \u2212( y 1 \u2212 y 2 ) 2 \u2212( z 1 \u2212 z 2 ) 2 . (28.14) So, for a relativistically invariant theory, we should take some function of the magnitude of s 12 , or what is the same thing, some function of s 2 12 . So Bopp\u2019s theory is that A \u03bc (1, t 1 )=\u222b j \u03bc (2, t 2 )F( s 2 12 )d V 2 cd t 2 . (28.15) (The integral must, of course, be over the four-dimensional volume cd t 2 d x 2 d y 2 d z 2 .) All that remains is to choose a suitable function for F . We assume only one thing about F \u2014that it is very small except when its argument is near zero\u2014so that a graph of F would be a curve like the one in Fig. 28\u20134. It is a narrow spike with a finite area centered at s 2 =0 , and with a width which we can say is roughly a 2 . We can say, crudely, that when we calculate the potential at point (1) , only those points (2) produce any appreciable effect if s 2 12 = c 2 ( t 1 \u2212 t 2 ) 2 \u2212 r 2 12 is within \u00b1 a 2 of zero. We can indicate this by saying that F is important only for s 2 12 = c 2 ( t 1 \u2212 t 2 ) 2 \u2212 r 2 12 \u2248\u00b1 a 2 . (28.16) You can make it more mathematical if you want to, but that\u2019s the idea. Now suppose that a is very small in comparison with the size of ordinary objects like motors, generators, and the like so that for normal problems r 12 \u226ba . Then Eq. (28.16) says that charges contribute to the integral of Eq. (28.15) only when t 1 \u2212 t 2 is in the small range c( t 1 \u2212 t 2 )\u2248 r 2 12 \u00b1 a 2 \u2212 \u2212 \u2212 \u2212 \u2212 \u2212 \u2212 \u221a = r 12 1\u00b1 a 2 r 2 12 \u2212 \u2212 \u2212 \u2212 \u2212 \u2212 \u221a . Since a 2 / r 2 12 \u226a1 , the square root can be approximated by 1\u00b1 a 2 /2 r 2 12 , so t 1 \u2212 t 2 = r 12 c (1\u00b1 a 2 2 r 2 12 )= r 12 c \u00b1 a 2 2 r 12 c . 2 2 What is the significance? This result says that the only times t 2 that are important in the integral of A \u03bc are those which differ from the time t 1 , at which we want the potential, by the delay r 12 /c \u2014with a negligible correction so long as r 12 \u226ba . In other words, this theory of Bopp approaches the Maxwell theory\u2014so long as we are far away from any particular charge\u2014in the sense that it gives the retarded wave effects. We can, in fact, see approximately what the integral of Eq. (28.15) is going to give. If we integrate first over t 2 from \u2212\u221e to +\u221e \u2014keeping r 12 fixed\u2014then s 2 12 is also going to go from \u2212\u221e to +\u221e . The integral will all come from t 2 \u2019s in a small interval of width \u0394 t 2 =2\u00d7 a 2 /2 r 12 c , centered at t 1 \u2212 r 12 /c . Say that the function F( s 2 ) has the value K at s 2 =0 ; then the integral over t 2 gives approximately K j \u03bc \u0394 t 2 , or K a 2 c j \u03bc r 12 . j We should, of course, take the value of j \u03bc at t 2 = t 1 \u2212 r 12 /c , so that Eq. (28.15) becomes A \u03bc (1, t 1 )= K a 2 c \u222b j \u03bc (2, t 1 \u2212 r 12 /c) r 12 d V 2 . ( / ) If we pick K=1/4\u03c0 \u03f5 0 c a 2 , we are right back to the retarded potential solution of Maxwell\u2019s equations\u2014including automatically the 1/r dependence! And it all came out of the simple proposition that the potential at one point in space-time depends on the current density at all other points in space-time, but with a weighting factor that is some narrow function of the four-dimensional distance between the two points. This theory again predicts a finite electromagnetic mass for the electron, and the energy and mass have the right relation for the relativity theory. They must, because the theory is relativistically invariant from the start, and everything seems to be all right. There is, however, one fundamental objection to this theory and to all the other theories we have described. All particles we know obey the laws of quantum mechanics, so a quantum-mechanical modification of electrodynamics has to be made. Light behaves like photons. It isn\u2019t 100 percent like the Maxwell theory. So the electrodynamic theory has to be changed. We have already mentioned that it might be a waste of time to work so hard to straighten out the classical theory, because it could turn out that in quantum electrodynamics the difficulties will disappear or may be resolved in some other fashion. But the difficulties do not disappear in quantum electrodynamics. That is one of the reasons that people have spent so much effort trying to straighten out the classical difficulties, hoping that if they could straighten out the classical difficulty and then make the quantum modifications, everything would be straightened out. The Maxwell theory still has the difficulties after the quantum mechanics modifications are made. The quantum effects do make some changes\u2014the formula for the mass is modified, and Planck\u2019s constant \u210f appears\u2014but the answer still comes out infinite unless you cut off an integration somehow\u2014just as we had to stop the classical integrals at r=a . And the answers depend on how you stop the integrals. We cannot, unfortunately, demonstrate for you here that the difficulties are really basically the same, because we have developed so little of the theory of quantum mechanics and even less of quantum electrodynamics. So you must just take our word that the quantized theory of Maxwell\u2019s electrodynamics gives an infinite mass for a point electron. It turns out, however, that nobody has ever succeeded in making a self-consistent quantum theory out of any of the modified theories. Born and Infeld\u2019s ideas have never been satisfactorily made into a quantum theory. The theories with the advanced and retarded waves of Dirac, or of Wheeler and Feynman, have never been made into a satisfactory quantum theory. The theory of Bopp has never been made into a satisfactory quantum theory. So today, there is no known solution to this problem. We do not know how to make a consistent theory\u2014including the quantum mechanics\u2014which does not produce an infinity for the self-energy of an electron, or any point charge. And at the same time, there is no satisfactory theory that describes a non-point charge. It\u2019s an unsolved problem. In case you are deciding to rush off to make a theory in which the action of an electron on itself is completely removed, so that electromagnetic mass is no longer meaningful, and then to make a quantum theory of it, you should be warned that you are certain to be in trouble. There is definite experimental evidence of the existence of electromagnetic inertia\u2014there is evidence that some of the mass of charged particles is electromagnetic in origin. It used to be said in the older books that since Nature will obviously not present us with two particles\u2014one neutral and the other charged, but otherwise the same\u2014we will never be able to tell how much of the mass is electromagnetic and how much is mechanical. But it turns out that Nature has been kind enough to present us with just such objects, so that by comparing the observed mass of the charged one with the observed mass of the neutral one, we can tell whether there is any electromagnetic mass. For example, there are the neutrons and protons. They interact with tremendous forces\u2014the nuclear forces\u2014whose origin is unknown. However, as we have already described, the nuclear forces have one remarkable property. So far as they are concerned, the neutron and proton are exactly the same. The nuclear forces between neutron and neutron, neutron and proton, and proton and proton are all identical as far as we can tell. Only the little electromagnetic forces are different; electrically the proton and neutron are as different as night and day. This is just what we wanted. There are two particles, identical from the point of view of the strong interactions, but different electrically. And they have a small difference in mass. The mass difference between the proton and the neutron\u2014expressed as the difference in the rest-energy m c 2 in units of MeV\u2014is about 1.3 MeV, which is about 2.6 times the electron mass. The classical theory would then predict a radius of about 1 3 to 1 2 the classical electron radius, or about 10 \u221213 cm. Of course, one should really use the quantum theory, but by some strange accident, all the constants\u2014 2\u03c0 \u2019s and \u210f \u2019s, etc.\u2014come out so that the quantum theory gives roughly the same radius as the classical theory. The only trouble is that the sign is wrong! The neutron is heavier than the proton. Nature has also given us several other pairs\u2014or triplets\u2014of particles which appear to be exactly the same except for their electrical charge. They interact with protons and neutrons, through the so-called \u201cstrong\u201d interactions of the nuclear forces. In such interactions, the particles of a given kind\u2014say the \u03c0 -mesons\u2014behave in every way like one object except for their electrical charge. In Table 28\u20131 we give a list of such particles, together with their measured masses. The charged \u03c0 -mesons\u2014positive or negative\u2014have a mass of 139.6 MeV, but the neutral \u03c0 -meson is 4.6 MeV lighter. We believe that this mass difference is electromagnetic; it would correspond to a particle radius of 3 to 4\u00d7 10 \u221214 cm. You will see from the table that the mass differences of the other particles are usually of the same general size. Now the size of these particles can be determined by other methods, for instance by the diameters they appear to have in high-energy collisions. So the electromagnetic mass seems to be in general agreement with electromagnetic theory, if we stop our integrals of the field energy at the same radius obtained by these other methods. That\u2019s why we believe that the differences do represent electromagnetic mass. You are no doubt worried about the different signs of the mass differences in the table. It is easy to see why the charged ones should be heavier than the neutral ones. But what about those pairs like the proton and the neutron, where the measured mass comes out the other way? Well, it turns out that these particles are complicated, and the computation of the electromagnetic mass must be more elaborate for them. For instance, although the neutron has no net charge, it does have a charge distribution inside it\u2014it is only the net charge that is zero. In fact, we believe that the neutron looks\u2014at least sometimes\u2014like a proton with a negative \u03c0 -meson in a \u201ccloud\u201d around it, as shown in Fig. 28\u20135. Although the neutron is \u201cneutral,\u201d because its total charge is zero, there are still electromagnetic energies (for example, it has a magnetic moment), so it\u2019s not easy to tell the sign of the electromagnetic mass difference without a detailed theory of the internal structure. We only wish to emphasize here the following points: (1) the electromagnetic theory predicts the existence of an electromagnetic mass, but it also falls on its face in doing so, because it does not produce a consistent theory\u2014and the same is true with the quantum modifications; (2) there is experimental evidence for the existence of electromagnetic mass; and (3) all these masses are roughly the same as the mass of an electron. So we come back again to the original idea of Lorentz\u2014maybe all the mass of an electron is purely electromagnetic, maybe the whole 0.511 MeV is due to electrodynamics. Is it or isn\u2019t it? We haven\u2019t got a theory, so we cannot say. We must mention one more piece of information, which is the most annoying. There is another particle in the world called a muon which, so far as we can tell, differs in no way whatsoever from an electron except for its mass. It acts in every way like an electron: it interacts with neutrinos and with the electromagnetic field, and it has no nuclear forces. It does nothing different from what an electron does\u2014at least, nothing which cannot be understood as merely a consequence of its higher mass ( 206.77 times the electron mass). Therefore, whenever someone finally gets the explanation of the mass of an electron, he will then have the puzzle of where a muon gets its mass. Why? Because whatever the electron does, the muon does the same\u2014so the mass ought to come out the same. There are those who believe faithfully in the idea that the muon and the electron are the same particle and that, in the final theory of the mass, the formula for the mass will be a quadratic equation with two roots\u2014one for each particle. There are also those who propose it will be a transcendental equation with an infinite number of roots, and who are engaged in guessing what the masses of the other particles in the series must be, and why these particles haven\u2019t been discovered yet. We would like to make some further remarks about the part of the mass of nuclear particles that is not electromagnetic. Where does this other large fraction come from? There are other forces besides electrodynamics\u2014like nuclear forces\u2014that have their own field theories, although no one knows whether the current theories are right. These theories also predict a field energy which gives the nuclear particles a mass term analogous to electromagnetic mass; we could call it the \u201c \u03c0 -mesic-field-mass.\u201d It is presumably very large, because the forces are great, and it is the possible origin of the mass of the heavy particles. But the meson field theories are still in a most rudimentary state. Even with the well-developed theory of electromagnetism, we found it impossible to get beyond first base in explaining the electron mass. With the theory of the mesons, we strike out. We may take a moment to outline the theory of the mesons, because of its interesting connection with electrodynamics. In electrodynamics, the field can be described in terms of a four-potential that satisfies the equation \u25a1 2 A \u03bc =sources. 2 Now we have seen that pieces of the field can be radiated away so that they exist separated from the sources. These are the photons of light, and they are described by a differential equation without sources: \u25a1 2 A \u03bc =0. 2 People have argued that the field of nuclear forces ought also to have its own \u201cphotons\u201d\u2014they would presumably be the \u03c0 -mesons\u2014and that they should be described by an analogous differential equation. (Because of the weakness of the human brain, we can\u2019t think of something really new; so we argue by analogy with what we know.) So the meson equation might be \u25a1 2 \u03d5=0, 2 where \u03d5 could be a different four-vector or perhaps a scalar. It turns out that the pion has no polarization, so \u03d5 should be a scalar. With the simple equation \u25a1 2 \u03d5=0 , the meson field would vary with distance from a source as 1/ r 2 , just as the electric field does. But we know that nuclear forces have much shorter distances of action, so the simple equation won\u2019t work. There is one way we can change things without disrupting the relativistic invariance: we can add or subtract from the d\u2019Alembertian a constant, times \u03d5 . So Yukawa suggested that the free quanta of the nuclear force field might obey the equation \u2212 \u25a1 2 \u03d5\u2212 \u03bc 2 \u03d5=0, (28.17) where \u03bc 2 is a constant\u2014that is, an invariant scalar. (Since \u25a1 2 is a scalar differential operator in four dimensions, its invariance is unchanged if we add another scalar to it.) Let\u2019s see what Eq. (28.17) gives for the nuclear force when things are not changing with time. We want a spherically symmetric solution of \u2207 2 \u03d5\u2212 \u03bc 2 \u03d5=0 2 around some point source at, say, the origin. If \u03d5 depends only on r , we know that \u2207 2 \u03d5= 1 r \u2202 2 \u2202 r 2 (r\u03d5). 2 So we have the equation 1 r \u2202 2 \u2202 r 2 (r\u03d5)\u2212 \u03bc 2 \u03d5=0 2 or \u2202 2 \u2202 r 2 (r\u03d5)= \u03bc 2 (r\u03d5). 2 Thinking of (r\u03d5) as our dependent variable, this is an equation we have seen many times. Its solution is r\u03d5=K e \u00b1\u03bcr . \u00b1 r Clearly, \u03d5 cannot become infinite for large r , so the + sign in the exponent is ruled out. The solution is \u03d5=K e \u2212\u03bcr r . (28.18) This function is called the Yukawa potential. For an attractive force, K is a negative number whose magnitude must be adjusted to fit the experimentally observed strength of the forces. The Yukawa potential of the nuclear forces dies off more rapidly than 1/r by the exponential factor. The potential\u2014and therefore the force\u2014falls to zero much more rapidly than 1/r for distances beyond 1/\u03bc , as shown in Fig. 28\u20136. The \u201crange\u201d of nuclear forces is much less than the \u201crange\u201d of electrostatic forces. It is found experimentally that the nuclear forces do not extend beyond about 10 \u221213 cm, so \u03bc\u2248 10 15 m \u22121 . Finally, let\u2019s look at the free-wave solution of Eq. (28.17). If we substitute \u03d5= \u03d5 0 e i(\u03c9t\u2212kz) i ( k ) into Eq. (28.17), we get that \u03c9 2 c 2 \u2212 k 2 \u2212 \u03bc 2 =0. 2 Relating frequency to energy and wave number to momentum, as we did at the end of Chapter 34 of Vol. I, we get that E 2 c 2 \u2212 p 2 = \u03bc 2 \u210f 2 , 2 which says that the Yukawa \u201cphoton\u201d has a mass equal to \u03bc\u210f/c . If we use for \u03bc the estimate 10 15 m \u22121 , which gives the observed range of the nuclear forces, the mass comes out to 3\u00d7 10 \u221225 g, or 170 MeV, which is roughly the observed mass of the \u03c0 -meson. So, by an analogy with electrodynamics, we would say that the \u03c0 -meson is the \u201cphoton\u201d of the nuclear force field. But now we have pushed the ideas of electrodynamics into regions where they may not really be valid\u2014we have gone beyond electrodynamics to the problem of the nuclear forces."
    },
    {
        "input": "Laws and IntuitionReview Lecture B",
        "output": "Last time we discussed the mathematics that you need to know to do the physics, and I pointed out that equations should be memorized as a tool, but that it isn\u2019t a good idea to memorize everything. In fact, it\u2019s impossible in the long run to do everything by memory. That doesn\u2019t mean to do nothing by memory\u2014the more you remember, in a certain sense, the better it is\u2014but you should be able to re-create anything that you forgot. Incidentally, on the subject of suddenly finding yourself below average when you come to Caltech, which we also discussed last time, if you somehow escape from being in the bottom half of the class, you\u2019re just making it miserable for somebody else, because now you\u2019re forcing somebody else. to go down to the bottom half! But there is a way you can do it without disturbing anybody: find and pursue something interesting that delights you especially, so you become a kind of temporary expert in some phenomenon that you heard about. It\u2019s the way to save your soul\u2014then you can always say, \u201cWell, at least the other guys don\u2019t know anything about this!\u201d Now, in this review, I\u2019m going to talk about the physical laws, and the first thing to do is to state what they are. We stated them in words a lot during the lectures so far, and it\u2019s hard to say it all again without using the same amount of time, but the physical laws can also be summarized by some equations, which I\u2019ll write down here. (By this time I\u2019ll suppose that your mathematics is developed to a point that you can understand the notation right away.) The following are all the physical laws that you should know. First: F= dp dt . That is, the force, F, is equal to the rate of change, with respect to time, of the momentum, p. (F and p are vectors. You\u2019re supposed to know what the symbols mean by this time.) I\u2019d like to emphasize that in any physical equation it is necessary to understand what the letters stand for. That doesn\u2019t mean to say, \u201cOh, I know that\u2019s p, which stands for the mass in motion times the velocity, or the mass at rest times the velocity over the square root of 1 minus v squared over c squared:\u201d1 p= mv \u221a 1\u2212v2/c2 . Instead, to understand physically what the p stands for, you have to know that p is not just \u201cthe momentum\u201d; it\u2019s the momentum of something\u2014the momentum of a particle whose mass is m and whose velocity is v. And, in Eq. (2.1), F is the total force\u2014the vector sum of all the forces that are acting on that particle. Only then can you have an understanding of these equations. Now, here\u2019s another physical law that you should know, called the conservation of momentum: \u2211 particles pafter= \u2211 particles pbefore. The law of conservation of momentum says that the total momentum is a constant in any situation. What does that mean, physically? For instance in a collision, it\u2019s the same as saying that the sum of the momenta of all the particles before a collision is the same as the sum of the momenta of all the particles after the collision. In the relativistic world, the particles can be different after the collision\u2014you can create new particles and destroy old ones\u2014but it\u2019s still true that the vector sum of the total momenta of everything before and after is the same. The next physical law you should know, called the conservation of energy, takes the same form: \u2211 particles Eafter= \u2211 particles Ebefore. That is, the sum of the energies of all the particles before a collision is equal to the sum of the energies of all the particles after the collision. In order to use this formula, you have to know what the energy of a particle is. The energy of a particle with rest mass m and speed v is E= mc2 \u221a 1\u2212v2/c2 . Now, those are the laws that are correct in the relativistic world. In the nonrelativistic approximation\u2014that is, if we look at particles at low velocity compared to the speed of light\u2014then there are some special cases of the above laws. To begin with, the momentum at low velocities is easy: \u221a 1\u2212v2/c2 is almost 1 , so Eq. (2.2) becomes p=mv. That means the formula for the force, F=dp/dt , can also be written F=d(mv)/dt Then, by moving the constant, m , out in front, we see that for low velocities, the force equals the mass times the acceleration: F= dp dt = d(mv) dt =m dv dt =ma. The conservation of momentum for particles at low velocities has the same form as Eq. (2.3), except that the formula for the momenta is p=mv (and the masses are all constant): \u2211 particles (mv)after= \u2211 particles (mv)before. However, the conservation of energy at low velocities becomes two laws: first, that the mass of each particle is constant\u2014you can\u2019t create or destroy any material\u2014and second, that the sum of the 1 2 mv2s (the total kinetic energy, or K.E.) of all the particles is constant:2 mafter =mbefore \u2211 particles ( 1 2 mv2)after = \u2211 particles ( 1 2 mv2)before If we think of large, everyday objects as particles with low velocities\u2014like an ashtray is a particle, approximately\u2014then the law that the sum of the kinetic energies before equals the sum after is not true, because there can be some 1 2 mv2s of the particles all mixed up on the inside of the objects, in the form of internal motion\u2014heat, for example. So in a collision between large objects, this law appears to fail. It\u2019s only true for fundamental particles. Of course with large objects, it can happen that not much energy goes into the internal motion, so the conservation of energy appears to be nearly true, and that\u2019s called a nearly elastic collision\u2014which is sometimes idealized as a perfectly elastic collision. So energy is much more difficult to keep track of than momentum, because the conservation of kinetic energy needn\u2019t be true when the objects involved are large, like weights and so on, that have inelastic collisions. Now, if we look not at a collision, but at motion when forces act\u2014then we get first a theorem that tells us that the change in kinetic energy of a particle is equal to the work done on it by the forces: \u0394K.E.=\u0394W. Remember, this means something\u2014you have to know what all the letters mean: it means that if a particle is moving on some curve, S , from point A to point B , and it\u2019s moving under the influence of a force F , where F is the total force acting on the particle, then if you knew what the 1 2 mv2 of the particle is at point A , and what it is over at point B , they differ by the integral, from A to B , of F\u22c5ds where ds is an increment of displacement along S . (See Fig. 2-1). \u0394K.E.= 1 2 mv 2 B \u2212 1 2 mv 2 A and \u0394W=\u222b B A F\u22c5ds. In certain cases, that integral can be calculated easily ahead of time, because the force on the particle depends only on its position in a simple way. Under those circumstances we can write that the work done on the particle is equal in magnitude and opposite to the change in another quantity called its potential energy, or P.E . Such forces are said to be \u201cconservative\u201d: \u0394W=\u2212\u0394P.E.(with a conservative force, F). Incidentally, the words that we use in physics are terrible: \u201cconservative forces\u201d doesn\u2019t mean that the forces are conserved, but rather that the forces are such that the energy of the things that the forces work on can be conserved.3 It\u2019s very confusing, I admit, and I can\u2019t help it. The total energy of a particle is its kinetic energy plus its potential energy: E=K.E+P.E. When only conservative forces act, a particle\u2019s total energy does not change: (with conservative forces). \u0394E=\u0394K.E.+\u0394P.E.=0(with conservative forces). But when nonconservative forces act\u2014forces not included in any potential\u2014then the change in a particle\u2019s energy is equal to the work done on it by those forces. \u0394E=\u0394W(with nonconservative forces). Now, the end of this part of the review comes when we give all the rules that are known for the various forces. But before I do that, there\u2019s a formula for acceleration that is very useful: if, at a given instant, a thing is moving on a circle of radius r at constant speed v , then its acceleration is directed towards the center, and is equal in magnitude to v 2 /r (See Fig. 2-2.) That\u2019s sort of at \u201cright angles\u201d to everything else I\u2019ve been talking about, but it\u2019s good to remember that formula, because it\u2019s a pain in the neck to derive it:4 |a|= v 2 r . (2.17) Now, to get back on the track, I will list a series of laws of force, and the formulas for their potentials. First is surface gravity on the earth. The force is down, but never mind the sign; just remember which direction the force is, because who knows what your axes are\u2014maybe you\u2019re making the z axis down! (You\u2019re allowed to.) So the force is \u2212mg , and potential energy is mgz , where m is the mass of an object, g is a constant (the acceleration of gravity at the surface of the earth\u2014otherwise, the formula is no good!), and z is the height above the ground, or any other level. That means the value of the potential energy can be zero any place you want. The way we\u2019re going to use potential energy is to talk about its changes\u2014and then, of course, it doesn\u2019t make any difference if you add a constant. Next is gravity in space between particles; this force is directed centrally, and is proportional to the product of the one mass by the other mass divided by the distance between the two squared, \u2212m m \u2032 / r 2 , or \u2212 m 1 m 2 / r 2 , or any other way you want to write it. It\u2019s better to just remember which direction the force is, than to worry about the sign. But this part you\u2019ve got to remember: the force of gravity goes as the inverse square of the distance between the particles. (So which way is the sign? Well, likes attract in gravity, so the force is in the opposite direction to the radius vector. That shows you that I don\u2019t remember the sign; I just remember physically which way the sign is: the particles attract\u2014that\u2019s all I have to remember.) Now, the potential energy between two particles is \u2212G m 1 m 2 /r . It\u2019s hard for me to remember which way the potential energy goes. Let\u2019s see: the particles lose potential energy when they come together, so that means when r is smaller, the potential energy should be less, so it\u2019s negative\u2014I hope that\u2019s right! I have a great deal of difficulty with signs. For electricity, the force is proportional to the product of the charges, q 1 and q 2 , divided by the distance between them squared. But the constant of proportionality, instead of being written in the numerator (as with gravity), is written as 4\u03c0 \u03f5 0 in the denominator. The electrical force is directed radially, just like gravitation is, but with the opposite law of sign: likes repel, electrically, and therefore the sign of electrical potential energy is opposite that of gravitational potential energy, but then the constant of proportionality is different: 1/4\u03c0 \u03f5 0 instead of G . Some technical points from the laws of electricity: the force on q units of charge can be written as q times the electric field, qE , and the energy can be written as q times the electrical potential, q\u03d5 . Here, E is a vector field and \u03d5 is a scalar field. q is measured in coulombs, and \u03d5 is measured in volts\u2014when the energy is in the usual units of joules. To continue this table of formulas, we have next an ideal spring. The force to pull out an ideal spring to a distance x is a constant, k , times x . Now, you have to know what the letters mean again: x is the distance that you pull the spring away from the equilibrium position, and the force pulls it back an amount \u2212kx . I put the sign in just to say the spring pulls backwards; you know damn well a spring pulls a thing back, and doesn\u2019t push it out further when you pull on it. Now, the potential energy is 1 2 k x 2 In order to pull out a spring you do work on it, so after it\u2019s pulled out, the potential energy is plus. So this sign business is easy\u2014for the spring. You see, details like the signs that I can\u2019t remember, I try to reconstruct by arguments\u2014that\u2019s how I remember all the things I don\u2019t remember. Friction: the force of friction against a dry surface is \u2212\u03bcN , and again you have to know what the symbols mean: when an object is pushed against another surface with a force whose component perpendicular to the surface is N , then in order to keep it sliding along the surface, the force required is \u03bc times N . You can easily figure out which direction the force is; it\u2019s opposite to the direction you slide it. Now, under the potential energy for friction in Table 2-3, the answer is No: friction does not conserve energy, and therefore we have no formula for the potential energy for friction. If you push an object along a surface one way, you do work; then, when you drag it back, you do work again. So after you\u2019ve gone through a complete cycle, you haven\u2019t come out with no energy change; you\u2019ve done work\u2014and so friction has no potential energy. Those are all the rules I can remember as being necessary. So you say, \u201cWell, that\u2019s very easy: I\u2019ll just memorize the whole damn table, and then I\u2019ll know all the physics.\u201d Well, it won\u2019t work. Actually, it might work fairly well at the beginning, but it gets harder and harder, as I pointed out in Chapter 1. Therefore, what we have to learn next is how to apply the mathematics to the physics in order to understand the world. The equations keep track of things for us, so we use them as tools\u2014but to do that, we have to know what objects the equations are talking about. The problem of how to deduce new things from old, and how to solve problems, is really very difficult to teach, and I don\u2019t really know how to do it. I don\u2019t know how to tell you something that will transform you from a person who can\u2019t analyze new situations or solve problems, to a person who can. In the case of the mathematics, I can transform you from somebody who can\u2019t differentiate to somebody who can, by giving you all the rules. But in the case of the physics, I can\u2019t transform you from somebody who can\u2019t to somebody who can, so I don\u2019t know what to do. Because I intuitively understand what\u2019s going on physically, I find it difficult to communicate: I can only do it by showing you examples. Therefore, the rest of this lecture, as well as the next one, will consist of doing a whole lot of little examples\u2014of applications, of phenomena in the physical world or in the industrial world, of applications of physics in different places\u2014to show you how what you already know will permit you to understand or to analyze what\u2019s going on. Only from the examples will you be able to catch on. We have found many old texts of ancient Babylonian mathematics. Among them is a great library full of mathematics workbooks for students. And it\u2019s very interesting: the Babylonians could solve quadratic equations; they even had tables for solving cubic equations. They could do triangles (See Fig. 2-3); they could do all kinds of things, but they never wrote down an algebraic formula. The ancient Babylonians had no way of writing formulas; instead, they did one example after the other\u2014that\u2019s all. The idea was you\u2019re supposed to look at examples until you get the idea. That\u2019s because the ancient Babylonians didn\u2019t have the power of expression in mathematical form. Today we do not have the power of expression to tell a student how to understand physics physically! We can write the laws, but we still can\u2019t say how to understand them physically. The only way you can understand physics physically, because of our lack of machinery for expressing this, is to follow the dull, Babylonian way of doing a whole lot of problems until you get the idea. That\u2019s all I can do for you. And the students who didn\u2019t get the idea in Babylonia flunked, and the guys who did get the idea died, so it\u2019s all the same! So, now we try. The first problem that I mentioned in Chapter 1 involved a lot of physical things. There were two rods, a roller, a pivot, and a weight\u2014it was 2 kg, I believe. The geometrical relation of the rods was 0.3 , 0.4 , and 0.5 , and the problem was, what is the horizontal force P required at the roller to hold the weight up, as shown in Figure 2-4? It took a little fiddling around (in fact, I had to do it twice before I got it right), but we found that the horizontal force on the roller corresponded to a weight of 3 4 kg, as shown in Figure 2-5. Now, if you just let yourself loose of the equations and think about it a while, and you pull back your sleeves and wave your arms, you can almost understand what the answer\u2019s going to be\u2014at least I can. Now, I have to teach you how to do that. You could say, \u201cWell, the force from the weight comes straight down, and it corresponds to 2 kg, and the weight is balanced equally on two legs. So the vertical force from each leg must be enough to hold up 1 kg. Now, the corresponding horizontal force on each leg must be the fraction of the vertical force that is merely the horizontal to vertical ratio in this right triangle, which is 3 to 4 . Therefore, the horizontal force on the roller corresponds to 3 4 kg weight\u2014period.\u201d Now, let\u2019s see if it makes sense: according to that idea, if the roller were shoved much closer to the pivot, so that the distance between the legs was much smaller, I would expect much less force on the roller. Is it true, that when the weight is waaaaay up there, the force on the roller should be low? Yeah! (See Fig. 2-6.) If you can\u2019t see it, it\u2019s hard to explain why\u2014but if you try to hold something up with a ladder, say, and you get the ladder directly under the thing, it\u2019s easy to keep the ladder from sliding out. But if the ladder is leaning way out at an angle, it\u2019s damn hard to keep the thing up! In fact, if you go waaaaay out, so that the far end of the ladder is only a very tiny distance from the ground, you\u2019ll find a nearly infinite horizontal force is required to hold the thing up at a very slight angle. Now, all these things you can feel. You don\u2019t have to feel them; you can work them out by making diagrams and calculations, but as problems get more and more difficult, and as you try to understand nature in more and more complicated situations, the more you can guess at, feel, and understand without actually calculating, the much better off you are! So that\u2019s what you should practice doing on the various problems: when you have time somewhere, and you\u2019re not worried about getting the answer for a quiz or something, look the problem over and see if you can understand the way it behaves, roughly, when you change some of the numbers. Now, how to explain how to do that, I don\u2019t know. I remember once trying to teach somebody who was having a great deal of trouble taking the physics course, even though he did well in mathematics. A good example of a problem that he found impossible to solve was this: \u201cThere\u2019s a round table on three legs. Where should you lean on it, so the table will be the most unstable?\u201d The student\u2019s solution was, \u201cProbably on top of one of the legs, but let me see: I\u2019ll calculate how much force will produce what lift, and so on, at different places.\u201d Then I said, \u201cNever mind calculating. Can you imagine a real table?\u201d \u201cBut that\u2019s not the way you\u2019re supposed to do it!\u201d \u201cNever mind how you\u2019re supposed to do it; you\u2019ve got a real table here with the various legs, you see? Now, where do you think you\u2019d lean? What would happen if you pushed down directly over a leg?\u201d \u201cNothin\u2019!\u201d I say, \u201cThat\u2019s right; and what happens if you push down near the edge, halfway between two of the legs?\u201d \u201cIt flips over!\u201d I say, \u201cOK! That\u2019s better!\u201d The point is that the student had not realized that these were not just mathematical problems; they described a real table with legs. Actually, it wasn\u2019t a real table, because it was perfectly circular, the legs were straight up and down, and so on. But it nearly described, roughly speaking, a real table, and from knowing what a real table does, you can get a very good idea of what this table does without having to calculate anything\u2014you know darn well where you have to lean to make the table flip over. So, how to explain that, I don\u2019t know! But once you get the idea that the problems are not mathematical problems but physical problems, it helps a lot. Now I\u2019m going to apply this approach to a series of problems: first, in machine design; second, to motions of satellites; third, to the propulsion of rockets; fourth, to beam analyzers, and then, if I still have time, to the disintegration of pi mesons, and a couple of other things. All these problems are pretty difficult, but they illustrate various points as we go along. So, let\u2019s see what happens. First, machine design. Here\u2019s the problem: there are two pivoted rods, each a half a meter long, which carry a weight of 2 kg\u2014sound familiar?\u2014and at the left a roller is being driven back or forth by some machinery at a constant velocity of 2 meters per second, OK? And the question for you is, what is the force required to do that when the height of the weight is 0.4 meters? (See Fig. 2-7.) You might be thinking, \u201cWe did that already! The horizontal force required to balance the weight was 3 4 of a 1 kg weight.\u201d But I argue, \u201cThe force is not 3 4 kg, because the weight is moving.\u201d You might counter, \u201cWhen an object is moving, is a force required to keep it moving? No!\u201d \u201cBut a force is required to change the object\u2019s motion.\u201d \u201cYes, but the roller is moving at a constant velocity!\u201d \u201cAh, yes, that\u2019s true: the roller is moving at a constant velocity of 2 meters per second. But what about the weight: is that moving at a constant velocity? Let\u2019s feel it: does the weight move slowly sometimes, and fast sometimes?\u201d \u201cYes . . . \u201d \u201cThen its motion is changing\u2014and that\u2019s the problem we have: to figure out the force required to keep the roller moving constantly at 2 meters per second when the weight is at a height of 0.4 meters.\u201d Let\u2019s see if we can understand how the weight\u2019s motion is changing. Well, if the weight is near the top and the roller is almost directly underneath it, the weight hardly moves up and down. In this position the weight is not moving very fast. But if the weight is down low, like we had before, and you push the roller just a shade to the right\u2014boy, that weight has to move way up to get out of the way! So, as we push the roller, the weight starts moving up very fast, and then slows down, correct? If it\u2019s going up very fast and it gets slower, which way is the acceleration, then? The acceleration must be down: it\u2019s like I threw it up fast and it slowed down\u2014like it\u2019s falling, sort of, so that the force must be reduced. That is, the horizontal force I\u2019m going to get on the roller is going to be less than it would be if it weren\u2019t moving. So we have to figure out how much less. (The reason I went through all this is that I couldn\u2019t keep the signs right in the equations, so I had at the end to figure out which way the sign was by this physical argument.) Incidentally, I have done this problem about four times\u2014making a mistake every time\u2014but I have, at last, got it right. I appreciate that when you do a problem the first time, there are many, many things that get confused: I got the numbers mixed up, I forgot to square, I put the sign of the time wrong, and I did a lot of other things wrong, but anyway, now I have it right, and I can show you how it can be done correctly\u2014but I must admit, frankly, that it took me quite a while to get it right. (Boy, I\u2019m glad I\u2019ve still got my notes!) Now, in order to calculate the force, we need the acceleration. It\u2019s impossible to find the acceleration by just looking at the diagram, with all dimensions fixed at the time of interest. To find the rate of change, we can\u2019t leave it fixed\u2014I mean, we can\u2019t say, \u201cWell, this is 0.3 , this is 0.4 , this is 0.5 , this is 2 meters per second, what\u2019s the acceleration?\u201d There\u2019s no easy way to get at that. The only way to find the acceleration is to find the general motion and differentiate it with respect to time.5 Then we can put in the value of the time that corresponds to this particular diagram. So I need, therefore, to analyze this thing in a more general circumstance, when the weight is at some arbitrary position. Let\u2019s say the pivot and the roller are together at time t=0 , and that the distance between them is 2t , because the roller is moving at 2 meters per second. The time when we want to make the analysis is 0.3 seconds before they\u2019re together, which is t=\u22120.3 , and so the distance between them is actually negative 2t \u2014but it\u2019ll be all right if we use t=0.3 and let the distance be 2t . There will be a lot of signs wrong at the end, but because of my little fishing around at the beginning as to what the right sign was for the force, I\u2019ll be all right\u2014I\u2019d rather leave the mathematics alone and get the sign right from physics, than the other way around. Anyhow, here we are. (Don\u2019t you do this; it\u2019s too difficult\u2014it takes practice!) (Remember what the t means: t is the time before the pivots are together, which is sort of a negative time, which will make everybody crazy, but I can\u2019t help it\u2014this is the way I did it.) Now, the geometry is such that the weight is always (horizontally) halfway between the roller and the pivot. So, if we put the origin of our coordinate system at the pivot, then the x coordinate of the weight is x= 1 2 (2t)=t . The length of the rods is 0.5 , so for the height of the weight, its y coordinate, I got y= 0.25\u2212 t 2 \u2212 \u2212 \u2212 \u2212 \u2212 \u2212 \u2212 \u221a , by the Pythagorean theorem. (See Fig. 2-8.) Can you imagine, the first time I worked this problem out, very carefully, I got y= 0.25+ t 2 \u2212 \u2212 \u2212 \u2212 \u2212 \u2212 \u2212 \u221a ? Now we need the acceleration, and the acceleration has two components: one is the horizontal acceleration, and the other is the vertical acceleration. If there\u2019s a horizontal acceleration, then there\u2019s a horizontal force, and we\u2019ve got to chase that down through the rod and figure out what it is on the roller. This problem is a little easier than it looks because there is no horizontal acceleration\u2014the x coordinate of the weight is always half that of the roller; it moves in the same direction, but at half its speed. So, the weight moves horizontally at a constant 1 meter per second. There\u2019s no acceleration sideways, thank god! That makes the problem a little easier; we only have to worry about the up and down acceleration. Therefore to get the acceleration, I must differentiate the height of the weight twice: once to get the velocity in the y direction, and again, to get the acceleration. The height is y= 0.25\u2212 t 2 \u2212 \u2212 \u2212 \u2212 \u2212 \u2212 \u2212 \u221a . You should be able to differentiate this fast, and the answer is y \u2032 = \u2212t 0.25\u2212 t 2 \u2212 \u2212 \u2212 \u2212 \u2212 \u2212 \u2212 \u221a (2.18) It\u2019s negative, even though the weight is moving up. But I got my signs all bungled up, so I\u2019ll leave it this way; anyway, I know the speed is up, so this would be wrong if t were positive, but t should really be negative\u2014so it\u2019s right anyway. Now, we calculate the acceleration. There are several ways you can do this: You can do it using ordinary methods, but I\u2019ll use the new \u201csuper\u201d method I showed you in Chapter 1: you write down y \u2032 again; then you say, \u201cThe first term that I want to differentiate is to the first power, \u2212t . Derivative of \u2212t is \u22121 . The next term that I want to differentiate is to the minus one-half power; the term is 0.25\u2212 t 2 . The derivative is \u22122t . Done!\u201d y \u2032 y \u2032\u2032 =\u2212t(0.25\u2212 t 2 ) \u22121/2 =\u2212t(0.25\u2212 t 2 ) \u22121/2 \u00d7 [1\u22c5 \u22121 (\u2212t) \u2212 1 2 \u22c5 \u22122t (0.25\u2212 t 2 ) ] (2.19) Now we have the acceleration at any time. In order to find the force, we need to multiply it by the mass. So, the force\u2014that is, the extra force besides gravity that\u2019s involved because of the acceleration\u2014is the mass, which is 2 kilograms, times this acceleration. Let\u2019s put the numbers into this thing: t is 0.3 . The square root of 0.25\u2212 t 2 is the square root of 0.25 minus 0.09 , which is 0.16 , the square root of which is 0.4 \u2014well, how convenient! Is that right? Yes indeed, sir; this square root is the same as y itself, and when t is 0.3 , according to our diagram, y is 0.4 . OK, no mistake. (I\u2019m always checking things while I calculate because I make so many mistakes. One way to check it is to do the mathematics very carefully; the other way to check it is to keep seeing whether the numbers that come out are sensible, whether they describe what\u2019s really happening.) Now we calculate. (The first time I did this I put 0.25\u2212 t 2 =0.4 instead of 0.16 \u2014it took me a while to find that one!) We get some number6 or other, which I have worked out; it\u2019s about 3.9 . So, the acceleration is 3.9 , and now for the force: the vertical force that this acceleration corresponds to is 3.9 times 2 kilograms times g . No, that\u2019s not right! I forgot there\u2019s no g now; 3.9 is the true acceleration. The vertical force of gravity is 2 kg times the acceleration due to gravity, 9.8 \u2014that\u2019s g \u2014and the vertical component of the force of the rod on the weight is the sum of these two, with a minus sign for one; the relative signs are opposite. So, you subtract, and you get F w =ma\u2212mg=7.8\u221219.6 =\u221211.8 newtons. (2.20) But remember, now, this is the vertical force on the weight. How much is the horizontal force on the roller? The answer is, the horizontal force on the roller is three-quarters of one-half of the vertical force on the weight. We noticed that before: the force pulling down is balanced by the two legs, which divides it by two, and then the geometry is such that the ratio of the horizontal component to the vertical component is 3 4 \u2014and so the answer is that the horizontal force on the roller is three-eighths of the vertical force on the weight. I worked out the three-eighths of each of these things, and I got 7.35 for gravity, and 2.925 for the term due to the acceleration, and the difference is 4.425 newtons\u2014about 3 newtons less than the force required to support the weight in the same position when it was not moving. (See Fig. 2-9.) Anyway, that\u2019s how you design machines; you know how much force you need to drive that thing forward. Now, you say, is that the correct way do to it? There is no such thing! There is no \u201ccorrect\u201d way to do anything. A particular way of doing it may be correct, but it is not the correct way. You can do it any damn way you want! (Well, excuse me: there are incorrect ways to do things . . . ) Now, if I were sufficiently smart, I could just look at this thing and tell you what the force is, but I\u2019m not sufficiently smart, so I had to do it some way or other\u2014but there are many ways of doing it. I will illustrate one other way, which is very useful, especially if you are involved in designing real machines. This problem is somewhat simplified by having the legs equal, and so on, because I didn\u2019t want to complicate the arithmetic. But the physical ideas are such that you can figure the whole thing out another way, even when the geometry is not so simple. And that is the following, interesting, other way. When you have a whole lot of levers moving a lot of weights, you can do this: as you drive the thing along, and all the weights begin to move because of all the levers, you\u2019re doing a certain amount of work, W . At any given time there\u2019s a certain power going in, which is the rate at which you are working, dW/dt . At the same time, the energy of all the weights, E , is changing at some rate, dE/dt , and those should match each other; that is, the rate at which you put work in should match the rate of change of the total energy of all of the weights: dE dt = dW dt . (2.21) As you may recall from the lectures, power is equal to force times velocity:7 dW dt = F\u22c5ds dt =F\u22c5 ds dt =F\u22c5v. (2.22) And so, we have dE dt =F\u22c5v. (2.23) The idea, then, is that at a given instant the weights have some kind of a speed, and thus they have a kinetic energy. They also have a certain height above the ground, and so they have a potential energy. So if we can figure out how fast the weights are moving and where they are, in order to get their total energy, and then we differentiate that with respect to time, that would be equal to the product of the component of force in the direction that the thing being worked on is moving, times its speed. Let\u2019s see if we can apply that to our problem. Now, when I push on the roller with a force P=\u2212 F R while moving it at a velocity v R , the rate of change of the energy of the whole darn thing, with respect to time, should equal the magnitude of the force times the speed, F R v R because in this case the force and the velocity are both in the same direction. It\u2019s not a general formula; if I had asked you for the force in some other direction, I couldn\u2019t have gotten it by this argument directly because this method only gives you the component of the force that does the work! (Of course, you can get it indirectly because you can know the force is going along the rod. If there were several more rods connected, this method would still work, provided you took the force in a direction of motion.) What about all the work done by all the forces of the constraints\u2014the roller, the pivots, and all the other machinery that holds this stuff in the right motion? No work is done by them, provided they aren\u2019t worked on by other forces as they go along. For example, if somebody else is sitting over there, pulling one leg out while I\u2019m pushing the other one in, I\u2019ve got to take the work done by the other guy into account! But nobody\u2019s doing that, so, with v R =2 , we have dE dt =2 F R . (2.24) So I\u2019m all set if I can calculate dE/dt \u2014divide by two, and lo and behold: the force! Ready? Let\u2019s go! Now, we have the total energy of the weight in two pieces: kinetic energy plus potential energy. Well, the potential energy is easy: it\u2019s mgy (see Table 2-3). We already know that y is 0.4 meters, m is 2 kg, and g is 9.8 meters per second squared. So the potential energy is 2\u00d79.8\u00d70.4=7.84 joules. And now the kinetic energy: well, after a lot of fiddling around, I\u2019ll get the velocity of the weight, and I\u2019ll write in the kinetic energy for that; we\u2019ll do that in just a second. Then I\u2019m all set because I\u2019ll have the total energy. I\u2019m not all set: unfortunately, I don\u2019t want the energy! I need the derivative of the energy with respect to time, and you cannot find how fast something changes by figuring out how much it is right now! You\u2019ve either got to figure it out at two adjacent times\u2014now, and an instant later\u2014or, if you want to use the mathematical form, you figure it out for an arbitrary time, t , and differentiate with respect to t . It depends on which is the easiest to do: it may be numerically much easier to figure out the geometry for two positions than it is to figure out the geometry in general, and to differentiate. (Most people immediately try to put a problem in mathematical form and differentiate it because they don\u2019t have enough experience with arithmetic to appreciate the tremendous power and ease of doing calculations with numbers instead of letters. Nevertheless, we\u2019ll do it with letters.) Again, we have to solve this problem, where x=t , and y= 0.25\u2212 t 2 \u2212 \u2212 \u2212 \u2212 \u2212 \u2212 \u2212 \u221a , so that we will be able to calculate the derivative. Now, we need the potential energy. That we can get very easily: it\u2019s mg times the height, y , and that comes out to P.E.=mgy =2 kg\u00d79.8 m/ s 2 \u00d7 0.25\u2212 t 2 \u2212 \u2212 \u2212 \u2212 \u2212 \u2212 \u2212 \u221a m =19.6 newtons\u00d7 0.25\u2212 t 2 \u2212 \u2212 \u2212 \u2212 \u2212 \u2212 \u2212 \u221a m =19.6 0.25\u2212 t 2 \u2212 \u2212 \u2212 \u2212 \u2212 \u2212 \u2212 \u221a joules. (2.25) But more interesting, and harder to figure out, is the kinetic energy. The kinetic energy is 1 2 m v 2 . To figure out the kinetic energy, I need to figure out the velocity squared, and that takes a lot of fooling around: the velocity squared is its x component squared plus its y component squared. I could figure out the y component just like I did before; the x component, I\u2019ve already pointed out, is 1 , and I could have squared those and added them together. But supposing I hadn\u2019t already done that, and I wanted to think of still another way to get the velocity. Well, after thinking about it, a good machine designer usually can figure it out from the principles of geometry and the layout of the machinery. For example, since the pivot is stationary, the weight must move around it in a circle. So, in which direction must the velocity of the weight be? It can have no velocity parallel to the rod, because that would change the length of the rod, right? Therefore, the velocity vector is perpendicular to the rod. (See Fig. 2-10.) You might say to yourself, \u201cOoh! I have to learn that trick!\u201d No. That trick is only good for a special kind of problem; it doesn\u2019t work most of the time. Very rarely do you happen to need the velocity of something that is rotating around a fixed point; there\u2019s no rule that says, \u201cvelocities are perpendicular to rods,\u201d or anything like that. You have to use common sense as often as possible. It\u2019s the general idea of analyzing the machine geometrically that\u2019s important here\u2014not any specific rule. So, now we know the direction of the velocity. The horizontal component of the velocity, we already know, is 1 , because it\u2019s half the speed of the roller. But look! The velocity is the hypotenuse of a right triangle that is similar to a triangle having the rod as its hypotenuse! To obtain the magnitude of the velocity is no harder than finding its proportion to its horizontal component, and we can get that proportion from the other triangle, which we already know all about. (See Fig. 2-11.) Finally, for the kinetic energy we get K.E.= 1 2 m v 2 = 1 2 \u00d72 kg\u00d7( 0.5 0.25\u2212 t 2 \u2212 \u2212 \u2212 \u2212 \u2212 \u2212 \u2212 \u221a m/s ) 2 = 1 1\u22124 t 2 joules. (2.26) Now, for the signs: the kinetic energy is certainly positive, and the potential energy is positive because I measured the distance from the floor. So now I\u2019m all right with the signs. So, the energy at any time is E =K.E.+P.E. = 1 1\u22124 t 2 +19.6 0.25\u2212 t 2 \u2212 \u2212 \u2212 \u2212 \u2212 \u2212 \u2212 \u221a . (2.27) Now, in order to find the force using this trick, we need to differentiate the energy and then we can divide by two and everything will be ready. (The apparent ease with which I do this is false: I swear I did it more than once before I got it right!) Now, we differentiate the energy with respect to time. I\u2019m not going to stall around with this; you\u2019re supposed to know how to differentiate by now. So there we are, with the answer for (which, incidentally, is twice the force required): dE dt = 8t (1\u22124 t 2 ) 2 \u2212 19.6t 0.25\u2212 t 2 \u2212 \u2212 \u2212 \u2212 \u2212 \u2212 \u2212 \u221a . (2.28) So I\u2019m all finished; I need merely put 0.3 in for t , and I\u2019m all done. Well, not quite\u2014to make the signs come out right, I have to use t=\u22120.3 : dE dt (\u22120.3) =\u2212 2.4 0.4096 +19.6\u00d7 0.3 0.4 . \u22488.84 watts. (2.29) Now, let\u2019s see whether this makes sense. If there were no motion, and I didn\u2019t have to worry about the kinetic energy, then the total energy of the weight would just be its potential energy, and its derivative should be the force due to the weight.8 And sure enough, it comes out here the same as we calculated in Chapter 1, 2 times 9.8 times 3 4 . The first term on the right-hand side of Eq. (2.29) is negative because the weight is decelerating, so it\u2019s losing kinetic energy; the second term is positive because the weight is going up, so it\u2019s gaining potential energy. Anyhow, they\u2019re opposite each other, which is all I want to know, and you can put the numbers in, and sure enough, the force comes out to be the same as before: 2 F R F R = dE dt \u22488.84 \u22484.42 newtons. (2.30) In fact, this is why I had to do it so many times: after doing it the first time, and being completely satisfied with my wrong answer, I decided to try to do it another, completely different, way. After I did it the other way, I was satisfied with a completely different answer! When you work hard, there are moments when you think, \u201cAt last, I\u2019ve discovered that mathematics is inconsistent!\u201d But pretty soon you discover the error, as I finally did. Anyway, that\u2019s just two ways of solving this problem. There\u2019s no unique way of doing any specific problem. By greater and greater ingenuity, you can find ways that require less and less work, but that takes experience.9 I don\u2019t have much time left, but the next problem we\u2019ll talk about is something involving the motion of planets. I\u2019ll have to come back to it because I certainly can\u2019t tell you everything about it this time. The first problem is, what is the velocity required to leave the earth\u2019s surface? How fast does something have to move so that it can just escape from Earth\u2019s gravity? Now, one way to work that out would be to calculate the motion under the force of gravity, but another way is by the conservation of energy. When the thing reaches way out there, infinitely far away, the kinetic energy will be zero, and the potential energy will be whatever it comes out for infinite distance. The formula for the gravitational potential is in Table 2-3; and it tells us that the potential energy, for particles that are infinitely distant, equals zero. So, the total energy of something when it leaves Earth at escape velocity must be the same after the thing has gone an infinite distance and Earth\u2019s gravity has slowed it down to zero velocity (assuming there are no other forces involved). If M is the mass of the earth, R is the radius of the earth, and G is the universal gravitational constant, we find that the square of the escape velocity must be 2GM/R . (K.E.+P.E.) at \u221e , v=0 = (K.E.+P.E.) at R , v= v escape (conservation of energy) P.E. at \u221e =\u2212 GMm \u221e K.E. at v=0 =\u2212 m 0 2 2 =0 =0 P.E. at R =\u2212 GMm R K.E. at v= v escape = m v 2 escape 2 + + 0 = (\u2212 GMm R + m v 2 escape 2 ) 2 \u2234 v 2 escape = 2GM R (2.31) Incidentally, the gravity constant, g (the acceleration of gravity near the earth\u2019s surface) is GM/ R 2 because the law of force, for a mass, m , is mg=GMm/ R 2 . In terms of the easier-to-remember gravity constant I can write v 2 =2gR . Now, g is 9.8 m/ s 2 , and the radius of the earth is 6400 km, so the earth\u2019s escape velocity is v escape = 2gR \u2212 \u2212 \u2212 \u2212 \u221a = 2\u00d79.8\u00d76400\u00d71000 \u2212 \u2212 \u2212 \u2212 \u2212 \u2212 \u2212 \u2212 \u2212 \u2212 \u2212 \u2212 \u2212 \u2212 \u2212 \u2212 \u2212 \u221a =11,200 m/s. (2.32) So you have to go 11 kilometers per second to get out\u2014which is pretty fast. Next, I would talk about what happens if you are going 15 kilometers per second, and you\u2019re shooting past the earth at some distance. Now, at 15 kilometers per second, the thing has enough energy to get out, going straight up. But is it obviously necessary that it gets out if it\u2019s not going straight up? Is it possible that the thing will go around and come back? That\u2019s not self-evident; it takes some thought. You say, \u201cIt has enough energy to get out,\u201d but how do you know? We didn\u2019t calculate the escape velocity for that direction. Could it be that the sideways acceleration due to Earth\u2019s gravity is enough to make it turn around? (See Fig. 2-12.) It is possible, in principle. You know the law that you sweep out equal areas in equal times, so you know that when you get far out, you have to be moving sideways somehow or other. It\u2019s not clear that some of the motion that you need to escape isn\u2019t going sideways, so that even at 15 kilometers per second you don\u2019t escape. Actually, it turns out that at 15 kilometers per second it does escape\u2014it escapes as long as the velocity is greater than the escape velocity we computed above. As long as it can escape, it does escape\u2014although that\u2019s not self-evident\u2014and the next time, I\u2019m going to try to show it. But to give you a hint as to how I\u2019m going to show it, so you can play around with it yourself, it\u2019s the following. We\u2019ll use the conservation of energy at two points, A and B , at its shortest distance from Earth, a , and at its longest distance from Earth, b , as shown in Figure 2-13; the problem is to calculate b . We know the total energy of the thing at A , and it\u2019s the same at B because the energy is conserved, so if we knew the velocity at B , we could calculate its potential energy, and thus b . But we don\u2019t know the velocity at B ! Yet we do: from the law that equal areas are swept out in equal times, we know that the speed at B must be lower than the speed at A , in a certain proportion\u2014in fact, it\u2019s a to b . Using that fact to get the speed at B , we\u2019re able to find this distance b in terms of a , and we\u2019ll do that next time. Here are three more approaches to solving the machine design problem presented earlier in this chapter (Section 2-7). The weight is always horizontally halfway between the roller and the pivot, so its horizontal speed is 1 m/s, half the speed of the roller. The weight moves on a circle (centered at the pivot), so its velocity is perpendicular to the rod. By similar triangles we obtain the velocity of the weight. (See Fig. 2-14a.) Because the weight moves on a circle, the radial component of its acceleration is a rad = v 2 r = (1.25 ) 2 0.5 =3.125. 2 as per Eq. (2.17). The vertical acceleration of the weight is the sum of its radial and transverse components. (See Fig. 2-14b.) Using similar triangles again, we obtain the vertical acceleration: a y = a y a rad \u00d7 a rad = 0.5 0.4 \u00d73.125=3.90625. a 0.5 The weight moves on a circular arc of radius 1 2 , so its equations of motion can be expressed in terms of the angle the rods make with the ground. (See Fig. 2-15.) x y = 1 2 cos\u03b8, = 1 2 sin\u03b8. The horizontal speed of the weight is 1 m/s (half the speed of the roller). So x=t , dx/dt=1 , and d 2 x/d t 2 =0 . The vertical acceleration can be calculated by differentiating y with respect to t twice. But first, since t= 1 2 cos\u03b8 , d\u03b8 dt =\u2212 2 sin\u03b8 . d \u03b8 Therefore, dy dt d 2 y d t 2 = 1 2 cos\u03b8\u22c5 d\u03b8 dt = 1 2 cos\u03b8\u22c5(\u2212 2 sin\u03b8 )=\u2212cot\u03b8, = 1 sin 2 \u03b8 \u22c5 d\u03b8 dt = 1 sin 2 \u03b8 \u22c5(\u2212 2 sin\u03b8 )=\u2212 2 sin 3 \u03b8 . When x=t=0.3 , we have y=0.4 and sin\u03b8=0.8 (since y= 1 2 sin\u03b8 ). The magnitude of the vertical acceleration is thus a y = \u2223 \u2223 \u2223 d 2 y d t 2 \u2223 \u2223 \u2223 = 2 (0.8 ) 3 =3.90625. 2 The torque on the weight is \u03c4=x F y \u2212y F x . The weight moves horizontally at 1 m/s, so there is no horizontal force on it: F x =0 . Letting x=t , the torque reduces to \u03c4=t F y . Torque is the time derivative of angular momentum, so if we can find the angular momentum L of the weight, we can differentiate it and divide by t to get F y : F y = \u03c4 t = 1 t dL dt . d L The angular momentum of the weight is easy to find because the weight moves in a circle. Its angular momentum is simply the length of the rod r , times the momentum of the weight, which is its mass m , times its speed v . The speed can be found using Feynman\u2019s geometric method (see Fig. 2-16) or by differentiating the weight\u2019s equations of motion. Putting this all together we have: F y = 1 t dL dt = 1 t d dt (rmv) = rm t \u22c5 d dt ( 0.5 0.25\u2212 t 2 \u2212 \u2212 \u2212 \u2212 \u2212 \u2212 \u2212 \u221a ) = 0.5\u22c52 t \u22c5 0.5t (0.25\u2212 t 2 ) 3/2 = 4 (1\u22124 t 2 ) 3/2 . At time t=0.3 we have F y =7.8125 . Dividing by 2 kg gives the vertical acceleration we found before: 3.90625 ."
    },
    {
        "input": "Applications of Kinetic Theory",
        "output": "In this chapter we shall discuss some further applications of kinetic theory. In the previous chapter we emphasized one particular aspect of kinetic theory, namely, that the average kinetic energy in any degree of freedom of a molecule or other object is 1 2 kT . The central feature of what we shall now discuss, on the other hand, is the fact that the probability of finding a particle in different places, per unit volume, varies as e \u2212potential energy/kT ; we shall make a number of applications of this. The phenomena which we want to study are relatively complicated: a liquid evaporating, or electrons in a metal coming out of the surface, or a chemical reaction in which there are a large number of atoms involved. In such cases it is no longer possible to make from the kinetic theory any simple and correct statements, because the situation is too complicated. Therefore, this chapter, except where otherwise emphasized, is quite inexact. The idea to be emphasized is only that we can understand, from the kinetic theory, more or less how things ought to behave. By using thermodynamic arguments, or some empirical measurements of certain critical quantities, we can get a more accurate representation of the phenomena. However, it is very useful to know even only more or less why something behaves as it does, so that when the situation is a new one, or one that we have not yet started to analyze, we can say, more or less, what ought to happen. So this discussion is highly inaccurate but essentially right\u2014right in idea, but a little bit simplified, let us say, in the specific details. The first example that we shall consider is the evaporation of a liquid. Suppose we have a box with a large volume, partially filled with liquid in equilibrium and with the vapor at a certain temperature. We shall suppose that the molecules of the vapor are relatively far apart, and that inside the liquid, the molecules are packed close together. The problem is to find out how many molecules there are in the vapor phase, compared with the number there are in the liquid. How dense is the vapor at a given temperature, and how does it depend on the temperature? Let us say that n equals the number of molecules per unit volume in the vapor. That number, of course, varies with the temperature. If we add heat, we get more evaporation. Now let another quantity, 1/ V a , equal the number of atoms per unit volume in the liquid: We suppose that each molecule in the liquid occupies a certain volume, so that if there are more molecules of liquid, then all together they occupy a bigger volume. Thus if V a is the volume occupied by one molecule, the number of molecules in a unit volume is a unit volume divided by the volume of each molecule. Furthermore, we suppose that there is a force of attraction between the molecules to hold them together in the liquid. Otherwise we cannot understand why it condenses. Thus suppose that there is such a force and that there is an energy of binding of the molecules in the liquid which is lost when they go into the vapor. That is, we are going to suppose that, in order to take a single molecule out of the liquid into the vapor, a certain amount of work W has to be done. There is a certain difference, W , in the energy of a molecule in the liquid from what it would have if it were in the vapor, because we have to pull it away from the other molecules which attract it. Now we use the general principle that the number of atoms per unit volume in two different regions is n 2 / n 1 = e \u2212( E 2 \u2212 E 1 )/kT . So the number n per unit volume in the vapor, divided by the number 1/ V a per unit volume in the liquid, is equal to n V a = e \u2212W/kT , (42.1) because that is the general rule. It is like the atmosphere in equilibrium under gravity, where the gas at the bottom is denser than that at the top because of the work mgh needed to lift the gas molecules to the height h . In the liquid, the molecules are denser than in the vapor because we have to pull them out through the energy \u201chill\u201d W , and the ratio of the densities is e \u2212W/kT . This is what we wanted to deduce\u2014that the vapor density varies as e to the minus some energy or other over kT . The factors in front are not really interesting to us, because in most cases the vapor density is very much lower than the liquid density. In those circumstances, where we are not near the critical point where they are almost the same, but where the vapor density is much lower than the liquid density, then the fact that n is very much less than 1/ V a is occasioned by the fact that W is very much greater than kT . So formulas such as (42.1) are interesting only when W is very much bigger than kT , because in those circumstances, since we are raising e to minus a tremendous amount, if we change T a little bit, that tremendous power changes a bit, and the change produced in the exponential factor is very much more important than any change that might occur in the factors out in front. Why should there be any changes in such factors as V a ? Because ours was an approximate analysis. After all, there is not really a definite volume for each molecule; as we change the temperature, the volume V a does not stay constant\u2014the liquid expands. There are other little features like that, and so the actual situation is more complicated. There are slowly varying temperature-dependent factors all over the place. In fact, we might say that W itself varies slightly with temperature, because at a higher temperature, at a different molecular volume, there would be different average attractions, and so on. So, while we might think that if we have a formula in which everything varies in an unknown way with temperature then we have no formula at all, if we realize that the exponent W/kT is, in general, very large, we see that in the curve of the vapor density as a function of temperature most of the variation is occasioned by the exponential factor, and if we take W as a constant and the coefficient 1/ V a as nearly constant, it is a good approximation for short intervals along the curve. Most of the variation, in other words, is of the general nature e \u2212W/kT . It turns out that there are many, many phenomena in nature which are characterized by having to borrow an energy from somewhere, and in which the central feature of the temperature variation is e to the minus the energy over kT . This is a useful fact only when the energy is large compared with kT , so that most of the variation is contained in the variation of the kT and not in the constant and in other factors. Now let us consider another way of obtaining a somewhat similar result for the evaporation, but looking at it in more detail. To arrive at (42.1), we simply applied a rule which is valid at equilibrium, but in order to understand things better, there is no harm in trying to look at the details of what is going on. We may also describe what is going on in the following way: the molecules that are in the vapor continually bombard the surface of the liquid; when they hit it, they may bounce off or they may get stuck. There is an unknown factor for that\u2014maybe 50 \u2013 50 , maybe 10 to 90 \u2014we do not know. Let us say they always get stuck\u2014we can analyze it over again later on the assumption that they do not always get stuck. Then at a given moment there will be a certain number of atoms which are condensing onto the surface of the liquid. The number of condensing molecules, the number that arrive on a unit area per unit time, is the number n per unit volume times the velocity v . This velocity of the molecules is related to the temperature, because we know that 1 2 m v 2 is equal to 3 2 kT on the average. So v is some kind of a mean velocity. Of course we should integrate over the angles and get some kind of an average, but it is roughly proportional to the root-mean-square velocity, within some factor. Thus N c =nv (42.2) is the rate at which the molecules arrive per unit area and are condensing. At the same time, however, the atoms in the liquid are jiggling about, and from time to time one of them gets kicked out. Now we have to estimate how fast they get kicked out. The idea will be that at equilibrium the number that are kicked out per second and the number that arrive per second are equal. How many get kicked out? In order to get kicked out, a particular molecule has to have acquired by accident an excess energy over its neighbors\u2014a considerable excess energy, because it is attracted very strongly by the other molecules in the liquid. Ordinarily it does not leave because it is so strongly attracted, but in the collisions sometimes one of them gets an extra energy by accident. And the chance that it gets the extra energy W which it needs in our case is very small if W\u226bkT . In fact, e \u2212W/kT is the chance that an atom has picked up more than this much energy. That is the general principle in kinetic theory: in order to borrow an excess energy W over the average, the odds are e to the minus the energy that we have to borrow, over kT . Now suppose that some molecules have borrowed this energy. We now have to estimate how many leave the surface per second. Of course, just because a molecule has the necessary energy does not mean that it will actually evaporate, since it may be buried too deeply inside the liquid or, even if it is near the surface, it may be travelling in the wrong direction. The number that are going to leave a unit area per second is going to be something like this: the number of atoms there are near the surface, per unit area, divided by the time it takes one to escape, multiplied by the probability e \u2212W/kT that they are ready to escape in the sense that they have enough energy. We shall suppose that each molecule at the surface of the liquid occupies a certain cross-sectional area A . Then the number of molecules per unit area of liquid surface will be 1/A . And now, how long does it take a molecule to escape? If the molecules have a certain average speed v , and have to move, say, one molecular diameter D , the thickness of the first layer, then the time it takes to get across that thickness is the time needed to escape, if the molecule has enough energy. The time will be D/v . Thus the number evaporating should be approximately N e =(1/A)(v/D) e \u2212W/kT . (42.3) Now the area of each atom times the thickness of the layer is approximately the same as the volume V a occupied by a single atom. And so, in order to get equilibrium, we must have N c = N e , or nv=(v/ V a ) e \u2212W/kT . (42.4) We may cancel the v \u2019s, since they are equal; even though one is the velocity of a molecule in the vapor and the other is the velocity of an evaporating molecule, these are the same, because we know their mean kinetic energy (in one direction) is 1 2 kT . But one may object, \u201cNo! No! These are the especially fast-moving ones; these are the ones that have picked up excess energy.\u201d Not really, because the moment they start to pull away from the liquid, they have to lose that excess energy against the potential energy. So, as they come to the surface they are slowed down to the velocity v ! It is the same as it was in our discussion of the distribution of molecular velocities in the atmosphere\u2014at the bottom, the molecules had a certain distribution of energy. The ones that arrive at the top have the same distribution of energy, because the slow ones did not arrive at all, and the fast ones were slowed down. The molecules that are evaporating have the same distribution of energy as the ones inside\u2014a rather remarkable fact. Anyway, it is useless to try to argue so closely about our formula because of other inaccuracies, such as the probability of bouncing back rather than entering the liquid, and so on. Thus we have a rough idea of the rate of evaporation and condensation, and we see, of course, that the vapor density n varies in the same way as before, but now we have understood it in some detail rather than just as an arbitrary formula. This deeper understanding permits us to analyze some things. For example, suppose that we were to pump away the vapor at such a great rate that we removed the vapor as fast as it formed (if we had very good pumps and the liquid was evaporating very slowly), how fast would evaporation occur if we maintained a liquid temperature T ? Suppose that we have already experimentally measured the equilibrium vapor density, so that we know, at the given temperature, how many molecules per unit volume are in equilibrium with the liquid. Now we would like to know how fast it will evaporate. Even though we have used only a rough analysis so far as the evaporation part of it is concerned, the number of vapor molecules arriving was not done so badly, aside from the unknown factor of reflection coefficient. So therefore we may use the fact that the number that are leaving, at equilibrium, is the same as the number that arrive. True, the vapor is being swept away and so the molecules are only coming out, but if the vapor were left alone, it would attain the equilibrium density at which the number that come back would equal the number that are evaporating. Therefore, we can easily see that the number that are coming off the surface per second is equal to one minus the unknown reflection coefficient R times the number that would come down to the surface per second were the vapor still there, because that is how many would balance the evaporation at equilibrium: N e =nv(1\u2212R)=(v(1\u2212R)/ V a ) e \u2212W/kT . (42.5) Of course, the number of molecules that hit the liquid from the vapor is easy to calculate, since we do not need to know as much about the forces as we do when we are worrying about how they get to escape through the liquid surface; it is much easier to make the argument the other way. We may give another example of a very practical situation that is similar to the evaporation of a liquid\u2014so similar that it is not worth making a separate analysis. It is essentially the same problem. In a radio tube there is a source of electrons, namely a heated tungsten filament, and a positively charged plate to attract the electrons. Any electron that escapes from the surface of the tungsten is immediately swept away to the plate. That is our ideal \u201cpump,\u201d which is \u201cpumping\u201d the electrons away all the time. Now the question is: How many electrons per second can we get out of a piece of tungsten, and how does that number vary with temperature? The answer to that problem is the same as (42.5), because it turns out that in a piece of metal, electrons are attracted to the ions, or to atoms, of the metal. They are attracted, if we may say it crudely, to the metal. In order to get an electron out of a piece of metal, it takes a certain amount of energy or work to pull it out. This work varies with the different kinds of metal. In fact, it varies even with the character of the surface of a given kind of metal, but the total work may be a few electron volts, which, incidentally, is typical of the energy involved in chemical reactions. We can remember the latter fact by remembering that the voltage in a chemical cell like a flashlight battery, which is produced by chemical reactions, is about one volt. How can we find out how many electrons come out per second? It would be quite difficult to analyze the effects on the electrons going out; it is easier to analyze the situation the other way. So, we could start out by imagining that we did not draw the electrons away, and that the electrons were like a gas, and could come back to the metal. Then there would be a certain density of electrons at equilibrium which would, of course, be given by exactly the same formula as (42.1), where V a is the volume per electron in the metal, roughly, and W is equal to q e \u03d5 , where \u03d5 is the so-called work function, or the voltage needed to pull an electron off the surface. This would tell us how many electrons would have to be in the surrounding space and striking the metal in order to balance the ones that are coming out. And thus it is easy to calculate how many are coming out if we sweep away all of them, because the number that are coming out is exactly equal to the number that would be going in with the above density of electron \u201cvapor.\u201d In other words, the answer is that the current of electricity that comes in per unit area is equal to the charge on each times the number that arrive per second per unit area, which is the number per unit volume times the velocity, as we have seen many times: I= q e nv=( q e v/ V a ) e \u2212 q e \u03d5/kT . (42.6) Now one electron volt corresponds to kT at a temperature of 11,600 degrees. The filament of the tube may be operating at a temperature of, say, 1100 degrees, so the exponential factor is something like e \u221210 ; when we change the temperature a little bit, the exponential factor changes a lot. Thus, again, the central feature of the formula is the e \u2212 q e \u03d5/kT . As a matter of fact, the factor in front is quite wrong\u2014it turns out that the behavior of electrons in a metal is not correctly described by the classical theory, but by quantum mechanics, but this only changes the factor in front a little. Actually, no one has ever been able to get the thing straightened out very well, even though many people have used the high-class quantum-mechanical theory for their calculations. The big problem is, does W change slightly with temperature? If it does, one cannot distinguish a W changing slowly with temperature from a different coefficient in front. That is, if W changed linearly, say, with temperature, so that W= W 0 +\u03b1kT , then we would have e \u2212W/kT = e \u2212( W 0 +\u03b1kT)/kT = e \u2212\u03b1 e \u2212 W 0 /kT . W / k T ( W k T ) / k T W / k T Thus a linearly temperature-dependent W is equivalent to a shifted \u201cconstant.\u201d It is really quite difficult and usually fruitless to try to obtain the coefficient in the front accurately. Now we go on to another example of the same idea; always the same idea. This has to do with ionization. Suppose that in a gas we have a whole lot of atoms which are in the neutral state, say, but the gas is hot and the atoms can become ionized. We would like to know how many ions there are in a given circumstance if we have a certain density of atoms per unit volume at a certain temperature. Again we consider a box in which there are N atoms which can hold electrons. (If an electron has come off an atom, it is called an ion, and if the atom is neutral, we simply call it an atom.) Then suppose that, at any given moment, the number of neutral atoms is n a , the number of ions is n i , and the number of electrons is n e , all per unit volume. The problem is: What is the relationship of these three numbers? In the first place, we have two conditions or constraints on the numbers. For instance, as we vary different conditions, like the temperature and so on, n a + n i would remain constant, because this would be simply the number N of atomic nuclei that are in the box. If we keep the number of nuclei per unit volume fixed, and change, say, the temperature, then as the ionization proceeded some atoms would turn to ions, but the total number of atoms plus ions would be unchanged. That is, n a + n i =N . Another condition is that if the entire gas is to be electrically neutral (and if we neglect double or triple ionization), that means that the number of ions is equal to the number of electrons at all times, or n i = n e . These are subsidiary equations that simply express the conservation of charge and the conservation of atoms. These equations are true, and we ultimately will use them when we consider a real problem. But we want to obtain another relationship between the quantities. We can do this as follows. We again use the idea that it takes a certain amount of energy to lift the electron out of the atom, which we call the ionization energy, and we would write it as W , in order to make all of the formulas look the same. So we let W equal the energy needed to pull an electron out of an atom and make an ion. Now we again say that the number of free electrons per unit volume in the \u201cvapor\u201d is equal to the number of bound electrons per unit volume in the atoms, times e to the minus the energy difference between being bound and being free, over kT . That is the basic equation again. How can we write it? The number of free electrons per unit volume would, of course, be n e , because that is the definition of n e . Now what about the number of electrons per unit volume that are bound to atoms? The total number of places that we could put the electrons is apparently n a + n i , and we will suppose that when they are bound each one is bound within a certain volume V a . So the total amount of volume which is available to electrons which would be bound is ( n a + n i ) V a , so we might want to write our formula as n e = n a ( n a + n i ) V a e \u2212W/kT . n The formula is wrong, however, in one essential feature, which is the following: when an electron is already on an atom, another electron cannot come to that volume anymore! In other words, all the volumes of all the possible sites are not really available for the one electron which is trying to make up its mind whether or not to be in the vapor or in the condensed position, because in this problem there is an extra feature that when one electron is where another electron is, it is not allowed to go\u2014it is repelled. For that reason, it comes out that we should count only that part of the volume which is available for an electron to sit on or not. That is, those which are already occupied do not count in the total available volume, but the only volume which is allowed is that of the ions, where there are vacant places for the electron to go. Then, in those circumstances, we find that a nicer way to write our formula is n e n i n a = 1 V a e \u2212W/kT . (42.7) This formula is called the Saha ionization equation. Now let us see if we can understand qualitatively why a formula like this is right, by arguing about the kinetic things that are happening. First, every once in a while an electron comes to an ion and they combine to make an atom. And also, every once in a while, an atom gets into a collision and breaks up into an ion and an electron. Now those two rates must be equal. How fast do electrons and ions find each other? The rate is certainly increased if the number of electrons per unit volume is increased. It is also increased if the number of ions per unit volume is increased. That is, the total rate at which recombination is occurring is certainly proportional to the number of electrons times the number of ions. Now the total rate at which ionization is occurring due to collisions must be dependent linearly on how many atoms there are to ionize. And so the rates will balance when there is some relationship between the product n e n i and the number of atoms, n a . The fact that this relationship happens to be given by this particular formula, where W is the ionization energy, is of course a little bit more information, but we can easily understand that the formula would necessarily involve the concentrations of the electrons, ions, and atoms in the combination n e n i / n a to produce a constant independent of the n \u2019s, and dependent only on temperature, the atomic cross sections, and other constant factors. We may also note that, since the equation involves the numbers per unit volume, if we were to do two experiments with a given total number N of atoms plus ions, that is, a certain fixed number of nuclei, but using boxes with different volumes, the n \u2019s would all be smaller in the larger box. But since the ratio n e n i / n a stays the same, the total number of electrons and ions must be greater in the larger box. To see this, suppose that there are N nuclei inside a box of volume V , and that a fraction f of them are ionized. Then n e = fN/V= n i , and n a =(1\u2212f)N/V . Then our equation becomes f 2 1\u2212f N V = e \u2212W/kT V a . (42.8) In other words, if we take a smaller and smaller density of atoms, or make the volume of the container bigger and bigger, the fraction f of electrons and ions must increase. That ionization, just from \u201cexpansion\u201d as the density goes down, is the reason why we believe that at very low densities, such as in the cold space between the stars, there may be ions present, even though we might not understand it from the point of view of the available energy. Although it takes many, many kT of energy to make them, there are ions present. Why can there be ions present when there is so much space around, while if we increase the density, the ions tend to disappear? Answer: Consider an atom. Every once in a while, light, or another atom, or an ion, or whatever it is that maintains thermal equilibrium, strikes it. Very rarely, because it takes such a terrific amount of excess energy, an electron comes off and an ion is left. Now that electron, if the space is enormous, wanders and wanders and does not come near anything for years, perhaps. But once in a very great while, it does come back to an ion and they combine to make an atom. So the rate at which electrons are coming out from the atoms is very slow. But if the volume is enormous, an electron which has escaped takes so long to find another ion to recombine with that its probability of recombination is very, very small; thus, in spite of the large excess energy needed, there may be a reasonable number of electrons. The same situation that we have just called \u201cionization\u201d is also found in a chemical reaction. For instance, if two objects A and B combine into a compound AB , then if we think about it for a while we see that AB is what we have called an atom, B is what we call an electron, and A is what we call an ion. With these substitutions the equations of equilibrium are exactly the same in form: n A n B n AB =c e \u2212W/kT . (42.9) This formula, of course, is not exact, since the \u201cconstant\u201d c depends on how much volume is allowed for the A and B to combine, and so on, but by thermodynamic arguments one can identify what the meaning of the W in the exponential factor is, and it turns out that it is very close to the energy needed in the reaction. Suppose that we tried to understand this formula as a result of collisions, much in the way that we understood the evaporation formula, by arguing about how many electrons came off and how many of them came back per unit time. Suppose that A and B combine in a collision every once in a while to form a compound AB . And suppose that the compound AB is a complicated molecule which jiggles around and is hit by other molecules, and from time to time it gets enough energy to explode and break up again into A and B . Now it actually turns out, in chemical reactions, that if the atoms come together with too small an energy, even though energy may be released in the reaction A+B\u2192AB , the fact that A and B may touch each other does not necessarily make the reaction start. It usually is required that the collision be rather hard, in fact, to get the reaction to go at all\u2014a \u201csoft\u201d collision between A and B may not do it, even though energy may be released in the process. So let us suppose that it is very common in chemical reactions that, in order for A and B to form AB , they cannot just hit each other, but they have to hit each other with sufficient energy. This energy is called the activation energy\u2014the energy needed to \u201cactivate\u201d the reaction. Call A \u2217 the activation energy, the excess energy needed in a collision in order that the reaction may really occur. Then the rate R f at which A and B produce AB would involve the number of atoms of A times the number of atoms of B , times the rate at which a single atom would strike a certain cross section \u03c3 AB , times a factor e \u2212 A \u2217 /kT which is the probability that they have enough energy: R f = n A n B v \u03c3 AB e \u2212 A \u2217 /kT . (42.10) Now we have to find the opposite rate, R r . There is a certain chance that AB will fly apart. In order to fly apart, it not only must have the energy W which it needs in order to get apart at all but, just as it was hard for A and B to come together, so there is a kind of hill that A and B have to climb over to get apart again; they must have not only enough energy just to get ready to pull apart, but a certain excess. It is like climbing a hill to get into a deep valley; they have to climb the hill coming in and they have to climb out of the valley and then over the hill coming back (Fig. 42\u20131). Thus the rate at which AB goes to A and B will be proportional to the number n AB that are present, times e \u2212(W+ A \u2217 )/kT : R r = c \u2032 n AB e \u2212(W+ A \u2217 )/kT . (42.11) The c \u2032 will involve the volume of atoms and the rate of collisions, which we can work out, as we did the case of evaporation, with areas and times and thicknesses; but we shall not do this. The main feature of interest to us is that when these two rates are equal, the ratio of them is equal to unity. This tells us that n A n B / n AB =c e \u2212W/kT , as before, where c involves the cross sections, velocities, and other factors independent of the n \u2019s. The interesting thing is that the rate of the reaction also varies as e \u2212const/kT , although the constant is not the same as that which governs the concentrations; the activation energy A \u2217 is quite different from the energy W . W governs the proportions of A , B , and AB that we have in equilibrium, but if we want to know how fast A+B goes to AB , that is not a question of equilibrium, and here a different energy, the activation energy, governs the rate of reaction through an exponential factor. Furthermore, A \u2217 is not a fundamental constant like W . Suppose that at the surface of the wall\u2014or at some other place\u2014 A and B could temporarily stick there in such a way that they could combine more easily. In other words, we might find a \u201ctunnel\u201d through the hill, or perhaps a lower hill. By the conservation of energy, when we are all finished we have still made AB out of A and B , so the energy difference W will be quite independent of the way the reaction occurred, but the activation energy A \u2217 will depend very much on the way the reaction occurs. This is why the rates of chemical reactions are very sensitive to outside conditions. We can change the rate by putting in a surface of a different kind, we can put it in a \u201cdifferent barrel\u201d and it will go at a different rate, if it depends on the nature of the surface. Or if we put in a third kind of object it may change the rate very much; some things produce enormous changes in rate simply by changing the A \u2217 a little bit\u2014they are called catalysts. A reaction might practically not occur at all because A \u2217 is too big at the given temperature, but when we put in this special stuff, the catalyst, then the reaction goes very fast indeed, because A \u2217 is reduced. Incidentally, there is some trouble with such a reaction, A plus B , making AB , because we cannot conserve both energy and momentum when we try to put two objects together to make one that is more stable. Therefore, we need at least a third object C , so the actual reaction is much more complicated. The forward rate would involve the product n A n B n C , and it might seem that our formula is going wrong, but no! When we look at the rate at which AB goes the other way, we find that it also needs to collide with C , so there is an n AB n C in the reverse rate; the n C \u2019s cancel out in the formula for the equilibrium concentrations. The law of equilibrium, (42.9), which we first wrote down is absolutely guaranteed to be true, no matter what the mechanism of the reaction may be! We now turn to an interesting analogous situation having to do with the blackbody radiation law. In the last chapter we worked out the distribution law for the radiation in a cavity the way Planck did, considering the radiation from an oscillator. The oscillator had to have a certain mean energy, and since it was oscillating, it would radiate and would keep pumping radiation into the cavity until it piled up enough radiation to balance the absorption and emission. In that way we found that the intensity of radiation at frequency \u03c9 was given by the formula I(\u03c9)d\u03c9= \u210f \u03c9 3 d\u03c9 \u03c0 2 c 2 ( e \u210f\u03c9/kT \u22121) . (42.12) This result involved the assumption that the oscillator which was generating the radiation had definite, equally spaced energy levels. We did not say that light had to be a photon or anything like that. There was no discussion about how, when an atom goes from one level to another, the energy must come out in one unit of energy, \u210f\u03c9 , in the form of light. Planck\u2019s original idea was that the matter was quantized but not the light: material oscillators cannot take up just any energy, but have to take it in lumps. Furthermore, the trouble with the derivation is that it was partially classical. We calculated the rate of radiation from an oscillator according to classical physics; then we turned around and said, \u201cNo, this oscillator has a lot of energy levels.\u201d So gradually, in order to find the right result, the completely quantum-mechanical result, there was a slow development which culminated in the quantum mechanics of 1927. But in the meantime, there was an attempt by Einstein to convert Planck\u2019s viewpoint that only oscillators of matter were quantized, to the idea that light was really photons and could be considered in a certain way as particles with energy \u210f\u03c9 . Furthermore, Bohr had pointed out that any system of atoms has energy levels, but they are not necessarily equally spaced like Planck\u2019s oscillator. And so it became necessary to rederive or at least rediscuss the radiation law from a more completely quantum-mechanical viewpoint. Einstein assumed that Planck\u2019s final formula was right, and he used that formula to obtain some new information, previously unknown, about the interaction of radiation with matter. His discussion went as follows: Consider any two of the many energy levels of an atom, say the m th level and the n th level (Fig. 42\u20132). Now Einstein proposed that when such an atom has light of the right frequency shining on it, it can absorb that photon of light and make a transition from state n to state m , and that the probability that this occurs per second depends upon the two levels, of course, but is proportional to how intense the light is that is shining on it. Let us call the proportionality constant B nm , merely to remind us that this is not a universal constant of nature, but depends on the particular pair of levels: some levels are easy to excite; some levels are hard to excite. Now what is the formula going to be for the rate of emission from m to n ? Einstein proposed that this must have two parts to it. First, even if there were no light present, there would be some chance that an atom in an excited state would fall to a lower state, emitting a photon; this we call spontaneous emission. It is analogous to the idea that an oscillator with a certain amount of energy, even in classical physics, does not keep that energy, but loses it by radiation. Thus the analog of spontaneous radiation of a classical system is that if the atom is in an excited state there is a certain probability A mn , which depends on the levels again, for it to go down from m to n , and this probability is independent of whether light is shining on the atom or not. But then Einstein went further, and by comparison with the classical theory and by other arguments, concluded that emission was also influenced by the presence of light\u2014that when light of the right frequency is shining on an atom, it has an increased rate of emitting a photon that is proportional to the intensity of the light, with a proportionality constant B mn . Later, if we deduce that this coefficient is zero, then we will have found that Einstein was wrong. Of course we will find he was right. Thus Einstein assumed that there are three kinds of processes: an absorption proportional to the intensity of light, an emission proportional to the intensity of light, called induced emission or sometimes stimulated emission, and a spontaneous emission independent of light. Now suppose that we have, in equilibrium at temperature T , a certain number of atoms N n in the state n and another number N m in the state m . Then the total number of atoms that are going from n to m is the number that are in the state n times the rate per second that, if one is in n , it goes up to m . So we have a formula for the number that are going from n to m per second: R n\u2192m = N n B nm I(\u03c9). (42.13) The number that will go from m to n is expressed in the same manner, as the number N m that are in m , times the chance per second that each one goes down to n . This time our expression is R m\u2192n = N m [ A mn + B mn I(\u03c9)]. (42.14) Now we shall suppose that in thermal equilibrium the number of atoms going up must equal the number coming down. That is one way, at least, in which the number will be sure to stay constant in each level.1 So we take these two rates to be equal at equilibrium. But we have one other piece of information: we know how large N m is compared with N n \u2014the ratio of those two is e \u2212( E m \u2212 E n )/kT . Now Einstein assumed that the only light which is effective in making the transition from n to m is the light which has the frequency corresponding to the energy difference, so E m \u2212 E n =\u210f\u03c9 in all our formulas. Thus N m = N n e \u2212\u210f\u03c9/kT . (42.15) Thus if we set the two rates equal: N n B nm I(\u03c9)= N m [ A mn + B mn I(\u03c9)] , and divide by N m , we get B nm I(\u03c9) e \u210f\u03c9/kT = A mn + B mn I(\u03c9). (42.16) From this equation, we can calculate I(\u03c9) . It is simply I(\u03c9)= A mn B nm e \u210f\u03c9/kT \u2212 B mn . (42.17) But Planck has already told us that the formula must be (42.12). Therefore we can deduce something: First, that B nm must equal B mn , since otherwise we cannot get the ( e \u210f\u03c9/kT \u22121) . So Einstein discovered some things that he did not know how to calculate, namely that the induced emission probability and the absorption probability must be equal. This is interesting. And furthermore, in order for (42.17) and (42.12) to agree, A mn / B mn must be\u210f \u03c9 3 / \u03c0 2 c 2 . (42.18) So if we know, for instance, the absorption rate for a given level, we can deduce the spontaneous emission rate and the induced emission rate, or any combination. This is as far as Einstein or anyone else could go using such arguments. To actually compute the absolute spontaneous emission rate or the other rates for any specific atomic transition, of course, requires a knowledge of the machinery of the atom, called quantum electrodynamics, which was not discovered until eleven years later. This work of Einstein was done in 1916. The possibility of induced emission has, today, found interesting applications. If there is light present, it will tend to induce the downward transition. The transition then adds its \u210f\u03c9 to the available light energy, if there were some atoms sitting in the upper state. Now we can arrange, by some nonthermal method, to have a gas in which the number in the state m is very much greater than the number in the state n . This is far out of equilibrium, and so is not given by the formula e \u2212\u210f\u03c9/kT , which is for equilibrium. We can even arrange it so that the number in the upper state is very large, while the number in the lower state is practically zero. Then light which has the frequency corresponding to the energy difference E m \u2212 E n will not be strongly absorbed, because there are not many atoms in state n to absorb it. On the other hand, when that light is present, it will induce the emission from this upper state! So, if we had a lot of atoms in the upper state, there would be a sort of chain reaction, in which, the moment the atoms began to emit, more would be caused to emit, and the whole lot of them would dump down together. This is what is called a laser, or, in the case of the far infrared, a maser. Various tricks can be used to obtain the atoms in state m . There may be higher levels to which the atoms can get if we shine in a strong beam of light of high frequency. From these high levels, they may trickle down, emitting various photons, until they all get stuck in the state m . If they tend to stay in the state m without emitting, the state is called metastable. And then they are all dumped down together by induced emissions. One more technical point\u2014if we put this system in an ordinary box, it would radiate in so many different directions spontaneously, compared with the induced effect, that we would still be in trouble. But we can enhance the induced effect, increase its efficiency, by putting nearly perfect mirrors on each side of the box, so that the light which is emitted gets another chance, and another chance, and another chance, to induce more emission. Although the mirrors are almost one hundred percent reflecting, there is a slight amount of transmission of the mirror, and a little light gets out. In the end, of course, from the conservation of energy, all the light goes out in a nice uniform straight direction which makes the strong light beams that are possible today with lasers."
    },
    {
        "input": "The Electric Field in Various Circumstances (Continued)",
        "output": "This chapter is a continuation of our consideration of the characteristics of electric fields in various particular situations. We shall first describe some of the more elaborate methods for solving problems with conductors. It is not expected that these more advanced methods can be mastered at this time. Yet it may be of interest to have some idea about the kinds of problems that can be solved, using techniques that may be learned in more advanced courses. Then we take up two examples in which the charge distribution is neither fixed nor is carried by a conductor, but instead is determined by some other law of physics. As we found in Chapter 6, the problem of the electrostatic field is fundamentally simple when the distribution of charges is specified; it requires only the evaluation of an integral. When there are conductors present, however, complications arise because the charge distribution on the conductors is not initially known; the charge must distribute itself on the surface of the conductor in such a way that the conductor is an equipotential. The solution of such problems is neither direct nor simple. We have looked at an indirect method of solving such problems, in which we find the equipotentials for some specified charge distribution and replace one of them by a conducting surface. In this way we can build up a catalog of special solutions for conductors in the shapes of spheres, planes, etc. The use of images, described in Chapter 6, is an example of an indirect method. We shall describe another in this chapter. If the problem to be solved does not belong to the class of problems for which we can construct solutions by the indirect method, we are forced to solve the problem by a more direct method. The mathematical problem of the direct method is the solution of Laplace\u2019s equation, \u22072\u03d5=0, subject to the condition that \u03d5 is a suitable constant on certain boundaries\u2014the surfaces of the conductors. Problems which involve the solution of a differential field equation subject to certain boundary conditions are called boundary-value problems. They have been the object of considerable mathematical study. In the case of conductors having complicated shapes, there are no general analytical methods. Even such a simple problem as that of a charged cylindrical metal can closed at both ends\u2014a beer can\u2014presents formidable mathematical difficulties. It can be solved only approximately, using numerical methods. The only general methods of solution are numerical. There are a few problems for which Eq. (7.1) can be solved directly. For example, the problem of a charged conductor having the shape of an ellipsoid of revolution can be solved exactly in terms of known special functions. The solution for a thin disc can be obtained by letting the ellipsoid become infinitely oblate. In a similar manner, the solution for a needle can be obtained by letting the ellipsoid become infinitely prolate. However, it must be stressed that the only direct methods of general applicability are the numerical techniques. Boundary-value problems can also be solved by measurements of a physical analog. Laplace\u2019s equation arises in many different physical situations: in steady-state heat flow, in irrotational fluid flow, in current flow in an extended medium, and in the deflection of an elastic membrane. It is frequently possible to set up a physical model which is analogous to an electrical problem which we wish to solve. By the measurement of a suitable analogous quantity on the model, the solution to the problem of interest can be determined. An example of the analog technique is the use of the electrolytic tank for the solution of two-dimensional problems in electrostatics. This works because the differential equation for the potential in a uniform conducting medium is the same as it is for a vacuum. There are many physical situations in which the variations of the physical fields in one direction are zero, or can be neglected in comparison with the variations in the other two directions. Such problems are called two-dimensional; the field depends on two coordinates only. For example, if we place a long charged wire along the z -axis, then for points not too far from the wire the electric field depends on x and y , but not on z ; the problem is two-dimensional. Since in a two-dimensional problem \u2202\u03d5/\u2202z=0 , the equation for \u03d5 in free space is \u22022\u03d5 \u2202x2 + \u22022\u03d5 \u2202y2 =0. Because the two-dimensional equation is comparatively simple, there is a wide range of conditions under which it can be solved analytically. There is, in fact, a very powerful indirect mathematical technique which depends on a theorem from the mathematics of functions of a complex variable, and which we will now describe. The complex variable z is defined as z=x+iy. (Do not confuse z with the z -coordinate, which we ignore in the following discussion because we assume there is no z -dependence of the fields.) Every point in x and y then corresponds to a complex number z . We can use z as a single (complex) variable, and with it write the usual kinds of mathematical functions F(z) . For example, F(z)=z2, or F(z)=1/z3, or F(z)=zlnz, and so forth. Given any particular F(z) we can substitute z=x+iy , and we have a function of x and y \u2014with real and imaginary parts. For example, z2=(x+iy)2=x2\u2212y2+2ixy. Any function F(z) can be written as a sum of a pure real part and a pure imaginary part, each part a function of x and y : F(z)=U(x,y)+iV(x,y), where U(x,y) and V(x,y) are real functions. Thus from any complex function F(z) two new functions U(x,y) and V(x,y) can be derived. For example, F(z)=z2 gives us the two functions U(x,y)=x2\u2212y2, and V(x,y)=2xy. Now we come to a miraculous mathematical theorem which is so delightful that we shall leave a proof of it for one of your courses in mathematics. (We should not reveal all the mysteries of mathematics, or that subject matter would become too dull.) It is this. For any \u201cordinary function\u201d (mathematicians will define it better) the functions U and V automatically satisfy the relations \u2202U \u2202x = \u2202V \u2202y , \u2202V \u2202x =\u2212 \u2202U \u2202y . It follows immediately that each of the functions U and V satisfy Laplace\u2019s equation: \u22022U \u2202x2 + \u22022U \u2202y2 =0, \u22022V \u2202x2 + \u22022V \u2202y2 =0, These equations are clearly true for the functions of (7.5) and (7.6). Thus, starting with any ordinary function, we can arrive at two functions U(x,y) and V(x,y) , which are both solutions of Laplace\u2019s equation in two dimensions. Each function represents a possible electrostatic potential. We can pick any function F(z) and it should represent some electric field problem\u2014in fact, two problems, because U and V each represent solutions. We can write down as many solutions as we wish\u2014by just making up functions\u2014then we just have to find the problem that goes with each solution. It may sound backwards, but it\u2019s a possible approach. As an example, let\u2019s see what physics the function F(z)=z2 gives us. From it we get the two potential functions of (7.5) and (7.6). To see what problem the function U belongs to, we solve for the equipotential surfaces by setting U=A , a constant: x2\u2212y2=A. This is the equation of a rectangular hyperbola. For various values of A , we get the hyperbolas shown in Fig. 7\u20131. When A=0 , we get the special case of diagonal straight lines through the origin. Such a set of equipotentials corresponds to the field at an inside right-angle corner of a conductor. If we have two electrodes shaped like those in Fig. 7\u20132, which are held at different potentials, the field near the corner marked C will look just like the field above the origin in Fig. 7\u20131. The solid lines are the equipotentials, and the broken lines at right angles correspond to lines of E . Whereas at points or protuberances the electric field tends to be high, it tends to be low in dents or hollows. The solution we have found also corresponds to that for a hyperbola-shaped electrode near a right-angle corner, or for two hyperbolas at suitable potentials. You will notice that the field of Fig. 7\u20131 has an interesting property. The x -component of the electric field, Ex , is given by Ex=\u2212 \u2202\u03d5 \u2202x =\u22122x. The electric field is proportional to the distance from the axis. This fact is used to make devices (called quadrupole lenses) that are useful for focusing particle beams (see Section 29\u20137). The desired field is usually obtained by using four hyperbola shaped electrodes, as shown in Fig. 7\u20133. For the electric field lines in Fig. 7\u20133, we have simply copied from Fig. 7\u20131 the set of broken-line curves that represent V=constant . We have a bonus! The curves for V=constant are orthogonal to the ones for U=constant because of the equations (7.7) and (7.8). Whenever we choose a function F(z) , we get from U and V both the equipotentials and field lines. And you will remember that we have solved either of two problems, depending on which set of curves we call the equipotentials. As a second example, consider the function F(z)= \u221a z . If we write z=x+iy=\u03c1ei\u03b8, where \u03c1= \u221a x2+y2 and tan\u03b8=y/x, then F(z) =\u03c11/2ei\u03b8/2 =\u03c11/2(cos \u03b8 2 +isin \u03b8 2 ), from which F(z)= [ (x2+y2)1/2+x 2 ]1/2 +i[ (x2+y2)1/2\u2212x 2 ]1/2. The curves for U(x,y)=A and V(x,y)=B , using U and V from Eq. (7.12), are plotted in Fig. 7\u20134. Again, there are many possible situations that could be described by these fields. One of the most interesting is the field near the edge of a thin plate. If the line B=0 \u2014to the right of the y -axis\u2014represents a thin charged plate, the field lines near it are given by the curves for various values of A . The physical situation is shown in Fig. 7\u20135. Further examples are F(z)= z 2/3 , (7.13) which yields the field outside a rectangular corner F(z)=lnz, (7.14) which yields the field for a line charge, and F(z)=1/z, (7.15) which gives the field for the two-dimensional analog of an electric dipole, i.e., two parallel line charges with opposite polarities, very close together. We will not pursue this subject further in this course, but should emphasize that although the complex variable technique is often powerful, it is limited to two-dimensional problems; and also, it is an indirect method. We consider now some physical situations in which the field is determined neither by fixed charges nor by charges on conducting surfaces, but by a combination of two physical phenomena. In other words, the field will be governed simultaneously by two sets of equations: (1) the equations from electrostatics relating electric fields to charge distribution, and (2) an equation from another part of physics that determines the positions or motions of the charges in the presence of the field. The first example that we will discuss is a dynamic one in which the motion of the charges is governed by Newton\u2019s laws. A simple example of such a situation occurs in a plasma, which is an ionized gas consisting of ions and free electrons distributed over a region in space. The ionosphere\u2014an upper layer of the atmosphere\u2014is an example of such a plasma. The ultraviolet rays from the sun knock electrons off the molecules of the air, creating free electrons and ions. In such a plasma the positive ions are very much heavier than the electrons, so we may neglect the ionic motion, in comparison to that of the electrons. Let n 0 be the density of electrons in the undisturbed, equilibrium state. Assuming the molecules are singly ionized, this must also be the density of positive ions, since the plasma is electrically neutral (when undisturbed). Now we suppose that the electrons are somehow moved from equilibrium and ask what happens. If the density of the electrons in one region is increased, they will repel each other and tend to return to their equilibrium positions. As the electrons move toward their original positions they pick up kinetic energy, and instead of coming to rest in their equilibrium configuration, they overshoot the mark. They will oscillate back and forth. The situation is similar to what occurs in sound waves, in which the restoring force is the gas pressure. In a plasma, the restoring force is the electrical force on the electrons. To simplify the discussion, we will worry only about a situation in which the motions are all in one dimension, say x . Let us suppose that the electrons originally at x are, at the instant t , displaced from their equilibrium positions by a small amount s(x,t) . Since the electrons have been displaced, their density will, in general, be changed. The change in density is easily calculated. Referring to Fig. 7\u20136, the electrons initially contained between the two planes a and b have moved and are now contained between the planes a \u2032 and b \u2032 . The number of electrons that were between a and b is proportional to n 0 \u0394x ; the same number are now contained in the space whose width is \u0394x+\u0394s . The density has changed to n= n 0 \u0394x \u0394x+\u0394s = n 0 1+(\u0394s/\u0394x) . (7.16) If the change in density is small, we can write [using the binomial expansion for (1+\u03f5 ) \u22121 ] n= n 0 (1\u2212 \u0394s \u0394x ). (7.17) We assume that the positive ions do not move appreciably (because of the much larger inertia), so their density remains n 0 . Each electron carries the charge \u2212 q e , so the average charge density at any point is given by \u03c1=\u2212(n\u2212 n 0 ) q e , ( ) or \u03c1= n 0 q e ds dx (7.18) (where we have written the differential form for \u0394s/\u0394x ). The charge density is related to the electric field by Maxwell\u2019s equations, in particular, \u2207\u22c5E= \u03c1 \u03f5 0 . (7.19) If the problem is indeed one-dimensional (and if there are no other fields but the one due to the displacements of the electrons), the electric field E has a single component E x . Equation (7.19), together with (7.18), gives \u2202 E x \u2202x = n 0 q e \u03f5 0 \u2202s \u2202x . (7.20) Integrating Eq. (7.20) gives E x = n 0 q e \u03f5 0 s+K. (7.21) Since E x =0 when s=0 , the integration constant K is zero. The force on an electron in the displaced position is F x =\u2212 n 0 q 2 e \u03f5 0 s, (7.22) a restoring force proportional to the displacement s of the electron. This leads to a harmonic oscillation of the electrons. The equation of motion of a displaced electron is m e d 2 s d t 2 =\u2212 n 0 q 2 e \u03f5 0 s. (7.23) We find that s will vary harmonically. Its time variation will be as cos \u03c9 p t , or\u2014using the exponential notation of Vol. I\u2014as e i \u03c9 p t . (7.24) The frequency of oscillation \u03c9 p is determined from (7.23): \u03c9 2 p = n 0 q 2 e \u03f5 0 m e , (7.25) and is called the plasma frequency. It is a characteristic number of the plasma. When dealing with electron charges many people prefer to express their answers in terms of a quantity e 2 defined by e 2 = q 2 e 4\u03c0 \u03f5 0 =2.3068\u00d7 10 \u221228 newton\u22c5meter 2 . (7.26) Using this convention, Eq. (7.25) becomes \u03c9 2 p = 4\u03c0 e 2 n 0 m e , (7.27) which is the form you will find in most books. Thus we have found that a disturbance of a plasma will set up free oscillations of the electrons about their equilibrium positions at the natural frequency \u03c9 p , which is proportional to the square root of the density of the electrons. The plasma electrons behave like a resonant system, such as those we described in Chapter 23 of Vol. I. This natural resonance of a plasma has some interesting effects. For example, if one tries to propagate a radiowave through the ionosphere, one finds that it can penetrate only if its frequency is higher than the plasma frequency. Otherwise the signal is reflected back. We must use high frequencies if we wish to communicate with a satellite in space. On the other hand, if we wish to communicate with a radio station beyond the horizon, we must use frequencies lower than the plasma frequency, so that the signal will be reflected back to the earth. Another interesting example of plasma oscillations occurs in metals. In a metal we have a contained plasma of positive ions, and free electrons. The density n 0 is very high, so \u03c9 p is also. But it should still be possible to observe the electron oscillations. Now, according to quantum mechanics, a harmonic oscillator with a natural frequency \u03c9 p has energy levels which are separated by the energy increment \u210f \u03c9 p . If, then, one shoots electrons through, say, an aluminum foil, and makes very careful measurements of the electron energies on the other side, one might expect to find that the electrons sometimes lose the energy \u210f \u03c9 p to the plasma oscillations. This does indeed happen. It was first observed experimentally in 1936 that electrons with energies of a few hundred to a few thousand electron volts lost energy in jumps when scattering from or going through a thin metal foil. The effect was not understood until 1953 when Bohm and Pines1 showed that the observations could be explained in terms of quantum excitations of the plasma oscillations in the metal. We turn to another phenomenon in which the locations of charges are governed by a potential that arises in part from the same charges. The resulting effects influence in an important way the behavior of colloids. A colloid consists of a suspension in water of small charged particles which, though microscopic, from an atomic point of view are still very large. If the colloidal particles were not charged, they would tend to coagulate into large lumps; but because of their charge, they repel each other and remain in suspension. Now if there is also some salt dissolved in the water, it will be dissociated into positive and negative ions. (Such a solution of ions is called an electrolyte.) The negative ions are attracted to the colloid particles (assuming their charge is positive) and the positive ions are repelled. We will determine how the ions which surround such a colloidal particle are distributed in space. To keep the ideas simple, we will again solve only a one-dimensional case. If we think of a colloidal particle as a sphere having a very large radius\u2014on an atomic scale!\u2014we can then treat a small part of its surface as a plane. (Whenever one is trying to understand a new phenomenon it is a good idea to take a somewhat oversimplified model; then, having understood the problem with that model, one is better able to proceed to tackle the more exact calculation.) We suppose that the distribution of ions generates a charge density \u03c1(x) , and an electrical potential \u03d5 , related by the electrostatic law \u2207 2 \u03d5=\u2212\u03c1/ \u03f5 0 or, for fields that vary in only one dimension, by d 2 \u03d5 d x 2 =\u2212 \u03c1 \u03f5 0 . (7.28) Now supposing there were such a potential \u03d5(x) , how would the ions distribute themselves in it? This we can determine by the principles of statistical mechanics. Our problem then is to determine \u03d5 so that the resulting charge density from statistical mechanics also satisfies (7.28). According to statistical mechanics (see Chapter 40, Vol. I), particles in thermal equilibrium in a force field are distributed in such a way that the density n of particles at the position x is given by n(x)= n 0 e \u2212U(x)/kT , (7.29) where U(x) is the potential energy, k is Boltzmann\u2019s constant, and T is the absolute temperature. We assume that the ions carry one electronic charge, positive or negative. At the distance x from the surface of a colloidal particle, a positive ion will have potential energy q e \u03d5(x) , so that U(x)= q e \u03d5(x). ( ) \u03d5 ( ) The density of positive ions, n + , is then n + (x)= n 0 e \u2212 q e \u03d5(x)/kT . \u03d5 ( ) / k T Similarly, the density of negative ions is n \u2212 (x)= n 0 e + q e \u03d5(x)/kT . \u03d5 ( ) / k T The total charge density is \u03c1= q e n + \u2212 q e n \u2212 , \u03c1 q n q n or \u03c1= q e n 0 ( e \u2212 q e \u03d5/kT \u2212 e + q e \u03d5/kT ). (7.30) Combining this with Eq. (7.28), we find that the potential \u03d5 must satisfy d 2 \u03d5 d x 2 =\u2212 q e n 0 \u03f5 0 ( e \u2212 q e \u03d5/kT \u2212 e + q e \u03d5/kT ). (7.31) This equation is readily solved in general [multiply both sides by 2(d\u03d5/dx) , and integrate with respect to x ], but to keep the problem as simple as possible, we will consider here only the limiting case in which the potentials are small or the temperature T is high. The case where \u03d5 is small corresponds to a dilute solution. For these cases the exponent is small, and we can approximate e \u00b1 q e \u03d5/kT =1\u00b1 q e \u03d5 kT . (7.32) Equation (7.31) then gives d 2 \u03d5 d x 2 =+ 2 n 0 q 2 e \u03f5 0 kT \u03d5(x). (7.33) Notice that this time the sign on the right is positive. The solutions for \u03d5 are not oscillatory, but exponential. The general solution of Eq. (7.33) is \u03d5=A e \u2212x/D +B e +x/D , (7.34) with D 2 = \u03f5 0 kT 2 n 0 q 2 e . (7.35) The constants A and B must be determined from the conditions of the problem. In our case, B must be zero; otherwise the potential would go to infinity for large x . So we have that \u03d5=A e \u2212x/D , (7.36) in which A is the potential at x=0 , the surface of the colloidal particle. The potential decreases by a factor 1/e each time the distance increases by D , as shown in the graph of Fig. 7\u20137. The number D is called the Debye length, and is a measure of the thickness of the ion sheath that surrounds a large charged particle in an electrolyte. Equation (7.35) says that the sheath gets thinner with increasing concentration of the ions ( n 0 ) or with decreasing temperature. The constant A in Eq. (7.36) is easily obtained if we know the surface charge density \u03c3 on the colloid particle. We know that E n = E x (0)= \u03c3 \u03f5 0 . (7.37) But E is also the gradient of \u2212\u03d5 : E x (0)=\u2212 \u2202\u03d5 \u2202x \u2223 \u2223 \u2223 0 =+ A D , (7.38) from which we get A= \u03c3D \u03f5 0 . (7.39) Using this result in (7.36), we find (by taking x=0 ) that the potential of the colloidal particle is \u03d5(0)= \u03c3D \u03f5 0 . (7.40) You will notice that this potential is the same as the potential difference across a condenser with a plate spacing D and a surface charge density \u03c3 . We have said that the colloidal particles are kept apart by their electrical repulsion. But now we see that the field a little way from the surface of a particle is reduced by the ion sheath that collects around it. If the sheaths get thin enough, the particles have a good chance of knocking against each other. They will then stick, and the colloid will coagulate and precipitate out of the liquid. From our analysis, we understand why adding enough salt to a colloid should cause it to precipitate out. The process is called \u201csalting out a colloid.\u201d Another interesting example is the effect that a salt solution has on protein molecules. A protein molecule is a long, complicated, and flexible chain of amino acids. The molecule has various charges on it, and it sometimes happens that there is a net charge, say negative, which is distributed along the chain. Because of mutual repulsion of the negative charges, the protein chain is kept stretched out. Also, if there are other similar chain molecules present in the solution, they will be kept apart by the same repulsive effects. We can, therefore, have a suspension of chain molecules in a liquid. But if we add salt to the liquid we change the properties of the suspension. As salt is added to the solution, decreasing the Debye distance, the chain molecules can approach one another, and can also coil up. If enough salt is added to the solution, the chain molecules will precipitate out of the solution. There are many chemical effects of this kind that can be understood in terms of electrical forces. As our last example, we would like to describe another interesting property of electric fields. It is one which is made use of in the design of electrical instruments, in the construction of vacuum tubes, and for other purposes. This is the character of the electric field near a grid of charged wires. To make the problem as simple as possible, let us consider an array of parallel wires lying in a plane, the wires being infinitely long and with a uniform spacing between them. If we look at the field a large distance above the plane of the wires, we see a constant electric field, just as though the charge were uniformly spread over a plane. As we approach the grid of wires, the field begins to deviate from the uniform field we found at large distances from the grid. We would like to estimate how close to the grid we have to be in order to see appreciable variations in the potential. Figure 7\u20138 shows a rough sketch of the equipotentials at various distances from the grid. The closer we get to the grid, the larger the variations. As we travel parallel to the grid, we observe that the field fluctuates in a periodic manner. Now we have seen (Chapter 50, Vol. I) that any periodic quantity can be expressed as a sum of sine waves (Fourier\u2019s theorem). Let\u2019s see if we can find a suitable harmonic function that satisfies our field equations. If the wires lie in the xy -plane and run parallel to the y -axis, then we might try terms like \u03d5(x,z)= F n (z)cos 2\u03c0nx a , (7.41) where a is the spacing of the wires and n is the harmonic number. (We have assumed long wires, so there should be no variation with y .) A complete solution would be made up of a sum of such terms for n=1 , 2 , 3 , \u2026 . If this is to be a valid potential, it must satisfy Laplace\u2019s equation in the region above the wires (where there are no charges). That is, \u2202 2 \u03d5 \u2202 x 2 + \u2202 2 \u03d5 \u2202 z 2 =0. 2 2 Trying this equation on the \u03d5 in (7.41), we find that \u2212 4 \u03c0 2 n 2 a 2 F n (z)cos 2\u03c0nx a + d 2 F n d z 2 cos 2\u03c0nx a =0, (7.42) or that F n (z) must satisfy d 2 F n d z 2 = 4 \u03c0 2 n 2 a 2 F n . (7.43) So we must have F n = A n e \u2212z/ z 0 , (7.44) where z 0 = a 2\u03c0n . (7.45) We have found that if there is a Fourier component of the field of harmonic n , that component will decrease exponentially with a characteristic distance z 0 =a/2\u03c0n . For the first harmonic ( n=1 ), the amplitude falls by the factor e \u22122\u03c0 (a large decrease) each time we increase z by one grid spacing a . The other harmonics fall off even more rapidly as we move away from the grid. We see that if we are only a few times the distance a away from the grid, the field is very nearly uniform, i.e., the oscillating terms are small. There would, of course, always remain the \u201czero harmonic\u201d field \u03d5 0 =\u2212 E 0 z \u03d5 E to give the uniform field at large z . For a complete solution, we would combine this term with a sum of terms like (7.41) with F n from (7.44). The coefficients A n would be adjusted so that the total sum would, when differentiated, give an electric field that would fit the charge density \u03bb of the grid wires. The method we have just developed can be used to explain why electrostatic shielding by means of a screen is often just as good as with a solid metal sheet. Except within a distance from the screen a few times the spacing of the screen wires, the fields inside a closed screen are zero. We see why copper screen\u2014lighter and cheaper than copper sheet\u2014is often used to shield sensitive electrical equipment from external disturbing fields."
    },
    {
        "input": "Modes",
        "output": "This chapter will consider some of the remarkable phenomena which are a result of confining waves in some finite region. We will be led first to discover a few particular facts about vibrating strings, for example, and then the generalization of these facts will give us a principle which is probably the most far-reaching principle of mathematical physics. Our first example of confining waves will be to confine a wave at one boundary. Let us take the simple example of a one-dimensional wave on a string. One could equally well consider sound in one dimension against a wall, or other situations of a similar nature, but the example of a string will be sufficient for our present purposes. Suppose that the string is held at one end, for example by fastening it to an \u201cinfinitely solid\u201d wall. This can be expressed mathematically by saying that the displacement y of the string at the position x=0 must be zero, because the end does not move. Now if it were not for the wall, we know that the general solution for the motion is the sum of two functions, F(x\u2212ct) and G(x+ct) , the first representing a wave travelling one way in the string, and the second a wave travelling the other way in the string: y=F(x\u2212ct)+G(x+ct) is the general solution for any string. But we have next to satisfy the condition that the string does not move at one end. If we put x=0 in Eq. (49.1) and examine y for any value of t , we get y=F(\u2212ct)+G(+ct) . Now if this is to be zero for all times, it means that the function G(ct) must be \u2212F(\u2212ct) . In other words, G of anything must be \u2212F of minus that same thing. If this result is put back into Eq. (49.1), we find that the solution for the problem is y=F(x\u2212ct)\u2212F(\u2212x\u2212ct). It is easy to check that we will get y=0 if we set x=0 . Figure 49\u20131 shows a wave travelling in the negative x -direction near x=0 , and a hypothetical wave travelling in the other direction reversed in sign and on the other side of the origin. We say hypothetical because, of course, there is no string to vibrate on that side of the origin. The total motion of the string is to be regarded as the sum of these two waves in the region of positive x . As they reach the origin, they will always cancel at x=0 , and finally the second (reflected) wave will be the only one to exist for positive x and it will, of course, be travelling in the opposite direction. These results are equivalent to the following statement: if a wave reaches the clamped end of a string, it will be reflected with a change in sign. Such a reflection can always be understood by imagining that what is coming to the end of the string comes out upside down from behind the wall. In short, if we assume that the string is infinite and that whenever we have a wave going one way we have another one going the other way with the stated symmetry, the displacement at x=0 will always be zero and it would make no difference if we clamped the string there. The next point to be discussed is the reflection of a periodic wave. Suppose that the wave represented by F(x\u2212ct) is a sine wave and has been reflected; then the reflected wave \u2212F(\u2212x\u2212ct) is also a sine wave of the same frequency, but travelling in the opposite direction. This situation can be most simply described by using the complex function notation: F(x\u2212ct)=ei\u03c9(t\u2212x/c) and F(\u2212x\u2212ct)=ei\u03c9(t+x/c) . It can be seen that if these are substituted in (49.2) and if x is set equal to 0 , then y=0 for all values of t , so it satisfies the necessary condition. Because of the properties of exponentials, this can be written in a simpler form: y=ei\u03c9t(e\u2212i\u03c9x/c\u2212ei\u03c9x/c)=\u22122iei\u03c9tsin(\u03c9x/c). There is something interesting and new here, in that this solution tells us that if we look at any fixed x , the string oscillates at frequency \u03c9 . No matter where this point is, the frequency is the same! But there are some places, in particular wherever sin(\u03c9x/c)=0 , where there is no displacement at all. Furthermore, if at any time t we take a snapshot of the vibrating string, the picture will be a sine wave. However, the displacement of this sine wave will depend upon the time t . From inspection of Eq. (49.3) we can see that the length of one cycle of the sine wave is equal to the wavelength of either of the superimposed waves: \u03bb=2\u03c0c/\u03c9. The points where there is no motion satisfy the condition sin(\u03c9x/c)=0 , which means that (\u03c9x/c)=0 , \u03c0 , 2\u03c0 , \u2026, n\u03c0 , \u2026 These points are called nodes. Between any two successive nodes, every point moves up and down sinusoidally, but the pattern of motion stays fixed in space. This is the fundamental characteristic of what we call a mode. If one can find a pattern of motion which has the property that at any point the object moves perfectly sinusoidally, and that all points move at the same frequency (though some will move more than others), then we have what is called a mode. The next interesting problem is to consider what happens if the string is held at both ends, say at x=0 and x=L . We can begin with the idea of the reflection of waves, starting with some kind of a bump moving in one direction. As time goes on, we would expect the bump to get near one end, and as time goes still further it will become a kind of little wobble, because it is combining with the reversed-image bump which is coming from the other side. Finally the original bump will disappear and the image bump will move in the other direction to repeat the process at the other end. This problem has an easy solution, but an interesting question is whether we can have a sinusoidal motion (the solution just described is periodic, but of course it is not sinusoidally periodic). Let us try to put a sinusoidally periodic wave on a string. If the string is tied at one end, we know it must look like our earlier solution (49.3). If it is tied at the other end, it has to look the same at the other end. So the only possibility for periodic sinusoidal motion is that the sine wave must neatly fit into the string length. If it does not fit into the string length, then it is not a natural frequency at which the string can continue to oscillate. In short, if the string is started with a sine wave shape that just fits in, then it will continue to keep that perfect shape of a sine wave and will oscillate harmonically at some frequency. Mathematically, we can write sinkx for the shape, where k is equal to the factor (\u03c9/c) in Eqs. (49.3) and (49.4), and this function will be zero at x=0 . However, it must also be zero at the other end. The significance of this is that k is no longer arbitrary, as was the case for the half-open string. With the string closed at both ends, the only possibility is that sin(kL)=0 , because this is the only condition that will keep both ends fixed. Now in order for a sine to be zero, the angle must be either 0 , \u03c0 , 2\u03c0 , or some other integral multiple of \u03c0 . The equation kL=n\u03c0 (49.5) will, therefore, give any one of the possible k \u2019s, depending on what integer is put in. For each of the k \u2019s there is a certain frequency \u03c9 , which, according to (49.3), is simply \u03c9=kc=n\u03c0c/L. (49.6) So we have found the following: that a string has a property that it can have sinusoidal motions, but only at certain frequencies. This is the most important characteristic of confined waves. No matter how complicated the system is, it always turns out that there are some patterns of motion which have a perfect sinusoidal time dependence, but with frequencies that are a property of the particular system and the nature of its boundaries. In the case of the string we have many different possible frequencies, each one, by definition, corresponding to a mode, because a mode is a pattern of motion which repeats itself sinusoidally. Figure 49\u20132 shows the first three modes for a string. For the first mode the wavelength \u03bb is 2L . This can be seen if one continues the wave out to x=2L to obtain one complete cycle of the sine wave. The angular frequency \u03c9 is 2\u03c0c divided by the wavelength, in general, and in this case, since \u03bb is 2L , the frequency is \u03c0c/L , which is in agreement with (49.6) with n=1 . Let us call the first mode frequency \u03c9 1 . Now the next mode shows two loops with one node in the middle. For this mode the wavelength, then, is simply L . The corresponding value of k is twice as great and the frequency is twice as large; it is 2 \u03c9 1 . For the third mode it is 3 \u03c9 1 , and so on. So all the different frequencies of the string are multiples, 1 , 2 , 3 , 4 , and so on, of the lowest frequency \u03c9 1 . Returning now to the general motion of the string, it turns out that any possible motion can always be analyzed by asserting that more than one mode is operating at the same time. In fact, for general motion an infinite number of modes must be excited at the same time. To get some idea of this, let us illustrate what happens when there are two modes oscillating at the same time: Suppose that we have the first mode oscillating as shown by the sequence of pictures in Fig. 49\u20133, which illustrates the deflection of the string for equally spaced time intervals extending through half a cycle of the lowest frequency. Now, at the same time, we suppose that there is an oscillation of the second mode also. Figure 49\u20133 also shows a sequence of pictures of this mode, which at the start is 90 \u2218 out of phase with the first mode. This means that at the start it has no displacement, but the two halves of the string have oppositely directed velocities. Now we recall a general principle relating to linear systems: if there are any two solutions, then their sum is also a solution. Therefore a third possible motion of the string would be a displacement obtained by adding the two solutions shown in Fig. 49\u20133. The result, also shown in the figure, begins to suggest the idea of a bump running back and forth between the ends of the string, although with only two modes we cannot make a very good picture of it; more modes are needed. This result is, in fact, a special case of a great principle for linear systems: Any motion at all can be analyzed by assuming that it is the sum of the motions of all the different modes, combined with appropriate amplitudes and phases. The importance of the principle derives from the fact that each mode is very simple\u2014it is nothing but a sinusoidal motion in time. It is true that even the general motion of a string is not really very complicated, but there are other systems, for example the whipping of an airplane wing, in which the motion is much more complicated. Nevertheless, even with an airplane wing, we find there is a certain particular way of twisting which has one frequency and other ways of twisting that have other frequencies. If these modes can be found, then the complete motion can always be analyzed as a superposition of harmonic oscillations (except when the whipping is of such degree that the system can no longer be considered as linear). The next example to be considered is the interesting situation of modes in two dimensions. Up to this point we have talked only about one-dimensional situations\u2014a stretched string or sound waves in a tube. Ultimately we should consider three dimensions, but an easier step will be that to two dimensions. Consider for definiteness a rectangular rubber drumhead which is confined so as to have no displacement anywhere on the rectangular edge, and let the dimensions of the rectangle be a and b , as shown in Fig. 49\u20134. Now the question is, what are the characteristics of the possible motion? We can start with the same procedure used for the string. If we had no confinement at all, we would expect waves travelling along with some kind of wave motion. For example, ( e i\u03c9t )( e \u2212i k x x+i k y y ) would represent a sine wave travelling in some direction which depends on the relative values of k x and k y . Now how can we make the x -axis, that is, the line y=0 , a node? Using the ideas developed for the one-dimensional string, we can imagine another wave represented by the complex function (\u2212 e i\u03c9t )( e \u2212i k x x\u2212i k y y ) . The superposition of these waves will give zero displacement at y=0 regardless of the values of x and t . (Although these functions are defined for negative y where there is no drumhead to vibrate, this can be ignored, since the displacement is truly zero at y=0 .) In this case we can look upon the second function as the reflected wave. However, we want a nodal line at y=b as well as at y=0 . How do we do that? The solution is related to something we did when studying reflection from crystals. These waves which cancel each other at y=0 will do the same at y=b only if 2bsin\u03b8 is an integral multiple of \u03bb , where \u03b8 is the angle shown in Fig. 49\u20134: m\u03bb=2bsin\u03b8,m=0, 1, 2, \u2026 (49.7) Now in the same way we can make the y -axis a nodal line by adding two more functions \u2212( e i\u03c9t )( e +i k x x+i k y y ) and +( e i\u03c9t )( e +i k x x\u2212i k y y ) , each representing a reflection of one of the other two waves from the x=0 line. The condition for a nodal line at x=a is similar to the one for y=b . It is that 2acos\u03b8 must also be an integral multiple of \u03bb : n\u03bb=2acos\u03b8. (49.8) Then the final result is that the waves bouncing about in the box produce a standing-wave pattern, that is, a definite mode. So we must satisfy the above two conditions if we are to have a mode. Let us first find the wavelength. This can be obtained by eliminating the angle \u03b8 from (49.7) and (49.8) to obtain the wavelength in terms of a , b , n and m . The easiest way to do that is to divide both sides of the respective equations by 2b and 2a , square them, and add the two equations together. The result is sin 2 \u03b8+ cos 2 \u03b8=1 =(n\u03bb/2a ) 2 +(m\u03bb/2b ) 2 , which can be solved for \u03bb : 1 \u03bb 2 = n 2 4 a 2 + m 2 4 b 2 . (49.9) In this way we have determined the wavelength in terms of two integers, and from the wavelength we immediately get the frequency \u03c9 , because, as we know, the frequency is equal to 2\u03c0c divided by the wavelength. This result is interesting and important enough that we should deduce it by a purely mathematical analysis instead of by an argument about the reflections. Let us represent the vibration by a superposition of four waves chosen so that the four lines x=0 , x=a , y=0 , and y=b are all nodes. In addition we shall require that all waves have the same frequency, so that the resulting motion will represent a mode. From our earlier treatment of light reflection we know that ( e i\u03c9t )( e \u2212i k x x+i k y y ) represents a wave travelling in the direction indicated in Fig. 49\u20134. Equation (49.6), that is, k=\u03c9/c , still holds, provided k 2 = k 2 x + k 2 y . (49.10) It is clear from the figure that k x =kcos\u03b8 and k y =ksin\u03b8 . Now our equation for the displacement, say \u03d5 , of the rectangular drumhead takes on the grand form \u03d5=[ e i\u03c9t ][ e (\u2212i k x x+i k y y) \u2212 e (+i k x x+i k y y) \u2212 e (\u2212i k x x\u2212i k y y) + e (+i k x x\u2212i k y y) ]. (49.11a) Although this looks rather a mess, the sum of these things now is not very hard. The exponentials can be combined to give sine functions, so that the displacement turns out to be \u03d5=[4sin k x xsin k y y][ e i\u03c9t ]. (49.11b) In other words, it is a sinusoidal oscillation, all right, with a pattern that is also sinusoidal in both the x - and the y -direction. Our boundary conditions are of course satisfied at x=0 and y=0 . We also want \u03d5 to be zero when x=a and when y=b . Therefore we have to put in two other conditions: k x a must be an integral multiple of \u03c0 , and k y b must be another integral multiple of \u03c0 . Since we have seen that k x =kcos\u03b8 and k y =ksin\u03b8 , we immediately get equations (49.7) and (49.8) and from these the final result (49.9). Now let us take as an example a rectangle whose width is twice the height. If we take a=2b and use Eqs. (49.4) and (49.9), we can calculate the frequencies of all of the modes: \u03c9 2 =( \u03c0c b ) 2 4 m 2 + n 2 4 . (49.12) Table 49\u20131 lists a few of the simple modes and also shows their shape in a qualitative way. The most important point to be emphasized about this particular case is that the frequencies are not multiples of each other, nor are they multiples of any number. The idea that the natural frequencies are harmonically related is not generally true. It is not true for a system of more than one dimension, nor is it true for one-dimensional systems which are more complicated than a string with uniform density and tension. A simple example of the latter is a hanging chain in which the tension is higher at the top than at the bottom. If such a chain is set in harmonic oscillation, there are various modes and frequencies, but the frequencies are not simple multiples of any number, nor are the mode shapes sinusoidal. The modes of more complicated systems are still more elaborate. For example, inside the mouth we have a cavity above the vocal cords, and by moving the tongue and the lips, and so forth, we make an open-ended pipe or a closed-ended pipe of different diameters and shapes; it is a terribly complicated resonator, but it is a resonator nevertheless. Now when one talks with the vocal cords, they are made to produce some kind of tone. The tone is rather complicated and there are many sounds coming out, but the cavity of the mouth further modifies that tone because of the various resonant frequencies of the cavity. For instance, a singer can sing various vowels, a, or o, or oo, and so forth, at the same pitch, but they sound different because the various harmonics are in resonance in this cavity to different degrees. The very great importance of the resonant frequencies of a cavity in modifying the voice sounds can be demonstrated by a simple experiment. Since the speed of sound goes as the reciprocal of the square root of the density, the speed of sound may be varied by using different gases. If one uses helium instead of air, so that the density is lower, the speed of sound is much higher, and all the frequencies of a cavity will be raised. Consequently if one fills one\u2019s lungs with helium before speaking, the character of his voice will be drastically altered even though the vocal cords may still be vibrating at the same frequency. Finally we should emphasize that not only do modes exist for complicated continuous systems, but also for very simple mechanical systems. A good example is the system of two coupled pendulums discussed in the preceding chapter. In that chapter it was shown that the motion could be analyzed as a superposition of two harmonic motions with different frequencies. So even this system can be analyzed in terms of harmonic motions or modes. The string has an infinite number of modes and the two-dimensional surface also has an infinite number of modes. In a sense it is a double infinity, if we know how to count infinities. But a simple mechanical thing which has only two degrees of freedom, and requires only two variables to describe it, has only two modes. Let us make a mathematical analysis of these two modes for the case where the pendulums are of equal length. Let the displacement of one be x , and the displacement of the other be y , as shown in Fig. 49\u20135. Without a spring, the force on the first mass is proportional to the displacement of that mass, because of gravity. There would be, if there were no spring, a certain natural frequency \u03c9 0 for this one alone. The equation of motion without a spring would be m d 2 x d t 2 =\u2212m \u03c9 2 0 x. (49.13) The other pendulum would swing in the same way if there were no spring. In addition to the force of restoration due to gravitation, there is an additional force pulling the first mass. That force depends upon the excess distance of x over y and is proportional to that difference, so it is some constant which depends on the geometry, times (x\u2212y) . The same force in reverse sense acts on the second mass. The equations of motion that have to be solved are therefore m d 2 x d t 2 =\u2212m \u03c9 2 0 x\u2212k(x\u2212y), m d 2 y d t 2 =\u2212m \u03c9 2 0 y\u2212k(y\u2212x). (49.14) In order to find a motion in which both of the masses move at the same frequency, we must determine how much each mass moves. In other words, pendulum x and pendulum y will oscillate at the same frequency, but their amplitudes must have certain values, A and B , whose relation is fixed. Let us try this solution: x=A e i\u03c9t ,y=B e i\u03c9t . (49.15) If these are substituted in Eqs. (49.14) and similar terms are collected, the results are ( \u03c9 2 \u2212 \u03c9 2 0 \u2212 k m )A ( \u03c9 2 \u2212 \u03c9 2 0 \u2212 k m )B =\u2212 k m B, =\u2212 k m A. (49.16) The equations as written have had the common factor e i\u03c9t removed and have been divided by m . Now we see that we have two equations for what looks like two unknowns. But there really are not two unknowns, because the whole size of the motion is something that we cannot determine from these equations. The above equations can determine only the ratio of A to B , but they must both give the same ratio. The necessity for both of these equations to be consistent is a requirement that the frequency be something very special. In this particular case this can be worked out rather easily. If the two equations are multiplied together, the result is ( \u03c9 2 \u2212 \u03c9 2 0 \u2212 k m ) 2 AB=( k m ) 2 AB. (49.17) The term AB can be removed from both sides unless A and B are zero, which means there is no motion at all. If there is motion, then the other terms must be equal, giving a quadratic equation to solve. The result is that there are two possible frequencies: \u03c9 2 1 = \u03c9 2 0 , \u03c9 2 2 = \u03c9 2 0 + 2k m . (49.18) Furthermore, if these values of frequency are substituted back into Eq. (49.16), we find that for the first frequency A=B , and for the second frequency A=\u2212B . These are the \u201cmode shapes,\u201d as can be readily verified by experiment. It is clear that in the first mode, where A=B , the spring is never stretched, and both masses oscillate at the frequency \u03c9 0 , as though the spring were absent. In the other solution, where A=\u2212B , the spring contributes a restoring force and raises the frequency. A more interesting case results if the pendulums have different lengths. The analysis is very similar to that given above, and is left as an exercise for the reader. Now let us summarize the ideas discussed above, which are all aspects of what is probably the most general and wonderful principle of mathematical physics. If we have a linear system whose character is independent of the time, then the motion does not have to have any particular simplicity, and in fact may be exceedingly complex, but there are very special motions, usually a series of special motions, in which the whole pattern of motion varies exponentially with the time. For the vibrating systems that we are talking about now, the exponential is imaginary, and instead of saying \u201cexponentially\u201d we might prefer to say \u201csinusoidally\u201d with time. However, one can be more general and say that the motions will vary exponentially with the time in very special modes, with very special shapes. The most general motion of the system can always be represented as a superposition of motions involving each of the different exponentials. This is worth stating again for the case of sinusoidal motion: a linear system need not be moving in a purely sinusoidal motion, i.e., at a definite single frequency, but no matter how it does move, this motion can be represented as a superposition of pure sinusoidal motions. The frequency of each of these motions is a characteristic of the system, and the pattern or waveform of each motion is also a characteristic of the system. The general motion in any such system can be characterized by giving the strength and the phase of each of these modes, and adding them all together. Another way of saying this is that any linear vibrating system is equivalent to a set of independent harmonic oscillators, with the natural frequencies corresponding to the modes. We conclude this chapter by remarking on the connection of modes with quantum mechanics. In quantum mechanics the vibrating object, or the thing that varies in space, is the amplitude of a probability function that gives the probability of finding an electron, or system of electrons, in a given configuration. This amplitude function can vary in space and time, and satisfies, in fact, a linear equation. But in quantum mechanics there is a transformation, in that what we call frequency of the probability amplitude is equal, in the classical idea, to energy. Therefore we can translate the principle stated above to this case by taking the word frequency and replacing it with energy. It becomes something like this: a quantum-mechanical system, for example an atom, need not have a definite energy, just as a simple mechanical system does not have to have a definite frequency; but no matter how the system behaves, its behavior can always be represented as a superposition of states of definite energy. The energy of each state is a characteristic of the atom, and so is the pattern of amplitude which determines the probability of finding particles in different places. The general motion can be described by giving the amplitude of each of these different energy states. This is the origin of energy levels in quantum mechanics. Since quantum mechanics is represented by waves, in the circumstance in which the electron does not have enough energy to ultimately escape from the proton, they are confined waves. Like the confined waves of a string, there are definite frequencies for the solution of the wave equation for quantum mechanics. The quantum-mechanical interpretation is that these are definite energies. Therefore a quantum-mechanical system, because it is represented by waves, can have definite states of fixed energy; examples are the energy levels of various atoms."
    },
    {
        "input": "The Dependence of Amplitudes on Time",
        "output": "We want now to talk a little bit about the behavior of probability amplitudes in time. We say a \u201clittle bit,\u201d because the actual behavior in time necessarily involves the behavior in space as well. Thus, we get immediately into the most complicated possible situation if we are to do it correctly and in detail. We are always in the difficulty that we can either treat something in a logically rigorous but quite abstract way, or we can do something which is not at all rigorous but which gives us some idea of a real situation\u2014postponing until later a more careful treatment. With regard to energy dependence, we are going to take the second course. We will make a number of statements. We will not try to be rigorous\u2014but will just be telling you things that have been found out, to give you some feeling for the behavior of amplitudes as a function of time. As we go along, the precision of the description will increase, so don\u2019t get nervous that we seem to be picking things out of the air. It is, of course, all out of the air\u2014the air of experiment and of the imagination of people. But it would take us too long to go over the historical development, so we have to plunge in somewhere. We could plunge into the abstract and deduce everything\u2014which you would not understand\u2014or we could go through a large number of experiments to justify each statement. We choose to do something in between. An electron alone in empty space can, under certain circumstances, have a certain definite energy. For example, if it is standing still (so it has no translational motion, no momentum, or kinetic energy), it has its rest energy. A more complicated object like an atom can also have a definite energy when standing still, but it could also be internally excited to another energy level. (We will describe later the machinery of this.) We can often think of an atom in an excited state as having a definite energy, but this is really only approximately true. An atom doesn\u2019t stay excited forever because it manages to discharge its energy by its interaction with the electromagnetic field. So there is some amplitude that a new state is generated\u2014with the atom in a lower state, and the electromagnetic field in a higher state, of excitation. The total energy of the system is the same before and after, but the energy of the atom is reduced. So it is not precise to say an excited atom has a definite energy; but it will often be convenient and not too wrong to say that it does. [Incidentally, why does it go one way instead of the other way? Why does an atom radiate light? The answer has to do with entropy. When the energy is in the electromagnetic field, there are so many different ways it can be\u2014so many different places where it can wander\u2014that if we look for the equilibrium condition, we find that in the most probable situation the field is excited with a photon, and the atom is de-excited. It takes a very long time for the photon to come back and find that it can knock the atom back up again. It\u2019s quite analogous to the classical problem: Why does an accelerating charge radiate? It isn\u2019t that it \u201cwants\u201d to lose energy, because, in fact, when it radiates, the energy of the world is the same as it was before. Radiation or absorption goes in the direction of increasing entropy.] Nuclei can also exist in different energy levels, and in an approximation which disregards the electromagnetic effects, we can say that a nucleus in an excited state stays there. Although we know that it doesn\u2019t stay there forever, it is often useful to start out with an approximation which is somewhat idealized and easier to think about. Also it is often a legitimate approximation under certain circumstances. (When we first introduced the classical laws of a falling body, we did not include friction, but there is almost never a case in which there isn\u2019t some friction.) Then there are the subnuclear \u201cstrange particles,\u201d which have various masses. But the heavier ones disintegrate into other light particles, so again it is not correct to say that they have a precisely definite energy. That would be true only if they lasted forever. So when we make the approximation that they have a definite energy, we are forgetting the fact that they must blow up. For the moment, then, we will intentionally forget about such processes and learn later how to take them into account. Suppose we have an atom\u2014or an electron, or any particle\u2014which at rest would have a definite energy E0 . By the energy E0 we mean the mass of the whole thing times c2 . This mass includes any internal energy; so an excited atom has a mass which is different from the mass of the same atom in the ground state. (The ground state means the state of lowest energy.) We will call E0 the \u201cenergy at rest.\u201d For an atom at rest, the quantum mechanical amplitude to find an atom at a place is the same everywhere; it does not depend on position. This means, of course, that the probability of finding the atom anywhere is the same. But it means even more. The probability could be independent of position, and still the phase of the amplitude could vary from point to point. But for a particle at rest, the complete amplitude is identical everywhere. It does, however, depend on the time. For a particle in a state of definite energy E0 , the amplitude to find the particle at (x,y,z) at the time t is ae\u2212i(E0/\u210f)t, where a is some constant. The amplitude to be at any point in space is the same for all points, but depends on time according to (7.1). We shall simply assume this rule to be true. Of course, we could also write (7.1) as ae\u2212i\u03c9t, with \u210f\u03c9=E0=Mc2, where M is the rest mass of the atomic state, or particle. There are three different ways of specifying the energy: by the frequency of an amplitude, by the energy in the classical sense, or by the inertia. They are all equivalent; they are just different ways of saying the same thing. You may be thinking that it is strange to think of a \u201cparticle\u201d which has equal amplitudes to be found throughout all space. After all, we usually imagine a \u201cparticle\u201d as a small object located \u201csomewhere.\u201d But don\u2019t forget the uncertainty principle. If a particle has a definite energy, it has also a definite momentum. If the uncertainty in momentum is zero, the uncertainty relation, \u0394p\u0394x=\u210f , tells us that the uncertainty in the position must be infinite, and that is just what we are saying when we say that there is the same amplitude to find the particle at all points in space. If the internal parts of an atom are in a different state with a different total energy, then the variation of the amplitude with time is different. If you don\u2019t know in which state it is, there will be a certain amplitude to be in one state and a certain amplitude to be in another\u2014and each of these amplitudes will have a different frequency. There will be an interference between these different components\u2014like a beat-note\u2014which can show up as a varying probability. Something will be \u201cgoing on\u201d inside of the atom\u2014even though it is \u201cat rest\u201d in the sense that its center of mass is not drifting. However, if the atom has one definite energy, the amplitude is given by (7.1), and the absolute square of this amplitude does not depend on time. You see, then, that if a thing has a definite energy and if you ask any probability question about it, the answer is independent of time. Although the amplitudes vary with time, if the energy is definite they vary as an imaginary exponential, and the absolute value doesn\u2019t change. That\u2019s why we often say that an atom in a definite energy level is in a stationary state. If you make any measurements of the things inside, you\u2019ll find that nothing (in probability) will change in time. In order to have the probabilities change in time, we have to have the interference of two amplitudes at two different frequencies, and that means that we cannot know what the energy is. The object will have one amplitude to be in a state of one energy and another amplitude to be in a state of another energy. That\u2019s the quantum mechanical description of something when its behavior depends on time. If we have a \u201ccondition\u201d which is a mixture of two different states with different energies, then the amplitude for each of the two states varies with time according to Eq. (7.2), for instance, as e \u2212i( E 1 /\u210f)t and e \u2212i( E 2 /\u210f)t . (7.3) And if we have some combination of the two, we will have an interference. But notice that if we added a constant to both energies, it wouldn\u2019t make any difference. If somebody else were to use a different scale of energy in which all the energies were increased (or decreased) by a constant amount\u2014say, by the amount A \u2014then the amplitudes in the two states would, from his point of view, be e \u2212i( E 1 +A)t/\u210f and e \u2212i( E 2 +A)t/\u210f . (7.4) All of his amplitudes would be multiplied by the same factor e \u2212i(A/\u210f)t , and all linear combinations, or interferences, would have the same factor. When we take the absolute squares to find the probabilities, all the answers would be the same. The choice of an origin for our energy scale makes no difference; we can measure energy from any zero we want. For relativistic purposes it is nice to measure the energy so that the rest mass is included, but for many purposes that aren\u2019t relativistic it is often nice to subtract some standard amount from all energies that appear. For instance, in the case of an atom, it is usually convenient to subtract the energy M s c 2 , where M s is the mass of all the separate pieces\u2014the nucleus and the electrons\u2014which is, of course, different from the mass of the atom. For other problems it may be useful to subtract from all energies the amount M g c 2 , where M g is the mass of the whole atom in the ground state; then the energy that appears is just the excitation energy of the atom. So, sometimes we may shift our zero of energy by some very large constant, but it doesn\u2019t make any difference, provided we shift all the energies in a particular calculation by the same constant. So much for a particle standing still. If we suppose that the relativity theory is right, a particle at rest in one inertial system can be in uniform motion in another inertial system. In the rest frame of the particle, the probability amplitude is the same for all x , y , and z but varies with t . The magnitude of the amplitude is the same for all t , but the phase depends on t . We can get a kind of a picture of the behavior of the amplitude if we plot lines of equal phase\u2014say, lines of zero phase\u2014as a function of x and t . For a particle at rest, these equal-phase lines are parallel to the x -axis and are equally spaced in the t -coordinate, as shown by the dashed lines in Fig. 7\u20131. In a different frame\u2014 x \u2032 , y \u2032 , z \u2032 , t \u2032 \u2014that is moving with respect to the particle in, say, the x -direction, the x \u2032 and t \u2032 coordinates of any particular point in space are related to x and t by the Lorentz transformation. This transformation can be represented graphically by drawing x \u2032 and t \u2032 axes, as is done in Fig. 7\u20131. (See Chapter 17, Vol. I, Fig. 17\u20132) You can see that in the x \u2032 - t \u2032 system, points of equal phase1 have a different spacing along the t \u2032 -axis, so the frequency of the time variation is different. Also there is a variation of the phase with x \u2032 , so the probability amplitude must be a function of x \u2032 . Under a Lorentz transformation for the velocity v , say along the negative x -direction, the time t is related to the time t \u2032 by t= t \u2032 \u2212 x \u2032 v/ c 2 1\u2212 v 2 / c 2 \u2212 \u2212 \u2212 \u2212 \u2212 \u2212 \u2212 \u2212 \u221a , \u2032 \u2032 2 so our amplitude now varies as e \u2212(i/\u210f) E 0 t = e \u2212(i/\u210f)( E 0 t \u2032 / 1\u2212 v 2 / c 2 \u221a \u2212 E 0 v x \u2032 / c 2 1\u2212 v 2 / c 2 \u221a ) . \u2032 \u2032 In the prime system it varies in space as well as in time. If we write the amplitude as e \u2212(i/\u210f)( E \u2032 p t \u2032 \u2212 p \u2032 x \u2032 ) , \u2032 \u2032 \u2032 \u2032 we see that E \u2032 p = E 0 / 1\u2212 v 2 / c 2 \u2212 \u2212 \u2212 \u2212 \u2212 \u2212 \u2212 \u2212 \u221a is the energy computed classically for a particle of rest energy E 0 travelling at the velocity v , and p \u2032 = E \u2032 p v/ c 2 is the corresponding particle momentum. You know that x \u03bc =(ct,x,y,z) and p \u03bc =(E/c, p x , p y , p z ) are four-vectors, and that p \u03bc x \u03bc =Et\u2212p\u22c5x is a scalar invariant. In the rest frame of the particle, p \u03bc x \u03bc is just Et ; so if we transform to another frame, Et will be replaced by E \u2032 t \u2032 \u2212 p \u2032 \u22c5 x \u2032 . \u2032 \u2032 Thus, the probability amplitude of a particle which has the momentum p will be proportional to e \u2212(i/\u210f)( E p t\u2212p\u22c5x) , (7.5) where E p is the energy of the particle whose momentum is p , that is, E p = (pc ) 2 + E 2 0 \u2212 \u2212 \u2212 \u2212 \u2212 \u2212 \u2212 \u2212 \u2212 \u221a , (7.6) where E 0 is, as before, the rest energy. For nonrelativistic problems, we can write E p = M s c 2 + W p , (7.7) where W p is the energy over and above the rest energy M s c 2 of the parts of the atom. In general, W p would include both the kinetic energy of the atom as well as its binding or excitation energy, which we can call the \u201cinternal\u201d energy. We would write W p = W int + p 2 2M , (7.8) and the amplitudes would be e \u2212(i/\u210f)( W p t\u2212p\u22c5x) . (7.9) Because we will generally be doing nonrelativistic calculations, we will use this form for the probability amplitudes. Note that our relativistic transformation has given us the variation of the amplitude of an atom which moves in space without any additional assumptions. The wave number of the space variations is, from (7.9), k= p \u210f ; (7.10) so the wavelength is \u03bb= 2\u03c0 k = h p . (7.11) This is the same wavelength we have used before for particles with the momentum p . This formula was first arrived at by de Broglie in just this way. For a moving particle, the frequency of the amplitude variations is still given by \u210f\u03c9= W p . (7.12) The absolute square of (7.9) is just 1 , so for a particle in motion with a definite energy, the probability of finding it is the same everywhere and does not change with time. (It is important to notice that the amplitude is a complex wave. If we used a real sine wave, the square would vary from point to point, which would not be right.) We know, of course, that there are situations in which particles move from place to place so that the probability depends on position and changes with time. How do we describe such situations? We can do that by considering amplitudes which are a superposition of two or more amplitudes for states of definite energy. We have already discussed this situation in Chapter 48 of Vol. I\u2014even for probability amplitudes! We found that the sum of two amplitudes with different wave numbers k (that is, momenta) and frequencies \u03c9 (that is, energies) gives interference humps, or beats, so that the square of the amplitude varies with space and time. We also found that these beats move with the so-called \u201cgroup velocity\u201d given by v g = \u0394\u03c9 \u0394k , \u0394 where \u0394k and \u0394\u03c9 are the differences between the wave numbers and frequencies for the two waves. For more complicated waves\u2014made up of the sum of many amplitudes all near the same frequency\u2014the group velocity is v g = d\u03c9 dk . (7.13) Taking \u03c9= E p /\u210f and k=p/\u210f , we see that v g = d E p dp . (7.14) Using Eq. (7.6), we have d E p dp = c 2 p E p . (7.15) At nonrelativistic speeds E p \u2248M c 2 , so d E p dp = p M , (7.16) which is just the classical velocity of the particle. Alternatively, if we use the nonrelativistic expressions Eqs. (7.7) and (7.8), we have \u03c9= W p \u210f andk= p \u210f , W and d\u03c9 dk = d W p dp = d dp ( p 2 2M )= p M , (7.17) which is again the classical velocity. Our result, then, is that if we have several amplitudes for pure energy states of nearly the same energy, their interference gives \u201clumps\u201d in the probability that move through space with a velocity equal to the velocity of a classical particle of that energy. We should remark, however, that when we say we can add two amplitudes of different wave number together to get a beat-note that will correspond to a moving particle, we have introduced something new\u2014something that we cannot deduce from the theory of relativity. We said what the amplitude did for a particle standing still and then deduced what it would do if the particle were moving. But we cannot deduce from these arguments what would happen when there are two waves moving with different speeds. If we stop one, we cannot stop the other. So we have added tacitly the extra hypothesis that not only is (7.9) a possible solution, but that there can also be solutions with all kinds of p \u2019s for the same system, and that the different terms will interfere. Now we would like to discuss what happens when the energy of a particle can change. We begin by thinking of a particle which moves in a force field described by a potential. We discuss first the effect of a constant potential. Suppose that we have a large metal can which we have raised to some electrostatic potential \u03d5 , as in Fig. 7\u20132. If there are charged objects inside the can, their potential energy will be q\u03d5 , which we will call V , and will be absolutely independent of position. Then there can be no change in the physics inside, because the constant potential doesn\u2019t make any difference so far as anything going on inside the can is concerned. Now there is no way we can deduce what the answer should be, so we must make a guess. The guess which works is more or less what you might expect: For the energy, we must use the sum of the potential energy V and the energy E p \u2014which is itself the sum of the internal and kinetic energies. The amplitude is proportional to e \u2212(i/\u210f)[( E p +V)t\u2212p\u22c5x] . (7.18) The general principle is that the coefficient of t , which we may call \u03c9 , is always given by the total energy of the system: internal (or \u201cmass\u201d) energy, plus kinetic energy, plus potential energy: \u210f\u03c9= E p +V. (7.19) Or, for nonrelativistic situations, \u210f\u03c9= W int + p 2 2M +V. (7.20) Now what about physical phenomena inside the box? If there are several different energy states, what will we get? The amplitude for each state has the same additional factor e \u2212(i/\u210f)Vt ( i / \u210f ) V over what it would have with V=0 . That is just like a change in the zero of our energy scale. It produces an equal phase change in all amplitudes, but as we have seen before, this doesn\u2019t change any of the probabilities. All the physical phenomena are the same. (We have assumed that we are talking about different states of the same charged object, so that q\u03d5 is the same for all. If an object could change its charge in going from one state to another, we would have quite another result, but conservation of charge prevents this.) So far, our assumption agrees with what we would expect for a change of energy reference level. But if it is really right, it should hold for a potential energy that is not just a constant. In general, V could vary in any arbitrary way with both time and space, and the complete result for the amplitude must be given in terms of a differential equation. We don\u2019t want to get concerned with the general case right now, but only want to get some idea about how some things happen, so we will think only of a potential that is constant in time and varies very slowly in space. Then we can make a comparison between the classical and quantum ideas. Suppose we think of the situation in Fig. 7\u20133, which has two boxes held at the constant potentials \u03d5 1 and \u03d5 2 and a region in between where we will assume that the potential varies smoothly from one to the other. We imagine that some particle has an amplitude to be found in any one of the regions. We also assume that the momentum is large enough so that in any small region in which there are many wavelengths, the potential is nearly constant. We would then think that in any part of the space the amplitude ought to look like (7.18) with the appropriate V for that part of the space. Let\u2019s think of a special case in which \u03d5 1 =0 , so that the potential energy there is zero, but in which q \u03d5 2 is negative, so that classically the particle would have more energy in the second box. Classically, it would be going faster in the second box\u2014it would have more energy and, therefore, more momentum. Let\u2019s see how that might come out of quantum mechanics. With our assumption, the amplitude in the first box would be proportional to e \u2212(i/\u210f)[( W int + p 2 1 /2M+ V 1 )t\u2212 p 1 \u22c5x] , (7.21) and the amplitude in the second box would be proportional to e \u2212(i/\u210f)[( W int + p 2 2 /2M+ V 2 )t\u2212 p 2 \u22c5x] . (7.22) (Let\u2019s say that the internal energy is not being changed, but remains the same in both regions.) The question is: How do these two amplitudes match together through the region between the boxes? We are going to suppose that the potentials are all constant in time\u2014so that nothing in the conditions varies. We will then suppose that the variations of the amplitude (that is, its phase) have the same frequency everywhere\u2014because, so to speak, there is nothing in the \u201cmedium\u201d that depends on time. If nothing in the space is changing, we can consider that the wave in one region \u201cgenerates\u201d subsidiary waves all over space which will all oscillate at the same frequency\u2014just as light waves going through materials at rest do not change their frequency. If the frequencies in (7.21) and (7.22) are the same, we must have that W int + p 2 1 2M + V 1 = W int + p 2 2 2M + V 2 . (7.23) Both sides are just the classical total energies, so Eq. (7.23) is a statement of the conservation of energy. In other words, the classical statement of the conservation of energy is equivalent to the quantum mechanical statement that the frequencies for a particle are everywhere the same if the conditions are not changing with time. It all fits with the idea that \u210f\u03c9=E . In the special example that V 1 =0 and V 2 is negative, Eq. (7.23) gives that p 2 is greater than p 1 , so the wavelength of the waves is shorter in region 2 . The surfaces of equal phase are shown by the dashed lines in Fig. 7\u20133. We have also drawn a graph of the real part of the amplitude, which shows again how the wavelength decreases in going from region 1 to region 2 . The group velocity of the waves, which is p/M , also increases in the way one would expect from the classical energy conservation, since it is just the same as Eq. (7.23). There is an interesting special case where V 2 gets so large that V 2 \u2212 V 1 is greater than p 2 1 /2M . Then p 2 2 , which is given by p 2 2 =2M[ p 2 1 2M \u2212 V 2 + V 1 ], (7.24) is negative. That means that p 2 is an imaginary number, say, i p \u2032 . Classically, we would say that the particle never gets into region 2 \u2014it doesn\u2019t have enough energy to climb the potential hill. Quantum mechanically, however, the amplitude is still given by Eq. (7.22); its space variation still goes as e (i/\u210f) p 2 \u22c5x . ( i / \u210f ) But if p 2 is imaginary, the space dependence becomes a real exponential. Say that the particle was initially going in the +x -direction; then the amplitude would vary as e \u2212 p \u2032 x/\u210f . (7.25) The amplitude decreases rapidly with increasing x . Imagine that the two regions at different potentials were very close together, so that the potential energy changed suddenly from V 1 to V 2 , as shown in Fig. 7\u20134(a). If we plot the real part of the probability amplitude, we get the dependence shown in part (b) of the figure. The wave in the first region corresponds to a particle trying to get into the second region, but the amplitude there falls off rapidly. There is some chance that it will be observed in the second region\u2014where it could never get classically\u2014but the amplitude is very small except right near the boundary. The situation is very much like what we found for the total internal reflection of light. The light doesn\u2019t normally get out, but we can observe it if we put something within a wavelength or two of the surface. You will remember that if we put a second surface close to the boundary where light was totally reflected, we could get some light transmitted into the second piece of material. The corresponding thing happens to particles in quantum mechanics. If there is a narrow region with a potential V , so great that the classical kinetic energy would be negative, the particle would classically never get past. But quantum mechanically, the exponentially decaying amplitude can reach across the region and give a small probability that the particle will be found on the other side where the kinetic energy is again positive. The situation is illustrated in Fig. 7\u20135. This effect is called the quantum mechanical \u201cpenetration of a barrier.\u201d The barrier penetration by a quantum mechanical amplitude gives the explanation\u2014or description\u2014of the \u03b1 -particle decay of a uranium nucleus. The potential energy of an \u03b1 -particle, as a function of the distance from the center, is shown in Fig. 7\u20136(a). If one tried to shoot an \u03b1 -particle with the energy E into the nucleus, it would feel an electrostatic repulsion from the nuclear charge z and would, classically, get no closer than the distance r 1 where its total energy is equal to the potential energy V . Closer in, however, the potential energy is much lower because of the strong attraction of the short-range nuclear forces. How is it then that in radioactive decay we find \u03b1 -particles which started out inside the nucleus coming out with the energy E ? Because they start out with the energy E inside the nucleus and \u201cleak\u201d through the potential barrier. The probability amplitude is roughly as sketched in part (b) of Fig. 7\u20136, although actually the exponential decay is much larger than shown. It is, in fact, quite remarkable that the mean life of an \u03b1 -particle in the uranium nucleus is as long as 4 1 2 billion years, when the natural oscillations inside the nucleus are so extremely rapid\u2014about 10 22 per sec! How can one get a number like 10 9 years from 10 \u221222 sec? The answer is that the exponential gives the tremendously small factor of about e \u221245 \u2014which gives the very small, though definite, probability of leakage. Once the \u03b1 -particle is in the nucleus, there is almost no amplitude at all for finding it outside; however, if you take many nuclei and wait long enough, you may be lucky and find one that has come out. Suppose that we have a particle moving along and passing through a region where there is a potential that varies at right angles to the motion. Classically, we would describe the situation as sketched in Fig. 7\u20137. If the particle is moving along the x -direction and enters a region where there is a potential that varies with y , the particle will get a transverse acceleration from the force F=\u2212\u2202V/\u2202y . If the force is present only in a limited region of width w , the force will act only for the time w/v . The particle will be given the transverse momentum p y =F w v . w The angle of deflection \u03b4\u03b8 is then \u03b4\u03b8= p y p = Fw pv , p where p is the initial momentum. Using \u2212\u2202V/\u2202y for F , we get \u03b4\u03b8=\u2212 w pv \u2202V \u2202y . (7.26) It is now up to us to see if our idea that the waves go as (7.20) will explain the same result. We look at the same thing quantum mechanically, assuming that everything is on a very large scale compared with a wavelength of our probability amplitudes. In any small region we can say that the amplitude varies as e \u2212(i/\u210f)[(W+ p 2 /2M+V)t\u2212p\u22c5x] . (7.27) Can we see that this will also give rise to a deflection of the particle when V has a transverse gradient? We have sketched in Fig. 7\u20138 what the waves of probability amplitude will look like. We have drawn a set of \u201cwave nodes\u201d which you can think of as surfaces where the phase of the amplitude is zero. In every small region, the wavelength\u2014the distance between successive nodes\u2014is \u03bb= h p , h where p is related to V through W+ p 2 2M +V=const. (7.28) In the region where V is larger, p is smaller, and the wavelength is longer. So the angle of the wave nodes gets changed as shown in the figure. To find the change in angle of the wave nodes we notice that for the two paths a and b in Fig. 7\u20138 there is a difference of potential \u0394V=(\u2202V/\u2202y)D , so there is a difference \u0394p in the momentum along the two tracks which can be obtained from (7.28): \u0394( p 2 2M )= p M \u0394p=\u2212\u0394V. (7.29) The wave number p/\u210f is, therefore, different along the two paths, which means that the phase is advancing at a different rate. The difference in the rate of increase of phase is \u0394k=\u0394p/\u210f , so the accumulated phase difference in the total distance w is \u0394(phase)=\u0394k\u22c5w= \u0394p \u210f \u22c5w=\u2212 M p\u210f \u0394V\u22c5w. (7.30) This is the amount by which the phase on path b is \u201cahead\u201d of the phase on path a as the wave leaves the strip. But outside the strip, a phase advance of this amount corresponds to the wave node being ahead by the amount \u0394x= \u03bb 2\u03c0 \u0394(phase)= \u210f p \u0394(phase) \u03bb \u210f or \u0394x=\u2212 M p 2 \u0394V\u22c5w. (7.31) Referring to Fig. 7\u20138, we see that the new wavefronts will be at the angle \u03b4\u03b8 given by \u0394x=D\u03b4\u03b8; (7.32) so we have D\u03b4\u03b8=\u2212 M p 2 \u0394V\u22c5w. (7.33) This is identical to Eq. (7.26) if we replace p/M by v and \u0394V/D by \u2202V/\u2202y . The result we have just got is correct only if the potential variations are slow and smooth\u2014in what we call the classical limit. We have shown that under these conditions we will get the same particle motions we get from F=ma , provided we assume that a potential contributes a phase to the probability amplitude equal to Vt/\u210f . In the classical limit, the quantum mechanics will agree with Newtonian mechanics. Notice that we have not assumed anything special about the potential energy\u2014it is just that energy whose derivative gives a force. For instance, in the Stern-Gerlach experiment we had the energy U=\u2212\u03bc\u22c5B , which gives a force if B has a spatial variation. If we wanted to give a quantum mechanical description, we would have said that the particles in one beam had an energy that varied one way and that those in the other beam had an opposite energy variation. (We could put the magnetic energy U into the potential energy V or into the \u201cinternal\u201d energy W ; it doesn\u2019t matter.) Because of the energy variation, the waves are refracted, and the beams are bent up or down. (We see now that quantum mechanics would give us the same bending as we would compute from the classical mechanics.) From the dependence of the amplitude on potential energy we would also expect that if a particle sits in a uniform magnetic field along the z -direction, its probability amplitude must be changing with time according to e \u2212(i/\u210f)(\u2212 \u03bc z B)t . ( i / \u210f ) ( B ) (We can consider that this is, in effect, a definition of \u03bc z .) In other words, if we place a particle in a uniform field B for a time \u03c4 , its probability amplitude will be multiplied by e \u2212(i/\u210f)(\u2212 \u03bc z B)\u03c4 ( i / \u210f ) ( B ) over what it would be in no field. Since for a spin one-half particle, \u03bc z can be either plus or minus some number, say \u03bc , the two possible states in a uniform field would have their phases changing at the same rate but in opposite directions. The two amplitudes get multiplied by e \u00b1(i/\u210f)\u03bcB\u03c4 . (7.34) This result has some interesting consequences. Suppose we have a spin one-half particle in some state that is not purely spin up or spin down. We can describe its condition in terms of the amplitudes to be in the pure up and pure down states. But in a magnetic field, these two states will have phases changing at a different rate. So if we ask some question about the amplitudes, the answer will depend on how long it has been in the field. As an example, we consider the disintegration of the muon in a magnetic field. When muons are produced as disintegration products of \u03c0 -mesons, they are polarized (in other words, they have a preferred spin direction). The muons, in turn, disintegrate\u2014in about 2.2 microseconds on the average\u2014emitting an electron and two neutrinos: \u03bc\u2192e+\u03bd+ \u03bd \u00af . In this disintegration it turns out that (for at least the highest energies) the electrons are emitted preferentially in the direction opposite to the spin direction of the muon. Suppose then that we consider the experimental arrangement shown in Fig. 7\u20139. If polarized muons enter from the left and are brought to rest in a block of material at A , they will, a little while later, disintegrate. The electrons emitted will, in general, go off in all possible directions. Suppose, however, that the muons all enter the stopping block at A with their spins in the x -direction. Without a magnetic field there would be some angular distribution of decay directions; we would like to know how this distribution is changed by the presence of the magnetic field. We expect that it may vary in some way with time. We can find out what happens by asking, for any moment, what the amplitude is that the muon will be found in the (+x) state. We can state the problem in the following way: A muon is known to have its spin in the +x -direction at t=0 ; what is the amplitude that it will be in the same state at the time \u03c4 ? Now we do not have any rule for the behavior of a spin one-half particle in a magnetic field at right angles to the spin, but we do know what happens to the spin up and spin down states with respect to the field\u2014their amplitudes get multiplied by the factor (7.34). Our procedure then is to choose the representation in which the base states are spin up and spin down with respect to the z -direction (the field direction). Any question can then be expressed with reference to the amplitudes for these states. Let\u2019s say that \u03c8(t) represents the muon state. When it enters the block A , its state is \u03c8(0) , and we want to know \u03c8(\u03c4) at the later time \u03c4 . If we represent the two base states by (+z) and (\u2212z) we know the two amplitudes \u27e8+z|\u03c8(0)\u27e9 and \u27e8\u2212z|\u03c8(0)\u27e9 \u2014we know these amplitudes because we know that \u03c8(0) represents a state with the spin in the (+x) state. From the results of the last chapter, these amplitudes are2 \u27e8+z|+x\u27e9 \u27e8\u2212z|+x\u27e9 = C + = 1 2 \u2013 \u221a , = C \u2212 = 1 2 \u2013 \u221a . (7.35) They happen to be equal. Since these amplitudes refer to the condition at t=0 , let\u2019s call them C + (0) and C \u2212 (0) . Now we know what happens to these two amplitudes with time. Using (7.34), we have C + (t) C \u2212 (t) = C + (0) e \u2212(i/\u210f)\u03bcBt , = C \u2212 (0) e +(i/\u210f)\u03bcBt . (7.36) But if we know C + (t) and C \u2212 (t) , we have all there is to know about the condition at t . The only trouble is that what we want to know is the probability that at t the spin will be in the +x -direction. Our general rules can, however, take care of this problem. We write that the amplitude to be in the (+x) state at time t , which we may call A + (t) , is A + (t) =\u27e8+x|\u03c8(t)\u27e9 =\u27e8+x|+z\u27e9\u27e8+z|\u03c8(t)\u27e9+\u27e8+x|\u2212z\u27e9\u27e8\u2212z|\u03c8(t)\u27e9 or A + (t)=\u27e8+x|+z\u27e9 C + (t)+\u27e8+x|\u2212z\u27e9 C \u2212 (t). (7.37) Again using the results of the last chapter\u2014or better the equality \u27e8\u03d5|\u03c7\u27e9=\u27e8\u03c7|\u03d5 \u27e9 \u2217 from Chapter 5\u2014we know that \u27e8+x|+z\u27e9= 1 2 \u2013 \u221a ,\u27e8+x|\u2212z\u27e9= 1 2 \u2013 \u221a . 1 1 So we know all the quantities in Eq. (7.37). We get A + (t)= 1 2 e (i/\u210f)\u03bcBt + 1 2 e \u2212(i/\u210f)\u03bcBt , 1 1 or A + (t)=cos \u03bcB \u210f t. B A particularly simple result! Notice that the answer agrees with what we expect for t=0 . We get A + (0)=1 , which is right, because we assumed that the muon was in the (+x) state at t=0 . The probability P + that the muon will be found in the (+x) state at t is ( A + ) 2 or P + = cos 2 \u03bcBt \u210f . B t The probability oscillates between zero and one, as shown in Fig. 7\u201310. Note that the probability returns to one for \u03bcBt/\u210f=\u03c0 (not 2\u03c0 ). Because we have squared the cosine function, the probability repeats itself with the frequency 2\u03bcB/\u210f . Thus, we find that the chance of catching the decay electron in the electron counter of Fig. 7\u20139 varies periodically with the length of time the muon has been sitting in the magnetic field. The frequency depends on the magnetic moment \u03bc . The magnetic moment of the muon has, in fact, been measured in just this way. We can, of course, use the same method to answer any other questions about the muon decay. For example, how does the chance of detecting a decay electron in the y -direction at 90 \u2218 to the x -direction but still at right angles to the field depend on t ? If you work it out, the probability to be in the (+y) state varies as cos 2 {(\u03bcBt/\u210f)\u2212\u03c0/4} , which oscillates with the same period but reaches its maximum one-quarter cycle later, when \u03bcBt/\u210f=\u03c0/4 . In fact, what is happening is that as time goes on, the muon goes through a succession of states which correspond to complete polarization in a direction that is continually rotating about the z -axis. We can describe this by saying that the spin is precessing at the frequency \u03c9 p = 2\u03bcB \u210f . (7.38) You can begin to see the form that our quantum mechanical description will take when we are describing how things behave in time."
    },
    {
        "input": "The Electric Field in Various Circumstances",
        "output": "This chapter will describe the behavior of the electric field in a number of different circumstances. It will provide some experience with the way the electric field behaves, and will describe some of the mathematical methods which are used to find this field. We begin by pointing out that the whole mathematical problem is the solution of two equations, the Maxwell equations for electrostatics: \u2207\u22c5E = \u03c1 \u03f50 , \u2207\u00d7E =0. In fact, the two can be combined into a single equation. From the second equation, we know at once that we can describe the field as the gradient of a scalar (see Section 3\u20137): E=\u2212\u2207\u03d5. We may, if we wish, completely describe any particular electric field in terms of its potential \u03d5 . We obtain the differential equation that \u03d5 must obey by substituting Eq. (6.3) into (6.1), to get \u2207\u22c5\u2207\u03d5=\u2212 \u03c1 \u03f50 . The divergence of the gradient of \u03d5 is the same as \u22072 operating on \u03d5 : \u2207\u22c5\u2207\u03d5=\u22072\u03d5= \u22022\u03d5 \u2202x2 + \u22022\u03d5 \u2202y2 + \u22022\u03d5 \u2202z2 , so we write Eq. (6.4) as \u22072\u03d5=\u2212 \u03c1 \u03f50 . The operator \u22072 is called the Laplacian, and Eq. (6.6) is called the Poisson equation. The entire subject of electrostatics, from a mathematical point of view, is merely a study of the solutions of the single equation (6.6). Once \u03d5 is obtained by solving Eq. (6.6) we can find E immediately from Eq. (6.3). We take up first the special class of problems in which \u03c1 is given as a function of x , y , z . In that case the problem is almost trivial, for we already know the solution of Eq. (6.6) for the general case. We have shown that if \u03c1 is known at every point, the potential at point (1) is \u03d5(1)=\u222b \u03c1(2)dV2 4\u03c0\u03f50r12 , where \u03c1(2) is the charge density, dV2 is the volume element at point (2) , and r12 is the distance between points (1) and (2) . The solution of the differential equation (6.6) is reduced to an integration over space. The solution (6.7) should be especially noted, because there are many situations in physics that lead to equations like \u22072(something)=(something else), and Eq. (6.7) is a prototype of the solution for any of these problems. The solution of electrostatic field problems is thus completely straightforward when the positions of all the charges are known. Let\u2019s see how it works in a few examples. First, take two point charges, +q and \u2212q , separated by the distance d . Let the z -axis go through the charges, and pick the origin halfway between, as shown in Fig. 6\u20131. Then, using (4.24), the potential from the two charges is given by \u03d5( x,y,z) = 1 4\u03c0\u03f50 [ q \u221a [z\u2212(d/2)]2+x2+y2 + \u2212q \u221a [z+(d/2)]2+x2+y2 ]. We are not going to write out the formula for the electric field, but we can always calculate it once we have the potential. So we have solved the problem of two charges. There is an important special case in which the two charges are very close together\u2014which is to say that we are interested in the fields only at distances from the charges large in comparison with their separation. We call such a close pair of charges a dipole. Dipoles are very common. A \u201cdipole\u201d antenna can often be approximated by two charges separated by a small distance\u2014if we don\u2019t ask about the field too close to the antenna. (We are usually interested in antennas with moving charges; then the equations of statics do not really apply, but for some purposes they are an adequate approximation.) More important perhaps, are atomic dipoles. If there is an electric field in any material, the electrons and protons feel opposite forces and are displaced relative to each other. In a conductor, you remember, some of the electrons move to the surfaces, so that the field inside becomes zero. In an insulator the electrons cannot move very far; they are pulled back by the attraction of the nucleus. They do, however, shift a little bit. So although an atom, or molecule, remains neutral in an external electric field, there is a very tiny separation of its positive and negative charges and it becomes a microscopic dipole. If we are interested in the fields of these atomic dipoles in the neighborhood of ordinary-sized objects, we are normally dealing with distances large compared with the separations of the pairs of charges. In some molecules the charges are somewhat separated even in the absence of external fields, because of the form of the molecule. In a water molecule, for example, there is a net negative charge on the oxygen atom and a net positive charge on each of the two hydrogen atoms, which are not placed symmetrically but as in Fig. 6\u20132. Although the charge of the whole molecule is zero, there is a charge distribution with a little more negative charge on one side and a little more positive charge on the other. This arrangement is certainly not as simple as two point charges, but when seen from far away the system acts like a dipole. As we shall see a little later, the field at large distances is not sensitive to the fine details. Let\u2019s look, then, at the field of two opposite charges with a small separation d . If d becomes zero, the two charges are on top of each other, the two potentials cancel, and there is no field. But if they are not exactly on top of each other, we can get a good approximation to the potential by expanding the terms of (6.8) in a power series in the small quantity d (using the binomial expansion). Keeping terms only to first order in d , we can write (z\u2212 d 2 ) 2 \u2248 z 2 \u2212zd. d It is convenient to write x 2 + y 2 + z 2 = r 2 . 2 2 2 2 Then (z\u2212 d 2 ) 2 + x 2 + y 2 \u2248 r 2 \u2212zd = r 2 (1\u2212 zd r 2 ), and 1 [z\u2212(d/2) ] 2 + x 2 + y 2 \u2212 \u2212 \u2212 \u2212 \u2212 \u2212 \u2212 \u2212 \u2212 \u2212 \u2212 \u2212 \u2212 \u2212 \u2212 \u2212 \u2212 \u221a \u2248 1 r 2 [1\u2212(zd/ r 2 )] \u2212 \u2212 \u2212 \u2212 \u2212 \u2212 \u2212 \u2212 \u2212 \u2212 \u2212 \u2212 \u221a = 1 r (1\u2212 zd r 2 ) \u22121/2 . Using the binomial expansion again for [1\u2212(zd/ r 2 ) ] \u22121/2 \u2014and throwing away terms with the square or higher powers of d \u2014we get 1 r (1+ 1 2 zd r 2 ). d Similarly, 1 [z+(d/2) ] 2 + x 2 + y 2 \u2212 \u2212 \u2212 \u2212 \u2212 \u2212 \u2212 \u2212 \u2212 \u2212 \u2212 \u2212 \u2212 \u2212 \u2212 \u2212 \u2212 \u221a \u2248 1 r (1\u2212 1 2 zd r 2 ). d The difference of these two terms gives for the potential \u03d5(x,y,z)= 1 4\u03c0 \u03f5 0 z r 3 qd. (6.9) The potential, and hence the field, which is its derivative, is proportional to qd , the product of the charge and the separation. This product is defined as the dipole moment of the two charges, for which we will use the symbol p (do not confuse with momentum!): p=qd. (6.10) Equation (6.9) can also be written as \u03d5(x,y,z)= 1 4\u03c0 \u03f5 0 pcos\u03b8 r 2 , (6.11) since z/r=cos\u03b8 , where \u03b8 is the angle between the axis of the dipole and the radius vector to the point (x,y,z) \u2014see Fig. 6\u20131. The potential of a dipole decreases as 1/ r 2 for a given direction from the axis (whereas for a point charge it goes as 1/r ). The electric field E of the dipole will then decrease as 1/ r 3 . We can put our formula into a vector form if we define p as a vector whose magnitude is p and whose direction is along the axis of the dipole, pointing from \u2212q toward +q . Then pcos\u03b8=p\u22c5 e r , (6.12) where e r is the unit radial vector (Fig. 6\u20133). We can also represent the point (x,y,z) by r . Then Dipole potential: \u03d5(r)= 1 4\u03c0 \u03f5 0 p\u22c5 e r r 2 = 1 4\u03c0 \u03f5 0 p\u22c5r r 3 (6.13) This formula is valid for a dipole with any orientation and position if r represents the vector from the dipole to the point of interest. If we want the electric field of the dipole we can get it by taking the gradient of \u03d5 . For example, the z -component of the field is \u2212\u2202\u03d5/\u2202z . For a dipole oriented along the z -axis we can use (6.9): \u2212 \u2202\u03d5 \u2202z =\u2212 p 4\u03c0 \u03f5 0 \u2202 \u2202z ( z r 3 )=\u2212 p 4\u03c0 \u03f5 0 ( 1 r 3 \u2212 3 z 2 r 5 ), 2 or E z = p 4\u03c0 \u03f5 0 3 cos 2 \u03b8\u22121 r 3 . (6.14) The x - and y -components are E x = p 4\u03c0 \u03f5 0 3zx r 5 , E y = p 4\u03c0 \u03f5 0 3zy r 5 . 3 3 These two can be combined to give one component directed perpendicular to the z -axis, which we will call the transverse component E \u22a5 : E \u22a5 = E 2 x + E 2 y \u2212 \u2212 \u2212 \u2212 \u2212 \u2212 \u2212 \u221a = p 4\u03c0 \u03f5 0 3z r 5 x 2 + y 2 \u2212 \u2212 \u2212 \u2212 \u2212 \u2212 \u221a 3 or E \u22a5 = p 4\u03c0 \u03f5 0 3cos\u03b8sin\u03b8 r 3 . (6.15) The transverse component E \u22a5 is in the xy -plane and points directly away from the axis of the dipole. The total field, of course, is E= E 2 z + E 2 \u22a5 \u2212 \u2212 \u2212 \u2212 \u2212 \u2212 \u2212 \u221a . The dipole field varies inversely as the cube of the distance from the dipole. On the axis, at \u03b8=0 , it is twice as strong as at \u03b8= 90 \u2218 . At both of these special angles the electric field has only a z -component, but of opposite sign at the two places (Fig. 6\u20134). This is a good place to make a general remark about vector analysis. The fundamental proofs can be expressed by elegant equations in a general form, but in making various calculations and analyses it is always a good idea to choose the axes in some convenient way. Notice that when we were finding the potential of a dipole we chose the z -axis along the direction of the dipole, rather than at some arbitrary angle. This made the work much easier. But then we wrote the equations in vector form so that they would no longer depend on any particular coordinate system. After that, we are allowed to choose any coordinate system we wish, knowing that the relation is, in general, true. It clearly doesn\u2019t make any sense to bother with an arbitrary coordinate system at some complicated angle when you can choose a neat system for the particular problem\u2014provided that the result can finally be expressed as a vector equation. So by all means take advantage of the fact that vector equations are independent of any coordinate system. On the other hand, if you are trying to calculate the divergence of a vector, instead of just looking at \u2207\u22c5E and wondering what it is, don\u2019t forget that it can always be spread out as \u2202 E x \u2202x + \u2202 E y \u2202y + \u2202 E z \u2202z . \u2202 E If you can then work out the x -, y -, and z -components of the electric field and differentiate them, you will have the divergence. There often seems to be a feeling that there is something inelegant\u2014some kind of defeat involved\u2014in writing out the components; that somehow there ought always to be a way to do everything with the vector operators. There is often no advantage to it. The first time we encounter a particular kind of problem, it usually helps to write out the components to be sure we understand what is going on. There is nothing inelegant about putting numbers into equations, and nothing inelegant about substituting the derivatives for the fancy symbols. In fact, there is often a certain cleverness in doing just that. Of course when you publish a paper in a professional journal it will look better\u2014and be more easily understood\u2014if you can write everything in vector form. Besides, it saves print. We would like to point out a rather amusing thing about the dipole formula, Eq. (6.13). The potential can also be written as \u03d5=\u2212 1 4\u03c0 \u03f5 0 p\u22c5\u2207( 1 r ). (6.16) If you calculate the gradient of 1/r , you get \u2207( 1 r )=\u2212 r r 3 =\u2212 e r r 2 , ( 1 ) and Eq. (6.16) is the same as Eq. (6.13). How did we think of that? We just remembered that e r / r 2 appeared in the formula for the field of a point charge, and that the field was the gradient of a potential which has a 1/r dependence. There is a physical reason for being able to write the dipole potential in the form of Eq. (6.16). Suppose we have a point charge q at the origin. The potential at the point P at (x,y,z) is \u03d5 0 = q r . q (Let\u2019s leave off the 1/4\u03c0 \u03f5 0 while we make these arguments; we can stick it in at the end.) Now if we move the charge +q up a distance \u0394z , the potential at P will change a little, by, say, \u0394 \u03d5 + . How much is \u0394 \u03d5 + ? Well, it is just the amount that the potential would change if we were to leave the charge at the origin and move P downward by the same distance \u0394z (Fig. 6\u20135). That is, \u0394 \u03d5 + =\u2212 \u2202 \u03d5 0 \u2202z \u0394z, \u2202 \u03d5 where by \u0394z we mean the same as d/2 . So, using \u03d5 0 =q/r , we have that the potential from the positive charge is \u03d5 + = q r \u2212 \u2202 \u2202z ( q r ) d 2 . (6.17) Applying the same reasoning for the potential from the negative charge, we can write \u03d5 \u2212 = \u2212q r + \u2202 \u2202z ( \u2212q r ) d 2 . (6.18) The total potential is the sum of (6.17) and (6.18): \u03d5= \u03d5 + + \u03d5 \u2212 =\u2212 \u2202 \u2202z ( q r )d =\u2212 \u2202 \u2202z ( 1 r )qd (6.19) For other orientations of the dipole, we could represent the displacement of the positive charge by the vector \u0394 r + . We should then write the equation above Eq. (6.17) as \u0394 \u03d5 + =\u2212\u2207 \u03d5 0 \u22c5\u0394 r + , \u0394 \u03d5 \u2207 \u03d5 \u0394 where \u0394 r + is then to be replaced by d/2 . Completing the derivation as before, Eq. (6.19) would then become \u03d5=\u2212\u2207( 1 r )\u22c5qd. ( 1 ) This is the same as Eq. (6.16), if we replace qd=p , and put back the 1/4\u03c0 \u03f5 0 . Looking at it another way, we see that the dipole potential, Eq. (6.13), can be interpreted as \u03d5=\u2212p\u22c5\u2207 \u03a6 0 , (6.20) where \u03a6 0 =1/4\u03c0 \u03f5 0 r is the potential of a unit point charge. Although we can always find the potential of a known charge distribution by an integration, it is sometimes possible to save time by getting the answer with a clever trick. For example, one can often make use of the superposition principle. If we are given a charge distribution that can be made up of the sum of two distributions for which the potentials are already known, it is easy to find the desired potential by just adding the two known ones. One example of this is our derivation of (6.20), another is the following. Suppose we have a spherical surface with a distribution of surface charge that varies as the cosine of the polar angle. The integration for this distribution is fairly messy. But, surprisingly, such a distribution can be analyzed by superposition. For imagine a sphere with a uniform volume density of positive charge, and another sphere with an equal uniform volume density of negative charge, originally superposed to make a neutral\u2014that is, uncharged\u2014sphere. If the positive sphere is then displaced slightly with respect to the negative sphere, the body of the uncharged sphere would remain neutral, but a little positive charge will appear on one side, and some negative charge will appear on the opposite side, as illustrated in Fig. 6\u20136. If the relative displacement of the two spheres is small, the net charge is equivalent to a surface charge (on a spherical surface), and the surface charge density will be proportional to the cosine of the polar angle. Now if we want the potential from this distribution, we do not need to do an integral. We know that the potential from each of the spheres of charge is\u2014for points outside the sphere\u2014the same as from a point charge. The two displaced spheres are like two point charges; the potential is just that of a dipole. In this way you can show that a charge distribution on a sphere of radius a with a surface charge density \u03c3= \u03c3 0 cos\u03b8 \u03b8 produces a field outside the sphere which is just that of a dipole whose moment is p= 4\u03c0 \u03c3 0 a 3 3 . 3 It can also be shown that inside the sphere the field is constant, with the value E= \u03c3 0 3 \u03f5 0 . \u03c3 If \u03b8 is the angle from the positive z -axis, the electric field inside the sphere is in the negative z -direction. The example we have just considered is not as artificial as it may appear; we will encounter it again in the theory of dielectrics. The dipole field appears in another circumstance both interesting and important. Suppose that we have an object that has a complicated distribution of charge\u2014like the water molecule (Fig. 6\u20132)\u2014and we are interested only in the fields far away. We will show that it is possible to find a relatively simple expression for the fields which is appropriate for distances large compared with the size of the object. We can think of our object as an assembly of point charges q i in a certain limited region, as shown in Fig. 6\u20137. (We can, later, replace q i by \u03c1dV if we wish.) Let each charge q i be located at the displacement d i from an origin chosen somewhere in the middle of the group of charges. What is the potential at the point P , located at R , where R is much larger than the maximum d i ? The potential from the whole collection is given by \u03d5= 1 4\u03c0 \u03f5 0 \u2211 i q i r i , (6.21) where r i is the distance from P to the charge q i (the length of the vector R\u2212 d i ). Now if the distance from the charges to P , the point of observation, is enormous, each of the r i \u2019s can be approximated by R . Each term becomes q i /R , and we can take 1/R out as a factor in front of the summation. This gives us the simple result \u03d5= 1 4\u03c0 \u03f5 0 1 R \u2211 i q i = Q 4\u03c0 \u03f5 0 R , (6.22) where Q is just the total charge of the whole object. Thus we find that for points far enough from any lump of charge, the lump looks like a point charge. The result is not too surprising. But what if there are equal numbers of positive and negative charges? Then the total charge Q of the object is zero. This is not an unusual case; in fact, as we know, objects are usually neutral. The water molecule is neutral, but the charges are not all at one point, so if we are close enough we should be able to see some effects of the separate charges. We need a better approximation than (6.22) for the potential from an arbitrary distribution of charge in a neutral object. Equation (6.21) is still precise, but we can no longer just set r i =R . We need a more accurate expression for r i . If the point P is at a large distance, r i will differ from R to an excellent approximation by the projection of d on R , as can be seen from Fig. 6\u20137. (You should imagine that P is really farther away than is shown in the figure.) In other words, if e R is the unit vector in the direction of R , then our next approximation to r i is r i \u2248R\u2212 d i \u22c5 e R . (6.23) What we really want is 1/ r i , which, since d i \u226aR , can be written to our approximation as 1 r i \u2248 1 R (1+ d i \u22c5 e R R ). (6.24) Substituting this in (6.21), we get that the potential is \u03d5= 1 4\u03c0 \u03f5 0 ( Q R + \u2211 i q i d i \u22c5 e R R 2 +\u22ef). (6.25) The three dots indicate the terms of higher order in d i /R that we have neglected. These, as well as the ones we have already obtained, are successive terms in a Taylor expansion of 1/ r i about 1/R in powers of d i /R . The first term in (6.25) is what we got before; it drops out if the object is neutral. The second term depends on 1/ R 2 , just as for a dipole. In fact, if we define p= \u2211 i q i d i (6.26) as a property of the charge distribution, the second term of the potential (6.25) is \u03d5= 1 4\u03c0 \u03f5 0 p\u22c5 e R R 2 , (6.27) precisely a dipole potential. The quantity p is called the dipole moment of the distribution. It is a generalization of our earlier definition, and reduces to it for the special case of two point charges. Our result is that, far enough away from any mess of charges that is as a whole neutral, the potential is a dipole potential. It decreases as 1/ R 2 and varies as cos\u03b8 \u2014and its strength depends on the dipole moment of the distribution of charge. It is for these reasons that dipole fields are important, since the simple case of a pair of point charges is quite rare. The water molecule, for example, has a rather strong dipole moment. The electric fields that result from this moment are responsible for some of the important properties of water. For many molecules, for example CO 2 , the dipole moment vanishes because of the symmetry of the molecule. For them we should expand still more accurately, obtaining another term in the potential which decreases as 1/ R 3 , and which is called a quadrupole potential. We will discuss such cases later. We have now finished with the examples we wish to cover of situations in which the charge distribution is known from the start. It has been a problem without serious complications, involving at most some integrations. We turn now to an entirely new kind of problem, the determination of the fields near charged conductors. Suppose that we have a situation in which a total charge Q is placed on an arbitrary conductor. Now we will not be able to say exactly where the charges are. They will spread out in some way on the surface. How can we know how the charges have distributed themselves on the surface? They must distribute themselves so that the potential of the surface is constant. If the surface were not an equipotential, there would be an electric field inside the conductor, and the charges would keep moving until it became zero. The general problem of this kind can be solved in the following way. We guess at a distribution of charge and calculate the potential. If the potential turns out to be constant everywhere on the surface, the problem is finished. If the surface is not an equipotential, we have guessed the wrong distribution of charges, and should guess again\u2014hopefully with an improved guess! This can go on forever, unless we are judicious about the successive guesses. The question of how to guess at the distribution is mathematically difficult. Nature, of course, has time to do it; the charges push and pull until they all balance themselves. When we try to solve the problem, however, it takes us so long to make each trial that that method is very tedious. With an arbitrary group of conductors and charges the problem can be very complicated, and in general it cannot be solved without rather elaborate numerical methods. Such numerical computations, these days, are set up on a computing machine that will do the work for us, once we have told it how to proceed. On the other hand, there are a lot of little practical cases where it would be nice to be able to find the answer by some more direct method\u2014without having to write a program for a computer. Fortunately, there are a number of cases where the answer can be obtained by squeezing it out of Nature by some trick or other. The first trick we will describe involves making use of solutions we have already obtained for situations in which charges have specified locations. We have solved, for example, the field of two point charges. Figure 6\u20138 shows some of the field lines and equipotential surfaces we obtained by the computations in Chapter 4. Now consider the equipotential surface marked A . Suppose we were to shape a thin sheet of metal so that it just fits this surface. If we place it right at the surface and adjust its potential to the proper value, no one would ever know it was there, because nothing would be changed. But notice! We have really solved a new problem. We have a situation in which the surface of a curved conductor with a given potential is placed near a point charge. If the metal sheet we placed at the equipotential surface eventually closes on itself (or, in practice, if it goes far enough) we have the kind of situation considered in Section 5\u201310, in which our space is divided into two regions, one inside and one outside a closed conducting shell. We found there that the fields in the two regions are quite independent of each other. So we would have the same fields outside our curved conductor no matter what is inside. We can even fill up the whole inside with conducting material. We have found, therefore, the fields for the arrangement of Fig. 6\u20139. In the space outside the conductor the field is just like that of two point charges, as in Fig. 6\u20138. Inside the conductor, it is zero. Also\u2014as it must be\u2014the electric field just outside the conductor is normal to the surface. Thus we can compute the fields in Fig. 6\u20139 by computing the field due to q and to an imaginary point charge \u2212q at a suitable point. The point charge we \u201cimagine\u201d existing behind the conducting surface is called an image charge. In books you can find long lists of solutions for hyperbolic-shaped conductors and other complicated looking things, and you wonder how anyone ever solved these terrible shapes. They were solved backwards! Someone solved a simple problem with given charges. He then saw that some equipotential surface showed up in a new shape, and he wrote a paper in which he pointed out that the field outside that particular shape can be described in a certain way. As the simplest application of the use of this method, let\u2019s make use of the plane equipotential surface B of Fig. 6\u20138. With it, we can solve the problem of a charge in front of a conducting sheet. We just cross out the left-hand half of the picture. The field lines for our solution are shown in Fig. 6\u201310. Notice that the plane, since it was halfway between the two charges, has zero potential. We have solved the problem of a positive charge next to a grounded conducting sheet. We have now solved for the total field, but what about the real charges that are responsible for it? There are, in addition to our positive point charge, some induced negative charges on the conducting sheet that have been attracted by the positive charge (from large distances away). Now suppose that for some technical reason\u2014or out of curiosity\u2014you would like to know how the negative charges are distributed on the surface. You can find the surface charge density by using the result we worked out in Section 5\u20139 with Gauss\u2019 law. The normal component of the electric field just outside a conductor is equal to the density of surface charge \u03c3 divided by \u03f5 0 . We can obtain the density of charge at any point on the surface by working backwards from the normal component of the electric field at the surface. We know that, because we know the field everywhere. Consider a point on the surface at the distance \u03c1 from the point directly beneath the positive charge (Fig. 6\u201310). The electric field at this point is normal to the surface and is directed into it. The component normal to the surface of the field from the positive point charge is E n+ =\u2212 1 4\u03c0 \u03f5 0 aq ( a 2 + \u03c1 2 ) 3/2 . (6.28) To this we must add the electric field produced by the negative image charge. That just doubles the normal component (and cancels all others), so the charge density \u03c3 at any point on the surface is \u03c3(\u03c1)= \u03f5 0 E(\u03c1)=\u2212 2aq 4\u03c0( a 2 + \u03c1 2 ) 3/2 . (6.29) An interesting check on our work is to integrate \u03c3 over the whole surface. We find that the total induced charge is \u2212q , as it should be. One further question: Is there a force on the point charge? Yes, because there is an attraction from the induced negative surface charge on the plate. Now that we know what the surface charges are (from Eq. 6.29), we could compute the force on our positive point charge by an integral. But we also know that the force acting on the positive charge is exactly the same as it would be with the negative image charge instead of the plate, because the fields in the neighborhood are the same in both cases. The point charge feels a force toward the plate whose magnitude is F= 1 4\u03c0 \u03f5 0 q 2 (2a ) 2 . (6.30) We have found the force much more easily than by integrating over all the negative charges. What other surfaces besides a plane have a simple solution? The next most simple shape is a sphere. Let\u2019s find the fields around a grounded metal sphere which has a point charge q near it, as shown in Fig. 6\u201311. Now we must look for a simple physical situation which gives a sphere for an equipotential surface. If we look around at problems people have already solved, we find that someone has noticed that the field of two unequal point charges has an equipotential that is a sphere. Aha! If we choose the location of an image charge\u2014and pick the right amount of charge\u2014maybe we can make the equipotential surface fit our sphere. Indeed, it can be done with the following prescription. Assume that you want the equipotential surface to be a sphere of radius a with its center at the distance b from the charge q . Put an image charge of strength q \u2032 =\u2212q(a/b) on the line from the charge to the center of the sphere, and at a distance a 2 /b from the center. The sphere will be at zero potential. The mathematical reason stems from the fact that a sphere is the locus of all points for which the distances from two points are in a constant ratio. Referring to Fig. 6\u201311, the potential at P from q and q \u2032 is proportional to q r 1 + q \u2032 r 2 . \u2032 The potential will thus be zero at all points for which q \u2032 r 2 =\u2212 q r 1 or r 2 r 1 =\u2212 q \u2032 q . \u2032 \u2032 If we place q \u2032 at the distance a 2 /b from the center, the ratio r 2 / r 1 has the constant value a/b . Then if q \u2032 q =\u2212 a b (6.31) the sphere is an equipotential. Its potential is, in fact, zero. What happens if we are interested in a sphere that is not at zero potential? That would be so only if its total charge happens accidentally to be q \u2032 . Of course if it is grounded, the charges induced on it would have to be just that. But what if it is insulated, and we have put no charge on it? Or if we know that the total charge Q has been put on it? Or just that it has a given potential not equal to zero? All these questions are easily answered. We can always add a point charge q \u2032\u2032 at the center of the sphere. The sphere still remains an equipotential by superposition; only the magnitude of the potential will be changed. If we have, for example, a conducting sphere which is initially uncharged and insulated from everything else, and we bring near to it the positive point charge q , the total charge of the sphere will remain zero. The solution is found by using an image charge q \u2032 as before, but, in addition, adding a charge q \u2032\u2032 at the center of the sphere, choosing q \u2032\u2032 =\u2212 q \u2032 = a b q. (6.32) The fields everywhere outside the sphere are given by the superposition of the fields of q , q \u2032 , and q \u2032\u2032 . The problem is solved. We can see now that there will be a force of attraction between the sphere and the point charge q . It is not zero even though there is no charge on the neutral sphere. Where does the attraction come from? When you bring a positive charge up to a conducting sphere, the positive charge attracts negative charges to the side closer to itself and leaves positive charges on the surface of the far side. The attraction by the negative charges exceeds the repulsion from the positive charges; there is a net attraction. We can find out how large the attraction is by computing the force on q in the field produced by q \u2032 and q \u2032\u2032 . The total force is the sum of the attractive force between q and a charge q \u2032 =\u2212(a/b)q , at the distance b\u2212( a 2 /b) , and the repulsive force between q and a charge q \u2032\u2032 =+(a/b)q at the distance b . Those who were entertained in childhood by the baking powder box which has on its label a picture of a baking powder box which has on its label a picture of a baking powder box which has \u2026 may be interested in the following problem. Two equal spheres, one with a total charge of +Q and the other with a total charge of \u2212Q , are placed at some distance from each other. What is the force between them? The problem can be solved with an infinite number of images. One first approximates each sphere by a charge at its center. These charges will have image charges in the other sphere. The image charges will have images, etc., etc., etc. The solution is like the picture on the box of baking powder\u2014and it converges pretty fast. We take up now another kind of a problem involving conductors. Consider two large metal plates which are parallel to each other and separated by a distance small compared with their width. Let\u2019s suppose that equal and opposite charges have been put on the plates. The charges on each plate will be attracted by the charges on the other plate, and the charges will spread out uniformly on the inner surfaces of the plates. The plates will have surface charge densities +\u03c3 and \u2212\u03c3 , respectively, as in Fig. 6\u201312. From Chapter 5 we know that the field between the plates is \u03c3/ \u03f5 0 , and that the field outside the plates is zero. The plates will have different potentials \u03d5 1 and \u03d5 2 . For convenience we will call the difference V ; it is often called the \u201cvoltage\u201d: \u03d5 1 \u2212 \u03d5 2 =V. \u03d5 \u03d5 V (You will find that sometimes people use V for the potential, but we have chosen to use \u03d5 .) The potential difference V is the work per unit charge required to carry a small charge from one plate to the other, so that V=Ed= \u03c3 \u03f5 0 d= d \u03f5 0 A Q, (6.33) where \u00b1Q is the total charge on each plate, A is the area of the plates, and d is the separation. We find that the voltage is proportional to the charge. Such a proportionality between V and Q is found for any two conductors in space if there is a plus charge on one and an equal minus charge on the other. The potential difference between them\u2014that is, the voltage\u2014will be proportional to the charge. (We are assuming that there are no other charges around.) Why this proportionality? Just the superposition principle. Suppose we know the solution for one set of charges, and then we superimpose two such solutions. The charges are doubled, the fields are doubled, and the work done in carrying a unit charge from one point to the other is also doubled. Therefore the potential difference between any two points is proportional to the charges. In particular, the potential difference between the two conductors is proportional to the charges on them. Someone originally wrote the equation of proportionality the other way. That is, they wrote Q=CV, Q C V where C is a constant. This coefficient of proportionality is called the capacity, and such a system of two conductors is called a condenser.1 For our parallel-plate condenser C= \u03f5 0 A d (parallel plates). (6.34) This formula is not exact, because the field is not really uniform everywhere between the plates, as we assumed. The field does not just suddenly quit at the edges, but really is more as shown in Fig. 6\u201313. The total charge is not \u03c3A , as we have assumed\u2014there is a little correction for the effects at the edges. To find out what the correction is, we will have to calculate the field more exactly and find out just what does happen at the edges. That is a complicated mathematical problem which can, however, be solved by techniques which we will not describe now. The result of such calculations is that the charge density rises somewhat near the edges of the plates. This means that the capacity of the plates is a little higher than we computed. We have talked about the capacity for two conductors only. Sometimes people talk about the capacity of a single object. They say, for instance, that the capacity of a sphere of radius a is 4\u03c0 \u03f5 0 a . What they imagine is that the other terminal is another sphere of infinite radius\u2014that when there is a charge +Q on the sphere, the opposite charge, \u2212Q , is on an infinite sphere. One can also speak of capacities when there are three or more conductors, a discussion we shall, however, defer. Suppose that we wish to have a condenser with a very large capacity. We could get a large capacity by taking a very big area and a very small separation. We could put waxed paper between sheets of aluminum foil and roll it up. (If we seal it in plastic, we have a typical radio-type condenser.) What good is it? It is good for storing charge. If we try to store charge on a ball, for example, its potential rises rapidly as we charge it up. It may even get so high that the charge begins to escape into the air by way of sparks. But if we put the same charge on a condenser whose capacity is very large, the voltage developed across the condenser will be small. In many applications in electronic circuits, it is useful to have something which can absorb or deliver large quantities of charge without changing its potential much. A condenser (or \u201ccapacitor\u201d) does just that. There are also many applications in electronic instruments and in computers where a condenser is used to get a specified change in voltage in response to a particular change in charge. We have seen a similar application in Chapter 23, Vol. I, where we described the properties of resonant circuits. From the definition of C , we see that its unit is one coulomb/volt. This unit is also called a farad. Looking at Eq. (6.34), we see that one can express the units of \u03f5 0 as farad/meter, which is the unit most commonly used. Typical sizes of condensers run from one micro-microfarad ( 1 picofarad) to millifarads. Small condensers of a few picofarads are used in high-frequency tuned circuits, and capacities up to hundreds or thousands of microfarads are found in power-supply filters. A pair of plates one square centimeter in area with a one millimeter separation have a capacity of roughly one micro-microfarad. We would like now to discuss qualitatively some of the characteristics of the fields around conductors. If we charge a conductor that is not a sphere, but one that has on it a point or a very sharp end, as, for example, the object sketched in Fig. 6\u201314, the field around the point is much higher than the field in the other regions. The reason is, qualitatively, that charges try to spread out as much as possible on the surface of a conductor, and the tip of a sharp point is as far away as it is possible to be from most of the surface. Some of the charges on the plate get pushed all the way to the tip. A relatively small amount of charge on the tip can still provide a large surface density; a high charge density means a high field just outside. One way to see that the field is highest at those places on a conductor where the radius of curvature is smallest is to consider the combination of a big sphere and a little sphere connected by a wire, as shown in Fig. 6\u201315. It is a somewhat idealized version of the conductor of Fig. 6\u201314. The wire will have little influence on the fields outside; it is there to keep the spheres at the same potential. Now, which ball has the biggest field at its surface? If the ball on the left has the radius a and carries a charge Q , its potential is about \u03d5 1 = 1 4\u03c0 \u03f5 0 Q a . 1 Q (Of course the presence of one ball changes the charge distribution on the other, so that the charges are not really spherically symmetric on either. But if we are interested only in an estimate of the fields, we can use the potential of a spherical charge.) If the smaller ball, whose radius is b , carries the charge q , its potential is about \u03d5 2 = 1 4\u03c0 \u03f5 0 q b . 1 But \u03d5 1 = \u03d5 2 , so Q a = q b . Q On the other hand, the field at the surface (see Eq. 5.8) is proportional to the surface charge density, which is like the total charge over the radius squared. We get that E a E b = Q/ a 2 q/ b 2 = b a . (6.35) Therefore the field is higher at the surface of the small sphere. The fields are in the inverse proportion of the radii. This result is technically very important, because air will break down if the electric field is too great. What happens is that a loose charge (electron, or ion) somewhere in the air is accelerated by the field, and if the field is very great, the charge can pick up enough speed before it hits another atom to be able to knock an electron off that atom. As a result, more and more ions are produced. Their motion constitutes a discharge, or spark. If you want to charge an object to a high potential and not have it discharge itself by sparks in the air, you must be sure that the surface is smooth, so that there is no place where the field is abnormally large. There is an interesting application of the extremely high electric field which surrounds any sharp protuberance on a charged conductor. The field-emission microscope depends for its operation on the high fields produced at a sharp metal point.2 It is built in the following way. A very fine needle, with a tip whose diameter is about 1000 angstroms, is placed at the center of an evacuated glass sphere (Fig. 6\u201316). The inner surface of the sphere is coated with a thin conducting layer of fluorescent material, and a very high potential difference is applied between the fluorescent coating and the needle. Let\u2019s first consider what happens when the needle is negative with respect to the fluorescent coating. The field lines are highly concentrated at the sharp point. The electric field can be as high as 40 million volts per centimeter. In such intense fields, electrons are pulled out of the surface of the needle and accelerated across the potential difference between the needle and the fluorescent layer. When they arrive there they cause light to be emitted, just as in a television picture tube. The electrons which arrive at a given point on the fluorescent surface are, to an excellent approximation, those which leave the other end of the radial field line, because the electrons will travel along the field line passing from the point to the surface. Thus we see on the surface some kind of an image of the tip of the needle. More precisely, we see a picture of the emissivity of the surface of the needle\u2014that is the ease with which electrons can leave the surface of the metal tip. If the resolution were high enough, one could hope to resolve the positions of the individual atoms on the tip of the needle. With electrons, this resolution is not possible for the following reasons. First, there is quantum-mechanical diffraction of the electron waves which blurs the image. Second, due to the internal motions of the electrons in the metal they have a small sideways initial velocity when they leave the needle, and this random transverse component of the velocity causes some smearing of the image. The combination of these two effects limits the resolution to 25 \u00c5 or so. If, however, we reverse the polarity and introduce a small amount of helium gas into the bulb, much higher resolutions are possible. When a helium atom collides with the tip of the needle, the intense field there strips an electron off the helium atom, leaving it positively charged. The helium ion is then accelerated outward along a field line to the fluorescent screen. Since the helium ion is so much heavier than an electron, the quantum-mechanical wavelengths are much smaller. If the temperature is not too high, the effect of the thermal velocities is also smaller than in the electron case. With less smearing of the image a much sharper picture of the point is obtained. It has been possible to obtain magnifications up to 2,000,000 times with the positive ion field-emission microscope\u2014a magnification ten times better than is obtained with the best electron microscope. Figure 6\u201317 is an example of the results which were obtained with a field-ion microscope, using a tungsten needle. The center of a tungsten atom ionizes a helium atom at a slightly different rate than the spaces between the tungsten atoms. The pattern of spots on the fluorescent screen shows the arrangement of the individual atoms on the tungsten tip. The reason the spots appear in rings can be understood by visualizing a large box of balls packed in a rectangular array, representing the atoms in the metal. If you cut an approximately spherical section out of this box, you will see the ring pattern characteristic of the atomic structure. The field-ion microscope provided human beings with the means of seeing atoms for the first time. This is a remarkable achievement, considering the simplicity of the instrument."
    },
    {
        "input": "Waveguides",
        "output": "In the last chapter we studied what happened to the lumped elements of circuits when they were operated at very high frequencies, and we were led to see that a resonant circuit could be replaced by a cavity with the fields resonating inside. Another interesting technical problem is the connection of one object to another, so that electromagnetic energy can be transmitted between them. In low-frequency circuits the connection is made with wires, but this method doesn\u2019t work very well at high frequencies because the circuits would radiate energy into all the space around them, and it is hard to control where the energy will go. The fields spread out around the wires; the currents and voltages are not \u201cguided\u201d very well by the wires. In this chapter we want to look into the ways that objects can be interconnected at high frequencies. At least, that\u2019s one way of presenting our subject. Another way is to say that we have been discussing the behavior of waves in free space. Now it is time to see what happens when oscillating fields are confined in one or more dimensions. We will discover the interesting new phenomenon when the fields are confined in only two dimensions and allowed to go free in the third dimension, they propagate in waves. These are \u201cguided waves\u201d\u2014the subject of this chapter. We begin by working out the general theory of the transmission line. The ordinary power transmission line that runs from tower to tower over the countryside radiates away some of its power, but the power frequencies (50 \u201360 cycles/sec) are so low that this loss is not serious. The radiation could be stopped by surrounding the line with a metal pipe, but this method would not be practical for power lines because the voltages and currents used would require a very large, expensive, and heavy pipe. So simple \u201copen lines\u201d are used. For somewhat higher frequencies\u2014say a few kilocycles\u2014radiation can already be serious. However, it can be reduced by using \u201ctwisted-pair\u201d transmission lines, as is done for short-run telephone connections. At higher frequencies, however, the radiation soon becomes intolerable, either because of power losses or because the energy appears in other circuits where it isn\u2019t wanted. For frequencies from a few kilocycles to some hundreds of megacycles, electromagnetic signals and power are usually transmitted via coaxial lines consisting of a wire inside a cylindrical \u201couter conductor\u201d or \u201cshield.\u201d Although the following treatment will apply to a transmission line of two parallel conductors of any shape, we will carry it out referring to a coaxial line. We take the simplest coaxial line that has a central conductor, which we suppose is a thin hollow cylinder, and an outer conductor which is another thin cylinder on the same axis as the inner conductor, as in Fig. 24\u20131. We begin by figuring out approximately how the line behaves at relatively low frequencies. We have already described some of the low-frequency behavior when we said earlier that two such conductors had a certain amount of inductance per unit length or a certain capacity per unit length. We can, in fact, describe the low-frequency behavior of any transmission line by giving its inductance per unit length, L0 and its capacity per unit length, C0 . Then we can analyze the line as the limiting case of the L -C filter as discussed in Section 22\u20136. We can make a filter which imitates the line by taking small series elements L0\u0394x and small shunt capacities C0\u0394x , where \u0394x is an element of length of the line. Using our results for the infinite filter, we see that there would be a propagation of electric signals along the line. Rather than following that approach, however, we would now rather look at the line from the point of view of a differential equation. Suppose that we see what happens at two neighboring points along the transmission line, say at the distances x and x+\u0394x from the beginning of the line. Let\u2019s call the voltage difference between the two conductors V(x) , and the current along the \u201chot\u201d conductor I(x) (see Fig. 24\u20132). If the current in the line is varying, the inductance will give us a voltage drop across the small section of line from x to x+\u0394x in the amount \u0394V=V(x+\u0394x)\u2212V(x)=\u2212L0\u0394x dI dt . Or, taking the limit as \u0394x\u21920 , we get \u2202V \u2202x =\u2212L0 \u2202I \u2202t . The changing current gives a gradient of the voltage. Referring again to the figure, if the voltage at x is changing, there must be some charge supplied to the capacity in that region. If we take the small piece of line between x and x+\u0394x , the charge on it is q=C0\u0394xV . The time rate-of-change of this charge is C0\u0394xdV/dt , but the charge changes only if the current I(x) into the element is different from the current I(x+\u0394x) out. Calling the difference \u0394I , we have \u0394I=\u2212C0\u0394x dV dt . Taking the limit as \u0394x\u21920 , we get \u2202I \u2202x =\u2212C0 \u2202V \u2202t . So the conservation of charge implies that the gradient of the current is proportional to the time rate-of-change of the voltage. Equations (24.1) and (24.2) are then the basic equations of a transmission line. If we wish, we could modify them to include the effects of resistance in the conductors or of leakage of charge through the insulation between the conductors, but for our present discussion we will just stay with the simple example. The two transmission line equations can be combined by differentiating one with respect to t and the other with respect to x and eliminating either V or I . Then we have either \u2202 2 V \u2202 x 2 = C 0 L 0 \u2202 2 V \u2202 t 2 (24.3) or \u2202 2 I \u2202 x 2 = C 0 L 0 \u2202 2 I \u2202 t 2 (24.4) Once more we recognize the wave equation in x . For a uniform transmission line, the voltage (and current) propagates along the line as a wave. The voltage along the line must be of the form V(x,t)=f(x\u2212vt) or V(x,t)=g(x+vt) , or a sum of both. Now what is the velocity v ? We know that the coefficient of the \u2202 2 /\u2202 t 2 term is just 1/ v 2 , so v= 1 L 0 C 0 \u2212 \u2212 \u2212 \u2212 \u221a . (24.5) We will leave it for you to show that the voltage for each wave in a line is proportional to the current of that wave and that the constant of proportionality is just the characteristic impedance z 0 . Calling V + and I + the voltage and current for a wave going in the plus x -direction, you should get V + = z 0 I + . (24.6) Similarly, for the wave going toward minus x the relation is V \u2212 = z 0 I \u2212 . V I The characteristic impedance\u2014as we found out from our filter equations\u2014is given by z 0 = L 0 C 0 \u2212 \u2212 \u2212 \u221a , (24.7) and is, therefore, a pure resistance. To find the propagation speed v and the characteristic impedance z 0 of a transmission line, we have to know the inductance and capacity per unit length. We can calculate them easily for a coaxial cable, so we will see how that goes. For the inductance we follow the ideas of Section 17\u20138, and set 1 2 L I 2 equal to the magnetic energy which we get by integrating \u03f5 0 c 2 B 2 /2 over the volume. Suppose that the central conductor carries the current I ; then we know that B=I/2\u03c0 \u03f5 0 c 2 r , where r is the distance from the axis. Taking as a volume element a cylindrical shell of thickness dr and of length l , we have for the magnetic energy U= \u03f5 0 c 2 2 \u222b b a ( I 2\u03c0 \u03f5 0 c 2 r ) 2 l2\u03c0rdr, b where a and b are the radii of the inner and outer conductors, respectively. Carrying out the integral, we get U= I 2 l 4\u03c0 \u03f5 0 c 2 ln b a . (24.8) Setting the energy equal to 1 2 L I 2 , we find L= l 2\u03c0 \u03f5 0 c 2 ln b a . (24.9) It is, as it should be, proportional to the length l of the line, so the inductance per unit length L 0 is L 0 = ln(b/a) 2\u03c0 \u03f5 0 c 2 . (24.10) We have worked out the charge on a cylindrical condenser (see Section 12\u20132). Now, dividing the charge by the potential difference, we get C= 2\u03c0 \u03f5 0 l ln(b/a) . 2 l The capacity per unit length C 0 is C/l . Combining this result with Eq. (24.10), we see that the product L 0 C 0 is just equal to 1/ c 2 , so v=1/ L 0 C 0 \u2212 \u2212 \u2212 \u2212 \u221a is equal to c . The wave travels down the line with the speed of light. We point out that this result depends on our assumptions: (a) that there are no dielectrics or magnetic materials in the space between the conductors, and (b) that the currents are all on the surfaces of the conductors (as they would be for perfect conductors). We will see later that for good conductors at high frequencies, all currents distribute themselves on the surfaces as they would for a perfect conductor, so this assumption is then valid. Now it is interesting that so long as assumptions (a) and (b) are correct, the product L 0 C 0 is equal to 1/ c 2 for any parallel pair of conductors\u2014even, say, for a hexagonal inner conductor anywhere inside an elliptical outer conductor. So long as the cross section is constant and the space between has no material, waves are propagated at the velocity of light. No such general statement can be made about the characteristic impedance. For the coaxial line, it is z 0 = ln(b/a) 2\u03c0 \u03f5 0 c . (24.11) The factor 1/ \u03f5 0 c has the dimensions of a resistance and is equal to 120\u03c0 ohms. The geometric factor ln(b/a) depends only logarithmically on the dimensions, so for the coaxial line\u2014and most lines\u2014the characteristic impedance has typical values of from 50 ohms or so to a few hundred ohms. The next thing we want to talk about seems, at first sight, to be a striking phenomenon: if the central conductor is removed from the coaxial line, it can still carry electromagnetic power. In other words, at high enough frequencies a hollow tube will work just as well as one with wires. It is related to the mysterious way in which a resonant circuit of a condenser and inductance gets replaced by nothing but a can at high frequencies. Although it may seem to be a remarkable thing when one has been thinking in terms of a transmission line as a distributed inductance and capacity, we all know that electromagnetic waves can travel along inside a hollow metal pipe. If the pipe is straight, we can see through it! So certainly electromagnetic waves go through a pipe. But we also know that it is not possible to transmit low-frequency waves (power or telephone) through the inside of a single metal pipe. So it must be that electromagnetic waves will go through if their wavelength is short enough. Therefore we want to discuss the limiting case of the longest wavelength (or the lowest frequency) that can get through a pipe of a given size. Since the pipe is then being used to carry waves, it is called a waveguide. We will begin with a rectangular pipe, because it is the simplest case to analyze. We will first give a mathematical treatment and come back later to look at the problem in a much more elementary way. The more elementary approach, however, can be applied easily only to a rectangular guide. The basic phenomena are the same for a general guide of arbitrary shape, so the mathematical argument is fundamentally more sound. Our problem, then, is to find what kind of waves can exist inside a rectangular pipe. Let\u2019s first choose some convenient coordinates; we take the z -axis along the length of the pipe, and the x - and y -axes parallel to the two sides, as shown in Fig. 24\u20133. We know that when light waves go down the pipe, they have a transverse electric field; so suppose we look first for solutions in which E is perpendicular to z , say with only a y -component, E y . This electric field will have some variation across the guide; in fact, it must go to zero at the sides parallel to the y -axis, because the currents and charges in a conductor always adjust themselves so that there is no tangential component of the electric field at the surface of a conductor. So E y will vary with x in some arch, as shown in Fig. 24\u20134. Perhaps it is the Bessel function we found for a cavity? No, because the Bessel function has to do with cylindrical geometries. For a rectangular geometry, waves are usually simple harmonic functions, so we should try something like sin k x x . Since we want waves that propagate down the guide, we expect the field to alternate between positive and negative values as we go along in z , as in Fig. 24\u20135, and these oscillations will travel along the guide with some velocity v . If we have oscillations at some definite frequency \u03c9 , we would guess that the wave might vary with z like cos(\u03c9t\u2212 k z z) , or to use the more convenient mathematical form, like e i(\u03c9t\u2212 k z z) . This z -dependence represents a wave travelling with the speed v=\u03c9/ k z (see Chapter 29, Vol. I). So we might guess that the wave in the guide would have the following mathematical form: E y = E 0 e i(\u03c9t\u2212 k z z) sin k x x. (24.12) Let\u2019s see whether this guess satisfies the correct field equations. First, the electric field should have no tangential components at the conductors. Our field satisfies this requirement; it is perpendicular to the top and bottom faces and is zero at the two side faces. Well, it is if we choose k x so that one-half a cycle of sin k x x just fits in the width of the guide\u2014that is, if k x a=\u03c0. (24.13) There are other possibilities, like k x a=2\u03c0 , 3\u03c0 , \u2026 , or, in general, k x a=n\u03c0, (24.14) where n is any integer. These represent various complicated arrangements of the field, but for now let\u2019s take only the simplest one, where k x =\u03c0/a , where a is the width of the inside of the guide. Next, the divergence of E must be zero in the free space inside the guide, since there are no charges there. Our E has only a y -component, and it doesn\u2019t change with y , so we do have that \u2207\u22c5E=0 . Finally, our electric field must agree with the rest of Maxwell\u2019s equations in the free space inside the guide. That is the same thing as saying that it must satisfy the wave equation \u2202 2 E y \u2202 x 2 + \u2202 2 E y \u2202 y 2 + \u2202 2 E y \u2202 z 2 \u2212 1 c 2 \u2202 2 E y \u2202 t 2 =0. (24.15) We have to see whether our guess, Eq. (24.12), will work. The second derivative of E y with respect to x is just \u2212 k 2 x E y . The second derivative with respect to y is zero, since nothing depends on y . The second derivative with respect to z is \u2212 k 2 z E y , and the second derivative with respect to t is \u2212 \u03c9 2 E y . Equation (24.15) then says that k 2 x E y + k 2 z E y \u2212 \u03c9 2 c 2 E y =0. 2 Unless E y is zero everywhere (which is not very interesting), this equation is correct if k 2 x + k 2 z \u2212 \u03c9 2 c 2 =0. (24.16) We have already fixed k x , so this equation tells us that there can be waves of the type we have assumed if k z is related to the frequency \u03c9 so that Eq. (24.16) is satisfied\u2014in other words, if k z = ( \u03c9 2 / c 2 )\u2212( \u03c0 2 / a 2 ) \u2212 \u2212 \u2212 \u2212 \u2212 \u2212 \u2212 \u2212 \u2212 \u2212 \u2212 \u2212 \u2212 \u2212 \u221a . (24.17) The waves we have described are propagated in the z -direction with this value of k z . The wave number k z we get from Eq. (24.17) tells us, for a given frequency \u03c9 , the speed with which the nodes of the wave propagate down the guide. The phase velocity is v= \u03c9 k z . (24.18) You will remember that the wavelength \u03bb of a travelling wave is given by \u03bb=2\u03c0v/\u03c9 , so k z is also equal to 2\u03c0/ \u03bb g , where \u03bb g is the wavelength of the oscillations along the z -direction\u2014the \u201cguide wavelength.\u201d The wavelength in the guide is different, of course, from the free-space wavelength of electromagnetic waves of the same frequency. If we call the free-space wavelength \u03bb 0 , which is equal to 2\u03c0c/\u03c9 , we can write Eq. (24.17) as \u03bb g = \u03bb 0 1\u2212( \u03bb 0 /2a ) 2 \u2212 \u2212 \u2212 \u2212 \u2212 \u2212 \u2212 \u2212 \u2212 \u2212 \u221a . (24.19) Besides the electric fields there are magnetic fields that will travel with the wave, but we will not bother to work out an expression for them right now. Since c 2 \u2207\u00d7B=\u2202E/\u2202t , the lines of B will circulate around the regions in which \u2202E/\u2202t is largest, that is, halfway between the maximum and minimum of E . The loops of B will lie parallel to the xz -plane and between the crests and troughs of E , as shown in Fig. 24\u20136. In solving Eq. (24.16) for k z , there should really be two roots\u2014one plus and one minus. We should write k z =\u00b1 ( \u03c9 2 / c 2 )\u2212( \u03c0 2 / a 2 ) \u2212 \u2212 \u2212 \u2212 \u2212 \u2212 \u2212 \u2212 \u2212 \u2212 \u2212 \u2212 \u2212 \u2212 \u221a . (24.20) The two signs simply mean that there can be waves which propagate with a negative phase velocity (toward \u2212z ), as well as waves which propagate in the positive direction in the guide. Naturally, it should be possible for waves to go in either direction. Since both types of waves can be present at the same time, there will be the possibility of standing-wave solutions. Our equation for k z also tells us that higher frequencies give larger values of k z , and therefore smaller wavelengths, until in the limit of large \u03c9 , k becomes equal to \u03c9/c , which is the value we would expect for waves in free space. The light we \u201csee\u201d through a pipe still travels at the speed c . But now notice that if we go toward low frequencies, something strange happens. At first the wavelength gets longer and longer, but if \u03c9 gets too small the quantity inside the square root of Eq. (24.20) suddenly becomes negative. This will happen as soon as \u03c9 gets to be less than \u03c0c/a \u2014or when \u03bb 0 becomes greater than 2a . In other words, when the frequency gets smaller than a certain critical frequency \u03c9 c =\u03c0c/a , the wave number k z (and also \u03bb g ) becomes imaginary and we haven\u2019t got a solution any more. Or do we? Who said that k z has to be real? What if it does come out imaginary? Our field equations are still satisfied. Perhaps an imaginary k z also represents a wave. Suppose \u03c9 is less than \u03c9 c ; then we can write k z =\u00b1i k \u2032 , (24.21) where k \u2032 is a positive real number: k \u2032 = ( \u03c0 2 / a 2 )\u2212( \u03c9 2 / c 2 ) \u2212 \u2212 \u2212 \u2212 \u2212 \u2212 \u2212 \u2212 \u2212 \u2212 \u2212 \u2212 \u2212 \u2212 \u221a . (24.22) If we now go back to our expression, Eq. (24.12), for E y , we have E y = E 0 e i(\u03c9t\u2213i k \u2032 z) sin k x x, (24.23) which we can write as E y = E 0 e \u00b1 k \u2032 z e i\u03c9t sin k x x. (24.24) This expression gives an E -field that oscillates with time as e i\u03c9t but which varies with z as e \u00b1 k \u2032 z . It decreases or increases with z smoothly as a real exponential. In our derivation we didn\u2019t worry about the sources that started the waves, but there must, of course, be a source someplace in the guide. The sign that goes with k \u2032 must be the one that makes the field decrease with increasing distance from the source of the waves. So for frequencies below \u03c9 c =\u03c0c/a , waves do not propagate down the guide; the oscillating fields penetrate into the guide only a distance of the order of 1/ k \u2032 . For this reason, the frequency \u03c9 c is called the \u201ccutoff frequency\u201d of the guide. Looking at Eq. (24.22), we see that for frequencies just a little below \u03c9 c , the number k \u2032 is small and the fields can penetrate a long distance into the guide. But if \u03c9 is much less than \u03c9 c , the exponential coefficient k \u2032 is equal to \u03c0/a and the field dies off extremely rapidly, as shown in Fig. 24\u20137. The field decreases by 1/e in the distance a/\u03c0 , or in only about one-third of the guide width. The fields penetrate very little distance from the source. We want to emphasize an interesting feature of our analysis of the guided waves\u2014the appearance of the imaginary wave number k z . Normally, if we solve an equation in physics and get an imaginary number, it doesn\u2019t mean anything physical. For waves, however, an imaginary wave number does mean something. The wave equation is still satisfied; it only means that the solution gives exponentially decreasing fields instead of propagating waves. So in any wave problem where k becomes imaginary for some frequency, it means that the form of the wave changes\u2014the sine wave changes into an exponential. The wave velocity we have used above is the phase velocity, which is the speed of a node of the wave; it is a function of frequency. If we combine Eqs. (24.17) and (24.18), we can write v phase = c 1\u2212( \u03c9 c /\u03c9 ) 2 \u2212 \u2212 \u2212 \u2212 \u2212 \u2212 \u2212 \u2212 \u2212 \u221a . (24.25) For frequencies above cutoff\u2014where travelling waves exist\u2014 \u03c9 c /\u03c9 is less than one, and v phase is real and greater than the speed of light. We have already seen in Chapter 48 of Vol. I that phase velocities greater than light are possible, because it is just the nodes of the wave which are moving and not energy or information. In order to know how fast signals will travel, we have to calculate the speed of pulses or modulations made by the interference of a wave of one frequency with one or more waves of slightly different frequencies (see Chapter 48, Vol. I). We have called the speed of the envelope of such a group of waves the group velocity; it is not \u03c9/k but d\u03c9/dk : v group = d\u03c9 dk . (24.26) Taking the derivative of Eq. (24.17) with respect to \u03c9 and inverting to get d\u03c9/dk , we find that v group =c 1\u2212( \u03c9 c /\u03c9 ) 2 \u2212 \u2212 \u2212 \u2212 \u2212 \u2212 \u2212 \u2212 \u2212 \u221a , (24.27) which is less than the speed of light. The geometric mean of v phase and v group is just c , the speed of light: v phase v group = c 2 . (24.28) This is curious, because we have seen a similar relation in quantum mechanics. For a particle with any velocity\u2014even relativistic\u2014the momentum p and energy U are related by U 2 = p 2 c 2 + m 2 c 4 . (24.29) But in quantum mechanics the energy is \u210f\u03c9 , and the momentum is \u210f/\u02c9\u03bb , which is equal to \u210fk ; so Eq. (24.29) can be written \u03c9 2 c 2 = k 2 + m 2 c 2 \u210f 2 , (24.30) or k= ( \u03c9 2 / c 2 )\u2212( m 2 c 2 / \u210f 2 ) \u2212 \u2212 \u2212 \u2212 \u2212 \u2212 \u2212 \u2212 \u2212 \u2212 \u2212 \u2212 \u2212 \u2212 \u2212 \u2212 \u221a , (24.31) which looks very much like Eq. (24.17) \u2026 Interesting! The group velocity of the waves is also the speed at which energy is transported along the guide. If we want to find the energy flow down the guide, we can get it from the energy density times the group velocity. If the root mean square electric field is E 0 , then the average density of electric energy is \u03f5 0 E 2 0 /2 . There is also some energy associated with the magnetic field. We will not prove it here, but in any cavity or guide the magnetic and electric energies are equal, so the total electromagnetic energy density is \u03f5 0 E 2 0 . The power dU/dt transmitted by the guide is then dU dt = \u03f5 0 E 2 0 ab v group . (24.32) (We will see later another, more general way of getting the energy flow.) Energy can be coupled into a waveguide by some kind of an \u201cantenna.\u201d For example, a little vertical wire or \u201cstub\u201d will do. The presence of the guided waves can be observed by picking up some of the electromagnetic energy with a little receiving \u201cantenna,\u201d which again can be a little stub of wire or a small loop. In Fig. 24\u20138, we show a guide with some cutaways to show a driving stub and a pickup \u201cprobe\u201d. The driving stub can be connected to a signal generator via a coaxial cable, and the pickup probe can be connected by a similar cable to a detector. It is usually convenient to insert the pickup probe via a long thin slot in the guide, as shown in Fig. 24\u20138. Then the probe can be moved back and forth along the guide to sample the fields at various positions. If the signal generator is set at some frequency \u03c9 greater than the cutoff frequency \u03c9 c , there will be waves propagated down the guide from the driving stub. These will be the only waves present if the guide is infinitely long, which can effectively be arranged by terminating the guide with a carefully designed absorber in such a way that there are no reflections from the far end. Then, since the detector measures the time average of the fields near the probe, it will pick up a signal which is independent of the position along the guide; its output will be proportional to the power being transmitted. If now the far end of the guide is finished off in some way that produces a reflected wave\u2014as an extreme example, if we closed it off with a metal plate\u2014there will be a reflected wave in addition to the original forward wave. These two waves will interfere and produce a standing wave in the guide similar to the standing waves on a string which we discussed in Chapter 49 of Vol. I. Then, as the pickup probe is moved along the line, the detector reading will rise and fall periodically, showing a maximum in the fields at each loop of the standing wave and a minimum at each node. The distance between two successive nodes (or loops) is just \u03bb g /2 . This gives a convenient way of measuring the guide wavelength. If the frequency is now moved closer to \u03c9 c , the distances between nodes increase, showing that the guide wavelength increases as predicted by Eq. (24.19). Suppose now the signal generator is set at a frequency just a little below \u03c9 c . Then the detector output will decrease gradually as the pickup probe is moved down the guide. If the frequency is set somewhat lower, the field strength will fall rapidly, following the curve of Fig. 24\u20137, and showing that waves are not propagated. An important practical use of waveguides is for the transmission of high-frequency power, as, for example, in coupling the high-frequency oscillator or output amplifier of a radar set to an antenna. In fact, the antenna itself usually consists of a parabolic reflector fed at its focus by a waveguide flared out at the end to make a \u201chorn\u201d that radiates the waves coming along the guide. Although high frequencies can be transmitted along a coaxial cable, a waveguide is better for transmitting large amounts of power. First, the maximum power that can be transmitted along a line is limited by the breakdown of the insulation (solid or gas) between the conductors. For a given amount of power, the field strengths in a guide are usually less than they are in a coaxial cable, so higher powers can be transmitted before breakdown occurs. Second, the power losses in the coaxial cable are usually greater than in a waveguide. In a coaxial cable there must be insulating material to support the central conductor, and there is an energy loss in this material\u2014particularly at high frequencies. Also, the current densities on the central conductor are quite high, and since the losses go as the square of the current density, the lower currents that appear on the walls of the guide result in lower energy losses. To keep these losses to a minimum, the inner surfaces of the guide are often plated with a material of high conductivity, such as silver. The problem of connecting a \u201ccircuit\u201d with waveguides is quite different from the corresponding circuit problem at low frequencies, and is usually called microwave \u201cplumbing.\u201d Many special devices have been developed for the purpose. For instance, two sections of waveguide are usually connected together by means of flanges, as can be seen in Fig. 24\u20139. Such connections can, however, cause serious energy losses, because the surface currents must flow across the joint, which may have a relatively high resistance. One way to avoid such losses is to make the flanges as shown in the cross section drawn in Fig. 24\u201310. A small space is left between the adjacent sections of the guide, and a groove is cut in the face of one of the flanges to make a small cavity of the type shown in Fig. 23\u201316(c). The dimensions are chosen so that this cavity is resonant at the frequency being used. This resonant cavity presents a high \u201cimpedance\u201d to the currents, so relatively little current flows across the metallic joints (at a in Fig. 24\u201310). The high guide currents simply charge and discharge the \u201ccapacity\u201d of the gap (at b in the figure), where there is little dissipation of energy. Suppose you want to stop a waveguide in a way that won\u2019t result in reflected waves. Then you must put something at the end that imitates an infinite length of guide. You need a \u201ctermination\u201d which acts for the guide like the characteristic impedance does for a transmission line\u2014something that absorbs the arriving waves without making reflections. Then the guide will act as though it went on forever. Such terminations are made by putting inside the guide some wedges of resistance material carefully designed to absorb the wave energy while generating almost no reflected waves. If you want to connect three things together\u2014for instance, one source to two different antennas\u2014then you can use a \u201cT\u201d like the one shown in Fig. 24\u201311. Power fed in at the center section of the \u201cT\u201d will be split and go out the two side arms (and there may also be some reflected waves). You can see qualitatively from the sketches in Fig. 24\u201312 that the fields would spread out when they get to the end of the input section and make electric fields that will start waves going out the two arms. Depending on whether electric fields in the guide are parallel or perpendicular to the \u201ctop\u201d of the \u201cT,\u201d the fields at the junction would be roughly as shown in (a) or (b) of Fig. 24\u201312. Finally, we would like to describe a device called a \u201cunidirectional coupler,\u201d which is very useful for telling what is going on after you have connected a complicated arrangement of waveguides. Suppose you want to know which way the waves are going in a particular section of guide\u2014you might be wondering, for instance, whether or not there is a strong reflected wave. The unidirectional coupler takes out a small fraction of the power of a guide if there is a wave going one way, but none if the wave is going the other way. By connecting the output of the coupler to a detector, you can measure the \u201cone-way\u201d power in the guide. Figure 24\u201313 is a drawing of a unidirectional coupler; a piece of waveguide AB has another piece of waveguide CD soldered to it along one face. The guide CD is curved away so that there is room for the connecting flanges. Before the guides are soldered together, two (or more) holes have been drilled in each guide (matching each other) so that some of the fields in the main guide AB can be coupled into the secondary guide CD . Each of the holes acts like a little antenna that produces a wave in the secondary guide. If there were only one hole, waves would be sent in both directions and would be the same no matter which way the wave was going in the primary guide. But when there are two holes with a separation space equal to one-quarter of the guide wavelength, they will make two sources 90 \u2218 out of phase. Do you remember that we considered in Chapter 29 of Vol. I the interference of the waves from two antennas spaced \u03bb/4 apart and excited 90 \u2218 out of phase in time? We found that the waves subtract in one direction and add in the opposite direction. The same thing will happen here. The wave produced in the guide CD will be going in the same direction as the wave in AB . If the wave in the primary guide is travelling from A toward B , there will be a wave at the output D of the secondary guide. If the wave in the primary guide goes from B toward A , there will be a wave going toward the end C of the secondary guide. This end is equipped with a termination, so that this wave is absorbed and there is no wave at the output of the coupler. The wave we have chosen to analyze is a special solution of the field equations. There are many more. Each solution is called a waveguide \u201cmode.\u201d For example, our x -dependence of the field was just one-half a cycle of a sine wave. There is an equally good solution with a full cycle; then the variation of E y with x is as shown in Fig. 24\u201314. The k x for such a mode is twice as large, so the cutoff frequency is much higher. Also, in the wave we studied E has only a y -component, but there are other modes with more complicated electric fields. If the electric field has components only in x and y \u2014so that the total electric field is always at right angles to the z -direction\u2014the mode is called a \u201ctransverse electric\u201d (or TE) mode. The magnetic field of such modes will always have a z -component. It turns out that if E has a component in the z -direction (along the direction of propagation), then the magnetic field will always have only transverse components. So such fields are called transverse magnetic (TM) modes. For a rectangular guide, all the other modes have a higher cutoff frequency than the simple TE mode we have described. It is, therefore, possible\u2014and usual\u2014to use a guide with a frequency just above the cutoff for this lowest mode but below the cutoff frequency for all the others, so that just the one mode is propagated. Otherwise, the behavior gets complicated and difficult to control. We want now to show you another way of understanding why a waveguide attenuates the fields rapidly for frequencies below the cutoff frequency \u03c9 c . Then you will have a more \u201cphysical\u201d idea of why the behavior changes so drastically between low and high frequencies. We can do this for the rectangular guide by analyzing the fields in terms of reflections\u2014or images\u2014in the walls of the guide. The approach only works for rectangular guides, however; that\u2019s why we started with the more mathematical analysis which works, in principle, for guides of any shape. For the mode we have described, the vertical dimension (in y ) had no effect, so we can ignore the top and bottom of the guide and imagine that the guide is extended indefinitely in the vertical direction. We imagine then that the guide just consists of two vertical plates with the separation a . Let\u2019s say that the source of the fields is a vertical wire placed in the middle of the guide, with the wire carrying a current that oscillates at the frequency \u03c9 . In the absence of the guide walls such a wire would radiate cylindrical waves. Now we consider that the guide walls are perfect conductors. Then, just as in electrostatics, the conditions at the surface will be correct if we add to the field of the wire the field of one or more suitable image wires. The image idea works just as well for electrodynamics as it does for electrostatics, provided, of course, that we also include the retardations. We know that is true because we have often seen a mirror producing an image of a light source. And a mirror is just a \u201cperfect\u201d conductor for electromagnetic waves with optical frequencies. Now let\u2019s take a horizontal cross section, as shown in Fig. 24\u201315, where W 1 and W 2 are the two guide walls and S 0 is the source wire. We call the direction of the current in the wire positive. Now if there were only one wall, say W 1 , we could remove it if we placed an image source (with opposite polarity) at the position marked S 1 . But with both walls in place there will also be an image of S 0 in the wall W 2 , which we show as the image S 2 . This source, too, will have an image in W 1 , which we call S 3 . Now both S 1 and S 3 will have images in W 2 at the positions marked S 4 and S 6 , and so on. For our two plane conductors with the source halfway between, the fields are the same as those produced by an infinite line of sources, all separated by the distance a . (It is, in fact just what you would see if you looked at a wire placed halfway between two parallel mirrors.) For the fields to be zero at the walls, the polarity of the currents in the images must alternate from one image to the next. In other words, they oscillate 180 \u2218 out of phase. The waveguide field is, then, just the superposition of the fields of such an infinite set of line sources. We know that if we are close to the sources, the field is very much like the static fields. We considered in Section 7\u20135 the static field of a grid of line sources and found that it is like the field of a charged plate except for terms that decrease exponentially with the distance from the grid. Here the average source strength is zero, because the sign alternates from one source to the next. Any fields which exist should fall off exponentially with distance. Close to the source, we see the field mainly of the nearest source; at large distances, many sources contribute and their average effect is zero. So now we see why the waveguide below cutoff frequency gives an exponentially decreasing field. At low frequencies, in particular, the static approximation is good, and it predicts a rapid attenuation of the fields with distance. Now we are faced with the opposite question: Why are waves propagated at all? That is the mysterious part! The reason is that at high frequencies the retardation of the fields can introduce additional changes in phase which can cause the fields of the out-of-phase sources to add instead of cancelling. In fact, in Chapter 29 of Vol. I we have already studied, just for this problem, the fields generated by an array of antennas or by an optical grating. There we found that when several radio antennas are suitably arranged, they can give an interference pattern that has a strong signal in some direction but no signal in another. Suppose we go back to Fig. 24\u201315 and look at the fields which arrive at a large distance from the array of image sources. The fields will be strong only in certain directions which depend on the frequency\u2014only in those directions for which the fields from all the sources add in phase. At a reasonable distance from the sources the field propagates in these special directions as plane waves. We have sketched such a wave in Fig. 24\u201316, where the solid lines represent the wave crests and the dashed lines represent the troughs. The wave direction will be the one for which the difference in the retardation for two neighboring sources to the crest of a wave corresponds to one-half a period of oscillation. In other words, the difference between r 2 and r 0 in the figure is one-half of the free-space wavelength: r 2 \u2212 r 0 = \u03bb 0 2 . \u03bb The angle \u03b8 is then given by sin\u03b8= \u03bb 0 2a . (24.33) There is, of course, another set of waves travelling downward at the symmetric angle with respect to the array of sources. The complete waveguide field (not too close to the source) is the superposition of these two sets of waves, as shown in Fig. 24\u201317. The actual fields are really like this, of course, only between the two walls of the waveguide. At points like A and C , the crests of the two wave patterns coincide, and the field will have a maximum; at points like B , both waves have their peak negative value, and the field has its minimum (largest negative) value. As time goes on the field in the guide appears to be travelling along the guide with a wavelength \u03bb g , which is the distance from A to C . That distance is related to \u03b8 by cos\u03b8= \u03bb 0 \u03bb g . (24.34) Using Eq. (24.33) for \u03b8 , we get that \u03bb g = \u03bb 0 cos\u03b8 = \u03bb 0 1\u2212( \u03bb 0 /2a ) 2 \u2212 \u2212 \u2212 \u2212 \u2212 \u2212 \u2212 \u2212 \u2212 \u2212 \u221a , (24.35) which is just what we found in Eq. (24.19). Now we see why there is only wave propagation above the cutoff frequency \u03c9 0 . If the free-space wavelength is longer than 2a , there is no angle where the waves shown in Fig. 24\u201316 can appear. The necessary constructive interference appears suddenly when \u03bb 0 drops below 2a , or when \u03c9 goes above \u03c9 0 =\u03c0c/a . If the frequency is high enough, there can be two or more possible directions in which the waves will appear. For our case, this will happen if \u03bb 0 < 2 3 a . In general, however, it could also happen when \u03bb 0 <a . These additional waves correspond to the higher guide modes we have mentioned. It has also been made evident by our analysis why the phase velocity of the guided waves is greater than c and why this velocity depends on \u03c9 . As \u03c9 is changed, the angle of the free waves of Fig. 24\u201316 changes, and therefore so does the velocity along the guide. Although we have described the guided wave as the superposition of the fields of an infinite array of line sources, you can see that we would arrive at the same result if we imagined two sets of free-space waves being continually reflected back and forth between two perfect mirrors\u2014remembering that a reflection means a reversal of phase. These sets of reflecting waves would all cancel each other unless they were going at just the angle \u03b8 given in Eq. (24.33). There are many ways of looking at the same thing."
    },
    {
        "input": "Polarization",
        "output": "In this chapter we shall consider those phenomena which depend on the fact that the electric field that describes the light is a vector. In previous chapters we have not been concerned with the direction of oscillation of the electric field, except to note that the electric vector lies in a plane perpendicular to the direction of propagation. The particular direction in this plane has not concerned us. We now consider those phenomena whose central feature is the particular direction of oscillation of the electric field. In ideally monochromatic light, the electric field must oscillate at a definite frequency, but since the x -component and the y -component can oscillate independently at a definite frequency, we must first consider the resultant effect produced by superposing two independent oscillations at right angles to each other. What kind of electric field is made up of an x -component and a y -component which oscillate at the same frequency? If one adds to an x -vibration a certain amount of y -vibration at the same phase, the result is a vibration in a new direction in the xy -plane. Figure 33\u20131 illustrates the superposition of different amplitudes for the x -vibration and the y -vibration. But the resultants shown in Fig. 33\u20131 are not the only possibilities; in all of these cases we have assumed that the x -vibration and the y -vibration are in phase, but it does not have to be that way. It could be that the x -vibration and the y -vibration are out of phase. When the x -vibration and the y -vibration are not in phase, the electric field vector moves around in an ellipse, and we can illustrate this in a familiar way. If we hang a ball from a support by a long string, so that it can swing freely in a horizontal plane, it will execute sinusoidal oscillations. If we imagine horizontal x - and y -coordinates with their origin at the rest position of the ball, the ball can swing in either the x - or y -direction with the same pendulum frequency. By selecting the proper initial displacement and initial velocity, we can set the ball in oscillation along either the x -axis or the y -axis, or along any straight line in the xy -plane. These motions of the ball are analogous to the oscillations of the electric field vector illustrated in Fig. 33\u20131. In each instance, since the x -vibrations and the y -vibrations reach their maxima and minima at the same time, the x - and y -oscillations are in phase. But we know that the most general motion of the ball is motion in an ellipse, which corresponds to oscillations in which the x - and y -directions are not in the same phase. The superposition of x - and y -vibrations which are not in phase is illustrated in Fig. 33\u20132 for a variety of angles between the phase of the x -vibration and that of the y -vibration. The general result is that the electric vector moves around an ellipse. The motion in a straight line is a particular case corresponding to a phase difference of zero (or an integral multiple of \u03c0 ); motion in a circle corresponds to equal amplitudes with a phase difference of 90 \u2218 (or any odd integral multiple of \u03c0/2 ). In Fig. 33\u20132 we have labeled the electric field vectors in the x - and y -directions with complex numbers, which are a convenient representation in which to express the phase difference. Do not confuse the real and imaginary components of the complex electric vector in this notation with the x - and y -coordinates of the field. The x - and y -coordinates plotted in Fig. 33\u20131 and Fig. 33\u20132 are actual electric fields that we can measure. The real and imaginary components of a complex electric field vector are only a mathematical convenience and have no physical significance. Now for some terminology. Light is linearly polarized (sometimes called plane polarized) when the electric field oscillates on a straight line; Fig. 33\u20131 illustrates linear polarization. When the end of the electric field vector travels in an ellipse, the light is elliptically polarized. When the end of the electric field vector travels around a circle, we have circular polarization. If the end of the electric vector, when we look at it as the light comes straight toward us, goes around in a counterclockwise direction, we call it right-hand circular polarization. Figure 33\u20132(g) illustrates right-hand circular polarization, and Fig. 33\u20132(c) shows left-hand circular polarization. In both cases the light is coming out of the paper. Our convention for labeling left-hand and right-hand circular polarization is consistent with that which is used today for all the other particles in physics which exhibit polarization (e.g., electrons). However, in some books on optics the opposite conventions are used, so one must be careful. We have considered linearly, circularly, and elliptically polarized light, which covers everything except for the case of unpolarized light. Now how can the light be unpolarized when we know that it must vibrate in one or another of these ellipses? If the light is not absolutely monochromatic, or if the x - and y -phases are not kept perfectly together, so that the electric vector first vibrates in one direction, then in another, the polarization is constantly changing. Remember that one atom emits during 10 \u22128 sec, and if one atom emits a certain polarization, and then another atom emits light with a different polarization, the polarizations will change every 10 \u22128 sec. If the polarization changes more rapidly than we can detect it, then we call the light unpolarized, because all the effects of the polarization average out. None of the interference effects of polarization would show up with unpolarized light. But as we see from the definition, light is unpolarized only if we are unable to find out whether the light is polarized or not. The first example of the polarization effect that we have already discussed is the scattering of light. Consider a beam of light, for example from the sun, shining on the air. The electric field will produce oscillations of charges in the air, and motion of these charges will radiate light with its maximum intensity in a plane normal to the direction of vibration of the charges. The beam from the sun is unpolarized, so the direction of polarization changes constantly, and the direction of vibration of the charges in the air changes constantly. If we consider light scattered at 90 \u2218 , the vibration of the charged particles radiates to the observer only when the vibration is perpendicular to the observer\u2019s line of sight, and then light will be polarized along the direction of vibration. So scattering is an example of one means of producing polarization. Another interesting effect of polarization is the fact that there are substances for which the index of refraction is different for light linearly polarized in one direction and linearly polarized in another. Suppose that we had some material which consisted of long, nonspherical molecules, longer than they are wide, and suppose that these molecules were arranged in the substance with their long axes parallel. Then what happens when the oscillating electric field passes through this substance? Suppose that because of the structure of the molecule, the electrons in the substance respond more easily to oscillations in the direction parallel to the axes of the molecules than they would respond if the electric field tries to push them at right angles to the molecular axis. In this way we expect a different response for polarization in one direction than for polarization at right angles to that direction. Let us call the direction of the axes of the molecules the optic axis. When the polarization is in the direction of the optic axis the index of refraction is different than it would be if the direction of polarization were at right angles to it. Such a substance is called birefringent. It has two refrangibilities, i.e., two indexes of refraction, depending on the direction of the polarization inside the substance. What kind of a substance can be birefringent? In a birefringent substance there must be a certain amount of lining up, for one reason or another, of unsymmetrical molecules. Certainly a cubic crystal, which has the symmetry of a cube, cannot be birefringent. But long needlelike crystals undoubtedly contain molecules that are asymmetric, and one observes this effect very easily. Let us see what effects we would expect if we were to shine polarized light through a plate of a birefringent substance. If the polarization is parallel to the optic axis, the light will go through with one velocity; if the polarization is perpendicular to the axis, the light is transmitted with a different velocity. An interesting situation arises when, say, light is linearly polarized at 45 \u2218 to the optic axis. Now the 45 \u2218 polarization, we have already noticed, can be represented as a superposition of the x - and the y -polarizations of equal amplitude and in phase, as shown in Fig. 33\u20132(a). Since the x - and y -polarizations travel with different velocities, their phases change at a different rate as the light passes through the substance. So, although at the start the x - and y -vibrations are in phase, inside the material the phase difference between x - and y -vibrations is proportional to the depth in the substance. As the light proceeds through the material the polarization changes as shown in the series of diagrams in Fig. 33\u20132. If the thickness of the plate is just right to introduce a 90 \u2218 phase shift between the x - and y -polarizations, as in Fig. 33\u20132(c), the light will come out circularly polarized. Such a thickness is called a quarter-wave plate, because it introduces a quarter-cycle phase difference between the x - and the y -polarizations. If linearly polarized light is sent through two quarter-wave plates, it will come out plane-polarized again, but at right angles to the original direction, as we can see from Fig. 33\u20132(e). One can easily illustrate this phenomenon with a piece of cellophane. Cellophane is made of long, fibrous molecules, and is not isotropic, since the fibers lie preferentially in a certain direction. To demonstrate birefringence we need a beam of linearly polarized light, and we can obtain this conveniently by passing unpolarized light through a sheet of polaroid. Polaroid, which we will discuss later in more detail, has the useful property that it transmits light that is linearly polarized parallel to the axis of the polaroid with very little absorption, but light polarized in a direction perpendicular to the axis of the polaroid is strongly absorbed. When we pass unpolarized light through a sheet of polaroid, only that part of the unpolarized beam which is vibrating parallel to the axis of the polaroid gets through, so that the transmitted beam is linearly polarized. This same property of polaroid is also useful in detecting the direction of polarization of a linearly polarized beam, or in determining whether a beam is linearly polarized or not. One simply passes the beam of light through the polaroid sheet and rotates the polaroid in the plane normal to the beam. If the beam is linearly polarized, it will not be transmitted through the sheet when the axis of the polaroid is normal to the direction of polarization. The transmitted beam is only slightly attenuated when the axis of the polaroid sheet is rotated through 90 \u2218 . If the transmitted intensity is independent of the orientation of the polaroid, the beam is not linearly polarized. To demonstrate the birefringence of cellophane, we use two sheets of polaroid, as shown in Fig. 33\u20133. The first gives us a linearly polarized beam which we pass through the cellophane and then through the second polaroid sheet, which serves to detect any effect the cellophane may have had on the polarized light passing through it. If we first set the axes of the two polaroid sheets perpendicular to each other and remove the cellophane, no light will be transmitted through the second polaroid. If we now introduce the cellophane between the two polaroid sheets, and rotate the sheet about the beam axis, we observe that in general the cellophane makes it possible for some light to pass through the second polaroid. However, there are two orientations of the cellophane sheet, at right angles to each other, which permit no light to pass through the second polaroid. These orientations in which linearly polarized light is transmitted through the cellophane with no effect on the direction of polarization must be the directions parallel and perpendicular to the optic axis of the cellophane sheet. We suppose that the light passes through the cellophane with two different velocities in these two different orientations, but it is transmitted without changing the direction of polarization. When the cellophane is turned halfway between these two orientations, as shown in Fig. 33\u20133, we see that the light transmitted through the second polaroid is bright. It just happens that ordinary cellophane used in commercial packaging is very close to a half-wave thickness for most of the colors in white light. Such a sheet will turn the axis of linearly polarized light through 90 \u2218 if the incident linearly polarized beam makes an angle of 45 \u2218 with the optic axis, so that the beam emerging from the cellophane is then vibrating in the right direction to pass through the second polaroid sheet. If we use white light in our demonstration, the cellophane sheet will be of the proper half-wave thickness only for a particular component of the white light, and the transmitted beam will have the color of this component. The color transmitted depends on the thickness of the cellophane sheet, and we can vary the effective thickness of the cellophane by tilting it so that the light passes through the cellophane at an angle, consequently through a longer path in the cellophane. As the sheet is tilted the transmitted color changes. With cellophane of different thicknesses one can construct filters that will transmit different colors. These filters have the interesting property that they transmit one color when the two polaroid sheets have their axes perpendicular, and the complementary color when the axes of the two polaroid sheets are parallel. Another interesting application of aligned molecules is quite practical. Certain plastics are composed of very long and complicated molecules all twisted together. When the plastic is solidified very carefully, the molecules are all twisted in a mass, so that there are as many aligned in one direction as another, and so the plastic is not particularly birefringent. Usually there are strains and stresses introduced when the material is solidified, so the material is not perfectly homogeneous. However, if we apply tension to a piece of this plastic material, it is as if we were pulling a whole tangle of strings, and there will be more strings preferentially aligned parallel to the tension than in any other direction. So when a stress is applied to certain plastics, they become birefringent, and one can see the effects of the birefringence by passing polarized light through the plastic. If we examine the transmitted light through a polaroid sheet, patterns of light and dark fringes will be observed (in color, if white light is used). The patterns move as stress is applied to the sample, and by counting the fringes and seeing where most of them are, one can determine what the stress is. Engineers use this phenomenon as a means of finding the stresses in odd-shaped pieces that are difficult to calculate. Another interesting example of a way of obtaining birefringence is by means of a liquid substance. Consider a liquid composed of long asymmetric molecules which carry a plus or minus average charge near the ends of the molecule, so that the molecule is an electric dipole. In the collisions in the liquid the molecules will ordinarily be randomly oriented, with as many molecules pointed in one direction as in another. If we apply an electric field the molecules will tend to line up, and the moment they line up the liquid becomes birefringent. With two polaroid sheets and a transparent cell containing such a polar liquid, we can devise an arrangement with the property that light is transmitted only when the electric field is applied. So we have an electrical switch for light, which is called a Kerr cell. This effect, that an electric field can produce birefringence in certain liquids, is called the Kerr effect. So far we have considered substances in which the refractive index is different for light polarized in different directions. Of very practical value are those crystals and other substances in which not only the index, but also the coefficient of absorption, is different for light polarized in different directions. By the same arguments which supported the idea of birefringence, it is understandable that absorption can vary with the direction in which the charges are forced to vibrate in an anisotropic substance. Tourmaline is an old, famous example and polaroid is another. Polaroid consists of a thin layer of small crystals of herapathite (a salt of iodine and quinine), all aligned with their axes parallel. These crystals absorb light when the oscillations are in one direction, and they do not absorb appreciably when the oscillations are in the other direction. Suppose that we send light into a polaroid sheet polarized linearly at an angle \u03b8 to the passing direction. What intensity will come through? This incident light can be resolved into a component perpendicular to the pass direction which is proportional to sin\u03b8 , and a component along the pass direction which is proportional to cos\u03b8 . The amplitude which comes out of the polaroid is only the cosine \u03b8 part; the sin\u03b8 component is absorbed. The amplitude which passes through the polaroid is smaller than the amplitude which entered, by a factor cos\u03b8 . The energy which passes through the polaroid, i.e., the intensity of the light, is proportional to the square of cos\u03b8 . Cos 2 \u03b8 , then, is the intensity transmitted when the light enters polarized at an angle \u03b8 to the pass direction. The absorbed intensity, of course, is sin 2 \u03b8 . An interesting paradox is presented by the following situation. We know that it is not possible to send a beam of light through two polaroid sheets with their axes crossed at right angles. But if we place a third polaroid sheet between the first two, with its pass axis at 45 \u2218 to the crossed axes, some light is transmitted. We know that polaroid absorbs light, it does not create anything. Nevertheless, the addition of a third polaroid at 45 \u2218 allows more light to get through. The analysis of this phenomenon is left as an exercise for the student. One of the most interesting examples of polarization is not in complicated crystals or difficult substances, but in one of the simplest and most familiar of situations\u2014the reflection of light from a surface. Believe it or not, when light is reflected from a glass surface it may be polarized, and the physical explanation of this is very simple. It was discovered empirically by Brewster that light reflected from a surface is completely polarized if the reflected beam and the beam refracted into the material form a right angle. The situation is illustrated in Fig. 33\u20134. If the incident beam is polarized in the plane of incidence, there will be no reflection at all. Only if the incident beam is polarized normal to the plane of incidence will it be reflected. The reason is very easy to understand. In the reflecting material the light is polarized transversely, and we know that it is the motion of the charges in the material which generates the emergent beam, which we call the reflected beam. The source of this so-called reflected light is not simply that the incident beam is reflected; our deeper understanding of this phenomenon tells us that the incident beam drives an oscillation of the charges in the material, which in turn generates the reflected beam. From Fig. 33\u20134 it is clear that only oscillations normal to the paper can radiate in the direction of reflection, and consequently the reflected beam will be polarized normal to the plane of incidence. If the incident beam is polarized in the plane of incidence, there will be no reflected light. This phenomenon is readily demonstrated by reflecting a linearly polarized beam from a flat piece of glass. If the glass is turned to present different angles of incidence to the polarized beam, sharp attenuation of the reflected intensity is observed when the angle of incidence passes through Brewster\u2019s angle. This attenuation is observed only if the plane of polarization lies in the plane of incidence. If the plane of polarization is normal to the plane of incidence, the usual reflected intensity is observed at all angles. Another most remarkable effect of polarization is observed in materials composed of molecules which do not have reflection symmetry: molecules shaped something like a corkscrew, or like a gloved hand, or any shape which, if viewed through a mirror, would be reversed in the same way that a left-hand glove reflects as a right-hand glove. Suppose all of the molecules in the substance are the same, i.e., none is a mirror image of any other. Such a substance may show an interesting effect called optical activity, whereby as linearly polarized light passes through the substance, the direction of polarization rotates about the beam axis. To understand the phenomenon of optical activity requires some calculation, but we can see qualitatively how the effect might come about, without actually carrying out the calculations. Consider an asymmetric molecule in the shape of a spiral, as shown in Fig. 33\u20135. Molecules need not actually be shaped like a corkscrew in order to exhibit optical activity, but this is a simple shape which we shall take as a typical example of those that do not have reflection symmetry. When a light beam linearly polarized along the y -direction falls on this molecule, the electric field will drive charges up and down the helix, thereby generating a current in the y -direction and radiating an electric field E y polarized in the y -direction. However, if the electrons are constrained to move along the spiral, they must also move in the x -direction as they are driven up and down. When a current is flowing up the spiral, it is also flowing into the paper at z= z 1 and out of the paper at z= z 1 +A , if A is the diameter of our molecular spiral. One might suppose that the current in the x -direction would produce no net radiation, since the currents are in opposite directions on opposite sides of the spiral. However, if we consider the x -components of the electric field arriving at z= z 2 , we see that the field radiated by the current at z= z 1 +A and the field radiated from z= z 1 arrive at z 2 separated in time by the amount A/c , and thus separated in phase by \u03c0+\u03c9A/c . Since the phase difference is not exactly \u03c0 , the two fields do not cancel exactly, and we are left with a small x -component in the electric field generated by the motion of the electrons in the molecule, whereas the driving electric field had only a y -component. This small x -component, added to the large y -component, produces a resultant field that is tilted slightly with respect to the y -axis, the original direction of polarization. As the light moves through the material, the direction of polarization rotates about the beam axis. By drawing a few examples and considering the currents that will be set in motion by an incident electric field, one can convince himself that the existence of optical activity and the sign of the rotation are independent of the orientation of the molecules. Corn syrup is a common substance which possesses optical activity. The phenomenon is easily demonstrated with a polaroid sheet to produce a linearly polarized beam, a transmission cell containing corn syrup, and a second polaroid sheet to detect the rotation of the direction of polarization as the light passes through the corn syrup. Let us now consider quantitatively the reflection coefficient as a function of angle. Figure 33\u20136(a) shows a beam of light striking a glass surface, where it is partly reflected and partly refracted into the glass. Let us suppose that the incident beam, of unit amplitude, is linearly polarized normal to the plane of the paper. We will call the amplitude of the reflected wave b , and the amplitude of the refracted wave a . The refracted and reflected waves will, of course, be linearly polarized, and the electric field vectors of the incident, reflected, and refracted waves are all parallel to each other. Figure 33\u20136(b) shows the same situation, but now we suppose that the incident wave, of unit amplitude, is polarized in the plane of the paper. Now let us call the amplitude of the reflected and refracted wave B and A , respectively. We wish to calculate how strong the reflection is in the two situations illustrated in Fig. 33\u20136(a) and 33\u20136(b). We already know that when the angle between the reflected beam and refracted beam is a right angle, there will be no reflected wave in Fig. 33\u20136(b), but let us see if we cannot get a quantitative answer\u2014an exact formula for B and b as a function of the angle of incidence, i . The principle that we must understand is as follows. The currents that are generated in the glass produce two waves. First, they produce the reflected wave. Moreover, we know that if there were no currents generated in the glass, the incident wave would continue straight into the glass. Remember that all the sources in the world make the net field. The source of the incident light beam produces a field of unit amplitude, which would move into the glass along the dotted line in the figure. This field is not observed, and therefore the currents generated in the glass must produce a field of amplitude \u22121 , which moves along the dotted line. Using this fact, we will calculate the amplitude of the refracted waves, a and A . In Fig. 33\u20136(a) we see that the field of amplitude b is radiated by the motion of charges inside the glass which are responding to a field a inside the glass, and that therefore b is proportional to a . We might suppose that since our two figures are exactly the same, except for the direction of polarization, the ratio B/A would be the same as the ratio b/a . This is not quite true, however, because in Fig. 33\u20136(b) the polarization directions are not all parallel to each other, as they are in Fig. 33\u20136(a). It is only the component of the electric field in the glass which is perpendicular to B , Acos(i+r) , which is effective in producing B . The correct expression for the proportionality is then b a = B Acos(i+r) . (33.1) Now we use a trick. We know that in both (a) and (b) of Fig. 33\u20136 the electric field in the glass must produce oscillations of the charges, which generate a field of amplitude \u22121 , polarized parallel to the incident beam, and moving in the direction of the dotted line. But we see from part (b) of the figure that only the component of the electric field in the glass that is normal to the dashed line has the right polarization to produce this field, whereas in Fig. 33\u20136(a) the full amplitude a is effective, since the polarization of wave a is parallel to the polarization of the wave of amplitude \u22121 . Therefore we can write Acos(i\u2212r) a = \u22121 \u22121 , (33.2) since the two amplitudes on the left side of Eq. (33.2) each produce the wave of amplitude \u22121 . Dividing Eq. (33.1) by Eq. (33.2), we obtain B b = cos(i+r) cos(i\u2212r) , (33.3) a result which we can check against what we already know. If we set (i+r)= 90 \u2218 , Eq. (33.3) gives B=0 , as Brewster says it should be, so our results so far are at least not obviously wrong. We have assumed unit amplitudes for the incident waves, so that |B | 2 / 1 2 is the reflection coefficient for waves polarized in the plane of incidence, and |b | 2 / 1 2 is the reflection coefficient for waves polarized normal to the plane of incidence. The ratio of these two reflection coefficients is determined by Eq. (33.3). Now we perform a miracle, and compute not just the ratio, but each coefficient |B | 2 and |b | 2 individually! We know from the conservation of energy that the energy in the refracted wave must be equal to the incident energy minus the energy in the reflected wave, 1\u2212|B | 2 in one case, 1\u2212|b | 2 in the other. Furthermore, the energy which passes into the glass in Fig. 33\u20136(b) is to the energy which passes into the glass in Fig. 33\u20136(a) as the ratio of the squares of the refracted amplitudes, |A | 2 /|a | 2 . One might ask whether we really know how to compute the energy inside the glass, because, after all, there are energies of motion of the atoms in addition to the energy in the electric field. But it is obvious that all of the various contributions to the total energy will be proportional to the square of the amplitude of the electric field. Therefore we can write 1\u2212|B | 2 1\u2212|b | 2 = |A | 2 |a | 2 . (33.4) We now substitute Eq. (33.2) to eliminate A/a from the expression above, and express B in terms of b by means of Eq. (33.3): 1\u2212|b | 2 cos 2 (i+r) cos 2 (i\u2212r) 1\u2212|b | 2 = 1 cos 2 (i\u2212r) . (33.5) This equation contains only one unknown amplitude, b . Solving for |b | 2 , we obtain |b | 2 = sin 2 (i\u2212r) sin 2 (i+r) (33.6) and, with the aid of (33.3), |B | 2 = tan 2 (i\u2212r) tan 2 (i+r) . (33.7) So we have found the reflection coefficient |b | 2 for an incident wave polarized perpendicular to the plane of incidence, and also the reflection coefficient |B | 2 for an incident wave polarized in the plane of incidence! It is possible to go on with arguments of this nature and deduce that b is real. To prove this, one must consider a case where light is coming from both sides of the glass surface at the same time, a situation not easy to arrange experimentally, but fun to analyze theoretically. If we analyze this general case, we can prove that b must be real, and therefore, in fact, that b=\u00b1sin(i\u2212r)/sin(i+r) . It is even possible to determine the sign by considering the case of a very, very thin layer in which there is reflection from the front and from the back surfaces, and calculating how much light is reflected. We know how much light should be reflected by a thin layer, because we know how much current is generated, and we have even worked out the fields produced by such currents. One can show by these arguments that b=\u2212 sin(i\u2212r) sin(i+r) ,B=\u2212 tan(i\u2212r) tan(i+r) . (33.8) These expressions for the reflection coefficients as a function of the angles of incidence and refraction are called Fresnel\u2019s reflection formulas. If we consider the limit as the angles i and r go to zero, we find, for the case of normal incidence, that B 2 \u2248 b 2 \u2248(i\u2212r ) 2 /(i+r ) 2 for both polarizations, since the sines are practically equal to the angles, as are also the tangents. But we know that sini/sinr=n , and when the angles are small, i/r\u2248n . It is thus easy to show that the coefficient of reflection for normal incidence is B 2 = b 2 = (n\u22121 ) 2 (n+1 ) 2 . 2 It is interesting to find out how much light is reflected at normal incidence from the surface of water, for example. For water, n is 4/3 , so that the reflection coefficient is (1/7 ) 2 \u22482% . At normal incidence, only two percent of the light is reflected from the surface of water. The last polarization effect we shall consider was actually one of the first to be discovered: anomalous refraction. Sailors visiting Iceland brought back to Europe crystals of Iceland spar (CaCO 3 ) which had the amusing property of making anything seen through the crystal appear doubled, i.e., as two images. This came to the attention of Huygens, and played an important role in the discovery of polarization. As is often the case, the phenomena which are discovered first are the hardest, ultimately, to explain. It is only after we understand a physical concept thoroughly that we can carefully select those phenomena which most clearly and simply demonstrate the concept. Anomalous refraction is a particular case of the same birefringence that we considered earlier. Anomalous refraction comes about when the optic axis, the long axis of our asymmetric molecules, is not parallel to the surface of the crystal. In Fig. 33\u20137 are drawn two pieces of birefringent material, with the optic axis as shown. In part (a) of the figure, the incident beam falling on the material is linearly polarized in a direction perpendicular to the optic axis of the material. When this beam strikes the surface of the material, each point on the surface acts as a source of a wave which travels into the crystal with velocity v \u22a5 , the velocity of light in the crystal when the plane of polarization is normal to the optic axis. The wavefront is just the envelope or locus of all these little spherical waves, and this wavefront moves straight through the crystal and out the other side. This is just the ordinary behavior we would expect, and this ray is called the ordinary ray. In part (b) of the figure the linearly polarized light falling on the crystal has its direction of polarization turned through 90 \u2218 , so that the optic axis lies in the plane of polarization. When we now consider the little waves originating at any point on the surface of the crystal, we see that they do not spread out as spherical waves. Light travelling along the optic axis travels with velocity v \u22a5 because the polarization is perpendicular to the optic axis, whereas the light travelling perpendicular to the optic axis travels with velocity v \u2225 because the polarization is parallel to the optic axis. In a birefringent material v \u2225 \u2260 v \u22a5 , and in the figure v \u2225 < v \u22a5 . A more complete analysis will show that the waves spread out on the surface of an ellipsoid, with the optic axis as major axis of the ellipsoid. The envelope of all these elliptical waves is the wavefront which proceeds through the crystal in the direction shown. Again, at the back surface the beam will be deflected just as it was at the front surface, so that the light emerges parallel to the incident beam, but displaced from it. Clearly, this beam does not follow Snell\u2019s law, but goes in an extraordinary direction. It is therefore called the extraordinary ray. When an unpolarized beam strikes an anomalously refracting crystal, it is separated into an ordinary ray, which travels straight through in the normal manner, and an extraordinary ray which is displaced as it passes through the crystal. These two emergent rays are linearly polarized at right angles to each other. That this is true can be readily demonstrated with a sheet of polaroid to analyze the polarization of the emergent rays. We can also demonstrate that our interpretation of this phenomenon is correct by sending linearly polarized light into the crystal. By properly orienting the direction of polarization of the incident beam, we can make this light go straight through without splitting, or we can make it go through without splitting but with a displacement. We have represented all the various polarization cases in Figs. 33\u20131 and 33\u20132 as superpositions of two special polarization cases, namely x and y in various amounts and phases. Other pairs could equally well have been used. Polarization along any two perpendicular axes x \u2032 , y \u2032 inclined to x and y would serve as well [for example, any polarization can be made up of superpositions of cases (a) and (e) of Fig. 33\u20132]. It is interesting, however, that this idea can be extended to other cases also. For example, any linear polarization can be made up by superposing suitable amounts at suitable phases of right and left circular polarizations [cases (c) and (g) of Fig. 33\u20132], since two equal vectors rotating in opposite directions add to give a single vector oscillating in a straight line (Fig. 33\u20138). If the phase of one is shifted relative to the other, the line is inclined. Thus all the pictures of Fig. 33\u20131 could be labeled \u201cthe superposition of equal amounts of right and left circularly polarized light at various relative phases.\u201d As the left slips behind the right in phase, the direction of the linear polarization changes. Therefore optically active materials are, in a sense, birefringent. Their properties can be described by saying that they have different indexes for right- and left-hand circularly polarized light. Superposition of right and left circularly polarized light of different intensities produces elliptically polarized light. Circularly polarized light has another interesting property\u2014it carries angular momentum (about the direction of propagation). To illustrate this, suppose that such light falls on an atom represented by a harmonic oscillator that can be displaced equally well in any direction in the plane xy . Then the x -displacement of the electron will respond to the E x component of the field, while the y -component responds, equally, to the equal E y component of the field but 90 \u2218 behind in phase. That is, the responding electron goes around in a circle, with angular velocity \u03c9 , in response to the rotating electric field of the light (Fig. 33\u20139). Depending on the damping characteristics of the response of the oscillator, the direction of the displacement a of the electron, and the direction of the force q e E on it need not be the same but they rotate around together. The E may have a component at right angles to a , so work is done on the system and a torque \u03c4 is exerted. The work done per second is \u03c4\u03c9 . Over a period of time T the energy absorbed is \u03c4\u03c9T , while \u03c4T is the angular momentum delivered to the matter absorbing the energy. We see therefore that a beam of right circularly polarized light containing a total energy E carries an angular momentum (with vector directed along the direction of propagation) E/\u03c9 . For when this beam is absorbed that angular momentum is delivered to the absorber. Left-hand circular light carries angular momentum of the opposite sign, \u2212E/\u03c9 ."
    },
    {
        "input": "Angular Momentum",
        "output": "In the last chapter we developed the idea of the conservation of angular momentum in quantum mechanics, and showed how it might be used to predict the angular distribution of the proton from the disintegration of the \u039b -particle. We want now to give you a number of other, similar, illustrations of the consequences of momentum conservation in atomic systems. Our first example is the radiation of light from an atom. The conservation of angular momentum (among other things) will determine the polarization and angular distribution of the emitted photons. Suppose we have an atom which is in an excited state of definite angular momentum\u2014say with a spin of one\u2014and it makes a transition to a state of angular momentum zero at a lower energy, emitting a photon. The problem is to figure out the angular distribution and polarization of the photons. (This problem is almost exactly the same as the \u039b0 disintegration, except that we have spin-one instead of spin one-half particles.) Since the upper state of the atom is spin one, there are three possibilities for its z -component of angular momentum. The value of m could be +1 , or 0 , or \u22121 . We will take m=+1 for our example. Once you see how it goes, you can work out the other cases. We suppose that the atom is sitting with its angular momentum along the +z -axis\u2014as in Fig. 18\u20131(a)\u2014and ask with what amplitude it will emit right circularly polarized light upward along the z -axis, so that the atom ends up with zero angular momentum\u2014as shown in part (b) of the figure. Well, we don\u2019t know the answer to that. But we do know that right circularly polarized light has one unit of angular momentum about its direction of propagation. So after the photon is emitted, the situation would have to be as shown in Fig. 18\u20131(b)\u2014the atom is left with zero angular momentum about the z -axis, since we have assumed an atom whose lower state is spin zero. We will let a stand for the amplitude for such an event. More precisely, we let a be the amplitude to emit a photon into a certain small solid angle \u0394\u03a9 , centered on the z -axis, during a time dt . Notice that the amplitude to emit a LHC photon in the same direction is zero. The net angular momentum about the z -axis would be \u22121 for such a photon and zero for the atom for a total of \u22121 , which would not conserve angular momentum. Similarly, if the spin of the atom is initially \u201cdown\u201d (\u22121 along the z -axis), it can emit only a LHC polarized photon in the direction of the +z -axis, as shown in Fig. 18\u20132. We will let b stand for the amplitude for this event\u2014meaning again the amplitude that the photon goes into a certain solid angle \u0394\u03a9 . On the other hand, if the atom is in the m=0 state, it cannot emit a photon in the +z -direction at all, because a photon can have only the angular momentum +1 or \u22121 along its direction of motion. Next, we can show that b is related to a . Suppose we perform an inversion of the situation in Fig. 18\u20131, which means that we should imagine what the system would look like if we were to move each part of the system to an equivalent point on the opposite side of the origin. This does not mean that we should reflect the angular momentum vectors, because they are artificial. We should, rather, invert the actual character of the motion that would correspond to such an angular momentum. In Fig. 18\u20133(a) and (b) we show what the process of Fig. 18\u20131 looks like before and after an inversion with respect to the center of the atom. Notice that the sense of rotation of the atom is unchanged.1 In the inverted system of Fig. 18\u20133(b) we have an atom with m=+1 emitting a LHC photon downward. If we now rotate the system of Fig. 18\u20133(b) by 180\u2218 about the x - or y -axis, it becomes identical to Fig. 18\u20132. The combination of the inversion and rotation turns the second process into the first. Using Table 17\u20132, we see that a rotation of 180\u2218 about the y -axis just throws an m=\u22121 state into an m=+1 state, so the amplitude b must be equal to the amplitude a except for a possible sign change due to the inversion. The sign change in the inversion will depend on the parities of the initial and final state of the atom. In atomic processes, parity is conserved, so the parity of the whole system must be the same before and after the photon emission. What happens will depend on whether the parities of the initial and final states of the atom are even or odd\u2014the angular distribution of the radiation will be different for different cases. We will take the common case of odd parity for the initial state and even parity for the final state; it will give what is called \u201celectric dipole radiation.\u201d (If the initial and final states have the same parity we say there is \u201cmagnetic dipole radiation,\u201d which has the character of the radiation from an oscillating current in a loop.) If the parity of the initial state is odd, its amplitude reverses its sign in the inversion which takes the system from (a) to (b) of Fig. 18\u20133. The final state of the atom has even parity, so its amplitude doesn\u2019t change sign. If the reaction is going to conserve parity, the amplitude b must be equal to a in magnitude but of the opposite sign. We conclude that if the amplitude is a that an m=+1 state will emit a photon upward, then for the assumed parities of the initial and final states the amplitude that an m=\u22121 state will emit a LHC photon upward is \u2212a .2 We have all we need to know to find the amplitude for a photon to be emitted at any angle \u03b8 with respect to the z -axis. Suppose we have an atom originally polarized with m=+1 . We can resolve this state into +1 , 0 , and \u22121 states with respect to a new z\u2032 -axis in the direction of the photon emission. The amplitudes for these three states are just the ones given in the lower half of Table 17\u20132. The amplitude that a RHC photon is emitted in the direction \u03b8 is then a times the amplitude to have m=+1 in that direction, namely, a\u27e8+|Ry(\u03b8)|+\u27e9= a 2 (1+cos\u03b8). The amplitude that a LHC photon is emitted in the same direction is \u2212a times the amplitude to have m=\u22121 in the new direction. Using Table 17\u20132, it is \u2212a\u27e8\u2212|Ry(\u03b8)|+\u27e9=\u2212 a 2 (1\u2212cos\u03b8). If you are interested in other polarizations you can find out the amplitude for them from the superposition of these two amplitudes. To get the intensity of any component as a function of angle, you must, of course, take the absolute square of the amplitudes. Let\u2019s use these results to solve a somewhat more complicated problem\u2014but also one which is somewhat more real. We suppose that the same atoms are sitting in their ground state (j=0 ), and scatter an incoming beam of light. Let\u2019s say that the light is going initially in the +z -direction, so that we have photons coming up to the atom from the \u2212z -direction, as shown in Fig. 18\u20134(a). We can consider the scattering of light as a two-step process: The photon is absorbed, and then is re-emitted. If we start with a RHC photon as in Fig. 18\u20134(a), and angular momentum is conserved, the atom will be in an m=+1 state after the absorption\u2014as shown in Fig. 18\u20134(b). We call the amplitude for this process c . The atom can then emit a RHC photon in the direction \u03b8 \u2014as in Fig. 18\u20134(c). The total amplitude that a RHC photon is scattered in the direction \u03b8 is just c times (18.1). Let\u2019s call this scattering amplitude \u27e8R\u2032|S|R\u27e9 ; we have \u27e8R\u2032|S|R\u27e9= ac 2 (1+cos\u03b8). There is also an amplitude that a RHC photon will be absorbed and that a LHC photon will be emitted. The product of the two amplitudes is the amplitude \u27e8L\u2032|S|R\u27e9 that a RHC photon is scattered as a LHC photon. Using (18.2), we have \u27e8L\u2032|S|R\u27e9=\u2212 ac 2 (1\u2212cos\u03b8). Now let\u2019s ask about what happens if a LHC photon comes in. When it is absorbed, the atom will go into an m=\u22121 state. By the same kind of arguments we used in the preceding section, we can show that this amplitude must be \u2212c . The amplitude that an atom in the m=\u22121 state will emit a RHC photon at the angle \u03b8 is a times the amplitude \u27e8+|Ry(\u03b8)|\u2212\u27e9 , which is 1 2 (1\u2212cos\u03b8) . So we have \u27e8R\u2032|S|L\u27e9=\u2212 ac 2 (1\u2212cos\u03b8). Finally, the amplitude for a LHC photon to be scattered as a LHC photon is \u27e8L\u2032|S|L\u27e9= ac 2 (1+cos\u03b8). (There are two minus signs which cancel.) If we make a measurement of the scattered intensity for any given combination of circular polarizations it will be proportional to the square of one of our four amplitudes. For instance, with an incoming beam of RHC light the intensity of the RHC light in the scattered radiation will vary as (1+cos\u03b8)2 . That\u2019s all very well, but suppose we start out with linearly polarized light. What then? If we have x -polarized light, it can be represented as a superposition of RHC and LHC light. We write (see Section 11-4) |x\u27e9= 1 \u221a 2 (|R\u27e9+|L\u27e9). Or, if we have y -polarized light, we would have |y\u27e9=\u2212 i \u221a 2 (|R\u27e9\u2212|L\u27e9). Now what do you want to know? Do you want the amplitude that an x -polarized photon will scatter into a RHC photon at the angle \u03b8 ? You can get it by the usual rule for combining amplitudes. First, multiply (18.7) by \u27e8R\u2032|S to get \u27e8R\u2032|S|x\u27e9= 1 \u221a 2 (\u27e8R\u2032|S|R\u27e9+\u27e8R\u2032|S|L\u27e9), and then use (18.3) and (18.5) for the two amplitudes. You get \u27e8R\u2032|S|x\u27e9= ac \u221a 2 cos\u03b8. If you wanted the amplitude that an x -photon would scatter into a LHC photon, you would get \u27e8L\u2032|S|x\u27e9= ac \u221a 2 cos\u03b8. Finally, suppose you wanted to know the amplitude that an x -polarized photon will scatter while keeping its x -polarization. What you want is \u27e8 x \u2032 |S|x\u27e9 . This can be written as \u27e8 x \u2032 |S|x\u27e9= + \u27e8 x \u2032 | R \u2032 \u27e9\u27e8 R \u2032 |S|x\u27e9 \u27e8 x \u2032 | L \u2032 \u27e9\u27e8 L \u2032 |S|x\u27e9. (18.12) If you then use the relations | R \u2032 \u27e9 | L \u2032 \u27e9 = 1 2 \u2013 \u221a (| x \u2032 \u27e9+i| y \u2032 \u27e9), = 1 2 \u2013 \u221a (| x \u2032 \u27e9\u2212i| y \u2032 \u27e9) (18.13) (18.14) it follows that \u27e8 x \u2032 | R \u2032 \u27e9 \u27e8 x \u2032 | L \u2032 \u27e9 = 1 2 \u2013 \u221a , = 1 2 \u2013 \u221a . (18.15) (18.16) So you get that \u27e8 x \u2032 |S|x\u27e9=accos\u03b8. (18.17) The answer is that a beam of x -polarized light will be scattered at the direction \u03b8 (in the xz -plane) with an intensity proportional to cos 2 \u03b8 . If you ask about y -polarized light, you find that \u27e8 y \u2032 |S|x\u27e9=0. (18.18) So the scattered light is completely polarized in the x -direction. Now we notice something interesting. The results (18.17) and (18.18) correspond exactly to the classical theory of light scattering we gave in Vol. I, Section 32-5, where we imagined that the electron was bound to the atom by a linear restoring force\u2014so that it acted like a classical oscillator. Perhaps you are thinking: \u201cIt\u2019s so much easier in the classical theory; if it gives the right answer why bother with the quantum theory?\u201d For one thing, we have considered so far only the special\u2014though common\u2014case of an atom with a j=1 excited state and a j=0 ground state. If the excited state had spin two, you would get a different result. Also, there is no reason why the model of an electron attached to a spring and driven by an oscillating electric field should work for a single photon. But we have found that it does in fact work, and that the polarization and intensities come out right. So in a certain sense we are bringing the whole course around to the real truth. Whereas we have, in Vol. I, done the theory of the index of refraction, and of light scattering, by the classical theory, we have now shown that the quantum theory gives the same result for the most common case. In effect we have now done the polarization of sky light, for instance, by quantum mechanical arguments, which is the only truly legitimate way. It should be, of course, that all the classical theories which work are supported ultimately by legitimate quantum arguments. Naturally, those things which we have spent a great deal of time in explaining to you were selected from just those parts of classical physics which still maintain validity in quantum mechanics. You\u2019ll notice that we did not discuss in great detail any model of the atom which has electrons going around in orbits. That\u2019s because such a model doesn\u2019t give results which agree with the quantum mechanics. But the electron on a spring\u2014which is not, in a sense, at all the way an atom \u201clooks\u201d\u2014does work, and so we used that model for the theory of the index of refraction. We would like next to take an example which is very pretty. It is quite interesting and, although somewhat complicated, we hope not too much so. Our example is the system called positronium, which is an \u201catom\u201d made up of an electron and a positron\u2014a bound state of an e + and an e \u2212 . It is like a hydrogen atom, except that a positron replaces the proton. This object has\u2014like the hydrogen atom\u2014many states. Also like the hydrogen, the ground state is split into a \u201chyperfine structure\u201d by the interaction of the magnetic moments. The spins of the electron and positron are each one-half, and they can be either parallel or antiparallel to any given axis. (In the ground state there is no other angular momentum due to orbital motion.) So there are four states: three are the substates of a spin-one system, all with the same energy; and one is a state of spin zero with a different energy. The energy splitting is, however, much larger than the 1420 megacycles of hydrogen because the positron magnetic moment is so much stronger\u2014 1000 times stronger\u2014than the proton moment. The most important difference, however, is that positronium cannot last forever. The positron is the antiparticle of the electron; they can annihilate each other. The two particles disappear completely\u2014converting their rest energy into radiation, which appears as \u03b3 -rays (photons). In the disintegration, two particles with a finite rest mass go into two or more objects which have zero rest mass.3 We begin by analyzing the disintegration of the spin-zero state of the positronium. It disintegrates into two \u03b3 -rays with a lifetime of about 10 \u221210 second. Initially, we have a positron and an electron close together and with spins antiparallel, making the positronium system. After the disintegration there are two photons going out with equal and opposite momenta (Fig. 18\u20135). The momenta must be equal and opposite, because the total momentum after the disintegration must be zero, as it was before, if we are taking the case of annihilation at rest. If the positronium is not at rest, we can ride with it, solve the problem, and then transform everything back to the lab system. (See, we can do anything now; we have all the tools.) First, we note that the angular distribution is not very interesting. Since the initial state has spin zero, it has no special axis\u2014it is symmetric under all rotations. The final state must then also be symmetric under all rotations. That means that all angles for the disintegration are equally likely\u2014the amplitude is the same for a photon to go in any direction. Of course, once we find one of the photons in some direction the other must be opposite. The only remaining question, which we now want to look at, is about the polarization of the photons. Let\u2019s call the directions of motion of the two photons the plus and minus z -axes. We can use any representations we want for the polarization states of the photons; we will choose for our description right and left circular polarization\u2014always with respect to the directions of motion.4 Right away, we can see that if the photon going upward is RHC, then angular momentum will be conserved if the downward going photon is also RHC. Each will carry +1 unit of angular momentum with respect to its momentum direction, which means plus and minus one unit about the z -axis. The total will be zero, and the angular momentum after the disintegration will be the same as before. See Fig. 18\u20136. The same arguments show that if the upward going photon is RHC, the downward cannot be LHC. Then the final state would have two units of angular momentum. This is not permitted if the initial state has spin zero. Note that such a final state is also not possible for the other positronium ground state of spin one, because it can have a maximum of one unit of angular momentum in any direction. Now we want to show that two-photon annihilation is not possible at all from the spin-one state. You might think that if we took the j=1 , m=0 state\u2014which has zero angular momentum about the z -axis\u2014it should be like the spin-zero state, and could disintegrate into two RHC photons. Certainly, the disintegration sketched in Fig. 18\u20137(a) conserves angular momentum about the z -axis. But now look what happens if we rotate this system around the y -axis by 180 \u2218 ; we get the picture shown in Fig. 18\u20137(b). It is exactly the same as in part (a) of the figure. All we have done is interchange the two photons. Now photons are Bose particles; if we interchange them, the amplitude has the same sign, so the amplitude for the disintegration in part (b) must be the same as in part (a). But we have assumed that the initial object is spin one. And when we rotate a spin-one object in a state with m=0 by 180 \u2218 about the y -axis, its amplitudes change sign (see Table 17\u20132 for \u03b8=\u03c0 ). So the amplitudes for (a) and (b) in Fig. 18\u20137 should have opposite signs; the spin-one state cannot disintegrate into two photons. When positronium is formed you would expect it to end up in the spin-zero state 1/4 of the time and in the spin-one state (with m=\u22121 , 0 , or +1 ) 3/4 of the time. So 1/4 of the time you would get two-photon annihilations. The other 3/4 of the time there can be no two-photon annihilations. There is still an annihilation, but it has to go with three photons. It is harder for it to do that and the lifetime is 1000 times longer\u2014about 10 \u22127 second. This is what is observed experimentally. We will not go into any more of the details of the spin-one annihilation. So far we have that if we only worry about angular momentum, the spin-zero state of the positronium can go into two RHC photons. There is also another possibility: it can go into two LHC photons as shown in Fig. 18\u20138. The next question is, what is the relation between the amplitudes for these two possible decay modes? We can find out from the conservation of parity. To do that, however, we need to know the parity of the positronium. Now theoretical physicists have shown in a way that is not easy to explain that the parity of the electron and the positron\u2014its antiparticle\u2014must be opposite, so that the spin-zero ground state of positronium must be odd. We will just assume that it is odd, and since we will get agreement with experiment, we can take that as sufficient proof. Let\u2019s see then what happens if we make an inversion of the process in Fig. 18\u20136. When we do that, the two photons reverse directions and polarizations. The inverted picture looks just like Fig. 18\u20138. Assuming that the parity of the positronium is odd, the amplitudes for the two processes in Figs. 18\u20136 and 18\u20138 must have the opposite sign. Let\u2019s let | R 1 R 2 \u27e9 stand for the final state of Fig. 18\u20136 in which both photons are RHC, and let | L 1 L 2 \u27e9 stand for the final state of Fig. 18\u20138, in which both photons are LHC. The true final state\u2014let\u2019s call it |F\u27e9 \u2014must be |F\u27e9=| R 1 R 2 \u27e9\u2212| L 1 L 2 \u27e9. (18.19) Then an inversion changes the R \u2019s into L \u2019s and gives the state P|F\u27e9=| L 1 L 2 \u27e9\u2212| R 1 R 2 \u27e9=\u2212|F\u27e9, (18.20) which is the negative of (18.19). So the final state |F\u27e9 has negative parity, which is the same as the initial spin-zero state of the positronium. This is the only final state that conserves both angular momentum and parity. There is some amplitude that the disintegration into this state will occur, which we don\u2019t need to worry about now, however, since we are only interested in questions about the polarization. What does the final state of (18.19) mean physically? One thing it means is the following: If we observe the two photons in two detectors which can be set to count separately the RHC or LHC photons, we will always see two RHC photons together, or two LHC photons together. That is, if you stand on one side of the positronium and someone else stands on the opposite side, you can measure the polarization and tell the other guy what polarization he will get. You have a 50 - 50 chance of catching a RHC photon or a LHC photon; whichever one you get, you can predict that he will get the same. Since there is a 50 - 50 chance for RHC or LHC polarization, it sounds as though it might be like linear polarization. Let\u2019s ask what happens if we observe the photon in counters that accept only linearly polarized light. For \u03b3 -rays it is not as easy to measure the polarization as it is for light; there is no polarizer which works well for such short wavelengths. But let\u2019s imagine that there is, to make the discussion easier. Suppose that you have a counter that only accepts light with x -polarization, and that there is a guy on the other side that also looks for linear polarized light with, say, y -polarization. What is the chance you will pick up the two photons from an annihilation? What we need to ask is the amplitude that |F\u27e9 will be in the state | x 1 y 2 \u27e9 . In other words, we want the amplitude \u27e8 x 1 y 2 |F\u27e9, \u27e8 | \u27e9 which is, of course, just \u27e8 x 1 y 2 | R 1 R 2 \u27e9\u2212\u27e8 x 1 y 2 | L 1 L 2 \u27e9. (18.21) Now although we are working with two-particle amplitudes for the two photons, we can handle them just as we did the single particle amplitudes, since each particle acts independently of the other. That means that the amplitude \u27e8 x 1 y 2 | R 1 R 2 \u27e9 is just the product of the two independent amplitudes \u27e8 x 1 | R 1 \u27e9 and \u27e8 y 2 | R 2 \u27e9 . Using Table 17\u20133, these two amplitudes are 1/ 2 \u2013 \u221a and i/ 2 \u2013 \u221a \u2014so \u27e8 x 1 y 2 | R 1 R 2 \u27e9=+ i 2 . i Similarly, we find that \u27e8 x 1 y 2 | L 1 L 2 \u27e9=\u2212 i 2 . i Subtracting these two amplitudes according to (18.21), we get that \u27e8 x 1 y 2 |F\u27e9=+i. (18.22) So there is a unit probability5 that if you get a photon in your x -polarized detector, the other guy will get a photon in his y -polarized detector. Now suppose that the other guy sets his counter for x -polarization the same as yours. He would never get a count when you got one. If you work it through, you will find that \u27e8 x 1 x 2 |F\u27e9=0. (18.23) It will, naturally, also work out that if you set your counter for y -polarization he will get coincident counts only if he is set for x -polarization. Now this all leads to an interesting situation. Suppose you were to set up something like a piece of calcite which separated the photons into x -polarized and y -polarized beams, and put a counter in each beam. Let\u2019s call one the x -counter and the other the y -counter. If the guy on the other side does the same thing, you can always tell him which beam his photon is going to go into. Whenever you and he get simultaneous counts, you can see which of your detectors caught the photon and then tell him which of his counters had a photon. Let\u2019s say that in a certain disintegration you find that a photon went into your x -counter; you can tell him that he must have had a count in his y -counter. Now many people who learn quantum mechanics in the usual (old-fashioned) way find this disturbing. They would like to think that once the photons are emitted it goes along as a wave with a definite character. They would think that since \u201cany given photon\u201d has some \u201camplitude\u201d to be x -polarized or to be y -polarized, there should be some chance of picking it up in either the x - or y -counter and that this chance shouldn\u2019t depend on what some other person finds out about a completely different photon. They argue that \u201csomeone else making a measurement shouldn\u2019t be able to change the probability that I will find something.\u201d Our quantum mechanics says, however, that by making a measurement on photon number one, you can predict precisely what the polarization of photon number two is going to be when it is detected. This point was never accepted by Einstein, and he worried about it a great deal\u2014it became known as the \u201cEinstein-Podolsky-Rosen paradox.\u201d But when the situation is described as we have done it here, there doesn\u2019t seem to be any paradox at all; it comes out quite naturally that what is measured in one place is correlated with what is measured somewhere else. The argument that the result is paradoxical runs something like this: If you have a counter which tells you whether your photon is RHC or LHC, you can predict exactly what kind of a photon (RHC or LHC) he will find. The photons he receives must, therefore, each be purely RHC or purely LHC, some of one kind and some of the other. Surely you cannot alter the physical nature of his photons by changing the kind of observation you make on your photons. No matter what measurements you make on yours, his must still be either RHC or LHC. Now suppose he changes his apparatus to split his photons into two linearly polarized beams with a piece of calcite so that all of his photons go either into an x -polarized beam or into a y -polarized beam. There is absolutely no way, according to quantum mechanics, to tell into which beam any particular RHC photon will go. There is a 50% probability it will go into the x -beam and a 50% probability it will go into the y -beam. And the same goes for a LHC photon. Since each photon is RHC or LHC\u2014according to (2) and (3)\u2014each one must have a 50-50 chance of going into the x -beam or the y -beam and there is no way to predict which way it will go. Yet the theory predicts that if you see your photon go through an x -polarizer you can predict with certainty that his photon will go into his y -polarized beam. This is in contradiction to (5) so there is a paradox. Nature apparently doesn\u2019t see the \u201cparadox,\u201d however, because experiment shows that the prediction in (6) is, in fact, true. We have already discussed the key to this \u201cparadox\u201d in our very first lecture on quantum mechanical behavior in Chapter 37, Vol. I.6 In the argument above, steps (1), (2), (4), and (6) are all correct, but (3), and its consequence (5), are wrong; they are not a true description of nature. Argument (3) says that by your measurement (seeing a RHC or a LHC photon) you can determine which of two alternative events occurs for him (seeing a RHC or a LHC photon), and that even if you do not make your measurement you can still say that his event will occur either by one alternative or the other. But it was precisely the point of Chapter 37, Vol. I, to point out right at the beginning that this is not so in Nature. Her way requires a description in terms of interfering amplitudes, one amplitude for each alternative. A measurement of which alternative actually occurs destroys the interference, but if a measurement is not made you cannot still say that \u201cone alternative or the other is still occurring.\u201d If you could determine for each one of your photons whether it was RHC or LHC, and also whether it was x -polarized (all for the same photon) there would indeed be a paradox. But you cannot do that\u2014it is an example of the uncertainty principle. Do you still think there is a \u201cparadox\u201d? Make sure that it is, in fact, a paradox about the behavior of Nature, by setting up an imaginary experiment for which the theory of quantum mechanics would predict inconsistent results via two different arguments. Otherwise the \u201cparadox\u201d is only a conflict between reality and your feeling of what reality \u201cought to be.\u201d Do you think that it is not a \u201cparadox,\u201d but that it is still very peculiar? On that we can all agree. It is what makes physics fascinating. By now you can see, we hope, how important the idea of the angular momentum is in understanding atomic processes. So far, we have considered only systems with spins\u2014or \u201ctotal angular momentum\u201d\u2014of zero, one-half, or one. There are, of course, atomic systems with higher angular momenta. For analyzing such systems we would need to have tables of rotation amplitudes like those in Section 17-6. That is, we would need the matrix of amplitudes for spin 3 2 , 2 , 5 2 , 3 , etc. Although we will not work out these tables in detail, we would like to show you how it is done, so that you can do it if you ever need to. As we have seen earlier, any system which has the spin or \u201ctotal angular momentum\u201d j can exist in any one of (2j+1) states for which the z -component of angular momentum can have any one of the discrete values in the sequence j , j\u22121 , j\u22122 , \u2026 , \u2212(j\u22121) , \u2212j (all in units of \u210f ). Calling the z -component of angular momentum of any particular state m\u210f , we can define a particular angular momentum state by giving the numerical values of the two \u201cangular momentum quantum numbers\u201d j and m . We can indicate such a state by the state vector |j,m\u27e9 . In the case of a spin one-half particle, the two states are then | 1 2 , 1 2 \u27e9 and | 1 2 ,\u2212 1 2 \u27e9 ; or for a spin-one system, the states would be written in this notation as |1,+1\u27e9 , |1,0\u27e9 , |1,\u22121\u27e9 . A spin-zero particle has, of course, only the one state |0,0\u27e9 . Now we want to know what happens when we project the general state |j,m\u27e9 into a representation with respect to a rotated set of axes. First, we know that j is a number which characterizes the system, so it doesn\u2019t change. If we rotate the axes, all we do is get a mixture of the various m -values for the same j . In general, there will be some amplitude that in the rotated frame the system will be in the state |j, m \u2032 \u27e9 , where m \u2032 gives the new z -component of angular momentum. So what we want are all the matrix elements \u27e8j, m \u2032 |R|j,m\u27e9 for various rotations. We already know what happens if we rotate by an angle \u03d5 about the z -axis. The new state is just the old one multiplied by e im\u03d5 \u2014it still has the same m -value. We can write this by R z (\u03d5)|j,m\u27e9= e im\u03d5 |j,m\u27e9. (18.24) Or, if you prefer, \u27e8j, m \u2032 | R z (\u03d5)|j,m\u27e9= \u03b4 m, m \u2032 e im\u03d5 (18.25) (where \u03b4 m, m \u2032 is 1 if m \u2032 =m , or zero otherwise). For a rotation about any other axis there will be a mixing of the various m -states. We could, of course, try to work out the matrix elements for an arbitrary rotation described by the Euler angles \u03b2 , \u03b1 , and \u03b3 . But it is easier to remember that the most general such rotation can be made up of the three rotations R z (\u03b3) , R y (\u03b1) , R z (\u03b2) ; so if we know the matrix elements for a rotation about the y -axis, we will have all we need. How can we find the rotation matrix for a rotation by the angle \u03b8 about the y -axis for a particle of spin j ? We can\u2019t tell you how to do it in a basic way (with what we have had). We did it for spin one-half by a complicated symmetry argument. We then did it for spin one by taking the special case of a spin-one system which was made up of two spin one-half particles. If you will go along with us and accept the fact that in the general case the answers depend only on the spin j , and are independent of how the inner guts of the object of spin j are put together, we can extend the spin-one argument to an arbitrary spin. We can, for example, cook up an artificial system of spin 3 2 out of three spin one-half objects. We can even avoid complications by imagining that they are all distinct particles\u2014like a proton, an electron, and a muon. By transforming each spin one-half object, we can see what happens to the whole system\u2014remembering that the three amplitudes are multiplied for the combined state. Let\u2019s see how it goes in this case. Suppose we take the three spin one-half objects all with spins \u201cup\u201d; we can indicate this state by |+++\u27e9 . If we look at this system in a frame rotated about the z -axis by the angle \u03d5 , each plus stays a plus, but gets multiplied by e i\u03d5/2 . We have three such factors, so R z (\u03d5)|+++\u27e9= e i(3\u03d5/2) |+++\u27e9. (18.26) Evidently the state |+++\u27e9 is just what we mean by the m=+ 3 2 state, or the state | 3 2 ,+ 3 2 \u27e9 . If we now rotate this system about the y -axis, each of the spin one-half objects will have some amplitude to be plus or to be minus, so the system will now be a mixture of the eight possible combinations |+++\u27e9 , |++\u2212\u27e9 , |+\u2212+\u27e9 , |\u2212++\u27e9 , |+\u2212\u2212\u27e9 , |\u2212+\u2212\u27e9 , |\u2212\u2212+\u27e9 , or |\u2212\u2212\u2212\u27e9 . It is clear, however, that these can be broken up into four sets, each set corresponding to a particular value of m . First, we have |+++\u27e9 , for which m= 3 2 . Then there are the three states |++\u2212\u27e9 , |+\u2212+\u27e9 , and |\u2212++\u27e9 \u2014each with two plusses and one minus. Since each spin one-half object has the same chance of coming out minus under the rotation, the amounts of each of these three combinations should be equal. So let\u2019s take the combination 1 3 \u2013 \u221a {|++\u2212\u27e9+|+\u2212+\u27e9+|\u2212++\u27e9} (18.27) with the factor 1/ 3 \u2013 \u221a put in to normalize the state. If we rotate this state about the z -axis, we get a factor e i\u03d5/2 for each plus, and e \u2212i\u03d5/2 for each minus. Each term in (18.27) is multiplied by e i\u03d5/2 , so there is the common factor e i\u03d5/2 . This state satisfies our idea of an m=+ 1 2 state; we can conclude that 1 3 \u2013 \u221a {|++\u2212\u27e9+|+\u2212+\u27e9+|\u2212++\u27e9} =| 3 2 ,+ 1 2 \u27e9. (18.28) Similarly, we can write 1 3 \u2013 \u221a {|+\u2212\u2212\u27e9+|\u2212+\u2212\u27e9+|\u2212\u2212+\u27e9} =| 3 2 ,\u2212 1 2 \u27e9, (18.29) which corresponds to a state with m=\u2212 1 2 . Notice that we take only the symmetric combinations\u2014we do not take any combinations with minus signs. They would correspond to states of the same m but a different j . (It\u2019s just like the spin-one case, where we found that (1/ 2 \u2013 \u221a ){|+\u2212\u27e9+|\u2212+\u27e9} was the state |1,0\u27e9 , but the state (1/ 2 \u2013 \u221a ){|+\u2212\u27e9\u2212|\u2212+\u27e9} was the state |0,0\u27e9 .) Finally, we would have that | 3 2 ,\u2212 3 2 \u27e9=|\u2212\u2212\u2212\u27e9. (18.30) We summarize our four states in Table 18\u20131. Now all we have to do is take each state and rotate it about the y -axis and see how much of the other states it gives\u2014using our known rotation matrix for the spin one-half particles. We can proceed in exactly the same way we did for the spin-one case in Section 12-6. (It just takes a little more algebra.) We will follow directly the ideas of Chapter 12, so we won\u2019t repeat all the explanations in detail. The states in the system S will be labelled | 3 2 ,+ 3 2 ,S\u27e9=|+++\u27e9 , | 3 2 ,+ 1 2 ,S\u27e9=(1/ 3 \u2013 \u221a ){|++\u2212\u27e9+|+\u2212+\u27e9+|\u2212++\u27e9} , and so on. The T -system will be one rotated about the y -axis of S by the angle \u03b8 . States in T will be labelled | 3 2 ,+ 3 2 ,T\u27e9 , | 3 2 ,+ 1 2 ,T\u27e9 , and so on. Of course, | 3 2 ,+ 3 2 ,T\u27e9 is the same as | + \u2032 + \u2032 + \u2032 \u27e9 , the primes referring always to the T -system. Similarly, | 3 2 ,+ 1 2 ,T\u27e9 will be equal to (1/ 3 \u2013 \u221a ){| + \u2032 + \u2032 \u2212 \u2032 \u27e9+| + \u2032 \u2212 \u2032 + \u2032 \u27e9+| \u2212 \u2032 + \u2032 + \u2032 \u27e9} , and so on. Each | + \u2032 \u27e9 state in the T -frame comes from both the |+\u27e9 and |\u2212\u27e9 states in S via the matrix elements of Table 12\u20134. When we have three spin one-half particles, Eq. (12.47) gets replaced by |+++\u27e9= a 3 | + \u2032 + \u2032 + \u2032 \u27e9 + a 2 b{| + \u2032 + \u2032 \u2212 \u2032 \u27e9+| + \u2032 \u2212 \u2032 + \u2032 \u27e9+| \u2212 \u2032 + \u2032 + \u2032 \u27e9} +a b 2 {| + \u2032 \u2212 \u2032 \u2212 \u2032 \u27e9+| \u2212 \u2032 + \u2032 \u2212 \u2032 \u27e9+| \u2212 \u2032 \u2212 \u2032 + \u2032 \u27e9} + b 3 | \u2212 \u2032 \u2212 \u2032 \u2212 \u2032 \u27e9. (18.31) Using the transformation of Table 12\u20134, we get instead of (12.48) the equation | 3 2 ,+ 3 2 ,S\u27e9 = a 3 | 3 2 ,+ 3 2 ,T\u27e9 + 3 \u2013 \u221a a 2 b| 3 2 ,+ 1 2 ,T\u27e9 + 3 \u2013 \u221a a b 2 | 3 2 ,\u2212 1 2 ,T\u27e9 + b 3 | 3 2 ,\u2212 3 2 ,T\u27e9. (18.32) This already gives us several of our matrix elements \u27e8jT|iS\u27e9 . To get the expression for | 3 2 ,+ 1 2 ,S\u27e9 we begin with the transformation of a state with two \u201c + \u201d and one \u201c \u2212 \u201d pieces. For instance, |++\u2212\u27e9 = a 2 c| + \u2032 + \u2032 + \u2032 \u27e9 + a 2 d| + \u2032 + \u2032 \u2212 \u2032 \u27e9 +abc| + \u2032 \u2212 \u2032 + \u2032 \u27e9 +bac| \u2212 \u2032 + \u2032 + \u2032 \u27e9+abd| + \u2032 \u2212 \u2032 \u2212 \u2032 \u27e9 +bad| \u2212 \u2032 + \u2032 \u2212 \u2032 \u27e9 + b 2 c| \u2212 \u2032 \u2212 \u2032 + \u2032 \u27e9+ b 2 d| \u2212 \u2032 \u2212 \u2032 \u2212 \u2032 \u27e9. (18.33) Adding two similar expressions for |+\u2212+\u27e9 and |\u2212++\u27e9 and dividing by 3 \u2013 \u221a , we find | 3 2 ,+ 1 2 ,S\u27e9 = 3 \u2013 \u221a a 2 c| 3 2 ,+ 3 2 ,T\u27e9 +( a 2 d+2abc)| 3 2 ,+ 1 2 ,T\u27e9 +(2bad+ b 2 c)| 3 2 ,\u2212 1 2 ,T\u27e9 + 3 \u2013 \u221a b 2 d| 3 2 ,\u2212 3 2 ,T\u27e9. (18.34) Continuing the process we find all the elements \u27e8jT|iS\u27e9 of the transformation matrix as given in Table 18\u20132. The first column comes from Eq. (18.32); the second from (18.34). The last two columns were worked out in the same way. Now suppose the T -frame were rotated with respect to S by the angle \u03b8 about their y -axes. Then a , b , c , and d have the values [see (12.54)] a= d= cos\u03b8/2 , and c= \u2212b= sin\u03b8/2 . Using these values in Table 18\u20132 we get the forms which correspond to the second part of Table 17\u20132, but now for a spin 3 2 system. The arguments we have just gone through are readily generalized to a system of any spin j . The states |j,m\u27e9 can be put together from 2j particles, each of spin one-half. (There are j+m of them in the |+\u27e9 state and j\u2212m in the |\u2212\u27e9 state.) Sums are taken over all the possible ways this can be done, and the state is normalized by multiplying by a suitable constant. Those of you who are mathematically inclined may be able to show that the following result comes out7: \u27e8j, m \u2032 | R y (\u03b8)|j,m\u27e9= [(j+m)!(j\u2212m)!(j+ m \u2032 )!(j\u2212 m \u2032 )! ] 1/2 \u00d7 \u2211 k (\u22121 ) k+m\u2212 m \u2032 (cos\u03b8/2 ) 2j+ m \u2032 \u2212m\u22122k (sin\u03b8/2 ) m\u2212 m \u2032 +2k (m\u2212 m \u2032 +k)!(j+ m \u2032 \u2212k)!(j\u2212m\u2212k)!k! , (18.35) where k is to go over all values which give terms \u22650 in all the factorials. This is quite a messy formula, but with it you can check Table 17\u20132 for j=1 and prepare tables of your own for larger j . Several special matrix elements are of extra importance and have been given special names. For example the matrix elements for m= m \u2032 =0 and integral j are known as the Legendre polynomials and are called P j (cos\u03b8) : \u27e8j,0| R y (\u03b8)|j,0\u27e9= P j (cos\u03b8). (18.36) The first few of these polynomials are: P 0 (cos\u03b8) P 1 (cos\u03b8) P 2 (cos\u03b8) P 3 (cos\u03b8) =1, =cos\u03b8, = 1 2 (3 cos 2 \u03b8\u22121), = 1 2 (5 cos 3 \u03b8\u22123cos\u03b8). (18.37) (18.38) (18.39) (18.40) We would like to show you one example of the application of the coefficients we have just described. It has to do with a recent, interesting experiment which you will now be able to understand. Some physicists wanted to find out the spin of a certain excited state of the Ne 20 nucleus. To do this, they bombarded a carbon target with a beam of accelerated carbon ions, and produced the desired excited state of Ne 20 \u2014called Ne 20\u2217 \u2014in the reaction C 12 + C 12 \u2192 Ne 20\u2217 + \u03b1 1 , 12 12 20 where \u03b1 1 is the \u03b1 -particle, or He 4 . Several of the excited states of Ne 20 produced this way are unstable and disintegrate in the reaction Ne 20\u2217 \u2192 O 16 + \u03b1 2 . 20 16 So experimentally there are two \u03b1 -particles which come out of the reaction. We call them \u03b1 1 and \u03b1 2 ; since they come off with different energies, they can be distinguished from each other. Also, by picking a particular energy for \u03b1 1 we can pick out any particular excited state of the Ne 20 . The experiment was set up as shown in Fig. 18\u20139. A beam of 16 -MeV carbon ions was directed onto a thin foil of carbon. The first \u03b1 -particle was counted in a silicon diffused junction detector marked \u03b1 1 \u2014set to accept \u03b1 -particles of the proper energy moving in the forward direction (with respect to the incident C 12 beam). The second \u03b1 -particle was picked up in the counter \u03b1 2 at the angle \u03b8 with respect to \u03b1 1 . The counting rate of coincidence signals from \u03b1 1 and \u03b1 2 were measured as a function of the angle \u03b8 . The idea of the experiment is the following. First, you need to know that the spins of C 12 , O 16 , and the \u03b1 -particle are all zero. If we call the direction of motion of the initial C 12 the +z -direction, then we know that the Ne 20\u2217 must have zero angular momentum about the z -axis. None of the other particles has any spin; the C 12 arrives along the z -axis and the \u03b1 1 leaves along the z -axis so they can\u2019t have any angular momentum about it. So whatever the spin j of the Ne 20\u2217 is, we know that it is in the state |j,0\u27e9 . Now what will happen when the Ne 20\u2217 disintegrates into an O 16 and the second \u03b1 -particle? Well, the \u03b1 -particle is picked up in the counter \u03b1 2 and to conserve momentum the O 16 must go off in the opposite direction.8 About the new axis through \u03b1 2 , there can be no component of angular momentum. The final state has zero angular momentum about the new axis, so the Ne 20\u2217 can disintegrate this way only if it has some amplitude to have m \u2032 equal to zero, where m \u2032 is the quantum number of the component of angular momentum about the new axis. In fact, the probability of observing \u03b1 2 at the angle \u03b8 is just the square of the amplitude (or matrix element) \u27e8j,0| R y (\u03b8)|j,0\u27e9. (18.41) To find the spin of the Ne 20\u2217 state in question, the intensity of the second \u03b1 -particle was plotted as a function of angle and compared with the theoretical curves for various values of j . As we said in the last section, the amplitudes \u27e8j,0| R y (\u03b8)|j,0\u27e9 are just the functions P j (cos\u03b8) . So the possible angular distributions are curves of [ P j (cos\u03b8) ] 2 . The experimental results are shown in Fig. 18\u201310 for two of the excited states. You can see that the angular distribution for the 5.80 -MeV state fits very well the curve for [ P 1 (cos\u03b8) ] 2 , and so it must be a spin-one state. The data for the 5.63 -MeV state, on the other hand, are quite different; they fit the curve [ P 3 (cos\u03b8) ] 2 . The state has a spin of 3 . From this experiment we have been able to find out the angular momentum of two of the excited states of Ne 20\u2217 . This information can then be used for trying to understand what the configuration of protons and neutrons is inside this nucleus\u2014one more piece of information about the mysterious nuclear forces. When we studied the hyperfine structure of the hydrogen atom in Chapter 12 we had to work out the internal states of a system composed of two particles\u2014the electron and the proton\u2014each with a spin of one-half. We found that the four possible spin states of such a system could be put together into two groups\u2014a group with one energy that looked to the external world like a spin-one particle, and one remaining state that behaved like a particle of zero spin. That is, putting together two spin one-half particles we can form a system whose \u201ctotal spin\u201d is one, or zero. In this section we want to discuss in more general terms the spin states of a system which is made up of two particles of arbitrary spin. It is another important problem about angular momentum in quantum mechanical systems. Let\u2019s first rewrite the results of Chapter 12 for the hydrogen atom in a form that will be easier to extend to the more general case. We began with two particles which we will now call particle a (the electron) and particle b (the proton). Particle a had the spin j a ( = 1 2 ), and its z -component of angular momentum m a could have one of several values (actually 2 , namely m a =+ 1 2 or m a =\u2212 1 2 ). Similarly, the spin state of particle b is described by its spin j b and its z -component of angular momentum m b . Various combinations of the spin states of the two particles could be formed. For instance, we could have particle a with m a = 1 2 and particle b with m b =\u2212 1 2 , to make a state |a,+ 1 2 ;b,\u2212 1 2 \u27e9 . In general, the combined states formed a system whose \u201csystem spin,\u201d or \u201ctotal spin,\u201d or \u201ctotal angular momentum\u201d J could be 1 , or 0 . And the system could have a z -component of angular momentum M , which was +1 , 0 , or \u22121 when J=1 , or 0 when J=0 . In this new language we can rewrite the formulas in (12.41) and (12.42) as shown in Table 18\u20133. In the table the left-hand column describes the compound state in terms of its total angular momentum J and the z -component M . The right-hand column shows how these states are made up in terms of the m -values of the two particles a and b . We want now to generalize this result to states made up of two objects a and b of arbitrary spins j a and j b . We start by considering an example for which j a = 1 2 and j b =1 , namely, the deuterium atom in which particle a is an electron (e) and particle b is the nucleus\u2014a deuteron (d). We have then that j a = j e = 1 2 . The deuteron is formed of one proton and one neutron in a state whose total spin is one, so j b = j d =1 . We want to discuss the hyperfine states of deuterium\u2014just the way we did for hydrogen. Since the deuteron has three possible states m b = m d =+1 , 0 , \u22121 , and the electron has two, m a = m e =+ 1 2 , \u2212 1 2 , there are six possible states as follows (using the notation |e, m e ;d, m d \u27e9 ): |e,+ 1 2 ;d,+1\u27e9, |e,+ 1 2 ;d,0\u27e9;|e,\u2212 1 2 ;d,+1\u27e9, |e,+ 1 2 ;d,\u22121\u27e9;|e,\u2212 1 2 ;d,0\u27e9, |e,\u2212 1 2 ;d,\u22121\u27e9. (18.42) You will notice that we have grouped the states according to the values of the sum of m e and m d \u2014arranged in descending order. Now we ask: What happens to these states if we project into a different coordinate system? If the new system is just rotated about the z -axis by the angle \u03d5 , then the state |e, m e ;d, m d \u27e9 gets multiplied by e i m e \u03d5 e i m d \u03d5 = e i( m e + m d )\u03d5 . (18.43) (The state may be thought of as the product |e, m e \u27e9|d, m d \u27e9 , and each state vector contributes independently its own exponential factor.) The factor (18.43) is of the form e iM\u03d5 , so the state |e, m e ;d, m d \u27e9 has a z -component of angular momentum equal to M= m e + m d . (18.44) The z -component of the total angular momentum is the sum of the z -components of angular momentum of the parts. In the list of (18.42), therefore, the state in the top line has M=+ 3 2 , the two in the second line have M=+ 1 2 , the next two have M=\u2212 1 2 , and the last state has M=\u2212 3 2 . We see immediately one possibility for the spin J of the combined state (the total angular momentum) must be 3 2 , and this will require four states with M=+ 3 2 , + 1 2 , \u2212 1 2 , and \u2212 3 2 . There is only one candidate for M=+ 3 2 , so we know already that |J= 3 2 ,M=+ 3 2 \u27e9=|e,+ 1 2 ;d,+1\u27e9. (18.45) But what is the state |J= 3 2 ,M=+ 1 2 \u27e9 ? We have two candidates in the second line of (18.42), and, in fact, any linear combination of them would also have M= 1 2 . So, in general, we must expect to find that |J= 3 2 ,M=+ 1 2 \u27e9= \u03b1|e,+ 1 2 ;d,0\u27e9+\u03b2|e,\u2212 1 2 ;d,+1\u27e9, (18.46) where \u03b1 and \u03b2 are two numbers. They are called the Clebsch-Gordan coefficients. Our next problem is to find out what they are. We can find out easily if we just remember that the deuteron is made up of a neutron and a proton, and write the deuteron states out more explicitly using the rules of Table 18\u20133. If we do that, the states listed in (18.42) then look as shown in Table 18\u20134. We want to form the four states of J= 3 2 , using the states in the table. But we already know the answer, because in Table 18\u20131 we have states of spin 3 2 formed from three spin one-half particles. The first state in Table 18\u20131 has |J= 3 2 ,M=+ 3 2 \u27e9 and it is |+++\u27e9 , which\u2014in our present notation\u2014is the same as |e,+ 1 2 ;n,+ 1 2 ;p,+ 1 2 \u27e9 , or the first state in Table 18\u20134. But this state is also the same as the first in the list of (18.42), confirming our statement in (18.45). The second line of Table 18\u20131 says\u2014changing to our present notation\u2014that |J= 3 2 ,M=+ 1 2 \u27e9= 1 3 \u2013 \u221a {|e,+ 1 2 ;n,+ 1 2 ;p,\u2212 1 2 \u27e9 +|e,+ 1 2 ;n,\u2212 1 2 ;p,+ 1 2 \u27e9 +|e,\u2212 1 2 ;n,+ 1 2 ;p,+ 1 2 \u27e9}. (18.47) The right side can evidently be put together from the two entries in the second line of Table 18\u20134 by taking 2/3 \u2212 \u2212 \u2212 \u221a of the first term with 1/3 \u2212 \u2212 \u2212 \u221a of the second. That is, Eq. (18.47) is equivalent to |J= 3 2 ,M=+ 1 2 \u27e9 = 2/3 \u2212 \u2212 \u2212 \u221a |e,+ 1 2 ;d,0\u27e9 + 1/3 \u2212 \u2212 \u2212 \u221a |e,\u2212 1 2 ;d,+1\u27e9. (18.48) We have found our two Clebsch-Gordan coefficients \u03b1 and \u03b2 in Eq. (18.46): \u03b1= 2/3 \u2212 \u2212 \u2212 \u221a ,\u03b2= 1/3 \u2212 \u2212 \u2212 \u221a . (18.49) Following the same procedure we can find that |J= 3 2 ,M=\u2212 1 2 \u27e9 = 1/3 \u2212 \u2212 \u2212 \u221a |e,+ 1 2 ;d,\u22121\u27e9 + 2/3 \u2212 \u2212 \u2212 \u221a |e,\u2212 1 2 ;d,0\u27e9. (18.50) And, also, of course, |J= 3 2 ,M=\u2212 3 2 \u27e9=|e,\u2212 1 2 ;d,\u22121\u27e9. (18.51) These are the rules for the composition of spin 1 and spin 1 2 to make a total J= 3 2 . We summarize (18.45), (18.48), (18.50), and (18.51) in Table 18\u20135. We have, however, only four states here while the system we are considering has six possible states. Of the two states in the second line of (18.42) we have used only one linear combination to form |J= 3 2 ,M=+ 1 2 \u27e9 . There is another linear combination orthogonal to the one we have taken which also has M=+ 1 2 , namely 1/3 \u2212 \u2212 \u2212 \u221a |e,+ 1 2 ;d,0\u27e9\u2212 2/3 \u2212 \u2212 \u2212 \u221a |e,\u2212 1 2 ;d,+1\u27e9. (18.52) Similarly, the two states in the third line of (18.42) can be combined to give two orthogonal states, each with M=\u2212 1 2 . The one orthogonal to (18.52) is 2/3 \u2212 \u2212 \u2212 \u221a |e,+ 1 2 ;d,\u22121\u27e9\u2212 1/3 \u2212 \u2212 \u2212 \u221a |e,\u2212 1 2 ;d,0\u27e9. (18.53) These are the two remaining states. They have M= m e + m d =\u00b1 1 2 ; and must be the two states corresponding to J= 1 2 . So we have |J= 1 2 ,M=+ 1 2 \u27e9 |J= 1 2 ,M=\u2212 1 2 \u27e9 = 1/3 \u2212 \u2212 \u2212 \u221a |e,+ 1 2 ;d,0\u27e9 \u2212 2/3 \u2212 \u2212 \u2212 \u221a |e,\u2212 1 2 ;d,+1\u27e9, = 2/3 \u2212 \u2212 \u2212 \u221a |e,+ 1 2 ;d,\u22121\u27e9 \u2212 1/3 \u2212 \u2212 \u2212 \u221a |e,\u2212 1 2 ;d,0\u27e9. (18.54) We can verify that these two states do indeed behave like the states of a spin one-half object by writing out the deuterium parts in terms of the neutron and proton states\u2014using Table 18\u20134. The first state in (18.52) is 1/6 \u2212 \u2212 \u2212 \u221a { \u2212 2/3 \u2212 \u2212 \u2212 \u221a |e,+ 1 2 ;n,+ 1 2 ;p,\u2212 1 2 \u27e9+ |e,+ 1 2 ;n,\u2212 1 2 ;p,+ 1 2 \u27e9} |e,\u2212 1 2 ;n,+ 1 2 ;p,+ 1 2 \u27e9, (18.55) which can also be written 1/3 \u2212 \u2212 \u2212 \u221a [ 1/2 \u2212 \u2212 \u2212 \u221a { + 1/2 \u2212 \u2212 \u2212 \u221a { |e,+ 1 2 ;n,+ 1 2 ;p,\u2212 1 2 \u27e9\u2212 |e,\u2212 1 2 ;n,+ 1 2 ;p,+ 1 2 \u27e9} |e,+ 1 2 ;n,\u2212 1 2 ;p,+ 1 2 \u27e9\u2212 |e,\u2212 1 2 ;n,+ 1 2 ;p,+ 1 2 \u27e9}]. (18.56) Now look at the terms in the first curly brackets, and think of the e and p taken together. Together they form a spin-zero state (see the bottom line of Table 18\u20133), and contribute no angular momentum. Only the neutron is left, so the whole of the first curly bracket of (18.56) behaves under rotations like a neutron, namely as a state with J= 1 2 , M=+ 1 2 . Following the same reasoning, we see that in the second curly bracket of (18.56) the electron and neutron team up to produce zero angular momentum, and only the proton contribution\u2014with m p = 1 2 \u2014is left. The terms behave like an object with J= 1 2 , M=+ 1 2 . So the whole expression of (18.56) transforms like |J= 1 2 ,M=+ 1 2 \u27e9 as it should. The M=\u2212 1 2 state which corresponds to (18.53) can be written down (by changing the proper + 1 2 's to \u2212 1 2 's) to get 1/3 \u2212 \u2212 \u2212 \u221a [ 1/2 \u2212 \u2212 \u2212 \u221a { + 1/2 \u2212 \u2212 \u2212 \u221a { |e,+ 1 2 ;n,\u2212 1 2 ;p,\u2212 1 2 \u27e9\u2212 |e,\u2212 1 2 ;n,\u2212 1 2 ;p,+ 1 2 \u27e9} |e,+ 1 2 ;n,\u2212 1 2 ;p,\u2212 1 2 \u27e9\u2212 |e,\u2212 1 2 ;n,+ 1 2 ;p,\u2212 1 2 \u27e9}]. (18.57) You can easily check that this is equal to the second line of (18.54), as it should be if the two terms of that pair are to be the two states of a spin one-half system. So our results are confirmed. A deuteron and an electron can exist in six spin states, four of which act like the states of a spin 3 2 object (Table 18\u20135) and two of which act like an object of spin one-half (18.54). The results of Table 18\u20135 and of Eq. (18.54) were obtained by making use of the fact that the deuteron is made up of a neutron and a proton. The truth of the equations does not depend on that special circumstance. For any spin-one object put together with any spin one-half object the composition laws (and the coefficients) are the same. The set of equations in Table 18\u20135 means that if the coordinates are rotated about, say, the y -axis\u2014so that the states of the spin one-half particle and of the spin-one particle change according to Table 17\u20131 and Table 17\u20132\u2014the linear combinations on the right-hand side will change in the proper way for a spin 3 2 object. Under the same rotation the states of (18.54) will change as the states of a spin one-half object. The results depend only on the rotation properties (that is, the spin states) of the two original particles but not in any way on the origins of their angular momenta. We have only made use of this fact to work out the formulas by choosing a special case in which one of the component parts is itself made up of two spin one-half particles in a symmetric state. We have put all our results together in Table 18\u20136, changing the notation \u201ce\u201d and \u201cd\u201d to \u201c a \u201d and \u201c b \u201d to emphasize the generality of the conclusions. Suppose we have the general problem of finding the states which can be formed when two objects of arbitrary spins are combined. Say one has j a (so its z -component m a runs over the 2 j a +1 values from \u2212 j a to + j a ) and the other has j b (with z -component m b running over the values from \u2212 j b to + j b ). The combined states are |a, m a ;b, m b \u27e9 , and there are (2 j a +1)(2 j b +1) different ones. Now what states of total spin J can be found? The total z -component of angular momentum M is equal to m a + m b , and the states can all be listed according to M [as in (18.42)]. The largest M is unique; it corresponds to m a = j a and m b = j b , and is, therefore, just j a + j b . That means that the largest total spin J is also equal to the sum j a + j b : J=(M ) max = j a + j b . ( ) For the first M value smaller than (M ) max , there are two states (either m a or m b is one unit less than its maximum). They must contribute one state to the set that goes with J= j a + j b , and the one left over will belong to a new set with J= j a + j b \u22121 . The next M -value\u2014the third from the top of the list\u2014can be formed in three ways. (From m a = j a \u22122 , m b = j b ; from m a = j a \u22121 , m b = j b \u22121 ; and from m a = j a , m b = j b \u22122 .) Two of these belong to groups already started above; the third tells us that states of J= j a + j b \u22122 must also be included. This argument continues until we reach a stage where in our list we can no longer go one more step down in one of the m \u2019s to make new states. Let j b be the smaller of j a and j b (if they are equal take either one); then only 2 j b values of J are required\u2014going in integer steps from j a + j b down to j a \u2212 j b . That is, when two objects of spin j a and j b are combined, the system can have a total angular momentum J equal to any one of the values J= \u23a7 \u23a9 \u23a8 \u23aa \u23aa \u23aa \u23aa \u23aa \u23aa \u23aa \u23aa \u23aa \u23aa \u23aa \u23aa | j a + j b j a + j b \u22121 j a + j b \u22122 \u22ee j a \u2212 j b |. (18.58) (By writing | j a \u2212 j b | instead of j a \u2212 j b we can avoid the extra admonition that j a \u2265 j b .) For each of these J values there are the 2J+1 states of different M -values\u2014with M going from +J to \u2212J . Each of these is formed from linear combinations of the original states |a, m a ;b, m b \u27e9 with appropriate factors\u2014the Clebsch-Gordan coefficients for each particular term. We can consider that these coefficients give the \u201camount\u201d of the state | j a , m a ; j b , m b \u27e9 which appears in the state |J,M\u27e9 . So each of the Clebsch-Gordan coefficients has, if you wish, six indices identifying its position in the formulas like those of Tables 18\u20133 and 18\u20136. That is, calling these coefficients C(J,M; j a , m a ; j b , m b ) , we could express the equality of the second line of Table 18\u20136 by writing C( 3 2 ,+ 1 2 ; 1 2 ,+ 1 2 ;1,0)= 2/3 \u2212 \u2212 \u2212 \u221a , C( 3 2 ,+ 1 2 ; 1 2 ,\u2212 1 2 ;1,+1)= 1/3 \u2212 \u2212 \u2212 \u221a . We will not calculate here the coefficients for any other special cases.9 You can, however, find tables in many books. You might wish to try another special case for yourself. The next one to do would be the composition of two spin-one particles. We give just the final result in Table 18\u20137. These laws of the composition of angular momenta are very important in particle physics\u2014where they have innumerable applications. Unfortunately, we have no time to look at more examples here. For those who would like to see the details, we work out here the general rotation matrix for a system with spin (total angular momentum) j . It is really not very important to work out the general case; once you have the idea, you can find the general results in tables in many books. On the other hand, after coming this far you might like to see that you can indeed understand even the very complicated formulas of quantum mechanics, such as Eq. (18.35), that come into the description of angular momentum. We extend the arguments of Section 18-4 to a system with spin j , which we consider to be made up of 2j spin one-half objects. The state with m=j would be |+++\u22ef+\u27e9 (with 2j plus signs). For m=j\u22121 , there will be 2j terms like |++\u22ef++\u2212\u27e9 , |++\u22ef+\u2212+\u27e9 , and so on. Let\u2019s consider the general case in which there are r plusses and s minuses\u2014with r+s=2j . Under a rotation about the z -axis each of the r plusses will contribute e +i\u03d5/2 . The result is a phase change of (r/2\u2212s/2)\u03d5 . You see that m= r\u2212s 2 . (18.59) Just as for j= 3 2 , each state of definite m must be the linear combination with plus signs of all the states with the same r and s \u2014that is, states corresponding to every possible arrangement which has r plusses and s minuses. We assume that you can figure out that there are (r+s)!/r!s! such arrangements. To normalize each state, we should divide the sum by the square root of this number. We can write [ (r+s)! r!s! ] \u22121/2 {| +++\u22ef++ \ue152 \ue153 \ue151\ue150 \ue154 \ue154 \ue154 \ue154 \ue154 \ue154 \ue154 \ue154 \ue154 \ue154 \ue154 \ue154 \ue154 \ue154 r \u2212\u2212\u2212\u22ef\u2212\u2212 \ue152 \ue153 \ue151\ue150 \ue154 \ue154 \ue154 \ue154 \ue154 \ue154 \ue154 \ue154 \ue154 \ue154 \ue154 \ue154 \ue154 \ue154 s \u27e9 +(all rearrangements of order)} =|j,m\u27e9 (18.60) with j= r+s 2 ,m= r\u2212s 2 . (18.61) It will help our work if we now go to still another notation. Once we have defined the states by Eq. (18.60), the two numbers r and s define a state just as well as j and m . It will help us keep track of things if we write |j,m\u27e9=| r s \u27e9, (18.62) where, using the equalities of (18.61) r=j+m,s=j\u2212m. j j Next, we would like to write Eq. (18.60) with a new special notation as |j,m\u27e9=| r s \u27e9=[ (r+s)! r!s! ] +1/2 {|+ \u27e9 r |\u2212 \u27e9 s } perm . (18.63) Note that we have changed the exponent of the factor in front to plus 1 2 . We do that because there are just N=(r+s)!/r!s! terms inside the curly brackets. Comparing (18.63) with (18.60) it is clear that {|+ \u27e9 r |\u2212 \u27e9 s } perm r s is just a shorthand way of writing {|++\u22ef\u2212\u2212\u27e9+all rearrangements} N , { | \u27e9 all rearrangements } where N is the number of different terms in the bracket. The reason that this notation is convenient is that each time we make a rotation, all of the plus signs contribute the same factor, so we get this factor to the r th power. Similarly, all together the s minus terms contribute a factor to the s th power no matter what the sequence of the terms is. Now suppose we rotate our system by the angle \u03b8 about the y -axis. What we want is R y (\u03b8)| r s \u27e9 . When R y (\u03b8) operates on each |+\u27e9 it gives R y (\u03b8)|+\u27e9=|+\u27e9C+|\u2212\u27e9S, (18.64) where C=cos\u03b8/2 and S=\u2212sin\u03b8/2 . When R y (\u03b8) operates on each |\u2212\u27e9 it gives R y (\u03b8)|\u2212\u27e9=|\u2212\u27e9C\u2212|+\u27e9S. ( \u03b8 ) | \u27e9 | \u27e9 | \u27e9 So what we want is R y (\u03b8)| r s \u27e9 =[ (r+s)! r!s! ] 1/2 R y (\u03b8){|+ \u27e9 r |\u2212 \u27e9 s } perm =[ (r+s)! r!s! ] 1/2 {( R y (\u03b8)|+\u27e9 ) r ( R y (\u03b8)|\u2212\u27e9 ) s } perm =[ (r+s)! r!s! ] 1/2 {(|+\u27e9C+|\u2212\u27e9S ) r (|\u2212\u27e9C\u2212|+\u27e9S ) s } perm . (18.65) Now each binomial has to be expanded out to its appropriate power and the two expressions multiplied together. There will be terms with |+\u27e9 to all powers from zero to (r+s) . Let\u2019s look at all of the terms which have |+\u27e9 to the r \u2032 power. They will appear always multiplied with |\u2212\u27e9 to the s \u2032 power, where s \u2032 =2j\u2212 r \u2032 . Suppose we collect all such terms. For each permutation they will have some numerical coefficient involving the factors of the binomial expansion as well as the factors C and S . Suppose we call that factor A r \u2032 . Then Eq. (18.65) will look like R y (\u03b8)| r s \u27e9= \u2211 r \u2032 =0 r+s { A r \u2032 |+ \u27e9 r \u2032 |\u2212 \u27e9 s \u2032 } perm . (18.66) Now let\u2019s say that we divide A r \u2032 by the factor [( r \u2032 + s \u2032 )!/ r \u2032 ! s \u2032 ! ] 1/2 and call the quotient B r \u2032 . Equation (18.66) is then equivalent to R y (\u03b8)| r s \u27e9= \u2211 r \u2032 =0 r+s B r \u2032 [ ( r \u2032 + s \u2032 )! r \u2032 ! s \u2032 ! ] 1/2 {|+ \u27e9 r \u2032 |\u2212 \u27e9 s \u2032 } perm . (18.67) (We could just say that this equation defines B r \u2032 by the requirement that (18.67) gives the same expression that appears in (18.65).) With this definition of B r \u2032 the remaining factors on the right-hand side of Eq. (18.67) are just the states | r \u2032 s \u2032 \u27e9 . So we have that R y (\u03b8)| r s \u27e9= \u2211 r \u2032 =0 r+s B r \u2032 | r \u2032 s \u2032 \u27e9, (18.68) with s \u2032 always equal to r+s\u2212 r \u2032 . This means, of course, that the coefficients B r \u2032 are just the matrix elements we want, namely \u27e8 r \u2032 s \u2032 | R y (\u03b8)| r s \u27e9= B r \u2032 . (18.69) Now we just have to push through the algebra to find the various B r \u2032 . Comparing (18.65) with (18.67)\u2014and remembering that r \u2032 + s \u2032 =r+s \u2014we see that B r \u2032 is just the coefficient of a r \u2032 b s \u2032 in the following expression: ( r \u2032 ! s \u2032 ! r!s! ) 1/2 (aC+bS ) r (bC\u2212aS ) s . (18.70) It is now only a dirty job to make the expansions by the binomial theorem, and collect the terms with the given power of a and b . If you work it all out, you find that the coefficient of a r \u2032 b s \u2032 in (18.70) is [ r \u2032 ! s \u2032 ! r!s! ] 1/2 \u2211 k (\u22121 ) k S r\u2212 r \u2032 +2k C s+ r \u2032 \u22122k \u00d7 r! (r\u2212 r \u2032 +k)!( r \u2032 \u2212k)! \u22c5 s! (s\u2212k)!k! . (18.71) The sum is to be taken over all integers k which give terms of zero or greater in the factorials. This expression is then the matrix element we wanted. Finally, we can return to our original notation in terms of j , m , and m \u2032 using r s = = j+m, j\u2212m, r \u2032 s \u2032 = = j+ m \u2032 , j\u2212 m \u2032 . Making these substitutions, we get Eq. (18.35) in Section 18-4. In Section 18-1 of this chapter we considered the emission of light by an atom that goes from an excited state of spin 1 to a ground state of spin 0 . If the excited state has its spin up ( m=+1 ), it can emit a RHC photon along the +z -axis or a LHC photon along the \u2212z -axis. Let\u2019s call these two states of the photon | R up \u27e9 and | L dn \u27e9 . Neither of these states has a definite parity. Letting P ^ be the parity operator, P ^ | R up \u27e9=| L dn \u27e9 and P ^ | L dn \u27e9=| R up \u27e9 . What about our earlier proof that an atom in a state of definite energy must have a definite parity, and our statement that parity is conserved in atomic processes? Shouldn\u2019t the final state in this problem (the state after the emission of a photon) have a definite parity? It does if we consider the complete final state which contains amplitudes for the emission of photons into all sorts of angles. In Section 18-1 we chose to consider only a part of the complete final state. If we wish we can look only at final states that do have a definite parity. For example, consider a final state | \u03c8 F \u27e9 which has some amplitude \u03b1 to be a RHC photon going along +z and some amplitude \u03b2 to be a LHC photon going along \u2212z . We can write | \u03c8 F \u27e9=\u03b1| R up \u27e9+\u03b2| L dn \u27e9. (18.72) The parity operation on this state gives P ^ | \u03c8 F \u27e9=\u03b1| L dn \u27e9+\u03b2| R up \u27e9. (18.73) This state will be \u00b1| \u03c8 F \u27e9 if \u03b2=\u03b1 or if \u03b2=\u2212\u03b1 . So a final state of even parity is | \u03c8 + F \u27e9=\u03b1{| R up \u27e9+| L dn \u27e9}, (18.74) and a state of odd parity is | \u03c8 \u2212 F \u27e9=\u03b1{| R up \u27e9\u2212| L dn \u27e9}. (18.75) Next, we wish to consider the decay of an excited state of odd parity to a ground state of even parity. If parity is to be conserved, the final state of the photon must have odd parity. It must be the state in (18.75). If the amplitude to find | R up \u27e9 is \u03b1 , the amplitude to find | L dn \u27e9 is \u2212\u03b1 . Now notice what happens when we perform a rotation of 180 \u2218 about the y -axis. The initial excited state of the atom becomes an m=\u22121 state (with no change in sign, according to Table 17\u20132). And the rotation of the final state gives R y ( 180 \u2218 )| \u03c8 \u2212 F \u27e9=\u03b1{| R dn \u27e9\u2212| L up \u27e9}. (18.76) Comparing this equation with (18.75), you see that for the assumed parity of the final state, the amplitude to get a LHC photon along +z from the m=\u22121 initial state is the negative of the amplitude to get a RHC photon from the m=+1 initial state. This agrees with the result we found in Section 18-1."
    },
    {
        "input": "Electrostatic Energy",
        "output": "In the study of mechanics, one of the most interesting and useful discoveries was the law of the conservation of energy. The expressions for the kinetic and potential energies of a mechanical system helped us to discover connections between the states of a system at two different times without having to look into the details of what was occurring in between. We wish now to consider the energy of electrostatic systems. In electricity also the principle of the conservation of energy will be useful for discovering a number of interesting things. The law of the energy of interaction in electrostatics is very simple; we have, in fact, already discussed it. Suppose we have two charges q1 and q2 separated by the distance r12 . There is some energy in the system, because a certain amount of work was required to bring the charges together. We have already calculated the work done in bringing two charges together from a large distance. It is q1q2 4\u03c0\u03f50r12 . We also know, from the principle of superposition, that if we have many charges present, the total force on any charge is the sum of the forces from the others. It follows, therefore, that the total energy of a system of a number of charges is the sum of terms due to the mutual interaction of each pair of charges. If qi and qj are any two of the charges and rij is the distance between them (Fig. 8\u20131), the energy of that particular pair is qiqj 4\u03c0\u03f50rij . The total electrostatic energy U is the sum of the energies of all possible pairs of charges: U=\u2211all pairs qiqj 4\u03c0\u03f50rij . If we have a distribution of charge specified by a charge density \u03c1 , the sum of Eq. (8.3) is, of course, to be replaced by an integral. We shall concern ourselves with two aspects of this energy. One is the application of the concept of energy to electrostatic problems; the other is the evaluation of the energy in different ways. Sometimes it is easier to compute the work done for some special case than to evaluate the sum in Eq. (8.3), or the corresponding integral. As an example, let us calculate the energy required to assemble a sphere of charge with a uniform charge density. The energy is just the work done in gathering the charges together from infinity. Imagine that we assemble the sphere by building up a succession of thin spherical layers of infinitesimal thickness. At each stage of the process, we gather a small amount of charge and put it in a thin layer from r to r+dr . We continue the process until we arrive at the final radius a (Fig. 8\u20132). If Qr is the charge of the sphere when it has been built up to the radius r , the work done in bringing a charge dQ to it is dU= QrdQ 4\u03c0\u03f50r . If the density of charge in the sphere is \u03c1 , the charge Qr is Qr=\u03c1\u22c5 4 3 \u03c0r3, and the charge dQ is dQ=\u03c1\u22c54\u03c0r2dr. Equation (8.4) becomes dU= 4\u03c0\u03c12r4dr 3\u03f50 . The total energy required to assemble the sphere is the integral of dU from r=0 to r=a , or U= 4\u03c0\u03c12a5 15\u03f50 . Or if we wish to express the result in terms of the total charge Q of the sphere, U= 3 5 Q2 4\u03c0\u03f50a . The energy is proportional to the square of the total charge and inversely proportional to the radius. We can also interpret Eq. (8.7) as saying that the average of (1/rij) for all pairs of points in the sphere is 6/5a . We consider now the energy required to charge a condenser. If the charge Q has been taken from one of the conductors of a condenser and placed on the other, the potential difference between them is V= Q C , (8.8) where C is the capacity of the condenser. How much work is done in charging the condenser? Proceeding as for the sphere, we imagine that the condenser has been charged by transferring charge from one plate to the other in small increments dQ . The work required to transfer the charge dQ is dU=VdQ. Taking V from Eq. (8.8), we write dU= QdQ C . Or integrating from zero charge to the final charge Q , we have U= 1 2 Q 2 C . (8.9) This energy can also be written as U= 1 2 C V 2 . (8.10) Recalling that the capacity of a conducting sphere (relative to infinity) is C sphere =4\u03c0 \u03f5 0 a, we can immediately get from Eq. (8.9) the energy of a charged sphere, U= 1 2 Q 2 4\u03c0 \u03f5 0 a . (8.11) This, of course, is also the energy of a thin spherical shell of total charge Q and is just 5/6 of the energy of a uniformly charged sphere, Eq. (8.7). We now consider applications of the idea of electrostatic energy. Consider the following questions: What is the force between the plates of a condenser? Or what is the torque about some axis of a charged conductor in the presence of another with opposite charge? Such questions are easily answered by using our result Eq. (8.9) for electrostatic energy of a condenser, together with the principle of virtual work (Chapters 4, 13, and 14 of Vol. I). Let\u2019s use this method for determining the force between the plates of a parallel-plate condenser. If we imagine that the spacing of the plates is increased by the small amount \u0394z , then the mechanical work done from the outside in moving the plates would be \u0394W=F\u0394z, (8.12) where F is the force between the plates. This work must be equal to the change in the electrostatic energy of the condenser. By Eq. (8.9), the energy of the condenser was originally U= 1 2 Q 2 C . 2 The change in energy (if we do not let the charge change) is \u0394U= 1 2 Q 2 \u0394( 1 C ). (8.13) Equating (8.12) and (8.13), we have F\u0394z= Q 2 2 \u0394( 1 C ). (8.14) This can also be written as F\u0394z=\u2212 Q 2 2 C 2 \u0394C. (8.15) The force, of course, results from the attraction of the charges on the plates, but we see that we do not have to worry in detail about how they are distributed; everything we need is taken care of in the capacity C . It is easy to see how the idea is extended to conductors of any shape, and for other components of the force. In Eq. (8.14), we replace F by the component we are looking for, and we replace \u0394z by a small displacement in the corresponding direction. Or if we have an electrode with a pivot and we want to know the torque \u03c4 , we write the virtual work as \u0394W=\u03c4\u0394\u03b8, \u0394 W \u0394 \u03b8 where \u0394\u03b8 is a small angular displacement. Of course, \u0394(1/C) must be the change in 1/C which corresponds to \u0394\u03b8 . We could, in this way, find the torque on the movable plates in a variable condenser of the type shown in Fig. 8\u20133. Returning to the special case of a parallel-plate condenser, we can use the formula we derived in Chapter 6 for the capacity: 1 C = d \u03f5 0 A , (8.16) where A is the area of each plate. If we increase the separation by \u0394z , \u0394( 1 C )= \u0394z \u03f5 0 A . 1 \u0394 From Eq. (8.14) we get that the force between the plates is F= Q 2 2 \u03f5 0 A . (8.17) Let\u2019s look at Eq. (8.17) a little more closely and see if we can tell how the force arises. If for the charge on one plate we write Q=\u03c3A, Q A Eq. (8.17) can be rewritten as F= 1 2 Q \u03c3 \u03f5 0 . 1 Or, since the electric field between the plates is E 0 = \u03c3 \u03f5 0 , \u03c3 then F= 1 2 Q E 0 . (8.18) One would immediately guess that the force acting on one plate is the charge Q on the plate times the field acting on the charge. But we have a surprising factor of one-half. The reason is that E 0 is not the field at the charges. If we imagine that the charge at the surface of the plate occupies a thin layer, as indicated in Fig. 8\u20134, the field will vary from zero at the inner boundary of the layer to E 0 in the space outside of the plate. The average field acting on the surface charges is E 0 /2 . That is why the factor one-half is in Eq. (8.18). You should notice that in computing the virtual work we have assumed that the charge on the condenser was constant\u2014that it was not electrically connected to other objects, and so the total charge could not change. Suppose we had imagined that the condenser was held at a constant potential difference as we made the virtual displacement. Then we should have taken U= 1 2 C V 2 1 and in place of Eq. (8.15) we would have had F\u0394z= 1 2 V 2 \u0394C, 1 which gives a force equal in magnitude to the one in Eq. (8.15) (because V=Q/C ), but with the opposite sign! Surely the force between the condenser plates doesn\u2019t reverse in sign as we disconnect it from its charging source. Also, we know that two plates with opposite electrical charges must attract. The principle of virtual work has been incorrectly applied in the second case\u2014we have not taken into account the virtual work done on the charging source. That is, to keep the potential constant at V as the capacity changes, a charge V\u0394C must be supplied by a source of charge. But this charge is supplied at a potential V , so the work done by the electrical system which keeps the potential constant is V 2 \u0394C . The mechanical work F\u0394z plus this electrical work V 2 \u0394C together make up the change in the total energy 1 2 V 2 \u0394C of the condenser. Therefore F\u0394z is \u2212 1 2 V 2 \u0394C , as before. We now consider an application of the concept of electrostatic energy in atomic physics. We cannot easily measure the forces between atoms, but we are often interested in the energy differences between one atomic arrangement and another, as, for example, the energy of a chemical change. Since atomic forces are basically electrical, chemical energies are in large part just electrostatic energies. Let\u2019s consider, for example, the electrostatic energy of an ionic lattice. An ionic crystal like NaCl consists of positive and negative ions which can be thought of as rigid spheres. They attract electrically until they begin to touch; then there is a repulsive force which goes up very rapidly if we try to push them closer together. For our first approximation, therefore, we imagine a set of rigid spheres that represent the atoms in a salt crystal. The structure of the lattice has been determined by x-ray diffraction. It is a cubic lattice\u2014like a three-dimensional checkerboard. Figure 8\u20135 shows a cross-sectional view. The spacing of the ions is 2.81 \u00c5 ( =2.81\u00d7 10 \u22128 cm). If our picture of this system is correct, we should be able to check it by asking the following question: How much energy will it take to pull all these ions apart\u2014that is, to separate the crystal completely into ions? This energy should be equal to the heat of vaporization of NaCl plus the energy required to dissociate the molecules into ions. This total energy to separate NaCl to ions is determined experimentally to be 7.92 electron volts per molecule. Using the conversion 1 eV=1.602\u00d7 10 \u221219 joule, 19 and Avogadro\u2019s number for the number of molecules in a mole, N 0 =6.02\u00d7 10 23 , 23 the energy of dissociation can also be given as W=7.64\u00d7 10 5 joules/mole. 5 Physical chemists prefer for an energy unit the kilocalorie, which is 4190 joules; so that 1 eV per molecule is 23 kilocalories per mole. A chemist would then say that the dissociation energy of NaCl is W=183 kcal/mole. W 183 kcal/mole Can we obtain this chemical energy theoretically by computing how much work it would take to pull apart the crystal? According to our theory, this work is the sum of the potential energies of all the pairs of ions. The easiest way to figure out this sum is to pick out a particular ion and compute its potential energy with each of the other ions. That will give us twice the energy per ion, because the energy belongs to the pairs of charges. If we want the energy to be associated with one particular ion, we should take half the sum. But we really want the energy per molecule, which contains two ions, so that the sum we compute will give directly the energy per molecule. The energy of an ion with one of its nearest neighbors is e 2 /a , where e 2 = q 2 e /4\u03c0 \u03f5 0 and a is the center-to-center spacing between ions. (We are considering monovalent ions.) This energy is 5.12 eV, which we already see is going to give us a result of the correct order of magnitude. But it is still a long way from the infinite sum of terms we need. Let\u2019s begin by summing all the terms from the ions along a straight line. Considering that the ion marked Na in Fig. 8\u20135 is our special ion, we shall consider first those ions on a horizontal line with it. There are two nearest Cl ions with negative charges, each at the distance a . Then there are two positive ions at the distance 2a , etc. Calling the energy of this sum U 1 , we write U 1 = e 2 a (\u2212 2 1 + 2 2 \u2212 2 3 + 2 4 \u2213\u22ef) =\u2212 2 e 2 a (1\u2212 1 2 + 1 3 \u2212 1 4 \u00b1\u22ef). (8.19) The series converges slowly, so it is difficult to evaluate numerically, but it is known to be equal to ln2 . So U 1 =\u2212 2 e 2 a ln2=\u22121.386 e 2 a . (8.20) Now consider the next adjacent line of ions above. The nearest is negative and at the distance a . Then there are two positives at the distance 2 \u2013 \u221a a . The next pair are at the distance 5 \u2013 \u221a a , the next at 10 \u2212 \u2212 \u221a a , and so on. So for the whole line we get the series e 2 a (\u2212 1 1 + 2 2 \u2013 \u221a \u2212 2 5 \u2013 \u221a + 2 10 \u2212 \u2212 \u221a \u2213\u22ef). (8.21) There are four such lines: above, below, in front, and in back. Then there are the four lines which are the nearest lines on diagonals, and on and on. If you work patiently through for all the lines, and then take the sum, you find that the grand total is U=\u22121.747 e 2 a , 2 which is just somewhat more than what we obtained in (8.20) for the first line. Using e 2 /a=5.12 eV, we get U=\u22128.94 eV. U 8.94 eV Our answer is about 10% above the experimentally observed energy. It shows that our idea that the whole lattice is held together by electrical Coulomb forces is fundamentally correct. This is the first time that we have obtained a specific property of a macroscopic substance from a knowledge of atomic physics. We will do much more later. The subject that tries to understand the behavior of bulk matter in terms of the laws of atomic behavior is called solid-state physics. Now what about the error in our calculation? Why is it not exactly right? It is because of the repulsion between the ions at close distances. They are not perfectly rigid spheres, so when they are close together they are partly squashed. They are not very soft, so they squash only a little bit. Some energy, however, is used in deforming them, and when the ions are pulled apart this energy is released. The actual energy needed to pull the ions apart is a little less than the energy that we calculated; the repulsion helps in overcoming the electrostatic attraction. Is there any way we can make an allowance for this contribution? We could if we knew the law of the repulsive force. We are not ready to analyze the details of this repulsive mechanism, but we can get some idea of its characteristics from some large-scale measurements. From a measurement of the compressibility of the whole crystal, it is possible to obtain a quantitative idea of the law of repulsion between the ions and therefore of its contribution to the energy. In this way it has been found that this contribution must be 1/9.4 of the contribution from the electrostatic attraction and, of course, of opposite sign. If we subtract this contribution from the pure electrostatic energy, we obtain 7.99 eV for the dissociation energy per molecule. It is much closer to the observed result of 7.92 eV, but still not in perfect agreement. There is one more thing we haven\u2019t taken into account: we have made no allowance for the kinetic energy of the crystal vibrations. If a correction is made for this effect, very good agreement with the experimental number is obtained. The ideas are then correct; the major contribution to the energy of a crystal like NaCl is electrostatic. We will now take up another example of electrostatic energy in atomic physics, the electrical energy of atomic nuclei. Before we do this we will have to discuss some properties of the main forces (called nuclear forces) that hold the protons and neutrons together in a nucleus. In the early days of the discovery of nuclei\u2014and of the neutrons and protons that make them up\u2014it was hoped that the law of the strong, nonelectrical part of the force between, say, a proton and another proton would have some simple law, like the inverse square law of electricity. For once one had determined this law of force, and the corresponding ones between a proton and a neutron, and a neutron and a neutron, it would be possible to describe theoretically the complete behavior of these particles in nuclei. Therefore a big program was started for the study of the scattering of protons, in the hope of finding the law of force between them; but after thirty years of effort, nothing simple has emerged. A considerable knowledge of the force between proton and proton has been accumulated, but we find that the force is as complicated as it can possibly be. What we mean by \u201cas complicated as it can be\u201d is that the force depends on as many things as it possibly can. First, the force is not a simple function of the distance between the two protons. At large distances there is an attraction, but at closer distances there is a repulsion. The distance dependence is a complicated function, still imperfectly known. Second, the force depends on the orientation of the protons\u2019 spin. The protons have a spin, and any two interacting protons may be spinning with their angular momenta in the same direction or in opposite directions. And the force is different when the spins are parallel from what it is when they are antiparallel, as in (a) and (b) of Fig. 8\u20136. The difference is quite large; it is not a small effect. Third, the force is considerably different when the separation of the two protons is in the direction parallel to their spins, as in (c) and (d) of Fig. 8\u20136, than it is when the separation is in a direction perpendicular to the spins, as in (a) and (b). Fourth, the force depends, as it does in magnetism, on the velocity of the protons, only much more strongly than in magnetism. And this velocity-dependent force is not a relativistic effect; it is strong even at speeds much less than the speed of light. Furthermore, this part of the force depends on other things besides the magnitude of the velocity. For instance, when a proton is moving near another proton, the force is different when the orbital motion has the same direction of rotation as the spin, as in (e) of Fig. 8\u20136, than when it has the opposite direction of rotation, as in (f). This is called the \u201cspin orbit\u201d part of the force. The force between a proton and a neutron and between a neutron and a neutron are also equally complicated. To this day we do not know the machinery behind these forces\u2014that is to say, any simple way of understanding them. There is, however, one important way in which the nucleon forces are simpler than they could be. That is that the nuclear force between two neutrons is the same as the force between a proton and a neutron, which is the same as the force between two protons! If, in any nuclear situation, we replace a proton by a neutron (or vice versa), the nuclear interactions are not changed. The \u201cfundamental reason\u201d for this equality is not known, but it is an example of an important principle that can be extended also to the interaction laws of other strongly interacting particles\u2014such as the \u03c0 -mesons and the \u201cstrange\u201d particles. This fact is nicely illustrated by the locations of the energy levels in similar nuclei. Consider a nucleus like B 11 (boron-eleven), which is composed of five protons and six neutrons. In the nucleus the eleven particles interact with one another in a most complicated dance. Now, there is one configuration of all the possible interactions which has the lowest possible energy; this is the normal state of the nucleus, and is called the ground state. If the nucleus is disturbed (for example, by being struck by a high-energy proton or other particle) it can be put into any number of other configurations, called excited states, each of which will have a characteristic energy that is higher than that of the ground state. In nuclear physics research, such as is carried on with Van de Graaff generators (for example, in Caltech\u2019s Kellogg and Sloan Laboratories), the energies and other properties of these excited states are determined by experiment. The energies of the fifteen lowest known excited states of B 11 are shown in a one-dimensional graph on the left half of Fig. 8\u20137. The lowest horizontal line represents the ground state. The first excited state has an energy 2.14 MeV higher than the ground state, the next an energy 4.46 MeV higher than the ground state, and so on. The study of nuclear physics attempts to find an explanation for this rather complicated pattern of energies; there is as yet, however, no complete general theory of such nuclear energy levels. If we replace one of the neutrons in B 11 with a proton, we have the nucleus of an isotope of carbon, C 11 . The energies of the lowest sixteen excited states of C 11 have also been measured; they are shown in the right half of Fig. 8\u20137. (The broken lines indicate levels for which the experimental information is questionable.) Looking at Fig. 8\u20137, we see a striking similarity between the pattern of the energy levels in the two nuclei. The first excited states are about 2 MeV above the ground states. There is a large gap of about 2.3 MeV to the second excited state, then a small jump of only 0.5 MeV to the third level. Again, between the fourth and fifth levels, a big jump; but between the fifth and sixth a tiny separation of the order of 0.1 MeV. And so on. After about the tenth level, the correspondence seems to become lost, but can still be seen if the levels are labeled with their other defining characteristics\u2014for instance, their angular momentum and what they do to lose their extra energy. The striking similarity of the pattern of the energy levels of B 11 and C 11 is surely not just a coincidence. It must reveal some physical law. It shows, in fact, that even in the complicated situation in a nucleus, replacing a neutron by a proton makes very little change. This can mean only that the neutron-neutron and proton-proton forces must be nearly identical. Only then would we expect the nuclear configurations with five protons and six neutrons to be the same as with six protons and five neutrons. Notice that the properties of these two nuclei tell us nothing about the neutron-proton force; there are the same number of neutron-proton combinations in both nuclei. But if we compare two other nuclei, such as C 14 , which has six protons and eight neutrons, with N 14 , which has seven of each, we find a similar correspondence of energy levels. So we can conclude that the p-p, n-n, and p-n forces are identical in all their complexities. There is an unexpected principle in the laws of nuclear forces. Even though the force between each pair of nuclear particles is very complicated, the force between the three possible different pairs is the same. But there are some small differences. The levels do not correspond exactly; also, the ground state of C 11 has an absolute energy (its mass) which is higher than the ground state of B 11 by 1.982 MeV. All the other levels are also higher in absolute energy by this same amount. So the forces are not exactly equal. But we know very well that the complete forces are not exactly equal; there is an electrical force between two protons because each has a positive charge, while between two neutrons there is no such electrical force. Can we perhaps explain the differences between B 11 and C 11 by the fact that the electrical interaction of the protons is different in the two cases? Perhaps even the remaining minor differences in the levels are caused by electrical effects? Since the nuclear forces are so much stronger than the electrical force, electrical effects would have only a small perturbing effect on the energies of the levels. In order to check this idea, or rather to find out what the consequences of this idea are, we first consider the difference in the ground-state energies of the two nuclei. To take a very simple model, we suppose that the nuclei are spheres of radius r (to be determined), containing Z protons. If we consider that a nucleus is like a sphere with uniform charge density, we would expect the electrostatic energy (from Eq. 8.7) to be U= 3 5 (Z q e ) 2 4\u03c0 \u03f5 0 r . (8.22) where q e is the elementary charge of the proton. Since Z is five for B 11 and six for C 11 , their electrostatic energies would be different. With such a small number of protons, however, Eq. (8.22) is not quite correct. If we compute the electrical energy between all pairs of protons, considered as points which we assume to be nearly uniformly distributed throughout the sphere, we find that in Eq. (8.22) the quantity Z 2 should be replaced by Z(Z\u22121) , so the energy is U= 3 5 Z(Z\u22121) q 2 e 4\u03c0 \u03f5 0 r = 3 5 Z(Z\u22121) e 2 r . (8.23) If we knew the nuclear radius r , we could use (8.23) to find the electrostatic energy difference between B 11 and C 11 . But let\u2019s do the opposite; let\u2019s instead use the observed energy difference to compute the radius, assuming that the energy difference is all electrostatic in origin. That is, however, not quite right. The energy difference of 1.982 MeV between the ground states of B 11 and C 11 includes the rest energies\u2014that is, the energy m c 2 \u2014of all the particles. In going from B 11 to C 11 , we replace a neutron by a proton and an electron, which have less mass. So part of the energy difference is the difference in the rest energies of a neutron and that of a proton plus an electron, which is 0.784 MeV. The difference, to be accounted for by electrostatic energy, is thus more than 1.982 MeV; it is 1.982 MeV+0.784 MeV=2.766 MeV. 1.982 MeV 0.784 MeV 2.766 MeV Using this energy in Eq. (8.23), for the radius of either B 11 or C 11 we find r=3.12\u00d7 10 \u221213 cm. (8.24) Does this number have any meaning? To see whether it does, we should compare it with some other determination of the radius of these nuclei. For example, we can make another measurement of the radius of a nucleus by seeing how it scatters fast particles. From such measurements it has been found, in fact, that the density of matter in all nuclei is nearly the same, i.e., their volumes are proportional to the number of particles they contain. If we let A be the number of protons and neutrons in a nucleus (a number very nearly proportional to its mass), it is found that its radius is given by r= A 1/3 r 0 , (8.25) where r 0 =1.2\u00d7 10 \u221213 cm. (8.26) From these measurements we find that the radius of a B 11 (or a C 11 ) nucleus is expected to be r=(11 ) 1/3 (1.2\u00d7 10 \u221213 ) cm=2.7\u00d7 10 \u221213 cm. 1 / 3 Comparing this result with (8.24), we see that our assumptions that the energy difference between B 11 and C 11 is electrostatic is fairly good; the discrepancy is only about 15% (not bad for our first nuclear computation!). The reason for the discrepancy is probably the following. According to the current understanding of nuclei, an even number of nuclear particles\u2014in the case of B 11 , five neutrons together with five protons\u2014makes a kind of core; when one more particle is added to this core, it revolves around on the outside to make a new spherical nucleus, rather than being absorbed. If this is so, we should have taken a different electrostatic energy for the additional proton. We should have taken the excess energy of C 11 over B 11 to be just Z B q 2 e 4\u03c0 \u03f5 0 r 2 which is the energy needed to add one more proton to the outside of the core. This number is just 5/6 of what Eq. (8.23) predicts, so the new prediction for the radius is 5/6 of (8.24), which is in much closer agreement with what is directly measured. We can draw two conclusions from this agreement. One is that the electrical laws appear to be working at dimensions as small as 10 \u221213 cm. The other is that we have verified the remarkable coincidence that the nonelectrical part of the forces between proton and proton, neutron and neutron, and proton and neutron are all equal. We now consider other methods of calculating electrostatic energy. They can all be derived from the basic relation Eq. (8.3), the sum, over all pairs of charges, of the mutual energies of each charge-pair. First we wish to write an expression for the energy of a charge distribution. As usual, we consider that each volume element dV contains the element of charge \u03c1dV . Then Eq. (8.3) should be written U= 1 2 \u222b all space \u03c1(1)\u03c1(2) 4\u03c0 \u03f5 0 r 12 d V 1 d V 2 . (8.27) Notice the factor 1 2 , which is introduced because in the double integral over d V 1 and d V 2 we have counted all pairs of charge elements twice. (There is no convenient way of writing an integral that keeps track of the pairs so that each pair is counted only once.) Next we notice that the integral over d V 2 in (8.27) is just the potential at (1) . That is, \u222b \u03c1(2) 4\u03c0 \u03f5 0 r 12 d V 2 =\u03d5(1), \u222b ( ) so that (8.27) can be written as U= 1 2 \u222b\u03c1(1)\u03d5(1)d V 1 . \u222b Or, since the point (2) no longer appears, we can simply write U= 1 2 \u222b\u03c1\u03d5dV. (8.28) This equation can be interpreted as follows. The potential energy of the charge \u03c1dV is the product of this charge and the potential at the same point. The total energy is therefore the integral over \u03d5\u03c1dV . But there is again the factor 1 2 . It is still required because we are counting energies twice. The mutual energies of two charges is the charge of one times the potential at it due to the other. Or, it can be taken as the second charge times the potential at it from the first. Thus for two point charges we would write U= q 1 \u03d5(1)= q 1 q 2 4\u03c0 \u03f5 0 r 12 q or U= q 2 \u03d5(2)= q 2 q 1 4\u03c0 \u03f5 0 r 12 . q Notice that we could also write U= 1 2 [ q 1 \u03d5(1)+ q 2 \u03d5(2)]. (8.29) The integral in (8.28) corresponds to the sum of both terms in the brackets of (8.29). That is why we need the factor 1 2 . An interesting question is: Where is the electrostatic energy located? One might also ask: Who cares? What is the meaning of such a question? If there is a pair of interacting charges, the combination has a certain energy. Do we need to say that the energy is located at one of the charges or the other, or at both, or in between? These questions may not make sense because we really know only that the total energy is conserved. The idea that the energy is located somewhere is not necessary. Yet suppose that it did make sense to say, in general, that energy is located at a certain place, as it does for heat energy. We might then extend our principle of the conservation of energy with the idea that if the energy in a given volume changes, we should be able to account for the change by the flow of energy into or out of that volume. You realize that our early statement of the principle of the conservation of energy is still perfectly all right if some energy disappears at one place and appears somewhere else far away without anything passing (that is, without any special phenomena occurring) in the space between. We are, therefore, now discussing an extension of the idea of the conservation of energy. We might call it a principle of the local conservation of energy. Such a principle would say that the energy in any given volume changes only by the amount that flows into or out of the volume. It is indeed possible that energy is conserved locally in such a way. If it is, we would have a much more detailed law than the simple statement of the conservation of total energy. It does turn out that in nature energy is conserved locally. We can find formulas for where the energy is located and how it travels from place to place. There is also a physical reason why it is imperative that we be able to say where energy is located. According to the theory of gravitation, all mass is a source of gravitational attraction. We also know, by E=m c 2 , that mass and energy are equivalent. All energy is, therefore, a source of gravitational force. If we could not locate the energy, we could not locate all the mass. We would not be able to say where the sources of the gravitational field are located. The theory of gravitation would be incomplete. If we restrict ourselves to electrostatics there is really no way to tell where the energy is located. The complete Maxwell equations of electrodynamics give us much more information (although even then the answer is, strictly speaking, not unique.) We will therefore discuss this question in detail again in a later chapter. We will give you now only the result for the particular case of electrostatics. The energy is located in space, where the electric field is. This seems reasonable because we know that when charges are accelerated they radiate electric fields. We would like to say that when light or radiowaves travel from one point to another, they carry their energy with them. But there are no charges in the waves. So we would like to locate the energy where the electromagnetic field is and not at the charges from which it came. We thus describe the energy, not in terms of the charges, but in terms of the fields they produce. We can, in fact, show that Eq. (8.28) is numerically equal to U= \u03f5 0 2 \u222bE\u22c5EdV. (8.30) We can then interpret this formula as saying that when an electric field is present, there is located in space an energy whose density (energy per unit volume) is u= \u03f5 0 2 E\u22c5E= \u03f5 0 E 2 2 . (8.31) This idea is illustrated in Fig. 8\u20138. To show that Eq. (8.30) is consistent with our laws of electrostatics, we begin by introducing into Eq. (8.28) the relation between \u03c1 and \u03d5 that we obtained in Chapter 6: \u03c1=\u2212 \u03f5 0 \u2207 2 \u03d5. 2 We get U=\u2212 \u03f5 0 2 \u222b\u03d5 \u2207 2 \u03d5dV. (8.32) Writing out the components of the integrand, we see that \u03d5 \u2207 2 \u03d5 =\u03d5( \u2202 2 \u03d5 \u2202 x 2 + \u2202 2 \u03d5 \u2202 y 2 + \u2202 2 \u03d5 \u2202 z 2 ) = \u2202 \u2202x (\u03d5 \u2202\u03d5 \u2202x )\u2212( \u2202\u03d5 \u2202x ) 2 + \u2202 \u2202y (\u03d5 \u2202\u03d5 \u2202y )\u2212( \u2202\u03d5 \u2202y ) 2 + \u2202 \u2202z (\u03d5 \u2202\u03d5 \u2202z )\u2212( \u2202\u03d5 \u2202z ) 2 =\u2207\u22c5(\u03d5\u2207\u03d5)\u2212(\u2207\u03d5)\u22c5(\u2207\u03d5). (8.33) Our energy integral is then U= \u03f5 0 2 \u222b(\u2207\u03d5)\u22c5(\u2207\u03d5)dV\u2212 \u03f5 0 2 \u222b\u2207\u22c5(\u03d5\u2207\u03d5)dV. \u222b \u222b We can use Gauss\u2019 theorem to change the second integral into a surface integral: \u222b vol. \u2207\u22c5(\u03d5\u2207\u03d5)dV= \u222b surface (\u03d5\u2207\u03d5)\u22c5nda. (8.34) We evaluate the surface integral in the case that the surface goes to infinity (so the volume integrals become integrals over all space), supposing that all the charges are located within some finite distance. The simple way to proceed is to take a spherical surface of enormous radius R whose center is at the origin of coordinates. We know that when we are very far away from all charges, \u03d5 varies as 1/R and \u2207\u03d5 as 1/ R 2 . (Both will decrease even faster with R if there the net charge in the distribution is zero.) Since the surface area of the large sphere increases as R 2 , we see that the surface integral falls off as (1/R)(1/ R 2 ) R 2 =(1/R) as the radius of the sphere increases. So if we include all space in our integration ( R\u2192\u221e ), the surface integral goes to zero and we have that U= \u03f5 0 2 \u222b all space (\u2207\u03d5)\u22c5(\u2207\u03d5)dV= \u03f5 0 2 \u222b all space E\u22c5EdV. (8.35) We see that it is possible for us to represent the energy of any charge distribution as being the integral over an energy density located in the field. Our new relation, Eq. (8.35), says that even a single point charge q will have some electrostatic energy. In this case, the electric field is given by E= q 4\u03c0 \u03f5 0 r 2 . q So the energy density at the distance r from the charge is \u03f5 0 E 2 2 = q 2 32 \u03c0 2 \u03f5 0 r 4 . 2 We can take for an element of volume a spherical shell of thickness dr and area 4\u03c0 r 2 . The total energy is U= \u222b r=0 \u221e q 2 8\u03c0 \u03f5 0 r 2 dr= \u2212 q 2 8\u03c0 \u03f5 0 1 r \u2223 \u2223 \u2223 r=\u221e r=0 . (8.36) Now the limit at r=\u221e gives no difficulty. But for a point charge we are supposed to integrate down to r=0 , which gives an infinite integral. Equation (8.35) says that there is an infinite amount of energy in the field of a point charge, although we began with the idea that there was energy only between point charges. In our original energy formula for a collection of point charges (Eq. 8.3), we did not include any interaction energy of a charge with itself. What has happened is that when we went over to a continuous distribution of charge in Eq. (8.27), we counted the energy of interaction of every infinitesimal charge with all other infinitesimal charges. The same account is included in Eq. (8.35), so when we apply it to a finite point charge, we are including the energy it would take to assemble that charge from infinitesimal parts. You will notice, in fact, that we would also get the result in Eq. (8.36) if we used our expression (8.11) for the energy of a charged sphere and let the radius tend toward zero. We must conclude that the idea of locating the energy in the field is inconsistent with the assumption of the existence of point charges. One way out of the difficulty would be to say that elementary charges, such as an electron, are not points but are really small distributions of charge. Alternatively, we could say that there is something wrong in our theory of electricity at very small distances, or with the idea of the local conservation of energy. There are difficulties with either point of view. These difficulties have never been overcome; they exist to this day. Sometime later, when we have discussed some additional ideas, such as the momentum in an electromagnetic field, we will give a more complete account of these fundamental difficulties in our understanding of nature."
    },
    {
        "input": "Electrostatic Analogs",
        "output": "The total amount of information which has been acquired about the physical world since the beginning of scientific progress is enormous, and it seems almost impossible that any one person could know a reasonable fraction of it. But it is actually quite possible for a physicist to retain a broad knowledge of the physical world rather than to become a specialist in some narrow area. The reasons for this are threefold: First, there are great principles which apply to all the different kinds of phenomena\u2014such as the principles of the conservation of energy and of angular momentum. A thorough understanding of such principles gives an understanding of a great deal all at once. Second, there is the fact that many complicated phenomena, such as the behavior of solids under compression, really basically depend on electrical and quantum-mechanical forces, so that if one understands the fundamental laws of electricity and quantum mechanics, there is at least some possibility of understanding many of the phenomena that occur in complex situations. Finally, there is a most remarkable coincidence: The equations for many different physical situations have exactly the same appearance. Of course, the symbols may be different\u2014one letter is substituted for another\u2014but the mathematical form of the equations is the same. This means that having studied one subject, we immediately have a great deal of direct and precise knowledge about the solutions of the equations of another. We are now finished with the subject of electrostatics, and will soon go on to study magnetism and electrodynamics. But before doing so, we would like to show that while learning electrostatics we have simultaneously learned about a large number of other subjects. We will find that the equations of electrostatics appear in several other places in physics. By a direct translation of the solutions (of course the same mathematical equations must have the same solutions) it is possible to solve problems in other fields with the same ease\u2014or with the same difficulty\u2014as in electrostatics. The equations of electrostatics, we know, are \u2207\u22c5(\u03baE) = \u03c1free \u03f50 , \u2207\u00d7E =0. (We take the equations of electrostatics with dielectrics so as to have the most general situation.) The same physics can be expressed in another mathematical form: E= \u2212\u2207\u03d5, \u2207\u22c5(\u03ba\u2207\u03d5) =\u2212 \u03c1free \u03f50 . Now the point is that there are many physics problems whose mathematical equations have the same form. There is a potential (\u03d5 ) whose gradient multiplied by a scalar function (\u03ba ) has a divergence equal to another scalar function (\u2212\u03c1free/\u03f50 ). Whatever we know about electrostatics can immediately be carried over into that other subject, and vice versa. (It works both ways, of course\u2014if the other subject has some particular characteristics that are known, then we can apply that knowledge to the corresponding electrostatic problem.) We want to consider a series of examples from different subjects that produce equations of this form. We have discussed one example earlier (Section 3\u20134)\u2014the flow of heat. Imagine a block of material, which need not be homogeneous but may consist of different materials at different places, in which the temperature varies from point to point. As a consequence of these temperature variations there is a flow of heat, which can be represented by the vector h . It represents the amount of heat energy which flows per unit time through a unit area perpendicular to the flow. The divergence of h represents the rate per unit volume at which heat is leaving a region: \u2207\u22c5h=rate of heat out per unit volume. (We could, of course, write the equation in integral form\u2014just as we did in electrostatics with Gauss\u2019 law\u2014which would say that the flux through a surface is equal to the rate of change of heat energy inside the material. We will not bother to translate the equations back and forth between the differential and the integral forms, because it goes exactly the same as in electrostatics.) The rate at which heat is generated or absorbed at various places depends, of course, on the problem. Suppose, for example, that there is a source of heat inside the material (perhaps a radioactive source, or a resistor heated by an electrical current). Let us call s the heat energy produced per unit volume per second by this source. There may also be losses (or gains) of thermal energy to other internal energies in the volume. If u is the internal energy per unit volume, \u2212du/dt will also be a \u201csource\u201d of heat energy. We have, then, \u2207\u22c5h=s\u2212 du dt . We are not going to discuss just now the complete equation in which things change with time, because we are making an analogy to electrostatics, where nothing depends on the time. We will consider only steady heat-flow problems, in which constant sources have produced an equilibrium state. In these cases, \u2207\u22c5h=s. It is, of course, necessary to have another equation, which describes how the heat flows at various places. In many materials the heat current is approximately proportional to the rate of change of the temperature with position: the larger the temperature difference, the more the heat current. As we have seen, the vector heat current is proportional to the temperature gradient. The constant of proportionality K , a property of the material, is called the thermal conductivity: h=\u2212K\u2207T. If the properties of the material vary from place to place, then K=K(x,y,z) , a function of position. [Equation (12.7) is not as fundamental as (12.5), which expresses the conservation of heat energy, since the former depends upon a special property of the substance.] If now we substitute Eq. (12.7) into Eq. (12.6) we have \u2207\u22c5(K\u2207T)=\u2212s, which has exactly the same form as (12.4). Steady heat-flow problems and electrostatic problems are the same. The heat flow vector h corresponds to E , and the temperature T corresponds to \u03d5 . We have already noticed that a point heat source produces a temperature field which varies as 1/r and a heat flow which varies as 1/r2 . This is nothing more than a translation of the statements from electrostatics that a point charge generates a potential which varies as 1/r and an electric field which varies as 1/r2 . We can, in general, solve static heat problems as easily as we can solve electrostatic problems. Consider a simple example. Suppose that we have a cylinder of radius a at the temperature T 1 , maintained by the generation of heat in the cylinder. (It could be, for example, a wire carrying a current, or a pipe with steam condensing inside.) The cylinder is covered with a concentric sheath of insulating material which has a conductivity K . Say the outside radius of the insulation is b and the outside is kept at temperature T 2 (Fig. 12\u20131a). We want to find out at what rate heat will be lost by the wire, or steampipe, or whatever it is in the center. Let the total amount of heat lost from a length L of the pipe be called G \u2014which is what we are trying to find. How can we solve this problem? We have the differential equations, but since these are the same as those of electrostatics, we have really already solved the mathematical problem. The analogous problem is that of a conductor of radius a at the potential \u03d5 1 , separated from another conductor of radius b at the potential \u03d5 2 , with a concentric layer of dielectric material in between, as drawn in Fig. 12\u20131(b). Now since the heat flow h corresponds to the electric field E , the quantity G that we want to find corresponds to the flux of the electric field, i.e., the electric charge over \u03f5 0 . We have solved the electrostatic problem by using Gauss\u2019 law. We follow the same procedure for our heat-flow problem. From the symmetry of the situation, we know that h depends only on the distance from the center. So we enclose the pipe in a Gaussian cylinder of length L and radius r . From Gauss\u2019 law, we know that the heat flow h multiplied by the area 2\u03c0rL of the surface must be equal to the total amount of heat generated inside, which is what we are calling G : 2\u03c0rLh=Gorh= G 2\u03c0rL . (12.9) The heat flow is proportional to the temperature gradient: h=\u2212K\u2207T, h K \u2207 T or, in this case, the radial component of h is h=\u2212K dT dr . d T This, together with (12.9), gives dT dr =\u2212 G 2\u03c0KLr . (12.10) Integrating from r=a to r=b , we get T 2 \u2212 T 1 =\u2212 G 2\u03c0KL ln b a . (12.11) Solving for G , we find G= 2\u03c0KL( T 1 \u2212 T 2 ) ln(b/a) . (12.12) This result corresponds exactly to the result for the charge on a cylindrical condenser: Q \u03f5 0 = 2\u03c0\u03baL( \u03d5 1 \u2212 \u03d5 2 ) ln(b/a) . ( \u03d5 \u03d5 ) The problems are the same, and they have the same solutions. From our knowledge of electrostatics, we also know how much heat is lost by an insulated pipe. Let\u2019s consider another example of heat flow. Suppose we wish to know the heat flow in the neighborhood of a point source of heat located a little way beneath the surface of the earth, or near the surface of a large metal block. The localized heat source might be an atomic bomb that was set off underground, leaving an intense source of heat, or it might correspond to a small radioactive source inside a block of iron\u2014there are numerous possibilities. We will treat the idealized problem of a point heat source of strength G at the distance a beneath the surface of an infinite block of uniform material whose thermal conductivity is K . And we will neglect the thermal conductivity of the air outside the material. We want to determine the distribution of the temperature on the surface of the block. How hot is it right above the source and at various places on the surface of the block? How shall we solve it? It is like an electrostatic problem with two materials with different dielectric coefficients \u03ba on opposite sides of a plane boundary. Aha! Perhaps it is the analog of a point charge near the boundary between a dielectric and a conductor, or something similar. Let\u2019s see what the situation is near the surface. The physical condition is that the normal component of h on the surface is zero, since we have assumed there is no heat flow out of the block. We should ask: In what electrostatic problem do we have the condition that the normal component of the electric field E (which is the analog of h ) is zero at a surface? There is none! That is one of the things that we have to watch out for. For physical reasons, there may be certain restrictions in the kinds of mathematical conditions which arise in any one subject. So if we have analyzed the differential equation only for certain limited cases, we may have missed some kinds of solutions that can occur in other physical situations. For example, there is no material with a dielectric constant of zero, whereas a vacuum does have zero thermal conductivity. So there is no electrostatic analogy for a perfect heat insulator. We can, however, still use the same methods. We can try to imagine what would happen if the dielectric constant were zero. (Of course, the dielectric constant is never zero in any real situation. But we might have a case in which there is a material with a very high dielectric constant, so that we could neglect the dielectric constant of the air outside.) How shall we find an electric field that has no component perpendicular to the surface? That is, one which is always tangent at the surface? You will notice that our problem is opposite to the one of a point charge near a plane conductor. There we wanted the field to be perpendicular to the surface, because the conductor was all at the same potential. In the electrical problem, we invented a solution by imagining a point charge behind the conducting plate. We can use the same idea again. We try to pick an \u201cimage source\u201d that will automatically make the normal component of the field zero at the surface. The solution is shown in Fig. 12\u20132. An image source of the same sign and the same strength placed at the distance a above the surface will cause the field to be always horizontal at the surface. The normal components of the two sources cancel out. Thus our heat flow problem is solved. The temperature everywhere is the same, by direct analogy, as the potential due to two equal point charges! The temperature T at the distance r from a single point source G in an infinite medium is T= G 4\u03c0Kr . (12.13) (This, of course, is just the analog of \u03d5=q/4\u03c0 \u03f5 0 R .) The temperature for a point source, together with its image source, is T= G 4\u03c0K r 1 + G 4\u03c0K r 2 . (12.14) This formula gives us the temperature everywhere in the block. Several isothermal surfaces are shown in Fig. 12\u20132. Also shown are lines of h , which can be obtained from h=\u2212K\u2207T . We originally asked for the temperature distribution on the surface. For a point on the surface at the distance \u03c1 from the axis, r 1 = r 2 = \u03c1 2 + a 2 \u2212 \u2212 \u2212 \u2212 \u2212 \u2212 \u221a , so T(surface)= 1 4\u03c0K 2G \u03c1 2 + a 2 \u2212 \u2212 \u2212 \u2212 \u2212 \u2212 \u221a . (12.15) This function is also shown in the figure. The temperature is, naturally, higher right above the source than it is farther away. This is the kind of problem that geophysicists often need to solve. We now see that it is the same kind of thing we have already been solving for electricity. Now let us consider a completely different physical situation which, nevertheless, gives the same equations again. Consider a thin rubber sheet\u2014a membrane\u2014which has been stretched over a large horizontal frame (like a drumhead). Suppose now that the membrane is pushed up in one place and down in another; as shown in Fig. 12\u20133. Can we describe the shape of the surface? We will show how the problem can be solved when the deflections of the membrane are not too large. There are forces in the sheet because it is stretched. If we were to make a small cut anywhere, the two sides of the cut would pull apart (see Fig. 12\u20134). So there is a surface tension in the sheet, analogous to the one-dimensional tension in a stretched string. We define the magnitude of the surface tension \u03c4 as the force per unit length which will just hold together the two sides of a cut such as one of those shown in Fig. 12\u20134. Suppose now that we look at a vertical cross section of the membrane. It will appear as a curve, like the one in Fig. 12\u20135. Let u be the vertical displacement of the membrane from its normal position, and x and y the coordinates in the horizontal plane. (The cross section shown is parallel to the x -axis.) Consider a little piece of the surface of length \u0394x and width \u0394y . There will be forces on the piece from the surface tension along each edge. The force along edge 1 of the figure will be \u03c4 1 \u0394y , directed tangent to the surface\u2014that is, at the angle \u03b8 1 from the horizontal. Along edge 2 , the force will be \u03c4 2 \u0394y at the angle \u03b8 2 . (There will be similar forces on the other two edges of the piece, but we will forget them for the moment.) The net upward force on the piece from edges 1 and 2 is \u0394F= \u03c4 2 \u0394ysin \u03b8 2 \u2212 \u03c4 1 \u0394ysin \u03b8 1 . \u0394 F \u0394 sin \u03b8 \u0394 sin \u03b8 We will limit our considerations to small distortions of the membrane, i.e., to small slopes: we can then replace sin\u03b8 by tan\u03b8 , which can be written as \u2202u/\u2202x . The force is then \u0394F=[ \u03c4 2 ( \u2202u \u2202x ) 2 \u2212 \u03c4 1 ( \u2202u \u2202x ) 1 ]\u0394y. \u2202 \u2202 The quantity in brackets can be equally well written (for small \u0394x ) as \u2202 \u2202x (\u03c4 \u2202u \u2202x )\u0394x; \u2202 \u2202 then \u0394F= \u2202 \u2202x (\u03c4 \u2202u \u2202x )\u0394x\u0394y. \u2202 \u2202 There will be another contribution to \u0394F from the forces on the other two edges; the total is evidently \u0394F=[ \u2202 \u2202x (\u03c4 \u2202u \u2202x )+ \u2202 \u2202y (\u03c4 \u2202u \u2202y )]\u0394x\u0394y. (12.16) The distortions of the diaphragm are caused by external forces. Let\u2019s let f represent the upward force per unit area on the sheet (a kind of \u201cpressure\u201d) from the external forces. When the membrane is in equilibrium (the static case), this force must be balanced by the internal force we have just computed, Eq. (12.16). That is f=\u2212 \u0394F \u0394x\u0394y . \u0394 F Equation (12.16) can then be written f=\u2212\u2207\u22c5(\u03c4\u2207u), (12.17) where by \u2207 we now mean, of course, the two-dimensional gradient operator (\u2202/\u2202x,\u2202/\u2202y) . We have the differential equation that relates u(x,y) to the applied forces f(x,y) and the surface tension \u03c4(x,y) , which may, in general, vary from place to place in the sheet. (The distortions of a three-dimensional elastic body are also governed by similar equations, but we will stick to two-dimensions.) We will worry only about the case in which the tension \u03c4 is constant throughout the sheet. We can then write for Eq. (12.17), \u2207 2 u=\u2212 f \u03c4 . (12.18) We have another equation that is the same as for electrostatics!\u2014only this time, limited to two-dimensions. The displacement u corresponds to \u03d5 , and f/\u03c4 corresponds to \u03c1/ \u03f5 0 . So all the work we have done for infinite plane charged sheets, or long parallel wires, or charged cylinders is directly applicable to the stretched membrane. Suppose we push the membrane at some points up to a definite height\u2014that is, we fix the value of u at some places. That is the analog of having a definite potential at the corresponding places in an electrical situation. So, for instance, we may make a positive \u201cpotential\u201d by pushing up on the membrane with an object having the cross-sectional shape of the corresponding cylindrical conductor. For example, if we push the sheet up with a round rod, the surface will take on the shape shown in Fig. 12\u20136. The height u is the same as the electrostatic potential \u03d5 of a charged cylindrical rod. It falls off as ln(1/r) . (The slope, which corresponds to the electric field E , drops off as 1/r .) The stretched rubber sheet has often been used as a way of solving complicated electrical problems experimentally. The analogy is used backwards! Various rods and bars are pushed against the sheet to heights that correspond to the potentials of a set of electrodes. Measurements of the height then give the electrical potential for the electrical situation. The analogy has been carried even further. If little balls are placed on the membrane, their motion corresponds approximately to the motion of electrons in the corresponding electric field. One can actually watch the \u201celectrons\u201d move on their trajectories. This method was used to design the complicated geometry of many photomultiplier tubes (such as the ones used for scintillation counters, and the one used for controlling the headlight beams on Cadillacs). The method is still used, but the accuracy is limited. For the most accurate work, it is better to determine the fields by numerical methods, using the large electronic computing machines. We take another example that gives the same kind of equation, this time having to do with diffusion. In Chapter 43 of Vol. I we considered the diffusion of ions in a single gas, and of one gas through another. This time, let\u2019s take a different example\u2014the diffusion of neutrons in a material like graphite. We choose to speak of graphite (a pure form of carbon) because carbon doesn\u2019t absorb slow neutrons. In it the neutrons are free to wander around. They travel in a straight line for several centimeters, on the average, before being scattered by a nucleus and deflected into a new direction. So if we have a large block\u2014many meters on a side\u2014the neutrons initially at one place will diffuse to other places. We want to find a description of their average behavior\u2014that is, their average flow. Let N(x,y,z)\u0394V be the number of neutrons in the element of volume \u0394V at the point (x,y,z) . Because of their motion, some neutrons will be leaving \u0394V , and others will be coming in. If there are more neutrons in one region than in a nearby region, more neutrons will go from the first region to the second than come back; there will be a net flow. Following the arguments of Chapter 43 in Vol. I, we describe the flow by a flow vector J . Its x -component J x is the net number of neutrons that pass in unit time a unit area perpendicular to the x -direction. We found that J x =\u2212D \u2202N \u2202x , (12.19) where the diffusion constant D is given in terms of the mean velocity v , and the mean-free-path l between scatterings is given by D= 1 3 lv. 1 The vector equation for J is J=\u2212D\u2207N. (12.20) The rate at which neutrons flow across any surface element da is J\u22c5nda (where, as usual, n is the unit normal). The net flow out of a volume element is then (following the usual Gaussian argument) \u2207\u22c5JdV . This flow would result in a decrease with time of the number in \u0394V unless neutrons are being created in \u0394V (by some nuclear process). If there are sources in the volume that generate S neutrons per unit time in a unit volume, then the net flow out of \u0394V will be equal to (S\u2212\u2202N/\u2202t)\u0394V . We have then that \u2207\u22c5J=S\u2212 \u2202N \u2202t . (12.21) Combining (12.21) with (12.20), we get the neutron diffusion equation \u2207\u22c5(\u2212D\u2207N)=S\u2212 \u2202N \u2202t . (12.22) In the static case\u2014where \u2202N/\u2202t=0 \u2014we have Eq. (12.4) all over again! We can use our knowledge of electrostatics to solve problems about the diffusion of neutrons. So let\u2019s solve a problem. (You may wonder: Why do a problem if we have already done all the problems in electrostatics? We can do it faster this time because we have done the electrostatic problems!) Suppose we have a block of material in which neutrons are being generated\u2014say by uranium fission\u2014uniformly throughout a spherical region of radius a (Fig. 12\u20137). We would like to know: What is the density of neutrons everywhere? How uniform is the density of neutrons in the region where they are being generated? What is the ratio of the neutron density at the center to the neutron density at the surface of the source region? Finding the answers is easy. The source density S 0 replaces the charge density \u03c1 , so our problem is the same as the problem of a sphere of uniform charge density. Finding N is just like finding the potential \u03d5 . We have already worked out the fields inside and outside of a uniformly charged sphere; we can integrate them to get the potential. Outside, the potential is Q/4\u03c0 \u03f5 0 r , with the total charge Q given by 4\u03c0 a 3 \u03c1/3 . So \u03d5 outside = \u03c1 a 3 3 \u03f5 0 r . (12.23) For points inside, the field is due only to the charge Q(r) inside the sphere of radius r , Q(r)=4\u03c0 r 3 \u03c1/3 , so E= \u03c1r 3 \u03f5 0 . (12.24) The field increases linearly with r . Integrating E to get \u03d5 , we have \u03d5 inside =\u2212 \u03c1 r 2 6 \u03f5 0 +a constant. 2 At the radius a , \u03d5 inside must be the same as \u03d5 outside , so the constant must be \u03c1 a 2 /2 \u03f5 0 . (We are assuming that \u03d5 is zero at large distances from the source, which will correspond to N being zero for the neutrons.) Therefore, \u03d5 inside = \u03c1 3 \u03f5 0 ( 3 a 2 2 \u2212 r 2 2 ). (12.25) We know immediately the neutron density in our other problem. The answer is N outside = S a 3 3Dr , (12.26) and N inside = S 3D ( 3 a 2 2 \u2212 r 2 2 ). (12.27) N is shown as a function of r in Fig. 12\u20137. Now what is the ratio of density at the center to that at the edge? At the center ( r=0 ), it is proportional to 3 a 2 /2 . At the edge ( r=a ) it is proportional to 2 a 2 /2 , so the ratio of densities is 3/2 . A uniform source doesn\u2019t produce a uniform density of neutrons. You see, our knowledge of electrostatics gives us a good start on the physics of nuclear reactors. There are many physical circumstances in which diffusion plays a big part. The motion of ions through a liquid, or of electrons through a semiconductor, obeys the same equation. We find again and again the same equations. Let\u2019s now consider an example which is not really a very good one, because the equations we will use will not really represent the subject with complete generality but only in an artificial idealized situation. We take up the problem of water flow. In the case of the stretched sheet, our equations were an approximation which was correct only for small deflections. For our consideration of water flow, we will not make that kind of an approximation; we must make restrictions that do not apply at all to real water. We treat only the case of the steady flow of an incompressible, nonviscous, circulation-free liquid. Then we represent the flow by giving the velocity v(r) as a function of position r . If the motion is steady (the only case for which there is an electrostatic analog) v is independent of time. If \u03c1 is the density of the fluid, then \u03c1v is the amount of mass which passes per unit time through a unit area. By the conservation of matter, the divergence of \u03c1v will be, in general, the time rate of change of the mass of the material per unit volume. We will assume that there are no processes for the continuous creation or destruction of matter. The conservation of matter then requires that \u2207\u22c5\u03c1v=0 . (It should, in general, be equal to \u2212\u2202\u03c1/\u2202t , but since our fluid is incompressible, \u03c1 cannot change.) Since \u03c1 is everywhere the same, we can factor it out, and our equation is simply \u2207\u22c5v=0. \u2207 0. Good! We have electrostatics again (with no charges); it\u2019s just like \u2207\u22c5E=0 . Not so! Electrostatics is not simply \u2207\u22c5E=0 . It is a pair of equations. One equation does not tell us enough; we need still an additional equation. To match electrostatics, we should have also that the curl of v is zero. But that is not generally true for real liquids. Most liquids will ordinarily develop some circulation. So we are restricted to the situation in which there is no circulation of the fluid. Such flow is often called irrotational. Anyway, if we make all our assumptions, we can imagine a case of fluid flow that is analogous to electrostatics. So we take \u2207\u22c5v=0 (12.28) and \u2207\u00d7v=0. (12.29) We want to emphasize that the number of circumstances in which liquid flow follows these equations is far from the great majority, but there are a few. They must be cases in which we can neglect surface tension, compressibility, and viscosity, and in which we can assume that the flow is irrotational. These assumptions are valid so rarely for real water that the mathematician John von Neumann said that people who analyze Eqs. (12.28) and (12.29) are studying \u201cdry water\u201d! (We take up the problem of fluid flow in more detail in Chapters 40 and 41.) Because \u2207\u00d7v=0 , the velocity of \u201cdry water\u201d can be written as the gradient of some potential: v=\u2212\u2207\u03c8. (12.30) What is the physical meaning of \u03c8 ? There isn\u2019t any very useful meaning. The velocity can be written as the gradient of a potential simply because the flow is irrotational. And by analogy with electrostatics, \u03c8 is called the velocity potential, but it is not related to a potential energy in the way that \u03d5 is. Since the divergence of v is zero, we have \u2207\u22c5(\u2207\u03c8)= \u2207 2 \u03c8=0. (12.31) The velocity potential \u03c8 obeys the same differential equation as the electrostatic potential in free space ( \u03c1=0 ). Let\u2019s pick a problem in irrotational flow and see whether we can solve it by the methods we have learned. Consider the problem of a spherical ball falling through a liquid. If it is going too slowly, the viscous forces, which we are disregarding, will be important. If it is going too fast, little whirlpools (turbulence) will appear in its wake and there will be some circulation of the water. But if the ball is going neither too fast nor too slow, it is more or less true that the water flow will fit our assumptions, and we can describe the motion of the water by our simple equations. It is convenient to describe what happens in a frame of reference fixed in the sphere. In this frame we are asking the question: How does water flow past a sphere at rest when the flow at large distances is uniform? That is, when, far from the sphere, the flow is everywhere the same. The flow near the sphere will be as shown by the streamlines drawn in Fig. 12\u20138. These lines, always parallel to v , correspond to lines of electric field. We want to get a quantitative description for the velocity field, i.e., an expression for the velocity at any point P . We can find the velocity from the gradient of \u03c8 , so we first work out the potential. We want a potential that satisfies Eq. (12.31) everywhere, and which also satisfies two restrictions: (1) there is no flow in the spherical region inside the surface of the ball, and (2) the flow is constant at large distances. To satisfy (1), the component of v normal to the surface of the sphere must be zero. That means that \u2202\u03c8/\u2202r is zero at r=a . To satisfy (2), we must have \u2202\u03c8/\u2202z= v 0 at all points where r\u226ba . Strictly speaking, there is no electrostatic case which corresponds exactly to our problem. It really corresponds to putting a sphere of dielectric constant zero in a uniform electric field. If we had worked out the solution to the problem of a sphere of a dielectric constant \u03ba in a uniform field, then by putting \u03ba=0 we would immediately have the solution to this problem. We have not actually worked out this particular electrostatic problem in detail, but let\u2019s do it now. (We could work directly on the fluid problem with v and \u03c8 , but we will use E and \u03d5 because we are so used to them.) The problem is: Find a solution of \u2207 2 \u03d5=0 such that E=\u2212\u2207\u03d5 is a constant, say E 0 , for large r , and such that the radial component of E is equal to zero at r=a . That is, \u2202\u03d5 \u2202r \u2223 \u2223 \u2223 r=a =0. (12.32) Our problem involves a new kind of boundary condition, not one for which \u03d5 is a constant on a surface, but for which \u2202\u03d5/\u2202r is a constant. That is a little different. It is not easy to get the answer immediately. First of all, without the sphere, \u03d5 would be \u2212 E 0 z . Then E would be in the z -direction and have the constant magnitude E 0 , everywhere. Now we have analyzed the case of a dielectric sphere which has a uniform polarization inside it, and we found that the field inside such a polarized sphere is a uniform field, and that outside it is the same as the field of a point dipole located at the center. So let\u2019s guess that the solution we want is a superposition of a uniform field plus the field of a dipole. The potential of a dipole (Chapter 6) is pz/4\u03c0 \u03f5 0 r 3 . Thus we assume that \u03d5=\u2212 E 0 z+ pz 4\u03c0 \u03f5 0 r 3 . (12.33) Since the dipole field falls off as 1/ r 3 , at large distances we have just the field E 0 . Our guess will automatically satisfy condition (2) above. But what do we take for the dipole strength p ? To find out, we may use the other condition on \u03d5 , Eq. (12.32). We must differentiate \u03d5 with respect to r , but of course we must do so at a constant angle \u03b8 , so it is more convenient if we first express \u03d5 in terms of r and \u03b8 , rather than of z and r . Since z=rcos\u03b8 , we get \u03d5=\u2212 E 0 rcos\u03b8+ pcos\u03b8 4\u03c0 \u03f5 0 r 2 . (12.34) The radial component of E is \u2212 \u2202\u03d5 \u2202r =+ E 0 cos\u03b8+ pcos\u03b8 2\u03c0 \u03f5 0 r 3 . (12.35) This must be zero at r=a for all \u03b8 . This will be true if p=\u22122\u03c0 \u03f5 0 a 3 E 0 . (12.36) Note carefully that if both terms in Eq. (12.35) had not had the same \u03b8 -dependence, it would not have been possible to choose p so that (12.35) turned out to be zero at r=a for all angles. The fact that it works out means that we have guessed wisely in writing Eq. (12.33). Of course, when we made the guess we were looking ahead; we knew that we would need another term that (a) satisfied \u2207 2 \u03d5=0 (any real field would do that), (b) dependent on cos\u03b8 , and (c) fell to zero at large r . The dipole field is the only one that does all three. Using (12.36), our potential is \u03d5=\u2212 E 0 cos\u03b8(r+ a 3 2 r 2 ). (12.37) The solution of the fluid flow problem can be written simply as \u03c8=\u2212 v 0 cos\u03b8(r+ a 3 2 r 2 ). (12.38) It is straightforward to find v from this potential. We will not pursue the matter further. In this section we turn to a completely different physical problem\u2014we want to illustrate the great variety of possibilities. This time we will do something that leads to the same kind of integral that we found in electrostatics. (If we have a mathematical problem which gives us a certain integral, then we know something about the properties of that integral if it is the same integral that we had to do for another problem.) We take our example from illumination engineering. Suppose there is a light source at the distance z above a plane surface. What is the illumination of the surface? That is, what is the radiant energy per unit time arriving at a unit area of the surface? (See Fig. 12\u20139.) We suppose that the source is spherically symmetric, so that light is radiated equally in all directions. Then the amount of radiant energy which passes through a unit area at right angles to a light flow varies inversely as the square of the distance. It is evident that the intensity of the light in the direction normal to the flow is given by the same kind of formula as for the electric field from a point source. If the light rays meet the surface at an angle \u03b8 to the normal, then I n , the energy arriving per unit area of the surface, is only cos\u03b8 as great, because the same energy goes onto an area larger by 1/cos\u03b8 . If we call the strength of our light source S , then I n , the illumination of a surface, is I n = S r 2 e r \u22c5n, (12.39) where e r is the unit vector from the source and n is the unit normal to the surface. The illumination I n corresponds to the normal component of the electric field from a point charge of strength 4\u03c0 \u03f5 0 S . Knowing that, we see that for any distribution of light sources, we can find the answer by solving the corresponding electrostatic problem. We calculate the vertical component of electric field on the plane due to a distribution of charge in the same way as for that of the light sources.1 Consider the following example. We wish for some special experimental situation to arrange that the top surface of a table will have a very uniform illumination. We have available long tubular fluorescent lights which radiate uniformly along their lengths. We can illuminate the table by placing the fluorescent tubes in a regular array on the ceiling, which is at the height z above the table. What is the widest spacing b from tube to tube that we should use if we want the surface illumination to be uniform to, say, within one part in a thousand? Answer: (1) Find the electric field from a grid of wires with the spacing b , each charged uniformly; (2) compute the vertical component of the electric field; (3) find out what b must be so that the ripples of the field are not more than one part in a thousand. In Chapter 7 we saw that the electric field of a grid of charged wires could be represented as a sum of terms, each one of which gave a sinusoidal variation of the field with a period of b/n , where n is an integer. The amplitude of any one of these terms is given by Eq. (7.44): F n = A n e \u22122\u03c0nz/b . 2 / b We need consider only n=1 , so long as we only want the field at points not too close to the grid. For a complete solution, we would still need to determine the coefficients A n , which we have not yet done (although it is a straightforward calculation). Since we need only A 1 , we can estimate that its magnitude is roughly the same as that of the average field. The exponential factor would then give us directly the relative amplitude of the variations. If we want this factor to be 10 \u22123 , we find that b must be 0.91z . If we make the spacing of the fluorescent tubes 3/4 of the distance to the ceiling, the exponential factor is then 1/4000 , and we have a safety factor of 4 , so we are fairly sure that we will have the illumination constant to one part in a thousand. (An exact calculation shows that A 1 is really twice the average field, so that b\u22480.83z .) It is somewhat surprising that for such a uniform illumination the allowed separation of the tubes comes out so large. In this chapter, we wished to show that in learning electrostatics you have learned at the same time how to handle many subjects in physics, and that by keeping this in mind, it is possible to learn almost all of physics in a limited number of years. However, a question surely suggests itself at the end of such a discussion: Why are the equations from different phenomena so similar? We might say: \u201cIt is the underlying unity of nature.\u201d But what does that mean? What could such a statement mean? It could mean simply that the equations are similar for different phenomena; but then, of course, we have given no explanation. The \u201cunderlying unity\u201d might mean that everything is made out of the same stuff, and therefore obeys the same equations. That sounds like a good explanation, but let us think. The electrostatic potential, the diffusion of neutrons, heat flow\u2014are we really dealing with the same stuff? Can we really imagine that the electrostatic potential is physically identical to the temperature, or to the density of particles? Certainly \u03d5 is not exactly the same as the thermal energy of particles. The displacement of a membrane is certainly not like a temperature. Why, then, is there \u201can underlying unity\u201d? A closer look at the physics of the various subjects shows, in fact, that the equations are not really identical. The equation we found for neutron diffusion is only an approximation that is good when the distance over which we are looking is large compared with the mean free path. If we look more closely, we would see the individual neutrons running around. Certainly the motion of an individual neutron is a completely different thing from the smooth variation we get from solving the differential equation. The differential equation is an approximation, because we assume that the neutrons are smoothly distributed in space. Is it possible that this is the clue? That the thing which is common to all the phenomena is the space, the framework into which the physics is put? As long as things are reasonably smooth in space, then the important things that will be involved will be the rates of change of quantities with position in space. That is why we always get an equation with a gradient. The derivatives must appear in the form of a gradient or a divergence; because the laws of physics are independent of direction, they must be expressible in vector form. The equations of electrostatics are the simplest vector equations that one can get which involve only the spatial derivatives of quantities. Any other simple problem\u2014or simplification of a complicated problem\u2014must look like electrostatics. What is common to all our problems is that they involve space and that we have imitated what is actually a complicated phenomenon by a simple differential equation. That leads us to another interesting question. Is the same statement perhaps also true for the electrostatic equations? Are they also correct only as a smoothed-out imitation of a really much more complicated microscopic world? Could it be that the real world consists of little X-ons which can be seen only at very tiny distances? And that in our measurements we are always observing on such a large scale that we can\u2019t see these little X-ons, and that is why we get the differential equations? Our currently most complete theory of electrodynamics does indeed have its difficulties at very short distances. So it is possible, in principle, that these equations are smoothed-out versions of something. They appear to be correct at distances down to about 10 \u221214 cm, but then they begin to look wrong. It is possible that there is some as yet undiscovered underlying \u201cmachinery,\u201d and that the details of an underlying complexity are hidden in the smooth-looking equations\u2014as is so in the \u201csmooth\u201d diffusion of neutrons. But no one has yet formulated a successful theory that works that way. Strangely enough, it turns out (for reasons that we do not at all understand) that the combination of relativity and quantum mechanics as we know them seems to forbid the invention of an equation that is fundamentally different from Eq. (12.4), and which does not at the same time lead to some kind of contradiction. Not simply a disagreement with experiment, but an internal contradiction. As, for example, the prediction that the sum of the probabilities of all possible occurrences is not equal to unity, or that energies may sometimes come out as complex numbers, or some other such idiocy. No one has yet made up a theory of electricity for which \u2207 2 \u03d5=\u2212\u03c1/ \u03f5 0 is understood as a smoothed-out approximation to a mechanism underneath, and which does not lead ultimately to some kind of an absurdity. But, it must be added, it is also true that the assumption that \u2207 2 \u03d5=\u2212\u03c1/ \u03f5 0 is valid for all distances, no matter how small, leads to absurdities of its own (the electrical energy of an electron is infinite)\u2014absurdities from which no one yet knows an escape."
    },
    {
        "input": "Spin One",
        "output": "In this chapter we really begin the quantum mechanics proper\u2014in the sense that we are going to describe a quantum mechanical phenomenon in a completely quantum mechanical way. We will make no apologies and no attempt to find connections to classical mechanics. We want to talk about something new in a new language. The particular situation which we are going to describe is the behavior of the so-called quantization of the angular momentum, for a particle of spin one. But we won\u2019t use words like \u201cangular momentum\u201d or other concepts of classical mechanics until later. We have chosen this particular example because it is relatively simple, although not the simplest possible example. It is sufficiently complicated that it can stand as a prototype which can be generalized for the description of all quantum mechanical phenomena. Thus, although we are dealing with a particular example, all the laws which we mention are immediately generalizable, and we will give the generalizations so that you will see the general characteristics of a quantum mechanical description. We begin with the phenomenon of the splitting of a beam of atoms into three separate beams in a Stern-Gerlach experiment. You remember that if we have an inhomogeneous magnetic field made by a magnet with a pointed pole tip and we send a beam through the apparatus, the beam of particles may be split into a number of beams\u2014the number depending on the particular kind of atom and its state. We are going to take the case of an atom which gives three beams, and we are going to call that a particle of spin one. You can do for yourself the case of five beams, seven beams, two beams, etc.\u2014you just copy everything down and where we have three terms, you will have five terms, seven terms, and so on. Imagine the apparatus drawn schematically in Fig. 5\u20131. A beam of atoms (or particles of any kind) is collimated by some slits and passes through a nonuniform field. Let\u2019s say that the beam moves in the y -direction and that the magnetic field and its gradient are both in the z -direction. Then, looking from the side, we will see the beam split vertically into three beams, as shown in the figure. Now at the output end of the magnet we could put small counters which count the rate of arrival of particles in any one of the three beams. Or we can block off two of the beams and let the third one go on. Suppose we block off the lower two beams and let the top-most beam go on and enter a second Stern-Gerlach apparatus of the same kind, as shown in Fig. 5\u20132. What happens? There are not three beams in the second apparatus; there is only the top beam.1 This is what you would expect if you think of the second apparatus as simply an extension of the first. Those atoms which are being pushed upward continue to be pushed upward in the second magnet. You can see then that the first apparatus has produced a beam of \u201cpurified\u201d objects\u2014atoms that get bent upward in the particular inhomogeneous field. The atoms, as they enter the original Stern-Gerlach apparatus, are of three \u201cvarieties,\u201d and the three kinds take different trajectories. By filtering out all but one of the varieties, we can make a beam whose future behavior in the same kind of apparatus is determined and predictable. We will call this a filtered beam, or a polarized beam, or a beam in which the atoms all are known to be in a definite state. For the rest of our discussion, it will be more convenient if we consider a somewhat modified apparatus of the Stern-Gerlach type. The apparatus looks more complicated at first, but it will make all the arguments simpler. Anyway, since they are only \u201cthought experiments,\u201d it doesn\u2019t cost anything to complicate the equipment. (Incidentally, no one has ever done all of the experiments we will describe in just this way, but we know what would happen from the laws of quantum mechanics, which are, of course, based on other similar experiments. These other experiments are harder to understand at the beginning, so we want to describe some idealized\u2014but possible\u2014experiments.) Figure 5\u20133(a) shows a drawing of the \u201cmodified Stern-Gerlach apparatus\u201d we would like to use. It consists of a sequence of three high-gradient magnets. The first one (on the left) is just the usual Stern-Gerlach magnet and splits the incoming beam of spin-one particles into three separate beams. The second magnet has the same cross section as the first, but is twice as long and the polarity of its magnetic field is opposite the field in magnet 1 . The second magnet pushes in the opposite direction on the atomic magnets and bends their paths back toward the axis, as shown in the trajectories drawn in the lower part of the figure. The third magnet is just like the first, and brings the three beams back together again, so that leaves the exit hole along the axis. Finally, we would like to imagine that in front of the hole at A there is some mechanism which can get the atoms started from rest and that after the exit hole at B there is a decelerating mechanism that brings the atoms back to rest at B . That is not essential, but it will mean that in our analysis we won\u2019t have to worry about including any effects of the motion as the atoms come out, and can concentrate on those matters having only to do with the spin. The whole purpose of the \u201cimproved\u201d apparatus is just to bring all the particles to the same place, and with zero speed. Now if we want to do an experiment like the one in Fig. 5\u20132, we can first make a filtered beam by putting a plate in the middle of the apparatus that blocks two of the beams, as shown in Fig. 5\u20134. If we now put the polarized atoms through a second identical apparatus, all the atoms will take the upper path, as can be verified by putting similar plates in the way of the various beams of the second S filter and seeing whether particles get through. Suppose we call the first apparatus by the name S . (We are going to consider all sorts of combinations, and we will need labels to keep things straight.) We will say that the atoms which take the top path in S are in the \u201cplus state with respect to S \u201d; the ones which take the middle path are in the \u201czero state with respect to S \u201d; and the ones which take the lowest path are in the \u201cminus state with respect to S .\u201d (In the more usual language we would say that the z -component of the angular momentum was +1\u210f , 0 , and \u22121\u210f , but we are not using that language now.) Now in Fig. 5\u20134 the second apparatus is oriented just like the first, so the filtered atoms will all go on the upper path. Or if we had blocked off the upper and lower beams in the first apparatus and let only the zero state through, all the filtered atoms would go through the middle path of the second apparatus. And if we had blocked off all but the lowest beam in the first, there would be only a low beam in the second. We can say that in each case our first apparatus has produced a filtered beam in a pure state with respect to S (+ , 0 , or \u2212 ), and we can test which state is present by putting the atoms through a second, identical apparatus. We can make our second apparatus so that it transmits only atoms of a particular state\u2014by putting masks inside it as we did for the first one\u2014and then we can test the state of the incoming beam just by seeing whether anything comes out the far end. For instance, if we block off the two lower paths in the second apparatus, 100 percent of the atoms will still come through; but if we block off the upper path, nothing will get through. To make this kind of discussion easier, we are going to invent a shorthand symbol to represent one of our improved Stern-Gerlach apparatuses. We will let the symbol { + 0 \u2212 } S stand for one complete apparatus. (This is not a symbol you will ever find used in quantum mechanics; we\u2019ve just invented it for this chapter. It is simply meant to be a shorthand picture of the apparatus of Fig. 5\u20133.) Since we are going to want to use several apparatuses at once, and with various orientations, we will identify each with a letter underneath. So the symbol in (5.1) stands for the apparatus S . When we block off one or more of the beams inside, we will show that by some vertical bars indicating which beam is blocked, like this: { + 0 \u2212 } S \u22c5 The various possible combinations we will be using are shown in Fig. 5\u20135. If we have two filters in succession (as in Fig. 5\u20134), we will put the two symbols next to each other, like this: \u23a7 \u23a9 \u23a8 \u23aa \u23aa + 0 \u2212 \u23ab \u23ad \u23ac \u23aa \u23aa S \u23a7 \u23a9 \u23a8 \u23aa \u23aa + 0 \u2212 \u23ab \u23ad \u23ac \u23aa \u23aa S \u22c5 (5.3) For this setup, everything that comes through the first also gets through the second. In fact, even if we block off the \u201czero\u201d and \u201cminus\u201d channels of the second apparatus, so that we have \u23a7 \u23a9 \u23a8 \u23aa \u23aa + 0 \u2212 \u23ab \u23ad \u23ac \u23aa \u23aa S \u23a7 \u23a9 \u23a8 \u23aa \u23aa + 0 \u2212 \u23ab \u23ad \u23ac \u23aa \u23aa S , (5.4) we still get 100 percent transmission through the second apparatus. On the other hand, if we have \u23a7 \u23a9 \u23a8 \u23aa \u23aa + 0 \u2212 \u23ab \u23ad \u23ac \u23aa \u23aa S \u23a7 \u23a9 \u23a8 \u23aa \u23aa + 0 \u2212 \u23ab \u23ad \u23ac \u23aa \u23aa S , (5.5) nothing at all comes out of the far end. Similarly, \u23a7 \u23a9 \u23a8 \u23aa \u23aa + 0 \u2212 \u23ab \u23ad \u23ac \u23aa \u23aa S \u23a7 \u23a9 \u23a8 \u23aa \u23aa + 0 \u2212 \u23ab \u23ad \u23ac \u23aa \u23aa S (5.6) would give nothing out. On the other hand, \u23a7 \u23a9 \u23a8 \u23aa \u23aa + 0 \u2212 \u23ab \u23ad \u23ac \u23aa \u23aa S \u23a7 \u23a9 \u23a8 \u23aa \u23aa + 0 \u2212 \u23ab \u23ad \u23ac \u23aa \u23aa S (5.7) would be just equivalent to \u23a7 \u23a9 \u23a8 \u23aa \u23aa + 0 \u2212 \u23ab \u23ad \u23ac \u23aa \u23aa S by itself. Now we want to describe these experiments quantum mechanically. We will say that an atom is in the (+S) state if it has gone through the apparatus of Fig. 5\u20135(b), that it is in a (0S) state if it has gone through (c), and in a (\u2212S) state if it has gone through (d).2 Then we let \u27e8b|a\u27e9 be the amplitude that an atom which is in state a will get through an apparatus into the b state. We can say: \u27e8b|a\u27e9 is the amplitude for an atom in the state a to get into the state b . The experiment (5.4) gives us that \u27e8+S|+S\u27e9=1, \u27e8 | \u27e9 whereas (5.5) gives us \u27e8\u2212S|+S\u27e9=0. \u27e8 | \u27e9 Similarly, the result of (5.6) is \u27e8+S|\u2212S\u27e9=0, \u27e8 | \u27e9 and of (5.7) is \u27e8\u2212S|\u2212S\u27e9=1. \u27e8 | \u27e9 As long as we deal only with \u201cpure\u201d states\u2014that is, we have only one channel open\u2014there are nine such amplitudes, and we can write them in a table: to from +S 0S \u2212S +S 1 0 0 0S 0 1 0 \u2212S 0 0 1 (5.8) This array of nine numbers\u2014called a matrix\u2014summarizes the phenomena we\u2019ve been describing. Now comes the big question: What happens if the second apparatus is tipped to a different angle, so that its field axis is no longer parallel to the first? It could be not only tipped, but also pointed in a different direction\u2014for instance, it could take the beam off at 90 \u2218 with respect to the original direction. To take it easy at first, let\u2019s first think about an arrangement in which the second Stern-Gerlach experiment is tilted by some angle \u03b1 about the y -axis, as shown in Fig. 5\u20136. We\u2019ll call the second apparatus T . Suppose that we now set up the following experiment: \u23a7 \u23a9 \u23a8 \u23aa \u23aa + 0 \u2212 \u23ab \u23ad \u23ac \u23aa \u23aa S \u23a7 \u23a9 \u23a8 \u23aa \u23aa + 0 \u2212 \u23ab \u23ad \u23ac \u23aa \u23aa T , or the experiment: \u23a7 \u23a9 \u23a8 \u23aa \u23aa + 0 \u2212 \u23ab \u23ad \u23ac \u23aa \u23aa S \u23a7 \u23a9 \u23a8 \u23aa \u23aa + 0 \u2212 \u23ab \u23ad \u23ac \u23aa \u23aa T \u22c5 What comes out at the far end in these cases? The answer is this: If the atoms are in a definite state with respect to S , they are not in the same state with respect to T \u2014a (+S) state is not also a (+T) state. There is, however, a certain amplitude to find the atom in a (+T) state\u2014or a (0T) state or a (\u2212T) state. In other words, as careful as we have been to make sure that we have the atoms in a definite condition, the fact of the matter is that if it goes through an apparatus which is tilted at a different angle it has, so to speak, to \u201creorient\u201d itself\u2014which it does, don\u2019t forget, by luck. We can put only one particle through at a time, and then we can only ask the question: What is the probability that it gets through? Some of the atoms that have gone through S will end in a (+T) state, some of them will end in a (0T) , and some in a (\u2212T) state\u2014all with different odds. These odds can be calculated by the absolute squares of complex amplitudes; what we want is some mathematical method, or quantum mechanical description, for these amplitudes. What we need to know are various quantities like \u27e8\u2212T|+S\u27e9, \u27e8 | \u27e9 by which we mean the amplitude that an atom initially in the (+S) state can get into the (\u2212T) condition (which is not zero unless T and S are lined up parallel to each other). There are other amplitudes like \u27e8+T|0S\u27e9,or\u27e80T|\u2212S\u27e9,etc. \u27e8 | \u27e9 \u27e8 | \u27e9 There are, in fact, nine such amplitudes\u2014another matrix\u2014that a theory of particles should tell us how to calculate. Just as F=ma tells us how to calculate what happens to a classical particle in any circumstance, the laws of quantum mechanics permit us to determine the amplitude that a particle will get through a particular apparatus. The central problem, then, is to be able to calculate\u2014for any given tilt angle \u03b1 , or in fact for any orientation whatever\u2014the nine amplitudes: \u27e8+T|+S\u27e9 \u27e80T|+S\u27e9 \u27e8\u2212T|+S\u27e9 , , , \u27e8+T|0S\u27e9 \u27e80T|0S\u27e9 \u27e8\u2212T|0S\u27e9 , , , \u27e8+T|\u2212S\u27e9 \u27e80T|\u2212S\u27e9 \u27e8\u2212T|\u2212S\u27e9 , , . (5.9) We can already figure out some relations among these amplitudes. First, according to our definitions, the absolute square |\u27e8+T|+S\u27e9 | 2 2 is the probability that an atom in a (+S) state will enter a (+T) state. We will often find it more convenient to write such squares in the equivalent form \u27e8+T|+S\u27e9\u27e8+T|+S \u27e9 \u2217 . \u2217 In the same notation the number \u27e80T|+S\u27e9\u27e80T|+S \u27e9 \u2217 \u2217 is the probability that a particle in the (+S) state will enter the (0T) state, and \u27e8\u2212T|+S\u27e9\u27e8\u2212T|+S \u27e9 \u2217 \u2217 is the probability that it will enter the (\u2212T) state. But the way our apparatuses are made, every atom which enters the T apparatus must be found in some one of the three states of the T apparatus\u2014there\u2019s nowhere else for a given kind of atom to go. So the sum of the three probabilities we\u2019ve just written must be equal to 100 percent. We have the relation \u27e8+T|+S\u27e9 \u27e80T|+S\u27e9 \u27e8\u2212T|+S\u27e9 \u27e8+T|+S\u27e9 \u27e80T|+S\u27e9 \u27e8\u2212T|+S\u27e9 \u2217 \u2217 \u2217 + + = 1. (5.10) There are, of course, two other such equations that we get if we start with a (0S) or a (\u2212S) state. But they are all we can easily get, so we\u2019ll go on to some other general questions. Here is an interesting question: Suppose we had atoms filtered into the (+S) state, then we put them through a second filter, say into a (0T) state, and then through another +S filter. (We\u2019ll call the last filter S \u2032 just so we can distinguish it from the first S -filter.) Do the atoms remember that they were once in a (+S) state? In other words, we have the following experiment: \u23a7 \u23a9 \u23a8 \u23aa \u23aa + 0 \u2212 \u23ab \u23ad \u23ac \u23aa \u23aa S \u23a7 \u23a9 \u23a8 \u23aa \u23aa + 0 \u2212 \u23ab \u23ad \u23ac \u23aa \u23aa T \u23a7 \u23a9 \u23a8 \u23aa \u23aa + 0 \u2212 \u23ab \u23ad \u23ac \u23aa \u23aa S \u2032 \u22c5 (5.11) We want to know whether all those that get through T also get through S \u2032 . They do not. Once they have been filtered by T , they do not remember in any way that they were in a (+S) state when they entered T . Note that the second S apparatus in (5.11) is oriented exactly the same as the first, so it is still an S -type filter. The states filtered by S \u2032 are, of course, still (+S) , (0S) , and (\u2212S) . The important point is this: If the T filter passes only one beam, the fraction that gets through the second S filter depends only on the setup of the T filter, and is completely independent of what precedes it. The fact that the same atoms were once sorted by an S filter has no influence whatever on what they will do once they have been sorted again into a pure beam by a T apparatus. From then on, the probability for getting into different states is the same no matter what happened before they got into the T apparatus. As an example, let\u2019s compare the experiment of (5.11) with the following experiment: \u23a7 \u23a9 \u23a8 \u23aa \u23aa + 0 \u2212 \u23ab \u23ad \u23ac \u23aa \u23aa S \u23a7 \u23a9 \u23a8 \u23aa \u23aa + 0 \u2212 \u23ab \u23ad \u23ac \u23aa \u23aa T \u23a7 \u23a9 \u23a8 \u23aa \u23aa + 0 \u2212 \u23ab \u23ad \u23ac \u23aa \u23aa S \u2032 (5.12) in which only the first S is changed. Let\u2019s say that the angle \u03b1 (between S and T ) is such that in experiment (5.11) one-third of the atoms that get through T also get through S \u2032 . In experiment (5.12), although there will, in general, be a different number of atoms coming through T , the same fraction of these\u2014one-third\u2014will also get through S \u2032 . We can, in fact, show from what you have learned earlier that the fraction of the atoms that come out of T and get through any particular S \u2032 depends only on T and S \u2032 , not on anything that happened earlier. Let\u2019s compare experiment (5.12) with \u23a7 \u23a9 \u23a8 \u23aa \u23aa + 0 \u2212 \u23ab \u23ad \u23ac \u23aa \u23aa S \u23a7 \u23a9 \u23a8 \u23aa \u23aa + 0 \u2212 \u23ab \u23ad \u23ac \u23aa \u23aa T \u23a7 \u23a9 \u23a8 \u23aa \u23aa + 0 \u2212 \u23ab \u23ad \u23ac \u23aa \u23aa S \u2032 . (5.13) The amplitude that an atom that comes out of S will also get through both T and S \u2032 is, for the experiments of (5.12), \u27e8+S|0T\u27e9\u27e80T|0S\u27e9. \u27e8 | \u27e9 \u27e8 | \u27e9 The corresponding probability is |\u27e8+S|0T\u27e9\u27e80T|0S\u27e9 | 2 =|\u27e8+S|0T\u27e9 | 2 |\u27e80T|0S\u27e9 | 2 . 2 2 2 The probability for experiment (5.13) is |\u27e80S|0T\u27e9\u27e80T|0S\u27e9 | 2 =|\u27e80S|0T\u27e9 | 2 |\u27e80T|0S\u27e9 | 2 . 2 2 2 The ratio is |\u27e80S|0T\u27e9 | 2 |\u27e8+S|0T\u27e9 | 2 . 2 and depends only on T and S \u2032 , and not at all on which beam (+S) , (0S) , or (\u2212S) is selected by S . (The absolute numbers may go up and down together depending on how much gets through T .) We would, of course, find the same result if we compared the probabilities that the atoms would go into the plus or the minus states with respect to S \u2032 , or the ratio of the probabilities to go into the zero or minus states. In fact, since these ratios depend only on which beam is allowed to pass through T , and not on the selection made by the first S filter, it is clear that we would get the same result even if the last apparatus were not an S filter. If we use for the third apparatus\u2014which we will now call R \u2014one rotated by some arbitrary angle with respect to T , we would find that a ratio such as |\u27e80R|0T\u27e9 | 2 /|\u27e8+R|0T\u27e9 | 2 was independent of which beam was passed by the first filter S . These results illustrate one of the basic principles of quantum mechanics: Any atomic system can be separated by a filtering process into a certain set of what we will call base states, and the future behavior of the atoms in any single given base state depends only on the nature of the base state\u2014it is independent of any previous history.3 The base states depend, of course, on the filter used; for instance, the three states (+T) , (0T) , and (\u2212T) are one set of base states; the three states (+S) , (0S) , and (\u2212S) are another. There are any number of possibilities each as good as any other. We should be careful to say that we are considering good filters which do indeed produce \u201cpure\u201d beams. If, for instance, our Stern-Gerlach apparatus didn\u2019t produce a good separation of the three beams so that we could not separate them cleanly by our masks, then we could not make a complete separation into base states. We can tell if we have pure base states by seeing whether or not the beams can be split again in another filter of the same kind. If we have a pure (+T) state, for instance, all the atoms will go through \u23a7 \u23a9 \u23a8 \u23aa \u23aa + 0 \u2212 \u23ab \u23ad \u23ac \u23aa \u23aa T , and none will go through \u23a7 \u23a9 \u23a8 \u23aa \u23aa + 0 \u2212 \u23ab \u23ad \u23ac \u23aa \u23aa T , or through \u23a7 \u23a9 \u23a8 \u23aa \u23aa + 0 \u2212 \u23ab \u23ad \u23ac \u23aa \u23aa T \u22c5 Our statement about base states means that it is possible to filter to some pure state, so that no further filtering by an identical apparatus is possible. We must also point out that what we are saying is exactly true only in rather idealized situations. In any real Stern-Gerlach apparatus, we would have to worry about diffraction by the slits that could cause some atoms to go into states corresponding to different angles, or about whether the beams might contain atoms with different excitations of their internal states, and so on. We have idealized the situation so that we are talking only about the states that are split in a magnetic field; we are ignoring things having to do with position, momentum, internal excitations, and the like. In general, one would need to consider also base states which are sorted out with respect to such things also. But to keep the concepts simple, we are considering only our set of three states, which is sufficient for the exact treatment of the idealized situation in which the atoms don\u2019t get torn up in going through the apparatus, or otherwise badly treated, and come to rest when they leave the apparatus. You will note that we always begin our thought experiments by taking a filter with only one channel open, so that we start with some definite base state. We do this because atoms come out of a furnace in various states determined at random by the accidental happenings inside the furnace. (It gives what is called an \u201cunpolarized\u201d beam.) This randomness involves probabilities of the \u201cclassical\u201d kind\u2014as in coin tossing\u2014which are different from the quantum mechanical probabilities we are worrying about now. Dealing with an unpolarized beam would get us into additional complications that are better to avoid until after we understand the behavior of polarized beams. So don\u2019t try to consider at this point what happens if the first apparatus lets more than one beam through. (We will tell you how you can handle such cases at the end of the chapter.) Let\u2019s now go back and see what happens when we go from a base state for one filter to a base state for a different filter. Suppose we start again with \u23a7 \u23a9 \u23a8 \u23aa \u23aa + 0 \u2212 \u23ab \u23ad \u23ac \u23aa \u23aa S \u23a7 \u23a9 \u23a8 \u23aa \u23aa + 0 \u2212 \u23ab \u23ad \u23ac \u23aa \u23aa T \u22c5 The atoms which come out of T are in the base state (0T) and have no memory that they were once in the state (+S) . Some people would say that in the filtering by T we have \u201clost the information\u201d about the previous state (+S) because we have \u201cdisturbed\u201d the atoms when we separated them into three beams in the apparatus T . But that is not true. The past information is not lost by the separation into three beams, but by the blocking masks that are put in\u2014as we can see by the following set of experiments. We start with a +S filter and will call N the number of atoms that come through it. If we follow this by a 0T filter, the number of atoms that come out is some fraction of the original number, say \u03b1N . If we then put another +S filter, only some fraction \u03b2 of these atoms will get to the far end. We can indicate this in the following way: \u23a7 \u23a9 \u23a8 \u23aa \u23aa + 0 \u2212 \u23ab \u23ad \u23ac \u23aa \u23aa S \u27f6 N \u23a7 \u23a9 \u23a8 \u23aa \u23aa + 0 \u2212 \u23ab \u23ad \u23ac \u23aa \u23aa T \u27f6 \u03b1N \u23a7 \u23a9 \u23a8 \u23aa \u23aa + 0 \u2212 \u23ab \u23ad \u23ac \u23aa \u23aa S \u2032 \u27f6. \u03b2\u03b1N (5.14) If our third apparatus S \u2032 selected a different state, say the (0S) state, a different fraction, say \u03b3 , would get through.4 We would have \u23a7 \u23a9 \u23a8 \u23aa \u23aa + 0 \u2212 \u23ab \u23ad \u23ac \u23aa \u23aa S \u27f6 N \u23a7 \u23a9 \u23a8 \u23aa \u23aa + 0 \u2212 \u23ab \u23ad \u23ac \u23aa \u23aa T \u27f6 \u03b1N \u23a7 \u23a9 \u23a8 \u23aa \u23aa + 0 \u2212 \u23ab \u23ad \u23ac \u23aa \u23aa S \u2032 \u27f6. \u03b3\u03b1N (5.15) Now suppose we repeat these two experiments but remove all the masks from T . We would then find the remarkable results as follows: \u23a7 \u23a9 \u23a8 \u23aa \u23aa + 0 \u2212 \u23ab \u23ad \u23ac \u23aa \u23aa S \u27f6 N \u23a7 \u23a9 \u23a8 \u23aa \u23aa + 0 \u2212 \u23ab \u23ad \u23ac \u23aa \u23aa T \u27f6 N \u23a7 \u23a9 \u23a8 \u23aa \u23aa + 0 \u2212 \u23ab \u23ad \u23ac \u23aa \u23aa S \u2032 \u27f6, N (5.16) \u23a7 \u23a9 \u23a8 \u23aa \u23aa + 0 \u2212 \u23ab \u23ad \u23ac \u23aa \u23aa S \u27f6 N \u23a7 \u23a9 \u23a8 \u23aa \u23aa + 0 \u2212 \u23ab \u23ad \u23ac \u23aa \u23aa T \u27f6 N \u23a7 \u23a9 \u23a8 \u23aa \u23aa + 0 \u2212 \u23ab \u23ad \u23ac \u23aa \u23aa S \u2032 \u27f6. 0 (5.17) All the atoms get through S \u2032 in the first case, but none in the second case! This is one of the great laws of quantum mechanics. That nature works this way is not self-evident, but the results we have given correspond for our idealized situation to the quantum mechanical behavior observed in innumerable experiments. How can it be that in going from (5.15) to (5.17)\u2014by opening more channels\u2014we let fewer atoms through? This is the old, deep mystery of quantum mechanics\u2014the interference of amplitudes. It\u2019s the same kind of thing we first saw in the two-slit interference experiment with electrons. We saw that we could get fewer electrons at some places with both slits open than we got with one slit open. It works quantitatively this way. We can write the amplitude that an atom will get through T and S \u2032 in the apparatus of (5.17) as the sum of three amplitudes, one for each of the three beams in T ; the sum is equal to zero: \u27e80S|+T\u27e9 \u27e80S|0T\u27e9 \u27e80S|\u2212T\u27e9 \u27e8+T|+S\u27e9 \u27e80T|+S\u27e9 \u27e8\u2212T|+S\u27e9 + + = 0. (5.18) None of the three individual amplitudes is zero\u2014for example, the absolute square of the second amplitude is \u03b3\u03b1 , see (5.15)\u2014but the sum is zero. We would have also the same answer if S \u2032 were set to select the (\u2212S) state. However, in the setup of (5.16), the answer is different. If we call a the amplitude to get through T and S \u2032 , in this case we have5 a= \u27e8+S|+T\u27e9 \u27e8+S|0T\u27e9 \u27e8+S|\u2212T\u27e9 \u27e8+T|+S\u27e9 \u27e80T|+S\u27e9 \u27e8\u2212T|+S\u27e9 + + = 1. (5.19) In the experiment (5.16) the beam has been split and recombined. Humpty Dumpty has been put back together again. The information about the original (+S) state is retained\u2014it is just as though the T apparatus were not there at all. This is true whatever is put after the \u201cwide-open\u201d T apparatus. We could follow it with an R filter\u2014a filter at some odd angle\u2014or anything we want. The answer will always be the same as if the atoms were taken directly from the first S filter. So this is the important principle: A T filter\u2014or any filter\u2014with wide-open masks produces no change at all. We should make one additional condition. The wide-open filter must not only transmit all three beams, but it must also not produce unequal disturbances on the three beams. For instance, it should not have a strong electric field near one beam and not the others. The reason is that even if this extra disturbance would still let all the atoms through the filter, it could change the phases of some of the amplitudes. Then the interference would be changed, and the amplitudes in Eqs. (5.18) and (5.19) would be different. We will always assume that there are no such extra disturbances. Let\u2019s rewrite Eqs. (5.18) and (5.19) in an improved notation. We will let i stand for any one of the three states (+T) , (0T) , or (\u2212T) ; then the equations can be written: \u2211 all i \u27e80S|i\u27e9\u27e8i|+S\u27e9=0 (5.20) and \u2211 all i \u27e8+S|i\u27e9\u27e8i|+S\u27e9=1. (5.21) Similarly, for an experiment where S \u2032 is replaced by a completely arbitrary filter R , we have \u23a7 \u23a9 \u23a8 \u23aa \u23aa + 0 \u2212 \u23ab \u23ad \u23ac \u23aa \u23aa S \u23a7 \u23a9 \u23a8 \u23aa \u23aa + 0 \u2212 \u23ab \u23ad \u23ac \u23aa \u23aa T \u23a7 \u23a9 \u23a8 \u23aa \u23aa + 0 \u2212 \u23ab \u23ad \u23ac \u23aa \u23aa R \u22c5 (5.22) The results will always be the same as if the T apparatus were left out and we had only \u23a7 \u23a9 \u23a8 \u23aa \u23aa + 0 \u2212 \u23ab \u23ad \u23ac \u23aa \u23aa S \u23a7 \u23a9 \u23a8 \u23aa \u23aa + 0 \u2212 \u23ab \u23ad \u23ac \u23aa \u23aa R \u22c5 Or, expressed mathematically, \u2211 all i \u27e8+R|i\u27e9\u27e8i|+S\u27e9=\u27e8+R|+S\u27e9. (5.23) This is our fundamental law, and it is generally true so long as i stands for the three base states of any filter. You will notice that in the experiment (5.22) there is no special relation of S and R to T . Furthermore, the arguments would be the same no matter what states they selected. To write the equation in a general way, without having to refer to the specific states selected by S and R , let\u2019s call \u03d5 (\u201cphi\u201d) the state prepared by the first filter (in our special example, +S ) and \u03c7 (\u201ckhi\u201d) the state tested by the final filter (in our example, +R ). Then we can state our fundamental law of Eq. (5.23) in the form \u27e8\u03c7|\u03d5\u27e9= \u2211 all i \u27e8\u03c7|i\u27e9\u27e8i|\u03d5\u27e9, (5.24) where i is to range over the three base states of some particular filter. We want to emphasize again what we mean by base states. They are like the three states which can be selected by one of our Stern-Gerlach apparatuses. One condition is that if you have a base state, then the future is independent of the past. Another condition is that if you have a complete set of base states, Eq. (5.24) is true for any set of beginning and ending states \u03d5 and \u03c7 . There is, however, no unique set of base states. We began by considering base states with respect to a particular apparatus T . We could equally well consider a different set of base states with respect to an apparatus S , or with respect to R , etc.6 We usually speak of the base states \u201cin a certain representation.\u201d Another condition on a set of base states in any particular representation is that they are all completely different. By that we mean that if we have a (+T) state, there is no amplitude for it to go into a (0T) or a (\u2212T) state. If we let i and j stand for any two base states of a particular set, the general rules discussed in connection with (5.8) are that \u27e8j|i\u27e9=0 \u27e8 | \u27e9 for all i and j that are not equal. Of course, we know that \u27e8i|i\u27e9=1. \u27e8 | \u27e9 These two equations are usually written as \u27e8j|i\u27e9= \u03b4 ji , (5.25) where \u03b4 ji (the \u201cKronecker delta\u201d) is a symbol that is defined to be zero for i\u2260j , and to be one for i=j . Equation (5.25) is not independent of the other laws we have mentioned. It happens that we are not particularly interested in the mathematical problem of finding the minimum set of independent axioms that will give all the laws as consequences.7 We are satisfied if we have a set that is complete and not apparently inconsistent. We can, however, show that Eqs. (5.25) and (5.24) are not independent. Suppose we let \u03d5 in Eq. (5.24) represent one of the base states of the same set as i , say the j th state; then we have \u27e8\u03c7|j\u27e9= \u2211 i \u27e8\u03c7|i\u27e9\u27e8i|j\u27e9. \u2211 But Eq. (5.25) says that \u27e8i|j\u27e9 is zero unless i=j , so the sum becomes just \u27e8\u03c7|j\u27e9 and we have an identity, which shows that the two laws are not independent. We can see that there must be another relation among the amplitudes if both Eqs. (5.10) and (5.24) are true. Equation (5.10) is \u27e8+T|+S\u27e9 \u27e80T|+S\u27e9 \u27e8\u2212T|+S\u27e9 \u27e8+T|+S\u27e9 \u27e80T|+S\u27e9 \u27e8\u2212T|+S\u27e9 \u2217 \u2217 \u2217 + + = 1. If we write Eq. (5.24), letting both \u03d5 and \u03c7 be the state (+S) , the left-hand side is \u27e8+S|+S\u27e9 , which is clearly =1 ; so we get once more Eq. (5.19), \u27e8+S|+T\u27e9 \u27e8+S|0T\u27e9 \u27e8+S|\u2212T\u27e9 \u27e8+T|+S\u27e9 \u27e80T|+S\u27e9 \u27e8\u2212T|+S\u27e9 + + = 1. These two equations are consistent (for all relative orientations of the T and S apparatuses) only if \u27e8+S|+T\u27e9 \u27e8+S|0T\u27e9 \u27e8+S|\u2212T\u27e9 =\u27e8+T|+S \u27e9 \u2217 , =\u27e80T|+S \u27e9 \u2217 , =\u27e8\u2212T|+S \u27e9 \u2217 . And it follows that for any states \u03d5 and \u03c7 , \u27e8\u03d5|\u03c7\u27e9=\u27e8\u03c7|\u03d5 \u27e9 \u2217 . (5.26) If this were not true, probability wouldn\u2019t be \u201cconserved,\u201d and particles would get \u201clost.\u201d Before going on, we want to summarize the three important general laws about amplitudes. They are Eqs. (5.24), (5.25), and (5.26): I II III \u27e8j|i\u27e9 \u27e8\u03c7|\u03d5\u27e9 \u27e8\u03d5|\u03c7\u27e9 = \u03b4 ji , = \u2211 all i \u27e8\u03c7|i\u27e9\u27e8i|\u03d5\u27e9, =\u27e8\u03c7|\u03d5 \u27e9 \u2217 . (5.27) In these equations the i and j refer to all the base states of some one representation, while \u03d5 and \u03c7 represent any possible states of the atom. It is important to note that II is valid only if the sum is carried out over all the base states of the system (in our case, three: +T , 0T , \u2212T ). These laws say nothing about what we should choose for a base for our set of base states. We began by using a T apparatus, which is a Stern-Gerlach experiment with some arbitrary orientation; but any other orientation, say W , would be just as good. We would have a different set of states to use for i and j , but all the laws would still be good\u2014there is no unique set. One of the great games of quantum mechanics is to make use of the fact that things can be calculated in more than one way. We want to show you why these laws are useful. Suppose we have an atom in a given condition (by which we mean that it was prepared in a certain way), and we want to know what will happen to it in some experiment. In other words, we start with our atom in the state \u03d5 and want to know what are the odds that it will go through some apparatus which accepts atoms only in the condition \u03c7 . The laws say that we can describe the apparatus completely in terms of three complex numbers \u27e8\u03c7|i\u27e9 , the amplitudes for each base state to be in the condition \u03c7 ; and that we can tell what will happen if an atom is put into the apparatus if we describe the state of the atom by giving three numbers \u27e8i|\u03d5\u27e9 , the amplitudes for the atom in its original condition to be found in each of the three base states. This is an important idea. Let\u2019s consider another illustration. Think of the following problem: We start with an S apparatus; then we have a complicated mess of junk, which we can call A , and then an R apparatus\u2014like this: \u23a7 \u23a9 \u23a8 \u23aa \u23aa + 0 \u2212 \u23ab \u23ad \u23ac \u23aa \u23aa S \u23a7 \u23a9 \u23a8 \u23aa \u23aa \u23aa \u23aa A \u23ab \u23ad \u23ac \u23aa \u23aa \u23aa \u23aa \u23a7 \u23a9 \u23a8 \u23aa \u23aa + 0 \u2212 \u23ab \u23ad \u23ac \u23aa \u23aa R \u22c5 (5.28) By A we mean any complicated arrangement of Stern-Gerlach apparatuses with masks or half-masks, oriented at peculiar angles, with odd electric and magnetic fields \u2026 almost anything you want to put. (It\u2019s nice to do thought experiments\u2014you don\u2019t have to go to all the trouble of actually building the apparatus!) The problem then is: With what amplitude does a particle that enters the section A in a (+S) state come out of A in the (0R) state, so that it will get through the last R filter? There is a regular notation for such an amplitude; it is \u27e80R|A|+S\u27e9. \u27e8 | | \u27e9 As usual, it is to be read from right to left (like Hebrew): \u27e8finish|through|start\u27e9. \u27e8 finish | through | \u27e9 If by chance A doesn\u2019t do anything\u2014but is just an open channel\u2014then we write \u27e80R|1|+S\u27e9=\u27e80R|+S\u27e9; (5.29) the two symbols are equivalent. For a more general problem, we might replace (+S) by a general starting state \u03d5 and (0R) by a general finishing state \u03c7 , and we would want to know the amplitude \u27e8\u03c7|A|\u03d5\u27e9. \u27e8 | | \u03d5 \u27e9 A complete analysis of the apparatus A would have to give the amplitude \u27e8\u03c7|A|\u03d5\u27e9 for every possible pair of states \u03d5 and \u03c7 \u2014an infinite number of combinations! How then can we give a concise description of the behavior of the apparatus A ? We can do it in the following way. Imagine that the apparatus of (5.28) is modified to be \u23a7 \u23a9 \u23a8 \u23aa \u23aa + 0 \u2212 \u23ab \u23ad \u23ac \u23aa \u23aa S \u23a7 \u23a9 \u23a8 \u23aa \u23aa + 0 \u2212 \u23ab \u23ad \u23ac \u23aa \u23aa T \u23a7 \u23a9 \u23a8 \u23aa \u23aa \u23aa \u23aa A \u23ab \u23ad \u23ac \u23aa \u23aa \u23aa \u23aa \u23a7 \u23a9 \u23a8 \u23aa \u23aa + 0 \u2212 \u23ab \u23ad \u23ac \u23aa \u23aa T \u23a7 \u23a9 \u23a8 \u23aa \u23aa + 0 \u2212 \u23ab \u23ad \u23ac \u23aa \u23aa R \u22c5 (5.30) This is really no modification at all since the wide-open T apparatuses don\u2019t do anything. But they do suggest how we can analyze the problem. There is a certain set of amplitudes \u27e8i|+S\u27e9 that the atoms from S will get into the i state of T . Then there is another set of amplitudes that an i state (with respect to T ) entering A will come out as a j state (with respect to T ). And finally there is an amplitude that each j state will get through the last filter as a (0R) state. For each possible alternative path, there is an amplitude of the form \u27e80R|j\u27e9\u27e8j|A|i\u27e9\u27e8i|+S\u27e9, \u27e8 | \u27e9 \u27e8 | | \u27e9 \u27e8 | \u27e9 and the total amplitude is the sum of the terms we can get with all possible combinations of i and j . The amplitude we want is \u2211 ij \u27e80R|j\u27e9\u27e8j|A|i\u27e9\u27e8i|+S\u27e9. (5.31) If (0R) and (+S) are replaced by general states \u03c7 and \u03d5 , we would have the same kind of expression; so we have the general result \u27e8\u03c7|A|\u03d5\u27e9= \u2211 ij \u27e8\u03c7|j\u27e9\u27e8j|A|i\u27e9\u27e8i|\u03d5\u27e9. (5.32) Now notice that the right-hand side of Eq. (5.32) is really \u201csimpler\u201d than the left-hand side. The apparatus A is completely described by the nine numbers \u27e8j|A|i\u27e9 which tell the response of A with respect to the three base states of the apparatus T . Once we know these nine numbers, we can handle any two incoming and outgoing states \u03d5 and \u03c7 if we define each in terms of the three amplitudes for going into, or from, each of the three base states. The result of an experiment is predicted using Eq. (5.32). This then is the machinery of quantum mechanics for a spin-one particle. Every state is described by three numbers which are the amplitudes to be in each of some selected set of base states. Every apparatus is described by nine numbers which are the amplitudes to go from one base state to another in the apparatus. From these numbers anything can be calculated. The nine amplitudes which describe the apparatus are often written as a square matrix\u2014called the matrix \u27e8j|A|i\u27e9 : to from +0\u2212 + 0 \u2212 \u27e8+|A|+\u27e9 \u27e80|A|+\u27e9 \u27e8\u2212|A|+\u27e9 \u27e8+|A|0\u27e9 \u27e80|A|0\u27e9 \u27e8\u2212|A|0\u27e9 \u27e8+|A|\u2212\u27e9 \u27e80|A|\u2212\u27e9 \u27e8\u2212|A|\u2212\u27e9 (5.33) to The mathematics of quantum mechanics is just an extension of this idea. We will give you a simple illustration. Suppose we have an apparatus C that we wish to analyze\u2014that is, we want to calculate the various \u27e8j|C|i\u27e9 . For instance, we might want to know what happens in an experiment like \u23a7 \u23a9 \u23a8 \u23aa \u23aa + 0 \u2212 \u23ab \u23ad \u23ac \u23aa \u23aa S \u23a7 \u23a9 \u23a8 \u23aa \u23aa \u23aa \u23aa C \u23ab \u23ad \u23ac \u23aa \u23aa \u23aa \u23aa \u23a7 \u23a9 \u23a8 \u23aa \u23aa + 0 \u2212 \u23ab \u23ad \u23ac \u23aa \u23aa R \u22c5 (5.34) But then we notice that C is just built of two pieces of apparatus A and B in series\u2014the particles go through A and then through B \u2014so we can write symbolically \u23a7 \u23a9 \u23a8 \u23aa \u23aa \u23aa \u23aa C \u23ab \u23ad \u23ac \u23aa \u23aa \u23aa \u23aa = \u23a7 \u23a9 \u23a8 \u23aa \u23aa \u23aa \u23aa A \u23ab \u23ad \u23ac \u23aa \u23aa \u23aa \u23aa \u22c5 \u23a7 \u23a9 \u23a8 \u23aa \u23aa \u23aa \u23aa B \u23ab \u23ad \u23ac \u23aa \u23aa \u23aa \u23aa \u22c5 (5.35) We can call the C apparatus the \u201cproduct\u201d of A and B . Suppose also that we already know how to analyze the two parts; so we can get the matrices (with respect to T ) of A and B . Our problem is then solved. We can easily find \u27e8\u03c7|C|\u03d5\u27e9 \u27e8 | | \u03d5 \u27e9 for any input and output states. First we write that \u27e8\u03c7|C|\u03d5\u27e9= \u2211 k \u27e8\u03c7|B|k\u27e9\u27e8k|A|\u03d5\u27e9. \u2211 Do you see why? (Hint: Imagine putting a T apparatus between A and B .) Then if we consider the special case in which \u03d5 and \u03c7 are also base states (of T ), say i and j , we have \u27e8j|C|i\u27e9= \u2211 k \u27e8j|B|k\u27e9\u27e8k|A|i\u27e9. (5.36) This equation gives the matrix for the \u201cproduct\u201d apparatus C in terms of the two matrices of the apparatuses A and B . Mathematicians call the new matrix \u27e8j|C|i\u27e9 \u2014formed from two matrices \u27e8j|B|i\u27e9 and \u27e8j|A|i\u27e9 according to the sum specified in Eq. (5.36)\u2014the \u201cproduct\u201d matrix BA of the two matrices B and A . (Note that the order is important, AB\u2260BA .) Thus, we can say that the matrix for a succession of two pieces of apparatus is the matrix product of the matrices for the two apparatuses (putting the first apparatus on the right in the product). Anyone who knows matrix algebra then understands that we mean just Eq. (5.36). We want to make one final point about the base states used in the calculations. Suppose we have chosen to work with some particular base\u2014say the S base\u2014and another fellow decides to do the same calculations with a different base\u2014say the T base. To keep things straight let\u2019s call our base states the (iS) states, where i=+ , 0 , \u2212 . Similarly, we can call his base states (jT) . How can we compare our work with his? The final answers for the result of any measurement should come out the same, but in the calculations the various amplitudes and matrices used will be different. How are they related? For instance, if we both start with the same \u03d5 , we will describe it in terms of the three amplitudes \u27e8iS|\u03d5\u27e9 that \u03d5 goes into our base states in the S representation, whereas he will describe it by the amplitudes \u27e8jT|\u03d5\u27e9 that the state \u03d5 goes into the base states in his T representation. How can we check that we are really both describing the same state \u03d5 ? We can do it with the general rule II in (5.27). Replacing \u03c7 by any one of his states jT , we have \u27e8jT|\u03d5\u27e9= \u2211 i \u27e8jT|iS\u27e9\u27e8iS|\u03d5\u27e9. (5.37) To relate the two representations, we need only give the nine complex numbers of the matrix \u27e8jT|iS\u27e9 . This matrix can then be used to convert all of our equations to his form. It tells us how to transform from one set of base states to another. (For this reason \u27e8jT|iS\u27e9 is sometimes called \u201cthe transformation matrix from representation S to representation T .\u201d Big words!) For the case of spin-one particles for which we have only three base states (for higher spins, there are more) the mathematical situation is analogous to what we have seen in vector algebra. Every vector can be represented by giving three numbers\u2014the components along the axes x , y , and z . That is, every vector can be resolved into three \u201cbase\u201d vectors which are vectors along the three axes. But suppose someone else chooses to use a different set of axes\u2014 x \u2032 , y \u2032 , and z \u2032 . He will be using different numbers to represent any particular vector. His calculations will look different, but the final results will be the same. We have considered this before and know the rules for transforming vectors from one set of axes to another. You may want to see how the quantum mechanical transformations work by trying some out; so we will give here, without proof, the transformation matrices for converting the spin-one amplitudes in one representation S to another representation T , for various special relative orientations of the S and T filters. (We will show you in a later chapter how to derive these same results.) First case: The T apparatus has the same y -axis (along which the particles move) as the S apparatus, but is rotated about the common y -axis by the angle \u03b1 (as in Fig. 5\u20136). (To be specific, a set of coordinates x \u2032 , y \u2032 , z \u2032 is fixed in the T apparatus, related to the x , y , z coordinates of the S apparatus by: z \u2032 =zcos\u03b1+xsin\u03b1 , x \u2032 =xcos\u03b1\u2212zsin\u03b1 , y \u2032 =y .) Then the transformation amplitudes are: \u27e8+T|+S\u27e9 \u27e80T|+S\u27e9 \u27e8\u2212T|+S\u27e9 \u27e8+T|0S\u27e9 \u27e80T|0S\u27e9 \u27e8\u2212T|0S\u27e9 \u27e8+T|\u2212S\u27e9 \u27e80T|\u2212S\u27e9 \u27e8\u2212T|\u2212S\u27e9 = 1 2 (1+cos\u03b1), =\u2212 1 2 \u2013 \u221a sin\u03b1, = 1 2 (1\u2212cos\u03b1), =+ 1 2 \u2013 \u221a sin\u03b1, =cos\u03b1, =\u2212 1 2 \u2013 \u221a sin\u03b1, = 1 2 (1\u2212cos\u03b1), =+ 1 2 \u2013 \u221a sin\u03b1, = 1 2 (1+cos\u03b1). (5.38) Second case: The T apparatus has the same z -axis as S , but is rotated around the z -axis by the angle \u03b2 . (The coordinate transformation is z \u2032 =z , x \u2032 =xcos\u03b2+ysin\u03b2 , y \u2032 =ycos\u03b2\u2212xsin\u03b2 .) Then the transformation amplitudes are: \u27e8+T|+S\u27e9 \u27e80T|0S\u27e9 \u27e8\u2212T|\u2212S\u27e9 all others = e +i\u03b2 , =1, = e \u2212i\u03b2 , =0. (5.39) Note that any rotations of T whatever can be made up of the two rotations described. If a state \u03d5 is defined by the three numbers C + C 0 C \u2212 =\u27e8+S|\u03d5\u27e9, =\u27e80S|\u03d5\u27e9, =\u27e8\u2212S|\u03d5\u27e9, (5.40) and the same state is described from the point of view of T by the three numbers C \u2032 + C \u2032 0 C \u2032 \u2212 =\u27e8+T|\u03d5\u27e9, =\u27e80T|\u03d5\u27e9, =\u27e8\u2212T|\u03d5\u27e9, (5.41) then the coefficients \u27e8jT|iS\u27e9 of (5.38) or (5.39) give the transformation connecting C i and C \u2032 i . In other words, the C i are very much like the components of a vector that appear different from the point of view of S and T . For a spin-one particle only\u2014because it requires three amplitudes\u2014the correspondence with a vector is very close. In each case, there are three numbers that must transform with coordinate changes in a certain definite way. In fact, there is a set of base states which transform just like the three components of a vector. The three combinations C x C y C z =\u2212 1 2 \u2013 \u221a ( C + \u2212 C \u2212 ), =\u2212 i 2 \u2013 \u221a ( C + + C \u2212 ), = C 0 (5.42) transform to C \u2032 x , C \u2032 y , and C \u2032 z just the way that x , y , z transform to x \u2032 , y \u2032 , z \u2032 . [You can check that this is so by using the transformation laws (5.38) and (5.39).] Now you see why a spin-one particle is often called a \u201cvector particle.\u201d We began by pointing out that our discussion of spin-one particles would be a prototype for any quantum mechanical problem. The generalization has only to do with the numbers of states. Instead of only three base states, any particular situation may involve n base states.8 Our basic laws in Eq. (5.27) have exactly the same form\u2014with the understanding that i and j must range over all n base states. Any phenomenon can be analyzed by giving the amplitudes that it starts in each one of the base states and ends in any other one of the base states, and then summing over the complete set of base states. Any proper set of base states can be used, and if someone wishes to use a different set, it is just as good; the two can be connected by using an n by n transformation matrix. We will have more to say later about such transformations. Finally, we promised to remark on what to do if atoms come directly from a furnace, go through some apparatus, say A , and are then analyzed by a filter which selects the state \u03c7 . You do not know what the state \u03d5 is that they start out in. It is perhaps best if you don\u2019t worry about this problem just yet, but instead concentrate on problems that always start out with pure states. But if you insist, here is how the problem can be handled. First, you have to be able to make some reasonable guess about the way the states are distributed in the atoms that come from the furnace. For example, if there were nothing \u201cspecial\u201d about the furnace, you might reasonably guess that atoms would leave the furnace with random \u201corientations.\u201d Quantum mechanically, that corresponds to saying that you don\u2019t know anything about the states, but that one-third are in the (+S) state, one-third are in the (0S) state, and one-third are in the (\u2212S) state. For those that are in the (+S) state the amplitude to get through is \u27e8\u03c7|A|+S\u27e9 and the probability is |\u27e8\u03c7|A|+S\u27e9 | 2 , and similarly for the others. The overall probability is then 1 3 |\u27e8\u03c7|A|+S\u27e9 | 2 + 1 3 |\u27e8\u03c7|A|0S\u27e9 | 2 + 1 3 |\u27e8\u03c7|A|\u2212S\u27e9 | 2 . 1 1 1 Why did we use S rather than, say, T ? The answer is, surprisingly, the same no matter what we choose for our initial resolution\u2014so long as we are dealing with completely random orientations. It comes about in the same way that \u2211 i |\u27e8\u03c7|iS\u27e9 | 2 = \u2211 j |\u27e8\u03c7|jT\u27e9 | 2 \u2211 2 \u2211 2 for any \u03c7 . (We leave it for you to prove.) Note that it is not correct to say that the input state has the amplitudes 1/3 \u2212 \u2212 \u2212 \u221a to be in (+S) , 1/3 \u2212 \u2212 \u2212 \u221a to be in (0S) , and 1/3 \u2212 \u2212 \u2212 \u221a to be in (\u2212S) ; that would imply that certain interferences might be possible. It is simply that you do not know what the initial state is; you have to think in terms of the probability that the system starts out in the various possible initial states, and then you have to take a weighted average over the various possibilities."
    },
    {
        "input": "The Relation of Wave and Particle Viewpoints",
        "output": "In this chapter we shall discuss the relationship of the wave and particle viewpoints. We already know, from the last chapter, that neither the wave viewpoint nor the particle viewpoint is correct. Usually we have tried to present things accurately, or at least precisely enough that they will not have to be changed when we learn more\u2014it may be extended, but it will not be changed! But when we try to talk about the wave picture or the particle picture, both are approximate, and both will change. Therefore what we learn in this chapter will not be accurate in a certain sense; it is a kind of half-intuitive argument that will be made more precise later, but certain things will be changed a little bit when we interpret them correctly in quantum mechanics. The reason for doing such a thing, of course, is that we are not going to go directly into quantum mechanics, but we want to have at least some idea of the kinds of effects that we will find. Furthermore, all our experiences are with waves and with particles, and so it is rather handy to use the wave and particle ideas to get some understanding of what happens in given circumstances before we know the complete mathematics of the quantum-mechanical amplitudes. We shall try to illustrate the weakest places as we go along, but most of it is very nearly correct\u2014it is just a matter of interpretation. First of all, we know that the new way of representing the world in quantum mechanics\u2014the new framework\u2014is to give an amplitude for every event that can occur, and if the event involves the reception of one particle then we can give the amplitude to find that one particle at different places and at different times. The probability of finding the particle is then proportional to the absolute square of the amplitude. In general, the amplitude to find a particle in different places at different times varies with position and time. In a special case the amplitude varies sinusoidally in space and time like ei(\u03c9t\u2212k\u22c5r) (do not forget that these amplitudes are complex numbers, not real numbers) and involves a definite frequency \u03c9 and wave number k . Then it turns out that this corresponds to a classical limiting situation where we would have believed that we have a particle whose energy E was known and is related to the frequency by E=\u210f\u03c9, and whose momentum p is also known and is related to the wave number by p=\u210fk. This means that the idea of a particle is limited. The idea of a particle\u2014its location, its momentum, etc.\u2014which we use so much, is in certain ways unsatisfactory. For instance, if an amplitude to find a particle at different places is given by ei(\u03c9t\u2212k\u22c5r) , whose absolute square is a constant, that would mean that the probability of finding a particle is the same at all points. That means we do not know where it is\u2014it can be anywhere\u2014there is a great uncertainty in its location. On the other hand, if the position of a particle is more or less well known and we can predict it fairly accurately, then the probability of finding it in different places must be confined to a certain region, whose length we call \u0394x . Outside this region, the probability is zero. Now this probability is the absolute square of an amplitude, and if the absolute square is zero, the amplitude is also zero, so that we have a wave train whose length is \u0394x (Fig. 38\u20131), and the wavelength (the distance between nodes of the waves in the train) of that wave train is what corresponds to the particle momentum. Here we encounter a strange thing about waves; a very simple thing which has nothing to do with quantum mechanics strictly. It is something that anybody who works with waves, even if he knows no quantum mechanics, knows: namely, we cannot define a unique wavelength for a short wave train. Such a wave train does not have a definite wavelength; there is an indefiniteness in the wave number that is related to the finite length of the train, and thus there is an indefiniteness in the momentum. Let us consider two examples of this idea\u2014to see the reason why there is an uncertainty in the position and/or the momentum, if quantum mechanics is right. We have also seen before that if there were not such a thing\u2014if it were possible to measure the position and the momentum of anything simultaneously\u2014we would have a paradox; it is fortunate that we do not have such a paradox, and the fact that such an uncertainty comes naturally from the wave picture shows that everything is mutually consistent. Here is one example which shows the relationship between the position and the momentum in a circumstance that is easy to understand. Suppose we have a single slit, and particles are coming from very far away with a certain energy\u2014so that they are all coming essentially horizontally (Fig. 38\u20132). We are going to concentrate on the vertical components of momentum. All of these particles have a certain horizontal momentum p0 , say, in a classical sense. So, in the classical sense, the vertical momentum py , before the particle goes through the hole, is definitely known. The particle is moving neither up nor down, because it came from a source that is far away\u2014and so the vertical momentum is of course zero. But now let us suppose that it goes through a hole whose width is B . Then after it has come out through the hole, we know the position vertically\u2014the y position\u2014with considerable accuracy\u2014namely \u00b1B .1 That is, the uncertainty in position, \u0394y , is of order B . Now we might also want to say, since we know the momentum is absolutely horizontal, that \u0394py is zero; but that is wrong. We once knew the momentum was horizontal, but we do not know it any more. Before the particles passed through the hole, we did not know their vertical positions. Now that we have found the vertical position by having the particle come through the hole, we have lost our information on the vertical momentum! Why? According to the wave theory, there is a spreading out, or diffraction, of the waves after they go through the slit, just as for light. Therefore there is a certain probability that particles coming out of the slit are not coming exactly straight. The pattern is spread out by the diffraction effect, and the angle of spread, which we can define as the angle of the first minimum, is a measure of the uncertainty in the final angle. How does the pattern become spread? To say it is spread means that there is some chance for the particle to be moving up or down, that is, to have a component of momentum up or down. We say chance and particle because we can detect this diffraction pattern with a particle counter, and when the counter receives the particle, say at C in Fig. 38\u20132, it receives the entire particle, so that, in a classical sense, the particle has a vertical momentum, in order to get from the slit up to C . To get a rough idea of the spread of the momentum, the vertical momentum py has a spread which is equal to p0\u0394\u03b8 , where p0 is the horizontal momentum. And how big is \u0394\u03b8 in the spread-out pattern? We know that the first minimum occurs at an angle \u0394\u03b8 such that the waves from one edge of the slit have to travel one wavelength farther than the waves from the other side\u2014we worked that out before (Chapter 30). Therefore \u0394\u03b8 is \u03bb/B , and so \u0394py in this experiment is p0\u03bb/B . Note that if we make B smaller and make a more accurate measurement of the position of the particle, the diffraction pattern gets wider. Remember, when we closed the slits on the experiment with the microwaves, we had more intensity farther out. So the narrower we make the slit, the wider the pattern gets, and the more is the likelihood that we would find that the particle has sidewise momentum. Thus the uncertainty in the vertical momentum is inversely proportional to the uncertainty of y . In fact, we see that the product of the two is equal to p0\u03bb . But \u03bb is the wavelength and p0 is the momentum, and in accordance with quantum mechanics, the wavelength times the momentum is Planck\u2019s constant h . So we obtain the rule that the uncertainties in the vertical momentum and in the vertical position have a product of the order h : \u0394y\u0394py\u2265\u210f/2. We cannot prepare a system in which we know the vertical position of a particle and can predict how it will move vertically with greater certainty than given by (38.3). That is, the uncertainty in the vertical momentum must exceed \u210f/2\u0394y , where \u0394y is the uncertainty in our knowledge of the position. Sometimes people say quantum mechanics is all wrong. When the particle arrived from the left, its vertical momentum was zero. And now that it has gone through the slit, its position is known. Both position and momentum seem to be known with arbitrary accuracy. It is quite true that we can receive a particle, and on reception determine what its position is and what its momentum would have had to have been to have gotten there. That is true, but that is not what the uncertainty relation (38.3) refers to. Equation (38.3) refers to the predictability of a situation, not remarks about the past. It does no good to say \u201cI knew what the momentum was before it went through the slit, and now I know the position,\u201d because now the momentum knowledge is lost. The fact that it went through the slit no longer permits us to predict the vertical momentum. We are talking about a predictive theory, not just measurements after the fact. So we must talk about what we can predict. Now let us take the thing the other way around. Let us take another example of the same phenomenon, a little more quantitatively. In the previous example we measured the momentum by a classical method. Namely, we considered the direction and the velocity and the angles, etc., so we got the momentum by classical analysis. But since momentum is related to wave number, there exists in nature still another way to measure the momentum of a particle\u2014photon or otherwise\u2014which has no classical analog, because it uses Eq. (38.2). We measure the wavelengths of the waves. Let us try to measure momentum in this way. Suppose we have a grating with a large number of lines (Fig. 38\u20133), and send a beam of particles at the grating. We have often discussed this problem: if the particles have a definite momentum, then we get a very sharp pattern in a certain direction, because of the interference. And we have also talked about how accurately we can determine that momentum, that is to say, what the resolving power of such a grating is. Rather than derive it again, we refer to Chapter 30, where we found that the relative uncertainty in the wavelength that can be measured with a given grating is 1/Nm , where N is the number of lines on the grating and m is the order of the diffraction pattern. That is, \u0394\u03bb/\u03bb=1/Nm. Now formula (38.4) can be rewritten as \u0394\u03bb/\u03bb2=1/Nm\u03bb=1/L, where L is the distance shown in Fig. 38\u20133. This distance is the difference between the total distance that the particle or wave or whatever it is has to travel if it is reflected from the bottom of the grating, and the distance that it has to travel if it is reflected from the top of the grating. That is, the waves which form the diffraction pattern are waves which come from different parts of the grating. The first ones that arrive come from the bottom end of the grating, from the beginning of the wave train, and the rest of them come from later parts of the wave train, coming from different parts of the grating, until the last one finally arrives, and that involves a point in the wave train a distance L behind the first point. So in order that we shall have a sharp line in our spectrum corresponding to a definite momentum, with an uncertainty given by (38.4), we have to have a wave train of at least length L . If the wave train is too short we are not using the entire grating. The waves which form the spectrum are being reflected from only a very short sector of the grating if the wave train is too short, and the grating will not work right\u2014we will find a big angular spread. In order to get a narrower one, we need to use the whole grating, so that at least at some moment the whole wave train is scattering simultaneously from all parts of the grating. Thus the wave train must be of length L in order to have an uncertainty in the wavelength less than that given by (38.5). Incidentally, \u0394\u03bb/\u03bb2=\u0394(1/\u03bb)=\u0394k/2\u03c0. Therefore \u0394k=2\u03c0/L, where L is the length of the wave train. This means that if we have a wave train whose length is less than L , the uncertainty in the wave number must exceed 2\u03c0/L . Or the uncertainty in a wave number times the length of the wave train\u2014we will call that for a moment \u0394x \u2014exceeds 2\u03c0 . We call it \u0394x because that is the uncertainty in the location of the particle. If the wave train exists only in a finite length, then that is where we could find the particle, within an uncertainty \u0394x . Now this property of waves, that the length of the wave train times the uncertainty of the wave number associated with it is at least 2\u03c0 , is a property that is known to everyone who studies them. It has nothing to do with quantum mechanics. It is simply that if we have a finite train, we cannot count the waves in it very precisely. Let us try another way to see the reason for that. Suppose that we have a finite train of length L ; then because of the way it has to decrease at the ends, as in Fig. 38\u20131, the number of waves in the length L is uncertain by something like \u00b11 . But the number of waves in L is kL/2\u03c0 . Thus k is uncertain, and we again get the result (38.7), a property merely of waves. The same thing works whether the waves are in space and k is the number of radians per centimeter and L is the length of the train, or the waves are in time and \u03c9 is the number of radians per second and T is the \u201clength\u201d in time that the wave train comes in. That is, if we have a wave train lasting only for a certain finite time T , then the uncertainty in the frequency is given by \u0394\u03c9=2\u03c0/T. (38.8) We have tried to emphasize that these are properties of waves alone, and they are well known, for example, in the theory of sound. The point is that in quantum mechanics we interpret the wave number as being a measure of the momentum of a particle, with the rule that p=\u210fk , so that relation (38.7) tells us that \u0394p\u2248h/\u0394x . This, then, is a limitation of the classical idea of momentum. (Naturally, it has to be limited in some ways if we are going to represent particles by waves!) It is nice that we have found a rule that gives us some idea of when there is a failure of classical ideas. Next let us consider the reflection of particle waves from a crystal. A crystal is a thick thing which has a whole lot of similar atoms\u2014we will include some complications later\u2014in a nice array. The question is how to set the array so that we get a strong reflected maximum in a given direction for a given beam of, say, light (x-rays), electrons, neutrons, or anything else. In order to obtain a strong reflection, the scattering from all of the atoms must be in phase. There cannot be equal numbers in phase and out of phase, or the waves will cancel out. The way to arrange things is to find the regions of constant phase, as we have already explained; they are planes which make equal angles with the initial and final directions (Fig. 38\u20134). If we consider two parallel planes, as in Fig. 38\u20134, the waves scattered from the two planes will be in phase provided the difference in distance travelled by a wavefront is an integral number of wavelengths. This difference can be seen to be 2dsin\u03b8 , where d is the perpendicular distance between the planes. Thus the condition for coherent reflection is 2dsin\u03b8=n\u03bb(n=1,2,\u2026). (38.9) If, for example, the crystal is such that the atoms happen to lie on planes obeying condition (38.9) with n=1 , then there will be a strong reflection. If, on the other hand, there are other atoms of the same nature (equal in density) halfway between, then the intermediate planes will also scatter equally strongly and will interfere with the others and produce no effect. So d in (38.9) must refer to adjacent planes; we cannot take a plane five layers farther back and use this formula! As a matter of interest, actual crystals are not usually as simple as a single kind of atom repeated in a certain way. Instead; if we make a two-dimensional analog, they are much like wallpaper, in which there is some kind of figure which repeats all over the wallpaper. By \u201cfigure\u201d we mean, in the case of atoms, some arrangement\u2014calcium and a carbon and three oxygens, etc., for calcium carbonate, and so on\u2014which may involve a relatively large number of atoms. But whatever it is, the figure is repeated in a pattern. This basic figure is called a unit cell. The basic pattern of repetition defines what we call the lattice type; the lattice type can be immediately determined by looking at the reflections and seeing what their symmetry is. In other words, where we find any reflections at all determines the lattice type, but in order to determine what is in each of the elements of the lattice one must take into account the intensity of the scattering at the various directions. Which directions scatter depends on the type of lattice, but how strongly each scatters is determined by what is inside each unit cell, and in that way the structure of crystals is worked out. Two photographs of x-ray diffraction patterns are shown in Figs. 38\u20135 and 38\u20136; they illustrate scattering from rock salt and myoglobin, respectively. Incidentally, an interesting thing happens if the spacings of the nearest planes are less than \u03bb/2 . In this case (38.9) has no solution for n . Thus if \u03bb is bigger than twice the distance between adjacent planes then there is no side diffraction pattern, and the light\u2014or whatever it is\u2014will go right through the material without bouncing off or getting lost. So in the case of light, where \u03bb is much bigger than the spacing, of course it does go through and there is no pattern of reflection from the planes of the crystal. This fact also has an interesting consequence in the case of piles which make neutrons (these are obviously particles, for anybody\u2019s money!). If we take these neutrons and let them into a long block of graphite, the neutrons diffuse and work their way along (Fig. 38\u20137). They diffuse because they are bounced by the atoms, but strictly, in the wave theory, they are bounced by the atoms because of diffraction from the crystal planes. It turns out that if we take a very long piece of graphite, the neutrons that come out the far end are all of long wavelength! In fact, if one plots the intensity as a function of wavelength, we get nothing except for wavelengths longer than a certain minimum (Fig. 38\u20138). In other words, we can get very slow neutrons that way. Only the slowest neutrons come through; they are not diffracted or scattered by the crystal planes of the graphite, but keep going right through like light through glass, and are not scattered out the sides. There are many other demonstrations of the reality of neutron waves and waves of other particles. We now consider another application of the uncertainty relation, Eq. (38.3). It must not be taken too seriously; the idea is right but the analysis is not very accurate. The idea has to do with the determination of the size of atoms, and the fact that, classically, the electrons would radiate light and spiral in until they settle down right on top of the nucleus. But that cannot be right quantum-mechanically because then we would know where each electron was and how fast it was moving. Suppose we have a hydrogen atom, and measure the position of the electron; we must not be able to predict exactly where the electron will be, or the momentum spread will then turn out to be infinite. Every time we look at the electron, it is somewhere, but it has an amplitude to be in different places so there is a probability of it being found in different places. These places cannot all be at the nucleus; we shall suppose there is a spread in position of order a . That is, the distance of the electron from the nucleus is usually about a . We shall determine a by minimizing the total energy of the atom. The spread in momentum is roughly \u210f/a because of the uncertainty relation, so that if we try to measure the momentum of the electron in some manner, such as by scattering x-rays off it and looking for the Doppler effect from a moving scatterer, we would expect not to get zero every time\u2014the electron is not standing still\u2014but the momenta must be of the order p\u2248\u210f/a . Then the kinetic energy is roughly 1 2 m v 2 = p 2 /2m= \u210f 2 /2m a 2 . (In a sense, this is a kind of dimensional analysis to find out in what way the kinetic energy depends upon the reduced Planck constant, upon m , and upon the size of the atom. We need not trust our answer to within factors like 2 , \u03c0 , etc. We have not even defined a very precisely.) Now the potential energy is minus e 2 over the distance from the center, say \u2212 e 2 /a , where, we remember, e 2 is the charge of an electron squared, divided by 4\u03c0 \u03f5 0 . Now the point is that the potential energy is reduced if a gets smaller, but the smaller a is, the higher the momentum required, because of the uncertainty principle, and therefore the higher the kinetic energy. The total energy is E= \u210f 2 /2m a 2 \u2212 e 2 /a. (38.10) We do not know what a is, but we know that the atom is going to arrange itself to make some kind of compromise so that the energy is as little as possible. In order to minimize E , we differentiate with respect to a , set the derivative equal to zero, and solve for a . The derivative of E is dE/da=\u2212 \u210f 2 /m a 3 + e 2 / a 2 , (38.11) and setting dE/da=0 gives for a the value a 0 = \u210f 2 /m e 2 =0.528 angstrom, =0.528\u00d7 10 \u221210 meter. (38.12) This particular distance is called the Bohr radius, and we have thus learned that atomic dimensions are of the order of angstroms, which is right: This is pretty good\u2014in fact, it is amazing, since until now we have had no basis for understanding the size of atoms! Atoms are completely impossible from the classical point of view, since the electrons would spiral into the nucleus. Now if we put the value (38.12) for a 0 into (38.10) to find the energy, it comes out E 0 =\u2212 e 2 /2 a 0 =\u2212m e 4 /2 \u210f 2 =\u221213.6 eV. (38.13) What does a negative energy mean? It means that the electron has less energy when it is in the atom than when it is free. It means it is bound. It means it takes energy to kick the electron out; it takes energy of the order of 13.6 eV to ionize a hydrogen atom. We have no reason to think that it is not two or three times this\u2014or half of this\u2014or (1/\u03c0) times this, because we have used such a sloppy argument. However, we have cheated, we have used all the constants in such a way that it happens to come out the right number! This number, 13.6 electron volts, is called a Rydberg of energy; it is the ionization energy of hydrogen. So we now understand why we do not fall through the floor. As we walk, our shoes with their masses of atoms push against the floor with its mass of atoms. In order to squash the atoms closer together, the electrons would be confined to a smaller space and, by the uncertainty principle, their momenta would have to be higher on the average, and that means high energy; the resistance to atomic compression is a quantum-mechanical effect and not a classical effect. Classically, we would expect that if we were to draw all the electrons and protons closer together, the energy would be reduced still further, and the best arrangement of positive and negative charges in classical physics is all on top of each other. This was well known in classical physics and was a puzzle because of the existence of the atom. Of course, the early scientists invented some ways out of the trouble\u2014but never mind, we have the right way out, now! (Maybe.) Incidentally, although we have no reason to understand it at the moment, in a situation where there are many electrons it turns out that they try to keep away from each other. If one electron is occupying a certain space, then another does not occupy the same space. More precisely, there are two spin cases, so that two can sit on top of each other, one spinning one way and one the other way. But after that we cannot put any more there. We have to put others in another place, and that is the real reason that matter has strength. If we could put all the electrons in the same place it would condense even more than it does. It is the fact that the electrons cannot all get on top of each other that makes tables and everything else solid. Obviously, in order to understand the properties of matter, we will have to use quantum mechanics and not be satisfied with classical mechanics. We have talked about the atom in its lowest possible energy condition, but it turns out that the electron can do other things. It can jiggle and wiggle in a more energetic manner, and so there are many different possible motions for the atom. According to quantum mechanics, in a stationary condition there can only be definite energies for an atom. We make a diagram (Fig. 38\u20139) in which we plot the energy vertically, and we make a horizontal line for each allowed value of the energy. When the electron is free, i.e., when its energy is positive, it can have any energy; it can be moving at any speed. But bound energies are not arbitrary. The atom must have one or another out of a set of allowed values, such as those in Fig. 38\u20139. Now let us call the allowed values of the energy E 0 , E 1 , E 2 , E 3 . If an atom is initially in one of these \u201cexcited states,\u201d E 1 , E 2 , etc., it does not remain in that state forever. Sooner or later it drops to a lower state and radiates energy in the form of light. The frequency of the light that is emitted is determined by conservation of energy plus the quantum-mechanical understanding that the frequency of the light is related to the energy of the light by (38.1). Therefore the frequency of the light which is liberated in a transition from energy E 3 to energy E 1 (for example) is \u03c9 31 =( E 3 \u2212 E 1 )/\u210f. (38.14) This, then, is a characteristic frequency of the atom and defines a spectral emission line. Another possible transition would be from E 3 to E 0 . That would have a different frequency \u03c9 30 =( E 3 \u2212 E 0 )/\u210f. (38.15) Another possibility is that if the atom were excited to the state E 1 it could drop to the ground state E 0 , emitting a photon of frequency \u03c9 10 =( E 1 \u2212 E 0 )/\u210f. (38.16) The reason we bring up three transitions is to point out an interesting relationship. It is easy to see from (38.14), (38.15), and (38.16) that \u03c9 30 = \u03c9 31 + \u03c9 10 . (38.17) In general, if we find two spectral lines, we shall expect to find another line at the sum of the frequencies (or the difference in the frequencies), and that all the lines can be understood by finding a series of levels such that every line corresponds to the difference in energy of some pair of levels. This remarkable coincidence in spectral frequencies was noted before quantum mechanics was discovered, and it is called the Ritz combination principle. This is again a mystery from the point of view of classical mechanics. Let us not belabor the point that classical mechanics is a failure in the atomic domain; we seem to have demonstrated that pretty well. We have already talked about quantum mechanics as being represented by amplitudes which behave like waves, with certain frequencies and wave numbers. Let us observe how it comes about from the point of view of amplitudes that the atom has definite energy states. This is something we cannot understand from what has been said so far, but we are all familiar with the fact that confined waves have definite frequencies. For instance, if sound is confined to an organ pipe, or anything like that, then there is more than one way that the sound can vibrate, but for each such way there is a definite frequency. Thus an object in which the waves are confined has certain resonance frequencies. It is therefore a property of waves in a confined space\u2014a subject which we will discuss in detail with formulas later on\u2014that they exist only at definite frequencies. And since the general relation exists between frequencies of the amplitude and energy, we are not surprised to find definite energies associated with electrons bound in atoms. Let us consider briefly some philosophical implications of quantum mechanics. As always, there are two aspects of the problem: one is the philosophical implication for physics, and the other is the extrapolation of philosophical matters to other fields. When philosophical ideas associated with science are dragged into another field, they are usually completely distorted. Therefore we shall confine our remarks as much as possible to physics itself. First of all, the most interesting aspect is the idea of the uncertainty principle; making an observation affects the phenomenon. It has always been known that making observations affects a phenomenon, but the point is that the effect cannot be disregarded or minimized or decreased arbitrarily by rearranging the apparatus. When we look for a certain phenomenon we cannot help but disturb it in a certain minimum way, and the disturbance is necessary for the consistency of the viewpoint. The observer was sometimes important in prequantum physics, but only in a rather trivial sense. The problem has been raised: if a tree falls in a forest and there is nobody there to hear it, does it make a noise? A real tree falling in a real forest makes a sound, of course, even if nobody is there. Even if no one is present to hear it, there are other traces left. The sound will shake some leaves, and if we were careful enough we might find somewhere that some thorn had rubbed against a leaf and made a tiny scratch that could not be explained unless we assumed the leaf were vibrating. So in a certain sense we would have to admit that there is a sound made. We might ask: was there a sensation of sound? No, sensations have to do, presumably, with consciousness. And whether ants are conscious and whether there were ants in the forest, or whether the tree was conscious, we do not know. Let us leave the problem in that form. Another thing that people have emphasized since quantum mechanics was developed is the idea that we should not speak about those things which we cannot measure. (Actually relativity theory also said this.) Unless a thing can be defined by measurement, it has no place in a theory. And since an accurate value of the momentum of a localized particle cannot be defined by measurement it therefore has no place in the theory. The idea that this is what was the matter with classical theory is a false position. It is a careless analysis of the situation. Just because we cannot measure position and momentum precisely does not a priori mean that we cannot talk about them. It only means that we need not talk about them. The situation in the sciences is this: A concept or an idea which cannot be measured or cannot be referred directly to experiment may or may not be useful. It need not exist in a theory. In other words, suppose we compare the classical theory of the world with the quantum theory of the world, and suppose that it is true experimentally that we can measure position and momentum only imprecisely. The question is whether the ideas of the exact position of a particle and the exact momentum of a particle are valid or not. The classical theory admits the ideas; the quantum theory does not. This does not in itself mean that classical physics is wrong. When the new quantum mechanics was discovered, the classical people\u2014which included everybody except Heisenberg, Schr\u00f6dinger, and Born\u2014said: \u201cLook, your theory is not any good because you cannot answer certain questions like: what is the exact position of a particle?, which hole does it go through?, and some others.\u201d Heisenberg\u2019s answer was: \u201cI do not need to answer such questions because you cannot ask such a question experimentally.\u201d It is that we do not have to. Consider two theories (a) and (b); (a) contains an idea that cannot be checked directly but which is used in the analysis, and the other, (b), does not contain the idea. If they disagree in their predictions, one could not claim that (b) is false because it cannot explain this idea that is in (a), because that idea is one of the things that cannot be checked directly. It is always good to know which ideas cannot be checked directly, but it is not necessary to remove them all. It is not true that we can pursue science completely by using only those concepts which are directly subject to experiment. In quantum mechanics itself there is a wave function amplitude, there is a potential, and there are many constructs that we cannot measure directly. The basis of a science is its ability to predict. To predict means to tell what will happen in an experiment that has never been done. How can we do that? By assuming that we know what is there, independent of the experiment. We must extrapolate the experiments to a region where they have not been done. We must take our concepts and extend them to places where they have not yet been checked. If we do not do that, we have no prediction. So it was perfectly sensible for the classical physicists to go happily along and suppose that the position\u2014which obviously means something for a baseball\u2014meant something also for an electron. It was not stupidity. It was a sensible procedure. Today we say that the law of relativity is supposed to be true at all energies, but someday somebody may come along and say how stupid we were. We do not know where we are \u201cstupid\u201d until we \u201cstick our neck out,\u201d and so the whole idea is to put our neck out. And the only way to find out that we are wrong is to find out what our predictions are. It is absolutely necessary to make constructs. We have already made a few remarks about the indeterminacy of quantum mechanics. That is, that we are unable now to predict what will happen in physics in a given physical circumstance which is arranged as carefully as possible. If we have an atom that is in an excited state and so is going to emit a photon, we cannot say when it will emit the photon. It has a certain amplitude to emit the photon at any time, and we can predict only a probability for emission; we cannot predict the future exactly. This has given rise to all kinds of nonsense and questions on the meaning of freedom of will, and of the idea that the world is uncertain. Of course we must emphasize that classical physics is also indeterminate, in a sense. It is usually thought that this indeterminacy, that we cannot predict the future, is an important quantum-mechanical thing, and this is said to explain the behavior of the mind, feelings of free will, etc. But if the world were classical\u2014if the laws of mechanics were classical\u2014it is not quite obvious that the mind would not feel more or less the same. It is true classically that if we knew the position and the velocity of every particle in the world, or in a box of gas, we could predict exactly what would happen. And therefore the classical world is deterministic. Suppose, however, that we have a finite accuracy and do not know exactly where just one atom is, say to one part in a billion. Then as it goes along it hits another atom, and because we did not know the position better than to one part in a billion, we find an even larger error in the position after the collision. And that is amplified, of course, in the next collision, so that if we start with only a tiny error it rapidly magnifies to a very great uncertainty. To give an example: if water falls over a dam, it splashes. If we stand nearby, every now and then a drop will land on our nose. This appears to be completely random, yet such a behavior would be predicted by purely classical laws. The exact position of all the drops depends upon the precise wigglings of the water before it goes over the dam. How? The tiniest irregularities are magnified in falling, so that we get complete randomness. Obviously, we cannot really predict the position of the drops unless we know the motion of the water absolutely exactly. Speaking more precisely, given an arbitrary accuracy, no matter how precise, one can find a time long enough that we cannot make predictions valid for that long a time. Now the point is that this length of time is not very large. It is not that the time is millions of years if the accuracy is one part in a billion. The time goes, in fact, only logarithmically with the error, and it turns out that in only a very, very tiny time we lose all our information. If the accuracy is taken to be one part in billions and billions and billions\u2014no matter how many billions we wish, provided we do stop somewhere\u2014then we can find a time less than the time it took to state the accuracy\u2014after which we can no longer predict what is going to happen! It is therefore not fair to say that from the apparent freedom and indeterminacy of the human mind, we should have realized that classical \u201cdeterministic\u201d physics could not ever hope to understand it, and to welcome quantum mechanics as a release from a \u201ccompletely mechanistic\u201d universe. For already in classical mechanics there was indeterminability from a practical point of view."
    },
    {
        "input": "Diffraction",
        "output": "This chapter is a direct continuation of the previous one, although the name has been changed from Interference to Diffraction. No one has ever been able to define the difference between interference and diffraction satisfactorily. It is just a question of usage, and there is no specific, important physical difference between them. The best we can do, roughly speaking, is to say that when there are only a few sources, say two, interfering, then the result is usually called interference, but if there is a large number of them, it seems that the word diffraction is more often used. So, we shall not worry about whether it is interference or diffraction, but continue directly from where we left off in the middle of the subject in the last chapter. Thus we shall now discuss the situation where there are n equally spaced oscillators, all of equal amplitude but different from one another in phase, either because they are driven differently in phase, or because we are looking at them at an angle such that there is a difference in time delay. For one reason or another, we have to add something like this: R=A[cos\u03c9t +cos(\u03c9t+\u03d5)+cos(\u03c9t+2\u03d5)+ \u22ef +cos(\u03c9t+(n\u22121)\u03d5)], where \u03d5 is the phase difference between one oscillator and the next one, as seen in a particular direction. Specifically, \u03d5=\u03b1+2\u03c0dsin\u03b8/\u03bb . Now we must add all the terms together. We shall do this geometrically. The first one is of length A , and it has zero phase. The next is also of length A and it has a phase equal to \u03d5 . The next one is again of length A and it has a phase equal to 2\u03d5 , and so on. So we are evidently going around an equiangular polygon with n sides (Fig. 30\u20131). Now the vertices, of course, all lie on a circle, and we can find the net amplitude most easily if we find the radius of that circle. Suppose that Q is the center of the circle. Then we know that the angle OQS is just a phase angle \u03d5 . (This is because the radius QS bears the same geometrical relation to A 2 as QO bears to A 1 , so they form an angle \u03d5 between them.) Therefore the radius r must be such that A=2rsin\u03d5/2 , which fixes r . But the large angle OQT is equal to n\u03d5 , and we thus find that A R =2rsinn\u03d5/2 . Combining these two results to eliminate r , we get A R =A sinn\u03d5/2 sin\u03d5/2 . (30.2) The resultant intensity is thus I= I 0 sin 2 n\u03d5/2 sin 2 \u03d5/2 . (30.3) Now let us analyze this expression and study some of its consequences. In the first place, we can check it for n=1 . It checks: I= I 0 . Next, we check it for n=2 : writing sin\u03d5=2sin\u03d5/2cos\u03d5/2 , we find that A R =2Acos\u03d5/2 , which agrees with (29.12). Now the idea that led us to consider the addition of several sources was that we might get a much stronger intensity in one direction than in another; that the nearby maxima which would have been present if there were only two sources will have gone down in strength. In order to see this effect, we plot the curve that comes from (30.3), taking n to be enormously large and plotting the region near \u03d5=0 . In the first place, if \u03d5 is exactly 0 , we have 0/0 , but if \u03d5 is infinitesimal, the ratio of the two sines squared is simply n 2 , since the sine and the angle are approximately equal. Thus the intensity of the maximum of the curve is equal to n 2 times the intensity of one oscillator. That is easy to see, because if they are all in phase, then the little vectors have no relative angle and all n of them add up so the amplitude is n times, and the intensity n 2 times, stronger. As the phase \u03d5 increases, the ratio of the two sines begins to fall off, and the first time it reaches zero is when n\u03d5/2=\u03c0 , because sin\u03c0=0 . In other words, \u03d5=2\u03c0/n corresponds to the first minimum in the curve (Fig. 30\u20132). In terms of what is happening with the arrows in Fig. 30\u20131, the first minimum occurs when all the arrows come back to the starting point; that means that the total accumulated angle in all the arrows, the total phase difference between the first and last oscillator, must be 2\u03c0 to complete the circle. Now we go to the next maximum, and we want to see that it is really much smaller than the first one, as we had hoped. We shall not go precisely to the maximum position, because both the numerator and the denominator of (30.3) are variant, but sin\u03d5/2 varies quite slowly compared with sinn\u03d5/2 when n is large, so when sin 2 n\u03d5/2=1 we are very close to the maximum. The next maximum of sin 2 n\u03d5/2 comes at n\u03d5/2=3\u03c0/2 , or \u03d5=3\u03c0/n . This corresponds to the arrows having traversed the circle one and a half times. On putting \u03d5=3\u03c0/n into the formula to find the size of the maximum, we find that sin 2 3\u03c0/2=1 in the numerator (because that is why we picked this angle), and in the denominator we have sin 2 3\u03c0/2n . Now if n is sufficiently large, then this angle is very small and the sine is equal to the angle; so for all practical purposes, we can put sin3\u03c0/2n=3\u03c0/2n . Thus we find that the intensity at this maximum is I= I 0 (4 n 2 /9 \u03c0 2 ) . But n 2 I 0 was the maximum intensity, and so we have 4/9 \u03c0 2 times the maximum intensity, which is about 0.045 , less than 5 percent, of the maximum intensity! Of course there are decreasing intensities farther out. So we have a very sharp central maximum with very weak subsidiary maxima on the sides. It is possible to prove that the area of the whole curve, including all the little bumps, is equal to 2\u03c0n I 0 , or twice the area of the dotted rectangle in Fig. 30\u20132. Now let us consider further how we may apply Eq. (30.3) in different circumstances, and try to understand what is happening. Let us consider our sources to be all on a line, as drawn in Fig. 30\u20133. There are n of them, all spaced by a distance d , and we shall suppose that the intrinsic relative phase, one to the next, is \u03b1 . Then if we are observing in a given direction \u03b8 from the normal, there is an additional phase 2\u03c0dsin\u03b8/\u03bb because of the time delay between each successive two, which we talked about before. Thus \u03d5 =\u03b1+2\u03c0dsin\u03b8/\u03bb =\u03b1+kdsin\u03b8. (30.4) First, we shall take the case \u03b1=0 . That is, all oscillators are in phase, and we want to know what the intensity is as a function of the angle \u03b8 . In order to find out, we merely have to put \u03d5=kdsin\u03b8 into formula (30.3) and see what happens. In the first place, there is a maximum when \u03d5=0 . That means that when all the oscillators are in phase there is a strong intensity in the direction \u03b8=0 . On the other hand, an interesting question is, where is the first minimum? That occurs when \u03d5=2\u03c0/n . In other words, when 2\u03c0dsin\u03b8/\u03bb=2\u03c0/n , we get the first minimum of the curve. If we get rid of the 2\u03c0 \u2019s so we can look at it a little better, it says that ndsin\u03b8=\u03bb. (30.5) Now let us understand physically why we get a minimum at that position. nd is the total length L of the array. Referring to Fig. 30\u20133, we see that ndsin\u03b8=Lsin\u03b8=\u0394 . What (30.5) says is that when \u0394 is equal to one wavelength, we get a minimum. Now why do we get a minimum when \u0394=\u03bb ? Because the contributions of the various oscillators are then uniformly distributed in phase from 0 \u2218 to 360 \u2218 . The arrows (Fig. 30\u20131) are going around a whole circle\u2014we are adding equal vectors in all directions, and such a sum is zero. So when we have an angle such that \u0394=\u03bb , we get a minimum. That is the first minimum. There is another important feature about formula (30.3), which is that if the angle \u03d5 is increased by any multiple of 2\u03c0 , it makes no difference to the formula. So we will get other strong maxima at \u03d5=2\u03c0 , 4\u03c0 , 6\u03c0 , and so forth. Near each of these great maxima the pattern of Fig. 30\u20132 is repeated. We may ask ourselves, what is the geometrical circumstance that leads to these other great maxima? The condition is that \u03d5=2\u03c0m , where m is any integer. That is, 2\u03c0dsin\u03b8/\u03bb=2\u03c0m . Dividing by 2\u03c0 , we see that dsin\u03b8=m\u03bb. (30.6) This looks like the other formula, (30.5). No, that formula was ndsin\u03b8=\u03bb . The difference is that here we have to look at the individual sources, and when we say dsin\u03b8=m\u03bb , that means that we have an angle \u03b8 such that \u03b4=m\u03bb . In other words, each source is now contributing a certain amount, and successive ones are out of phase by a whole multiple of 360 \u2218 , and therefore are contributing in phase, because out of phase by 360 \u2218 is the same as being in phase. So they all contribute in phase and produce just as good a maximum as the one for m=0 that we discussed before. The subsidiary bumps, the whole shape of the pattern, is just like the one near \u03d5=0 , with exactly the same minima on each side, etc. Thus such an array will send beams in various directions\u2014each beam having a strong central maximum and a certain number of weak \u201cside lobes.\u201d The various strong beams are referred to as the zero-order beam, the first-order beam, etc., according to the value of m . m is called the order of the beam. We call attention to the fact that if d is less than \u03bb , Eq. (30.6) can have no solution except m=0 , so that if the spacing is too small there is only one possible beam, the zero-order one centered at \u03b8=0 . (Of course, there is also a beam in the opposite direction.) In order to get subsidiary great maxima, we must have the spacing d of the array greater than one wavelength. In technical work with antennas and wires it is possible to arrange that all the phases of the little oscillators, or antennas, are equal. The question is whether and how we can do a similar thing with light. We cannot at the present time literally make little optical-frequency radio stations and hook them up with infinitesimal wires and drive them all with a given phase. But there is a very easy way to do what amounts to the same thing. Suppose that we had a lot of parallel wires, equally spaced at a spacing d , and a radiofrequency source very far away, practically at infinity, which is generating an electric field which arrives at each one of the wires at the same phase (it is so far away that the time delay is the same for all of the wires). (One can work out cases with curved arrays, but let us take a plane one.) Then the external electric field will drive the electrons up and down in each wire. That is, the field which is coming from the original source will shake the electrons up and down, and in moving, these represent new generators. This phenomenon is called scattering: a light wave from some source can induce a motion of the electrons in a piece of material, and these motions generate their own waves. Therefore all that is necessary is to set up a lot of wires, equally spaced, drive them with a radiofrequency source far away, and we have the situation that we want, without a whole lot of special wiring. If the incidence is normal, the phases will be equal, and we will get exactly the circumstance we have been discussing. Therefore, if the wire spacing is greater than the wavelength, we will get a strong intensity of scattering in the normal direction, and in certain other directions given by (30.6). This can also be done with light! Instead of wires, we use a flat piece of glass and make notches in it such that each of the notches scatters a little differently than the rest of the glass. If we then shine light on the glass, each one of the notches will represent a source, and if we space the lines very finely, but not closer than a wavelength (which is technically almost impossible anyway), then we would expect a miraculous phenomenon: the light not only will pass straight through, but there will also be a strong beam at a finite angle, depending on the spacing of the notches! Such objects have actually been made and are in common use\u2014they are called diffraction gratings. In one of its forms, a diffraction grating consists of nothing but a plane glass sheet, transparent and colorless, with scratches on it. There are often several hundred scratches to the millimeter, very carefully arranged so as to be equally spaced. The effect of such a grating can be seen by arranging a projector so as to throw a narrow, vertical line of light (the image of a slit) onto a screen. When we put the grating into the beam, with its scratches vertical, we see that the line is still there but, in addition, on each side we have another strong patch of light which is colored. This, of course, is the slit image spread out over a wide angular range, because the angle \u03b8 in (30.6) depends upon \u03bb , and lights of different colors, as we know, correspond to different frequencies, and therefore different wavelengths. The longest visible wavelength is red, and since dsin\u03b8=\u03bb , that requires a larger \u03b8 . And we do, in fact, find that red is at a greater angle out from the central image! There should also be a beam on the other side, and indeed we see one on the screen. Then, there might be another solution of (30.6) when m=2 . We do see that there is something vaguely there\u2014very weak\u2014and there are even other beams beyond. We have just argued that all these beams ought to be of the same strength, but we see that they actually are not and, in fact, not even the first ones on the right and left are equal! The reason is that the grating has been carefully built to do just this. How? If the grating consists of very fine notches, infinitesimally wide, spaced evenly, then all the intensities would indeed be equal. But, as a matter of fact, although we have taken the simplest case, we could also have considered an array of pairs of antennas, in which each member of the pair has a certain strength and some relative phase. In this case, it is possible to get intensities which are different in the different orders. A grating is often made with little \u201csawtooth\u201d cuts instead of little symmetrical notches. By carefully arranging the \u201csawteeth,\u201d more light may be sent into one particular order of spectrum than into the others. In a practical grating, we would like to have as much light as possible in one of the orders. This may seem a complicated point to bring in, but it is a very clever thing to do, because it makes the grating more useful. So far, we have taken the case where all the phases of the sources are equal. But we also have a formula for \u03d5 when the phases differ from one to the next by an angle \u03b1 . That requires wiring up our antennas with a slight phase shift between each one. Can we do that with light? Yes, we can do it very easily, for suppose that there were a source of light at infinity, at an angle such that the light is coming in at an angle \u03b8 in , and let us say that we wish to discuss the scattered beam, which is leaving at an angle \u03b8 out (Fig. 30\u20134). The \u03b8 out is the same \u03b8 as we have had before, but the \u03b8 in is merely a means for arranging that the phase of each source is different: the light coming from the distant driving source first hits one scratch, then the next, then the next, and so on, with a phase shift from one to the other, which, as we see, is \u03b1=\u22122\u03c0dsin \u03b8 in /\u03bb . Therefore we have the formula for a grating in which light both comes in and goes out at an angle: \u03d5=2\u03c0dsin \u03b8 out /\u03bb\u22122\u03c0dsin \u03b8 in /\u03bb. (30.7) Let us try to find out where we get strong intensity in these circumstances. The condition for strong intensities is, of course, that \u03d5 should be a multiple of 2\u03c0 . There are several interesting points to be noted. One case of rather great interest is that which corresponds to m=0 , where d is less than \u03bb/2 ; in fact, this is the only solution. In this case we see that sin \u03b8 out =sin \u03b8 in , which may mean that \u03b8 out is the supplement of \u03b8 in so the light comes out in the same direction as the light which was exciting the grating. We might think that the light \u201cgoes right through.\u201d No, it is different light that we are talking about. The light that goes right through is from the original source; what we are talking about is the new light which is generated by scattering. It turns out that the scattered light is going in the same direction as the original light, in fact it can interfere with it\u2014a feature which we will study later. There is another solution for this same case: \u03b8 out may equal \u03b8 in . So not only do we get a beam in the same direction as the incoming beam but also one in another direction, such that the angle of incidence is equal to the angle of scattering. This we call the reflected beam. So we begin to understand the basic machinery of reflection: the light that comes in generates motions of the atoms in the reflector, and the reflector then regenerates a new wave, and one of the solutions for the direction of scattering, the only solution if the spacing of the scatterers is small compared with one wavelength, is that the angle at which the light comes out is equal to the angle at which it comes in! Next, we discuss the special case when d\u21920 . That is, we have just a solid piece of material, so to speak, but of finite length. In addition, we want the phase shift from one scatterer to the next to go to zero. In other words, we put more and more antennas between the other ones, so that each of the phase differences is getting smaller, but the number of antennas is increasing in such a way that the total phase difference, between one end of the line and the other, is constant. Let us see what happens to (30.3) if we keep the difference in phase n\u03d5 from one end to the other constant (say n\u03d5=\u03a6 ), letting the number go to infinity and the phase shift \u03d5 of each one go to zero. But now \u03d5 is so small that sin\u03d5=\u03d5 , and if we also recognize n 2 I 0 as I m , the maximum intensity at the center of the beam, we find I=4 I m sin 2 1 2 \u03a6/ \u03a6 2 . (30.8) This limiting case is what is shown in Fig. 30\u20132. In such circumstances we find the same general kind of a picture as for finite spacing with d<\u03bb/2 ; all the side lobes are practically the same as before, but there are no subsidiary higher-order maxima. If the scatterers are all in phase, we get a maximum in the direction \u03b8 out =0 , and a minimum when the distance \u0394 is equal to \u03bb , just as for finite d and n . So we can even analyze a continuous distribution of scatterers or oscillators, by using integrals instead of summing. As an example, suppose there were a long line of oscillators, with the charge oscillating along the direction of the line (Fig. 30\u20135). From such an array the greatest intensity is perpendicular to the line. There is a little bit of intensity up and down from the equatorial plane, but it is very slight. With this result, we can handle a more complicated situation. Suppose we have a set of such lines, each producing a beam only in a plane perpendicular to the line. To find the intensity in various directions from a series of long wires, instead of infinitesimal wires, is the same problem as it was for infinitesimal wires, so long as we are in the central plane perpendicular to the wires; we just add the contribution from each of the long wires. That is why, although we actually analyzed only tiny antennas, we might as well have used a grating with long, narrow slots. Each of the long slots produces an effect only in its own direction, not up and down, but they are all set next to each other horizontally, so they produce interference that way. Thus we can build up more complicated situations by having various distributions of scatterers in lines, planes, or in space. The first thing we did was to consider scatterers in a line, and we have just extended the analysis to strips; we can work it out by just doing the necessary summations, adding the contributions from the individual scatterers. The principle is always the same. We are now in a position to understand a number of interesting phenomena. For example, consider the use of a grating for separating wavelengths. We noticed that the whole spectrum was spread out on the screen, so a grating can be used as an instrument for separating light into its different wavelengths. One of the interesting questions is: supposing that there were two sources of slightly different frequency, or slightly different wavelength, how close together in wavelength could they be such that the grating would be unable to tell that there were really two different wavelengths there? The red and the blue were clearly separated. But when one wave is red and the other is slightly redder, very close, how close can they be? This is called the resolving power of the grating, and one way of analyzing the problem is as follows. Suppose that for light of a certain color we happen to have the maximum of the diffracted beam occurring at a certain angle. If we vary the wavelength the phase 2\u03c0dsin\u03b8/\u03bb is different, so of course the maximum occurs at a different angle. That is why the red and blue are spread out. How different in angle must it be in order for us to be able to see it? If the two maxima are exactly on top of each other, of course we cannot see them. If the maximum of one is far enough away from the other, then we can see that there is a double bump in the distribution of light. In order to be able to just make out the double bump, the following simple criterion, called Rayleigh\u2019s criterion, is usually used (Fig. 30\u20136). It is that the first minimum from one bump should sit at the maximum of the other. Now it is very easy to calculate, when one minimum sits on the other maximum, how much the difference in wavelength is. The best way to do it is geometrically. In order to have a maximum for wavelength \u03bb \u2032 , the distance \u0394 (Fig. 30\u20133) must be n \u03bb \u2032 , and if we are looking at the m th-order beam, it is mn \u03bb \u2032 . In other words, 2\u03c0dsin\u03b8/ \u03bb \u2032 =2\u03c0m , so ndsin\u03b8 , which is \u0394 , is m \u03bb \u2032 times n , or mn \u03bb \u2032 . For the other beam, of wavelength \u03bb , we want to have a minimum at this angle. That is, we want \u0394 to be exactly one wavelength \u03bb more than mn\u03bb . That is, \u0394=mn\u03bb+\u03bb=mn \u03bb \u2032 . Thus if \u03bb \u2032 =\u03bb+\u0394\u03bb , we find \u0394\u03bb/\u03bb=1/mn. (30.9) The ratio \u03bb/\u0394\u03bb is called the resolving power of a grating; we see that it is equal to the total number of lines in the grating, times the order. It is not hard to prove that this formula is equivalent to the formula that the error in frequency is equal to the reciprocal time difference between extreme paths that are allowed to interfere:1 \u0394\u03bd=1/T. \u0394 / T In fact, that is the best way to remember it, because the general formula works not only for gratings, but for any other instrument whatsoever, while the special formula (30.9) depends on the fact that we are using a grating. Now let us consider another problem in resolving power. This has to do with the antenna of a radio telescope, used for determining the position of radio sources in the sky, i.e., how large they are in angle. Of course if we use any old antenna and find signals, we would not know from what direction they came. We are very interested to know whether the source is in one place or another. One way we can find out is to lay out a whole series of equally spaced dipole wires on the Australian landscape. Then we take all the wires from these antennas and feed them into the same receiver, in such a way that all the delays in the feed lines are equal. Thus the receiver receives signals from all of the dipoles in phase. That is, it adds all the waves from every one of the dipoles in the same phase. Now what happens? If the source is directly above the array, at infinity or nearly so, then its radiowaves will excite all the antennas in the same phase, so they all feed the receiver together. Now suppose that the radio source is at a slight angle \u03b8 from the vertical. Then the various antennas are receiving signals a little out of phase. The receiver adds all these out-of-phase signals together, and so we get nothing, if the angle \u03b8 is too big. How big may the angle be? Answer: we get zero if the angle \u0394/L=\u03b8 (Fig. 30\u20133) corresponds to a 360 \u2218 phase shift, that is, if \u0394 is the wavelength \u03bb . This is because the vector contributions form together a complete polygon with zero resultant. The smallest angle that can be resolved by an antenna array of length L is \u03b8=\u03bb/L . Notice that the receiving pattern of an antenna such as this is exactly the same as the intensity distribution we would get if we turned the receiver around and made it into a transmitter. This is an example of what is called a reciprocity principle. It turns out, in fact, to be generally true for any arrangement of antennas, angles, and so on, that if we first work out what the relative intensities would be in various directions if the receiver were a transmitter instead, then the relative directional sensitivity of a receiver with the same external wiring, the same array of antennas, is the same as the relative intensity of emission would be if it were a transmitter. Some radio antennas are made in a different way. Instead of having a whole lot of dipoles in a long line, with a lot of feed wires, we may arrange them not in a line but in a curve, and put the receiver at a certain point where it can detect the scattered waves. This curve is cleverly designed so that if the radiowaves are coming down from above, and the wires scatter, making a new wave, the wires are so arranged that the scattered waves reach the receiver all at the same time (Fig. 26\u201312). In other words, the curve is a parabola, and when the source is exactly on its axis, we get a very strong intensity at the focus. In this case we understand very clearly what the resolving power of such an instrument is. The arranging of the antennas on a parabolic curve is not an essential point. It is only a convenient way to get all the signals to the same point with no relative delay and without feed wires. The angle such an instrument can resolve is still \u03b8=\u03bb/L , where L is the separation of the first and last antennas. It does not depend on the spacing of the antennas and they may be very close together or in fact be all one piece of metal. Now we are describing a telescope mirror, of course. We have found the resolving power of a telescope! (Sometimes the resolving power is written \u03b8=1.22\u03bb/L , where L is the diameter of the telescope. The reason that it is not exactly \u03bb/L is this: when we worked out that \u03b8=\u03bb/L , we assumed that all the lines of dipoles were equal in strength, but when we have a circular telescope, which is the way we usually arrange a telescope, not as much signal comes from the outside edges, because it is not like a square, where we get the same intensity all along a side. We get somewhat less because we are using only part of the telescope there; thus we can appreciate that the effective diameter is a little shorter than the true diameter, and that is what the 1.22 factor tells us. In any case, it seems a little pedantic to put such precision into the resolving power formula.2) The above, then, are some of the effects of interference obtained by adding the various waves. But there are a number of other examples, and even though we do not understand the fundamental mechanism yet, we will some day, and we can understand even now how the interference occurs. For example, when a light wave hits a surface of a material with an index n , let us say at normal incidence, some of the light is reflected. The reason for the reflection we are not in a position to understand right now; we shall discuss it later. But suppose we know that some of the light is reflected both on entering and leaving a refracting medium. Then, if we look at the reflection of a light source in a thin film, we see the sum of two waves; if the thicknesses are small enough, these two waves will produce an interference, either constructive or destructive, depending on the signs of the phases. It might be, for instance, that for red light, we get an enhanced reflection, but for blue light, which has a different wavelength, perhaps we get a destructively interfering reflection, so that we see a bright red reflection. If we change the thickness, i.e., if we look at another place where the film is thicker, it may be reversed, the red interfering and the blue not, so it is bright blue, or green, or yellow, or whatnot. So we see colors when we look at thin films and the colors change if we look at different angles, because we can appreciate that the timings are different at different angles. Thus we suddenly appreciate another hundred thousand situations involving the colors that we see on oil films, soap bubbles, etc. at different angles. But the principle is all the same: we are only adding waves at different phases. As another important application of diffraction, we may mention the following. We used a grating and we saw the diffracted image on the screen. If we had used monochromatic light, it would have been at a certain specific place. Then there were various higher-order images also. From the positions of the images, we could tell how far apart the lines on the grating were, if we knew the wavelength of the light. From the difference in intensity of the various images, we could find out the shape of the grating scratches, whether the grating was made of wires, sawtooth notches, or whatever, without being able to see them. This principle is used to discover the positions of the atoms in a crystal. The only complication is that a crystal is three-dimensional; it is a repeating three-dimensional array of atoms. We cannot use ordinary light, because we must use something whose wavelength is less than the space between the atoms or we get no effect; so we must use radiation of very short wavelength, i.e., x-rays. So, by shining x-rays into a crystal and by noticing how intense is the reflection in the various orders, we can determine the arrangement of the atoms inside without ever being able to see them with the eye! It is in this way that we know the arrangement of the atoms in various substances, which permitted us to draw those pictures in the first chapter, showing the arrangement of atoms in salt, and so on. We shall later come back to this subject and discuss it in more detail, and therefore we say no more about this most remarkable idea at present. Now we come to a very interesting situation. Suppose that we have an opaque sheet with holes in it, and a light on one side of it. We want to know what the intensity is on the other side. What most people say is that the light shines through the holes, and produces an effect on the other side. It will turn out that one gets the right answer, to an excellent approximation, if he assumes that there are sources distributed with uniform density across the open holes, and that the phases of these sources are the same as they would have been if the opaque material were absent. Of course, actually there are no sources at the holes, in fact that is the only place that there are certainly no sources. Nevertheless, we get the correct diffraction patterns by considering the holes to be the only places that there are sources; that is a rather peculiar fact. We shall explain later why this is true, but for now let us just suppose that it is. In the theory of diffraction there is another kind of diffraction that we should briefly discuss. It is usually not discussed in an elementary course as early as this, only because the mathematical formulas involved in adding these little vectors are a little elaborate. Otherwise it is exactly the same as we have been doing all along. All the interference phenomena are the same; there is nothing very much more advanced involved, only the circumstances are more complicated and it is harder to add the vectors together, that is all. Suppose that we have light coming in from infinity, casting a shadow of an object. Figure 30\u20137 shows a screen on which the shadow of an object AB is made by a light source very far away compared with one wavelength. Now we would expect that outside the shadow, the intensity is all bright, and inside it, it is all dark. As a matter of fact, if we plot the intensity as a function of position near the shadow edge, the intensity rises and then overshoots, and wobbles, and oscillates about in a very peculiar manner near this edge (Fig. 30\u20139). We now shall discuss the reason for this. If we use the theorem that we have not yet proved, then we can replace the actual problem by a set of effective sources uniformly distributed over the open space beyond the object. We imagine a large number of very closely spaced antennas, and we want the intensity at some point P . That looks just like what we have been doing. Not quite; because our screen is not at infinity. We do not want the intensity at infinity, but at a finite point. To calculate the intensity at some particular place, we have to add the contributions from all the antennas. First there is an antenna at D , exactly opposite P ; if we go up a little bit in angle, let us say a height h , then there is an increase in delay (there is also a change in amplitude because of the change in distance, but this is a very small effect if we are at all far away, and is much less important than the difference in the phases). Now the path difference EP\u2212DP is approximately h 2 /2s , so that the phase difference is proportional to the square of how far we go from D , while in our previous work s was infinite, and the phase difference was linearly proportional to h . When the phases are linearly proportional, each vector adds at a constant angle to the next vector. What we now need is a curve which is made by adding a lot of infinitesimal vectors with the requirement that the angle they make shall increase, not linearly, but as the square of the length of the curve. To construct that curve involves slightly advanced mathematics, but we can always construct it by actually drawing the arrows and measuring the angles. In any case, we get the marvelous curve (called Cornu\u2019s spiral) shown in Fig. 30\u20138. Now how do we use this curve? If we want the intensity, let us say, at point P , we add a lot of contributions of different phases from point D on up to infinity, and from D down only to point B P . So we start at B P in Fig. 30\u20138, and draw a series of arrows of ever-increasing angle. Therefore the total contribution above point B P all goes along the spiraling curve. If we were to stop integrating at some place, then the total amplitude would be a vector from B to that point; in this particular problem we are going to infinity, so the total answer is the vector B P\u221e . Now the position on the curve which corresponds to point B P on the object depends upon where point P is located, since point D , the inflection point, always corresponds to the position of point P . Thus, depending upon where P is located above B , the beginning point will fall at various positions on the lower left part of the curve, and the resultant vector B P\u221e , will have many maxima and minima (Fig. 30\u20139). On the other hand, if we are at Q , on the other side of P , then we are using only one end of the spiral curve, and not the other end. In other words, we do not even start at D , but at B Q , so on this side we get an intensity which continuously falls off as Q goes farther into the shadow. One point that we can immediately calculate with ease, to show that we really understand it, is the intensity exactly opposite the edge. The intensity here is 1/4 that of the incident light. Reason: Exactly at the edge (so the endpoint B of the arrow is at D in Fig. 30\u20138) we have half the curve that we would have had if we were far into the bright region. If our point R is far into the light we go from one end of the curve to the other, that is, one full unit vector; but if we are at the edge of the shadow, we have only half the amplitude\u2014 1/4 the intensity. In this chapter we have been finding the intensity produced in various directions from various distributions of sources. As a final example we shall derive a formula which we shall need for the next chapter on the theory of the index of refraction. Up to this point relative intensities have been sufficient for our purpose, but this time we shall find the complete formula for the field in the following situation. Suppose that we have a plane full of sources, all oscillating together, with their motion in the plane and all having the same amplitude and phase. What is the field at a finite, but very large, distance away from the plane? (We cannot get very close, of course, because we do not have the right formulas for the field close to the sources.) If we let the plane of the charges be the xy -plane, then we want to find the field at the point P far out on the z -axis (Fig. 30\u201310). We suppose that there are \u03b7 charges per unit area of the plane, and that each one of them has a charge q . All of the charges move with simple harmonic motion, with the same direction, amplitude, and phase. We let the motion of each charge, with respect to its own average position, be x 0 cos\u03c9t . Or, using the complex notation and remembering that the real part represents the actual motion, the motion can be described by x 0 e i\u03c9t . Now we find the field at the point P from all of the charges by finding the field there from each charge q , and then adding the contributions from all the charges. We know that the radiation field is proportional to the acceleration of the charge, which is \u2212 \u03c9 2 x 0 e i\u03c9t (and is the same for every charge). The electric field that we want at the point P due to a charge at the point Q is proportional to the acceleration of the charge q , but we have to remember that the field at the point P at the instant t is given by the acceleration of the charge at the earlier time t \u2032 =t\u2212r/c , where r/c is the time it takes the waves to travel the distance r from Q to P . Therefore the field at P is proportional to \u2212 \u03c9 2 x 0 e i\u03c9(t\u2212r/c) . (30.10) Using this value for the acceleration as seen from P in our formula for the electric field at large distances from a radiating charge, we get ( Electric field at P from charge at Q )\u2248 q 4\u03c0 \u03f5 0 c 2 \u03c9 2 x 0 e i\u03c9(t\u2212r/c) r . (30.11) Now this formula is not quite right, because we should have used not the acceleration of the charge but its component perpendicular to the line QP . We shall suppose, however, that the point P is so far away, compared with the distance of the point Q from the axis (the distance \u03c1 in Fig. 30\u201310), for those charges that we need to take into account, that we can leave out the cosine factor (which would be nearly equal to 1 anyway). To get the total field at P , we now add the effects of all the charges in the plane. We should, of course, make a vector sum. But since the direction of the electric field is nearly the same for all the charges, we may, in keeping with the approximation we have already made, just add the magnitudes of the fields. To our approximation the field at P depends only on the distance r , so all charges at the same r produce equal fields. So we add, first, the fields of those charges in a ring of width d\u03c1 and radius \u03c1 . Then, by taking the integral over all \u03c1 , we will obtain the total field. The number of charges in the ring is the product of the surface area of the ring, 2\u03c0\u03c1d\u03c1 , and \u03b7 , the number of charges per unit area. We have, then, Total field at P= \u222b q 4\u03c0 \u03f5 0 c 2 \u03c9 2 x 0 e i\u03c9(t\u2212r/c) r \u22c5\u03b7\u22c52\u03c0\u03c1d\u03c1. (30.12) We wish to evaluate this integral from \u03c1=0 to \u03c1=\u221e . The variable t , of course, is to be held fixed while we do the integral, so the only varying quantities are \u03c1 and r . Leaving out all the constant factors, including the factor e i\u03c9t , for the moment, the integral we wish is \u222b \u03c1=\u221e \u03c1=0 e \u2212i\u03c9r/c r \u03c1d\u03c1. (30.13) To do this integral we need to use the relation between r and \u03c1 : r 2 = \u03c1 2 + z 2 . (30.14) Since z is independent of \u03c1 , when we take the differential of this equation, we get 2rdr=2\u03c1d\u03c1, 2 d 2 d which is lucky, since in our integral we can replace \u03c1d\u03c1 by rdr and the r will cancel the one in the denominator. The integral we want is then the simpler one \u222b r=\u221e r=z e \u2212i\u03c9r/c dr. (30.15) To integrate an exponential is very easy. We divide by the coefficient of r in the exponent and evaluate the exponential at the limits. But the limits of r are not the same as the limits of \u03c1 . When \u03c1=0 , we have r=z , so the limits of r are z to infinity. We get for the integral \u2212 c i\u03c9 [ e \u2212i\u221e \u2212 e \u2212(i\u03c9/c)z ], (30.16) where we have written \u221e for (\u03c9/c)\u221e , since they both just mean a very large number! Now e \u2212i\u221e is a mysterious quantity. Its real part, for example, is cos(\u2212\u221e) , which, mathematically speaking, is completely indefinite (although we would expect it to be somewhere\u2014or everywhere (?)\u2014between +1 and \u22121 !). But in a physical situation, it can mean something quite reasonable, and usually can just be taken to be zero. To see that this is so in our case, we go back to consider again the original integral (30.15). We can understand (30.15) as a sum of many small complex numbers, each of magnitude \u0394r , and with the angle \u03b8=\u2212\u03c9r/c in the complex plane. We can try to evaluate the sum by a graphical method. In Fig. 30\u201311 we have drawn the first five pieces of the sum. Each segment of the curve has the length \u0394r and is placed at the angle \u0394\u03b8=\u2212\u03c9\u0394r/c with respect to the preceding piece. The sum for these first five pieces is represented by the arrow from the starting point to the end of the fifth segment. As we continue to add pieces we shall trace out a polygon until we get back to the starting point (approximately) and then start around once more. Adding more pieces, we just go round and round, staying close to a circle whose radius is easily shown to be c/\u03c9 . We can see now why the integral does not give a definite answer! But now we have to go back to the physics of the situation. In any real situation the plane of charges cannot be infinite in extent, but must sometime stop. If it stopped suddenly, and was exactly circular in shape, our integral would have some value on the circle in Fig. 30\u201311. If, however, we let the number of charges in the plane gradually taper off at some large distance from the center (or else stop suddenly but in an irregular shape so for larger \u03c1 the entire ring of width d\u03c1 no longer contributes), then the coefficient \u03b7 in the exact integral would decrease toward zero. Since we are adding smaller pieces but still turning through the same angle, the graph of our integral would then become a curve which is a spiral. The spiral would eventually end up at the center of our original circle, as drawn in Fig. 30\u201312. The physically correct integral is the complex number A in the figure represented by the interval from the starting point to the center of the circle, which is just equal to c i\u03c9 e \u2212i\u03c9z/c , (30.17) as you can work out for yourself. This is the same result we would get from Eq. (30.16) if we set e \u2212i\u221e =0 . (There is also another reason why the contribution to the integral tapers off for large values of r , and that is the factor we have omitted for the projection of the acceleration on the plane perpendicular to the line PQ .) We are, of course, interested only in physical situations, so we will take e \u2212i\u221e equal to zero. Returning to our original formula (30.12) for the field and putting back all of the factors that go with the integral, we have the result Total field at P= \u2212 \u03b7q 2 \u03f5 0 c i\u03c9 x 0 e i\u03c9(t\u2212z/c) (30.18) (remembering that 1/i=\u2212i ). It is interesting to note that ( i\u03c9 x 0 e i\u03c9t ) is just equal to the velocity of the charges, so that we can also write the equation for the field as Total field at P= \u2212 \u03b7q 2 \u03f5 0 c [velocity of charges ] at t\u2212z/c , (30.19) which is a little strange, because the retardation is just by the distance z , which is the shortest distance from P to the plane of charges. But that is the way it comes out\u2014fortunately a rather simple formula. (We may add, by the way, that although our derivation is valid only for distances far from the plane of oscillatory charges, it turns out that the formula (30.18) or (30.19) is correct at any distance z , even for z<\u03bb .)"
    },
    {
        "input": "The Hyperfine Splitting in Hydrogen",
        "output": "In this chapter we take up the \u201chyperfine splitting\u201d of hydrogen, because it is a physically interesting example of what we can already do with quantum mechanics. It\u2019s an example with more than two states, and it will be illustrative of the methods of quantum mechanics as applied to slightly more complicated problems. It is enough more complicated that once you see how this one is handled you can get immediately the generalization to all kinds of problems. As you know, the hydrogen atom consists of an electron sitting in the neighborhood of the proton, where it can exist in any one of a number of discrete energy states in each one of which the pattern of motion of the electron is different. The first excited state, for example, lies 3/4 of a Rydberg, or about 10 electron volts, above the ground state. But even the so-called ground state of hydrogen is not really a single, definite-energy state, because of the spins of the electron and the proton. These spins are responsible for the \u201chyperfine structure\u201d in the energy levels, which splits all the energy levels into several nearly equal levels. The electron can have its spin either \u201cup\u201d or \u201cdown,\u201d and the proton can also have its spin either \u201cup\u201d or \u201cdown.\u201d There are, therefore, four possible spin states for every dynamical condition of the atom. That is, when people say \u201cthe ground state\u201d of hydrogen, they really mean the \u201cfour ground states,\u201d and not just the very lowest state. The four spin states do not all have exactly the same energy; there are slight shifts from the energies we would expect with no spins. The shifts are, however, much, much smaller than the 10 electron volts or so from the ground state to the next state above. As a consequence, each dynamical state has its energy split into a set of very close energy levels\u2014the so-called hyperfine splitting. The energy differences among the four spin states is what we want to calculate in this chapter. The hyperfine splitting is due to the interaction of the magnetic moments of the electron and proton, which gives a slightly different magnetic energy for each spin state. These energy shifts are only about ten-millionths of an electron volt\u2014really very small compared with 10 electron volts! It is because of this large gap that we can think about the ground state of hydrogen as a \u201cfour-state\u201d system, without worrying about the fact that there are really many more states at higher energies. We are going to limit ourselves here to a study of the hyperfine structure of the ground state of the hydrogen atom. For our purposes we are not interested in any of the details about the positions of the electron and proton because that has all been worked out by the atom so to speak\u2014it has worked itself out by getting into the ground state. We need know only that we have an electron and proton in the neighborhood of each other with some definite spatial relationship. In addition, they can have various different relative orientations of their spins. It is only the effect of the spins that we want to look into. The first question we have to answer is: What are the base states for the system? Now the question has been put incorrectly. There is no such thing as \u201cthe\u201d base states, because, of course, the set of base states you may choose is not unique. New sets can always be made out of linear combinations of the old. There are always many choices for the base states, and among them, any choice is equally legitimate. So the question is not what is the base set, but what could a base set be? We can choose any one we wish for our own convenience. It is usually best to start with a base set which is physically the clearest. It may not be the solution to any problem, or may not have any direct importance, but it will generally make it easier to understand what is going on. We choose the following four base states: State 1:The electron and proton are both spin \u201cup.\u201d State 2:The electron is \u201cup\u201d and the proton is \u201cdown.\u201d State 3:The electron is \u201cdown\u201d and the proton is \u201cup.\u201d State 4:The electron and proton are both \u201cdown.\u201d We need a handy notation for these four states, so we\u2019ll represent them this way: State 1:|++\u27e9;electronup,protonup State 2:|+\u2212\u27e9;electronup,protondown State 3:|\u2212+\u27e9;electrondown,protonup State 4:|\u2212\u2212\u27e9;electrondown,protondown (12.1) You will have to remember that the first plus or minus sign refers to the electron and the second, to the proton. For handy reference, we\u2019ve also summarized the notation in Fig. 12-1. Sometimes it will also be convenient to call these states |1\u27e9 , |2\u27e9 , |3\u27e9 , and |4\u27e9 . You may say, \u201cBut the particles interact, and maybe these aren\u2019t the right base states. It sounds as though you are considering the two particles independently.\u201d Yes, indeed! The interaction raises the problem: what is the Hamiltonian for the system, but the interaction is not involved in the question of how to describe the system. What we choose for the base states has nothing to do with what happens next. It may be that the atom cannot ever stay in one of these base states, even if it is started that way. That\u2019s another question. That\u2019s the question: How do the amplitudes change with time in a particular (fixed) base? In choosing the base states, we are just choosing the \u201cunit vectors\u201d for our description. While we\u2019re on the subject, let\u2019s look at the general problem of finding a set of base states when there is more than one particle. You know the base states for a single particle. An electron, for example, is completely described in real life\u2014not in our simplified cases, but in real life\u2014by giving the amplitudes to be in each of the following states: |electron \u201cup\u201d with momentum p\u27e9 | electron \u201cup\u201d with momentum \u27e9 or |electron \u201cdown\u201d with momentum p\u27e9. | electron \u201cdown\u201d with momentum \u27e9 There are really two infinite sets of states, one state for each value of p . That is to say that an electron state |\u03c8\u27e9 is completely described if you know all the amplitudes \u27e8+,p|\u03c8\u27e9and\u27e8\u2212,p|\u03c8\u27e9, \u27e8 | \u03c8 \u27e9 and \u27e8 | \u03c8 \u27e9 where the + and \u2212 represent the components of angular momentum along some axis\u2014usually the z -axis\u2014and p is the vector momentum. There must, therefore, be two amplitudes for every possible momentum (a multi-infinite set of base states). That is all there is to describing a single particle. When there is more than one particle, the base states can be written in a similar way. For instance, if there were an electron and a proton in a more complicated situation than we are considering, the base states could be of the following kind: | electron spin \u201cup\u201d with momentum p 1 , proton spin \u201cdown\u201d with momentum p 2 \u27e9. And so on for other spin combinations. If there are more than two particles\u2014same idea. So you see that to write down the possible base states is really very easy. The only problem is, what is the Hamiltonian? For our study of the ground state of hydrogen we don\u2019t need to use the full sets of base states for the various momenta. We are specifying particular momentum states for the proton and electron when we say \u201cthe ground state.\u201d The details of the configuration\u2014the amplitudes for all the momentum base states\u2014can be calculated, but that is another problem. Now we are concerned only with the effects of the spin, so we can take only the four base states of (12.1). Our next problem is: What is the Hamiltonian for this set of states? We\u2019ll tell you in a moment what it is. But first, we should remind you of one thing: any state can always be written as a linear combination of the base states. For any state |\u03c8\u27e9 we can write |\u03c8\u27e9= + |++\u27e9\u27e8++|\u03c8\u27e9+|+\u2212\u27e9\u27e8+\u2212|\u03c8\u27e9 |\u2212+\u27e9\u27e8\u2212+|\u03c8\u27e9+|\u2212\u2212\u27e9\u27e8\u2212\u2212|\u03c8\u27e9. (12.2) Remember that the complete brackets are just complex numbers, so we can also write them in the usual fashion as C i , where i=1 , 2 , 3 , or 4 , and write Eq. (12.2) as |\u03c8\u27e9= + |++\u27e9 C 1 +|+\u2212\u27e9 C 2 |\u2212+\u27e9 C 3 +|\u2212\u2212\u27e9 C 4 . (12.3) By giving the four amplitudes C i we completely describe the spin state |\u03c8\u27e9 . If these four amplitudes change with time, as they will, the rate of change in time is given by the operator H ^ . The problem is to find the H ^ . There is no general rule for writing down the Hamiltonian of an atomic system, and finding the right formula is much more of an art than finding a set of base states. We were able to tell you a general rule for writing a set of base states for any problem of a proton and an electron, but to describe the general Hamiltonian of such a combination is too hard at this level. Instead, we will lead you to a Hamiltonian by some heuristic argument\u2014and you will have to accept it as the correct one because the results will agree with the test of experimental observation. You will remember that in the last chapter we were able to describe the Hamiltonian of a single, spin one-half particle by using the sigma matrices\u2014or the exactly equivalent sigma operators. The properties of the operators are summarized in Table 12-1. These operators\u2014which are just a convenient, shorthand way of keeping track of the matrix elements of the type \u27e8+| \u03c3 z |+\u27e9 \u2014were useful for describing the behavior of a single particle of spin one-half. The question is: Can we find an analogous device to describe a system with two spins? The answer is yes, very simply, as follows. We invent a thing which we will call \u201csigma electron,\u201d which we represent by the vector operator \u03c3 e , and which has the x -, y -, and z -components, \u03c3 e x , \u03c3 e y , \u03c3 e z . We now make the convention that when one of these things operates on any one of our four base states of the hydrogen atom, it acts only on the electron spin, and in exactly the same way as if the electron were all by itself. Example: What is \u03c3 e y |\u2212+\u27e9 ? Since \u03c3 y on an electron \u201cdown\u201d is \u2212i times the corresponding state with the electron \u201cup\u201d, \u03c3 e y |\u2212+\u27e9=\u2212i|++\u27e9. e | \u27e9 | \u27e9 (When \u03c3 e y acts on the combined state it flips over the electron, but does nothing to the proton and multiplies the result by \u2212i .) Operating on the other states, \u03c3 e y would give \u03c3 e y |++\u27e9 \u03c3 e y |+\u2212\u27e9 \u03c3 e y |\u2212\u2212\u27e9 =i|\u2212+\u27e9, =i|\u2212\u2212\u27e9, =\u2212i|+\u2212\u27e9. Just remember that the operators \u03c3 e work only on the first spin symbol\u2014that is, on the electron spin. Next we define the corresponding operator \u201csigma proton\u201d for the proton spin. Its three components \u03c3 p x , \u03c3 p y , \u03c3 p z act in the same way as \u03c3 e , only on the proton spin. For example, if we have \u03c3 p x acting on each of the four base states, we get\u2014always using Table 12-1\u2014 \u03c3 p x |++\u27e9 \u03c3 p x |+\u2212\u27e9 \u03c3 p x |\u2212+\u27e9 \u03c3 p x |\u2212\u2212\u27e9 =|+\u2212\u27e9, =|++\u27e9, =|\u2212\u2212\u27e9, =|\u2212+\u27e9. As you can see, it\u2019s not very hard. Now in the most general case we could have more complex things. For instance, we could have products of the two operators like \u03c3 e y \u03c3 p z . When we have such a product we do first what the operator on the right says, and then do what the other one says.1 For example, we would have that \u03c3 e x \u03c3 p z |+\u2212\u27e9= \u03c3 e x ( \u03c3 p z |+\u2212\u27e9)= \u03c3 e x (\u2212|+\u2212\u27e9)=\u2212 \u03c3 e x |+\u2212\u27e9=\u2212|\u2212\u2212\u27e9. Note that these operators don\u2019t do anything on pure numbers\u2014we have used this fact when we wrote \u03c3 e x (\u22121)=(\u22121) \u03c3 e x . We say that the operators \u201ccommute\u201d with pure numbers, or that a number \u201ccan be moved through\u201d the operator. You can practice by showing that the product \u03c3 e x \u03c3 p z gives the following results for the four states: \u03c3 e x \u03c3 p z |++\u27e9 \u03c3 e x \u03c3 p z |+\u2212\u27e9 \u03c3 e x \u03c3 p z |\u2212+\u27e9 \u03c3 e x \u03c3 p z |\u2212\u2212\u27e9 =+|\u2212+\u27e9, =\u2212|\u2212\u2212\u27e9, =+|++\u27e9, =\u2212|+\u2212\u27e9. If we take all the possible operators, using each kind of operator only once, there are sixteen possibilities. Yes, sixteen\u2014provided we include also the \u201cunit operator\u201d 1 ^ . First, there are the three: \u03c3 e x , \u03c3 e y , \u03c3 e z . Then the three \u03c3 p x , \u03c3 p y , \u03c3 p z \u2014that makes six. In addition, there are the nine possible products of the form \u03c3 e x \u03c3 p y which makes a total of 15. And there\u2019s the unit operator which just leaves any state unchanged. Sixteen in all. Now note that for a four-state system, the Hamiltonian matrix has to be a four-by-four matrix of coefficients\u2014it will have sixteen entries. It is easily demonstrated that any four-by-four matrix\u2014and, therefore, the Hamiltonian matrix in particular\u2014can be written as a linear combination of the sixteen double-spin matrices corresponding to the set of operators we have just made up. Therefore, for the interaction between a proton and an electron that involves only their spins, we can expect that the Hamiltonian operator can be written as a linear combination of the same 16 operators. The only question is, how? Well, first, we know that the interaction doesn\u2019t depend on our choice of axes for a coordinate system. If there is no external disturbance\u2014like a magnetic field\u2014to determine a unique direction in space, the Hamiltonian can\u2019t depend on our choice of the direction of the x -, y -, and z -axes. That means that the Hamiltonian can\u2019t have a term like \u03c3 e x all by itself. It would be ridiculous, because then somebody with a different coordinate system would get different results. The only possibilities are a term with the unit matrix, say a constant a (times 1 ^ ), and some combination of the sigmas that doesn\u2019t depend on the coordinates\u2014some \u201cinvariant\u201d combination. The only scalar invariant combination of two vectors is the dot product, which for our \u03c3 \u2019s is \u03c3 e \u22c5 \u03c3 p = \u03c3 e x \u03c3 p x + \u03c3 e y \u03c3 p y + \u03c3 e z \u03c3 p z . (12.4) This operator is invariant with respect to any rotation of the coordinate system. So the only possibility for a Hamiltonian with the proper symmetry in space is a constant times the unit matrix plus a constant times this dot product, say, H ^ = E 0 +A \u03c3 e \u22c5 \u03c3 p . (12.5) That\u2019s our Hamiltonian. It\u2019s the only thing that it can be, by the symmetry of space, so long as there is no external field. The constant term doesn\u2019t tell us much; it just depends on the level we choose to measure energies from. We may just as well take E 0 =0 . The second term tells us all we need to know to find the level splitting of the hydrogen. If you want to, you can think of the Hamiltonian in a different way. If there are two magnets near each other with magnetic moments \u03bc e and \u03bc p , the mutual energy will depend on \u03bc e \u22c5 \u03bc p \u2014among other things. And, you remember, we found that the classical thing we call \u03bc e appears in quantum mechanics as \u03bc e \u03c3 e . Similarly, what appears classically as \u03bc p will usually turn out in quantum mechanics to be \u03bc p \u03c3 p (where \u03bc p is the magnetic moment of the proton, which is about 1000 times smaller than \u03bc e , and has the opposite sign). So Eq. (12.5) says that the interaction energy is like the interaction between two magnets\u2014only not quite, because the interaction of the two magnets depends on the radial distance between them. But Eq. (12.5) could be\u2014and, in fact, is\u2014some kind of an average interaction. The electron is moving all around inside the atom, and our Hamiltonian gives only the average interaction energy. All it says is that for a prescribed arrangement in space for the electron and proton there is an energy proportional to the cosine of the angle between the two magnetic moments, speaking classically. Such a classical qualitative picture may help you to understand where it comes from, but the important thing is that Eq. (12.5) is the correct quantum mechanical formula. The order of magnitude of the classical interaction between two magnets would be the product of the two magnetic moments divided by the cube of the distance between them. The distance between the electron and the proton in the hydrogen atom is, speaking roughly, one half an atomic radius, or 0.5 angstrom. It is, therefore, possible to make a crude estimate that the constant A should be about equal to the product of the two magnetic moments \u03bc e and \u03bc p divided by the cube of 1/2 angstrom. Such an estimate gives a number in the right ballpark. It turns out that A can be calculated accurately once you understand the complete quantum theory of the hydrogen atom\u2014which we so far do not. It has, in fact, been calculated to an accuracy of about 30 parts in one million. So, unlike the flip-flop constant A of the ammonia molecule, which couldn\u2019t be calculated at all well by a theory, our constant A for the hydrogen can be calculated from a more detailed theory. But never mind, we will for our present purposes think of the A as a number which could be determined by experiment, and analyze the physics of the situation. Taking the Hamiltonian of Eq. (12.5), we can use it with the equation i\u210f C \u02d9 i = \u2211 j H ij C j (12.6) to find out what the spin interactions do to the energy levels. To do that, we need to work out the sixteen matrix elements H ij =\u27e8i|H|j\u27e9 corresponding to each pair of the four base states in (12.1). We begin by working out what H ^ |j\u27e9 is for each of the four base states. For example, H ^ |++\u27e9 =A \u03c3 e \u22c5 \u03c3 p |++\u27e9 =A{ \u03c3 e x \u03c3 p x + \u03c3 e y \u03c3 p y + \u03c3 e z \u03c3 p z }|++\u27e9. (12.7) Using the method we described a little earlier\u2014it\u2019s easy if you have memorized Table 12-1\u2014we find what each pair of \u03c3 \u2019s does on |++\u27e9 . The answer is \u03c3 e x \u03c3 p x |++\u27e9 \u03c3 e y \u03c3 p y |++\u27e9 \u03c3 e z \u03c3 p z |++\u27e9 =+|\u2212\u2212\u27e9, =\u2212|\u2212\u2212\u27e9, =+|++\u27e9. (12.8) So (12.7) becomes H ^ |++\u27e9 =A{|\u2212\u2212\u27e9\u2212|\u2212\u2212\u27e9+|++\u27e9} =A|++\u27e9. (12.9) Since our four base states are all orthogonal, that gives us immediately that \u27e8++|H|++\u27e9 \u27e8+\u2212|H|++\u27e9 \u27e8\u2212+|H|++\u27e9 \u27e8\u2212\u2212|H|++\u27e9 =A\u27e8++|++\u27e9=A, =A\u27e8+\u2212|++\u27e9=0, =A\u27e8\u2212+|++\u27e9=0, =A\u27e8\u2212\u2212|++\u27e9=0. (12.10) Remembering that \u27e8j|H|i\u27e9=\u27e8i|H|j \u27e9 \u2217 , we can already write down the differential equation for the amplitudes C 1 : i\u210f C \u02d9 1 = H 11 C 1 + H 12 C 2 + H 13 C 3 + H 14 C 4 or i\u210f C \u02d9 1 =A C 1 . (12.11) That\u2019s all! We get only the one term. Now to get the rest of the Hamiltonian equations we have to crank through the same procedure for H ^ operating on the other states. First, we will let you practice by checking out all of the sigma products we have written down in Table 12-2. Then we can use them to get: H ^ |+\u2212\u27e9 H ^ |\u2212+\u27e9 H ^ |\u2212\u2212\u27e9 =A{2|\u2212+\u27e9\u2212|+\u2212\u27e9}, =A{2|+\u2212\u27e9\u2212|\u2212+\u27e9}, =A|\u2212\u2212\u27e9. (12.12) Then, multiplying each one in turn on the left by all the other state vectors, we get the following Hamiltonian matrix, H ij : H ij = i\u2193 j\u2192 \u239b \u239d \u239c \u239c \u239c \u239c \u239c \u239c A 0 0 0 0 \u2212A 2A 0 0 2A \u2212A 0 0 0 0 A \u239e \u23a0 \u239f \u239f \u239f \u239f \u239f \u239f . (12.13) It means, of course, nothing more than that our differential equations for the four amplitudes C i are i\u210f C \u02d9 1 i\u210f C \u02d9 2 i\u210f C \u02d9 3 i\u210f C \u02d9 4 =A C 1 , =\u2212A C 2 +2A C 3 , =2A C 2 \u2212A C 3 , =A C 4 . (12.14) Before solving these equations we can\u2019t resist telling you about a clever rule due to Dirac\u2014it will make you feel that you are really advanced\u2014although we don\u2019t need it for our work. We have\u2014from the equations (12.9) and (12.12)\u2014that \u03c3 e \u22c5 \u03c3 p |++\u27e9 \u03c3 e \u22c5 \u03c3 p |+\u2212\u27e9 \u03c3 e \u22c5 \u03c3 p |\u2212+\u27e9 \u03c3 e \u22c5 \u03c3 p |\u2212\u2212\u27e9 =|++\u27e9, =2|\u2212+\u27e9\u2212|+\u2212\u27e9, =2|+\u2212\u27e9\u2212|\u2212+\u27e9, =|\u2212\u2212\u27e9. (12.15) Look, said Dirac, I can also write the first and last equations as \u03c3 e \u22c5 \u03c3 p |++\u27e9 \u03c3 e \u22c5 \u03c3 p |\u2212\u2212\u27e9 =2|++\u27e9\u2212|++\u27e9, =2|\u2212\u2212\u27e9\u2212|\u2212\u2212\u27e9; then they are all quite similar. Now I invent a new operator, which I will call P spin exch and which I define to have the following properties:2 P spin exch |++\u27e9 P spin exch |+\u2212\u27e9 P spin exch |\u2212+\u27e9 P spin exch |\u2212\u2212\u27e9 =|++\u27e9, =|\u2212+\u27e9, =|+\u2212\u27e9, =|\u2212\u2212\u27e9. All the operator does is interchange the spin directions of the two particles. Then I can write the whole set of equations in (12.15) as a simple operator equation: \u03c3 e \u22c5 \u03c3 p =2 P spin exch \u22121. (12.16) That\u2019s the formula of Dirac. His \u201cspin exchange operator\u201d gives a handy rule for figuring out \u03c3 e \u22c5 \u03c3 p . (You see, you can do everything now. The gates are open.) Now we are ready to work out the energy levels of the ground state of hydrogen by solving the Hamiltonian equations (12.14). We want to find the energies of the stationary states. This means that we want to find those special states |\u03c8\u27e9 for which each amplitude C i =\u27e8i|\u03c8\u27e9 in the set belonging to |\u03c8\u27e9 has the same time dependence\u2014namely, e \u2212i\u03c9t . Then the state will have the energy E=\u210f\u03c9 . So we want a set for which C i = a i e \u2212(i/\u210f)Et , (12.17) where the four coefficients a i are independent of time. To see whether we can get such amplitudes, we substitute (12.17) into Eq. (12.14) and see what happens. Each i\u210fdC/dt in Eq. (12.14) turns into EC , and\u2014after cancelling out the common exponential factor\u2014each C becomes an a ; we get E a 1 E a 2 E a 3 E a 4 =A a 1 , =\u2212A a 2 +2A a 3 , =2A a 2 \u2212A a 3 , =A a 4 , (12.18) which we have to solve for a 1 , a 2 , a 3 , and a 4 . Isn\u2019t it nice that the first equation is independent of the rest\u2014that means we can see one solution right away. If we choose E=A , a 1 =1, a 2 = a 3 = a 4 =0, 1 0 gives a solution. (Of course, taking all the a \u2019s equal to zero also gives a solution, but that\u2019s no state at all!) Let\u2019s call our first solution the state |I\u27e9 :3 |I\u27e9=|1\u27e9=|++\u27e9. (12.19) Its energy is E I =A. E A With that clue you can immediately see another solution from the last equation in (12.18): a 1 E = a 2 = a 3 =0, a 4 =1, =A. We\u2019ll call that solution state |II\u27e9 : |II\u27e9 E II =|4\u27e9=|\u2212\u2212\u27e9, =A. (12.20) Now it gets a little harder; the two equations left in (12.18) are mixed up. But we\u2019ve done it all before. Adding the two, we get E( a 2 + a 3 )=A( a 2 + a 3 ). (12.21) Subtracting, we have E( a 2 \u2212 a 3 )=\u22123A( a 2 \u2212 a 3 ). (12.22) By inspection\u2014and remembering ammonia\u2014we see that there are two solutions: a 2 and a 2 = a 3 , =\u2212 a 3 , E E =A =\u22123A. (12.23) They are mixtures of |2\u27e9 and |3\u27e9 . Calling these states |III\u27e9 and |IV\u27e9 , and putting in a factor 1/ 2 \u2013 \u221a to make the states properly normalized, we have |III\u27e9 E III = 1 2 \u2013 \u221a (|2\u27e9+|3\u27e9) = 1 2 \u2013 \u221a (|+\u2212\u27e9+|\u2212+\u27e9), =A (12.24) and |IV\u27e9 E IV = 1 2 \u2013 \u221a (|2\u27e9\u2212|3\u27e9) = 1 2 \u2013 \u221a (|+\u2212\u27e9\u2212|\u2212+\u27e9), =\u22123A. (12.25) We have found four stationary states and their energies. Notice, incidentally, that our four states are orthogonal, so they also can be used for base states if desired. Our problem is completely solved. Three of the states have the energy A , and the last has the energy \u22123A . The average is zero\u2014which means that when we took E 0 =0 in Eq. (12.5), we were choosing to measure all the energies from the average energy. We can draw the energy-level diagram for the ground state of hydrogen as shown in Fig. 12-2. Now the difference in energy between state |IV\u27e9 and any one of the others is 4A . An atom which happens to have gotten into state |I\u27e9 could fall from there to state |IV\u27e9 and emit light. Not optical light, because the energy is so tiny\u2014it would emit a microwave quantum. Or, if we shine microwaves on hydrogen gas, we will find an absorption of energy as the atoms in state |IV\u27e9 pick up energy and go into one of the upper states\u2014but only at the frequency \u03c9=4A/\u210f . This frequency has been measured experimentally; the best result, obtained very recently,4 is f=\u03c9/2\u03c0= (1,420,405,751.800\u00b10.028) cycles per second. (12.26) The error is only two parts in 100 billion! Probably no basic physical quantity is measured better than that\u2014it\u2019s one of the most remarkably accurate measurements in physics. The theorists were very happy that they could compute the energy to an accuracy of 3 parts in 10 5 , but in the meantime it has been measured to 2 parts in 10 11 \u2014a million times more accurate than the theory. So the experimenters are way ahead of the theorists. In the theory of the ground state of the hydrogen atom you are as good as anybody. You, too, can just take your value of A from experiment\u2014that\u2019s what everybody has to do in the end. You have probably heard before about the \u201c 21 -centimeter line\u201d of hydrogen. That\u2019s the wavelength of the 1420 megacycle spectral line between the hyperfine states. Radiation of this wavelength is emitted or absorbed by the atomic hydrogen gas in the galaxies. So with radio telescopes tuned in to 21 -cm waves (or 1420 megacycles approximately) we can observe the velocities and the location of concentrations of atomic hydrogen gas. By measuring the intensity, we can estimate the amount of hydrogen. By measuring the frequency shift due to the Doppler effect, we can find out about the motion of the gas in the galaxy. That is one of the big programs of radio astronomy. So now we are talking about something that\u2019s very real\u2014it is not an artificial problem. Although we have finished the problem of finding the energy levels of the hydrogen ground state, we would like to study this interesting system some more. In order to say anything more about it\u2014for instance, in order to calculate the rate at which the hydrogen atom absorbs or emits radio waves at 21 centimeters\u2014we have to know what happens when the atom is disturbed. We have to do as we did for the ammonia molecule\u2014after we found the energy levels we went on and studied what happened when the molecule was in an electric field. We were then able to figure out the effects from the electric field in a radio wave. For the hydrogen atom, the electric field does nothing to the levels, except to move them all by some constant amount proportional to the square of the field\u2014which is not of any interest because that won\u2019t change the energy differences. It is now the magnetic field which is important. So the next step is to write the Hamiltonian for a more complicated situation in which the atom sits in an external magnetic field. What, then, is the Hamiltonian? We\u2019ll just tell you the answer, because we can\u2019t give you any \u201cproof\u201d except to say that this is the way the atom works. The Hamiltonian is H ^ =A( \u03c3 e \u22c5 \u03c3 p )\u2212 \u03bc e \u03c3 e \u22c5B\u2212 \u03bc p \u03c3 p \u22c5B. (12.27) It now consists of three parts. The first term A \u03c3 e \u22c5 \u03c3 p represents the magnetic interaction between the electron and the proton\u2014it is the same one that would be there if there were no magnetic field. This is the term we have already had; and the influence of the magnetic field on the constant A is negligible. The effect of the external magnetic field shows up in the last two terms. The second term, \u2212 \u03bc e \u03c3 e \u22c5B , is the energy the electron would have in the magnetic field if it were there alone.5 In the same way, the last term \u2212 \u03bc p \u03c3 p \u22c5B , would have been the energy of a proton alone. Classically, the energy of the two of them together would be the sum of the two, and that works also quantum mechanically. In a magnetic field, the energy of interaction due to the magnetic field is just the sum of the energy of interaction of the electron with the external field, and of the proton with the field\u2014both expressed in terms of the sigma operators. In quantum mechanics these terms are not really the energies, but thinking of the classical formulas for the energy is a way of remembering the rules for writing down the Hamiltonian. Anyway, the correct Hamiltonian is Eq. (12.27). Now we have to go back to the beginning and do the problem all over again. Much of the work is, however, done\u2014we need only to add the effects of the new terms. Let\u2019s take a constant magnetic field B in the z -direction. Then we have to add to our Hamiltonian operator H ^ the two new pieces\u2014which we can call H ^ \u2032 : H ^ \u2032 =\u2212( \u03bc e \u03c3 e z + \u03bc p \u03c3 p z )B. \u2032 Using Table 12-1, we get right away that H ^ \u2032 |++\u27e9 H ^ \u2032 |+\u2212\u27e9 H ^ \u2032 |\u2212+\u27e9 H ^ \u2032 |\u2212\u2212\u27e9 =\u2212( \u03bc e + \u03bc p )B|++\u27e9, =\u2212( \u03bc e \u2212 \u03bc p )B|+\u2212\u27e9, =\u2212(\u2212 \u03bc e + \u03bc p )B|\u2212+\u27e9, =( \u03bc e + \u03bc p )B|\u2212\u2212\u27e9. (12.28) How very convenient! The H ^ \u2032 operating on each state just gives a number times that state. The matrix \u27e8i| H \u2032 |j\u27e9 has, therefore, only diagonal elements\u2014we can just add the coefficients in (12.28) to the corresponding diagonal terms of (12.13), and the Hamiltonian equations of (12.14) become i\u210fd C 1 /dt i\u210fd C 2 /dt i\u210fd C 3 /dt i\u210fd C 4 /dt ={A\u2212( \u03bc e + \u03bc p )B} C 1 , =\u2212{A+( \u03bc e \u2212 \u03bc p )B} C 2 +2A C 3 , =2A C 2 \u2212{A\u2212( \u03bc e \u2212 \u03bc p )B} C 3 , ={A+( \u03bc e + \u03bc p )B} C 4 . (12.29) The form of the equations is not different\u2014only the coefficients. So long as B doesn\u2019t vary with time, we can continue as we did before. Substituting C i = a i e \u2212(i/\u210f)Et , we get\u2014as a modification of (12.18)\u2014 E a 1 E a 2 E a 3 E a 4 ={A\u2212( \u03bc e + \u03bc p )B} a 1 , =\u2212{A+( \u03bc e \u2212 \u03bc p )B} a 2 +2A a 3 , =2A a 2 \u2212{A\u2212( \u03bc e \u2212 \u03bc p )B} a 3 , ={A+( \u03bc e + \u03bc p )B} a 4 . (12.30) Fortunately, the first and fourth equations are still independent of the rest, so the same technique works again. One solution is the state |I\u27e9 for which a 1 =1 , a 2 = a 3 = a 4 = 0 , or |I\u27e9 with E I =|1\u27e9=|++\u27e9, =A\u2212( \u03bc e + \u03bc p )B. (12.31) Another is |II\u27e9 with E II =|4\u27e9=|\u2212\u2212\u27e9, =A+( \u03bc e + \u03bc p )B. (12.32) A little more work is involved for the remaining two equations, because the coefficients of a 2 and a 3 are no longer equal. But they are just like the pair we had for the ammonia molecule. Looking back at Eq. (9.20), we can make the following analogy (remembering that the labels 1 and 2 there correspond to 2 and 3 here): H 11 H 12 H 21 H 22 \u2192\u2212A\u2212( \u03bc e \u2212 \u03bc p )B, \u21922A, \u21922A, \u2192\u2212A+( \u03bc e \u2212 \u03bc p )B. (12.33) The energies are then given by (9.25), which was E= H 11 + H 22 2 \u00b1 ( H 11 \u2212 H 22 ) 2 4 + H 12 H 21 \u2212 \u2212 \u2212 \u2212 \u2212 \u2212 \u2212 \u2212 \u2212 \u2212 \u2212 \u2212 \u2212 \u2212 \u2212 \u2212 \u2212 \u2212 \u221a . (12.34) Making the substitutions from (12.33), the energy formula becomes E=\u2212A\u00b1 ( \u03bc e \u2212 \u03bc p ) 2 B 2 +4 A 2 \u2212 \u2212 \u2212 \u2212 \u2212 \u2212 \u2212 \u2212 \u2212 \u2212 \u2212 \u2212 \u2212 \u2212 \u2212 \u2212 \u221a . Although in Chapter 9 we used to call these energies E I and E II , and we are in this problem calling them E III and E IV , E III E IV =A{\u22121+2 1+( \u03bc e \u2212 \u03bc p ) 2 B 2 /4 A 2 \u2212 \u2212 \u2212 \u2212 \u2212 \u2212 \u2212 \u2212 \u2212 \u2212 \u2212 \u2212 \u2212 \u2212 \u2212 \u2212 \u2212 \u2212 \u221a }, =\u2212A{1+2 1+( \u03bc e \u2212 \u03bc p ) 2 B 2 /4 A 2 \u2212 \u2212 \u2212 \u2212 \u2212 \u2212 \u2212 \u2212 \u2212 \u2212 \u2212 \u2212 \u2212 \u2212 \u2212 \u2212 \u2212 \u2212 \u221a }. (12.35) So we have found the energies of the four stationary states of a hydrogen atom in a constant magnetic field. Let\u2019s check our results by letting B go to zero and seeing whether we get the same energies we had in the preceding section. You see that we do. For B=0 , the energies E I , E II , and E III go to +A , and E IV goes to \u22123A . Even our labeling of the states agrees with what we called them before. When we turn on the magnetic field though, all of the energies change in a different way. Let\u2019s see how they go. First, we have to remember that for the electron, \u03bc e is negative, and about 1000 times larger than \u03bc p \u2014which is positive. So \u03bc e + \u03bc p and \u03bc e \u2212 \u03bc p are both negative numbers, and nearly equal. Let\u2019s call them \u2212\u03bc and \u2212 \u03bc \u2032 : \u03bc=\u2212( \u03bc e + \u03bc p ), \u03bc \u2032 =\u2212( \u03bc e \u2212 \u03bc p ). (12.36) (Both \u03bc and \u03bc \u2032 are positive numbers, nearly equal to magnitude of \u03bc e \u2014which is about one Bohr magneton.) Then our four energies are E I E II E III E IV =A+\u03bcB, =A\u2212\u03bcB, =A{\u22121+2 1+ \u03bc \u20322 B 2 /4 A 2 \u2212 \u2212 \u2212 \u2212 \u2212 \u2212 \u2212 \u2212 \u2212 \u2212 \u2212 \u2212 \u221a }, =\u2212A{1+2 1+ \u03bc \u20322 B 2 /4 A 2 \u2212 \u2212 \u2212 \u2212 \u2212 \u2212 \u2212 \u2212 \u2212 \u2212 \u2212 \u2212 \u221a }. (12.37) The energy E I starts at A and increases linearly with B \u2014with the slope \u03bc . The energy E II also starts at A but decreases linearly with increasing B \u2014its slope is \u2212\u03bc . These two levels vary with B as shown in Fig. 12-3. We show also in the figure the energies E III and E IV . They have a different B -dependence. For small B , they depend quadratically on B , so they start out with horizontal slopes. Then they begin to curve, and for large B they approach straight lines with slopes \u00b1 \u03bc \u2032 , which are nearly the same as the slopes of E I and E II . The shift of the energy levels of an atom due to a magnetic field is called the Zeeman effect. We say that the curves in Fig. 12-3 show the Zeeman splitting of the ground state of hydrogen. When there is no magnetic field, we get just one spectral line from the hyperfine structure of hydrogen. The transitions between state |IV\u27e9 and any one of the others occurs with the absorption or emission of a photon whose frequency 1420 megacycles is 1/h times the energy difference 4A . When the atom is in a magnetic field B , however, there are many more lines. There can be transitions between any two of the four states. So if we have atoms in all four states, energy can be absorbed\u2014or emitted\u2014in any one of the six transitions shown by the vertical arrows in Fig. 12-4. Many of these transitions can be observed by the Rabi molecular beam technique we described in Volume II, Section 35-3. What makes the transitions go? The transitions will occur if you apply a small disturbing magnetic field that varies with time (in addition to the steady strong field B ). It\u2019s just as we saw for a varying electric field on the ammonia molecule. Only here, it is the magnetic field which couples with the magnetic moments and does the trick. But the theory follows through in the same way that we worked it out for the ammonia. The theory is the simplest if you take a perturbing magnetic field that rotates in the xy -plane\u2014although any horizontal oscillating field will do. When you put in this perturbing field as an additional term in the Hamiltonian, you get solutions in which the amplitudes vary with time\u2014as we found for the ammonia molecule. So you can calculate easily and accurately the probability of a transition from one state to another. And you find that it all agrees with experiment. We would like now to discuss the shapes of the curves in Fig. 12-3. In the first place, the energies for large fields are easy to understand, and rather interesting. For B large enough (namely for \u03bcB/A\u226b1 ) we can neglect the 1 in the formulas of (12.37). The four energies become E I E III =A+\u03bcB, =\u2212A+ \u03bc \u2032 B, E II E IV =A\u2212\u03bcB, =\u2212A\u2212 \u03bc \u2032 B. (12.38) These are the equations of the four straight lines in Fig. 12-3. We can understand these energies physically in the following way. The nature of the stationary states in a zero field is determined completely by the interaction of the two magnetic moments. The mixtures of the base states |+\u2212\u27e9 and |\u2212+\u27e9 in the stationary states |III\u27e9 and |IV\u27e9 are due to this interaction. In large external fields, however, the proton and electron will be influenced hardly at all by the field of the other; each will act as if it were alone in the external field. Then\u2014as we have seen many times\u2014the electron spin will be either parallel to or opposite to the external magnetic field. Suppose the electron spin is \u201cup\u201d\u2014that is, along the field; its energy will be \u2212 \u03bc e B . The proton can still be either way. If the proton spin is also \u201cup,\u201d its energy is \u2212 \u03bc p B . The sum of the two is \u2212( \u03bc e + \u03bc p )B=\u03bcB . That is just what we find for E I \u2014which is fine, because we are describing the state |++\u27e9=|I\u27e9 . There is still the small additional term A (now \u03bcB\u226bA ) which represents the interaction energy of the proton and electron when their spins are parallel. (We originally took A as positive because the theory we spoke of says it should be, and experimentally it is indeed so.) On the other hand, the proton can have its spin down. Then its energy in the external field goes to + \u03bc p B , so it and the electron have the energy \u2212( \u03bc e \u2212 \u03bc p )B= \u03bc \u2032 B . And the interaction energy becomes \u2212A . The sum is just the energy E III , in (12.38). So the state |III\u27e9 must for large fields become the state |+\u2212\u27e9 . Suppose now the electron spin is \u201cdown.\u201d Its energy in the external field is \u03bc e B . If the proton is also \u201cdown,\u201d the two together have the energy ( \u03bc e + \u03bc p )B=\u2212\u03bcB , plus the interaction energy A \u2014since their spins are parallel. That makes just the energy E II in (12.38) and corresponds to the state |\u2212\u2212\u27e9=|II\u27e9 \u2014which is nice. Finally if the electron is \u201cdown\u201d and the proton is \u201cup,\u201d we get the energy ( \u03bc e \u2212 \u03bc p )B\u2212A (minus A for the interaction because the spins are opposite) which is just E IV . And the state corresponds to |\u2212+\u27e9 . \u201cBut, wait a moment!\u201d, you are probably saying, \u201cThe states |III\u27e9 and |IV\u27e9 are not the states |+\u2212\u27e9 and |\u2212+\u27e9 ; they are mixtures of the two.\u201d Well, only slightly. They are indeed mixtures for B=0 , but we have not yet figured out what they are for large B . When we used the analogies of (12.33) in our formulas of Chapter 9 to get the energies of the stationary states, we could also have taken the amplitudes that go with them. They come from Eq. (9.24), which is a 2 a 3 = E\u2212 H 22 H 21 . E H The ratio a 2 / a 3 is, of course, just C 2 / C 3 . Plugging in the analogous quantities from (12.33), we get C 2 C 3 or C 2 C 3 = E+A\u2212( \u03bc e \u2212 \u03bc p )B 2A = E+A+ \u03bc \u2032 B 2A , (12.39) where for E we are to use the appropriate energy\u2014either E III or E IV . For instance, for state |III\u27e9 we have ( C 2 C 3 ) III \u2248 \u03bc \u2032 B A . (12.40) So for large B the state |III\u27e9 has C 2 \u226b C 3 ; the state becomes almost completely the state |2\u27e9=|+\u2212\u27e9 . Similarly, if we put E IV into (12.39) we get ( C 2 / C 3 ) IV \u226a1 ; for high fields state |IV\u27e9 becomes just the state |3\u27e9=|\u2212+\u27e9 . You see that the coefficients in the linear combinations of our base states which make up the stationary states depend on B . The state we call |III\u27e9 is a 50 - 50 mixture of |+\u2212\u27e9 and |\u2212+\u27e9 at very low fields, but shifts completely over to |+\u2212\u27e9 at high fields. Similarly, the state |IV\u27e9 , which at low fields is also a 50 - 50 mixture (with opposite signs) of |+\u2212\u27e9 and |\u2212+\u27e9 , goes over into the state |\u2212+\u27e9 when the spins are uncoupled by a strong external field. We would also like to call your attention particularly to what happens at very low magnetic fields. There is one energy\u2014at \u22123A \u2014which does not change when you turn on a small magnetic field. And there is another energy\u2014at +A \u2014which splits into three different energy levels when you turn on a small magnetic field. For weak fields the energies vary with B as shown in Fig. 12\u20135. Suppose that we have somehow selected a bunch of hydrogen atoms which all have the energy \u22123A . If we put them through a Stern-Gerlach experiment\u2014with fields that are not too strong\u2014we would find that they just go straight through. (Since their energy doesn\u2019t depend on B , there is\u2014according to the principle of virtual work\u2014no force on them in a magnetic field gradient.) Suppose, on the other hand, we were to select a bunch of atoms with the energy +A , and put them through a Stern-Gerlach apparatus, say an S apparatus. (Again the fields in the apparatus should not be so great that they disrupt the insides of the atom, by which we mean a field small enough that the energies vary linearly with B .) We would find three beams. The states |I\u27e9 and |II\u27e9 get opposite forces\u2014their energies vary linearly with B with the slopes \u00b1\u03bc so the forces are like those on a dipole with \u03bc z =\u2213\u03bc ; but the state |III\u27e9 goes straight through. So we are right back in Chapter 5. A hydrogen atom with the energy +A is a spin-one particle. This energy state is a \u201cparticle\u201d for which j=1 , and it can be described\u2014with respect to some set of axes in space\u2014in terms of the base states |+S\u27e9 , |0S\u27e9 , and |\u2212S\u27e9 we used in Chapter 5. On the other hand, when a hydrogen atom has the energy \u22123A , it is a spin-zero particle. (Remember, what we are saying is only strictly true for infinitesimal magnetic fields.) So we can group the states of hydrogen in zero magnetic field this way: |I\u27e9 |III\u27e9 |II\u27e9 =|++\u27e9 = |+\u2212\u27e9+|\u2212+\u27e9 2 \u2013 \u221a =|\u2212\u2212\u27e9 \u23ab \u23ad \u23ac \u23aa \u23aa \u23aa \u23aa \u23aa \u23aa \u23aa \u23aa |IV\u27e9= |+\u2212\u27e9\u2212|\u2212+\u27e9 2 \u2013 \u221a spin 1 \u23a7 \u23a9 \u23a8 \u23aa \u23aa \u23aa \u23aa \u23aa \u23aa \u23aa \u23aa \u23aa \u23aa |+S\u27e9 |0S\u27e9 |\u2212S\u27e9 spin 0. (12.41) (12.42) We have said in Chapter 35 of Volume II that for any particle its component of angular momentum along any axis can have only certain values always \u210f apart. The z -component of angular momentum J z can be j\u210f , (j\u22121)\u210f , (j\u22122)\u210f , \u2026 , (\u2212j)\u210f , where j is the spin of the particle (which can be an integer or half-integer). Although we neglected to say so at the time, people usually write J z =m\u210f, (12.43) where m stands for one of the numbers j , j\u22121 , j\u22122 , \u2026 , \u2212j . You will, therefore, see people in books label the four ground states of hydrogen by the so-called quantum numbers j and m [often called the \u201ctotal angular momentum quantum number\u201d ( j ) and \u201cmagnetic quantum number\u201d ( m )]. Then, instead of our state symbols |I\u27e9 , |II\u27e9 , and so on, they will write a state as |j,m\u27e9 . So they would write our little table of states for zero field in (12.41) and (12.42) as shown in Table 12-3. It\u2019s not new physics, it\u2019s all just a matter of notation. We would like now to use our knowledge of the hydrogen atom to do something special. We discussed in Chapter 5 that a particle of spin one which was in one of the base states ( + , 0 , or \u2212 ) with respect to a Stern-Gerlach apparatus of a particular orientation\u2014say an S apparatus\u2014would have a certain amplitude to be in each of the three states with respect to a T apparatus with a different orientation in space. There are nine such amplitudes \u27e8jT|iS\u27e9 which make up the projection matrix. In Section 5\u20137 we gave without proof the terms of this matrix for various orientations of T with respect to S . Now we will show you one way they can be derived. In the hydrogen atom we have found a spin-one system which is made up of two spin one-half particles. We have already worked out in Chapter 6 how to transform the spin one-half amplitudes. We can use this information to calculate the transformation for spin one. This is the way it works: We have a system\u2014a hydrogen atom with the energy +A \u2014which has spin one. Suppose we run it through a Stern-Gerlach filter S , so that we know it is in one of the base states with respect to S , say |+S\u27e9 . What is the amplitude that it will be in one of the base states, say |+T\u27e9 , with respect to the T apparatus? If we call the coordinate system of the S apparatus the x,y,z system, the |+S\u27e9 state is what we have been calling the state |++\u27e9 . But suppose another guy took his z -axis along the axis of T . He will be referring his states to what we will call the x \u2032 , y \u2032 , z \u2032 frame. His \u201cup\u201d and \u201cdown\u201d states for the electron and proton would be different from ours. His \u201cplus-plus\u201d state\u2014which we can write | + \u2032 + \u2032 \u27e9 , referring to the \u201cprime\u201d frame\u2014is the |+T\u27e9 state of the spin-one particle. What we want is \u27e8+T|+S\u27e9 which is just another way of writing the amplitude \u27e8 + \u2032 + \u2032 |++\u27e9 . We can find the amplitude \u27e8 + \u2032 + \u2032 |++\u27e9 in the following way. In our frame the electron in the |++\u27e9 state has its spin \u201cup\u201d. That means that it has some amplitude \u27e8 + \u2032 |+ \u27e9 e of being \u201cup\u201d in his frame, and some amplitude \u27e8 \u2212 \u2032 |+ \u27e9 e of being \u201cdown\u201d in that frame. Similarly, the proton in the |++\u27e9 state has spin \u201cup\u201d in our frame and the amplitudes \u27e8 + \u2032 |+ \u27e9 p and \u27e8 \u2212 \u2032 |+ \u27e9 p of having spin \u201cup\u201d or spin \u201cdown\u201d in the \u201cprime\u201d frame. Since we are talking about two distinct particles, the amplitude that both particles will be \u201cup\u201d together in his frame is the product of the two amplitudes, \u27e8 + \u2032 + \u2032 |++\u27e9=\u27e8 + \u2032 |+ \u27e9 e \u27e8 + \u2032 |+ \u27e9 p . (12.44) We have put the subscripts e and p on the amplitudes \u27e8 + \u2032 |+\u27e9 to make it clear what we were doing. But they are both just the transformation amplitudes for a spin one-half particle, so they are really identical numbers. They are, in fact, just the amplitude we have called \u27e8+T|+S\u27e9 in Chapter 6, and which we listed in the tables at the end of that chapter. Now, however, we are about to get into trouble with notation. We have to be able to distinguish the amplitude \u27e8+T|+S\u27e9 for a spin one-half particle from what we have also called \u27e8+T|+S\u27e9 for a spin-one particle\u2014yet they are completely different! We hope it won\u2019t be too confusing, but for the moment at least, we will have to use some different symbols for the spin one-half amplitudes. To help you keep things straight, we summarize the new notation in Table 12-4. We will continue to use the notation |+S\u27e9 , |0S\u27e9 , and |\u2212S\u27e9 for the states of a spin-one particle. With our new notation, Eq. (12.44) becomes simply \u27e8 + \u2032 + \u2032 |++\u27e9= a 2 , \u2032 \u2032 2 and this is just the spin-one amplitude \u27e8+T|+S\u27e9 . Now, let\u2019s suppose, for instance, that the other guy\u2019s coordinate frame\u2014that is, the T , or \u201cprimed,\u201d apparatus\u2014is just rotated with respect to our z -axis by the angle \u03d5 ; then from Table 6-2, a=\u27e8 + \u2032 |+\u27e9= e i\u03d5/2 . \u2032 i \u03d5 / 2 So from (12.44) we have that the spin-one amplitude is \u27e8+T|+S\u27e9=\u27e8 + \u2032 + \u2032 |++\u27e9=( e i\u03d5/2 ) 2 = e i\u03d5 . (12.45) You can see how it goes. Now we will work through the general case for all the states. If the proton and electron are both \u201cup\u201d in our frame\u2014the S -frame\u2014the amplitudes that it will be in any one of the four possible states in the other guy\u2019s frame\u2014the T -frame\u2014are \u27e8 + \u2032 + \u2032 |++\u27e9 \u27e8 + \u2032 \u2212 \u2032 |++\u27e9 \u27e8 \u2212 \u2032 + \u2032 |++\u27e9 \u27e8 \u2212 \u2032 \u2212 \u2032 |++\u27e9 =\u27e8 + \u2032 |+ \u27e9 e \u27e8 + \u2032 |+ \u27e9 p = a 2 , =\u27e8 + \u2032 |+ \u27e9 e \u27e8 \u2212 \u2032 |+ \u27e9 p =ab, =\u27e8 \u2212 \u2032 |+ \u27e9 e \u27e8 + \u2032 |+ \u27e9 p =ba, =\u27e8 \u2212 \u2032 |+ \u27e9 e \u27e8 \u2212 \u2032 |+ \u27e9 p = b 2 . (12.46) We can, then, write the state |++\u27e9 as the following linear combination: |++\u27e9 = + + ab a 2 { b 2 | + \u2032 + \u2032 \u27e9 | + \u2032 \u2212 \u2032 \u27e9+| \u2212 \u2032 + \u2032 \u27e9} | \u2212 \u2032 \u2212 \u2032 \u27e9. (12.47) Now we notice that | + \u2032 + \u2032 \u27e9 is the state |+T\u27e9 , that {| + \u2032 \u2212 \u2032 \u27e9+| \u2212 \u2032 + \u2032 \u27e9} is just 2 \u2013 \u221a times the state |0T\u27e9 \u2014see (12.41)\u2014and that | \u2212 \u2032 \u2212 \u2032 \u27e9=|\u2212T\u27e9 . In other words, Eq. (12.47) can be rewritten as |+S\u27e9= a 2 |+T\u27e9+ 2 \u2013 \u221a ab|0T\u27e9+ b 2 |\u2212T\u27e9. (12.48) In a similar way you can easily show that |\u2212S\u27e9= c 2 |+T\u27e9+ 2 \u2013 \u221a cd|0T\u27e9+ d 2 |\u2212T\u27e9. (12.49) For |0S\u27e9 it\u2019s a little more complicated, because |0S\u27e9= 1 2 \u2013 \u221a {|+\u2212\u27e9+|\u2212+\u27e9}. 1 But we can express each of the states |+\u2212\u27e9 and |\u2212+\u27e9 in terms of the \u201cprime\u201d states and take the sum. That is, |+\u2212\u27e9 =ac +bc | + \u2032 + \u2032 \u27e9+ad| + \u2032 \u2212 \u2032 \u27e9 | \u2212 \u2032 + \u2032 \u27e9+bd| \u2212 \u2032 \u2212 \u2032 \u27e9 (12.50) and |\u2212+\u27e9 =ac +ad | + \u2032 + \u2032 \u27e9+bc| + \u2032 \u2212 \u2032 \u27e9 | \u2212 \u2032 + \u2032 \u27e9+bd| \u2212 \u2032 \u2212 \u2032 \u27e9. (12.51) Taking 1/ 2 \u2013 \u221a times the sum, we get |0S\u27e9 = + + 2 2 \u2013 \u221a ac ad+bc 2 \u2013 \u221a 2 2 \u2013 \u221a bd { | + \u2032 + \u2032 \u27e9 | + \u2032 \u2212 \u2032 \u27e9+| \u2212 \u2032 + \u2032 \u27e9} | \u2212 \u2032 \u2212 \u2032 \u27e9. It follows that |0S\u27e9 = 2 \u2013 \u221a ac|+T\u27e9 +(ad+bc)|0T\u27e9 + 2 \u2013 \u221a bd|\u2212T\u27e9. (12.52) We have now all of the amplitudes we wanted. The coefficients of Eqs. (12.48), (12.49), and (12.52) are the matrix elements \u27e8jT|iS\u27e9 . Let\u2019s pull them all together: \u27e8jT|iS\u27e9= jT\u2193 iS\u2192 \u239b \u239d \u239c \u239c \u239c a 2 2 \u2013 \u221a ab b 2 2 \u2013 \u221a ac ad+bc 2 \u2013 \u221a bd c 2 2 \u2013 \u221a cd d 2 \u239e \u23a0 \u239f \u239f \u239f . (12.53) We have expressed the spin-one transformation in terms of the spin one-half amplitudes a , b , c , and d . For instance, if the T -frame is rotated with respect to S by the angle \u03b1 about the y -axis\u2014as in Fig. 5-6\u2014the amplitudes in Table 12-4 are just the matrix elements of R y (\u03b1) in Table 6-2. a c =cos \u03b1 2 , =sin \u03b1 2 , b d =\u2212sin \u03b1 2 , =cos \u03b1 2 . (12.54) Using these in (12.53), we get the formulas of (5.38), which we gave there without proof. What ever happened to the state |IV\u27e9 ?! Well, it is a spin-zero system, so it has only one state\u2014it is the same in all coordinate systems. We can check that everything works out by taking the difference of Eq. (12.50) and (12.51); we get that |+\u2212\u27e9\u2212|\u2212+\u27e9=(ad\u2212bc){| + \u2032 \u2212 \u2032 \u27e9\u2212| \u2212 \u2032 + \u2032 \u27e9}. \u2032 \u2032 \u2032 \u2032 But (ad\u2212bc) is the determinant of the spin one-half matrix, and so is equal to 1 . We get that | IV \u2032 \u27e9=|IV\u27e9 \u2032 for any relative orientation of the two coordinate frames."
    },
    {
        "input": "Basic Physics",
        "output": "In this chapter, we shall examine the most fundamental ideas that we have about physics\u2014the nature of things as we see them at the present time. We shall not discuss the history of how we know that all these ideas are true; you will learn these details in due time. The things with which we concern ourselves in science appear in myriad forms, and with a multitude of attributes. For example, if we stand on the shore and look at the sea, we see the water, the waves breaking, the foam, the sloshing motion of the water, the sound, the air, the winds and the clouds, the sun and the blue sky, and light; there is sand and there are rocks of various hardness and permanence, color and texture. There are animals and seaweed, hunger and disease, and the observer on the beach; there may be even happiness and thought. Any other spot in nature has a similar variety of things and influences. It is always as complicated as that, no matter where it is. Curiosity demands that we ask questions, that we try to put things together and try to understand this multitude of aspects as perhaps resulting from the action of a relatively small number of elemental things and forces acting in an infinite variety of combinations. For example: Is the sand other than the rocks? That is, is the sand perhaps nothing but a great number of very tiny stones? Is the moon a great rock? If we understood rocks, would we also understand the sand and the moon? Is the wind a sloshing of the air analogous to the sloshing motion of the water in the sea? What common features do different movements have? What is common to different kinds of sound? How many different colors are there? And so on. In this way we try gradually to analyze all things, to put together things which at first sight look different, with the hope that we may be able to reduce the number of different things and thereby understand them better. A few hundred years ago, a method was devised to find partial answers to such questions. Observation, reason, and experiment make up what we call the scientific method. We shall have to limit ourselves to a bare description of our basic view of what is sometimes called fundamental physics, or fundamental ideas which have arisen from the application of the scientific method. What do we mean by \u201cunderstanding\u201d something? We can imagine that this complicated array of moving things which constitutes \u201cthe world\u201d is something like a great chess game being played by the gods, and we are observers of the game. We do not know what the rules of the game are; all we are allowed to do is to watch the playing. Of course, if we watch long enough, we may eventually catch on to a few of the rules. The rules of the game are what we mean by fundamental physics. Even if we knew every rule, however, we might not be able to understand why a particular move is made in the game, merely because it is too complicated and our minds are limited. If you play chess you must know that it is easy to learn all the rules, and yet it is often very hard to select the best move or to understand why a player moves as he does. So it is in nature, only much more so; but we may be able at least to find all the rules. Actually, we do not have all the rules now. (Every once in a while something like castling is going on that we still do not understand.) Aside from not knowing all of the rules, what we really can explain in terms of those rules is very limited, because almost all situations are so enormously complicated that we cannot follow the plays of the game using the rules, much less tell what is going to happen next. We must, therefore, limit ourselves to the more basic question of the rules of the game. If we know the rules, we consider that we \u201cunderstand\u201d the world. How can we tell whether the rules which we \u201cguess\u201d at are really right if we cannot analyze the game very well? There are, roughly speaking, three ways. First, there may be situations where nature has arranged, or we arrange nature, to be simple and to have so few parts that we can predict exactly what will happen, and thus we can check how our rules work. (In one corner of the board there may be only a few chess pieces at work, and that we can figure out exactly.) A second good way to check rules is in terms of less specific rules derived from them. For example, the rule on the move of a bishop on a chessboard is that it moves only on the diagonal. One can deduce, no matter how many moves may be made, that a certain bishop will always be on a red square. So, without being able to follow the details, we can always check our idea about the bishop\u2019s motion by finding out whether it is always on a red square. Of course it will be, for a long time, until all of a sudden we find that it is on a black square (what happened of course, is that in the meantime it was captured, another pawn crossed for queening, and it turned into a bishop on a black square). That is the way it is in physics. For a long time we will have a rule that works excellently in an overall way, even when we cannot follow the details, and then some time we may discover a new rule. From the point of view of basic physics, the most interesting phenomena are of course in the new places, the places where the rules do not work\u2014not the places where they do work! That is the way in which we discover new rules. The third way to tell whether our ideas are right is relatively crude but probably the most powerful of them all. That is, by rough approximation. While we may not be able to tell why Alekhine moves this particular piece, perhaps we can roughly understand that he is gathering his pieces around the king to protect it, more or less, since that is the sensible thing to do in the circumstances. In the same way, we can often understand nature, more or less, without being able to see what every little piece is doing, in terms of our understanding of the game. At first the phenomena of nature were roughly divided into classes, like heat, electricity, mechanics, magnetism, properties of substances, chemical phenomena, light or optics, x-rays, nuclear physics, gravitation, meson phenomena, etc. However, the aim is to see complete nature as different aspects of one set of phenomena. That is the problem in basic theoretical physics, today\u2014to find the laws behind experiment; to amalgamate these classes. Historically, we have always been able to amalgamate them, but as time goes on new things are found. We were amalgamating very well, when all of a sudden x-rays were found. Then we amalgamated some more, and mesons were found. Therefore, at any stage of the game, it always looks rather messy. A great deal is amalgamated, but there are always many wires or threads hanging out in all directions. That is the situation today, which we shall try to describe. Some historic examples of amalgamation are the following. First, take heat and mechanics. When atoms are in motion, the more motion, the more heat the system contains, and so heat and all temperature effects can be represented by the laws of mechanics. Another tremendous amalgamation was the discovery of the relation between electricity, magnetism, and light, which were found to be different aspects of the same thing, which we call today the electromagnetic field. Another amalgamation is the unification of chemical phenomena, the various properties of various substances, and the behavior of atomic particles, which is in the quantum mechanics of chemistry. The question is, of course, is it going to be possible to amalgamate everything, and merely discover that this world represents different aspects of one thing? Nobody knows. All we know is that as we go along, we find that we can amalgamate pieces, and then we find some pieces that do not fit, and we keep trying to put the jigsaw puzzle together. Whether there are a finite number of pieces, and whether there is even a border to the puzzle, is of course unknown. It will never be known until we finish the picture, if ever. What we wish to do here is to see to what extent this amalgamation process has gone on, and what the situation is at present, in understanding basic phenomena in terms of the smallest set of principles. To express it in a simple manner, what are things made of and how few elements are there? It is a little difficult to begin at once with the present view, so we shall first see how things looked in about 1920 and then take a few things out of that picture. Before 1920, our world picture was something like this: The \u201cstage\u201d on which the universe goes is the three-dimensional space of geometry, as described by Euclid, and things change in a medium called time. The elements on the stage are particles, for example the atoms, which have some properties. First, the property of inertia: if a particle is moving it keeps on going in the same direction unless forces act upon it. The second element, then, is forces, which were then thought to be of two varieties: First, an enormously complicated, detailed kind of interaction force which held the various atoms in different combinations in a complicated way, which determined whether salt would dissolve faster or slower when we raise the temperature. The other force that was known was a long-range interaction\u2014a smooth and quiet attraction\u2014which varied inversely as the square of the distance, and was called gravitation. This law was known and was very simple. Why things remain in motion when they are moving, or why there is a law of gravitation was, of course, not known. A description of nature is what we are concerned with here. From this point of view, then, a gas, and indeed all matter, is a myriad of moving particles. Thus many of the things we saw while standing at the seashore can immediately be connected. First the pressure: this comes from the collisions of the atoms with the walls or whatever; the drift of the atoms, if they are all moving in one direction on the average, is wind; the random internal motions are the heat. There are waves of excess density, where too many particles have collected, and so as they rush off they push up piles of particles farther out, and so on. This wave of excess density is sound. It is a tremendous achievement to be able to understand so much. Some of these things were described in the previous chapter. What kinds of particles are there? There were considered to be 92 at that time: 92 different kinds of atoms were ultimately discovered. They had different names associated with their chemical properties. The next part of the problem was, what are the short-range forces? Why does carbon attract one oxygen or perhaps two oxygens, but not three oxygens? What is the machinery of interaction between atoms? Is it gravitation? The answer is no. Gravity is entirely too weak. But imagine a force analogous to gravity, varying inversely with the square of the distance, but enormously more powerful and having one difference. In gravity everything attracts everything else, but now imagine that there are two kinds of \u201cthings,\u201d and that this new force (which is the electrical force, of course) has the property that likes repel but unlikes attract. The \u201cthing\u201d that carries this strong interaction is called charge. Then what do we have? Suppose that we have two unlikes that attract each other, a plus and a minus, and that they stick very close together. Suppose we have another charge some distance away. Would it feel any attraction? It would feel practically none, because if the first two are equal in size, the attraction for the one and the repulsion for the other balance out. Therefore there is very little force at any appreciable distance. On the other hand, if we get very close with the extra charge, attraction arises, because the repulsion of likes and attraction of unlikes will tend to bring unlikes closer together and push likes farther apart. Then the repulsion will be less than the attraction. This is the reason why the atoms, which are constituted out of plus and minus electric charges, feel very little force when they are separated by appreciable distance (aside from gravity). When they come close together, they can \u201csee inside\u201d each other and rearrange their charges, with the result that they have a very strong interaction. The ultimate basis of an interaction between the atoms is electrical. Since this force is so enormous, all the plusses and all minuses will normally come together in as intimate a combination as they can. All things, even ourselves, are made of fine-grained, enormously strongly interacting plus and minus parts, all neatly balanced out. Once in a while, by accident, we may rub off a few minuses or a few plusses (usually it is easier to rub off minuses), and in those circumstances we find the force of electricity unbalanced, and we can then see the effects of these electrical attractions. To give an idea of how much stronger electricity is than gravitation, consider two grains of sand, a millimeter across, thirty meters apart. If the force between them were not balanced, if everything attracted everything else instead of likes repelling, so that there were no cancellation, how much force would there be? There would be a force of three million tons between the two! You see, there is very, very little excess or deficit of the number of negative or positive charges necessary to produce appreciable electrical effects. This is, of course, the reason why you cannot see the difference between an electrically charged or uncharged thing\u2014so few particles are involved that they hardly make a difference in the weight or size of an object. With this picture the atoms were easier to understand. They were thought to have a \u201cnucleus\u201d at the center, which is positively electrically charged and very massive, and the nucleus is surrounded by a certain number of \u201celectrons\u201d which are very light and negatively charged. Now we go a little ahead in our story to remark that in the nucleus itself there were found two kinds of particles, protons and neutrons, almost of the same weight and very heavy. The protons are electrically charged and the neutrons are neutral. If we have an atom with six protons inside its nucleus, and this is surrounded by six electrons (the negative particles in the ordinary world of matter are all electrons, and these are very light compared with the protons and neutrons which make nuclei), this would be atom number six in the chemical table, and it is called carbon. Atom number eight is called oxygen, etc., because the chemical properties depend upon the electrons on the outside, and in fact only upon how many electrons there are. So the chemical properties of a substance depend only on a number, the number of electrons. (The whole list of elements of the chemists really could have been called 1 , 2 , 3 , 4 , 5 , etc. Instead of saying \u201ccarbon,\u201d we could say \u201celement six,\u201d meaning six electrons, but of course, when the elements were first discovered, it was not known that they could be numbered that way, and secondly, it would make everything look rather complicated. It is better to have names and symbols for these things, rather than to call everything by number.) More was discovered about the electrical force. The natural interpretation of electrical interaction is that two objects simply attract each other: plus against minus. However, this was discovered to be an inadequate idea to represent it. A more adequate representation of the situation is to say that the existence of the positive charge, in some sense, distorts, or creates a \u201ccondition\u201d in space, so that when we put the negative charge in, it feels a force. This potentiality for producing a force is called an electric field. When we put an electron in an electric field, we say it is \u201cpulled.\u201d We then have two rules: (a) charges make a field, and (b) charges in fields have forces on them and move. The reason for this will become clear when we discuss the following phenomena: If we were to charge a body, say a comb, electrically, and then place a charged piece of paper at a distance and move the comb back and forth, the paper will respond by always pointing to the comb. If we shake it faster, it will be discovered that the paper is a little behind, there is a delay in the action. (At the first stage, when we move the comb rather slowly, we find a complication which is magnetism. Magnetic influences have to do with charges in relative motion, so magnetic forces and electric forces can really be attributed to one field, as two different aspects of exactly the same thing. A changing electric field cannot exist without magnetism.) If we move the charged paper farther out, the delay is greater. Then an interesting thing is observed. Although the forces between two charged objects should go inversely as the square of the distance, it is found, when we shake a charge, that the influence extends very much farther out than we would guess at first sight. That is, the effect falls off more slowly than the inverse square. Here is an analogy: If we are in a pool of water and there is a floating cork very close by, we can move it \u201cdirectly\u201d by pushing the water with another cork. If you looked only at the two corks, all you would see would be that one moved immediately in response to the motion of the other\u2014there is some kind of \u201cinteraction\u201d between them. Of course, what we really do is to disturb the water; the water then disturbs the other cork. We could make up a \u201claw\u201d that if you pushed the water a little bit, an object close by in the water would move. If it were farther away, of course, the second cork would scarcely move, for we move the water locally. On the other hand, if we jiggle the cork a new phenomenon is involved, in which the motion of the water moves the water there, etc., and waves travel away, so that by jiggling, there is an influence very much farther out, an oscillatory influence, that cannot be understood from the direct interaction. Therefore the idea of direct interaction must be replaced with the existence of the water, or in the electrical case, with what we call the electromagnetic field. The electromagnetic field can carry waves; some of these waves are light, others are used in radio broadcasts, but the general name is electromagnetic waves. These oscillatory waves can have various frequencies. The only thing that is really different from one wave to another is the frequency of oscillation. If we shake a charge back and forth more and more rapidly, and look at the effects, we get a whole series of different kinds of effects, which are all unified by specifying but one number, the number of oscillations per second. The usual \u201cpickup\u201d that we get from electric currents in the circuits in the walls of a building have a frequency of about one hundred cycles per second. If we increase the frequency to 500 or 1000 kilocycles ( 1 kilocycle =1000 cycles) per second, we are \u201con the air,\u201d for this is the frequency range which is used for radio broadcasts. (Of course it has nothing to do with the air! We can have radio broadcasts without any air.) If we again increase the frequency, we come into the range that is used for FM and TV. Going still further, we use certain short waves, for example for radar. Still higher, and we do not need an instrument to \u201csee\u201d the stuff, we can see it with the human eye. In the range of frequency from 5\u00d7 10 14 to 10 15 cycles per second our eyes would see the oscillation of the charged comb, if we could shake it that fast, as red, blue, or violet light, depending on the frequency. Frequencies below this range are called infrared, and above it, ultraviolet. The fact that we can see in a particular frequency range makes that part of the electromagnetic spectrum no more impressive than the other parts from a physicist\u2019s standpoint, but from a human standpoint, of course, it is more interesting. If we go up even higher in frequency, we get x-rays. X-rays are nothing but very high-frequency light. If we go still higher, we get gamma rays. These two terms, x-rays and gamma rays, are used almost synonymously. Usually electromagnetic rays coming from nuclei are called gamma rays, while those of high energy from atoms are called x-rays, but at the same frequency they are indistinguishable physically, no matter what their source. If we go to still higher frequencies, say to 10 24 cycles per second, we find that we can make those waves artificially, for example with the synchrotron here at Caltech. We can find electromagnetic waves with stupendously high frequencies\u2014with even a thousand times more rapid oscillation\u2014in the waves found in cosmic rays. These waves cannot be controlled by us. Having described the idea of the electromagnetic field, and that this field can carry waves, we soon learn that these waves actually behave in a strange way which seems very unwavelike. At higher frequencies they behave much more like particles! It is quantum mechanics, discovered just after 1920, which explains this strange behavior. In the years before 1920, the picture of space as a three-dimensional space, and of time as a separate thing, was changed by Einstein, first into a combination which we call space-time, and then still further into a curved space-time to represent gravitation. So the \u201cstage\u201d is changed into space-time, and gravitation is presumably a modification of space-time. Then it was also found that the rules for the motions of particles were incorrect. The mechanical rules of \u201cinertia\u201d and \u201cforces\u201d are wrong\u2014Newton\u2019s laws are wrong\u2014in the world of atoms. Instead, it was discovered that things on a small scale behave nothing like things on a large scale. That is what makes physics difficult\u2014and very interesting. It is hard because the way things behave on a small scale is so \u201cunnatural\u201d; we have no direct experience with it. Here things behave like nothing we know of, so that it is impossible to describe this behavior in any other than analytic ways. It is difficult, and takes a lot of imagination. Quantum mechanics has many aspects. In the first place, the idea that a particle has a definite location and a definite speed is no longer allowed; that is wrong. To give an example of how wrong classical physics is, there is a rule in quantum mechanics that says that one cannot know both where something is and how fast it is moving. The uncertainty of the momentum and the uncertainty of the position are complementary, and the product of the two is bounded by a small constant. We can write the law like this: \u0394x\u0394p\u2265\u210f/2 , but we shall explain it in more detail later. This rule is the explanation of a very mysterious paradox: if the atoms are made out of plus and minus charges, why don\u2019t the minus charges simply sit on top of the plus charges (they attract each other) and get so close as to completely cancel them out? Why are atoms so big? Why is the nucleus at the center with the electrons around it? It was first thought that this was because the nucleus was so big; but no, the nucleus is very small. An atom has a diameter of about 10 \u22128 cm. The nucleus has a diameter of about 10 \u221213 cm. If we had an atom and wished to see the nucleus, we would have to magnify it until the whole atom was the size of a large room, and then the nucleus would be a bare speck which you could just about make out with the eye, but very nearly all the weight of the atom is in that infinitesimal nucleus. What keeps the electrons from simply falling in? This principle: If they were in the nucleus, we would know their position precisely, and the uncertainty principle would then require that they have a very large (but uncertain) momentum, i.e., a very large kinetic energy. With this energy they would break away from the nucleus. They make a compromise: they leave themselves a little room for this uncertainty and then jiggle with a certain amount of minimum motion in accordance with this rule. (Remember that when a crystal is cooled to absolute zero, we said that the atoms do not stop moving, they still jiggle. Why? If they stopped moving, we would know where they were and that they had zero motion, and that is against the uncertainty principle. We cannot know where they are and how fast they are moving, so they must be continually wiggling in there!) Another most interesting change in the ideas and philosophy of science brought about by quantum mechanics is this: it is not possible to predict exactly what will happen in any circumstance. For example, it is possible to arrange an atom which is ready to emit light, and we can measure when it has emitted light by picking up a photon particle, which we shall describe shortly. We cannot, however, predict when it is going to emit the light or, with several atoms, which one is going to. You may say that this is because there are some internal \u201cwheels\u201d which we have not looked at closely enough. No, there are no internal wheels; nature, as we understand it today, behaves in such a way that it is fundamentally impossible to make a precise prediction of exactly what will happen in a given experiment. This is a horrible thing; in fact, philosophers have said before that one of the fundamental requisites of science is that whenever you set up the same conditions, the same thing must happen. This is simply not true, it is not a fundamental condition of science. The fact is that the same thing does not happen, that we can find only an average, statistically, as to what happens. Nevertheless, science has not completely collapsed. Philosophers, incidentally, say a great deal about what is absolutely necessary for science, and it is always, so far as one can see, rather naive, and probably wrong. For example, some philosopher or other said it is fundamental to the scientific effort that if an experiment is performed in, say, Stockholm, and then the same experiment is done in, say, Quito, the same results must occur. That is quite false. It is not necessary for science to do that; it may be a fact of experience, but it is not necessary. For example, if one of the experiments is to look out at the sky and see the aurora borealis in Stockholm, you do not see it in Quito; that is a different phenomenon. \u201cBut,\u201d you say, \u201cthat is something that has to do with the outside; can you close yourself up in a box in Stockholm and pull down the shade and get any difference?\u201d Surely. If we take a pendulum on a universal joint, and pull it out and let go, then the pendulum will swing almost in a plane, but not quite. Slowly the plane keeps changing in Stockholm, but not in Quito. The blinds are down, too. The fact that this happened does not bring on the destruction of science. What is the fundamental hypothesis of science, the fundamental philosophy? We stated it in the first chapter: the sole test of the validity of any idea is experiment. If it turns out that most experiments work out the same in Quito as they do in Stockholm, then those \u201cmost experiments\u201d will be used to formulate some general law, and those experiments which do not come out the same we will say were a result of the environment near Stockholm. We will invent some way to summarize the results of the experiment, and we do not have to be told ahead of time what this way will look like. If we are told that the same experiment will always produce the same result, that is all very well, but if when we try it, it does not, then it does not. We just have to take what we see, and then formulate all the rest of our ideas in terms of our actual experience. Returning again to quantum mechanics and fundamental physics, we cannot go into details of the quantum-mechanical principles at this time, of course, because these are rather difficult to understand. We shall assume that they are there, and go on to describe what some of the consequences are. One of the consequences is that things which we used to consider as waves also behave like particles, and particles behave like waves; in fact everything behaves the same way. There is no distinction between a wave and a particle. So quantum mechanics unifies the idea of the field and its waves, and the particles, all into one. Now it is true that when the frequency is low, the field aspect of the phenomenon is more evident, or more useful as an approximate description in terms of everyday experiences. But as the frequency increases, the particle aspects of the phenomenon become more evident with the equipment with which we usually make the measurements. In fact, although we mentioned many frequencies, no phenomenon directly involving a frequency has yet been detected above approximately 10 12 cycles per second. We only deduce the higher frequencies from the energy of the particles, by a rule which assumes that the particle-wave idea of quantum mechanics is valid. Thus we have a new view of electromagnetic interaction. We have a new kind of particle to add to the electron, the proton, and the neutron. That new particle is called a photon. The new view of the interaction of electrons and photons that is electromagnetic theory, but with everything quantum-mechanically correct, is called quantum electrodynamics. This fundamental theory of the interaction of light and matter, or electric field and charges, is our greatest success so far in physics. In this one theory we have the basic rules for all ordinary phenomena except for gravitation and nuclear processes. For example, out of quantum electrodynamics come all known electrical, mechanical, and chemical laws: the laws for the collision of billiard balls, the motions of wires in magnetic fields, the specific heat of carbon monoxide, the color of neon signs, the density of salt, and the reactions of hydrogen and oxygen to make water are all consequences of this one law. All these details can be worked out if the situation is simple enough for us to make an approximation, which is almost never, but often we can understand more or less what is happening. At the present time no exceptions are found to the quantum-electrodynamic laws outside the nucleus, and there we do not know whether there is an exception because we simply do not know what is going on in the nucleus. In principle, then, quantum electrodynamics is the theory of all chemistry, and of life, if life is ultimately reduced to chemistry and therefore just to physics because chemistry is already reduced (the part of physics which is involved in chemistry being already known). Furthermore, the same quantum electrodynamics, this great thing, predicts a lot of new things. In the first place, it tells the properties of very high-energy photons, gamma rays, etc. It predicted another very remarkable thing: besides the electron, there should be another particle of the same mass, but of opposite charge, called a positron, and these two, coming together, could annihilate each other with the emission of light or gamma rays. (After all, light and gamma rays are all the same, they are just different points on a frequency scale.) The generalization of this, that for each particle there is an antiparticle, turns out to be true. In the case of electrons, the antiparticle has another name\u2014it is called a positron, but for most other particles, it is called anti-so-and-so, like antiproton or antineutron. In quantum electrodynamics, two numbers are put in and most of the other numbers in the world are supposed to come out. The two numbers that are put in are called the mass of the electron and the charge of the electron. Actually, that is not quite true, for we have a whole set of numbers for chemistry which tells how heavy the nuclei are. That leads us to the next part. What are the nuclei made of, and how are they held together? It is found that the nuclei are held together by enormous forces. When these are released, the energy released is tremendous compared with chemical energy, in the same ratio as the atomic bomb explosion is to a TNT explosion, because, of course, the atomic bomb has to do with changes inside the nucleus, while the explosion of TNT has to do with the changes of the electrons on the outside of the atoms. The question is, what are the forces which hold the protons and neutrons together in the nucleus? Just as the electrical interaction can be connected to a particle, a photon, Yukawa suggested that the forces between neutrons and protons also have a field of some kind, and that when this field jiggles it behaves like a particle. Thus there could be some other particles in the world besides protons and neutrons, and he was able to deduce the properties of these particles from the already known characteristics of nuclear forces. For example, he predicted they should have a mass of two or three hundred times that of an electron; and lo and behold, in cosmic rays there was discovered a particle of the right mass! But it later turned out to be the wrong particle. It was called a \u03bc -meson, or muon. However, a little while later, in 1947 or 1948, another particle was found, the \u03c0 -meson, or pion, which satisfied Yukawa\u2019s criterion. Besides the proton and the neutron, then, in order to get nuclear forces we must add the pion. Now, you say, \u201cOh great!, with this theory we make quantum nucleodynamics using the pions just like Yukawa wanted to do, and see if it works, and everything will be explained.\u201d Bad luck. It turns out that the calculations that are involved in this theory are so difficult that no one has ever been able to figure out what the consequences of the theory are, or to check it against experiment, and this has been going on now for almost twenty years! So we are stuck with a theory, and we do not know whether it is right or wrong, but we do know that it is a little wrong, or at least incomplete. While we have been dawdling around theoretically, trying to calculate the consequences of this theory, the experimentalists have been discovering some things. For example, they had already discovered this muon, and we do not yet know where it fits. Also, in cosmic rays, a large number of other \u201cextra\u201d particles were found. It turns out that today we have approximately thirty particles, and it is very difficult to understand the relationships of all these particles, and what nature wants them for, or what the connections are from one to another. We do not today understand these various particles as different aspects of the same thing, and the fact that we have so many unconnected particles is a representation of the fact that we have so much unconnected information without a good theory. After the great successes of quantum electrodynamics, there is a certain amount of knowledge of nuclear physics which is rough knowledge, sort of half experience and half theory, assuming a type of force between protons and neutrons and seeing what will happen, but not really understanding where the force comes from. Aside from that, we have made very little progress. We have collected an enormous number of chemical elements. In the chemical case, there suddenly appeared a relationship among these elements which was unexpected, and which is embodied in the periodic table of Mendeleev. For example, sodium and potassium are about the same in their chemical properties and are found in the same column in the Mendeleev chart. We have been seeking a Mendeleev-type chart for the new particles. One such chart of the new particles was made independently by Gell-Mann in the U.S.A. and Nishijima in Japan. The basis of their classification is a new number, like the electric charge, which can be assigned to each particle, called its \u201cstrangeness,\u201d S . This number is conserved, like the electric charge, in reactions which take place by nuclear forces. In Table 2\u20132 are listed all the particles. We cannot discuss them much at this stage, but the table will at least show you how much we do not know. Underneath each particle its mass is given in a certain unit, called the MeV. One MeV is equal to 1.783\u00d7 10 \u221227 gram. The reason this unit was chosen is historical, and we shall not go into it now. More massive particles are put higher up on the chart; we see that a neutron and a proton have almost the same mass. In vertical columns we have put the particles with the same electrical charge, all neutral objects in one column, all positively charged ones to the right of this one, and all negatively charged objects to the left. Particles are shown with a solid line and \u201cresonances\u201d with a dashed one. Several particles have been omitted from the table. These include the important zero-mass, zero-charge particles, the photon and the graviton, which do not fall into the baryon-meson-lepton classification scheme, and also some of the newer resonances ( K \u2217 , \u03d5 , \u03b7 ). The antiparticles of the mesons are listed in the table, but the antiparticles of the leptons and baryons would have to be listed in another table which would look exactly like this one reflected on the zero-charge column. Although all of the particles except the electron, neutrino, photon, graviton, and proton are unstable, decay products have been shown only for the resonances. Strangeness assignments are not applicable for leptons, since they do not interact strongly with nuclei. All particles which are together with the neutrons and protons are called baryons, and the following ones exist: There is a \u201clambda,\u201d with a mass of 1115 MeV, and three others, called sigmas, minus, neutral, and plus, with several masses almost the same. There are groups or multiplets with almost the same mass, within one or two percent. Each particle in a multiplet has the same strangeness. The first multiplet is the proton-neutron doublet, and then there is a singlet (the lambda) then the sigma triplet, and finally the xi doublet. Very recently, in 1961, even a few more particles were found. Or are they particles? They live so short a time, they disintegrate almost instantaneously, as soon as they are formed, that we do not know whether they should be considered as new particles, or some kind of \u201cresonance\u201d interaction of a certain definite energy between the \u039b and \u03c0 products into which they disintegrate. In addition to the baryons the other particles which are involved in the nuclear interaction are called mesons. There are first the pions, which come in three varieties, positive, negative, and neutral; they form another multiplet. We have also found some new things called K-mesons, and they occur as a doublet, K + and K 0 . Also, every particle has its antiparticle, unless a particle is its own antiparticle. For example, the \u03c0 \u2212 and the \u03c0 + are antiparticles, but the \u03c0 0 is its own antiparticle. The K \u2212 and K + are antiparticles, and the K 0 and K \u00af \u00af \u00af \u00af 0 . In addition, in 1961 we also found some more mesons or maybe mesons which disintegrate almost immediately. A thing called \u03c9 which goes into three pions has a mass 780 on this scale, and somewhat less certain is an object which disintegrates into two pions. These particles, called mesons and baryons, and the antiparticles of the mesons are on the same chart, but the antiparticles of the baryons must be put on another chart, \u201creflected\u201d through the charge-zero column. Just as Mendeleev\u2019s chart was very good, except for the fact that there were a number of rare earth elements which were hanging out loose from it, so we have a number of things hanging out loose from this chart\u2014particles which do not interact strongly in nuclei, have nothing to do with a nuclear interaction, and do not have a strong interaction (I mean the powerful kind of interaction of nuclear energy). These are called leptons, and they are the following: there is the electron, which has a very small mass on this scale, only 0.510 MeV. Then there is that other, the muon, which has a mass much higher, 206 times as heavy as an electron. So far as we can tell, by all experiments so far, the difference between the electron and the muon is nothing but the mass. Everything works exactly the same for the muon as for the electron, except that one is heavier than the other. Why is there another one heavier; what is the use for it? We do not know. In addition, there is a lepton which is neutral, called a neutrino, and this particle has zero mass. In fact, it is now known that there are two different kinds of neutrinos, one related to electrons and the other related to muons. Finally, we have two other particles which do not interact strongly with the nuclear ones: one is a photon, and perhaps, if the field of gravity also has a quantum-mechanical analog (a quantum theory of gravitation has not yet been worked out), then there will be a particle, a graviton, which will have zero mass. What is this \u201czero mass\u201d? The masses given here are the masses of the particles at rest. The fact that a particle has zero mass means, in a way, that it cannot be at rest. A photon is never at rest, it is always moving at 186,000 miles a second. We will understand more what mass means when we understand the theory of relativity, which will come in due time. Thus we are confronted with a large number of particles, which together seem to be the fundamental constituents of matter. Fortunately, these particles are not all different in their interactions with one another. In fact, there seem to be just four kinds of interaction between particles which, in the order of decreasing strength, are the nuclear force, electrical interactions, the beta-decay interaction, and gravity. The photon is coupled to all charged particles and the strength of the interaction is measured by some number, which is 1/137 . The detailed law of this coupling is known, that is quantum electrodynamics. Gravity is coupled to all energy, but its coupling is extremely weak, much weaker than that of electricity. This law is also known. Then there are the so-called weak decays\u2014beta decay, which causes the neutron to disintegrate into proton, electron, and neutrino, relatively slowly. This law is only partly known. The so-called strong interaction, the meson-baryon interaction, has a strength of 1 in this scale, and the law is completely unknown, although there are a number of known rules, such as that the number of baryons does not change in any reaction. This then, is the horrible condition of our physics today. To summarize it, I would say this: outside the nucleus, we seem to know all; inside it, quantum mechanics is valid\u2014the principles of quantum mechanics have not been found to fail. The stage on which we put all of our knowledge, we would say, is relativistic space-time; perhaps gravity is involved in space-time. We do not know how the universe got started, and we have never made experiments which check our ideas of space and time accurately, below some tiny distance, so we only know that our ideas work above that distance. We should also add that the rules of the game are the quantum-mechanical principles, and those principles apply, so far as we can tell, to the new particles as well as to the old. The origin of the forces in nuclei leads us to new particles, but unfortunately they appear in great profusion and we lack a complete understanding of their interrelationship, although we already know that there are some very surprising relationships among them. We seem gradually to be groping toward an understanding of the world of subatomic particles, but we really do not know how far we have yet to go in this task."
    },
    {
        "input": "Electromagnetism",
        "output": "Consider a force like gravitation which varies predominantly inversely as the square of the distance, but which is about a billion-billion-billion-billion times stronger. And with another difference. There are two kinds of \u201cmatter,\u201d which we can call positive and negative. Like kinds repel and unlike kinds attract\u2014unlike gravity where there is only attraction. What would happen? A bunch of positives would repel with an enormous force and spread out in all directions. A bunch of negatives would do the same. But an evenly mixed bunch of positives and negatives would do something completely different. The opposite pieces would be pulled together by the enormous attractions. The net result would be that the terrific forces would balance themselves out almost perfectly, by forming tight, fine mixtures of the positive and the negative, and between two separate bunches of such mixtures there would be practically no attraction or repulsion at all. There is such a force: the electrical force. And all matter is a mixture of positive protons and negative electrons which are attracting and repelling with this great force. So perfect is the balance, however, that when you stand near someone else you don\u2019t feel any force at all. If there were even a little bit of unbalance you would know it. If you were standing at arm\u2019s length from someone and each of you had one percent more electrons than protons, the repelling force would be incredible. How great? Enough to lift the Empire State Building? No! To lift Mount Everest? No! The repulsion would be enough to lift a \u201cweight\u201d equal to that of the entire earth! With such enormous forces so perfectly balanced in this intimate mixture, it is not hard to understand that matter, trying to keep its positive and negative charges in the finest balance, can have a great stiffness and strength. The Empire State Building, for example, swings less than one inch in the wind because the electrical forces hold every electron and proton more or less in its proper place. On the other hand, if we look at matter on a scale small enough that we see only a few atoms, any small piece will not, usually, have an equal number of positive and negative charges, and so there will be strong residual electrical forces. Even when there are equal numbers of both charges in two neighboring small pieces, there may still be large net electrical forces because the forces between individual charges vary inversely as the square of the distance. A net force can arise if a negative charge of one piece is closer to the positive than to the negative charges of the other piece. The attractive forces can then be larger than the repulsive ones and there can be a net attraction between two small pieces with no excess charges. The force that holds the atoms together, and the chemical forces that hold molecules together, are really electrical forces acting in regions where the balance of charge is not perfect, or where the distances are very small. You know, of course, that atoms are made with positive protons in the nucleus and with electrons outside. You may ask: \u201cIf this electrical force is so terrific, why don\u2019t the protons and electrons just get on top of each other? If they want to be in an intimate mixture, why isn\u2019t it still more intimate?\u201d The answer has to do with the quantum effects. If we try to confine our electrons in a region that is very close to the protons, then according to the uncertainty principle they must have some mean square momentum which is larger the more we try to confine them. It is this motion, required by the laws of quantum mechanics, that keeps the electrical attraction from bringing the charges any closer together. There is another question: \u201cWhat holds the nucleus together\u201d? In a nucleus there are several protons, all of which are positive. Why don\u2019t they push themselves apart? It turns out that in nuclei there are, in addition to electrical forces, nonelectrical forces, called nuclear forces, which are greater than the electrical forces and which are able to hold the protons together in spite of the electrical repulsion. The nuclear forces, however, have a short range\u2014their force falls off much more rapidly than 1/r2. And this has an important consequence. If a nucleus has too many protons in it, it gets too big, and it will not stay together. An example is uranium, with 92 protons. The nuclear forces act mainly between each proton (or neutron) and its nearest neighbor, while the electrical forces act over larger distances, giving a repulsion between each proton and all of the others in the nucleus. The more protons in a nucleus, the stronger is the electrical repulsion, until, as in the case of uranium, the balance is so delicate that the nucleus is almost ready to fly apart from the repulsive electrical force. If such a nucleus is just \u201ctapped\u201d lightly (as can be done by sending in a slow neutron), it breaks into two pieces, each with positive charge, and these pieces fly apart by electrical repulsion. The energy which is liberated is the energy of the atomic bomb. This energy is usually called \u201cnuclear\u201d energy, but it is really \u201celectrical\u201d energy released when electrical forces have overcome the attractive nuclear forces. We may ask, finally, what holds a negatively charged electron together (since it has no nuclear forces). If an electron is all made of one kind of substance, each part should repel the other parts. Why, then, doesn\u2019t it fly apart? But does the electron have \u201cparts\u201d? Perhaps we should say that the electron is just a point and that electrical forces only act between different point charges, so that the electron does not act upon itself. Perhaps. All we can say is that the question of what holds the electron together has produced many difficulties in the attempts to form a complete theory of electromagnetism. The question has never been answered. We will entertain ourselves by discussing this subject some more in later chapters. As we have seen, we should expect that it is a combination of electrical forces and quantum-mechanical effects that will determine the detailed structure of materials in bulk, and, therefore, their properties. Some materials are hard, some are soft. Some are electrical \u201cconductors\u201d\u2014because their electrons are free to move about; others are \u201cinsulators\u201d\u2014because their electrons are held tightly to individual atoms. We shall consider later how some of these properties come about, but that is a very complicated subject, so we will begin by looking at the electrical forces only in simple situations. We begin by treating only the laws of electricity\u2014including magnetism, which is really a part of the same subject. We have said that the electrical force, like a gravitational force, decreases inversely as the square of the distance between charges. This relationship is called Coulomb\u2019s law. But it is not precisely true when charges are moving\u2014the electrical forces depend also on the motions of the charges in a complicated way. One part of the force between moving charges we call the magnetic force. It is really one aspect of an electrical effect. That is why we call the subject \u201celectromagnetism.\u201d There is an important general principle that makes it possible to treat electromagnetic forces in a relatively simple way. We find, from experiment, that the force that acts on a particular charge\u2014no matter how many other charges there are or how they are moving\u2014depends only on the position of that particular charge, on the velocity of the charge, and on the amount of charge. We can write the force F on a charge q moving with a velocity v as F=q(E+v\u00d7B). We call E the electric field and B the magnetic field at the location of the charge. The important thing is that the electrical forces from all the other charges in the universe can be summarized by giving just these two vectors. Their values will depend on where the charge is, and may change with time. Furthermore, if we replace that charge with another charge, the force on the new charge will be just in proportion to the amount of charge so long as all the rest of the charges in the world do not change their positions or motions. (In real situations, of course, each charge produces forces on all other charges in the neighborhood and may cause these other charges to move, and so in some cases the fields can change if we replace our particular charge by another.) We know from Vol. I how to find the motion of a particle if we know the force on it. Equation (1.1) can be combined with the equation of motion to give d dt [ mv (1\u2212v2/c2)1/2 ]=F=q(E+v\u00d7B). So if E and B are given, we can find the motions. Now we need to know how the E \u2019s and B \u2019s are produced. One of the most important simplifying principles about the way the fields are produced is this: Suppose a number of charges moving in some manner would produce a field E1 , and another set of charges would produce E2 . If both sets of charges are in place at the same time (keeping the same locations and motions they had when considered separately), then the field produced is just the sum E=E1+E2. This fact is called the principle of superposition of fields. It holds also for magnetic fields. This principle means that if we know the law for the electric and magnetic fields produced by a single charge moving in an arbitrary way, then all the laws of electrodynamics are complete. If we want to know the force on charge A we need only calculate the E and B produced by each of the charges B , C , D , etc., and then add the E \u2019s and B \u2019s from all the charges to find the fields, and from them the forces acting on charge A . If it had only turned out that the field produced by a single charge was simple, this would be the neatest way to describe the laws of electrodynamics. We have already given a description of this law (Chapter 28, Vol. I) and it is, unfortunately, rather complicated. It turns out that the forms in which the laws of electrodynamics are simplest are not what you might expect. It is not simplest to give a formula for the force that one charge produces on another. It is true that when charges are standing still the Coulomb force law is simple, but when charges are moving about the relations are complicated by delays in time and by the effects of acceleration, among others. As a result, we do not wish to present electrodynamics only through the force laws between charges; we find it more convenient to consider another point of view\u2014a point of view in which the laws of electrodynamics appear to be the most easily manageable. First, we must extend, somewhat, our ideas of the electric and magnetic vectors, E and B . We have defined them in terms of the forces that are felt by a charge. We wish now to speak of electric and magnetic fields at a point even when there is no charge present. We are saying, in effect, that since there are forces \u201cacting on\u201d the charge, there is still \u201csomething\u201d there when the charge is removed. If a charge located at the point (x,y,z) at the time t feels the force F given by Eq. (1.1) we associate the vectors E and B with the point in space (x,y,z) . We may think of E(x,y,z,t) and B(x,y,z,t) as giving the forces that would be experienced at the time t by a charge located at (x,y,z) , with the condition that placing the charge there did not disturb the positions or motions of all the other charges responsible for the fields. Following this idea, we associate with every point (x,y,z) in space two vectors E and B , which may be changing with time. The electric and magnetic fields are, then, viewed as vector functions of x , y , z , and t . Since a vector is specified by its components, each of the fields E(x,y,z,t) and B(x,y,z,t) represents three mathematical functions of x , y , z , and t . It is precisely because E (or B ) can be specified at every point in space that it is called a \u201cfield.\u201d A \u201cfield\u201d is any physical quantity which takes on different values at different points in space. Temperature, for example, is a field\u2014in this case a scalar field, which we write as T(x,y,z) . The temperature could also vary in time, and we would say the temperature field is time-dependent, and write T(x,y,z,t) . Another example is the \u201cvelocity field\u201d of a flowing liquid. We write v(x,y,z,t) for the velocity of the liquid at each point in space at the time t . It is a vector field. Returning to the electromagnetic fields\u2014although they are produced by charges according to complicated formulas, they have the following important characteristic: the relationships between the values of the fields at one point and the values at a nearby point are very simple. With only a few such relationships in the form of differential equations we can describe the fields completely. It is in terms of such equations that the laws of electrodynamics are most simply written. There have been various inventions to help the mind visualize the behavior of fields. The most correct is also the most abstract: we simply consider the fields as mathematical functions of position and time. We can also attempt to get a mental picture of the field by drawing vectors at many points in space, each of which gives the field strength and direction at that point. Such a representation is shown in Fig. 1\u20131. We can go further, however, and draw lines which are everywhere tangent to the vectors\u2014which, so to speak, follow the arrows and keep track of the direction of the field. When we do this we lose track of the lengths of the vectors, but we can keep track of the strength of the field by drawing the lines far apart when the field is weak and close together when it is strong. We adopt the convention that the number of lines per unit area at right angles to the lines is proportional to the field strength. This is, of course, only an approximation, and it will require, in general, that new lines sometimes start up in order to keep the number up to the strength of the field. The field of Fig. 1\u20131 is represented by field lines in Fig. 1\u20132. There are two mathematically important properties of a vector field which we will use in our description of the laws of electricity from the field point of view. Suppose we imagine a closed surface of some kind and ask whether we are losing \u201csomething\u201d from the inside; that is, does the field have a quality of \u201coutflow\u201d? For instance, for a velocity field we might ask whether the velocity is always outward on the surface or, more generally, whether more fluid flows out (per unit time) than comes in. We call the net amount of fluid going out through the surface per unit time the \u201cflux of velocity\u201d through the surface. The flow through an element of a surface is just equal to the component of the velocity perpendicular to the surface times the area of the surface. For an arbitrary closed surface, the net outward flow\u2014or flux\u2014is the average outward normal component of the velocity, times the area of the surface: Flux=( average normal component )\u22c5( surface area ). In the case of an electric field, we can mathematically define something analogous to an outflow, and we again call it the flux, but of course it is not the flow of any substance, because the electric field is not the velocity of anything. It turns out, however, that the mathematical quantity which is the average normal component of the field still has a useful significance. We speak, then, of the electric flux\u2014also defined by Eq. (1.4). Finally, it is also useful to speak of the flux not only through a completely closed surface, but through any bounded surface. As before, the flux through such a surface is defined as the average normal component of a vector times the area of the surface. These ideas are illustrated in Fig. 1\u20133. There is a second property of a vector field that has to do with a line, rather than a surface. Suppose again that we think of a velocity field that describes the flow of a liquid. We might ask this interesting question: Is the liquid circulating? By that we mean: Is there a net rotational motion around some loop? Suppose that we instantaneously freeze the liquid everywhere except inside of a tube which is of uniform bore, and which goes in a loop that closes back on itself as in Fig. 1\u20134. Outside of the tube the liquid stops moving, but inside the tube it may keep on moving because of the momentum in the trapped liquid\u2014that is, if there is more momentum heading one way around the tube than the other. We define a quantity called the circulation as the resulting speed of the liquid in the tube times its circumference. We can again extend our ideas and define the \u201ccirculation\u201d for any vector field (even when there isn\u2019t anything moving). For any vector field the circulation around any imagined closed curve is defined as the average tangential component of the vector (in a consistent sense) multiplied by the circumference of the loop (Fig. 1\u20135): Circulation=( average tangential component )\u22c5( distance around ) You will see that this definition does indeed give a number which is proportional to the circulation velocity in the quickly frozen tube described above. With just these two ideas\u2014flux and circulation\u2014we can describe all the laws of electricity and magnetism at once. You may not understand the significance of the laws right away, but they will give you some idea of the way the physics of electromagnetism will be ultimately described. The first law of electromagnetism describes the flux of the electric field: ( Flux of E through any closed surface )= ( net charge inside ) \u03f50 , where \u03f50 is a convenient constant. (The constant \u03f50 is usually read as \u201cepsilon-zero\u201d or \u201cepsilon-naught\u201d.) If there are no charges inside the surface, even though there are charges nearby outside the surface, the average normal component of E is zero, so there is no net flux through the surface. To show the power of this type of statement, we can show that Eq. (1.6) is the same as Coulomb\u2019s law, provided only that we also add the idea that the field from a single charge is spherically symmetric. For a point charge, we draw a sphere around the charge. Then the average normal component is just the value of the magnitude of E at any point, since the field must be directed radially and have the same strength for all points on the sphere. Our rule now says that the field at the surface of the sphere, times the area of the sphere\u2014that is, the outgoing flux\u2014is proportional to the charge inside. If we were to make the radius of the sphere bigger, the area would increase as the square of the radius. The average normal component of the electric field times that area must still be equal to the same charge inside, and so the field must decrease as the square of the distance\u2014we get an \u201cinverse square\u201d field. If we have an arbitrary stationary curve in space and measure the circulation of the electric field around the curve, we will find that it is not, in general, zero (although it is for the Coulomb field). Rather, for electricity there is a second law that states: for any surface S (not closed) whose edge is the curve C , ( Circulation of E around C )=\u2212 d dt ( flux of B through S ). We can complete the laws of the electromagnetic field by writing two corresponding equations for the magnetic field B : \u239b \u239d Flux of B through any closed surface \u239e \u23a0 =0. (1.8) For a surface S bounded by the curve C , c 2 ( circulation of B around C )= d dt ( flux of E through S )+ ( flux of electric current through S ) \u03f5 0 . (1.9) The constant c 2 that appears in Eq. (1.9) is the square of the velocity of light. It appears because magnetism is in reality a relativistic effect of electricity. The constant \u03f5 0 has been stuck in to make the units of electric current come out in a convenient way. Equations (1.6) through (1.9), together with Eq. (1.1), are all the laws of electrodynamics1. As you remember, the laws of Newton were very simple to write down, but they had a lot of complicated consequences and it took us a long time to learn about them all. These laws are not nearly as simple to write down, which means that the consequences are going to be more elaborate and it will take us quite a lot of time to figure them all out. We can illustrate some of the laws of electrodynamics by a series of small experiments which show qualitatively the interrelationships of electric and magnetic fields. You have experienced the first term of Eq. (1.1) when combing your hair, so we won\u2019t show that one. The second part of Eq. (1.1) can be demonstrated by passing a current through a wire which hangs above a bar magnet, as shown in Fig. 1\u20136. The wire will move when a current is turned on because of the force F=qv\u00d7B . When a current exists, the charges inside the wire are moving, so they have a velocity v , and the magnetic field from the magnet exerts a force on them, which results in pushing the wire sideways. When the wire is pushed to the left, we would expect that the magnet must feel a push to the right. (Otherwise we could put the whole thing on a wagon and have a propulsion system that didn\u2019t conserve momentum!) Although the force is too small to make movement of the bar magnet visible, a more sensitively supported magnet, like a compass needle, will show the movement. How does the wire push on the magnet? The current in the wire produces a magnetic field of its own that exerts forces on the magnet. According to the last term in Eq. (1.9), a current must have a circulation of B \u2014in this case, the lines of B are loops around the wire, as shown in Fig. 1\u20137. This B -field is responsible for the force on the magnet. Equation (1.9) tells us that for a fixed current through the wire the circulation of B is the same for any curve that surrounds the wire. For curves\u2014say circles\u2014that are farther away from the wire, the circumference is larger, so the tangential component of B must decrease. You can see that we would, in fact, expect B to decrease linearly with the distance from a long straight wire. Now, we have said that a current through a wire produces a magnetic field, and that when there is a magnetic field present there is a force on a wire carrying a current. Then we should also expect that if we make a magnetic field with a current in one wire, it should exert a force on another wire which also carries a current. This can be shown by using two hanging wires as shown in Fig. 1\u20138. When the currents are in the same direction, the two wires attract, but when the currents are opposite, they repel. In short, electrical currents, as well as magnets, make magnetic fields. But wait, what is a magnet, anyway? If magnetic fields are produced by moving charges, is it not possible that the magnetic field from a piece of iron is really the result of currents? It appears to be so. We can replace the bar magnet of our experiment with a coil of wire, as shown in Fig. 1\u20139. When a current is passed through the coil\u2014as well as through the straight wire above it\u2014we observe a motion of the wire exactly as before, when we had a magnet instead of a coil. In other words, the current in the coil imitates a magnet. It appears, then, that a piece of iron acts as though it contains a perpetual circulating current. We can, in fact, understand magnets in terms of permanent currents in the atoms of the iron. The force on the magnet in Fig. 1\u20137 is due to the second term in Eq. (1.1). Where do the currents come from? One possibility would be from the motion of the electrons in atomic orbits. Actually, that is not the case for iron, although it is for some materials. In addition to moving around in an atom, an electron also spins about on its own axis\u2014something like the spin of the earth\u2014and it is the current from this spin that gives the magnetic field in iron. (We say \u201csomething like the spin of the earth\u201d because the question is so deep in quantum mechanics that the classical ideas do not really describe things too well.) In most substances, some electrons spin one way and some spin the other, so the magnetism cancels out, but in iron\u2014for a mysterious reason which we will discuss later\u2014many of the electrons are spinning with their axes lined up, and that is the source of the magnetism. Since the fields of magnets are from currents, we do not have to add any extra term to Eqs. (1.8) or (1.9) to take care of magnets. We just take all currents, including the circulating currents of the spinning electrons, and then the law is right. You should also notice that Eq. (1.8) says that there are no magnetic \u201ccharges\u201d analogous to the electrical charges appearing on the right side of Eq. (1.6). None has been found. The first term on the right-hand side of Eq. (1.9) was discovered theoretically by Maxwell and is of great importance. It says that changing electric fields produce magnetic effects. In fact, without this term the equation would not make sense, because without it there could be no currents in circuits that are not complete loops. But such currents do exist, as we can see in the following example. Imagine a capacitor made of two flat plates. It is being charged by a current that flows toward one plate and away from the other, as shown in Fig. 1\u201310. We draw a curve C around one of the wires and fill it in with a surface which crosses the wire, as shown by the surface S 1 in the figure. According to Eq. (1.9), the circulation of B around C (times c 2 ) is given by the current in the wire (divided by \u03f5 0 ). But what if we fill in the curve with a different surface S 2 , which is shaped like a bowl and passes between the plates of the capacitor, staying always away from the wire? There is certainly no current through this surface. But, surely, just changing the location of an imaginary surface is not going to change a real magnetic field! The circulation of B must be what it was before. The first term on the right-hand side of Eq. (1.9) does, indeed, combine with the second term to give the same result for the two surfaces S 1 and S 2 . For S 2 the circulation of B is given in terms of the rate of change of the flux of E between the plates of the capacitor. And it works out that the changing E is related to the current in just the way required for Eq. (1.9) to be correct. Maxwell saw that it was needed, and he was the first to write the complete equation. With the setup shown in Fig. 1\u20136 we can demonstrate another of the laws of electromagnetism. We disconnect the ends of the hanging wire from the battery and connect them to a galvanometer which tells us when there is a current through the wire. When we push the wire sideways through the magnetic field of the magnet, we observe a current. Such an effect is again just another consequence of Eq. (1.1)\u2014the electrons in the wire feel the force F=qv\u00d7B . The electrons have a sidewise velocity because they move with the wire. This v with a vertical B from the magnet results in a force on the electrons directed along the wire, which starts the electrons moving toward the galvanometer. Suppose, however, that we leave the wire alone and move the magnet. We guess from relativity that it should make no difference, and indeed, we observe a similar current in the galvanometer. How does the magnetic field produce forces on charges at rest? According to Eq. (1.1) there must be an electric field. A moving magnet must make an electric field. How that happens is said quantitatively by Eq. (1.7). This equation describes many phenomena of great practical interest, such as those that occur in electric generators and transformers. The most remarkable consequence of our equations is that the combination of Eq. (1.7) and Eq. (1.9) contains the explanation of the radiation of electromagnetic effects over large distances. The reason is roughly something like this: suppose that somewhere we have a magnetic field which is increasing because, say, a current is turned on suddenly in a wire. Then by Eq. (1.7) there must be a circulation of an electric field. As the electric field builds up to produce its circulation, then according to Eq. (1.9) a magnetic circulation will be generated. But the building up of this magnetic field will produce a new circulation of the electric field, and so on. In this way fields work their way through space without the need of charges or currents except at their source. That is the way we see each other! It is all in the equations of the electromagnetic fields. We now make a few remarks on our way of looking at this subject. You may be saying: \u201cAll this business of fluxes and circulations is pretty abstract. There are electric fields at every point in space; then there are these \u2018laws.\u2019 But what is actually happening? Why can\u2019t you explain it, for instance, by whatever it is that goes between the charges.\u201d Well, it depends on your prejudices. Many physicists used to say that direct action with nothing in between was inconceivable. (How could they find an idea inconceivable when it had already been conceived?) They would say: \u201cLook, the only forces we know are the direct action of one piece of matter on another. It is impossible that there can be a force with nothing to transmit it.\u201d But what really happens when we study the \u201cdirect action\u201d of one piece of matter right against another? We discover that it is not one piece right against the other; they are slightly separated, and there are electrical forces acting on a tiny scale. Thus we find that we are going to explain so-called direct-contact action in terms of the picture for electrical forces. It is certainly not sensible to try to insist that an electrical force has to look like the old, familiar, muscular push or pull, when it will turn out that the muscular pushes and pulls are going to be interpreted as electrical forces! The only sensible question is what is the most convenient way to look at electrical effects. Some people prefer to represent them as the interaction at a distance of charges, and to use a complicated law. Others love the field lines. They draw field lines all the time, and feel that writing E \u2019s and B \u2019s is too abstract. The field lines, however, are only a crude way of describing a field, and it is very difficult to give the correct, quantitative laws directly in terms of field lines. Also, the ideas of the field lines do not contain the deepest principle of electrodynamics, which is the superposition principle. Even though we know how the field lines look for one set of charges and what the field lines look like for another set of charges, we don\u2019t get any idea about what the field line patterns will look like when both sets are present together. From the mathematical standpoint, on the other hand, superposition is easy\u2014we simply add the two vectors. The field lines have some advantage in giving a vivid picture, but they also have some disadvantages. The direct interaction way of thinking has great advantages when thinking of electrical charges at rest, but has great disadvantages when dealing with charges in rapid motion. The best way is to use the abstract field idea. That it is abstract is unfortunate, but necessary. The attempts to try to represent the electric field as the motion of some kind of gear wheels, or in terms of lines, or of stresses in some kind of material have used up more effort of physicists than it would have taken simply to get the right answers about electrodynamics. It is interesting that the correct equations for the behavior of light were worked out by MacCullagh in 1839. But people said to him: \u201cYes, but there is no real material whose mechanical properties could possibly satisfy those equations, and since light is an oscillation that must vibrate in something, we cannot believe this abstract equation business.\u201d If people had been more open-minded, they might have believed in the right equations for the behavior of light a lot earlier than they did. In the case of the magnetic field we can make the following point: Suppose that you finally succeeded in making up a picture of the magnetic field in terms of some kind of lines or of gear wheels running through space. Then you try to explain what happens to two charges moving in space, both at the same speed and parallel to each other. Because they are moving, they will behave like two currents and will have a magnetic field associated with them (like the currents in the wires of Fig. 1\u20138). An observer who was riding along with the two charges, however, would see both charges as stationary, and would say that there is no magnetic field. The \u201cgear wheels\u201d or \u201clines\u201d disappear when you ride along with the object! All we have done is to invent a new problem. How can the gear wheels disappear?! The people who draw field lines are in a similar difficulty. Not only is it not possible to say whether the field lines move or do not move with charges\u2014they may disappear completely in certain coordinate frames. What we are saying, then, is that magnetism is really a relativistic effect. In the case of the two charges we just considered, travelling parallel to each other, we would expect to have to make relativistic corrections to their motion, with terms of order v 2 / c 2 . These corrections must correspond to the magnetic force. But what about the force between the two wires in our experiment (Fig. 1\u20138). There the magnetic force is the whole force. It didn\u2019t look like a \u201crelativistic correction.\u201d Also, if we estimate the velocities of the electrons in the wire (you can do this yourself), we find that their average speed along the wire is about 0.01 centimeter per second. So v 2 / c 2 is about 10 \u221225 . Surely a negligible \u201ccorrection.\u201d But no! Although the magnetic force is, in this case, 10 \u221225 of the \u201cnormal\u201d electrical force between the moving electrons, remember that the \u201cnormal\u201d electrical forces have disappeared because of the almost perfect balancing out\u2014because the wires have the same number of protons as electrons. The balance is much more precise than one part in 10 25 , and the small relativistic term which we call the magnetic force is the only term left. It becomes the dominant term. It is the near-perfect cancellation of electrical effects which allowed relativity effects (that is, magnetism) to be studied and the correct equations\u2014to order v 2 / c 2 \u2014to be discovered, even though physicists didn\u2019t know that\u2019s what was happening. And that is why, when relativity was discovered, the electromagnetic laws didn\u2019t need to be changed. They\u2014unlike mechanics\u2014were already correct to a precision of v 2 / c 2 . Let us end this chapter by pointing out that among the many phenomena studied by the Greeks there were two very strange ones: that if you rubbed a piece of amber you could lift up little pieces of papyrus, and that there was a strange rock from the land of Magnesia which attracted iron. It is amazing to think that these were the only phenomena known to the Greeks in which the effects of electricity or magnetism were apparent. The reason that these were the only phenomena that appeared is due primarily to the fantastic precision of the balancing of charges that we mentioned earlier. Study by scientists who came after the Greeks uncovered one new phenomenon after another that were really some aspect of these amber and/or lodestone effects. Now we realize that the phenomena of chemical interaction and, ultimately, of life itself are to be understood in terms of electromagnetism. At the same time that an understanding of the subject of electromagnetism was being developed, technical possibilities that defied the imagination of the people that came before were appearing: it became possible to signal by telegraph over long distances, and to talk to another person miles away without any connections between, and to run huge power systems\u2014a great water wheel, connected by filaments over hundreds of miles to another engine that turns in response to the master wheel\u2014many thousands of branching filaments\u2014ten thousand engines in ten thousand places running the machines of industries and homes\u2014all turning because of the knowledge of the laws of electromagnetism. Today we are applying even more subtle effects. The electrical forces, enormous as they are, can also be very tiny, and we can control them and use them in very many ways. So delicate are our instruments that we can tell what a man is doing by the way he affects the electrons in a thin metal rod hundreds of miles away. All we need to do is to use the rod as an antenna for a television receiver! From a long view of the history of mankind\u2014seen from, say, ten thousand years from now\u2014there can be little doubt that the most significant event of the 19th century will be judged as Maxwell\u2019s discovery of the laws of electrodynamics. The American Civil War will pale into provincial insignificance in comparison with this important scientific event of the same decade."
    },
    {
        "input": "Algebra",
        "output": "In our study of oscillating systems we shall have occasion to use one of the most remarkable, almost astounding, formulas in all of mathematics. From the physicist\u2019s point of view we could bring forth this formula in two minutes or so, and be done with it. But science is as much for intellectual enjoyment as for practical utility, so instead of just spending a few minutes on this amazing jewel, we shall surround the jewel by its proper setting in the grand design of that branch of mathematics which is called elementary algebra. Now you may ask, \u201cWhat is mathematics doing in a physics lecture?\u201d We have several possible excuses: first, of course, mathematics is an important tool, but that would only excuse us for giving the formula in two minutes. On the other hand, in theoretical physics we discover that all our laws can be written in mathematical form; and that this has a certain simplicity and beauty about it. So, ultimately, in order to understand nature it may be necessary to have a deeper understanding of mathematical relationships. But the real reason is that the subject is enjoyable, and although we humans cut nature up in different ways, and we have different courses in different departments, such compartmentalization is really artificial, and we should take our intellectual pleasures where we find them. Another reason for looking more carefully at algebra now, even though most of us studied algebra in high school, is that that was the first time we studied it; all the equations were unfamiliar, and it was hard work, just as physics is now. Every so often it is a great pleasure to look back to see what territory has been covered, and what the great map or plan of the whole thing is. Perhaps some day somebody in the Mathematics Department will present a lecture on mechanics in such a way as to show what it was we were trying to learn in the physics course! The subject of algebra will not be developed from the point of view of a mathematician, exactly, because the mathematicians are mainly interested in how various mathematical facts are demonstrated, and how many assumptions are absolutely required, and what is not required. They are not so interested in the result of what they prove. For example, we may find the Pythagorean theorem quite interesting, that the sum of the squares of the sides of a right triangle is equal to the square of the hypotenuse; that is an interesting fact, a curiously simple thing, which may be appreciated without discussing the question of how to prove it, or what axioms are required. So, in the same spirit, we shall describe qualitatively, if we may put it that way, the system of elementary algebra. We say elementary algebra because there is a branch of mathematics called modern algebra in which some of the rules such as ab=ba , are abandoned, and it is still called algebra, but we shall not discuss that. To discuss this subject we start in the middle. We suppose that we already know what integers are, what zero is, and what it means to increase a number by one unit. You may say, \u201cThat is not in the middle!\u201d But it is the middle from a mathematical standpoint, because we could go even further back and describe the theory of sets in order to derive some of these properties of integers. But we are not going in that direction, the direction of mathematical philosophy and mathematical logic, but rather in the other direction, from the assumption that we know what integers are and we know how to count. If we start with a certain number a , an integer, and we count successively one unit b times, the number we arrive at we call a+b , and that defines addition of integers. Once we have defined addition, then we can consider this: if we start with nothing and add a to it, b times in succession, we call the result multiplication of integers; we call it b times a . Now we can also have a succession of multiplications: if we start with 1 and multiply by a , b times in succession, we call that raising to a power: ab . Now as a consequence of these definitions it can be easily shown that all of the following relationships are true: (a) a+b=b+a (b) a+(b+c)=(a+b)+c (c) ab=ba (d) a(b+c)=ab+ac (e) (ab)c=a(bc) (f) (ab)c=acbc (g) abac=a(b+c) (h) (ab)c=a(bc) (i) a+0=a (j) a\u22c51=a (k) a1=a These results are well known and we shall not belabor the point, we merely list them. Of course, 1 and 0 have special properties; for example, a+0 is a , a times 1=a , and a to the first power is a . In this discussion we must also assume a few other properties like continuity and ordering, which are very hard to define; we will let the rigorous theory do it. Furthermore, it is definitely true that we have written down too many \u201crules\u201d; some of them may be deducible from the others, but we shall not worry about such matters. In addition to the direct operations of addition, multiplication, and raising to a power, we have also the inverse operations, which are defined as follows. Let us assume that a and c are given, and that we wish to find what values of b satisfy such equations as a+b=c , ab=c , ba=c . If a+b=c , b is defined as c\u2212a , which is called subtraction. The operation called division is also clear: if ab=c , then b=c/a defines division\u2014a solution of the equation ab=c \u201cbackwards.\u201d Now if we have a power ba=c and we ask ourselves, \u201cWhat is b ?,\u201d it is called the a th root of c : b=a \u221a c . For instance, if we ask ourselves the following question, \u201cWhat integer, raised to the third power, equals 8 ?,\u201d then the answer is called the cube root of 8 ; it is 2 . Because ba and ab are not equal, there are two inverse problems associated with powers, and the other inverse problem would be, \u201cTo what power must we raise 2 to get 8 ?\u201d This is called taking the logarithm. If ab=c , we write b=logac . The fact that it has a cumbersome notation relative to the others does not mean that it is any less elementary, at least applied to integers, than the other processes. Although logarithms come late in an algebra class, in practice they are, of course, just as simple as roots; they are just a different kind of solution of an algebraic equation. The direct and inverse operations are summarized as follows: (a) addition (a\u2032) subtraction a+b=c b=c\u2212a (b) multiplication (b\u2032) division ab=c b=c/a (c) power (c\u2032) root ba=c b=a \u221a c (d) power (d\u2032) logarithm ab=c b=logac Now here is the idea. These relationships, or rules, are correct for integers, since they follow from the definitions of addition, multiplication, and raising to a power. We are going to discuss whether or not we can broaden the class of objects which a , b , and c represent so that they will obey these same rules, although the processes for a+b , and so on, will not be definable in terms of the direct action of adding 1 , for instance, or successive multiplications by integers. When we try to solve simple algebraic equations using all these definitions, we soon discover some insoluble problems, such as the following. Suppose that we try to solve the equation b=3\u22125 . That means, according to our definition of subtraction, that we must find a number which, when added to 5 , gives 3 . And of course there is no such number, because we consider only positive integers; this is an insoluble problem. However, the plan, the great idea, is this: abstraction and generalization. From the whole structure of algebra, rules plus integers, we abstract the original definitions of addition and multiplication, but we leave the rules (22.1) and (22.2), and assume these to be true in general on a wider class of numbers, even though they are originally derived on a smaller class. Thus, rather than using integers symbolically to define the rules, we use the rules as the definition of the symbols, which then represent a more general kind of number. As an example, by working with the rules alone we can show that 3\u22125=0\u22122 . In fact we can show that one can make all subtractions, provided we define a whole set of new numbers: 0\u22121 , 0\u22122 , 0\u22123 , 0\u22124 , and so on, called the negative integers. Then we may use all the other rules, like a(b+c)=ab+ac and so forth, to find what the rules are for multiplying negative numbers, and we will discover, in fact, that all of the rules can be maintained with negative as well as positive integers. So we have increased the range of objects over which the rules work, but the meaning of the symbols is different. One cannot say, for instance, that \u22122 times 5 really means to add 5 together successively \u22122 times. That means nothing. But nevertheless everything will work out all right according to the rules. An interesting problem comes up in taking powers. Suppose that we wish to discover what a(3\u22125) means. We know only that 3\u22125 is a solution of the problem, (3\u22125)+5=3 . Knowing that, we know that a(3\u22125)a5=a3 . Therefore a(3\u22125)=a3/a5 , by the definition of division. With a little more work, this can be reduced to 1/a2 . So we find that the negative powers are the reciprocals of the positive powers, but 1/a2 is a meaningless symbol, because if a is a positive or negative integer, the square of it can be greater than 1 , and we do not yet know what we mean by 1 divided by a number greater than 1 ! Onward! The great plan is to continue the process of generalization; whenever we find another problem that we cannot solve we extend our realm of numbers. Consider division: we cannot find a number which is an integer, even a negative integer, which is equal to the result of dividing 3 by 5 . But if we suppose that all fractional numbers also satisfy the rules, then we can talk about multiplying and adding fractions, and everything works as well as it did before. Take another example of powers: what is a3/5 ? We know only that (3/5)5=3 , since that was the definition of 3/5 . So we know also that (a(3/5))5= a(3/5)(5)= a3 , because this is one of the rules. Then by the definition of roots we find that a(3/5)=5 \u221a a3 . In this way, then, we can define what we mean by putting fractions in the various symbols, by using the rules themselves to help us determine the definition\u2014it is not arbitrary. It is a remarkable fact that all the rules still work for positive and negative integers, as well as for fractions! We go on in the process of generalization. Are there any other equations we cannot solve? Yes, there are. For example, it is impossible to solve this equation: b= 21/2= \u221a 2 . It is impossible to find a number which is rational (a fraction) whose square is equal to 2 . It is very easy for us in modern days to answer this question. We know the decimal system, and so we have no difficulty in appreciating the meaning of an unending decimal as a type of approximation to the square root of 2 . Historically, this idea presented great difficulty to the Greeks. To really define precisely what is meant here requires that we add some substance of continuity and ordering, and it is, in fact, quite the most difficult step in the processes of generalization just at this point. It was made, formally and rigorously, by Dedekind. However, without worrying about the mathematical rigor of the thing, it is quite easy to understand that what we mean is that we are going to find a whole sequence of approximate fractions, perfect fractions (because any decimal, when stopped somewhere, is of course rational), which just keeps on going, getting closer and closer to the desired result. That is good enough for what we wish to discuss, and it permits us to involve ourselves in irrational numbers, and to calculate things like the square root of 2 to any accuracy that we desire, with enough work. The next problem comes with what happens with the irrational powers. Suppose that we want to define, for instance, 10 \u221a 2 . In principle, the answer is simple enough. If we approximate the square root of 2 to a certain number of decimal places, then the power is rational, and we can take the approximate root, using the above method, and get an approximation to 10 \u221a 2 . Then we may run it up a few more decimal places (it is again rational), take the appropriate root, this time a much higher root because there is a much bigger denominator in the fraction, and get a better approximation. Of course we are going to get some enormously high roots involved here, and the work is quite difficult. How can we cope with this problem? In the computations of square roots, cube roots, and other small roots, there is an arithmetical process available by which we can get one decimal place after another. But the amount of labor needed to calculate irrational powers and the logarithms that go with them (the inverse problem) is so great that there is no simple arithmetical process we can use. Therefore tables have been built up which permit us to calculate these powers, and these are called the tables of logarithms, or the tables of powers, depending on which way the table is set up. It is merely a question of saving time; if we must raise some number to an irrational power, we can look it up rather than having to compute it. Of course, such a computation is just a technical problem, but it is an interesting one, and of great historical value. In the first place, not only do we have the problem of solving x=10 \u221a 2 , but we also have the problem of solving 10x=2 , or x=log102 . This is not a problem where we have to define a new kind of number for the result, it is merely a computational problem. The answer is simply an irrational number, an unending decimal, not a new kind of a number. Let us now discuss the problem of calculating solutions of such equations. The general idea is really very simple. If we could calculate 10 1 , and 10 4/10 , and 10 1/100 , and 10 4/1000 and so on, and multiply them all together, we would get 10 1.414\u2026 or 10 2 \u221a , and that is the general idea on which things work. But instead of calculating 10 1/10 and so on, we shall calculate 10 1/2 , 10 1/4 , and so on. Before we start, we should explain why we make so much work with 10 , instead of some other number. Of course, we realize that logarithm tables are of great practical utility, quite aside from the mathematical problem of taking roots, since with any base at all, log b (ac)= log b a+ log b c. (22.3) We are all familiar with the fact that one can use this fact in a practical way to multiply numbers if we have a table of logarithms. The only question is, with what base b shall we compute? It makes no difference what base is used; we can use the same principle all the time, and if we are using logarithms to any particular base, we can find logarithms to any other base merely by a change in scale, a multiplying factor. If we multiply Eq. (22.3) by 61 , it is just as true, and if we had a table of logs with a base b , and somebody else multiplied all of our table by 61 , there would be no essential difference. Suppose that we know the logarithms of all the numbers to the base b . In other words, we can solve the equation b a =c for any c because we have a table. The problem is to find the logarithm of the same number c to some other base, let us say the base x . We would like to solve x a \u2032 =c . It is easy to do, because we can always write x= b t , which defines t , knowing x and b . As a matter of fact, t= log b x . Then if we put that in and solve for a \u2032 , we see that ( b t ) a \u2032 = b a \u2032 t =c . In other words, t a \u2032 is the logarithm of c in base b . Thus a \u2032 =a/t . Thus logs to base x are just 1/t , which is a constant, times the logs to the base, b . Therefore any log table is equivalent to any other log table if we multiply by a constant, and the constant is 1/ log b x . This permits us to choose a particular base, and for convenience we take the base 10 . (The question may arise as to whether there is any natural base, any base in which things are somehow simpler, and we shall try to find an answer to that later. At the moment we shall just use the base 10 .) Now let us see how to calculate logarithms. We begin by computing successive square roots of 10 , by cut and try. The results are shown in Table 22\u20131. The powers of 10 are given in the first column, and the result, 10 s , is given in the third column. Thus 10 1 =10 . The one-half power of 10 we can easily work out, because that is the square root of 10 , and there is a known, simple process for taking square roots of any number.1 Using this process, we find the first square root to be 3.16228 . What good is that? It already tells us something, it tells us how to take 10 0.5 , so we now know at least one logarithm, if we happen to need the logarithm of 3.16228 , we know the answer is close to 0.50000 . But we must do a little bit better than that; we clearly need more information. So we take the square root again, and find 10 1/4 , which is 1.77828 . Now we have the logarithm of more numbers than we had before, 1.250 is the logarithm of 17.78 and, incidentally, if it happens that somebody asks for 10 0.75 , we can get it, because that is 10 (0.5+0.25) ; it is therefore the product of the second and third numbers. If we can get enough numbers in column s to be able to make up almost any number, then by multiplying the proper things in column 3, we can get 10 to any power; that is the plan. So we evaluate ten successive square roots of 10 , and that is the main work which is involved in the calculations. Why don\u2019t we keep on going for more and more accuracy? Because we begin to notice something. When we raise 10 to a very small power, we get 1 plus a small amount. The reason for this is clear, because we are going to have to take the 1000 th power of 10 1/1000 to get back to 10 , so we had better not start with too big a number; it has to be close to 1 . What we notice is that the small numbers that are added to 1 begin to look as though we are merely dividing by 2 each time; we see 1815 becomes 903 , then 450 , 225 ; so it is clear that, to an excellent approximation, if we take another root, we shall get 1.00112 something, and rather than actually take all the square roots, we guess at the ultimate limit. When we take a small fraction \u0394/1024 as \u0394 approaches zero, what will the answer be? Of course it will be some number close to 1+0.0022511\u0394 . Not exactly 1+0.0022511\u0394 , however\u2014we can get a better value by the following trick: we subtract the 1 , and then divide by the power s . This ought to correct all the excesses to the same value. We see that they are very closely equal. At the top of the table they are not equal, but as they come down, they get closer and closer to a constant value. What is the value? Again we look to see how the series is going, how it has changed with s . It changed by 211 , by 104 , by 53 , by 26 . These changes are obviously half of each other, very closely, as we go down. Therefore, if we kept going, the changes would be 13 , 7 , 3 , 2 and 1 , more or less, or a total of 26 . Thus we have only 26 more to go, and so we find that the true number is 2.3025 . (Actually, we shall later see that the exact number should be 2.3026 , but to keep it realistic, we shall not alter anything in the arithmetic.) From this table we can now calculate any power of 10 , by compounding the power out of 1024 ths. Let us now actually calculate a logarithm, because the process we shall use is where logarithm tables actually come from. The procedure is shown in Table 22\u20132, and the numerical values are shown in Table 22\u20131 (columns 2 and 3). Suppose we want the logarithm of 2 . That is, we want to know to what power we must raise 10 to get 2 . Can we raise 10 to the 1/2 power? No; that is too big. In other words, we can see that the answer is going to be bigger than 1/4 , and less than 1/2 . Let us take the factor 10 1/4 out; we divide 2 by 1.778\u2026 , and get 1.124\u2026 , and so on, and now we know that we have taken away 0.250000 from the logarithm. The number 1.124\u2026 , is now the number whose logarithm we need. When we are finished we shall add back the 1/4 , or 256/1024 . Now we look in the table for the next number just below 1.124\u2026 , and that is 1.074607 . We therefore divide by 1.074607 and get 1.046598 . From that we discover that 2 can be made up of a product of numbers that are in Table 22\u20131, as follows: 2=(1.77828)(1.074607)(1.036633)\u00d7 (1.0090350)(1.000573). There was one factor (1.000573) left over, naturally, which is beyond the range of our table. To get the logarithm of this factor, we use our result that 10 \u0394/1024 \u22481+2.3025\u0394/1024 . We find \u0394=0.254 . Therefore our answer is 10 to the following power: (256+32+16+4+0.254)/1024 . Adding those together, we get 308.254/1024 . Dividing, we get 0.30103 , so we know that the log 10 2=0.30103 , which happens to be right to 5 figures! This is how logarithms were originally computed by Mr. Briggs of Halifax, in 1620. He said, \u201cI computed successively 54 square roots of 10 .\u201d We know he really computed only the first 27 , because the rest of them can be obtained by this trick with \u0394 . His work involved calculating the square root of 10 twenty-seven times, which is not much more than the ten times we did; however, it was more work because he calculated to sixteen decimal places, and then reduced his answer to fourteen when he published it, so that there were no rounding errors. He made tables of logarithms to fourteen decimal places by this method, which is quite tedious. But all logarithm tables for three hundred years were borrowed from Mr. Briggs\u2019 tables by reducing the number of decimal places. Only in modern times, with the WPA and computing machines, have new tables been independently computed. There are much more efficient methods of computing logarithms today, using certain series expansions. In the above process, we discovered something rather interesting, and that is that for very small powers \u03f5 we can calculate 10 \u03f5 easily; we have discovered that 10 \u03f5 =1+2.3025\u03f5 , by sheer numerical analysis. Of course this also means that 10 n/2.3025 =1+n if n is very small. Now logarithms to any other base are merely multiples of logarithms to the base 10 . The base 10 was used only because we have 10 fingers, and the arithmetic of it is easy, but if we ask for a mathematically natural base, one that has nothing to do with the number of fingers on human beings, we might try to change our scale of logarithms in some convenient and natural manner, and the method which people have chosen is to redefine the logarithms by multiplying all the logarithms to the base 10 by 2.3025\u2026 This then corresponds to using some other base, and this is called the natural base, or base e . Note that log e (1+n)\u2248n , or e n \u22481+n as n\u21920 . It is easy enough to find out what e is: e= 10 1/2.3025\u2026 or 10 0.434310\u2026 , an irrational power. Our table of the successive square roots of 10 can be used to compute, not just logarithms, but also 10 to any power, so let us use it to calculate this natural base e . For convenience we transform 0.434310\u2026 into 444.73/1024 . Now, 444.73 is 256+128+32+16+8+4+0.73 . Therefore e , since it is an exponent of a sum, will be a product of the numbers (1. 77828)(1.33352)(1.074607)(1.036633)\u00d7 (1.018152)(1.009035)(1.001643)=2.7184. (The only problem is the last one, which is 0.73 , and which is not in the table, but we know that if \u0394 is small enough, the answer is 1+0.0022486\u0394 .) When we multiply all these together, we get 2.7184 (it should be 2.7183 , but it is good enough). The use of such tables, then, is the way in which irrational powers and the logarithms of irrational numbers are all calculated. That takes care of the irrationals. Now it turns out that after all that work we still cannot solve every equation! For instance, what is the square root of \u22121 ? Suppose we have to find x 2 =\u22121 . The square of no rational, of no irrational, of nothing that we have discovered so far, is equal to \u22121 . So we again have to generalize our numbers to a still wider class. Let us suppose that a specific solution of x 2 =\u22121 is called something, we shall call it i ; i has the property, by definition, that its square is \u22121 . That is about all we are going to say about it; of course, there is more than one root of the equation x 2 =\u22121 . Someone could write i , but another could say, \u201cNo, I prefer \u2212i . My i is minus your i .\u201d It is just as good a solution, and since the only definition that i has is that i 2 =\u22121 , it must be true that any equation we can write is equally true if the sign of i is changed everywhere. This is called taking the complex conjugate. Now we are going to make up numbers by adding successive i \u2019s, and multiplying i \u2019s by numbers, and adding other numbers, and so on, according to all of our rules. In this way we find that numbers can all be written in the form p+iq , where p and q are what we call real numbers, i.e., the numbers we have been defining up until now. The number i is called the unit imaginary number. Any real multiple of i is called pure imaginary. The most general number, a , is of the form p+iq and is called a complex number. Things do not get any worse if, for instance, we multiply two such numbers, let us say (r+is)(p+iq) . Then, using the rules, we get (r+is)(p+iq) =rp+r(iq)+(is)p+(is)(iq) =rp+i(rq)+i(sp)+(ii)(sq) =(rp\u2212sq)+i(rq+sp), (22.4) since ii= i 2 = \u22121 . Therefore all the numbers that now belong in the rules (22.1) have this mathematical form. Now you say, \u201cThis can go on forever! We have defined powers of imaginaries and all the rest, and when we are all finished, somebody else will come along with another equation which cannot be solved, like x 6 +3 x 2 =\u22122 . Then we have to generalize all over again!\u201d But it turns out that with this one more invention, just the square root of \u22121 , every algebraic equation can be solved! This is a fantastic fact, which we must leave to the Mathematics Department to prove. The proofs are very beautiful and very interesting, but certainly not self-evident. In fact, the most obvious supposition is that we are going to have to invent again and again and again. But the greatest miracle of all is that we do not. This is the last invention. After this invention of complex numbers, we find that the rules still work with complex numbers, and we are finished inventing new things. We can find the complex power of any complex number, we can solve any equation that is written algebraically, in terms of a finite number of those symbols. We do not find any new numbers. The square root of i , for instance, has a definite result, it is not something new; and i i is something. We will discuss that now. We have already discussed multiplication, and addition is also easy; if we add two complex numbers, (p+iq)+(r+is) , the answer is (p+r)+i(q+s) . Now we can add and multiply complex numbers. But the real problem, of course, is to compute complex powers of complex numbers. It turns out that the problem is actually no more difficult than computing complex powers of real numbers. So let us concentrate now on the problem of calculating 10 to a complex power, not just an irrational power, but 10 (r+is) . Of course, we must at all times use our rules (22.1) and (22.2). Thus 10 (r+is) = 10 r 10 is . (22.5) But 10 r we already know how to compute, and we can always multiply anything by anything else; therefore the problem is to compute only 10 is . Let us call it some complex number, x+iy . Problem: given s , find x , find y . Now if 10 is =x+iy, i then the complex conjugate of this equation must also be true, so that 10 \u2212is =x\u2212iy. i (Thus we see that we can deduce a number of things without actually computing anything, by using our rules.) We deduce another interesting thing by multiplying these together: 10 is 10 \u2212is = 10 0 =1 =(x+iy)(x\u2212iy)= x 2 + y 2 . (22.6) Thus if we find x , we have y also. Now the problem is how to compute 10 to an imaginary power. What guide is there? We may work over our rules until we can go no further, but here is a reasonable guide: if we can compute it for any particular s , we can get it for all the rest. If we know 10 is for any one s and then we want it for twice that s , we can square the number, and so on. But how can we find 10 is for even one special value of s ? To do so we shall make one additional assumption, which is not quite in the category of all the other rules, but which leads to reasonable results and permits us to make progress: when the power is small, we shall suppose that the \u201claw\u201d 10 \u03f5 =1+2.3025\u03f5 is right, as \u03f5 gets very small, not only for real \u03f5 , but for complex \u03f5 as well. Therefore, we begin with the supposition that this law is true in general, and that tells us that 10 is =1+2.3025\u22c5is , for s\u21920 . So we assume that if s is very small, say one part in 1024 , we have a rather good approximation to 10 is . Now we make a table by which we can compute all the imaginary powers of 10 , that is, compute x and y . It is done as follows. The first power we start with is the 1/1024 power, which we presume is very nearly 1+2.3025i/1024 . Thus we start with 10 i/1024 =1.00000+0.0022486i, (22.7) and if we keep multiplying the number by itself, we can get to a higher imaginary power. In fact, we may just reverse the procedure we used in making our logarithm table, and calculate the square, 4 th power, 8 th power, etc., of (22.7), and thus build up the values shown in Table 22\u20133. We notice an interesting thing, that the x numbers are positive at first, but then swing negative. We shall look into that a little bit more in a moment. But first we may be curious to find for what number s the real part of 10 is is zero. The y -value would be 1 , and so we would have 10 is =1i , or is= log 10 i . As an example of how to use this table, just as we calculated log 10 2 before, let us now use Table 22\u20133 to find log 10 i . Which of the numbers in Table 22\u20133 do we have to multiply together to get a pure imaginary result? After a little trial and error, we discover that to reduce x the most, it is best to multiply \u201c 512 \u201d by \u201c 128 .\u201d This gives 0.13056+0.99159i . Then we discover that we should multiply this by a number whose imaginary part is about equal to the size of the real part we are trying to remove. Thus we choose \u201c 64 \u201d whose y -value is 0.14349 , since that is closest to 0.13056 . This then gives \u22120.01308+1.00008i . Now we have overshot, and must divide by 0.99996+0.00900i . How do we do that? By changing the sign of i and multiplying by 0.99996\u22120.00900i (which works if x 2 + y 2 =1 ). Continuing in this way, we find that the entire power to which 10 must be raised to give i is i(512+128+64\u22124\u22122+0.20)/1024 , or 698.20i/1024 . If we raise 10 to that power, we can get i . Therefore log 10 i=0.68184i . To further investigate the subject of taking complex imaginary powers, let us look at the powers of 10 taking successive powers, not doubling the power each time, in order to follow Table 22\u20133 further and to see what happens to those minus signs. This is shown in Table 22\u20134, in which we take 10 i/8 , and just keep multiplying it. We see that x decreases, passes through zero, swings almost to \u22121 (if we could get in between p=10 and p=11 it would obviously swing to \u22121 ), and swings back. The y -value is going back and forth too. In Fig. 22\u20131 the dots represent the numbers that appear in Table 22\u20134, and the lines are just drawn to help you visually. So we see that the numbers x and y oscillate; 10 is repeats itself, it is a periodic thing, and as such, it is easy enough to explain, because if a certain power is i , then the fourth power of that would be i 2 squared. It would be +1 again, and therefore, since 10 0.68i is equal to i , by taking the fourth power we discover that 10 2.72i is equal to +1 . Therefore, if we wanted 10 3.00i , for instance, we could write it as 10 2.72i times 10 0.28i . In other words, it has a period, it repeats. Of course, we recognize what the curves look like! They look like the sine and cosine, and we shall call them, for a while, the algebraic sine and algebraic cosine. However, instead of using the base 10 , we shall put them into our natural base, which only changes the horizontal scale; so we denote 2.3025s by t , and write 10 is = e it , where t is a real number. Now e it =x+iy , and we shall write this as the algebraic cosine of t plus i times the algebraic sine of t . Thus e it = cos \u2212 \u2212 \u2212 t+i sin \u2212 \u2212 \u2212 t. (22.8) What are the properties of cos \u2212 \u2212 \u2212 t and sin \u2212 \u2212 \u2212 t ? First, we know, for instance, that x 2 + y 2 must be 1 ; we have proved that before, and it is just as true for base e as for base 10 . Therefore cos \u2212 \u2212 \u2212 2 t+ sin \u2212 \u2212 \u2212 2 t=1 . We also know that, for small t , e it =1+it , and therefore cos \u2212 \u2212 \u2212 t is nearly 1 , and sin \u2212 \u2212 \u2212 t is nearly t , and so it goes, that all of the various properties of these remarkable functions, which come from taking imaginary powers, are the same as the sine and cosine of trigonometry. Is the period the same? Let us find out. e to what power is equal to i ? What is the logarithm of i to the base e ? We worked it out before, in the base 10 it was 0.68184i , but when we change our logarithmic scale to e , we have to multiply by 2.3025 , and if we do that it comes out 1.570 . So this will be called \u201calgebraic \u03c0/2 .\u201d But, we see, it differs from the regular \u03c0/2 by only one place in the last point, and that, of course, is the result of errors in our arithmetic! So we have created two new functions in a purely algebraic manner, the cosine and the sine, which belong to algebra, and only to algebra. We wake up at the end to discover the very functions that are natural to geometry. So there is a connection, ultimately, between algebra and geometry. We summarize with this, the most remarkable formula in mathematics: e i\u03b8 =cos\u03b8+isin\u03b8. (22.9) This is our jewel. We may relate the geometry to the algebra by representing complex numbers in a plane; the horizontal position of a point is x , the vertical position of a point is y (Fig. 22\u20132). We represent every complex number, x+iy . Then if the radial distance to this point is called r and the angle is called \u03b8 , the algebraic law is that x+iy is written in the form r e i\u03b8 , where the geometrical relationships between x , y , r , and \u03b8 are as shown. This, then, is the unification of algebra and geometry. When we began this chapter, armed only with the basic notions of integers and counting, we had little idea of the power of the processes of abstraction and generalization. Using the set of algebraic \u201claws,\u201d or properties of numbers, Eq. (22.1), and the definitions of inverse operations (22.2), we have been able here, ourselves, to manufacture not only numbers but useful things like tables of logarithms, powers, and trigonometric functions (for these are what the imaginary powers of real numbers are), all merely by extracting ten successive square roots of ten!"
    },
    {
        "input": "The Relation of Physics to Other Sciences",
        "output": "Physics is the most fundamental and all-inclusive of the sciences, and has had a profound effect on all scientific development. In fact, physics is the present-day equivalent of what used to be called natural philosophy, from which most of our modern sciences arose. Students of many fields find themselves studying physics because of the basic role it plays in all phenomena. In this chapter we shall try to explain what the fundamental problems in the other sciences are, but of course it is impossible in so small a space really to deal with the complex, subtle, beautiful matters in these other fields. Lack of space also prevents our discussing the relation of physics to engineering, industry, society, and war, or even the most remarkable relationship between mathematics and physics. (Mathematics is not a science from our point of view, in the sense that it is not a natural science. The test of its validity is not experiment.) We must, incidentally, make it clear from the beginning that if a thing is not a science, it is not necessarily bad. For example, love is not a science. So, if something is said not to be a science, it does not mean that there is something wrong with it; it just means that it is not a science. The science which is perhaps the most deeply affected by physics is chemistry. Historically, the early days of chemistry dealt almost entirely with what we now call inorganic chemistry, the chemistry of substances which are not associated with living things. Considerable analysis was required to discover the existence of the many elements and their relationships\u2014how they make the various relatively simple compounds found in rocks, earth, etc. This early chemistry was very important for physics. The interaction between the two sciences was very great because the theory of atoms was substantiated to a large extent by experiments in chemistry. The theory of chemistry, i.e., of the reactions themselves, was summarized to a large extent in the periodic chart of Mendeleev, which brings out many strange relationships among the various elements, and it was the collection of rules as to which substance is combined with which, and how, that constituted inorganic chemistry. All these rules were ultimately explained in principle by quantum mechanics, so that theoretical chemistry is in fact physics. On the other hand, it must be emphasized that this explanation is in principle. We have already discussed the difference between knowing the rules of the game of chess, and being able to play. So it is that we may know the rules, but we cannot play very well. It turns out to be very difficult to predict precisely what will happen in a given chemical reaction; nevertheless, the deepest part of theoretical chemistry must end up in quantum mechanics. There is also a branch of physics and chemistry which was developed by both sciences together, and which is extremely important. This is the method of statistics applied in a situation in which there are mechanical laws, which is aptly called statistical mechanics. In any chemical situation a large number of atoms are involved, and we have seen that the atoms are all jiggling around in a very random and complicated way. If we could analyze each collision, and be able to follow in detail the motion of each molecule, we might hope to figure out what would happen, but the many numbers needed to keep track of all these molecules exceeds so enormously the capacity of any computer, and certainly the capacity of the mind, that it was important to develop a method for dealing with such complicated situations. Statistical mechanics, then, is the science of the phenomena of heat, or thermodynamics. Inorganic chemistry is, as a science, now reduced essentially to what are called physical chemistry and quantum chemistry; physical chemistry to study the rates at which reactions occur and what is happening in detail (How do the molecules hit? Which pieces fly off first?, etc.), and quantum chemistry to help us understand what happens in terms of the physical laws. The other branch of chemistry is organic chemistry, the chemistry of the substances which are associated with living things. For a time it was believed that the substances which are associated with living things were so marvelous that they could not be made by hand, from inorganic materials. This is not at all true\u2014they are just the same as the substances made in inorganic chemistry, but more complicated arrangements of atoms are involved. Organic chemistry obviously has a very close relationship to the biology which supplies its substances, and to industry, and furthermore, much physical chemistry and quantum mechanics can be applied to organic as well as to inorganic compounds. However, the main problems of organic chemistry are not in these aspects, but rather in the analysis and synthesis of the substances which are formed in biological systems, in living things. This leads imperceptibly, in steps, toward biochemistry, and then into biology itself, or molecular biology. Thus we come to the science of biology, which is the study of living things. In the early days of biology, the biologists had to deal with the purely descriptive problem of finding out what living things there were, and so they just had to count such things as the hairs of the limbs of fleas. After these matters were worked out with a great deal of interest, the biologists went into the machinery inside the living bodies, first from a gross standpoint, naturally, because it takes some effort to get into the finer details. There was an interesting early relationship between physics and biology in which biology helped physics in the discovery of the conservation of energy, which was first demonstrated by Mayer in connection with the amount of heat taken in and given out by a living creature. If we look at the processes of biology of living animals more closely, we see many physical phenomena: the circulation of blood, pumps, pressure, etc. There are nerves: we know what is happening when we step on a sharp stone, and that somehow or other the information goes from the leg up. It is interesting how that happens. In their study of nerves, the biologists have come to the conclusion that nerves are very fine tubes with a complex wall which is very thin; through this wall the cell pumps ions, so that there are positive ions on the outside and negative ions on the inside, like a capacitor. Now this membrane has an interesting property; if it \u201cdischarges\u201d in one place, i.e., if some of the ions were able to move through one place, so that the electric voltage is reduced there, that electrical influence makes itself felt on the ions in the neighborhood, and it affects the membrane in such a way that it lets the ions through at neighboring points also. This in turn affects it farther along, etc., and so there is a wave of \u201cpenetrability\u201d of the membrane which runs down the fiber when it is \u201cexcited\u201d at one end by stepping on the sharp stone. This wave is somewhat analogous to a long sequence of vertical dominoes; if the end one is pushed over, that one pushes the next, etc. Of course this will transmit only one message unless the dominoes are set up again; and similarly in the nerve cell, there are processes which pump the ions slowly out again, to get the nerve ready for the next impulse. So it is that we know what we are doing (or at least where we are). Of course the electrical effects associated with this nerve impulse can be picked up with electrical instruments, and because there are electrical effects, obviously the physics of electrical effects has had a great deal of influence on understanding the phenomenon. The opposite effect is that, from somewhere in the brain, a message is sent out along a nerve. What happens at the end of the nerve? There the nerve branches out into fine little things, connected to a structure near a muscle, called an endplate. For reasons which are not exactly understood, when the impulse reaches the end of the nerve, little packets of a chemical called acetylcholine are shot off (five or ten molecules at a time) and they affect the muscle fiber and make it contract\u2014how simple! What makes a muscle contract? A muscle is a very large number of fibers close together, containing two different substances, myosin and actomyosin, but the machinery by which the chemical reaction induced by acetylcholine can modify the dimensions of the muscle is not yet known. Thus the fundamental processes in the muscle that make mechanical motions are not known. Biology is such an enormously wide field that there are hosts of other problems that we cannot mention at all\u2014problems on how vision works (what the light does in the eye), how hearing works, etc. (The way in which thinking works we shall discuss later under psychology.) Now, these things concerning biology which we have just discussed are, from a biological standpoint, really not fundamental, at the bottom of life, in the sense that even if we understood them we still would not understand life itself. To illustrate: the men who study nerves feel their work is very important, because after all you cannot have animals without nerves. But you can have life without nerves. Plants have neither nerves nor muscles, but they are working, they are alive, just the same. So for the fundamental problems of biology we must look deeper; when we do, we discover that all living things have a great many characteristics in common. The most common feature is that they are made of cells, within each of which is complex machinery for doing things chemically. In plant cells, for example, there is machinery for picking up light and generating glucose, which is consumed in the dark to keep the plant alive. When the plant is eaten the glucose itself generates in the animal a series of chemical reactions very closely related to photosynthesis (and its opposite effect in the dark) in plants. In the cells of living systems there are many elaborate chemical reactions, in which one compound is changed into another and another. To give some impression of the enormous efforts that have gone into the study of biochemistry, the chart in Fig. 3\u20131 summarizes our knowledge to date on just one small part of the many series of reactions which occur in cells, perhaps a percent or so of it. Here we see a whole series of molecules which change from one to another in a sequence or cycle of rather small steps. It is called the Krebs cycle, the respiratory cycle. Each of the chemicals and each of the steps is fairly simple, in terms of what change is made in the molecule, but\u2014and this is a centrally important discovery in biochemistry\u2014these changes are relatively difficult to accomplish in a laboratory. If we have one substance and another very similar substance, the one does not just turn into the other, because the two forms are usually separated by an energy barrier or \u201chill.\u201d Consider this analogy: If we wanted to take an object from one place to another, at the same level but on the other side of a hill, we could push it over the top, but to do so requires the addition of some energy. Thus most chemical reactions do not occur, because there is what is called an activation energy in the way. In order to add an extra atom to our chemical requires that we get it close enough that some rearrangement can occur; then it will stick. But if we cannot give it enough energy to get it close enough, it will not go to completion, it will just go part way up the \u201chill\u201d and back down again. However, if we could literally take the molecules in our hands and push and pull the atoms around in such a way as to open a hole to let the new atom in, and then let it snap back, we would have found another way, around the hill, which would not require extra energy, and the reaction would go easily. Now there actually are, in the cells, very large molecules, much larger than the ones whose changes we have been describing, which in some complicated way hold the smaller molecules just right, so that the reaction can occur easily. These very large and complicated things are called enzymes. (They were first called ferments, because they were originally discovered in the fermentation of sugar. In fact, some of the first reactions in the cycle were discovered there.) In the presence of an enzyme the reaction will go. An enzyme is made of another substance called protein. Enzymes are very big and complicated, and each one is different, each being built to control a certain special reaction. The names of the enzymes are written in Fig. 3\u20131 at each reaction. (Sometimes the same enzyme may control two reactions.) We emphasize that the enzymes themselves are not involved in the reaction directly. They do not change; they merely let an atom go from one place to another. Having done so, the enzyme is ready to do it to the next molecule, like a machine in a factory. Of course, there must be a supply of certain atoms and a way of disposing of other atoms. Take hydrogen, for example: there are enzymes which have special units on them which carry the hydrogen for all chemical reactions. For example, there are three or four hydrogen-reducing enzymes which are used all over our cycle in different places. It is interesting that the machinery which liberates some hydrogen at one place will take that hydrogen and use it somewhere else. The most important feature of the cycle of Fig. 3\u20131 is the transformation from GDP to GTP (guanosine-di-phosphate to guanosine-tri-phosphate) because the one substance has much more energy in it than the other. Just as there is a \u201cbox\u201d in certain enzymes for carrying hydrogen atoms around, there are special energy-carrying \u201cboxes\u201d which involve the triphosphate group. So, GTP has more energy than GDP and if the cycle is going one way, we are producing molecules which have extra energy and which can go drive some other cycle which requires energy, for example the contraction of muscle. The muscle will not contract unless there is GTP. We can take muscle fiber, put it in water, and add GTP, and the fibers contract, changing GTP to GDP if the right enzymes are present. So the real system is in the GDP-GTP transformation; in the dark the GTP which has been stored up during the day is used to run the whole cycle around the other way. An enzyme, you see, does not care in which direction the reaction goes, for if it did it would violate one of the laws of physics. Physics is of great importance in biology and other sciences for still another reason, that has to do with experimental techniques. In fact, if it were not for the great development of experimental physics, these biochemistry charts would not be known today. The reason is that the most useful tool of all for analyzing this fantastically complex system is to label the atoms which are used in the reactions. Thus, if we could introduce into the cycle some carbon dioxide which has a \u201cgreen mark\u201d on it, and then measure after three seconds where the green mark is, and again measure after ten seconds, etc., we could trace out the course of the reactions. What are the \u201cgreen marks\u201d? They are different isotopes. We recall that the chemical properties of atoms are determined by the number of electrons, not by the mass of the nucleus. But there can be, for example in carbon, six neutrons or seven neutrons, together with the six protons which all carbon nuclei have. Chemically, the two atoms C12 and C13 are the same, but they differ in weight and they have different nuclear properties, and so they are distinguishable. By using these isotopes of different weights, or even radioactive isotopes like C14 , which provide a more sensitive means for tracing very small quantities, it is possible to trace the reactions. Now, we return to the description of enzymes and proteins. Not all proteins are enzymes, but all enzymes are proteins. There are many proteins, such as the proteins in muscle, the structural proteins which are, for example, in cartilage and hair, skin, etc., that are not themselves enzymes. However, proteins are a very characteristic substance of life: first of all they make up all the enzymes, and second, they make up much of the rest of living material. Proteins have a very interesting and simple structure. They are a series, or chain, of different amino acids. There are twenty different amino acids, and they all can combine with each other to form chains in which the backbone is CO-NH, etc. Proteins are nothing but chains of various ones of these twenty amino acids. Each of the amino acids probably serves some special purpose. Some, for example, have a sulfur atom at a certain place; when two sulfur atoms are in the same protein, they form a bond, that is, they tie the chain together at two points and form a loop. Another has extra oxygen atoms which make it an acidic substance, another has a basic characteristic. Some of them have big groups hanging out to one side, so that they take up a lot of space. One of the amino acids, called proline, is not really an amino acid, but imino acid. There is a slight difference, with the result that when proline is in the chain, there is a kink in the chain. If we wished to manufacture a particular protein, we would give these instructions: put one of those sulfur hooks here; next, add something to take up space; then attach something to put a kink in the chain. In this way, we will get a complicated-looking chain, hooked together and having some complex structure; this is presumably just the manner in which all the various enzymes are made. One of the great triumphs in recent times (since 1960), was at last to discover the exact spatial atomic arrangement of certain proteins, which involve some fifty-six or sixty amino acids in a row. Over a thousand atoms (more nearly two thousand, if we count the hydrogen atoms) have been located in a complex pattern in two proteins. The first was hemoglobin. One of the sad aspects of this discovery is that we cannot see anything from the pattern; we do not understand why it works the way it does. Of course, that is the next problem to be attacked. Another problem is how do the enzymes know what to be? A red-eyed fly makes a red-eyed fly baby, and so the information for the whole pattern of enzymes to make red pigment must be passed from one fly to the next. This is done by a substance in the nucleus of the cell, not a protein, called DNA (short for desoxyribose nucleic acid). This is the key substance which is passed from one cell to another (for instance sperm cells consist mostly of DNA) and carries the information as to how to make the enzymes. DNA is the \u201cblueprint.\u201d What does the blueprint look like and how does it work? First, the blueprint must be able to reproduce itself. Secondly, it must be able to instruct the protein. Concerning the reproduction, we might think that this proceeds like cell reproduction. Cells simply grow bigger and then divide in half. Must it be thus with DNA molecules, then, that they too grow bigger and divide in half? Every atom certainly does not grow bigger and divide in half! No, it is impossible to reproduce a molecule except by some more clever way. The structure of the substance DNA was studied for a long time, first chemically to find the composition, and then with x-rays to find the pattern in space. The result was the following remarkable discovery: The DNA molecule is a pair of chains, twisted upon each other. The backbone of each of these chains, which are analogous to the chains of proteins but chemically quite different, is a series of sugar and phosphate groups, as shown in Fig. 3\u20132. Now we see how the chain can contain instructions, for if we could split this chain down the middle, we would have a series BAADC\u2026 and every living thing could have a different series. Thus perhaps, in some way, the specific instructions for the manufacture of proteins are contained in the specific series of the DNA. Attached to each sugar along the line, and linking the two chains together, are certain pairs of cross-links. However, they are not all of the same kind; there are four kinds, called adenine, thymine, cytosine, and guanine, but let us call them A , B , C , and D . The interesting thing is that only certain pairs can sit opposite each other, for example A with B and C with D . These pairs are put on the two chains in such a way that they \u201cfit together,\u201d and have a strong energy of interaction. However, C will not fit with A , and B will not fit with C ; they will only fit in pairs, A against B and C against D . Therefore if one is C , the other must be D , etc. Whatever the letters may be in one chain, each one must have its specific complementary letter on the other chain. What then about reproduction? Suppose we split this chain in two. How can we make another one just like it? If, in the substances of the cells, there is a manufacturing department which brings up phosphate, sugar, and A , B , C , D units not connected in a chain, the only ones which will attach to our split chain will be the correct ones, the complements of BAADC\u2026 , namely, ABBCD\u2026 Thus what happens is that the chain splits down the middle during cell division, one half ultimately to go with one cell, the other half to end up in the other cell; when separated, a new complementary chain is made by each half-chain. Next comes the question, precisely how does the order of the A , B , C , D units determine the arrangement of the amino acids in the protein? This is the central unsolved problem in biology today. The first clues, or pieces of information, however, are these: There are in the cell tiny particles called ribosomes, and it is now known that that is the place where proteins are made. But the ribosomes are not in the nucleus, where the DNA and its instructions are. Something seems to be the matter. However, it is also known that little molecule pieces come off the DNA\u2014not as long as the big DNA molecule that carries all the information itself, but like a small section of it. This is called RNA, but that is not essential. It is a kind of copy of the DNA, a short copy. The RNA, which somehow carries a message as to what kind of protein to make goes over to the ribosome; that is known. When it gets there, protein is synthesized at the ribosome. That is also known. However, the details of how the amino acids come in and are arranged in accordance with a code that is on the RNA are, as yet, still unknown. We do not know how to read it. If we knew, for example, the \u201clineup\u201d A , B , C , C , A , we could not tell you what protein is to be made. Certainly no subject or field is making more progress on so many fronts at the present moment, than biology, and if we were to name the most powerful assumption of all, which leads one on and on in an attempt to understand life, it is that all things are made of atoms, and that everything that living things do can be understood in terms of the jigglings and wigglings of atoms. In this rapid-fire explanation of the whole world, we must now turn to astronomy. Astronomy is older than physics. In fact, it got physics started by showing the beautiful simplicity of the motion of the stars and planets, the understanding of which was the beginning of physics. But the most remarkable discovery in all of astronomy is that the stars are made of atoms of the same kind as those on the earth.1 How was this done? Atoms liberate light which has definite frequencies, something like the timbre of a musical instrument, which has definite pitches or frequencies of sound. When we are listening to several different tones we can tell them apart, but when we look with our eyes at a mixture of colors we cannot tell the parts from which it was made, because the eye is nowhere near as discerning as the ear in this connection. However, with a spectroscope we can analyze the frequencies of the light waves and in this way we can see the very tunes of the atoms that are in the different stars. As a matter of fact, two of the chemical elements were discovered on a star before they were discovered on the earth. Helium was discovered on the sun, whence its name, and technetium was discovered in certain cool stars. This, of course, permits us to make headway in understanding the stars, because they are made of the same kinds of atoms which are on the earth. Now we know a great deal about the atoms, especially concerning their behavior under conditions of high temperature but not very great density, so that we can analyze by statistical mechanics the behavior of the stellar substance. Even though we cannot reproduce the conditions on the earth, using the basic physical laws we often can tell precisely, or very closely, what will happen. So it is that physics aids astronomy. Strange as it may seem, we understand the distribution of matter in the interior of the sun far better than we understand the interior of the earth. What goes on inside a star is better understood than one might guess from the difficulty of having to look at a little dot of light through a telescope, because we can calculate what the atoms in the stars should do in most circumstances. One of the most impressive discoveries was the origin of the energy of the stars, that makes them continue to burn. One of the men who discovered this was out with his girlfriend the night after he realized that nuclear reactions must be going on in the stars in order to make them shine. She said \u201cLook at how pretty the stars shine!\u201d He said \u201cYes, and right now I am the only man in the world who knows why they shine.\u201d She merely laughed at him. She was not impressed with being out with the only man who, at that moment, knew why stars shine. Well, it is sad to be alone, but that is the way it is in this world. It is the nuclear \u201cburning\u201d of hydrogen which supplies the energy of the sun; the hydrogen is converted into helium. Furthermore, ultimately, the manufacture of various chemical elements proceeds in the centers of the stars, from hydrogen. The stuff of which we are made, was \u201ccooked\u201d once, in a star, and spit out. How do we know? Because there is a clue. The proportion of the different isotopes\u2014how much C12 , how much C13 , etc., is something which is never changed by chemical reactions, because the chemical reactions are so much the same for the two. The proportions are purely the result of nuclear reactions. By looking at the proportions of the isotopes in the cold, dead ember which we are, we can discover what the furnace was like in which the stuff of which we are made was formed. That furnace was like the stars, and so it is very likely that our elements were \u201cmade\u201d in the stars and spit out in the explosions which we call novae and supernovae. Astronomy is so close to physics that we shall study many astronomical things as we go along. We turn now to what are called earth sciences, or geology. First, meteorology and the weather. Of course the instruments of meteorology are physical instruments, and the development of experimental physics made these instruments possible, as was explained before. However, the theory of meteorology has never been satisfactorily worked out by the physicist. \u201cWell,\u201d you say, \u201cthere is nothing but air, and we know the equations of the motions of air.\u201d Yes we do. \u201cSo if we know the condition of air today, why can\u2019t we figure out the condition of the air tomorrow?\u201d First, we do not really know what the condition is today, because the air is swirling and twisting everywhere. It turns out to be very sensitive, and even unstable. If you have ever seen water run smoothly over a dam, and then turn into a large number of blobs and drops as it falls, you will understand what I mean by unstable. You know the condition of the water before it goes over the spillway; it is perfectly smooth; but the moment it begins to fall, where do the drops begin? What determines how big the lumps are going to be and where they will be? That is not known, because the water is unstable. Even a smooth moving mass of air, in going over a mountain turns into complex whirlpools and eddies. In many fields we find this situation of turbulent flow that we cannot analyze today. Quickly we leave the subject of weather, and discuss geology! The question basic to geology is, what makes the earth the way it is? The most obvious processes are in front of your very eyes, the erosion processes of the rivers, the winds, etc. It is easy enough to understand these, but for every bit of erosion there is an equal amount of something else going on. Mountains are no lower today, on the average, than they were in the past. There must be mountain-forming processes. You will find, if you study geology, that there are mountain-forming processes and volcanism, which nobody understands but which is half of geology. The phenomenon of volcanoes is really not understood. What makes an earthquake is, ultimately, not understood. It is understood that if something is pushing something else, it snaps and will slide\u2014that is all right. But what pushes, and why? The theory is that there are currents inside the earth\u2014circulating currents, due to the difference in temperature inside and outside\u2014which, in their motion, push the surface slightly. Thus if there are two opposite circulations next to each other, the matter will collect in the region where they meet and make belts of mountains which are in unhappy stressed conditions, and so produce volcanoes and earthquakes. What about the inside of the earth? A great deal is known about the speed of earthquake waves through the earth and the density of distribution of the earth. However, physicists have been unable to get a good theory as to how dense a substance should be at the pressures that would be expected at the center of the earth. In other words, we cannot figure out the properties of matter very well in these circumstances. We do much less well with the earth than we do with the conditions of matter in the stars. The mathematics involved seems a little too difficult, so far, but perhaps it will not be too long before someone realizes that it is an important problem, and really works it out. The other aspect, of course, is that even if we did know the density, we cannot figure out the circulating currents. Nor can we really work out the properties of rocks at high pressure. We cannot tell how fast the rocks should \u201cgive\u201d; that must all be worked out by experiment. Next, we consider the science of psychology. Incidentally, psychoanalysis is not a science: it is at best a medical process, and perhaps even more like witch-doctoring. It has a theory as to what causes disease\u2014lots of different \u201cspirits,\u201d etc. The witch doctor has a theory that a disease like malaria is caused by a spirit which comes into the air; it is not cured by shaking a snake over it, but quinine does help malaria. So, if you are sick, I would advise that you go to the witch doctor because he is the man in the tribe who knows the most about the disease; on the other hand, his knowledge is not science. Psychoanalysis has not been checked carefully by experiment, and there is no way to find a list of the number of cases in which it works, the number of cases in which it does not work, etc. The other branches of psychology, which involve things like the physiology of sensation\u2014what happens in the eye, and what happens in the brain\u2014are, if you wish, less interesting. But some small but real progress has been made in studying them. One of the most interesting technical problems may or may not be called psychology. The central problem of the mind, if you will, or the nervous system, is this: when an animal learns something, it can do something different than it could before, and its brain cell must have changed too, if it is made out of atoms. In what way is it different? We do not know where to look, or what to look for, when something is memorized. We do not know what it means, or what change there is in the nervous system, when a fact is learned. This is a very important problem which has not been solved at all. Assuming, however, that there is some kind of memory thing, the brain is such an enormous mass of interconnecting wires and nerves that it probably cannot be analyzed in a straightforward manner. There is an analog of this to computing machines and computing elements, in that they also have a lot of lines, and they have some kind of element, analogous, perhaps, to the synapse, or connection of one nerve to another. This is a very interesting subject which we have not the time to discuss further\u2014the relationship between thinking and computing machines. It must be appreciated, of course, that this subject will tell us very little about the real complexities of ordinary human behavior. All human beings are so different. It will be a long time before we get there. We must start much further back. If we could even figure out how a dog works, we would have gone pretty far. Dogs are easier to understand, but nobody yet knows how dogs work. In order for physics to be useful to other sciences in a theoretical way, other than in the invention of instruments, the science in question must supply to the physicist a description of the object in a physicist\u2019s language. They can say \u201cwhy does a frog jump?,\u201d and the physicist cannot answer. If they tell him what a frog is, that there are so many molecules, there is a nerve here, etc., that is different. If they will tell us, more or less, what the earth or the stars are like, then we can figure it out. In order for physical theory to be of any use, we must know where the atoms are located. In order to understand the chemistry, we must know exactly what atoms are present, for otherwise we cannot analyze it. That is but one limitation, of course. There is another kind of problem in the sister sciences which does not exist in physics; we might call it, for lack of a better term, the historical question. How did it get that way? If we understand all about biology, we will want to know how all the things which are on the earth got there. There is the theory of evolution, an important part of biology. In geology, we not only want to know how the mountains are forming, but how the entire earth was formed in the beginning, the origin of the solar system, etc. That, of course, leads us to want to know what kind of matter there was in the world. How did the stars evolve? What were the initial conditions? That is the problem of astronomical history. A great deal has been found out about the formation of stars, the formation of elements from which we were made, and even a little about the origin of the universe. There is no historical question being studied in physics at the present time. We do not have a question, \u201cHere are the laws of physics, how did they get that way?\u201d We do not imagine, at the moment, that the laws of physics are somehow changing with time, that they were different in the past than they are at present. Of course they may be, and the moment we find they are, the historical question of physics will be wrapped up with the rest of the history of the universe, and then the physicist will be talking about the same problems as astronomers, geologists, and biologists. Finally, there is a physical problem that is common to many fields, that is very old, and that has not been solved. It is not the problem of finding new fundamental particles, but something left over from a long time ago\u2014over a hundred years. Nobody in physics has really been able to analyze it mathematically satisfactorily in spite of its importance to the sister sciences. It is the analysis of circulating or turbulent fluids. If we watch the evolution of a star, there comes a point where we can deduce that it is going to start convection, and thereafter we can no longer deduce what should happen. A few million years later the star explodes, but we cannot figure out the reason. We cannot analyze the weather. We do not know the patterns of motions that there should be inside the earth. The simplest form of the problem is to take a pipe that is very long and push water through it at high speed. We ask: to push a given amount of water through that pipe, how much pressure is needed? No one can analyze it from first principles and the properties of water. If the water flows very slowly, or if we use a thick goo like honey, then we can do it nicely. You will find that in your textbook. What we really cannot do is deal with actual, wet water running through a pipe. That is the central problem which we ought to solve some day, and we have not. A poet once said, \u201cThe whole universe is in a glass of wine.\u201d We will probably never know in what sense he meant that, for poets do not write to be understood. But it is true that if we look at a glass of wine closely enough we see the entire universe. There are the things of physics: the twisting liquid which evaporates depending on the wind and weather, the reflections in the glass, and our imagination adds the atoms. The glass is a distillation of the earth\u2019s rocks, and in its composition we see the secrets of the universe\u2019s age, and the evolution of stars. What strange array of chemicals are in the wine? How did they come to be? There are the ferments, the enzymes, the substrates, and the products. There in wine is found the great generalization: all life is fermentation. Nobody can discover the chemistry of wine without discovering, as did Louis Pasteur, the cause of much disease. How vivid is the claret, pressing its existence into the consciousness that watches it! If our small minds, for some convenience, divide this glass of wine, this universe, into parts\u2014physics, biology, geology, astronomy, psychology, and so on\u2014remember that nature does not know it! So let us put it all back together, not forgetting ultimately what it is for. Let it give us one more final pleasure: drink it and forget it all!"
    },
    {
        "input": "Transients",
        "output": "Although this chapter is entitled \u201ctransients,\u201d certain parts of it are, in a way, part of the last chapter on forced oscillation. One of the features of a forced oscillation which we have not yet discussed is the energy in the oscillation. Let us now consider that energy. In a mechanical oscillator, how much kinetic energy is there? It is proportional to the square of the velocity. Now we come to an important point. Consider an arbitrary quantity A , which may be the velocity or something else that we want to discuss. When we write A= A ^ e i\u03c9t , a complex number, the true and honest A , in the physical world, is only the real part; therefore if, for some reason, we want to use the square of A , it is not right to square the complex number and then take the real part, because the real part of the square of a complex number is not just the square of the real part, but also involves the imaginary part. So when we wish to find the energy we have to get away from the complex notation for a while to see what the inner workings are. Now the true physical A is the real part of A 0 e i(\u03c9t+\u0394) , that is, A= A 0 cos(\u03c9t+\u0394) , where A ^ , the complex number, is written as A 0 e i\u0394 . Now the square of this real physical quantity is A 2 = A 2 0 cos 2 (\u03c9t+\u0394) . The square of the quantity, then, goes up and down from a maximum to zero, like the square of the cosine. The square of the cosine has a maximum of 1 and a minimum of 0 , and its average value is 1/2 . In many circumstances we are not interested in the energy at any specific moment during the oscillation; for a large number of applications we merely want the average of A 2 , the mean of the square of A over a period of time large compared with the period of oscillation. In those circumstances, the average of the cosine squared may be used, so we have the following theorem: if A is represented by a complex number, then the mean of A 2 is equal to 1 2 A 2 0 . Now A 2 0 is the square of the magnitude of the complex A ^ . (This can be written in many ways\u2014some people like to write | A ^ | 2 ; others write, A ^ A ^ \u2217 , A ^ times its complex conjugate.) We shall use this theorem several times. Now let us consider the energy in a forced oscillator. The equation for the forced oscillator is m d 2 x/d t 2 +\u03b3mdx/dt+m \u03c9 2 0 x=F(t). (24.1) In our problem, of course, F(t) is a cosine function of t . Now let us analyze the situation: how much work is done by the outside force F ? The work done by the force per second, i.e., the power, is the force times the velocity. (We know that the differential work in a time dt is Fdx , and the power is Fdx/dt .) Thus P=F =m dx dt [( dx dt )( d 2 x d t 2 )+ \u03c9 2 0 x( dx dt )] +\u03b3m( dx dt ) 2 . (24.2) But the first two terms on the right can also be written as d/dt[ 1 2 m(dx/dt ) 2 + 1 2 m \u03c9 2 0 x 2 ] , as is immediately verified by differentiating. That is to say, the term in brackets is a pure derivative of two terms that are easy to understand\u2014one is the kinetic energy of motion, and the other is the potential energy of the spring. Let us call this quantity the stored energy, that is, the energy stored in the oscillation. Suppose that we want the average power over many cycles when the oscillator is being forced and has been running for a long time. In the long run, the stored energy does not change\u2014its derivative gives zero average effect. In other words, if we average the power in the long run, all the energy ultimately ends up in the resistive term \u03b3m(dx/dt ) 2 . There is some energy stored in the oscillation, but that does not change with time, if we average over many cycles. Therefore the mean power \u27e8P\u27e9 is \u27e8P\u27e9=\u27e8\u03b3m(dx/dt ) 2 \u27e9. (24.3) Using our method of writing complex numbers, and our theorem that \u27e8 A 2 \u27e9= 1 2 A 2 0 , we may find this mean power. Thus if x= x ^ e i\u03c9t , then dx/dt=i\u03c9 x ^ e i\u03c9t . Therefore, in these circumstances, the average power could be written as \u27e8P\u27e9= 1 2 \u03b3m \u03c9 2 x 2 0 . (24.4) In the notation for electrical circuits, dx/dt is replaced by the current I ( I is dq/dt , where q corresponds to x ), and m\u03b3 corresponds to the resistance R . Thus the rate of the energy loss\u2014the power used up by the forcing function\u2014is the resistance in the circuit times the average square of the current: \u27e8P\u27e9=R\u27e8 I 2 \u27e9=R\u22c5 1 2 I 2 0 . (24.5) This energy, of course, goes into heating the resistor; it is sometimes called the heating loss or the Joule heating. Another interesting feature to discuss is how much energy is stored. That is not the same as the power, because although power was at first used to store up some energy, after that the system keeps on absorbing power, insofar as there are any heating (resistive) losses. At any moment there is a certain amount of stored energy, so we would like to calculate the mean stored energy \u27e8E\u27e9 also. We have already calculated what the average of (dx/dt ) 2 is, so we find \u27e8E\u27e9 = 1 2 m\u27e8(dx/dt ) 2 \u27e9+ 1 2 m \u03c9 2 0 \u27e8 x 2 \u27e9 = 1 2 m( \u03c9 2 + \u03c9 2 0 ) 1 2 x 2 0 . (24.6) Now, when an oscillator is very efficient, and if \u03c9 is near \u03c9 0 , so that | x ^ | is large, the stored energy is very high\u2014we can get a large stored energy from a relatively small force. The force does a great deal of work in getting the oscillation going, but then to keep it steady, all it has to do is to fight the friction. The oscillator can have a great deal of energy if the friction is very low, and even though it is oscillating strongly, not much energy is being lost. The efficiency of an oscillator can be measured by how much energy is stored, compared with how much work the force does per oscillation. How does the stored energy compare with the amount of work that is done in one cycle? This is called the Q of the system, and Q is defined as 2\u03c0 times the mean stored energy, divided by the work done per cycle. (If we were to say the work done per radian instead of per cycle, then the 2\u03c0 disappears.) Q=2\u03c0 1 2 m( \u03c9 2 + \u03c9 2 0 )\u22c5\u27e8 x 2 \u27e9 \u03b3m \u03c9 2 \u27e8 x 2 \u27e9\u22c52\u03c0/\u03c9 = \u03c9 2 + \u03c9 2 0 2\u03b3\u03c9 . (24.7) Q is not a very useful number unless it is very large. When it is relatively large, it gives a measure of how good the oscillator is. People have tried to define Q in the simplest and most useful way; various definitions differ a bit from one another, but if Q is very large, all definitions are in agreement. The most generally accepted definition is Eq. (24.7), which depends on \u03c9 . For a good oscillator, close to resonance, we can simplify (24.7) a little by setting \u03c9= \u03c9 0 , and we then have Q= \u03c9 0 /\u03b3 , which is the definition of Q that we used before. What is Q for an electrical circuit? To find out, we merely have to translate L for m , R for m\u03b3 , and 1/C for m \u03c9 2 0 (see Table 23\u20131). The Q at resonance is L\u03c9/R , where \u03c9 is the resonance frequency. If we consider a circuit with a high Q , that means that the amount of energy stored in the oscillation is very large compared with the amount of work done per cycle by the machinery that drives the oscillations. We now turn to our main topic of discussion: transients. By a transient is meant a solution of the differential equation when there is no force present, but when the system is not simply at rest. (Of course, if it is standing still at the origin with no force acting, that is a nice problem\u2014it stays there!) Suppose the oscillation starts another way: say it was driven by a force for a while, and then we turn off the force. What happens then? Let us first get a rough idea of what will happen for a very high Q system. So long as a force is acting, the stored energy stays the same, and there is a certain amount of work done to maintain it. Now suppose we turn off the force, and no more work is being done; then the losses which are eating up the energy of the supply are no longer eating up its energy\u2014there is no more driver. The losses will have to consume, so to speak, the energy that is stored. Let us suppose that Q/2\u03c0=1000 . Then the work done per cycle is 1/1000 of the stored energy. Is it not reasonable, since it is oscillating with no driving force, that in one cycle the system will still lose a thousandth of its energy E , which ordinarily would have been supplied from the outside, and that it will continue oscillating, always losing 1/1000 of its energy per cycle? So, as a guess, for a relatively high Q system, we would suppose that the following equation might be roughly right (we will later do it exactly, and it will turn out that it was right!): dE/dt=\u2212\u03c9E/Q. (24.8) This is rough because it is true only for large Q . In each radian the system loses a fraction 1/Q of the stored energy E . Thus in a given amount of time dt the energy will change by an amount \u03c9dt/Q , since the number of radians associated with the time dt is \u03c9dt . What is the frequency? Let us suppose that the system moves so nicely, with hardly any force, that if we let go it will oscillate at essentially the same frequency all by itself. So we will guess that \u03c9 is the resonant frequency \u03c9 0 . Then we deduce from Eq. (24.8) that the stored energy will vary as E= E 0 e \u2212 \u03c9 0 t/Q = E 0 e \u2212\u03b3t . (24.9) This would be the measure of the energy at any moment. What would the formula be, roughly, for the amplitude of the oscillation as a function of the time? The same? No! The amount of energy in a spring, say, goes as the square of the displacement; the kinetic energy goes as the square of the velocity; so the total energy goes as the square of the displacement. Thus the displacement, the amplitude of oscillation, will decrease half as fast because of the square. In other words, we guess that the solution for the damped transient motion will be an oscillation of frequency close to the resonance frequency \u03c9 0 , in which the amplitude of the sine-wave motion will diminish as e \u2212\u03b3t/2 : x= A 0 e \u2212\u03b3t/2 cos \u03c9 0 t. (24.10) This equation and Fig. 24\u20131 give us an idea of what we should expect; now let us try to analyze the motion precisely by solving the differential equation of the motion itself. So, starting with Eq. (24.1), with no outside force, how do we solve it? Being physicists, we do not have to worry about the method as much as we do about what the solution is. Armed with our previous experience, let us try as a solution an exponential curve, x=A e i\u03b1t . (Why do we try this? It is the easiest thing to differentiate!) We put this into (24.1) (with F(t)=0 ), using the rule that each time we differentiate x with respect to time, we multiply by i\u03b1 . So it is really quite simple to substitute. Thus our equation looks like this: (\u2212 \u03b1 2 +i\u03b3\u03b1+ \u03c9 2 0 )A e i\u03b1t =0. (24.11) The net result must be zero for all times, which is impossible unless (a) A=0 , which is no solution at all\u2014it stands still, or (b) \u2212 \u03b1 2 +i\u03b1\u03b3+ \u03c9 2 0 =0. (24.12) If we can solve this and find an \u03b1 , then we will have a solution in which A need not be zero! \u03b1=i\u03b3/2\u00b1 \u03c9 2 0 \u2212 \u03b3 2 /4 \u2212 \u2212 \u2212 \u2212 \u2212 \u2212 \u2212 \u2212 \u221a . (24.13) For a while we shall assume that \u03b3 is fairly small compared with \u03c9 0 , so that \u03c9 2 0 \u2212 \u03b3 2 /4 is definitely positive, and there is nothing the matter with taking the square root. The only bothersome thing is that we get two solutions! Thus \u03b1 1 =i\u03b3/2+ \u03c9 2 0 \u2212 \u03b3 2 /4 \u2212 \u2212 \u2212 \u2212 \u2212 \u2212 \u2212 \u2212 \u221a =i\u03b3/2+ \u03c9 \u03b3 (24.14) and \u03b1 2 =i\u03b3/2\u2212 \u03c9 2 0 \u2212 \u03b3 2 /4 \u2212 \u2212 \u2212 \u2212 \u2212 \u2212 \u2212 \u2212 \u221a =i\u03b3/2\u2212 \u03c9 \u03b3 . (24.15) Let us consider the first one, supposing that we had not noticed that the square root has two possible values. Then we know that a solution for x is x 1 =A e i \u03b1 1 t , where A is any constant whatever. Now, in substituting \u03b1 1 , because it is going to come so many times and it takes so long to write, we shall call \u03c9 2 0 \u2212 \u03b3 2 /4 \u2212 \u2212 \u2212 \u2212 \u2212 \u2212 \u2212 \u2212 \u221a = \u03c9 \u03b3 . Thus i \u03b1 1 =\u2212\u03b3/2+i \u03c9 \u03b3 , and we get x=A e (\u2212\u03b3/2+i \u03c9 \u03b3 )t , or what is the same, because of the wonderful properties of an exponential, x 1 =A e \u2212\u03b3t/2 e i \u03c9 \u03b3 t . (24.16) First, we recognize this as an oscillation, an oscillation at a frequency \u03c9 \u03b3 , which is not exactly the frequency \u03c9 0 , but is rather close to \u03c9 0 if it is a good system. Second, the amplitude of the oscillation is decreasing exponentially! If we take, for instance, the real part of (24.16), we get x 1 =A e \u2212\u03b3t/2 cos \u03c9 \u03b3 t. (24.17) This is very much like our guessed-at solution (24.10), except that the frequency really is \u03c9 \u03b3 . This is the only error, so it is the same thing\u2014we have the right idea. But everything is not all right! What is not all right is that there is another solution. The other solution is \u03b1 2 , and we see that the difference is only that the sign of \u03c9 \u03b3 is reversed: x 2 =B e \u2212\u03b3t/2 e \u2212i \u03c9 \u03b3 t . (24.18) What does this mean? We shall soon prove that if x 1 and x 2 are each a possible solution of Eq. (24.1) with F=0 , then x 1 + x 2 is also a solution of the same equation! So the general solution x is of the mathematical form x= e \u2212\u03b3t/2 (A e i \u03c9 \u03b3 t +B e \u2212i \u03c9 \u03b3 t ). (24.19) Now we may wonder why we bother to give this other solution, since we were so happy with the first one all by itself. What is the extra one for, because of course we know we should only take the real part? We know that we must take the real part, but how did the mathematics know that we only wanted the real part? When we had a nonzero driving force F(t) , we put in an artificial force to go with it, and the imaginary part of the equation, so to speak, was driven in a definite way. But when we put F(t)\u22610 , our convention that x should be only the real part of whatever we write down is purely our own, and the mathematical equations do not know it yet. The physical world has a real solution, but the answer that we were so happy with before is not real, it is complex. The equation does not know that we are arbitrarily going to take the real part, so it has to present us, so to speak, with a complex conjugate type of solution, so that by putting them together we can make a truly real solution; that is what \u03b1 2 is doing for us. In order for x to be real, B e \u2212i \u03c9 \u03b3 t will have to be the complex conjugate of A e i \u03c9 \u03b3 t that the imaginary parts disappear. So it turns out that B is the complex conjugate of A , and our real solution is x= e \u2212\u03b3t/2 (A e i \u03c9 \u03b3 t + A \u2217 e \u2212i \u03c9 \u03b3 t ). (24.20) So our real solution is an oscillation with a phase shift and a damping\u2014just as advertised. Now let us see if the above really works. We construct the electrical circuit shown in Fig. 24\u20132, in which we apply to an oscilloscope the voltage across the inductance L after we suddenly turn on a voltage by closing the switch S . It is an oscillatory circuit, and it generates a transient of some kind. It corresponds to a circumstance in which we suddenly apply a force and the system starts to oscillate. It is the electrical analog of a damped mechanical oscillator, and we watch the oscillation on an oscilloscope, where we should see the curves that we were trying to analyze. (The horizontal motion of the oscilloscope is driven at a uniform speed, while the vertical motion is the voltage across the inductor. The rest of the circuit is only a technical detail. We would like to repeat the experiment many, many times, since the persistence of vision is not good enough to see only one trace on the screen. So we do the experiment again and again by closing the switch 60 times a second; each time we close the switch, we also start the oscilloscope horizontal sweep, and it draws the curve over and over.) In Figs. 24\u20133 to 24\u20136 we see examples of damped oscillations, actually photographed on an oscilloscope screen. Figure 24\u20133 shows a damped oscillation in a circuit which has a high Q , a small \u03b3 . It does not die out very fast; it oscillates many times on the way down. But let us see what happens as we decrease Q , so that the oscillation dies out more rapidly. We can decrease Q by increasing the resistance R in the circuit. When we increase the resistance in the circuit, it dies out faster (Fig. 24\u20134). Then if we increase the resistance in the circuit still more, it dies out faster still (Fig. 24\u20135). But when we put in more than a certain amount, we cannot see any oscillation at all! The question is, is this because our eyes are not good enough? If we increase the resistance still more, we get a curve like that of Fig. 24\u20136, which does not appear to have any oscillations, except perhaps one. Now, how can we explain that by mathematics? The resistance is, of course, proportional to the \u03b3 term in the mechanical device. Specifically, \u03b3 is R/L . Now if we increase the \u03b3 in the solutions (24.14) and (24.15) that we were so happy with before, chaos sets in when \u03b3/2 exceeds \u03c9 0 ; we must write it a different way, as i\u03b3/2+i \u03b3 2 /4\u2212 \u03c9 2 0 \u2212 \u2212 \u2212 \u2212 \u2212 \u2212 \u2212 \u2212 \u221a andi\u03b3/2\u2212i \u03b3 2 /4\u2212 \u03c9 2 0 \u2212 \u2212 \u2212 \u2212 \u2212 \u2212 \u2212 \u2212 \u221a . Those are now the two solutions and, following the same line of mathematical reasoning as previously, we again find two solutions: e i \u03b1 1 t and e i \u03b1 2 t . If we now substitute for \u03b1 1 , we get x=A e \u2212(\u03b3/2+ \u03b3 2 /4\u2212 \u03c9 2 0 \u221a )t , a nice exponential decay with no oscillations. Likewise, the other solution is x=B e \u2212(\u03b3/2\u2212 \u03b3 2 /4\u2212 \u03c9 2 0 \u221a )t . Note that the square root cannot exceed \u03b3/2 , because even if \u03c9 0 =0 , one term just equals the other. But \u03c9 2 0 is taken away from \u03b3 2 /4 , so the square root is less than \u03b3/2 , and the term in parentheses is, therefore, always a positive number. Thank goodness! Why? Because if it were negative, we would find e raised to a positive factor times t , which would mean it was exploding! In putting more and more resistance into the circuit, we know it is not going to explode\u2014quite the contrary. So now we have two solutions, each one by itself a dying exponential, but one having a much faster \u201cdying rate\u201d than the other. The general solution is of course a combination of the two; the coefficients in the combination depending upon how the motion starts\u2014what the initial conditions of the problem are. In the particular way this circuit happens to be starting, the A is negative and the B is positive, so we get the difference of two exponential curves. Now let us discuss how we can find the two coefficients A and B (or A and A \u2217 ), if we know how the motion was started. Suppose that at t=0 we know that x= x 0 , and dx/dt= v 0 . If we put t=0 , x= x 0 , and dx/dt= v 0 into the expressions x= e \u2212\u03b3t/2 ( dx/dt= e \u2212\u03b3t/2 [ A e i \u03c9 \u03b3 t + A \u2217 e \u2212i \u03c9 \u03b3 t ), (\u2212\u03b3/2+i \u03c9 \u03b3 )A e i \u03c9 \u03b3 t + (\u2212\u03b3/2\u2212i \u03c9 \u03b3 ) A \u2217 e \u2212i \u03c9 \u03b3 t ], we find, since e 0 = e i0 = 1 , x 0 v 0 =A+ A \u2217 =2 A R , =\u2212(\u03b3/2)(A+ A \u2217 )+i \u03c9 \u03b3 (A\u2212 A \u2217 ) =\u2212\u03b3 x 0 /2+i \u03c9 \u03b3 (2i A I ), where A= A R +i A I , and A \u2217 = A R \u2212i A I . Thus we find A R = x 0 /2 A / and A I =\u2212( v 0 +\u03b3 x 0 /2)/2 \u03c9 \u03b3 . (24.21) This completely determines A and A \u2217 , and therefore the complete curve of the transient solution, in terms of how it begins. Incidentally, we can write the solution another way if we note that e i\u03b8 + e \u2212i\u03b8 =2cos\u03b8and e i\u03b8 \u2212 e \u2212i\u03b8 =2isin\u03b8. i \u03b8 i \u03b8 i \u03b8 i \u03b8 We may then write the complete solution as x= e \u2212\u03b3t/2 [ x 0 cos \u03c9 \u03b3 t+ v 0 +\u03b3 x 0 /2 \u03c9 \u03b3 sin \u03c9 \u03b3 t], (24.22) where \u03c9 \u03b3 =+ \u03c9 2 0 \u2212 \u03b3 2 /4 \u2212 \u2212 \u2212 \u2212 \u2212 \u2212 \u2212 \u2212 \u221a . This is the mathematical expression for the way an oscillation dies out. We shall not make direct use of it, but there are a number of points we should like to emphasize that are true in more general cases. First of all the behavior of such a system with no external force is expressed by a sum, or superposition, of pure exponentials in time (which we wrote as e i\u03b1t ). This is a good solution to try in such circumstances. The values of \u03b1 may be complex in general, the imaginary parts representing damping. Finally the intimate mathematical relation of the sinusoidal and exponential function discussed in Chapter 22 often appears physically as a change from oscillatory to exponential behavior when some physical parameter (in this case resistance, \u03b3 ) exceeds some critical value."
    },
    {
        "input": "Other Two-State Systems",
        "output": "In the last chapter we discussed some aspects of the ammonia molecule under the approximation that it can be considered as a two-state system. It is, of course, not really a two-state system\u2014there are many states of rotation, vibration, translation, and so on\u2014but each of these states of motion must be analyzed in terms of two internal states because of the flip-flop of the nitrogen atom. Here we are going to consider other examples of systems which, to some approximation or other, can be considered as two-state systems. Lots of things will be approximate because there are always many other states, and in a more accurate analysis they would have to be taken into account. But in each of our examples we will be able to understand a great deal by just thinking about two states. Since we will only be dealing with two-state systems, the Hamiltonian we need will look just like the one we used in the last chapter. When the Hamiltonian is independent of time, we know that there are two stationary states with definite\u2014and usually different\u2014energies. Generally, however, we start our analysis with a set of base states which are not these stationary states, but states which may, perhaps, have some other simple physical meaning. Then, the stationary states of the system will be represented by a linear combination of these base states. For convenience, we will summarize the important equations from Chapter 9. Let the original choice of base states be |1\u27e9 and |2\u27e9 . Then any state |\u03c8\u27e9 is represented by the linear combination |\u03c8\u27e9 =|1\u27e9\u27e81|\u03c8\u27e9+|2\u27e9\u27e82|\u03c8\u27e9 =|1\u27e9C1+|2\u27e9C2. The amplitudes Ci (by which we mean either C1 or C2 ) satisfy the two linear differential equations i\u210f dCi dt = \u2211 j HijCj, where both i and j take on the values 1 and 2 . When the terms of the Hamiltonian Hij do not depend on t , the two states of definite energy (the stationary states), which we call |\u03c8I\u27e9=|I\u27e9e\u2212(i/\u210f)EItand|\u03c8II\u27e9=|II\u27e9e\u2212(i/\u210f)EIIt, have the energies EI = H11+H22 2 + \u221a ( H11\u2212H22 2 )2+H12H21 , EII = H11+H22 2 \u2212 \u221a ( H11\u2212H22 2 )2+H12H21 . The two C \u2019s for each of these states have the same time dependence. The state vectors |I\u27e9 and |II\u27e9 which go with the stationary states are related to our original base states |1\u27e9 and |2\u27e9 by |I\u27e9 =|1\u27e9a1+|2\u27e9a2, |II\u27e9 =|1\u27e9a \u2032 1 +|2\u27e9a \u2032 2 . The a \u2019s are complex constants, which satisfy |a1|2+|a2|2=1, a1 a2 = H12 EI\u2212H11 , |a \u2032 1 |2+|a \u2032 2 |2=1, a \u2032 1 a \u2032 2 = H12 EII\u2212H11 . If H11 and H22 are equal\u2014say both are equal to E0 \u2014and H12=H21=\u2212A , then EI=E0+A , EII=E0\u2212A , and the states |I\u27e9 and |II\u27e9 are particularly simple: |I\u27e9= 1 \u221a 2 [|1\u27e9\u2212|2\u27e9], |II\u27e9= 1 \u221a 2 [|1\u27e9+|2\u27e9]. Now we will use these results to discuss a number of interesting examples taken from the fields of chemistry and physics. The first example is the hydrogen molecular ion. A positively ionized hydrogen molecule consists of two protons with one electron worming its way around them. If the two protons are very far apart, what states would we expect for this system? The answer is pretty clear: The electron will stay close to one proton and form a hydrogen atom in its lowest state, and the other proton will remain alone as a positive ion. So, if the two protons are far apart, we can visualize one physical state in which the electron is \u201cattached\u201d to one of the protons. There is, clearly, another state symmetric to that one in which the electron is near the other proton, and the first proton is the one that is an ion. We will take these two as our base states, and we\u2019ll call them |1\u27e9 and |2\u27e9 . They are sketched in Fig. 10\u20131. Of course, there are really many states of an electron near a proton, because the combination can exist as any one of the excited states of the hydrogen atom. We are not interested in that variety of states now; we will consider only the situation in which the hydrogen atom is in the lowest state\u2014its ground state\u2014and we will, for the moment, disregard spin of the electron. We can just suppose that for all our states the electron has its spin \u201cup\u201d along the z -axis.1 Now to remove an electron from a hydrogen atom requires 13.6 electron volts of energy. So long as the two protons of the hydrogen molecular ion are far apart, it still requires about this much energy\u2014which is for our present considerations a great deal of energy\u2014to get the electron somewhere near the midpoint between the protons. So it is impossible, classically, for the electron to jump from one proton to the other. However, in quantum mechanics it is possible\u2014though not very likely. There is some small amplitude for the electron to move from one proton to the other. As a first approximation, then, each of our base states |1\u27e9 and |2\u27e9 will have the energy E0 , which is just the energy of one hydrogen atom plus one proton. We can take that the Hamiltonian matrix elements H11 and H22 are both approximately equal to E0 . The other matrix elements H12 and H21 , which are the amplitudes for the electron to go back and forth, we will again write as \u2212A . You see that this is the same game we played in the last two chapters. If we disregard the fact that the electron can flip back and forth, we have two states of exactly the same energy. This energy will, however, be split into two energy levels by the possibility of the electron going back and forth\u2014the greater the probability of the transition, the greater the split. So the two energy levels of the system are E0+A and E0\u2212A ; and the states which have these definite energies are given by Eqs. (10.7). From our solution we see that if a proton and a hydrogen atom are put anywhere near together, the electron will not stay on one of the protons but will flip back and forth between the two protons. If it starts on one of the protons, it will oscillate back and forth between the states |1\u27e9 and |2\u27e9 \u2014giving a time-varying solution. In order to have the lowest energy solution (which does not vary with time), it is necessary to start the system with equal amplitudes for the electron to be around each proton. Remember, there are not two electrons\u2014we are not saying that there is an electron around each proton. There is only one electron, and it has the same amplitude\u20141/ \u221a 2 in magnitude\u2014to be in either position. Now the amplitude A for an electron which is near one proton to get to the other one depends on the separation between the protons. The closer the protons are together, the larger the amplitude. You remember that we talked in Chapter 7 about the amplitude for an electron to \u201cpenetrate a barrier,\u201d which it could not do classically. We have the same situation here. The amplitude for an electron to get across decreases roughly exponentially with the distance\u2014for large distances. Since the transition probability, and therefore A , gets larger when the protons are closer together, the separation of the energy levels will also get larger. If the system is in the state |I\u27e9 , the energy E0+A increases with decreasing distance, so these quantum mechanical effects make a repulsive force tending to keep the protons apart. On the other hand, if the system is in the state |II\u27e9 , the total energy decreases if the protons are brought closer together; there is an attractive force pulling the protons together. The variation of the two energies with the distance between the two protons should be roughly as shown in Fig. 10\u20132. We have, then, a quantum-mechanical explanation of the binding force that holds the H + 2 ion together. We have, however, forgotten one thing. In addition to the force we have just described, there is also an electrostatic repulsive force between the two protons. When the two protons are far apart\u2014as in Fig. 10\u20131\u2014the \u201cbare\u201d proton sees only a neutral atom, so there is a negligible electrostatic force. At very close distances, however, the \u201cbare\u201d proton begins to get \u201cinside\u201d the electron distribution\u2014that is, it is closer to the proton on the average than to the electron. So there begins to be some extra electrostatic energy which is, of course, positive. This energy\u2014which also varies with the separation\u2014should be included in E 0 . So for E 0 we should take something like the broken-line curve in Fig. 10\u20132 which rises rapidly for distances less than the radius of a hydrogen atom. We should add and subtract the flip-flop energy A from this E 0 . When we do that, the energies E I and E II will vary with the interproton distance D as shown in Fig. 10\u20133. [In this figure, we have plotted the results of a more detailed calculation. The interproton distance is given in units of 1 \u00c5 ( 10 \u22128 cm), and the excess energy over a proton plus a hydrogen atom is given in units of the binding energy of the hydrogen atom\u2014the so-called \u201cRydberg\u201d energy, 13.6 eV.] We see that the state |II\u27e9 has a minimum-energy point. This will be the equilibrium configuration\u2014the lowest energy condition\u2014for the H + 2 ion. The energy at this point is lower than the energy of a separated proton and hydrogen atom, so the system is bound. A single electron acts to hold the two protons together. A chemist would call it a \u201cone-electron bond.\u201d This kind of chemical binding is also often called \u201cquantum mechanical resonance\u201d (by analogy with the two coupled pendulums we have described before). But that really sounds more mysterious than it is, it\u2019s only a \u201cresonance\u201d if you start out by making a poor choice for your base states\u2014as we did also! If you picked the state |II\u27e9 , you would have the lowest energy state\u2014that\u2019s all. We can see in another way why such a state should have a lower energy than a proton and a hydrogen atom. Let\u2019s think about an electron near two protons with some fixed, but not too large, separation. You remember that with a single proton the electron is \u201cspread out\u201d because of the uncertainty principle. It seeks a balance between having a low Coulomb potential energy and not getting confined into too small a space, which would make a high kinetic energy (because of the uncertainty relation \u0394p\u0394x\u2248\u210f ). Now if there are two protons, there is more space where the electron can have a low potential energy. It can spread out\u2014lowering its kinetic energy\u2014without increasing its potential energy. The net result is a lower energy than a proton and a hydrogen atom. Then why does the other state |I\u27e9 have a higher energy? Notice that this state is the difference of the states |1\u27e9 and |2\u27e9 . Because of the symmetry of |1\u27e9 and |2\u27e9 , the difference must have zero amplitude to find the electron half-way between the two protons. This means that the electron is somewhat more confined, which leads to a larger energy. We should say that our approximate treatment of the H + 2 ion as a two-state system breaks down pretty badly once the protons get as close together as they are at the minimum in the curve of Fig. 10\u20133, and so, will not give a good value for the actual binding energy. For small separations, the energies of the two \u201cstates\u201d we imagined in Fig. 10\u20131 are not really equal to E 0 ; a more refined quantum mechanical treatment is needed. Suppose we ask now what would happen if instead of two protons, we had two different objects\u2014as, for example, one proton and one lithium positive ion (both particles still with a single positive charge). In such a case, the two terms H 11 and H 22 of the Hamiltonian would no longer be equal; they would, in fact, be quite different. If it should happen that the difference ( H 11 \u2212 H 22 ) is, in absolute value, much greater than A=\u2212 H 12 , the attractive force gets very weak, as we can see in the following way. If we put H 12 H 21 = A 2 into Eqs. (10.3) we get E= H 11 + H 22 2 \u00b1 H 11 \u2212 H 22 2 1+ 4 A 2 ( H 11 \u2212 H 22 ) 2 \u2212 \u2212 \u2212 \u2212 \u2212 \u2212 \u2212 \u2212 \u2212 \u2212 \u2212 \u2212 \u2212 \u2212 \u221a . When H 11 \u2212 H 22 is much greater than A 2 , the square root is very nearly equal to 1+ 2 A 2 ( H 11 \u2212 H 22 ) 2 . 2 The two energies are then E I E II = H 11 + A 2 ( H 11 \u2212 H 22 ) , = H 22 \u2212 A 2 ( H 11 \u2212 H 22 ) . (10.8) They are now very nearly just the energies H 11 and H 22 of the isolated atoms, pushed apart only slightly by the flip-flop amplitude A . The energy difference E I \u2212 E II is ( H 11 \u2212 H 22 )+ 2 A 2 H 11 \u2212 H 22 . 2 The additional separation from the flip-flop of the electron is no longer equal to 2A ; it is smaller by the factor A/( H 11 \u2212 H 22 ) , which we are now taking to be much less than one. Also, the dependence of E I \u2212 E II on the separation of the two nuclei is much smaller than for the H + 2 ion\u2014it is also reduced by the factor A/( H 11 \u2212 H 22 ) . We can now see why the binding of unsymmetric diatomic molecules is generally very weak. In our theory of the H + 2 ion we have discovered an explanation for the mechanism by which an electron shared by two protons provides, in effect, an attractive force between the two protons which can be present even when the protons are at large distances. The attractive force comes from the reduced energy of the system due to the possibility of the electron jumping from one proton to the other. In such a jump the system changes from the configuration (hydrogen atom, proton) to the configuration (proton, hydrogen atom), or switches back. We can write the process symbolically as (H,p)\u21cc(p,H). ( ) ( ) The energy shift due to this process is proportional to the amplitude A that an electron whose energy is \u2212 W H (its binding energy in the hydrogen atom) can get from one proton to the other. For large distances R between the two protons, the electrostatic potential energy of the electron is nearly zero over most of the space it must go when it makes its jump. In this space, then, the electron moves nearly like a free particle in empty space\u2014but with a negative energy! We have seen in Chapter 3 [Eq. (3.7)] that the amplitude for a particle of definite energy to get from one place to another a distance r away is proportional to e (i/\u210f)pr r , ( i / \u210f ) where p is the momentum corresponding to the definite energy. In the present case (using the nonrelativistic formula), p is given by p 2 2m =\u2212 W H . (10.9) This means that p is an imaginary number, p=i 2m W H \u2212 \u2212 \u2212 \u2212 \u2212 \u2212 \u221a (the other sign for the radical gives nonsense here). We should expect, then, that the amplitude A for the H + 2 ion will vary as A\u221d e \u2212( 2m W H \u221a /\u210f)R R (10.10) for large separations R between the two protons. The energy shift due to the electron binding is proportional to A , so there is a force pulling the two protons together which is proportional\u2014for large R \u2014to the derivative of (10.10) with respect to R . Finally, to be complete, we should remark that in the two-proton, one-electron system there is still one other effect which gives a dependence of the energy on R . We have neglected it until now because it is usually rather unimportant\u2014the exception is just for those very large distances where the energy of the exchange term A has decreased exponentially to very small values. The new effect we are thinking of is the electrostatic attraction of the proton for the hydrogen atom, which comes about in the same way any charged object attracts a neutral object. The bare proton makes an electric field E (varying as 1/ R 2 ) at the neutral hydrogen atom. The atom becomes polarized, taking on an induced dipole moment \u03bc proportional to E . The energy of the dipole is \u03bcE , which is proportional to E 2 \u2014or to 1/ R 4 . So there is a term in the energy of the system which decreases with the fourth power of the distance. (It is a correction to E 0 .) This energy falls off with distance more slowly than the shift A given by (10.10); at some large separation R it becomes the only remaining important term giving a variation of energy with R \u2014and, therefore, the only remaining force. Note that the electrostatic term has the same sign for both of the base states (the force is attractive, so the energy is negative) and so also for the two stationary states, whereas the electron exchange term A gives opposite signs for the two stationary states. We have seen that the system of a hydrogen atom and a proton has an energy of interaction due to the exchange of the single electron which varies at large separations R as e \u2212\u03b1R R , (10.11) with \u03b1= 2m W H \u2212 \u2212 \u2212 \u2212 \u2212 \u2212 \u221a /\u210f . (One usually says that there is an exchange of a \u201cvirtual\u201d electron when\u2014as here\u2014the electron has to jump across a space where it would have a negative energy. More specifically, a \u201cvirtual exchange\u201d means that the phenomenon involves a quantum mechanical interference between an exchanged state and a nonexchanged state.) Now we might ask the following question: Could it be that forces between other kinds of particles have an analogous origin? What about, for example, the nuclear force between a neutron and a proton, or between two protons? In an attempt to explain the nature of nuclear forces, Yukawa proposed that the force between two nucleons is due to a similar exchange effect\u2014only, in this case, due to the virtual exchange, not of an electron, but of a new particle, which he called a \u201cmeson.\u201d Today, we would identify Yukawa\u2019s meson with the \u03c0 -meson (or \u201cpion\u201d) produced in high-energy collisions of protons or other particles. Let\u2019s see, as an example, what kind of a force we would expect from the exchange of a positive pion ( \u03c0 + ) of mass m \u03c0 between a proton and a neutron. Just as a hydrogen atom H 0 can go into a proton p + by giving up an electron e \u2212 , H 0 \u2192 p + + e \u2212 , (10.12) a proton p + can go into a neutron n 0 by giving up a \u03c0 + meson: p + \u2192 n 0 + \u03c0 + . (10.13) So if we have a proton at a and a neutron at b separated by the distance R , the proton can become a neutron by emitting a \u03c0 + , which is then absorbed by the neutron at b , turning it into a proton. There is an energy of interaction of the two-nucleon (plus pion) system which depends on the amplitude A for the pion exchange\u2014just as we found for the electron exchange in the H + 2 ion. In the process (10.12), the energy of the H 0 atom is less than that of the proton by W H (calculating nonrelativistically, and omitting the rest energy m c 2 of the electron), so the electron has a negative kinetic energy\u2014or imaginary momentum\u2014as in Eq. (10.9). In the nuclear process (10.13), the proton and neutron have almost equal masses, so the \u03c0 + will have zero total energy. The relation between the total energy E and the momentum p for a pion of mass m \u03c0 is E 2 = p 2 c 2 + m 2 \u03c0 c 4 . 2 Since E is zero (or at least negligible in comparison with m \u03c0 ), the momentum is again imaginary: p=i m \u03c0 c. i Using the same arguments we gave for the amplitude that a bound electron would penetrate the barrier in the space between two protons, we get for the nuclear case an exchange amplitude A which should\u2014for large R \u2014go as e \u2212( m \u03c0 c/\u210f)R R . (10.14) The interaction energy is proportional to A , and so varies in the same way. We get an energy variation in the form of the so-called Yukawa potential between two nucleons. Incidentally, we obtained this same formula earlier directly from the differential equation for the motion of a pion in free space [see Chapter 28, Vol. II, Eq. (28.18)]. We can, following the same line of argument, discuss the interaction between two protons (or between two neutrons) which results from the exchange of a neutral pion ( \u03c0 0 ). The basic process is now p + \u2192 p + + \u03c0 0 . (10.15) A proton can emit a virtual \u03c0 0 , but then it remains still a proton. If we have two protons, proton No. 1 can emit a virtual \u03c0 0 which is absorbed by proton No. 2 . At the end, we still have two protons. This is somewhat different from the H + 2 ion. There the H 0 went into a different condition\u2014the proton\u2014after emitting the electron. Now we are assuming that a proton can emit a \u03c0 0 without changing its character. Such processes are, in fact, observed in high-energy collisions. The process is analogous to the way that an electron emits a photon and ends up still an electron: e\u2192e+photon. (10.16) We do not \u201csee\u201d the photons inside the electrons before they are emitted or after they are absorbed, and their emission does not change the \u201cnature\u201d of the electron. Going back to the two protons, there is an interaction energy which arises from the amplitude A that one proton emits a neutral pion which travels across (with imaginary momentum) to the other proton and is absorbed there. This amplitude is again proportional to (10.14), with m \u03c0 the mass of the neutral pion. All the same arguments give an equal interaction energy for two neutrons. Since the nuclear forces (disregarding electrical effects) between neutron and proton, between proton and proton, between neutron and neutron are the same, we conclude that the masses of the charged and neutral pions should be the same. Experimentally, the masses are indeed very nearly equal, and the small difference is about what one would expect from electric self-energy corrections (see Chapter 28, Vol. II). There are other kinds of particles\u2014like K-mesons\u2014which can be exchanged between two nucleons. It is also possible for two pions to be exchanged at the same time. But all of these other exchanged \u201cobjects\u201d have a rest mass m x higher than the pion mass m \u03c0 , and lead to terms in the exchange amplitude which vary as e \u2212( m x c/\u210f)R R . ( / \u210f ) R These terms die out faster with increasing R than the one-meson term. No one knows, today, how to calculate these higher-mass terms, but for large enough values of R only the one-pion term survives. And, indeed, those experiments which involve nuclear interactions only at large distances do show that the interaction energy is as predicted from the one-pion exchange theory. In the classical theory of electricity and magnetism, the Coulomb electrostatic interaction and the radiation of light by an accelerating charge are closely related\u2014both come out of the Maxwell equations. We have seen in the quantum theory that light can be represented as the quantum excitations of the harmonic oscillations of the classical electromagnetic fields in a box. Alternatively, the quantum theory can be set up by describing light in terms of particles\u2014photons\u2014which obey Bose statistics. We emphasized in Section 4\u20135 that the two alternative points of view always give identical predictions. Can the second point of view be carried through completely to include all electromagnetic effects? In particular, if we want to describe the electromagnetic field purely in terms of Bose particles\u2014that is, in terms of photons\u2014what is the Coulomb force due to? From the \u201cparticle\u201d point of view the Coulomb interaction between two electrons comes from the exchange of a virtual photon. One electron emits a photon\u2014as in reaction (10.16)\u2014which goes over to the second electron, where it is absorbed in the reverse of the same reaction. The interaction energy is again given by a formula like (10.14), but now with m \u03c0 replaced by the rest mass of the photon\u2014which is zero. So the virtual exchange of a photon between two electrons gives an interaction energy that varies simply inversely as R , the distance between the two electrons\u2014just the normal Coulomb potential energy! In the \u201cparticle\u201d theory of electromagnetism, the process of a virtual photon exchange gives rise to all the phenomena of electrostatics. As our next two-state system we will look at the neutral hydrogen molecule H 2 . It is, naturally, more complicated to understand because it has two electrons. Again, we start by thinking of what happens when the two protons are well separated. Only now we have two electrons to add. To keep track of them, we\u2019ll call one of them \u201celectron a \u201d and the other \u201celectron b .\u201d We can again imagine two possible states. One possibility is that \u201celectron a \u201d is around the first proton and \u201celectron b \u201d is around the second, as shown in the top half of Fig. 10\u20134. We have simply two hydrogen atoms. We will call this state |1\u27e9 . There is also another possibility: that \u201celectron b \u201d is around the first proton and that \u201celectron a \u201d is around the second. We call this state |2\u27e9 . From the symmetry of the situation, those two possibilities should be energetically equivalent, but, as we will see, the energy of the system is not just the energy of two hydrogen atoms. We should mention that there are many other possibilities. For instance, \u201celectron a \u201d might be near the first proton and \u201celectron b \u201d might be in another state around the same proton. We\u2019ll disregard such a case, since it will certainly have higher energy (because of the large Coulomb repulsion between the two electrons). For greater accuracy, we would have to include such states, but we can get the essentials of the molecular binding by considering just the two states of Fig. 10\u20134. To this approximation we can describe any state by giving the amplitude \u27e81|\u03d5\u27e9 to be in the state |1\u27e9 and an amplitude \u27e82|\u03d5\u27e9 to be in state |2\u27e9 . In other words, the state vector |\u03d5\u27e9 can be written as the linear combination |\u03d5\u27e9= \u2211 i |i\u27e9\u27e8i|\u03d5\u27e9. \u2211 To proceed, we assume\u2014as usual\u2014that there is some amplitude A that the electrons can move through the intervening space and exchange places. This possibility of exchange means that the energy of the system is split, as we have seen for other two-state systems. As for the hydrogen molecular ion, the splitting is very small when the distance between the protons is large. As the protons approach each other, the amplitude for the electrons to go back and forth increases, so the splitting increases. The decrease of the lower energy state means that there is an attractive force which pulls the atoms together. Again the energy levels rise when the protons get very close together because of the Coulomb repulsion. The net final result is that the two stationary states have energies which vary with the separation as shown in Fig. 10\u20135. At a separation of about 0.74 \u00c5, the lower energy level reaches a minimum; this is the proton-proton distance of the true hydrogen molecule. Now you have probably been thinking of an objection. What about the fact that the two electrons are identical particles? We have been calling them \u201celectron a \u201d and \u201celectron b ,\u201d but there really is no way to tell which is which. And we have said in Chapter 4 that for electrons\u2014which are Fermi particles\u2014if there are two ways something can happen by exchanging the electrons, the two amplitudes will interfere with a negative sign. This means that if we switch which electron is which, the sign of the amplitude must reverse. We have just concluded, however, that the bound state of the hydrogen molecule would be (at t=0 ) |II\u27e9= 1 2 \u2013 \u221a (|1\u27e9+|2\u27e9). 1 However, according to our rules of Chapter 4, this state is not allowed. If we reverse which electron is which, we get the state 1 2 \u2013 \u221a (|2\u27e9+|1\u27e9). 1 and we get the same sign instead of the opposite one. These arguments are correct if both electrons have the same spin. It is true that if both electrons have spin up (or both have spin down), the only state that is permitted is |I\u27e9= 1 2 \u2013 \u221a (|1\u27e9\u2212|2\u27e9). 1 For this state, an interchange of the two electrons gives 1 2 \u2013 \u221a (|2\u27e9\u2212|1\u27e9). 1 which is \u2212|I\u27e9 , as required. So if we bring two hydrogen atoms near to each other with their electrons spinning in the same direction, they can go into the state |I\u27e9 and not state |II\u27e9 . But notice that state |I\u27e9 is the upper energy state. Its curve of energy versus separation has no minimum. The two hydrogens will always repel and will not form a molecule. So we conclude that the hydrogen molecule cannot exist with parallel electron spins. And that is right. On the other hand, our state |II\u27e9 is perfectly symmetric for the two electrons. In fact, if we interchange which electron we call a and which we call b we get back exactly the same state. We saw in Section 4\u20137 that if two Fermi particles are in the same state, they must have opposite spins. So, the bound hydrogen molecule must have one electron with spin up and one with spin down. The whole story of the hydrogen molecule is really somewhat more complicated if we want to include the proton spins. It is then no longer right to think of the molecule as a two-state system. It should really be looked at as an eight-state system\u2014there are four possible spin arrangements for each of our states |1\u27e9 and |2\u27e9 \u2014so we were cutting things a little short by neglecting the spins. Our final conclusions are, however, correct. We find that the lowest energy state\u2014the only bound state\u2014of the H 2 molecule has the two electrons with spins opposite. The total spin angular momentum of the electrons is zero. On the other hand, two nearby hydrogen atoms with spins parallel\u2014and so with a total angular momentum \u210f \u2014must be in a higher (unbound) energy state; the atoms repel each other. There is an interesting correlation between the spins and the energies. It gives another illustration of something we mentioned before, which is that there appears to be an \u201cinteraction\u201d energy between two spins because the case of parallel spins has a higher energy than the opposite case. In a certain sense you could say that the spins try to reach an antiparallel condition and, in doing so, have the potential to liberate energy\u2014not because there is a large magnetic force, but because of the exclusion principle. We saw in Section 10\u20131 that the binding of two different ions by a single electron is likely to be quite weak. This is not true for binding by two electrons. Suppose the two protons in Fig. 10\u20134 were replaced by any two ions (with closed inner electron shells and a single ionic charge), and that the binding energies of an electron at the two ions are different. The energies of states |1\u27e9 and |2\u27e9 would still be equal because in each of these states we have one electron bound to each ion. Therefore, we always have the splitting proportional to A . Two-electron binding is ubiquitous\u2014it is the most common valence bond. Chemical binding usually involves this flip-flop game played by two electrons. Although two atoms can be bound together by only one electron, it is relatively rare\u2014because it requires just the right conditions. Finally, we want to mention that if the energy of attraction for an electron to one nucleus is much greater than to the other, then what we have said earlier about ignoring other possible states is no longer right. Suppose nucleus a (or it may be a positive ion) has a much stronger attraction for an electron than does nucleus b . It may then happen that the total energy is still fairly low even when both electrons are at nucleus a , and no electron is at nucleus b . The strong attraction may more than compensate for the mutual repulsion of the two electrons. If it does, the lowest energy state may have a large amplitude to find both electrons at a (making a negative ion) and a small amplitude to find any electron at b . The state looks like a negative ion with a positive ion. This is, in fact, what happens in an \u201cionic\u201d molecule like NaCl. You can see that all the gradations between covalent binding and ionic binding are possible. You can now begin to see how it is that many of the facts of chemistry can be most clearly understood in terms of a quantum mechanical description. Chemists have invented nice diagrams to represent complicated organic molecules. Now we are going to discuss one of the most interesting of them\u2014the benzene molecule shown in Fig. 10\u20136. It contains six carbon and six hydrogen atoms in a symmetrical array. Each bar of the diagram represents a pair of electrons, with spins opposite, doing the covalent bond dance. Each hydrogen atom contributes one electron and each carbon atom contributes four electrons to make up the total of 30 electrons involved. (There are two more electrons close to the nucleus of the carbon which form the first, or K, shell. These are not shown since they are so tightly bound that they are not appreciably involved in the covalent binding.) So each bar in the figure represents a bond, or pair of electrons, and the double bonds mean that there are two pairs of electrons between alternate pairs of carbon atoms. There is a mystery about this benzene molecule. We can calculate what energy should be required to form this chemical compound, because the chemists have measured the energies of various compounds which involve pieces of the ring\u2014for instance, they know the energy of a double bond by studying ethylene, and so on. We can, therefore, calculate the total energy we should expect for the benzene molecule. The actual energy of the benzene ring, however, is much lower than we get by such a calculation; it is more tightly bound than we would expect from what is called an \u201cunsaturated double bond system.\u201d Usually a double bond system which is not in such a ring is easily attacked chemically because it has a relatively high energy\u2014the double bonds can be easily broken by the addition of other hydrogens. But in benzene the ring is quite permanent and hard to break up. In other words, benzene has a much lower energy than you would calculate from the bond picture. Then there is another mystery. Suppose we replace two adjacent hydrogens by bromine atoms to make ortho-dibromobenzene. There are two ways to do this, as shown in Fig. 10\u20137. The bromines could be on the opposite ends of a double bond as shown in part (a) of the figure, or could be on the opposite ends of a single bond as in (b). One would think that ortho-dibromobenzene should have two different forms, but it doesn\u2019t. There is only one such chemical.2 Now we want to resolve these mysteries\u2014and perhaps you have already guessed how: by noticing, of course, that the \u201cground state\u201d of the benzene ring is really a two-state system. We could imagine that the bonds in benzene could be in either of the two arrangements shown in Fig. 10\u20138. You say, \u201cBut they are really the same; they should have the same energy.\u201d Indeed, they should. And for that reason they must be analyzed as a two-state system. Each state represents a different configuration of the whole set of electrons, and there is some amplitude A that the whole bunch can switch from one arrangement to the other\u2014there is a chance that the electrons can flip from one dance to the other. As we have seen, this chance of flipping makes a mixed state whose energy is lower than you would calculate by looking separately at either of the two pictures in Fig. 10\u20138. Instead, there are two stationary states\u2014one with an energy above and one with an energy below the expected value. So actually, the true normal state (lowest energy) of benzene is neither of the possibilities shown in Fig. 10\u20138, but it has the amplitude 1/ 2 \u2013 \u221a to be in each of the states shown. It is the only state that is involved in the chemistry of benzene at normal temperatures. Incidentally, the upper state also exists; we can tell it is there because benzene has a strong absorption for ultraviolet light at the frequency \u03c9=( E I \u2212 E II )/\u210f . You will remember that in ammonia, where the object flipping back and forth was three protons, the energy separation was in the microwave region. In benzene, the objects are electrons, and because they are much lighter, they find it easier to flip back and forth, which makes the coefficient A very much larger. The result is that the energy difference is much larger\u2014about 3 eV, which is the energy of an ultraviolet photon.3 What happens if we substitute bromine? Again the two \u201cpossibilities\u201d (a) and (b) in Fig. 10\u20137 represent the two different electron configurations. The only difference is that the two base states we start with would have slightly different energies. The lowest energy stationary state will still involve a linear combination of the two states, but with unequal amplitudes. The amplitude for state |1\u27e9 might have a value something like 2/3 \u2212 \u2212 \u2212 \u221a , say, whereas state |2\u27e9 would have the magnitude 1/3 \u2212 \u2212 \u2212 \u221a . We can\u2019t say for sure without more information, but once the two energies H 11 and H 22 are no longer equal, then the amplitudes C 1 and C 2 no longer have equal magnitudes. This means, of course, that one of the two possibilities in the figure is more likely than the other, but the electrons are mobile enough so that there is some amplitude for both. The other state has different amplitudes (like 1/3 \u2212 \u2212 \u2212 \u221a and \u2212 2/3 \u2212 \u2212 \u2212 \u221a ) but lies at a higher energy. There is only one lowest state, not two as the naive theory of fixed chemical bonds would suggest. We will give you one more chemical example of the two-state phenomenon\u2014this time on a larger molecular scale. It has to do with the theory of dyes. Many dyes\u2014in fact, most artificial dyes\u2014have an interesting characteristic; they have a kind of symmetry. Figure 10\u20139 shows an ion of a particular dye called magenta, which has a purplish red color. The molecule has three ring structures\u2014two of which are benzene rings. The third is not exactly the same as a benzene ring because it has only two double bonds inside the ring. The figure shows two equally satisfactory pictures, and we would guess that they should have equal energies. But there is a certain amplitude that all the electrons can flip from one condition to the other, shifting the position of the \u201cunfilled\u201d position to the opposite end. With so many electrons involved, the flipping amplitude is somewhat lower than it is in the case of benzene, and the difference in energy between the two stationary states is smaller. There are, nevertheless, the usual two stationary states |I\u27e9 and |II\u27e9 which are the sum and difference combinations of the two base states shown in the figure. The energy separation of |I\u27e9 and |II\u27e9 comes out to be equal to the energy of a photon in the optical region. If one shines light on the molecule, there is a very strong absorption at one frequency, and it appears to be brightly colored. That\u2019s why it\u2019s a dye! Another interesting feature of such a dye molecule is that in the two base states shown, the center of electric charge is located at different places. As a result, the molecule should be strongly affected by an external electric field. We had a similar effect in the ammonia molecule. Evidently we can analyze it by using exactly the same mathematics, provided we know the numbers E 0 and A . Generally, these are obtained by gathering experimental data. If one makes measurements with many dyes, it is often possible to guess what will happen with some related dye molecule. Because of the large shift in the position of the center of electric charge the value of \u03bc in formula (9.55) is large and the material has a high probability for absorbing light of the characteristic frequency 2A/\u210f . Therefore, it is not only colored but very strongly so\u2014a small amount of substance absorbs a lot of light. The rate of flipping\u2014and, therefore, A \u2014is very sensitive to the complete structure of the molecule. By changing A , the energy splitting, and with it the color of the dye, can be changed. Also, the molecules do not have to be perfectly symmetrical. We have seen that the same basic phenomenon exists with slight modifications, even if there is some small asymmetry present. So, one can get some modification of the colors by introducing slight asymmetries in the molecules. For example, another important dye, malachite green, is very similar to magenta, but has two of the hydrogens replaced by CH 3 . It\u2019s a different color because the A is shifted and the flip-flop rate is changed. Now we would like to discuss a two-state system involving an object of spin one-half. Some of what we will say has been covered in earlier chapters, but doing it again may help to make some of the puzzling points a little clearer. We can think of an electron at rest as a two-state system. Although we will be talking in this section about \u201can electron,\u201d what we find out will be true for any spin one-half particle. Suppose we choose for our base states |1\u27e9 and |2\u27e9 the states in which the z -component of the electron spin is +\u210f/2 and \u2212\u210f/2 . These states are, of course, the same ones we have called (+) and (\u2212) in earlier chapters. To keep the notation of this chapter consistent, though, we call the \u201cplus\u201d spin state |1\u27e9 and the \u201cminus\u201d spin state |2\u27e9 \u2014where \u201cplus\u201d and \u201cminus\u201d refer to the angular momentum in the z -direction. Any possible state \u03c8 for the electron can be described as in Eq. (10.1) by giving the amplitude C 1 that the electron is in state |1\u27e9 , and the amplitude C 2 that it is in state |2\u27e9 . To treat this problem, we will need to know the Hamiltonian for this two-state system\u2014that is, for an electron in a magnetic field. We begin with the special case of a magnetic field in the z -direction. Suppose that the vector B has only a z -component B z . From the definition of the two base states (that is, spins parallel and antiparallel to B ) we know that they are already stationary states with a definite energy in the magnetic field. State |1\u27e9 corresponds to an energy4 equal to \u2212\u03bc B z and state |2\u27e9 to +\u03bc B z . The Hamiltonian must be very simple in this case since C 1 , the amplitude to be in state |1\u27e9 , is not affected by C 2 , and vice versa: i\u210f d C 1 dt i\u210f d C 2 dt = E 1 C 1 =\u2212\u03bc B z C 1 , = E 2 C 2 =+\u03bc B z C 2 . (10.17) For this special case, the Hamiltonian is H 11 H 21 =\u2212\u03bc B z , =0, H 12 H 22 =0, =+\u03bc B z . (10.18) So we know what the Hamiltonian is for the magnetic field in the z -direction, and we know the energies of the stationary states. Now suppose the field is not in the z -direction. What is the Hamiltonian? How are the matrix elements changed if the field is not in the z -direction? We are going to make an assumption that there is a kind of superposition principle for the terms of the Hamiltonian. More specifically, we want to assume that if two magnetic fields are superposed, the terms in the Hamiltonian simply add\u2014if we know the H ij for a pure B z and we know the H ij for a pure B x , then the H ij for both B z and B x together is simply the sum. This is certainly true if we consider only fields in the z -direction\u2014if we double B z , then all the H ij are doubled. So let\u2019s assume that H is linear in the field B . That\u2019s all we need to be able to find the H ij for any magnetic field. Suppose we have a constant field B . We could have chosen our z -axis in its direction, and we would have found two stationary states with the energies \u2213\u03bcB . Just choosing our axes in a different direction won\u2019t change the physics. Our description of the stationary states will be different, but their energies will still be \u2213\u03bcB \u2014that is, E I E II =\u2212\u03bc B 2 x + B 2 y + B 2 z \u2212 \u2212 \u2212 \u2212 \u2212 \u2212 \u2212 \u2212 \u2212 \u2212 \u2212 \u221a , =+\u03bc B 2 x + B 2 y + B 2 z \u2212 \u2212 \u2212 \u2212 \u2212 \u2212 \u2212 \u2212 \u2212 \u2212 \u2212 \u221a . (10.19) The rest of the game is easy. We have here the formulas for the energies. We want a Hamiltonian which is linear in B x , B y , and B z , and which will give these energies when used in our general formula of Eq. (10.3). The problem: find the Hamiltonian. First, notice that the energy splitting is symmetric, with an average value of zero. Looking at Eq. (10.3), we can see directly that that requires H 22 =\u2212 H 11 . H H (Note that this checks with what we already know when B x and B y are both zero; in that case H 11 =\u2212\u03bc B z , and H 22 =\u03bc B z .) Now if we equate the energies of Eq. (10.3) with what we know from Eq. (10.19), we have ( H 11 \u2212 H 22 2 ) 2 +| H 12 | 2 = \u03bc 2 ( B 2 x + B 2 y + B 2 z ). (10.20) (We have also made use of the fact that H 21 = H \u2217 12 , so that H 12 H 21 can also be written as | H 12 | 2 .) Again for the special case of a field in the z -direction, this gives \u03bc 2 B 2 z +| H 12 | 2 = \u03bc 2 B 2 z . 2 2 2 Clearly, | H 12 | must be zero in this special case, which means that H 12 cannot have any terms in B z . (Remember, we have said that all terms must be linear in B x , B y , and B z .) So far, then, we have discovered that H 11 and H 22 have terms in B z , while H 12 and H 21 do not. We can make a simple guess that will satisfy Eq. (10.20) if we say that H 11 H 22 =\u2212\u03bc B z , =\u03bc B z , and | H 12 | 2 = \u03bc 2 ( B 2 x + B 2 y ). (10.21) And it turns out that that\u2019s the only way it can be done! \u201cWait\u201d\u2014you say\u2014\u201c H 12 is not linear in B ; Eq. (10.21) gives H 12 = \u03bc B 2 x + B 2 y \u2212 \u2212 \u2212 \u2212 \u2212 \u2212 \u2212 \u221a .\u201d Not necessarily. There is another possibility which is linear, namely, H 12 =\u03bc( B x +i B y ). ( ) There are, in fact, several such possibilities\u2014most generally, we could write H 12 =\u03bc( B x \u00b1i B y ) e i\u03b4 , i \u03b4 where \u03b4 is some arbitrary phase. Which sign and phase should we use? It turns out that you can choose either sign, and any phase you want, and the physical results will always be the same. So the choice is a matter of convention. People ahead of us have chosen to use the minus sign and to take e i\u03b4 =\u22121 . We might as well follow suit and write H 12 =\u2212\u03bc( B x \u2212i B y ), H 21 =\u2212\u03bc( B x +i B y ). ( ) ( ) (Incidentally, these conventions are related to, and consistent with, some of the arbitrary choices we made in Chapter 6.) The complete Hamiltonian for an electron in an arbitrary magnetic field is, then H 11 H 21 =\u2212\u03bc B z , =\u2212\u03bc( B x +i B y ), H 12 H 22 =\u2212\u03bc( B x \u2212i B y ), =+\u03bc B z . (10.22) And the equations for the amplitudes C 1 and C 2 are i\u210f d C 1 dt i\u210f d C 2 dt =\u2212\u03bc[ B z C 1 +( B x \u2212i B y ) C 2 ], =\u2212\u03bc[( B x +i B y ) C 1 \u2212 B z C 2 ]. (10.23) So we have discovered the \u201cequations of motion for the spin states\u201d of an electron in a magnetic field. We guessed at them by making some physical argument, but the real test of any Hamiltonian is that it should give predictions in agreement with experiment. According to any tests that have been made, these equations are right. In fact, although we made our arguments only for constant fields, the Hamiltonian we have written is also right for magnetic fields which vary with time. So we can now use Eq. (10.23) to look at all kinds of interesting problems. Example number one: We start with a constant field in the z -direction. There are just the two stationary states with energies \u2213\u03bc B z . Suppose we add a small field in the x -direction. Then the equations look like our old two-state problem. We get the flip-flop business once more, and the energy levels are split a little farther apart. Now let\u2019s let the x -component of the field vary with time\u2014say, as cos\u03c9t . The equations are then the same as we had when we put an oscillating electric field on the ammonia molecule in Chapter 9. You can work out the details in the same way. You will get the result that the oscillating field causes transitions from the +z -state to the \u2212z -state\u2014and vice versa\u2014when the horizontal field oscillates near the resonant frequency \u03c9 0 =2\u03bc B z /\u210f . This gives the quantum mechanical theory of the magnetic resonance phenomena we described in Chapter 35 of Volume II. It is also possible to make a maser which uses a spin one-half system. A Stern-Gerlach apparatus is used to produce a beam of particles polarized in, say, the +z -direction, which are sent into a cavity in a constant magnetic field. The oscillating fields in the cavity can couple with the magnetic moment and induce transitions which give energy to the cavity. Now let\u2019s look at the following question. Suppose we have a magnetic field B which points in the direction whose polar angle is \u03b8 and azimuthal angle is \u03d5 , as in Fig. 10\u201310. Suppose, additionally, that there is an electron which has been prepared with its spin pointing along this field. What are the amplitudes C 1 and C 2 for such an electron? In other words, calling the state of the electron |\u03c8\u27e9 , we want to write |\u03c8\u27e9=|1\u27e9 C 1 +|2\u27e9 C 2 , | \u03c8 \u27e9 | \u27e9 | \u27e9 where C 1 and C 2 are C 1 =\u27e81|\u03c8\u27e9, C 2 =\u27e82|\u03c8\u27e9, \u27e8 | \u03c8 \u27e9 \u27e8 | \u03c8 \u27e9 where by |1\u27e9 and |2\u27e9 we mean the same thing we used to call |+\u27e9 and |\u2212\u27e9 (referred to our chosen z -axis). The answer to this question is also in our general equations for two-state systems. First, we know that since the electron\u2019s spin is parallel to B it is in a stationary state with energy E I =\u2212\u03bcB . Therefore, both C 1 and C 2 must vary as e \u2212i E I t/\u210f , as in (9.18); and their coefficients a 1 and a 2 are given by (10.5), namely, a 1 a 2 = H 12 E I \u2212 H 11 . (10.24) An additional condition is that a 1 and a 2 should be normalized so that | a 1 | 2 +| a 2 | 2 =1 . We can take H 11 and H 12 from (10.22) using B z B x B y =Bcos\u03b8, =Bsin\u03b8cos\u03d5, =Bsin\u03b8sin\u03d5. So we have H 11 H 12 =\u2212\u03bcBcos\u03b8, =\u2212\u03bcBsin\u03b8(cos\u03d5\u2212isin\u03d5). (10.25) The last factor in the second equation is, incidentally, e \u2212i\u03d5 , so it is simpler to write H 12 =\u2212\u03bcBsin\u03b8 e \u2212i\u03d5 . (10.26) Using these matrix elements in Eq. (10.24)\u2014and canceling \u2212\u03bcB from numerator and denominator\u2014we find a 1 a 2 = sin\u03b8 e \u2212i\u03d5 1\u2212cos\u03b8 . (10.27) With this ratio and the normalization condition, we can find both a 1 and a 2 . That\u2019s not hard, but we can make a short cut with a little trick. Notice that 1\u2212cos\u03b8=2 sin 2 (\u03b8/2) , and that sin\u03b8=2sin(\u03b8/2)cos(\u03b8/2) . Then Eq. (10.27) is equivalent to a 1 a 2 = cos \u03b8 2 e \u2212i\u03d5 sin \u03b8 2 . (10.28) So one possible answer is a 1 =cos \u03b8 2 e \u2212i\u03d5 , a 2 =sin \u03b8 2 , (10.29) since it fits with (10.28) and also makes | a 1 | 2 +| a 2 | 2 =1. 2 2 As you know, multiplying both a 1 and a 2 by an arbitrary phase factor doesn\u2019t change anything. People generally prefer to make Eqs. (10.29) more symmetric by multiplying both by e i\u03d5/2 . So the form usually used is a 1 =cos \u03b8 2 e \u2212i\u03d5/2 , a 2 =sin \u03b8 2 e +i\u03d5/2 , (10.30) and this is the answer to our question. The numbers a 1 and a 2 are the amplitudes to find an electron with its spin up or down along the z -axis when we know that its spin is along the axis at \u03b8 and \u03d5 . (The amplitudes C 1 and C 2 are just a 1 and a 2 times e \u2212i E I t/\u210f .) Now we notice an interesting thing. The strength B of the magnetic field does not appear anywhere in (10.30). The result is clearly the same in the limit that B goes to zero. This means that we have answered in general the question of how to represent a particle whose spin is along an arbitrary axis. The amplitudes of (10.30) are the projection amplitudes for spin one-half particles corresponding to the projection amplitudes we gave in Chapter 5 [Eqs. (5.38)] for spin-one particles. We can now find the amplitudes for filtered beams of spin one-half particles to go through any particular Stern-Gerlach filter. Let |+z\u27e9 represent a state with spin up along the z -axis, and |\u2212z\u27e9 represent the spin down state. If |+ z \u2032 \u27e9 represents a state with spin up along a z \u2032 -axis which makes the polar angles \u03b8 and \u03d5 with the z -axis, then in the notation of Chapter 5, we have \u27e8+z|+ z \u2032 \u27e9 \u27e8\u2212z|+ z \u2032 \u27e9 =cos \u03b8 2 e \u2212i\u03d5/2 , =sin \u03b8 2 e +i\u03d5/2 . (10.31) These results are equivalent to what we found in Chapter 6, Eq. (6.36), by purely geometrical arguments. (So if you decided to skip Chapter 6, you now have the essential results anyway.) As our final example lets look again at one which we\u2019ve already mentioned a number of times. Suppose that we consider the following problem. We start with an electron whose spin is in some given direction, then turn on a magnetic field in the z -direction for 25 minutes, and then turn it off. What is the final state? Again let\u2019s represent the state by the linear combination |\u03c8\u27e9=|1\u27e9 C 1 +|2\u27e9 C 2 . For this problem, however, the states of definite energy are also our base states |1\u27e9 and |2\u27e9 . So C 1 and C 2 only vary in phase. We know that C 1 (t)= C 1 (0) e \u2212i E I t/\u210f = C 1 (0) e +i\u03bcBt/\u210f , i E / \u210f i B / \u210f and C 2 (t)= C 2 (0) e \u2212i E II t/\u210f = C 2 (0) e \u2212i\u03bcBt/\u210f . i E / \u210f i B / \u210f Now initially we said the electron spin was set in a given direction. That means that initially C 1 and C 2 are two numbers given by Eqs. (10.30). After we wait for a period of time T , the new C 1 and C 2 are the same two numbers multiplied respectively by e i\u03bc B z T/\u210f and e \u2212i\u03bc B z T/\u210f . What state is that? That\u2019s easy. It\u2019s exactly the same as if the angle \u03d5 had been changed by the subtraction of 2\u03bc B z T/\u210f and the angle \u03b8 had been left unchanged. That means that at the end of the time T , the state |\u03c8\u27e9 represents an electron lined up in a direction which differs from the original direction only by a rotation about the z -axis through the angle \u0394\u03d5=2\u03bc B z T/\u210f . Since this angle is proportional to T , we can also say the direction of the spin precesses at the angular velocity 2\u03bc B z /\u210f around the z -axis. This result we discussed several times previously in a less complete and rigorous manner. Now we have obtained a complete and accurate quantum mechanical description of the precession of atomic magnets. It is interesting that the mathematical ideas we have just gone over for the spinning electron in a magnetic field can be applied to any two-state system. That means that by making a mathematical analogy to the spinning electron, any problem about two-state systems can be solved by pure geometry. It works like this. First you shift the zero of energy so that ( H 11 + H 22 ) is equal to zero so that H 11 =\u2212 H 22 . Then any two-state problem is formally the same as the electron in a magnetic field. All you have to do is identify \u2212\u03bc B z with H 11 and \u2212\u03bc( B x \u2212i B y ) with H 12 . No matter what the physics is originally\u2014an ammonia molecule, or whatever\u2014you can translate it into a corresponding electron problem. So if we can solve the electron problem in general, we have solved all two-state problems. And we have the general solution for the electron! Suppose you have some state to start with that has spin \u201cup\u201d in some direction, and you have a magnetic field B that points in some other direction. You just rotate the spin direction around the axis of B with the vector angular velocity \u03c9(t) equal to a constant times the vector B (namely \u03c9=2\u03bcB/\u210f ). As B varies with time, you keep moving the axis of the rotation to keep it parallel with B , and keep changing the speed of rotation so that it is always proportional to the strength of B . See Fig. 10\u201311. If you keep doing this, you will end up with a certain final orientation of the spin axis, and the amplitudes C 1 and C 2 are just given by the projections\u2014using (10.30)\u2014into your coordinate frame. You see, it\u2019s just a geometric problem to keep track of where you end up after all the rotating. Although it\u2019s easy to see what\u2019s involved, this geometric problem (of finding the net result of a rotation with a varying angular velocity vector) is not easy to solve explicitly in the general case. Anyway, we see, in principle, the general solution to any two-state problem. In the next chapter we will look some more into the mathematical techniques for handling the important case of a spin one-half particle\u2014and, therefore, for handling two-state systems in general."
    },
    {
        "input": "Spin One-Half",
        "output": "In the last chapter, using a system of spin one as an example, we outlined the general principles of quantum mechanics: Any state \u03c8 can be described in terms of a set of base states by giving the amplitudes to be in each of the base states. The amplitude to go from any state to another can, in general, be written as a sum of products, each product being the amplitude to go into one of the base states times the amplitude to go from that base state to the final condition, with the sum including a term for each base state: \u27e8\u03c7|\u03c8\u27e9= \u2211 i \u27e8\u03c7|i\u27e9\u27e8i|\u03c8\u27e9. The base states are orthogonal\u2014the amplitude to be in one if you are in the other is zero: \u27e8i|j\u27e9=\u03b4ij. The amplitude to get from one state to another directly is the complex conjugate of the reverse: \u27e8\u03c7|\u03c8\u27e9\u2217=\u27e8\u03c8|\u03c7\u27e9. We also discussed a little bit about the fact that there can be more than one base for the states and that we can use Eq. (6.1) to convert from one base to another. Suppose, for example, that we have the amplitudes \u27e8iS|\u03c8\u27e9 to find the state \u03c8 in every one of the base states i of a base system S , but that we then decide that we would prefer to describe the state in terms of another set of base states, say the states j belonging to the base T . In the general formula, Eq. (6.1), we could substitute jT for \u03c7 and obtain this formula: \u27e8jT|\u03c8\u27e9= \u2211 i \u27e8jT|iS\u27e9\u27e8iS|\u03c8\u27e9. The amplitudes for the state (\u03c8) to be in the base states (jT) are related to the amplitudes to be in the base states (iS) by the set of coefficients \u27e8jT|iS\u27e9 . If there are N base states, there are N2 such coefficients. Such a set of coefficients is often called the \u201ctransformation matrix to go from the S -representation to the T -representation.\u201d This looks rather formidable mathematically, but with a little renaming we can see that it is really not so bad. If we call Ci the amplitude that the state \u03c8 is in the base state iS \u2014that is, Ci=\u27e8iS|\u03c8\u27e9 \u2014and call C \u2032 j the corresponding amplitudes for the base system T \u2014that is, C \u2032 j =\u27e8jT|\u03c8\u27e9 , then Eq. (6.4) can be written as C \u2032 j = \u2211 i RjiCi, where Rji means the same thing as \u27e8jT|iS\u27e9 . Each amplitude C \u2032 j is equal to a sum over all i of one of the coefficients Rji times each amplitude Ci . It has the same form as the transformation of a vector from one coordinate system to another. In order to avoid being too abstract for too long, we have given you some examples of these coefficients for the spin-one case, so you can see how to use them in practice. On the other hand, there is a very beautiful thing in quantum mechanics\u2014that from the sheer fact that there are three states and from the symmetry properties of space under rotations, these coefficients can be found purely by abstract reasoning. Showing you such arguments at this early stage has a disadvantage in that you are immersed in another set of abstractions before we get \u201cdown to earth.\u201d However, the thing is so beautiful that we are going to do it anyway. We will show you in this chapter how the transformation coefficients can be derived for spin one-half particles. We pick this case, rather than spin one, because it is somewhat easier. Our problem is to determine the coefficients Rji for a particle\u2014an atomic system\u2014which is split into two beams in a Stern-Gerlach apparatus. We are going to derive all the coefficients for the transformation from one representation to another by pure reasoning\u2014plus a few assumptions. Some assumptions are always necessary in order to use \u201cpure\u201d reasoning! Although the arguments will be abstract and somewhat involved, the result we get will be relatively simple to state and easy to understand\u2014and the result is the most important thing. You may, if you wish, consider this as a sort of cultural excursion. We have, in fact, arranged that all the essential results derived here are also derived in some other way when they are needed in later chapters. So you need have no fear of losing the thread of our study of quantum mechanics if you omit this chapter entirely, or study it at some later time. The excursion is \u201ccultural\u201d in the sense that it is intended to show that the principles of quantum mechanics are not only interesting, but are so deep that by adding only a few extra hypotheses about the structure of space, we can deduce a great many properties of physical systems. Also, it is important that we know where the different consequences of quantum mechanics come from, because so long as our laws of physics are incomplete\u2014as we know they are\u2014it is interesting to find out whether the places where our theories fail to agree with experiment is where our logic is the best or where our logic is the worst. Until now, it appears that where our logic is the most abstract it always gives correct results\u2014it agrees with experiment. Only when we try to make specific models of the internal machinery of the fundamental particles and their interactions are we unable to find a theory that agrees with experiment. The theory then that we are about to describe agrees with experiment wherever it has been tested\u2014for the strange particles as well as for electrons, protons, and so on. One remark on an annoying, but interesting, point before we proceed: It is not possible to determine the coefficients Rji uniquely, because there is always some arbitrariness in the probability amplitudes. If you have a set of amplitudes of any kind, say the amplitudes to arrive at some place by a whole lot of different routes, and if you multiply every single amplitude by the same phase factor\u2014say by ei\u03b4 \u2014you have another set that is just as good. So, it is always possible to make an arbitrary change in phase of all the amplitudes in any given problem if you want to. Suppose you calculate some probability by writing a sum of several amplitudes, say (A+B+C+\u22ef) and taking the absolute square. Then somebody else calculates the same thing by using the sum of the amplitudes (A\u2032+B\u2032+C\u2032+\u22ef) and taking the absolute square. If all the A\u2032 , B\u2032 , C\u2032 , etc., are equal to the A , B , C , etc., except for a factor ei\u03b4 , all probabilities obtained by taking the absolute squares will be exactly the same, since (A\u2032+B\u2032+C\u2032+\u22ef) is then equal to ei\u03b4(A+B+C+\u22ef) . Or suppose, for instance, that we were computing something with Eq. (6.1), but then we suddenly change all of the phases of a certain base system. Every one of the amplitudes \u27e8i|\u03c8\u27e9 would be multiplied by the same factor ei\u03b4 . Similarly, the amplitudes \u27e8i|\u03c7\u27e9 would also be changed by ei\u03b4 , but the amplitudes \u27e8\u03c7|i\u27e9 are the complex conjugates of the amplitudes \u27e8i|\u03c7\u27e9 ; therefore, the former gets changed by the factor e\u2212i\u03b4 . The plus and minus i\u03b4 \u2019s in the exponents cancel out, and we would have the same expression we had before. So it is a general rule that if we change all the amplitudes with respect to a given base system by the same phase\u2014or even if we just change all the amplitudes in any problem by the same phase\u2014it makes no difference. There is, therefore, some freedom to choose the phases in our transformation matrix. Every now and then we will make such an arbitrary choice\u2014usually following the conventions that are in general use. We consider again the \u201cimproved\u201d Stern-Gerlach apparatus described in the last chapter. A beam of spin one-half particles, entering at the left, would, in general, be split into two beams, as shown schematically in Fig. 6-1. (There were three beams for spin one.) As before, the beams are put back together again unless one or the other of them is blocked off by a \u201cstop\u201d which intercepts the beam at its half-way point. In the figure we show an arrow which points in the direction of the increase of the magnitude of the field\u2014say toward the magnet pole with the sharp edges. This arrow we take to represent the \u201cup\u201d axis of any particular apparatus. It is fixed relative to the apparatus and will allow us to indicate the relative orientations when we use several apparatuses together. We also assume that the direction of the magnetic field in each magnet is always the same with respect to the arrow. We will say that those atoms which go in the \u201cupper\u201d beam are in the (+) state with respect to that apparatus and that those in the \u201clower\u201d beam are in the (\u2212) state. (There is no \u201czero\u201d state for spin one-half particles.) Now suppose we put two of our modified Stern-Gerlach apparatuses in sequence, as shown in Fig. 6-2(a). The first one, which we call S , can be used to prepare a pure (+S) or a pure (\u2212S) state by blocking one beam or the other. [As shown it prepares a pure (+S) state.] For each condition, there is some amplitude for a particle that comes out of S to be in either the (+T) or the (\u2212T) beam of the second apparatus. There are, in fact, just four amplitudes: the amplitude to go from (+S) to (+T) , from (+S) to (\u2212T) , from (\u2212S) to (+T) , from (\u2212S) to (\u2212T) . These amplitudes are just the four coefficients of the transformation matrix Rji to go from the S -representation to the T -representation. We can consider that the first apparatus \u201cprepares\u201d a particular state in one representation and that the second apparatus \u201canalyzes\u201d that state in terms of the second representation. The kind of question we want to answer, then, is this: If an atom has been prepared in a given condition\u2014say the (+S) state\u2014by blocking one of the beams in the apparatus S , what is the chance that it will get through the second apparatus T if this is set for, say, the (\u2212T) state. The result will depend, of course, on the angles between the two systems S and T . We should explain why it is that we could have any hope of finding the coefficients Rji by deduction. You know that it is almost impossible to believe that if a particle has its spin lined up in the +z -direction, that there is some chance of finding the same particle with its spin pointing in the +x -direction\u2014or in any other direction at all. In fact, it is almost impossible, but not quite. It is so nearly impossible that there is only one way it can be done, and that is the reason we can find out what that unique way is. The first kind of argument we can make is this. Suppose we have a setup like the one in Fig. 6-2(a), in which we have the two apparatuses S and T , with T cocked at the angle \u03b1 with respect to S , and we let only the (+) beam through S and the (\u2212) beam through T . We would observe a certain number for the probability that the particles coming out of S get through T . Now suppose we make another measurement with the apparatus of Fig. 6-2(b). The relative orientation of S and T is the same, but the whole system sits at a different angle in space. We want to assume that both of these experiments give the same number for the chance that a particle in a pure state with respect to S will get into some particular state with respect to T . We are assuming, in other words, that the result of any experiment of this type is the same\u2014that the physics is the same\u2014no matter how the whole apparatus is oriented in space. (You say, \u201cThat\u2019s obvious.\u201d But it is an assumption, and it is \u201cright\u201d only if it is actually what happens.) That means that the coefficients Rji depend only on the relation in space of S and T , and not on the absolute situation of S and T . To say this in another way, Rji depends only on the rotation which carries S to T , for evidently what is the same in Fig. 6-2(a) and Fig. 6-2(b) is the three-dimensional rotation which would carry apparatus S into the orientation of apparatus T . When the transformation matrix Rji depends only on a rotation, as it does here, it is called a rotation matrix. For our next step we will need one more piece of information. Suppose we add a third apparatus which we can call U , which follows T at some arbitrary angle, as in Fig. 6-3(a). (It\u2019s beginning to look horrible, but that\u2019s the fun of abstract thinking\u2014you can make the most weird experiments just by drawing lines!) Now what is the S\u2192T\u2192U transformation? What we really want to ask for is the amplitude to go from some state with respect to S to some other state with respect to U , when we know the transformation from S to T and from T to U . We are then asking about an experiment in which both channels of T are open. We can get the answer by applying Eq. (6.5) twice in succession. For going from the S -representation to the T -representation, we have C \u2032 j = \u2211 i R TS ji Ci, where we put the superscripts TS on the R , so that we can distinguish it from the coefficients RUT we will have for going from T to U . Assuming the amplitudes to be in the base states of the U -representation C \u2033 k , we can relate them to the T -amplitudes by using Eq. (6.5) once more; we get C \u2033 k = \u2211 j R UT kj C \u2032 j . Now we can combine Eqs. (6.6) and (6.7) to get the transformation to U directly from S . Substituting C \u2032 j from Eq. (6.6) in Eq. (6.7), we have C \u2033 k = \u2211 j R UT kj \u2211 i R TS ji Ci. Or, since i does not appear in R UT kj , we can put the i -summation also in front, and write C \u2033 k = \u2211 i \u2211 j R UT kj R TS ji Ci. This is the formula for a double transformation. Notice, however, that so long as all the beams in T are unblocked, the state coming out of T is the same as the one that went in. We could just as well have made a transformation from the S -representation directly to the U -representation. It should be the same as putting the U apparatus right after S , as in Fig. 6-3(b). In that case, we would have written C \u2033 k = \u2211 i R US ki Ci, with the coefficients R US ki belonging to this transformation. Now, clearly, Eqs. (6.9) and (6.10) should give the same amplitudes C \u2033 k , and this should be true no matter what the original state \u03d5 was which gave us the amplitudes Ci . So it must be that R US ki = \u2211 j R UT kj R TS ji . In other words, for any rotation S\u2192U of a reference base, which is viewed as a compounding of two successive rotations S\u2192T and T\u2192U , the rotation matrix R US ki can be obtained from the matrices of the two partial rotations by Eq. (6.11). If you wish, you can find Eq. (6.11) directly from Eq. (6.1), for it is only a different notation for \u27e8kU|iS\u27e9=\u2211j\u27e8kU|jT\u27e9\u27e8jT|iS\u27e9 . To be thorough, we should add the following parenthetical remarks. They are not terribly important, however, so you can skip to the next section if you want. What we have said is not quite right. We cannot really say that Eq. (6.9) and Eq. (6.10) must give exactly the same amplitudes. Only the physics should be the same; all the amplitudes could be different by some common phase factor like e i\u03b4 without changing the result of any calculation about the real world. So, instead of Eq. (6.11), all we can say, really, is that e i\u03b4 R US ki = \u2211 j R UT kj R TS ji , (6.12) where \u03b4 is some real constant. What this extra factor of e i\u03b4 means, of course, is that the amplitudes we get if we use the matrix R US might all differ by the same phase ( e \u2212i\u03b4 ) from the amplitude we would get using the two rotations R UT and R TS . We know that it doesn\u2019t matter if all amplitudes are changed by the same phase, so we could just ignore this phase factor if we wanted to. It turns out, however, that if we define all of our rotation matrices in a particular way, this extra phase factor will never appear\u2014the \u03b4 in Eq. (6.12) will always be zero. Although it is not important for the rest of our arguments, we can give a quick proof by using a mathematical theorem about determinants. [If you don\u2019t yet know much about determinants, don\u2019t worry about the proof and just skip to the definition of Eq. (6.15).] First, we should say that Eq. (6.11) is the mathematical definition of a \u201cproduct\u201d of two matrices. (It is just convenient to be able to say: \u201c R US is the product of R UT and R TS .\u201d ) Second, there is a theorem of mathematics\u2014which you can easily prove for the two-by-two matrices we have here\u2014which says that the determinant of a \u201cproduct\u201d of two matrices is the product of their determinants. Applying this theorem to Eq. (6.12), we get e i2\u03b4 (Det R US )=(Det R UT )\u22c5(Det R TS ). (6.13) (We leave off the subscripts, because they don\u2019t tell us anything useful.) Yes, the 2\u03b4 is right. Remember that we are dealing with two-by-two matrices; every term in the matrix R US ki is multiplied by e i\u03b4 , so each product in the determinant\u2014which has two factors\u2014gets multiplied by e i2\u03b4 . Now let\u2019s take the square root of Eq. (6.13) and divide it into Eq. (6.12); we get R US ki Det R US \u2212 \u2212 \u2212 \u2212 \u2212 \u2212 \u2212 \u221a = \u2211 j R UT kj Det R UT \u2212 \u2212 \u2212 \u2212 \u2212 \u2212 \u2212 \u221a R TS ji Det R TS \u2212 \u2212 \u2212 \u2212 \u2212 \u2212 \u2212 \u221a . (6.14) The extra phase factor has disappeared. Now it turns out that if we want all of our amplitudes in any given representation to be normalized (which means, you remember, that \u2211 i \u27e8\u03d5|i\u27e9\u27e8i|\u03d5\u27e9=1 ), the rotation matrices will all have determinants that are pure imaginary exponentials, like e i\u03b1 . (We won\u2019t prove it; you will see that it always comes out that way.) So we can, if we wish, choose to make all our rotation matrices R have a unique phase by making Det R=1 . It is done like this. Suppose we find a rotation matrix R in some arbitrary way. We make it a rule to \u201cconvert\u201d it to \u201cstandard form\u201d by defining R standard = R Det R \u2212 \u2212 \u2212 \u2212 \u2212 \u221a . (6.15) We can do this because we are just multiplying each term of R by the same phase factor, to get the phases we want. In what follows, we will always assume that our matrices have been put in the \u201cstandard form\u201d ; then we can use Eq. (6.11) without having any extra phase factors. We are now ready to find the transformation matrix R ji between two different representations. With our rule for compounding rotations and our assumption that space has no preferred direction, we have the keys we need for finding the matrix of any arbitrary rotation. There is only one solution. We begin with the transformation which corresponds to a rotation about the z -axis. Suppose we have two apparatuses S and T placed in series along a straight line with their axes parallel and pointing out of the page, as shown in Fig. 6-4(a). We take our \u201c z -axis\u201d in this direction. Surely, if the beam goes \u201cup\u201d (toward +z ) in the S apparatus, it will do the same in the T apparatus. Similarly, if it goes down in S , it will go down in T . Suppose, however, that the T apparatus were placed at some other angle, but still with its axis parallel to the axis of S , as in Fig. 6-4(b). Intuitively, you would say that a (+) beam in S would still go with a (+) beam in T , because the fields and field gradients are still in the same physical direction. And that would be quite right. Also, a (\u2212) beam in S would still go into a (\u2212) beam in T . The same result would apply for any orientation of T in the xy -plane of S . What does this tell us about the relation between C \u2032 + =\u27e8+T|\u03c8\u27e9 , C \u2032 \u2212 =\u27e8\u2212T|\u03c8\u27e9 and C + =\u27e8+S|\u03c8\u27e9 , C \u2212 =\u27e8\u2212S|\u03c8\u27e9 ? You might conclude that any rotation about the z -axis of the \u201cframe of reference\u201d for base states leaves the amplitudes to be \u201cup\u201d and \u201cdown\u201d the same as before. We could write C \u2032 + = C + and C \u2032 \u2212 = C \u2212 \u2014but that is wrong. All we can conclude is that for such rotations the probabilities to be in the \u201cup\u201d beam are the same for the S and T apparatuses. That is, | C \u2032 + |=| C + |and| C \u2032 \u2212 |=| C \u2212 |. \u2032 \u2032 We cannot say that the phases of the amplitudes referred to the T apparatus may not be different for the two different orientations in (a) and (b) of Fig. 6-4. The two apparatuses in (a) and (b) of Fig. 6-4 are, in fact, different, as we can see in the following way. Suppose that we put an apparatus in front of S which produces a pure (+x) state. (The x -axis points toward the bottom of the figure.) Such particles would be split into (+z) and (\u2212z) beams in S , but the two beams would be recombined to give a (+x) state again at P 1 \u2014the exit of S . The same thing happens again in T . If we follow T by a third apparatus U , whose axis is in the (+x) direction and, as shown in Fig. 6-5(a), all the particles would go into the (+) beam of U . Now imagine what happens if T and U are swung around together by 90 \u2218 to the positions shown in Fig. 6-5(b). Again, the T apparatus puts out just what it takes in, so the particles that enter U are in a (+x) state with respect to S . But U now analyzes for the (+y) state with respect to S , which is different. (By symmetry, we would now expect only one-half of the particles to go into the (+) beam of U .) What could have changed? The apparatuses T and U are still in the same physical relationship to each other. Can the physics be changed just because T and U are in a different orientation? Our original assumption is that it should not. It must be that the amplitudes with respect to T are different in the two cases shown in Fig. 6-5\u2014and, therefore, also in Fig. 6-4. There must be some way for a particle to know that it has turned the corner at P 1 . How could it tell? Well, all we have decided is that the magnitudes of C \u2032 + and C + are the same in the two cases, but they could\u2014in fact, must\u2014have different phases. We conclude that C \u2032 + and C + must be related by C \u2032 + = e i\u03bb C + , \u2032 and that C \u2032 \u2212 and C \u2212 must be related by C \u2032 \u2212 = e i\u03bc C \u2212 , \u2032 where \u03bb and \u03bc are real numbers which must be related in some way to the angle between S and T . The only thing we can say at the moment about \u03bb and \u03bc is that they must not be equal [except for the special case shown in Fig. 6-5(a), when T is in the same orientation as S ]. We have seen that equal phase changes in all amplitudes have no physical consequence. For the same reason, we can always add the same arbitrary amount to both \u03bb and \u03bc without changing anything. So we are permitted to choose to make \u03bb and \u03bc equal to plus and minus the same number. That is, we can always take \u03bb \u2032 =\u03bb\u2212 (\u03bb+\u03bc) 2 , \u03bc \u2032 =\u03bc\u2212 (\u03bb+\u03bc) 2 . ( \u03bb ) ( \u03bb ) Then \u03bb \u2032 = \u03bb 2 \u2212 \u03bc 2 =\u2212 \u03bc \u2032 . \u03bb So we adopt the convention2 that \u03bc=\u2212\u03bb . We have then the general rule that for a rotation of the reference apparatus by some angle about the z -axis, the transformation is C \u2032 + = e +i\u03bb C + , C \u2032 \u2212 = e \u2212i\u03bb C \u2212 . (6.16) The absolute values are the same, only the phases are different. These phase factors are responsible for the different results in the two experiments of Fig. 6-5. Now we would like to know the law that relates \u03bb to the angle between S and T . We already know the answer for one case. If the angle is zero, \u03bb is zero. Now we will assume that the phase shift \u03bb is a continuous function of angle \u03d5 between S and T (see Fig. 6-4) as \u03d5 goes to zero\u2014as only seems reasonable. In other words, if we rotate T from the straight line through S by the small angle \u03f5 , the \u03bb is also a small quantity, say m\u03f5 , where m is some number. We write it this way because we can show that \u03bb must be proportional to \u03f5 . Suppose we were to put after T another apparatus T \u2032 which makes the angle \u03f5 with T , and, therefore, the angle 2\u03f5 with S . Then, with respect to T , we have C \u2032 + = e i\u03bb C + , \u2032 and with respect to T \u2032 , we have C \u2032\u2032 + = e i\u03bb C \u2032 + = e i2\u03bb C + . \u2033 \u2032 But we know that we should get the same result if we put T \u2032 right after S . Thus, when the angle is doubled, the phase is doubled. We can evidently extend the argument and build up any rotation at all by a sequence of infinitesimal rotations. We conclude that for any angle \u03d5 , \u03bb is proportional to the angle. We can, therefore, write \u03bb=m\u03d5 . The general result we get, then, is that for T rotated about the z -axis by the angle \u03d5 with respect to S C \u2032 + = e im\u03d5 C + , C \u2032 \u2212 = e \u2212im\u03d5 C \u2212 . (6.17) For the angle \u03d5 , and for all rotations we speak of in the future, we adopt the standard convention that a positive rotation is a right-handed rotation about the positive direction of the reference axis. A positive \u03d5 has the sense of rotation of a right-handed screw advancing in the positive z -direction. Now we have to find what m must be. First, we might try this argument: Suppose T is rotated by 360 \u2218 ; then, clearly, it is right back at zero degrees, and we should have C \u2032 + = C + and C \u2032 \u2212 = C \u2212 , or, what is the same thing, e im2\u03c0 =1 . We get m=1 . This argument is wrong! To see that it is, consider that T is rotated by 180 \u2218 . If m were equal to 1 , we would have C \u2032 + = e i\u03c0 C + = \u2212 C + and C \u2032 \u2212 = e \u2212i\u03c0 C \u2212 = \u2212 C \u2212 . However, this is just the original state all over again. Both amplitudes are just multiplied by \u22121 which gives back the original physical system. (It is again a case of a common phase change.) This means that if the angle between T and S in Fig. 6-5(b) is increased to 180 \u2218 , the system (with respect to T ) would be indistinguishable from the zero-degree situation, and the particles would again go through the (+) state of the U apparatus. At 180 \u2218 , though, the (+) state of the U apparatus is the (\u2212x) state of the original S apparatus. So a (+x) state would become a (\u2212x) state. But we have done nothing to change the original state; the answer is wrong. We cannot have m=1 . We must have the situation that a rotation by 360 \u2218 and no smaller angle reproduces the same physical state. This will happen if m= 1 2 . Then, and only then, will the first angle that reproduces the same physical state be \u03d5= 360 \u2218 .3 It gives C \u2032 + C \u2032 \u2212 =\u2212 C + =\u2212 C \u2212 \u23ab \u23ad \u23ac \u23aa \u23aa 360 \u2218 about z-axis. (6.18) It is very curious to say that if you turn the apparatus 360 \u2218 you get new amplitudes. They aren\u2019t really new, though, because the common change of sign doesn\u2019t give any different physics. If someone else had decided to change all the signs of the amplitudes because he thought he had turned 360 \u2218 , that\u2019s all right; he gets the same physics.4 So our final answer is that if we know the amplitudes C + and C \u2212 for spin one-half particles with respect to a reference frame S , and we then use a base system referred to T which is obtained from S by a rotation of \u03d5 around the z -axis, the new amplitudes are given in terms of the old by C \u2032 + = e i\u03d5/2 C + C \u2032 \u2212 = e \u2212i\u03d5/2 C \u2212 \u23ab \u23ad \u23ac \u23aa \u23aa \u03d5 about z. (6.19) Next, we will try to guess the transformation for a rotation of T with respect to S of 180 \u2218 around an axis perpendicular to the z -axis\u2014say, about the y -axis. (We have defined the coordinate axes in Fig. 6-1.) In other words, we start with two identical Stern-Gerlach equipments, with the second one, T , turned \u201cupside down\u201d with respect to the first one, S , as in Fig. 6-6. Now if we think of our particles as little magnetic dipoles, a particle that is in the (+S) state\u2014so that it goes on the \u201cupper\u201d path in the first apparatus\u2014will also take the \u201cupper\u201d path in the second, so that it will be in the minus state with respect to T . (In the inverted T apparatus, both the gradients and the field direction are reversed; for a particle with its magnetic moment in a given direction, the force is unchanged.) Anyway, what is \u201cup\u201d with respect to S will be \u201cdown\u201d with respect to T . For these relative positions of S and T , then, we know that the transformation must give | C \u2032 + |=| C \u2212 |,| C \u2032 \u2212 |=| C + |. \u2032 \u2032 As before, we cannot rule out some additional phase factors; we could have (for 180 \u2218 about the y -axis) C \u2032 + = e i\u03b2 C \u2212 and C \u2032 \u2212 = e i\u03b3 C + , (6.20) where \u03b2 and \u03b3 are still to be determined. What about a rotation of 360 \u2218 about the y -axis? Well, we already know the answer for a rotation of 360 \u2218 about the z -axis\u2014the amplitude to be in any state changes sign. A rotation of 360 \u2218 around any axis always brings us back to the original position. It must be that for any 360 \u2218 rotation, the result is the same as a 360 \u2218 rotation about the z -axis\u2014all amplitudes simply change sign. Now suppose we imagine two successive rotations of 180 \u2218 about y \u2014using Eq. (6.20)\u2014we should get the result of Eq. (6.18). In other words, C \u2032\u2032 + = e i\u03b2 C \u2032 \u2212 = e i\u03b2 e i\u03b3 C + =\u2212 C + \u2033 \u2032 and C \u2032\u2032 \u2212 = e i\u03b3 C \u2032 + = e i\u03b3 e i\u03b2 C \u2212 =\u2212 C \u2212 . (6.21) This means that e i\u03b2 e i\u03b3 =\u22121or e i\u03b3 =\u2212 e \u2212i\u03b2 . i \u03b2 i i i \u03b2 So the transformation for a rotation of 180 \u2218 about the y -axis can be written C \u2032 + = e i\u03b2 C \u2212 , C \u2032 \u2212 =\u2212 e \u2212i\u03b2 C + . (6.22) The arguments we have just used would apply equally well to a rotation of 180 \u2218 about any axis in the xy -plane, although different axes can, of course, give different numbers for \u03b2 . However, that is the only way they can differ. Now there is a certain amount of arbitrariness in the number \u03b2 , but once it is specified for one axis of rotation in the xy -plane it is determined for any other axis. It is conventional to choose to set \u03b2=0 for a 180 \u2218 rotation about the y -axis. To show that we have this choice, suppose we imagine that \u03b2 was not equal to zero for a rotation about the y -axis; then we can show that there is some other axis in the xy -plane, for which the corresponding phase factor will be zero. Let\u2019s find the phase factor \u03b2 A for an axis A that makes the angle \u03b1 with the y -axis, as shown in Fig. 6-7(a). (For clarity, the figure is drawn with \u03b1 equal to a negative number, but that doesn\u2019t matter.) Now if we take a T apparatus which is initially lined up with the S apparatus and is then rotated 180 \u2218 about the axis A , its axes\u2014which we will call x \u2032\u2032 , y \u2032\u2032 , and z \u2032\u2032 \u2014will be as shown in Fig. 6-7(a). The amplitudes with respect to T will then be C \u2032\u2032 + = e i \u03b2 A C \u2212 , C \u2032\u2032 \u2212 =\u2212 e \u2212i \u03b2 A C + . (6.23) We can now think of getting to the same orientation by the two successive rotations shown in (b) and (c) of the figure. First, we imagine an apparatus U which is rotated with respect to S by 180 \u2218 about the y -axis. The axes x \u2032 , y \u2032 , and z \u2032 of U will be as shown in Fig. 6-7(b), and the amplitudes with respect to U are given by (6.22). Now notice that we can go from U to T by a rotation about the \u201c z -axis\u201d of U , namely about z \u2032 , as shown in Fig. 6-7(c). From the figure you can see that the angle required is two times the angle \u03b1 but in the opposite direction (with respect to z \u2032 ). Using the transformation of (6.19) with \u03d5=\u22122\u03b1 , we get C \u2032\u2032 + = e \u2212i\u03b1 C \u2032 + , C \u2032\u2032 \u2212 = e +i\u03b1 C \u2032 \u2212 . (6.24) Combining Eqs. (6.24) and (6.22), we get that C \u2032\u2032 + = e i(\u03b2\u2212\u03b1) C \u2212 , C \u2032\u2032 \u2212 =\u2212 e \u2212i(\u03b2\u2212\u03b1) C + . (6.25) These amplitudes must, of course, be the same as we got in (6.23). So \u03b2 A must be related to \u03b1 and \u03b2 by \u03b2 A =\u03b2\u2212\u03b1. (6.26) This means that if the angle \u03b1 between the A -axis and the y -axis (of S ) is equal to \u03b2 , the transformation for a rotation of 180 \u2218 about A will have \u03b2 A =0 . Now so long as some axis perpendicular to the z -axis is going to have \u03b2=0 , we may as well take it to be the y -axis. It is purely a matter of convention, and we adopt the one in general use. Our result: For a rotation of 180 \u2218 about the y -axis, we have C \u2032 + C \u2032 \u2212 = C \u2212 =\u2212 C + \u23ab \u23ad \u23ac \u23aa \u23aa 180 \u2218 about y. (6.27) While we are thinking about the y -axis, let\u2019s next ask for the transformation matrix for a rotation of 90 \u2218 about y . We can find it because we know that two successive 90 \u2218 rotations about the same axis must equal one 180 \u2218 rotation. We start by writing the transformation for 90 \u2218 in the most general form: C \u2032 + =a C + +b C \u2212 , C \u2032 \u2212 =c C + +d C \u2212 . (6.28) A second rotation of 90 \u2218 about the same axis would have the same coefficients: C \u2032\u2032 + =a C \u2032 + +b C \u2032 \u2212 , C \u2032\u2032 \u2212 =c C \u2032 + +d C \u2032 \u2212 . (6.29) Combining Eqs. (6.28) and (6.29), we have C \u2032\u2032 + C \u2032\u2032 \u2212 =a(a C + +b C \u2212 ) =c(a C + +b C \u2212 ) +b(c C + +d C \u2212 ), +d(c C + +d C \u2212 ). (6.30) However, from (6.27) we know that C \u2032\u2032 + = C \u2212 , C \u2032\u2032 \u2212 =\u2212 C + , \u2033 \u2033 so that we must have that ab+bd a 2 +bc ac+cd bc+ d 2 =1, =0, =\u22121, =0. (6.31) These four equations are enough to determine all our unknowns: a , b , c , and d . It is not hard to do. Look at the second and fourth equations. Deduce that a 2 = d 2 , which means that a=d or else that a=\u2212d . But a=\u2212d is out, because then the first equation wouldn\u2019t be right. So d=a . Using this, we have immediately that b=1/2a and that c=\u22121/2a . Now we have everything in terms of a . Putting, say, the second equation all in terms of a , we have a 2 \u2212 1 4 a 2 =0or a 4 = 1 4 . 1 1 This equation has four different solutions, but only two of them give the standard value for the determinant. We might as well take a=1/ 2 \u2013 \u221a ; then5 a c =1/ 2 \u2013 \u221a , =\u22121/ 2 \u2013 \u221a , b d =1/ 2 \u2013 \u221a , =1/ 2 \u2013 \u221a . In other words, for two apparatuses S and T , with T rotated with respect to S by 90 \u2218 about the y -axis, the transformation is C \u2032 + C \u2032 \u2212 = 1 2 \u2013 \u221a ( C + + C \u2212 ) = 1 2 \u2013 \u221a (\u2212 C + + C \u2212 ) \u23ab \u23ad \u23ac \u23aa \u23aa \u23aa \u23aa \u23aa \u23aa \u23aa \u23aa \u23aa \u23aa 90 \u2218 about y. (6.32) We can, of course, solve these equations for C + and C \u2212 , which will give us the transformation for a rotation of minus 90 \u2218 about y . Changing the primes around, we would conclude that C \u2032 + C \u2032 \u2212 = 1 2 \u2013 \u221a ( C + \u2212 C \u2212 ) = 1 2 \u2013 \u221a ( C + + C \u2212 ) \u23ab \u23ad \u23ac \u23aa \u23aa \u23aa \u23aa \u23aa \u23aa \u23aa \u23aa \u23aa \u23aa \u2212 90 \u2218 about y. (6.33) You may be thinking: \u201cThis is getting ridiculous. What are they going to do next, 47 \u2218 around y , then 33 \u2218 about x , and so on, forever?\u201d No, we are almost finished. With just two of the transformations we have\u2014 90 \u2218 about y , and an arbitrary angle about z (which we did first if you remember)\u2014we can generate any rotation at all. As an illustration, suppose that we want the angle \u03b1 around x . We know how to deal with the angle \u03b1 around z , but now we want it around x . How do we get it? First, we turn the axis z down onto x \u2014which is a rotation of + 90 \u2218 about y , as shown in Fig. 6-8. Then we turn through the angle \u03b1 around z \u2032 . Then we rotate \u2212 90 \u2218 about y \u2032\u2032 . The net result of the three rotations is the same as turning around x by the angle \u03b1 . It is a property of space. (These facts of the combinations of rotations, and what they produce, are hard to grasp intuitively. It is rather strange, because we live in three dimensions, but it is hard for us to appreciate what happens if we turn this way and then that way. Perhaps, if we were fish or birds and had a real appreciation of what happens when we turn somersaults in space, we could more easily appreciate such things.) Anyway, let\u2019s work out the transformation for a rotation by \u03b1 around the x -axis by using what we know. From the first rotation by + 90 \u2218 around y the amplitudes go according to Eq. (6.32). Calling the rotated axes x \u2032 , y \u2032 , and z \u2032 , the next rotation by the angle \u03b1 around z \u2032 takes us to a frame x \u2032\u2032 , y \u2032\u2032 , z \u2032\u2032 , for which C \u2032\u2032 + = e i\u03b1/2 C \u2032 + , C \u2032\u2032 \u2212 = e \u2212i\u03b1/2 C \u2032 \u2212 . \u2033 \u2032 \u2033 \u2032 The last rotation of \u2212 90 \u2218 about y \u2032\u2032 takes us to x \u2032\u2032\u2032 , y \u2032\u2032\u2032 , z \u2032\u2032\u2032 ; by (6.33), C \u2032\u2032\u2032 + = 1 2 \u2013 \u221a ( C \u2032\u2032 + \u2212 C \u2032\u2032 \u2212 ), C \u2032\u2032\u2032 \u2212 = 1 2 \u2013 \u221a ( C \u2032\u2032 + + C \u2032\u2032 \u2212 ). 1 1 Combining these last two transformations, we get C \u2032\u2032\u2032 + C \u2032\u2032\u2032 \u2212 = 1 2 \u2013 \u221a ( e +i\u03b1/2 C \u2032 + \u2212 e \u2212i\u03b1/2 C \u2032 \u2212 ), = 1 2 \u2013 \u221a ( e +i\u03b1/2 C \u2032 + + e \u2212i\u03b1/2 C \u2032 \u2212 ). Using Eqs. (6.32) for C \u2032 + and C \u2032 \u2212 , we get the complete transformation: C \u2032\u2032\u2032 + C \u2032\u2032\u2032 \u2212 = 1 2 { e +i\u03b1/2 ( C + + C \u2212 )\u2212 e \u2212i\u03b1/2 (\u2212 C + + C \u2212 )}, = 1 2 { e +i\u03b1/2 ( C + + C \u2212 )+ e \u2212i\u03b1/2 (\u2212 C + + C \u2212 )}. We can put these formulas in a simpler form by remembering that e i\u03b8 + e \u2212i\u03b8 =2cos\u03b8,and e i\u03b8 \u2212 e \u2212i\u03b8 =2isin\u03b8. i \u03b8 i \u03b8 i \u03b8 i \u03b8 We get C \u2032\u2032\u2032 + C \u2032\u2032\u2032 \u2212 =( =i( cos \u03b1 2 sin \u03b1 2 ) C + +i( ) C + +( sin \u03b1 2 cos \u03b1 2 ) C \u2212 ) C \u2212 \u23ab \u23ad \u23ac \u23aa \u23aa \u23aa \u23aa \u23aa \u23aa \u23aa \u23aa \u23aa \u23aa \u23aa \u23aa \u03b1 about x. (6.34) Here is our transformation for a rotation about the x -axis by any angle \u03b1 . It is only a little more complicated than the others. Now we can see how to do any angle at all. First, notice that any relative orientation of two coordinate frames can be described in terms of three angles, as shown in Fig. 6-9. If we have a set of axes x \u2032 , y \u2032 , and z \u2032 oriented in any way at all with respect to x , y , and z , we can describe the relationship between the two frames by means of the three Euler angles \u03b1 , \u03b2 , and \u03b3 , which define three successive rotations that will bring the x , y , z frame into the x \u2032 , y \u2032 , z \u2032 frame. Starting at x , y , z , we rotate our frame through the angle \u03b2 about the z -axis, bringing the x -axis to the line x 1 . Then, we rotate by \u03b1 about this temporary x -axis, to bring z down to z \u2032 . Finally, a rotation about the new z -axis (that is, z \u2032 ) by the angle \u03b3 will bring the x -axis into x \u2032 and the y -axis into y \u2032 .6 We know the transformations for each of the three rotations\u2014they are given in (6.19) and (6.34). Combining them in the proper order, we get C \u2032 + C \u2032 \u2212 = =i cos \u03b1 2 sin \u03b1 2 e i(\u03b2+\u03b3)/2 C + +i e i(\u03b2\u2212\u03b3)/2 C + + sin \u03b1 2 cos \u03b1 2 e \u2212i(\u03b2\u2212\u03b3)/2 C \u2212 , e \u2212i(\u03b2+\u03b3)/2 C \u2212 . (6.35) So just starting from some assumptions about the properties of space, we have derived the amplitude transformation for any rotation at all. That means that if we know the amplitudes for any state of a spin one-half particle to go into the two beams of a Stern-Gerlach apparatus S , whose axes are x , y , and z , we can calculate what fraction would go into either beam of an apparatus T with the axes x \u2032 , y \u2032 , and z \u2032 . In other words, if we have a state \u03c8 of a spin one-half particle, whose amplitudes are C + =\u27e8+|\u03c8\u27e9 and C \u2212 =\u27e8\u2212|\u03c8\u27e9 to be \u201cup\u201d and \u201cdown\u201d with respect to the z -axis of the x , y , z frame, we also know the amplitudes C \u2032 + and C \u2032 \u2212 to be \u201cup\u201d and \u201cdown\u201d with respect to the z \u2032 -axis of any other frame x \u2032 , y \u2032 , z \u2032 . The four coefficients in Eqs. (6.35) are the terms of the \u201ctransformation matrix\u201d with which we can project the amplitudes of a spin one-half particle into any other coordinate system. We will now work out a few examples to show you how it all works. Let\u2019s take the following simple question. We put a spin one-half atom through a Stern-Gerlach apparatus that transmits only the (+z) state. What is the amplitude that it will be in the (+x) state? The +x axis is the same as the + z \u2032 axis of a system rotated 90 \u2218 about the y -axis. For this problem, then, it is simplest to use Eqs. (6.32)\u2014although you could, of course, use the complete equations of (6.35). Since C + =1 and C \u2212 =0 , we get C \u2032 + =1/ 2 \u2013 \u221a . The probabilities are the absolute square of these amplitudes; there is a 50 percent chance that the particle will go through an apparatus that selects the (+x) state. If we had asked about the (\u2212x) state the amplitude would have been \u22121/ 2 \u2013 \u221a , which also gives a probability 1/2 \u2014as you would expect from the symmetry of space. So if a particle is in the (+z) state, it is equally likely to be in (+x) or (\u2212x) , but with opposite phase. There\u2019s no prejudice in y either. A particle in the (+z) state has a 50 \u2013 50 chance of being in (+y) or in (\u2212y) . However, for these (using the formula for rotating \u2212 90 \u2218 about x ), the amplitudes are 1/ 2 \u2013 \u221a and \u2212i/ 2 \u2013 \u221a . In this case, the two amplitudes have a phase difference of 90 \u2218 instead of 180 \u2218 , as they did for the (+x) and (\u2212x) . In fact, that\u2019s how the distinction between x and y shows up. As our final example, suppose that we know that a spin one-half particle is in a state \u03c8 such that it is polarized \u201cup\u201d along some axis A , defined by the angles \u03b8 and \u03d5 in Fig. 6-10. We want to know the amplitude C + that the particle is \u201cup\u201d along z and the amplitude C \u2212 that it is \u201cdown\u201d along z . We can find these amplitudes by imagining that A is the z -axis of a system whose x -axis lies in some arbitrary direction\u2014say in the plane formed by A and z . We can then bring the frame of A into x , y , z by three rotations. First, we make a rotation by \u2212\u03c0/2 about the axis A , which brings the x -axis into the line B in the figure. Then we rotate by \u03b8 about line B (the new x -axis of frame A ) to bring A to the z -axis. Finally, we rotate by the angle (\u03c0/2\u2212\u03d5) about z . Remembering that we have only a (+) state with respect to A , we get C + =cos \u03b8 2 e \u2212i\u03d5/2 , C \u2212 =sin \u03b8 2 e +i\u03d5/2 . (6.36) We would like, finally, to summarize the results of this chapter in a form that will be useful for our later work. First, we remind you that our primary result in Eqs. (6.35) can be written in another notation. Note that Eqs. (6.35) mean just the same thing as Eq. (6.4). That is, in Eqs. (6.35) the coefficients of C + =\u27e8+S|\u03c8\u27e9 and C \u2212 =\u27e8\u2212S|\u03c8\u27e9 are just the amplitudes \u27e8jT|iS\u27e9 of Eq. (6.4)\u2014the amplitudes that a particle in the i -state with respect to S will be in the j -state with respect to T (when the orientation of T with respect to S is given in terms of the angles \u03b1 , \u03b2 , and \u03b3 ). We also called them R TS ji in Eq. (6.6). (We have a plethora of notations!) For example, R TS \u2212+ =\u27e8\u2212T|+S\u27e9 is the coefficient of C + in the formula for C \u2032 \u2212 , namely, isin(\u03b1/2) e i(\u03b2\u2212\u03b3)/2 . We can, therefore, make a summary of our results in the form of a table, as we have done in Table 6\u20131. It will occasionally be handy to have these amplitudes already worked out for some simple special cases. Let\u2019s let R z (\u03d5) stand for a rotation by the angle \u03d5 about the z -axis. We can also let it stand for the corresponding rotation matrix (omitting the subscripts i and j , which are to be implicitly understood). In the same spirit R x (\u03d5) and R y (\u03d5) will stand for rotations by the angle \u03d5 about the x -axis or the y -axis. We give in Table 6\u20132 the matrices\u2014the tables of amplitudes \u27e8jT|iS\u27e9 \u2014which project the amplitudes from the S -frame into the T -frame, where T is obtained from S by the rotation specified."
    },
    {
        "input": "Ferromagnetism",
        "output": "In this chapter we will discuss some materials in which the net effect of the magnetic moments in the material is much greater than in the case of paramagnetism or diamagnetism. The phenomenon is called ferromagnetism. In paramagnetic and diamagnetic materials the induced magnetic moments are usually so weak that we don\u2019t have to worry about the additional fields produced by the magnetic moments. For ferromagnetic materials, however, the magnetic moments induced by applied magnetic fields are quite enormous and have a great effect on the fields themselves. In fact, the induced moments are so strong that they are often the dominant effect in producing the observed fields. So one of the things we will have to worry about is the mathematical theory of large induced magnetic moments. That is, of course, just a technical question. The real problem is, why are the magnetic moments so strong\u2014how does it all work? We will come to that question in a little while. Finding the magnetic fields of ferromagnetic materials is something like the problem of finding the electrostatic field in the presence of dielectrics. You will remember that we first described the internal properties of a dielectric in terms of a vector field P , the dipole moment per unit volume. Then we figured out that the effects of this polarization are equivalent to a charge density \u03c1pol given by the divergence of P : \u03c1pol=\u2212\u2207\u22c5P. The total charge in any situation can be written as the sum of this polarization charge plus all other charges, whose density we write1 \u03c1other . Then the Maxwell equation which relates the divergence of E to the charge density becomes \u2207\u22c5E= \u03c1 \u03f50 = \u03c1pol+\u03c1other \u03f50 , or \u2207\u22c5E=\u2212 \u2207\u22c5P \u03f50 + \u03c1other \u03f50 . We can then pull out the polarization part of the charge and put it on the other side of the equation, to get the new law \u2207\u22c5(\u03f50E+P)=\u03c1other. The new law says the divergence of the quantity (\u03f50E+P) is equal to the density of the other charges. Pulling E and P together as in Eq. (36.2), of course, is useful only if we know some relation between them. We have seen that the theory which relates the induced electric dipole moment to the field was a relatively complicated business and can really only be applied to certain simple situations, and even then as an approximation. We would like to remind you of one of the approximate ideas we used. To find the induced dipole moment of an atom inside a dielectric, it is necessary to know the electric field that acts on an individual atom. We made the approximation\u2014which is not too bad in many cases\u2014that the field on the atom is the same as it would be at the center of the small hole which would be left if we took out the atom (keeping the dipole moments of all the neighboring atoms the same). You will also remember that the electric field in a hole in a polarized dielectric depends on the shape of the hole. We summarize our earlier results in Fig. 36\u20131. For a thin, disc-shaped hole perpendicular to the polarization, the electric field in the hole is given by Ehole=Edielectric+ P \u03f50 , which we showed by using Gauss\u2019 law. On the other hand, in a needle-shaped slot parallel to the polarization, we showed\u2014by using the fact that the curl of E is zero\u2014that the electric fields inside and outside of the slot are the same. Finally, we found that for a spherical hole the electric field was one-third of the way between the field of the slot and the field of the disc: Ehole=Edielectric+ 1 3 P \u03f50 (spherical hole). This was the field we used in thinking about what happens to an atom inside a polarized dielectric. Now we have to discuss the analog of all this for the case of magnetism. One simple, short-cut way of doing this is to say the M , the magnetic moment per unit volume, is just like P , the electric dipole moment per unit volume, and that, therefore, the negative of the divergence of M is equivalent to a \u201cmagnetic charge density\u201d \u03c1 m \u2014whatever that may mean. The trouble is, of course, that there isn\u2019t any such thing as a \u201cmagnetic charge\u201d in the physical world. As we know, the divergence of B is always zero. But that does not stop us from making an artificial analog and writing \u2207\u22c5M=\u2212 \u03c1 m , (36.4) where it is to be understood that \u03c1 m is purely mathematical. Then we could make a complete analogy with the electrostatic case and use all our old equations from electrostatics. People have often done something like that. In fact, historically, people even believed that the analogy was right. They believed that the quantity \u03c1 m represented the density of \u201cmagnetic poles.\u201d These days, however, we know that the magnetization of materials comes from circulating currents within the atoms\u2014either from the spinning electrons or from the motion of the electrons in the atom. It is therefore nicer from a physical point of view to describe things realistically in terms of the atomic currents, rather than in terms of a density of some mythical \u201cmagnetic poles.\u201d Incidentally, these currents are sometimes called \u201cAmp\u00e8rian\u201d currents, because Amp\u00e8re first suggested that the magnetism of matter came from circulating atomic currents. The actual microscopic current density in magnetized matter is, of course, very complicated. Its value depends on where you look in the atom\u2014it\u2019s large in some places and small in others; it goes one way in one part of the atom and the opposite way in another part (just as the microscopic electric field varies enormously inside a dielectric). In many practical problems, however, we are interested only in the fields outside of the matter or in the average magnetic field inside of the matter\u2014where we mean an average taken over many, many atoms. It is only for such macroscopic problems that it is convenient to describe the magnetic state of the matter in terms of M , the average dipole moment per unit volume. What we want to show now is that the atomic currents of magnetized matter can give rise to certain large-scale currents which are related to M . What we are going to do, then, is to separate the current density j \u2014which is the real source of the magnetic fields\u2014into various parts: one part to describe the circulating currents of the atomic magnets, and the other parts to describe what other currents there may be. It is usually most convenient to separate the currents into three parts. In Chapter 32 we made a distinction between the currents which flow freely on conductors and the ones which are due to the back and forth motions of the bound charges in dielectrics. In Section 32\u20132 we wrote j= j pol + j other , j j j where j pol represented the currents from the motion of the bound charges in dielectrics and j other took care of all other currents. Now we want to go further. We want to separate j other into one part, j mag , which describes the average currents inside of magnetized materials, and an additional term which we can call j cond for whatever is left over. The last term will generally refer to currents in conductors, but it may also include other currents\u2014for example the currents from charges moving freely through empty space. So we will write for the total current density: j= j pol + j mag + j cond . (36.5) Of course it is this total current which belongs in the Maxwell equation for the curl of B : c 2 \u2207\u00d7B= j \u03f5 0 + \u2202E \u2202t . (36.6) Now we have to relate the current j mag to the magnetization vector M . So that you can see where we are going, we will tell you that the result is going to be that j mag =\u2207\u00d7M. (36.7) If we are given the magnetization vector M everywhere in a magnetic material, the circulation current density is given by the curl of M . Let\u2019s see if we can understand why this is so. First, let\u2019s take the case of a cylindrical rod which has a uniform magnetization parallel to its axis. Physically, we know that such a uniform magnetization really means a uniform density of atomic circulating currents everywhere inside the material. Suppose we try to imagine what the actual currents would look like in a cross section of the material. We would expect to see currents something like those shown in Fig. 36\u20132. Each atomic current goes around and around in a little circle, with all the circulating currents going around in the same direction. Now what is the effective current of such a thing? Well, in most of the bar there is no effect at all, because right next to each current there is another current going in the opposite direction. If we imagine a small surface\u2014but one still quite a bit larger than a single atom\u2014such as is indicated in Fig. 36\u20132 by the line AB \u00af \u00af \u00af \u00af \u00af \u00af \u00af \u00af , the net current through such a surface is zero. There is no net current anywhere inside the material. Note, however, that at the surface of the material there are atomic currents which are not cancelled by neighboring currents going the other way. At the surface there is a net current always going in the same direction around the rod. Now you see why we said earlier that a uniformly magnetized rod is equivalent to a long solenoid carrying an electric current. How does this view fit with Eq. (36.7)? First, inside the material the magnetization M is constant, so all its derivatives are zero. This agrees with our geometric picture. At the surface, however, M is not really constant\u2014it is constant up to the edge and then suddenly collapses to zero. So, right at the surface there are terrific gradients which, according to (36.7), will give a high current density. Suppose we look at what happens near the point C in Fig. 36\u20132. Taking the x - and y -directions as in the figure, the magnetization M is in the z -direction. Writing out the components of Eq. (36.7), we have \u2202 M z \u2202y \u2212 \u2202 M z \u2202x =( j mag ) x , =( j mag ) y . (36.8) At the point C , the derivative \u2202 M z /\u2202y is zero, but \u2202 M z /\u2202x is large and positive. Equation (36.7) says that there is a large current density in the minus y -direction. This agrees with our picture of a surface current going around the bar. Now we want to find the current density for a more complicated case in which the magnetization varies from point to point in a material. It is easy to see qualitatively that if the magnetization is different in two neighboring regions, there will not be a perfect cancellation of the circulating currents so that there will be a net current in the volume of the material. It is this effect that we want to work out quantitatively. First, we need to recall the results of Section 14\u20135 that a circulating current I has a magnetic moment \u03bc given by \u03bc=IA, (36.9) where A is the area of the current loop (see Fig. 36\u20133). Now let\u2019s consider a small rectangular block inside of a magnetized material, as sketched in Fig. 36\u20134. We take the block so small that we can consider that the magnetization is uniform inside it. If this block has a magnetization M z in the z -direction, the net effect will be the same as a surface current going around on the vertical faces, as shown. We can find the magnitude of these currents from Eq. (36.9). The total magnetic moment of the block is equal to the magnetization times the volume: \u03bc= M z (abc), ( b ) from which we get (remembering that the area of the loop is ac ) I= M z b. I M b In other words, the current per unit length (vertically) on each of the vertical surfaces is equal to M z . Now suppose that we imagine two such little blocks next to each other, as shown in Fig. 36\u20135. Because block 2 is slightly displaced from block 1 , it will have a slightly different vertical component of magnetization, which we call M z +\u0394 M z . Now on the surface between the two blocks there will be two contributions to the total current. Block 1 will produce a current I 1 flowing in the positive y -direction, and block 2 will produce a surface current I 2 flowing in the negative y -direction. The total surface current in the positive y -direction is the sum: I = I 1 \u2212 I 2 = M z b\u2212( M z +\u0394 M z )b =\u2212\u0394 M z b. We can write \u0394 M z , as the derivative of M z in the x -direction times the displacement from block 1 to block 2 , which is just a : \u0394 M z = \u2202 M z \u2202x a. \u2202 M The current flowing between the two blocks is then I=\u2212 \u2202 M z \u2202x ab. \u2202 M To relate the current I to an average volume current density j , we must realize that this current I is really spread over a certain cross-sectional area. If we imagine the whole volume of the material to be filled with such little blocks, one such side face (perpendicular to the x -axis) can be associated with each block.2 Then we see that the area to be associated with the current I is just the area ab of one of the front faces. We get the result j y = I ab =\u2212 \u2202 M z \u2202x . \u2202 M We have at least the beginning of the curl of M . There should be another term in j y from the variation of the x -component of the magnetization with z . This contribution to j will come from the surface between two little blocks stacked one on top of the other, as shown in Fig. 36\u20136. Using the same arguments we have just made, you can show that this surface will contribute to j y the amount \u2202 M x /\u2202z . These are the only surfaces which can contribute to the y -component of the current so we have that the total current density in the y -direction is j y = \u2202 M x \u2202z \u2212 \u2202 M z \u2202x . \u2202 M \u2202 M Working out the currents on the remaining faces of a cube\u2014or using the fact that our z -direction is completely arbitrary\u2014we can conclude that the vector current density is indeed given by the equation j=\u2207\u00d7M. j \u2207 M So if we choose to describe the magnetic situation in matter in terms of the average magnetic moment per unit volume M , we find that the circulating atomic currents are equivalent to an average current density in matter given by Eq. (36.7). If the material is also a dielectric, there may be, in addition, a polarization current j pol =\u2202P/\u2202t . And if the material is also a conductor, we may have a conduction current j cond as well. We can write the total current as j= j cond +\u2207\u00d7M+ \u2202P \u2202t . (36.10) Next, we want to insert the current as written in Eq. (36.10) into Maxwell\u2019s equations. We get c 2 \u2207\u00d7B = j \u03f5 0 + \u2202E \u2202t = 1 \u03f5 0 ( j cond +\u2207\u00d7M+ \u2202P \u2202t )+ \u2202E \u2202t . We can move the term in M to the left-hand side: c 2 \u2207\u00d7(B\u2212 M \u03f5 0 c 2 )= j cond \u03f5 0 + \u2202 \u2202t (E+ P \u03f5 0 ). (36.11) As we remarked in Chapter 32, many people like to write (E+P/ \u03f5 0 ) as a new vector field D/ \u03f5 0 . Similarly, it is often convenient to write (B\u2212M/ \u03f5 0 c 2 ) as a single vector field. We choose to define a new vector field H by H=B\u2212 M \u03f5 0 c 2 . (36.12) Then Eq. (36.11) becomes \u03f5 0 c 2 \u2207\u00d7H= j cond + \u2202D \u2202t . (36.13) It looks simple, but all the complexity is just hidden in the letters D and H . Now we have to give you a warning. Most people who use the mks units have chosen to use a different definition of H . Calling their field H \u2032 (of course, they still call it H without the prime), it is defined by H \u2032 = \u03f5 0 c 2 B\u2212M. (36.14) (Also, they usually write \u03f5 0 c 2 as a new number 1/ \u03bc 0 ; then they have one more constant to keep track of!) With this definition, Eq. (36.13) looks even simpler: \u2207\u00d7 H \u2032 = j cond + \u2202D \u2202t . (36.15) But the difficulties with this definition of H \u2032 are, first, that it doesn\u2019t agree with the definition of people who don\u2019t use the mks units, and second, that it makes H \u2032 and B have different units. We think it is more convenient for H to have the same units as B \u2014rather than the units of M , as H \u2032 does. But if you are going to be an engineer and work on the design of transformers, magnets, and such, you will have to watch out. You will find many books which use for H the definition of Eq. (36.14) rather than our definition of Eq. (36.12), and many other books\u2014especially handbooks about magnetic materials\u2014that relate B and H the way we have done. You\u2019ll have to be careful to figure out which convention they are using. One way to tell is by the units they use. Remember that in the mks system, B \u2014and therefore our H \u2014are measured with the unit: one weber per square meter, equal to 10,000 gauss. In the mks system, a magnetic moment (a current times an area) has the unit: one ampere-meter 2 . The magnetization M , then, has the unit: one ampere per meter. For H \u2032 the units are the same as for M . You can see that this also agrees with Eq. (36.15), since \u2207 has the dimensions of one over a length. People who are working with electromagnets also get in the habit of calling the unit of H (with the H \u2032 definition) \u201cone ampere turn per meter\u201d\u2014thinking of the turns of wire on a winding. But a \u201cturn\u201d is really a dimensionless number, so that doesn\u2019t need to confuse you. Since our H is equal to H \u2032 / \u03f5 0 c 2 , if you are using the mks system, H (in webers/meter 2 ) is equal to 4\u03c0\u00d7 10 \u22127 times H \u2032 (in amperes per meter). It is perhaps more convenient to remember that H (in gauss) =0.0126 H \u2032 (in amp/meter). There is one more horrible thing. Many people who use our definition of H have decided to call the units of H and B by different names! Even though they have the same dimensions, they call the unit of B one gauss, and the unit of H one oersted (after Gauss and Oersted, of course). So, in many books you will find graphs with B plotted in gauss and H in oersteds. They are really the same unit\u2014 10 \u22124 of the mks unit. We have summarized the confusion about magnetic units in Table 36\u20131. Now we will look at some simple situations in which the magnetic field is constant, or in which the fields change slowly enough that we can neglect \u2202D/\u2202t in comparison with j cond . Then the fields obey the equations \u2207\u22c5B=0, \u2207\u00d7H= j cond / \u03f5 0 c 2 , H=B\u2212M/ \u03f5 0 c 2 . (36.16) (36.17) (36.18) Suppose we have a torus (a donut) of iron wrapped with a coil of copper wire, as shown in Fig. 36\u20137(a). A current I flows in the wire. What is the magnetic field? The magnetic field will be mainly inside the iron; there, the lines of B will be circles, as drawn in Fig. 36\u20137(b). Since the flux of B is continuous, its divergence is zero, and Eq. (36.16) is satisfied. Next, we write Eq. (36.17) in another form by integrating around the closed loop \u0393 drawn in Fig. 36\u20137(b). From Stokes\u2019 theorem, we have that \u222e \u0393 H\u22c5ds= 1 \u03f5 0 c 2 \u222b S j cond \u22c5nda, (36.19) where the integral of j is to be carried out over any surface S bounded by \u0393 . This surface is cut once by each turn of the winding. Each turn contributes the current I to the integral, and, if there are N turns in all, the integral is NI . From the symmetry of our problem, B is the same all around the curve \u0393 ; if we assume that the magnetization, and therefore, the field H is also constant along \u0393 , Eq. (36.19) becomes Hl= NI \u03f5 0 c 2 , N I where l is the length of the curve \u0393 . So, H= 1 \u03f5 0 c 2 NI l . (36.20) It is because H is directly proportional to the magnetizing current in cases like this one that H is sometimes called the magnetizing field. Now all we need is an equation which relates H to B . But there isn\u2019t any such equation! There is, of course, Eq. (36.18), but it is no help because there is no direct relation between M and B for a ferromagnetic material like iron. The magnetization M depends on the whole past history of the iron, and not only on what B is at the moment. All is not lost, though. We can get solutions in certain simple cases. If we start out with unmagnetized iron\u2014let\u2019s say with iron that has been annealed at high temperatures\u2014then in the simple geometry of the torus, all the iron will have the same magnetic history. Then we can say something about M \u2014and therefore about the relation between B and H \u2014from experimental measurements. The field H in the torus is, from Eq. (36.20), given as a constant times the current I in the winding. The field B can be measured by integrating over time the emf in the coil (or in an extra coil wound over the magnetizing coil shown in the figure). This emf is equal to the rate of change of the flux of B , so the integral of the emf with time is equal to B times the cross-sectional area of the torus. Figure 36\u20138 shows the relation between B and H , observed with a torus of soft iron. When the current is first turned on, B increases with increasing H along the curve a . Note the different scales on B and H ; initially, it takes only a relatively small H to make a large B . Why is B so much larger with the iron than it would be with air? Because there is a large magnetization M which is equivalent to a large surface current on the iron\u2014the field B comes from the sum of this current and the conduction current in the winding. Why M should be so large, we will discuss later. At higher values of H , the magnetization curve levels off. We say that the iron saturates. With the scales of our figure, the curve appears to become horizontal. Actually, it continues to rise slightly\u2014for large fields, B becomes proportional to H , and with a unit slope. There is no further increase of M . Incidentally, we should point out that if the torus were made of some nonmagnetic material, M would be zero and B would equal H for all fields. The first thing we notice is that curve a in Fig. 36\u20138\u2014which is the so-called magnetization curve\u2014is highly nonlinear. But it\u2019s worse than that. If, after reaching saturation, we decrease the current in the coil to bring H back to zero, the magnetic field B falls along curve b . When H reaches zero, there is still some B left. Even with no magnetizing current there is a magnetic field in the iron\u2014it has become permanently magnetized. If we now turn on a negative current in the coil, the B - H curve continues along b until the iron is saturated in the negative direction. If we then bring the current back to zero again, B goes along curve c . If we alternate the current between large positive and negative values, the B - H curve goes back and forth along very nearly the curves b and c . If we vary H in some arbitrary way, however, we can get more complicated curves which will, in general, lie somewhere between the curves b and c . The loop made by repeated oscillation of the fields is called a hysteresis loop of the iron. We see then that we cannot write a functional relationship like B=f(H) , because the value of B at any instant depends not only on what H is at that time, but on its whole past history. Naturally, the magnetization and hysteresis curves are different for different substances. The shape of the curves depends critically on the chemical composition of the material, and also on the details of its preparation and subsequent physical treatment. We will discuss some of the physical explanations for these complications in the next chapter. One of the most important applications of magnetic materials is in electrical circuits\u2014for example, in transformers, electric motors, and so on. One reason is that with iron we can control where the magnetic fields go, and also get much larger fields for a given electric current. For example, the typical \u201ctoroidal\u201d inductance is made very much like the object shown in Fig. 36\u20137. For a given inductance, it can be much smaller in volume and use much less copper than an equivalent \u201cair-core\u201d inductance. For a given inductance, we get a much smaller resistance in the winding, so the inductance is more nearly \u201cideal\u201d\u2014particularly for low frequencies. It is very easy to understand, qualitatively, how such an inductance works. If I is the current in the winding, then the field H which is produced in the inside is proportional to I \u2014as given by Eq. (36.20). The voltage V across the terminals is related to the magnetic field B . Neglecting the resistance of the winding, the voltage V is proportional to \u2202B/\u2202t . The inductance L , which is the ratio of V to dI/dt (see Section 17\u20137), thus involves the relation between B and H in the iron. Since the B is so much bigger than the H , we get a large factor in the inductance. Physically, what happens is that a small current in the coil, which would ordinarily produce a small magnetic field, causes the little \u201cslave\u201d magnets in the iron to line up and produce a tremendously greater \u201cmagnetic\u201d current than the external current in the winding. It is as if we had a lot more current going through the coil than we really have. When we reverse the current, all the little magnets flip over\u2014all those internal currents reverse\u2014and we get a much higher induced emf than we would get without the iron. If we want to calculate the inductance, we can do so through the energy\u2014as described in Section 17\u20138. The rate at which energy is delivered from the current source is IV . The voltage V is the cross-sectional area A of the core, times N , times dB/dt . From Eq. (36.20), I=( \u03f5 0 c 2 l/N)H . So we have dU dt =VI=( \u03f5 0 c 2 lA)H dB dt . d U d B Integrating over time, we have U=( \u03f5 0 c 2 lA)\u222bHdB. (36.21) Notice that lA is the volume of the torus, so we have shown that the energy density u=U/vol in a magnetic material is given by u= \u03f5 0 c 2 \u222bHdB. (36.22) An interesting feature is involved here. When we use alternating currents, the iron is driven around a hysteresis loop. Since B is not a single-valued function of H , the integral of \u222bHdB around one complete cycle is not equal to zero. It is the area enclosed inside the hysteresis curve. Thus, the driving source delivers a certain net energy each cycle\u2014an energy proportional to the area inside the hysteresis loop. And that energy is \u201clost.\u201d It is lost from the electromagnetic goings on, but turns up as heat in the iron. It is called the hysteresis loss. To keep such energy losses small, we would like the hysteresis loop to be as narrow as possible. One way to decrease the area of the loop is to reduce the maximum field that is reached during each cycle. For smaller maximum fields, we get a hysteresis curve like the one shown in Fig. 36\u20139. Also, special materials are designed to have a very narrow loop. The so-called transformer irons\u2014which are iron alloys with a small amount of silicon\u2014have been developed to have this property. When an inductance is run over a small hysteresis loop, the relationship between B and H can be approximated by a linear equation. People usually write B=\u03bcH. (36.23) The constant \u03bc is not the magnetic moment we have used before. It is called the permeability of the iron. (It is also sometimes called the \u201crelative permeability.\u201d) The permeability of ordinary irons is typically several thousand. There are special alloys alike \u201csupermalloy\u201d which can have permeabilities as high as a million. If we use the approximation that B=\u03bcH in Eq. (36.21), we can write the energy in a toroidal inductance as U =( \u03f5 0 c 2 lA)\u03bc\u222bHdH =( \u03f5 0 c 2 lA) \u03bc H 2 2 . (36.24) So the energy density is approximately u\u2248 \u03f5 0 c 2 2 \u03bc H 2 . 2 We can now set the energy of Eq. (36.24) equal to the energy L I 2 /2 of an inductance, and solve for L . We get L=( \u03f5 0 c 2 lA)\u03bc( H I ) 2 . H Using H/I from Eq. (36.20), we have L= \u03bc N 2 A \u03f5 0 c 2 l . (36.25) The inductance is proportional to \u03bc . If you want inductances for such things as audio amplifiers, you will try to operate them on a hysteresis loop where the B - H relationship is as linear as possible. (You will remember that we spoke in Chapter 50, Vol. I, about the generation of harmonics in nonlinear systems.) For such purposes, Eq. (36.23) is a useful approximation. On the other hand, if you want to generate harmonics, you may use an inductance which is intentionally operated in a highly nonlinear way. Then you will have to use the complete B - H curves, and analyze what happens by graphical or numerical methods. A \u201ctransformer\u201d is often made by putting two coils on the same torus\u2014or core\u2014of a magnetic material. (For the larger transformers, the core is made with rectangular proportions for convenience.) Then a varying current in the \u201cprimary\u201d winding causes the magnetic field in the core to change, which induces an emf in the \u201csecondary\u201d winding. Since the flux through each turn of both windings is the same, the emf\u2019s in the two windings are in the same ratio as the number of turns on each. A voltage applied to the primary is transformed to a different voltage at the secondary. Since a certain net current around the core is needed to produce the required change in the magnetic field, the algebraic sum of the currents in the two windings will be fixed and equal to the required \u201cmagnetizing\u201d current. If the current drawn from the secondary increases, the primary current must increase in proportion\u2014there is a \u201ctransformation\u201d of currents as well as voltage. Now let\u2019s discuss a practical situation which is a little more complicated. Suppose we have an electromagnet of the rather standard form shown in Fig. 36\u201310\u2014there is a \u201cC-shaped\u201d yoke of iron, with a coil of many turns of wire wrapped around the yoke. What is the magnetic field B in the gap? If the gap thickness is small compared with all the other dimensions, we can, as a first approximation, assume that the lines of B will go around through the loop, just as they did in the torus. They will look more or less as shown in Fig. 36\u201311(a). They tend to spread out somewhat in the gap, but if the gap is narrow, this will be a small effect. It is a fair approximation to assume that the flux of B through any cross section of the yoke is a constant. If the yoke has a uniform cross-sectional area A \u2014and if we neglect any edge effects at the gaps or at the corners\u2014we can say that B is uniform around the yoke. Also, B will have the same value in the gap. This follows from Eq. (36.16). Imagine the closed surface S , shown in Fig. 36\u201311(b), which has one face in the gap and the other in the iron. The total flux of B out of this surface must be zero. Calling B 1 the field in the gap and B 2 the field in the iron, we have (to our approximation) that B 1 A\u2212 B 2 A=0. B A B A 0. It follows that B 1 = B 2 . Now let\u2019s look at H . We can again use Eq. (36.19), taking the line integral around the curve \u0393 in Fig. 36\u201311(b). As before, the integral on the right-hand side is NI , the number of turns times the current. Now, however, H will be different in the iron and in the air. Calling H 2 the field in the iron and l 2 the path length around the yoke, this part of the curve will contribute the amount H 2 l 2 to the integral. Calling H 1 the field in the gap and l 1 the gap thickness, we get the contribution H 1 l 1 from the gap. We have that H 1 l 1 + H 2 l 2 = NI \u03f5 0 c 2 . (36.26) Now we know something else: that in the air gap, the magnetization is negligible, so that B 1 = H 1 . Since B 1 = B 2 , Eq. (36.26) becomes B 2 l 1 + H 2 l 2 = NI \u03f5 0 c 2 . (36.27) We still have two unknowns. To find B 2 and H 2 , we need another relationship\u2014namely, the one which relates B to H in the iron. If we can make the approximation that B 2 =\u03bc H 2 , we can solve the equation algebraically. However, let\u2019s do the general case, in which the magnetization curve of the iron is one like that shown in Fig. 36\u20138. What we want is the simultaneous solution of this functional relationship together with Eq. (36.27). We can find it by plotting a graph of Eq. (36.27) on the same graph with the magnetization curve, as is done in Fig. 36\u201312. Where the two curves intersect, we have our solution. For a given current I , the function (36.27) is the straight line marked I>0 in Fig. 36\u201312. The line intersects the H -axis ( B 2 =0 ) at H 2 =NI/ \u03f5 0 c 2 l 2 , and the slope is \u2212 l 2 / l 1 . Different currents just shift the line horizontally. From Fig. 36\u201312, we see that for a given current there are several different solutions, depending on how you got there. If you have just built the magnet and turned the current up to I , the field B 2 (which is also B 1 ) will have the value given by point a . If you have run the current to some very high value and come down to I , the field will be given by point b . Or, if you have just had a high negative current in the magnet and then come up to I , the field is the one at point c . The field in the gap will depend on what you have done in the past. When the current in the magnet is zero, the relation between B 2 and H 2 in Eq. (36.27) is shown by the line marked I=0 in the figure. There are still various possible solutions. If you have first saturated the iron, there may be a considerable residual field in the magnet as given by point d . You can take the coil off, and you have a permanent magnet. You can see that for a good permanent magnet, you would want a material with a wide hysteresis loop. Special alloys, such as Alnico V, have very wide loops. We now turn to the question of why it is that in ferromagnetic materials a small magnetic field produces such a large magnetization. The magnetization of ferromagnetic materials like iron and nickel comes from the magnetic moment of the electrons in the inner shell of the atom. Each electron has a magnetic moment \u03bc equal to q/2m times its g -factor, times its angular momentum J . For a single electron with no net orbital motion, g=2 , and the component of J in any direction\u2014say the z -direction\u2014is \u00b1\u210f/2 , so the component of \u03bc along the z -axis is \u03bc z = q\u210f 2m =0.928\u00d7 10 \u221223 amp\u22c5m 2 . (36.28) In an iron atom, there are actually two electrons that contribute to the ferromagnetism, so to keep the discussion simpler we will talk about nickel, which is ferromagnetic like iron but which has only one electron in the inner shell. (It is easy to extend the arguments to iron.) Now the point is that in the presence of an external field B , the atomic magnets tend to line up with the field, but are knocked about by thermal motions just as we described for paramagnetic materials. In the last chapter we found out that the balance between a magnetic field trying to line up the atomic magnets and the thermal motions trying to derange them produced the result that the mean magnetic moment per unit volume will end up as M=N\u03bctanh \u03bc B a kT . (36.29) By B a we mean the field acting at the atom, and kT is the Boltzmann energy. In the theory of paramagnetism we used for B a just B itself, neglecting the part of the field at any given atom contributed by the atoms nearby. In the ferromagnetic case, there is a complication. We shouldn\u2019t use the average field in the iron for the B a acting on an individual atom. Instead, we must do as we did in the case of dielectrics\u2014we have to find the local field acting at a single atom. For an exact calculation we should add up the fields at the atom in question contributed by all of the other atoms in the crystal lattice. But as we did for dielectrics, we will make the approximation that the field at an atom is the same as we would find in a small spherical hole in the material\u2014assuming that the moments of the atoms in the neighborhood are not changed by the presence of the hole. Following the arguments we made in Chapter 11, we might think that we could write B hole =B+ 1 3 M \u03f5 0 c 2 (wrong!). 1 M But that is not right. We can, however, make use of the results of Chapter 11 if we make a careful comparison of the equations of Chapter 11 with the equations for ferromagnetism in this chapter. Let\u2019s put together the corresponding equations. For regions where there are no conduction currents or charges we have: Electrostatics \u2207\u22c5(E+ P \u03f5 0 )=0 \u2207\u00d7E=0 Static ferromagnetism \u2207\u22c5B=0 \u2207\u00d7(B\u2212 M \u03f5 0 c 2 )=0 (36.30) These two sets of equations can be thought of as analogous if we make the following purely mathematical correspondences: E\u2192B\u2212 M \u03f5 0 c 2 ,E+ P \u03f5 0 \u2192B. M P This is the same as making the analogy E\u2192H,P\u2192M/ c 2 . (36.31) In other words, if we write the equations of ferromagnetism as \u2207\u22c5(H+ M \u03f5 0 c 2 )=0, \u2207\u00d7H=0, (36.32) they look like the equations of electrostatics. This purely algebraic correspondence has led to some confusion in the past. People tended to think that H was \u201cthe magnetic field.\u201d But, as we have seen, B and E are physically the fundamental fields, and H is a derived idea. So although the equations are analogous, the physics is not analogous. However, that doesn\u2019t need to stop us from using the principle that the same equations have the same solutions. We can use our earlier results for the electric field inside of holes of various shapes in dielectrics\u2014summarized in Fig. 36\u20131\u2014to find the field H inside of corresponding holes. Knowing H , we can determine B . For instance (using the results we summarized in Section 36\u20131), the field H in a needle-shaped hole parallel to M is the same as the H in the material, H hole = H material . H H But since M in the hole is zero, we have B hole = B material \u2212 M \u03f5 0 c 2 . (36.33) On the other hand, for a disc-shaped hole, perpendicular to M , we have E hole = E dielectric + P \u03f5 0 , P which translates into H hole = H material + M \u03f5 0 c 2 . M Or, in terms of B , B hole = B material . (36.34) Finally, for a spherical hole, by making our analogy with Eq. (36.3) we would have H hole = H material + M 3 \u03f5 0 c 2 M or B hole = B material \u2212 2 3 M \u03f5 0 c 2 . (36.35) This result is quite different from what we got for E . It is, of course, possible to get these results in a more physical way, by using the Maxwell equations directly. For example, Eq. (36.34) follows directly from \u2207\u22c5B=0 . (You use a Gaussian surface that is half in the material and half out.) Similarly, you can get Eq. (36.33) by using a line integral along a curve that goes up inside the hole and returns through the material. Physically, the field in the hole is reduced because of the surface currents\u2014which are given by \u2207\u00d7M . We will leave it for you to show that Eq. (36.35) can also be obtained by considering the effects of the surface currents on the boundary of the spherical cavity. In finding the equilibrium magnetization from Eq. (36.29), it turns out to be most convenient to deal with H ; so write B a =H+\u03bb M \u03f5 0 c 2 . (36.36) In the spherical hole approximation, we would have \u03bb= 1 3 , but, as you will see, we will want later to use some other value, so we leave it as an adjustable parameter. Also, we will take all the fields in the same direction so that we won\u2019t need to worry about the vector directions. If we were now to substitute Eq. (36.36) into Eq. (36.29), we would have one equation that relates the magnetization M to the magnetizing field H : M=N\u03bctanh(\u03bc H+\u03bbM/ \u03f5 0 c 2 kT ). 2 It is however, an equation that cannot be solved explicitly, so we will do it graphically. Let\u2019s put the problem in a generalized form by writing Eq. (36.29) as M M sat =tanhx, (36.37) where M sat is the saturation value of the magnetization, namely, N\u03bc , and x represents \u03bc B a /kT . The dependence of M/ M sat on x is shown by curve a in Fig. 36\u201313. We can also write x as a function of M \u2014using Eq. (36.36) for B a \u2014as x= \u03bc B a kT = \u03bcH kT +( \u03bc\u03bb M sat \u03f5 0 c 2 kT ) M M sat . (36.38) For any given value of H , this is a straight-line relationship between M/ M sat and x . The x intercept is at x=\u03bcH/kT , and the slope is \u03f5 0 c 2 kT/\u03bc\u03bb M sat . For any particular H , we would have a line like the one marked b in Fig. 36\u201313. The intersection of curves a and b gives us the solution for M/ M sat . We have solved the problem. Let\u2019s look at how the solutions will go for various circumstances. We start with H=0 . There are two possible situations, shown by the lines b 1 and b 2 in Fig. 36\u201314. You will notice from Eq. (36.38) that the slope of the line is proportional to the absolute temperature T . So, at high temperatures we would have a line like b 1 . The solution is M/ M sat =0 . When the magnetizing field H is zero, the magnetization is also zero. But at low temperatures, we would have a line like b 2 , and there are two solutions for M/ M sat \u2014one with M/ M sat =0 and one with M/ M sat near one. It turns out that only the upper solution is stable\u2014as you can see by considering small variations about these solutions. According to these ideas, then, a magnetic material should magnetize itself spontaneously at sufficiently low temperatures. In short, when the thermal motions are small enough, the coupling between the atomic magnets causes them all to line up parallel to each other\u2014we have a permanently magnetized material analogous to the ferroelectrics we discussed in Chapter 11. If we start at high temperatures and come down, there is a critical temperature, called the Curie temperature T c , where the ferromagnetic behavior suddenly sets in. This temperature corresponds to the line b 3 of Fig. 36\u201314, which is tangent to the curve a , and has, therefore, a slope of 1 . The Curie temperature is given by \u03f5 0 c 2 k T c \u03bc\u03bb M sat =1. (36.39) We can, if we wish, write Eq. (36.38) more simply in terms of T c as x= \u03bcH kT + T c T ( M M sat ). (36.40) Now we want to see what happens for small magnetizing fields H . We can see from Fig. 36\u201314 how things will go if we shift our straight lines a little to the right. For the low-temperature case, the intersection point will move out a little bit along the low-slope part of curve a , and M will change relatively little. For the high-temperature case, however, the intersection point runs up the steep part of curve a , and M will change relatively rapidly. In fact, we can approximate this part of curve a by a straight line of unit slope, and write: M M sat =x= \u03bcH kT + T c T ( M M sat ). M H T M Now we can solve for M/ M sat : M M sat = \u03bcH k(T\u2212 T c ) . (36.41) We have a law that is something like the one we had for paramagnetism. For paramagnetism, we had M M sat = \u03bcB kT . (36.42) One difference now is that we have the magnetization in terms of H , which includes some of the effects of the interaction of the atomic magnets, but the main difference is that the magnetization is inversely proportional to the difference between T and T c , instead of to the absolute temperate T , alone. Neglecting the interactions between neighboring atoms corresponds to taking \u03bb=0 , which from Eq. (36.39) means taking T c =0 . Then the results are just what we had in Chapter 35. We can check our theoretical picture with the experimental data for nickel. It is observed experimentally that the ferromagnetic behavior of nickel disappears when its temperature is raised above 631 \u2218 K. We can compare this with T c calculated from Eq. (36.39). Remembering that M sat =\u03bcN , we have T c =\u03bb N \u03bc 2 k \u03f5 0 c 2 . 2 From the density and atomic weight of nickel, we get N=9.1\u00d7 10 28 m \u22123 . 28 3 Taking \u03bc from Eq. (36.28), and setting \u03bb= 1 3 , we get T c = 0.24 \u2218 K. T \u2218 K There is a discrepancy of a factor of about 2600 ! Our theory of ferromagnetism fails completely. We can try to \u201cpatch up\u201d the theory as Weiss did by saying that for some unknown reason \u03bb is not one-third, but (2600)\u00d7 1 3 \u2014or about 900 . It turns out that one gets similar values for other ferromagnetic materials like iron. To see what this means, let\u2019s go back to Eq. (36.36). We see that a large \u03bb means that B a , the local field on the atom, appears to be much, much larger than we would think. In fact, writing H=B\u2212M/ \u03f5 0 c 2 , we have B a =B+ (\u03bb\u22121)M \u03f5 0 c 2 . ( \u03bb ) According to our original idea\u2014with \u03bb= 1 3 the local magnetization M reduces the effective field B a by the amount \u2212 2 3 M/ \u03f5 0 c 2 . Even if our model of a spherical hole were not very good, we would still expect some reduction. Instead, to explain the phenomenon of ferromagnetism, we have to imagine that the magnetization of the field enhances the local field by some large factor\u2014like one thousand or more. There doesn\u2019t seem to be any reasonable way to manufacture such tremendous fields at an atom\u2014nor even fields of the proper sign! Clearly, our \u201cmagnetic\u201d theory of ferromagnetism is a dismal failure. We must conclude, then, that ferromagnetism has to do with some nonmagnetic interaction between the spinning electrons in neighboring atoms. This interaction must generate a strong tendency for all of the nearby spins to line up in one direction. We will see later that it has to do with quantum mechanics and the Pauli exclusion principle. Finally, we look at what happens at low temperatures\u2014for T< T c . We have seen that there will then be a spontaneous magnetization\u2014even with H=0 \u2014given by the intersection of the curves a and b 2 of Fig. 36\u201314. If we solve for M for various temperatures\u2014by varying the slope of the line b 2 \u2014we get the theoretical curve shown in Fig. 36\u201315. This curve should be the same for all ferromagnetic materials for which the atomic moment comes from a single electron. The curves for other materials are only slightly different. In the limit, as T goes to absolute zero, M goes to M sat . As the temperature is increased, the magnetization decreases, falling to zero at the Curie temperature. The points in Fig. 36\u201315 are the experimental observations for nickel. They fit the theoretical curve fairly well. Even though we don\u2019t understand the basic mechanism, the general features of the theory seem to be correct. Finally, there is one more disturbing discrepancy in our attempt to understand ferromagnetism. We have found that above some temperature the material should behave like a paramagnetic substance with a magnetization M proportional to H (or B ), and that below that temperature it should become spontaneously magnetized. But that\u2019s not what we found when we measured the magnetization curve for iron. It only became permanently magnetized after we had \u201cmagnetized\u201d it. According to the ideas just discussed, it would magnetize itself! What is wrong? Well, it turns out that if you look at a small enough crystal of iron or nickel, it is indeed completely magnetized! But in large pieces of iron, there are many small regions or \u201cdomains\u201d that are magnetized in different directions, so that on a large scale the average magnetization appears to be zero. In each small domain, however, the iron has a locked-in magnetization with M nearly equal to M sat . The consequences of this domain structure are that gross properties of large pieces of material are quite different from the microscopic properties that we have really been treating. We will take up in the next lecture the story of the practical behavior of bulk magnetic materials."
    },
    {
        "input": "Semiconductors",
        "output": "One of the remarkable and dramatic developments in recent years has been the application of solid state science to technical developments in electrical devices such as transistors. The study of semiconductors led to the discovery of their useful properties and to a large number of practical applications. The field is changing so rapidly that what we tell you today may be incorrect next year. It will certainly be incomplete. And it is perfectly clear that with the continuing study of these materials many new and more wonderful things will be possible as time goes on. You will not need to understand this chapter for what comes later in this volume, but you may find it interesting to see that at least something of what you are learning has some relation to the practical world. There are large numbers of semiconductors known, but we\u2019ll concentrate on those which now have the greatest technical application. They are also the ones that are best understood, and in understanding them we will obtain a degree of understanding of many of the others. The semiconductor substances in most common use today are silicon and germanium. These elements crystallize in the diamond lattice, a kind of cubic structure in which the atoms have tetrahedral bonding with their four nearest neighbors. They are insulators at very low temperatures\u2014near absolute zero\u2014although they do conduct electricity somewhat at room temperature. They are not metals; they are called semiconductors. If we somehow put an extra electron into a crystal of silicon or germanium which is at a low temperature, we will have just the situation we described in the last chapter. The electron will be able to wander around in the crystal jumping from one atomic site to the next. Actually, we have looked only at the behavior of electrons in a rectangular lattice, and the equations would be somewhat different for the real lattice of silicon or germanium. All of the essential points are, however, illustrated by the results for the rectangular lattice. As we saw in Chapter 13, these electrons can have energies only in a certain energy band\u2014called the conduction band. Within this band the energy is related to the wave-number k of the probability amplitude C (see Eq. (13.24)) by E=E0\u22122Axcoskxa\u22122Aycoskyb\u22122Azcoskzc. The A \u2019s are the amplitudes for jumping in the x -, y -, and z -directions, and a , b , and c are the lattice spacings in these directions. For energies near the bottom of the band, we can approximate Eq. (14.1) by E=Emin+Axa2k 2 x +Ayb2k 2 y +Azc2k 2 z (see Section 13\u20134). If we think of electron motion in some particular direction, so that the components of k are always in the same ratio, the energy is a quadratic function of the wave number\u2014and as we have seen of the momentum of the electron. We can write E=Emin+\u03b1k2, where \u03b1 is some constant, and we can make a graph of E versus k as in Fig. 14\u20131. We\u2019ll call such a graph an \u201cenergy diagram.\u201d An electron in a particular state of energy and momentum can be indicated by a point such as S in the figure. As we also mentioned in Chapter 13, we can have a similar situation if we remove an electron from a neutral insulator. Then, an electron can jump over from a nearby atom and fill the \u201chole,\u201d but leaving another \u201chole\u201d at the atom it started from. We can describe this behavior by writing an amplitude to find the hole at any particular atom, and by saying that the hole can jump from one atom to the next. (Clearly, the amplitudes A that the hole jumps from atom a to atom b is just the same as the amplitude that an electron on atom b jumps into the hole at atom a .) The mathematics is just the same for the hole as it was for the extra electron, and we get again that the energy of the hole is related to its wave number by an equation just like Eq. (14.1) or (14.2), except, of course, with different numerical values for the amplitudes Ax , Ay , and Az . The hole has an energy related to the wave number of its probability amplitudes. Its energy lies in a restricted band, and near the bottom of the band its energy varies quadratically with the wave number\u2014or momentum\u2014just as in Fig. 14\u20131. Following the arguments of Section 13\u20133, we would find that the hole also behaves like a classical particle with a certain effective mass\u2014except that in noncubic crystals the mass depends on the direction of motion. So the hole behaves like a positive particle moving through the crystal. The charge of the hole-particle is positive, because it is located at the site of a missing electron; and when it moves in one direction there are actually electrons moving in the opposite direction. If we put several electrons into a neutral crystal, they will move around much like the atoms of a low-pressure gas. If there are not too many, their interactions will not be very important. If we then put an electric field across the crystal, the electrons will start to move and an electric current will flow. Eventually they would all be drawn to one edge of the crystal, and, if there is a metal electrode there, they would be collected, leaving the crystal neutral. Similarly we could put many holes into a crystal. They would roam around at random unless there is an electric field. With a field they would flow toward the negative terminal, and would be \u201ccollected\u201d\u2014what actually happens is that they are neutralized by electrons from the metal terminal. One can also have both holes and electrons together. If there are not too many, they will all go their way independently. With an electric field, they will all contribute to the current. For obvious reasons, electrons are called the negative carriers and the holes are called the positive carriers. We have so far considered that electrons are put into the crystal from the outside, or are removed to make a hole. It is also possible to \u201ccreate\u201d an electron-hole pair by taking a bound electron away from one neutral atom and putting it some distance away in the same crystal. We then have a free electron and a free hole, and the two can move about as we have described. The energy required to put an electron into a state S \u2014we say to \u201ccreate\u201d the state S \u2014is the energy E\u2212 shown in Fig. 14\u20132. It is some energy above E \u2212 min . The energy required to \u201ccreate\u201d a hole in some state S\u2032 is the energy E+ of Fig. 14\u20133, which is some energy greater than E + min . Now if we create a pair in the states S and S\u2032 , the energy required is just E\u2212+E+ . The creation of pairs is a common process (as we will see later), so many people like to put Fig. 14\u20132 and Fig. 14\u20133 together on the same graph\u2014with the hole energy plotted downward, although it is, of course a positive energy. We have combined our two graphs in this way in Fig. 14\u20134. The advantage of such a graph is that the energy E pair = E \u2212 + E + required to create a pair with the electron in S and the hole in S \u2032 is just the vertical distance between S and S \u2032 as shown in Fig. 14\u20134. The minimum energy required to create a pair is called the \u201cgap\u201d energy and is equal to E \u2212 min + E + min . Sometimes you will see a simpler diagram called an energy level diagram which is drawn when people are not interested in the k variable. Such a diagram\u2014shown in Fig. 14\u20135\u2014just shows the possible energies for the electrons and holes.1 How can electron-hole pairs be created? There are several ways. For example, photons of light (or x-rays) can be absorbed and create a pair if the photon energy is above the energy of the gap. The rate at which pairs are produced is proportional to the light intensity. If two electrodes are plated on a wafer of the crystal and a \u201cbias\u201d voltage is applied, the electrons and holes will be drawn to the electrodes. The circuit current will be proportional to the intensity of the light. This mechanism is responsible for the phenomenon of photoconductivity and the operation of photoconductive cells. Electron hole pairs can also be produced by high-energy particles. When a fast-moving charged particle\u2014for instance, a proton or a pion with an energy of tens or hundreds of MeV\u2014goes through a crystal, its electric field will knock electrons out of their bound states creating electron-hole pairs. Such events occur hundreds of thousands of times per millimeter of track. After the passage of the particle, the carriers can be collected and in doing so will give an electrical pulse. This is the mechanism at play in the semiconductor counters recently put to use for experiments in nuclear physics. Such counters do not require semiconductors, they can also be made with crystalline insulators. In fact, the first of such counters was made using a diamond crystal which is an insulator at room temperature. Very pure crystals are required if the holes and electrons are to be able to move freely to the electrodes without being trapped. The semiconductors silicon and germanium are used because they can be produced with high purity in reasonable large sizes (centimeter dimensions). So far we have been concerned with semiconductor crystals at temperatures near absolute zero. At any finite temperature there is still another mechanism by which electron-hole pairs can be created. The pair energy can be provided from the thermal energy of the crystal. The thermal vibrations of the crystal can transfer their energy to a pair\u2014giving rise to \u201cspontaneous\u201d creation. The probability per unit time that the energy as large as the gap energy E gap will be concentrated at one atomic site is proportional to e \u2212 E gap /\u03baT , where T is the temperature and \u03ba is Boltzmann\u2019s constant (see Chapter 40, Vol. I). Near absolute zero there is no appreciable probability, but as the temperature rises there is an increasing probability of producing such pairs. At any finite temperature the production should continue forever at a constant rate giving more and more negative and positive carriers. Of course that does not happen because after a while the electrons and holes accidentally find each other\u2014the electron drops into the hole and the excess energy is given to the lattice. We say that the electron and hole \u201cannihilate.\u201d There is a certain probability per second that a hole meets an electron and the two things annihilate each other. If the number of electrons per unit volume is N n ( n for negative carriers) and the density of positive carriers is N p , the chance per unit time that an electron and a hole will find each other and annihilate is proportional to the product N n N p . In equilibrium this rate must equal the rate that pairs are created. You see that in equilibrium the product of N n and N p should be given by some constant times the Boltzmann factor: N n N p =const e \u2212 E gap /\u03baT . (14.4) When we say constant, we mean nearly constant. A more complete theory\u2014which includes more details about how holes and electrons \u201cfind\u201d each other\u2014shows that the \u201cconstant\u201d is slightly dependent upon temperature, but the major dependence on temperature is in the exponential. Let\u2019s consider, as an example, a pure material which is originally neutral. At a finite temperature you would expect the number of positive and negative carriers to be equal, N n = N p . Then each of them should vary with temperature as e \u2212 E gap /2\u03baT . The variation of many of the properties of a semiconductor\u2014the conductivity for example\u2014is mainly determined by the exponential factor because all the other factors vary much more slowly with temperature. The gap energy for germanium is about 0.72 eV and for silicon 1.1 eV. At room temperature \u03baT is about 1/40 of an electron volt. At these temperatures there are enough holes and electrons to give a significant conductivity, while at, say, 30 \u2218 K\u2014one-tenth of room temperature\u2014the conductivity is imperceptible. The gap energy of diamond is 6 or 7 eV and diamond is a good insulator at room temperature. So far we have talked about two ways that extra electrons can be put into an otherwise ideally perfect crystal lattice. One way was to inject the electron from an outside source; the other way, was to knock a bound electron off a neutral atom creating simultaneously an electron and a hole. It is possible to put electrons into the conduction band of a crystal in still another way. Suppose we imagine a crystal of germanium in which one of the germanium atoms is replaced by an arsenic atom. The germanium atoms have a valence of 4 and the crystal structure is controlled by the four valence electrons. Arsenic, on the other hand, has a valence of 5 . It turns out that a single arsenic atom can sit in the germanium lattice (because it has approximately the correct size), but in doing so it must act as a valence 4 atom\u2014using four of its valence electrons to form the crystal bonds and having one electron left over. This extra electron is very loosely attached\u2014the binding energy is only about 1/100 of an electron volt. At room temperature the electron easily picks up that much energy from the thermal energy of the crystal, and then takes off on its own\u2014moving about in the lattice as a free electron. An impurity atom such as the arsenic is called a donor site because it can give up a negative carrier to the crystal. If a crystal of germanium is grown from a melt to which a very small amount of arsenic has been added, the arsenic donor sites will be distributed throughout the crystal and the crystal will have a certain density of negative carriers built in. You might think that these carriers would get swept away as soon as any small electric field was put across the crystal. This will not happen, however, because the arsenic atoms in the body of the crystal each have a positive charge. If the body of the crystal is to remain neutral, the average density of negative carrier electrons must be equal to the density of donor sites. If you put two electrodes on the edges of such a crystal and connect them to a battery, a current will flow; but as the carrier electrons are swept out at one end, new conduction electrons must be introduced from the electrode on the other end so that the average density of conduction electrons is left very nearly equal to the density of donor sites. Since the donor sites are positively charged, there will be some tendency for them to capture some of the conduction electrons as they diffuse around inside the crystal. A donor site can, therefore, act as a trap such as those we discussed in the last section. But if the trapping energy is sufficiently small\u2014as it is for arsenic\u2014the number of carriers which are trapped at any one time is a small fraction of the total. For a complete understanding of the behavior of semiconductors one must take into account this trapping. For the rest of our discussion, however, we will assume that the trapping energy is sufficiently low and the temperature is sufficiently high, that all of the donor sites have given up their electrons. This is, of course, just an approximation. It is also possible to build into a germanium crystal some impurity atom whose valence is 3 , such as aluminum. The aluminum atom tries to act as a valence 4 object by stealing an extra electron. It can steal an electron from some nearby germanium atom and end up as a negatively charged atom with an effective valence of 4 . Of course, when it steals the electron from a germanium atom, it leaves a hole there; and this hole can wander around in the crystal as a positive carrier. An impurity atom which can produce a hole in this way is called an acceptor because it \u201caccepts\u201d an electron. If a germanium or a silicon crystal is grown from a melt to which a small amount of aluminum impurity has been added, the crystal will have built-in a certain density of holes which can act as positive carriers. When a donor or an acceptor impurity is added to a semiconductor, we say that the material has been \u201cdoped.\u201d When a germanium crystal with some built-in donor impurities is at room temperature, some conduction electrons are contributed by the thermally induced electron-hole pair creation as well as by the donor sites. The electrons from both sources are, naturally, equivalent, and it is the total number N n which comes into play in the statistical processes that lead to equilibrium. If the temperature is not too low, the number of negative carriers contributed by the donor impurity atoms is roughly equal to the number of impurity atoms present. In equilibrium Eq. (14.4) must still be valid; at a given temperature the product N n N p is determined. This means that if we add some donor impurity which increases N n , the number N p of positive carriers will have to decrease by such an amount that N n N p is unchanged. If the impurity concentration is high enough, the number N n of negative carriers is determined by the number of donor sites and is nearly independent of temperature\u2014all of the variation in the exponential factor is supplied by N p , even though it is much less than N n . An otherwise pure crystal with a small concentration of donor impurity will have a majority of negative carriers; such a material is called an \u201c n -type\u201d semiconductor. If an acceptor-type impurity is added to the crystal lattice, some of the new holes will drift around and annihilate some of the free electrons produced by thermal fluctuation. This process will go on until Eq. (14.4) is satisfied. Under equilibrium conditions the number of positive carriers will be increased and the number of negative carriers will be decreased, leaving the product a constant. A material with an excess of positive carriers is called a \u201c p -type\u201d semiconductor. If we put two electrodes on a piece of semiconductor crystal and connect them to a source of potential difference, there will be an electric field inside the crystal. The electric field will cause the positive and the negative carriers to move, and an electric current will flow. Let\u2019s consider first what will happen in an n -type material in which there is a large majority of negative carriers. For such material we can disregard the holes; they will contribute very little to the current because there are so few of them. In an ideal crystal the carriers would move across without any impediment. In a real crystal at a finite temperature, however,\u2014especially in a crystal with some impurities\u2014the electrons do not move completely freely. They are continually making collisions which knock them out of their original trajectories, that is, changing their momentum. These collisions are just exactly the scatterings we talked about in the last chapter and occur at any irregularity in the crystal lattice. In an n -type material the main causes of scattering are the very donor sites that are producing the carriers. Since the conduction electrons have a very slightly different energy at the donor sites, the probability waves are scattered from that point. Even in a perfectly pure crystal, however, there are (at any finite temperature) irregularities in the lattice due to thermal vibrations. From the classical point of view we can say that the atoms aren\u2019t lined up exactly on a regular lattice, but are, at any instant, slightly out of place due to their thermal vibrations. The energy E 0 associated with each lattice point in the theory we described in Chapter 13 varies a little bit from place to place so that the waves of probability amplitude are not transmitted perfectly but are scattered in an irregular fashion. At very high temperatures or for very pure materials this scattering may become important, but in most doped materials used in practical devices the impurity atoms contribute most of the scattering. We would like now to make an estimate of the electrical conductivity of such a material. When an electric field is applied to an n -type semiconductor, each negative carrier will be accelerated in this field, picking up velocity until it is scattered from one of the donor sites. This means that the carriers which are ordinarily moving about in a random fashion with their thermal energies will pick up an average drift velocity along the lines of the electric field and give rise to a current through the crystal. The drift velocity is in general rather small compared with the typical thermal velocities so that we can estimate the current by assuming that the average time that the carrier travels between scatterings is a constant. Let\u2019s say that the negative carrier has an effective electric charge q n . In an electric field E , the force on the carrier will be q n E . In Section 43\u20133 of Volume I we calculated the average drift velocity under such circumstances and found that it is given by F\u03c4/m , where F is the force on the charge, \u03c4 is the mean free time between collisions, and m is the mass. We should use the effective mass we calculated in the last chapter but since we want to make a rough calculation we will suppose that this effective mass is the same in all directions. Here we will call it m n . With this approximation the average drift velocity will be v drift = q n E \u03c4 n m n . (14.5) Knowing the drift velocity we can find the current. Electric current density j is just the number of carriers per unit volume, N n , multiplied by the average drift velocity, and by the charge on each carrier. The current density is therefore j= N n v drift q n = N n q 2 n \u03c4 n m n E. (14.6) We see that the current density is proportional to the electric field; such a semiconductor material obeys Ohm\u2019s law. The coefficient of proportionality between j and E , the conductivity \u03c3 , is \u03c3= N n q 2 n \u03c4 n m n . (14.7) For an n -type material the conductivity is relatively independent of temperature. First, the number of majority carriers N n is determined primarily by the density of donors in the crystal (so long as the temperature is not so low that too many of the carriers are trapped). Second, the mean time between collisions \u03c4 n is mainly controlled by the density of impurity atoms, which is, of course, independent of the temperature. We can apply all the same arguments to a p -type material, changing only the values of the parameters which appear in Eq. (14.7). If there are comparable numbers of both negative and positive carriers present at the same time, we must add the contributions from each kind of carrier. The total conductivity will be given by \u03c3= N n q 2 n \u03c4 n m n + N p q 2 p \u03c4 p m p . (14.8) For very pure materials, N p and N n will be nearly equal. They will be smaller than in a doped material, so the conductivity will be less. Also they will vary rapidly with temperature (like e \u2212 E gap /2\u03baT , as we have seen), so the conductivity may change extremely fast with temperature. It is certainly a peculiar thing that in a substance where the only relatively free objects are electrons, there should be an electrical current carried by holes that behave like positive particles. We would like, therefore, to describe an experiment that shows in a rather clear way that the sign of the carrier of electric current is quite definitely positive. Suppose we have a block made of semiconductor material\u2014it could also be a metal\u2014and we put an electric field on it so as to draw a current in some direction, say the horizontal direction as drawn in Fig. 14\u20136. Now suppose we put a magnetic field on the block pointing at a right angle to the current, say into the plane of the figure. The moving carriers will feel a magnetic force q(v\u00d7B) . And since the average drift velocity is either right or left\u2014depending on the sign of the charge on the carrier\u2014the average magnetic force on the carriers will be either up or down. No, that is not right! For the directions we have assumed for the current and the magnetic field the magnetic force on the moving charges will always be up. Positive charges moving in the direction of j (to the right) will feel an upward force. If the current is carried by negative charges, they will be moving left (for the same sign of the conduction current) and they will also feel an upward force. Under steady conditions, however, there is no upward motion of the carriers because the current can flow only from left to right. What happens is that a few of the charges initially flow upward, producing a surface charge density along the upper surface of semiconductor\u2014leaving an equal and opposite surface charge density along the bottom surface of the crystal. The charges pile up on the top and bottom surfaces until the electric forces they produce on the moving charges just exactly cancel the magnetic force (on the average) so that the steady current flows horizontally. The charges on the top and bottom surfaces will produce a potential difference vertically across the crystal which can be measured with a high-resistance voltmeter, as shown in Fig. 14\u20137. The sign of the potential difference registered by the voltmeter will depend on the sign of the carrier charges responsible for the current. When such experiments were first done it was expected that the sign of the potential difference would be negative as one would expect for negative conduction electrons. People were, therefore, quite surprised to find that for some materials the sign of the potential difference was in the opposite direction. It appeared that the current carrier was a particle with a positive charge. From our discussion of doped semiconductors it is understandable that an n -type semiconductor should produce the sign of potential difference appropriate to negative carriers, and that a p -type semiconductor should give an opposite potential difference, since the current is carried by the positively charged holes. The original discovery of the anomalous sign of the potential difference in the Hall effect was made in a metal rather than a semiconductor. It had been assumed that in metals the conduction was always by electron; however, it was found out that for beryllium the potential difference had the wrong sign. It is now understood that in metals as well as in semiconductors it is possible, in certain circumstances, that the \u201cobjects\u201d responsible for the conduction are holes. Although it is ultimately the electrons in the crystal which do the moving, nevertheless, the relationship of the momentum and the energy, and the response to external fields is exactly what one would expect for an electric current carried by positive particles. Let\u2019s see if we can make a quantitative estimate of the magnitude of the voltage difference expected from the Hall effect. If the voltmeter in Fig. 14\u20137 draws a negligible current, then the charges inside the semiconductor must be moving from left to right and the vertical magnetic force must be precisely cancelled by a vertical electric field which we will call E tr (the \u201ctr\u201d is for \u201ctransverse\u201d). If this electric field is to cancel the magnetic forces, we must have E tr =\u2212 v drift \u00d7B. (14.9) Using the relation between the drift velocity and the electric current density given in Eq. (14.6), we get E tr =\u2212 1 qN jB. 1 The potential difference between the top and the bottom of the crystal is, of course, this electric field strength multiplied by the height of the crystal. The electric field strength E tr in the crystal is proportional to the current density and to the magnetic field strength. The constant of proportionality 1/qN is called the Hall coefficient and is usually represented by the symbol R H . The Hall coefficient depends just on the density of carriers\u2014provided that carriers of one sign are in a large majority. Measurement of the Hall effect is, therefore, one convenient way of determining experimentally the density of carriers in a semiconductor. We would like to discuss now what happens if we take two pieces of germanium or silicon with different internal characteristics\u2014say different kinds or amounts of doping\u2014and put them together to make a \u201cjunction.\u201d Let\u2019s start out with what is called a p - n junction in which we have p -type germanium on one side of the boundary and n -type germanium on the other side of the boundary\u2014as sketched in Fig. 14\u20138. Actually, it is not practical to put together two separate pieces of crystal and have them in uniform contact on an atomic scale. Instead, junctions are made out of a single crystal which has been modified in the two separate regions. One way is to add some suitable doping impurity to the \u201cmelt\u201d after only half of the crystal has grown. Another way is to paint a little of the impurity element on the surface and then heat the crystal causing some impurity atoms to diffuse into the body of the crystal. Junctions made in these ways do not have a sharp boundary, although the boundaries can be made as thin as 10 \u22124 centimeters or so. For our discussions we will imagine an ideal situation in which these two regions of the crystal with different properties meet at a sharp boundary. On the n -type side of the p - n junction there are free electrons which can move about, as well as the fixed donor sites which balance the overall electric charge. On the p -type side there are free holes moving about and an equal number of negative acceptor sites keeping the charge balanced. Actually, that describes the situation before we put the two materials in contact. Once they are connected together the situation will change near the boundary. When the electrons in the n -type material arrive at the boundary they will not be reflected back as they would at a free surface, but are able to go right on into the p -type material. Some of the electrons of the n -type material will, therefore, tend to diffuse over into the p -type material where there are fewer electrons. This cannot go on forever because as we lose electrons from the n -side the net positive charge there increases until finally an electric voltage is built up which retards the diffusion of electrons into the p -side. In a similar way, the positive carriers of the p -type material can diffuse across the junction into the n -type material. When they do this they leave behind an excess of negative charge. Under equilibrium conditions the net diffusion current must be zero. This is brought about by the electric fields, which are established in such a way as to draw the positive carriers back toward the p -type material. The two diffusion processes we have been describing go on simultaneously and, you will notice, both act in the direction which will charge up the n -type material in a positive sense and the p -type material in a negative sense. Because of the finite conductivity of the semiconductor material, the change in potential from the p -side to the n -side will occur in a relatively narrow region near the boundary; the main body of each block of material will have a uniform potential. Let\u2019s imagine an x -axis in a direction perpendicular to the boundary surface. Then the electric potential will vary with x , as shown in Fig. 14\u20139(b). We have also shown in part (c) of the figure the expected variation of the density N n of n -carriers and the density N p of p -carriers. Far away from the junction the carrier densities N p and N n should be just the equilibrium density we would expect for individual blocks of materials at the same temperature. (We have drawn the figure for a junction in which the p -type material is more heavily doped than the n -type material.) Because of the potential gradient at the junction, the positive carriers have to climb up a potential hill to get to the n -type side. This means that under equilibrium conditions there can be fewer positive carriers in the n -type material than there are in the p -type material. Remembering the laws of statistical mechanics, we expect that the ratio of p -type carriers on the two sides to be given by the following equation: N p (n-side) N p (p-side) = e \u2212 q p V/\u03baT . (14.10) The product q p V in the numerator of the exponential is just the energy required to carry a charge of q p through a potential difference V . We have a precisely similar equation for the densities of the n -type carriers: N n (n-side) N n (p-side) = e \u2212 q n V/\u03baT . (14.11) If we know the equilibrium densities in each of the two materials, we can use either of the two equations above to determine the potential difference across the junction. Notice that if Eqs. (14.10) and (14.11) are to give the same value for the potential difference V , the product N p N n must be the same for the p -side as for the n -side. (Remember that q n =\u2212 q p .) We have seen earlier, however, that this product depends only on the temperature and the gap energy of the crystal. Provided both sides of the crystal are at the same temperature, the two equations are consistent with the same value of the potential difference. Since there is a potential difference from one side of the junction to the other, it looks something like a battery. Perhaps if we connect a wire from the n -type side to the p -type side we will get an electrical current. That would be nice because then the current would flow forever without using up any material and we would have an infinite source of energy in violation of the second law of thermodynamics! There is, however, no current if you connect a wire from the p -side to the n -side. And the reason is easy to see. Suppose we imagine first a wire made out of a piece of undoped material. When we connect this wire to the n -type side, we have a junction. There will be a potential difference across this junction. Let\u2019s say that it is just one-half the potential difference from the p -type material to the n -type material. When we connect our undoped wire to the p -type side of the junction, there is also a potential difference at this junction\u2014again, one-half the potential drop across the p - n junction. At all the junctions the potential differences adjust themselves so that there is no net current flow in the circuit. Whatever kind of wire you use to connect together the two sides of the p - n junction, you are producing two new junctions, and so long as all the junctions are at the same temperature, the potential jumps at the junctions all compensate each other and no current will flow in the circuit. It does turn out, however\u2014if you work out the details\u2014that if some of the junctions are at a different temperature than the other junctions, currents will flow. Some of the junctions will be heated and others will be cooled by this current and thermal energy will be converted into electrical energy. This effect is responsible for the operation of thermocouples which are used for measuring temperatures, and of thermoelectric generators. The same effect is also used to make small refrigerators. If we cannot measure the potential difference between the two sides of a p - n junction, how can we really be sure that the potential gradient shown in Fig. 14\u20139 really exists? One way is to shine light on the junction. When the light photons are absorbed they can produce an electron-hole pair. In the strong electric field that exists at the junction (equal to the slope of the potential curve of Fig. 14\u20139) the hole will be driven into the p -type region and the electron will be driven into the n -type region. If the two sides of the junction are now connected to an external circuit, these extra charges will provide a current. The energy of the light will be converted into electrical energy in the junction. The solar cells which generate electrical power for the operation of some of our satellites operate on this principle. In our discussion of the operation of a semiconductor junction we have been assuming that the holes and the electrons act more-or-less independently\u2014except that they somehow get into proper statistical equilibrium. When we were describing the current produced by light shining on the junction, we were assuming that an electron or a hole produced in the junction region would get into the main body of the crystal before being annihilated by a carrier of the opposite polarity. In the immediate vicinity of the junction, where the density of carriers of both signs is approximately equal, the effect of electron-hole annihilation (or as it is often called, \u201crecombination\u201d) is an important effect, and in a detailed analysis of a semiconductor junction must be properly taken into account. We have been assuming that a hole or an electron produced in a junction region has a good chance of getting into the main body of the crystal before recombining. The typical time for an electron or a hole to find an opposite partner and annihilate it is for typical semiconductor materials in the range between 10 \u22123 and 10 \u22127 seconds. This time is, incidentally, much longer than the mean free time \u03c4 between collisions with scattering sites in the crystal which we used in the analysis of conductivity. In a typical p - n junction, the time for an electron or hole formed in the junction region to be swept away into the body of the crystal is generally much shorter than the recombination time. Most of the pairs will, therefore, contribute to an external current. We would like to show next how it is that a p - n junction can act like a rectifier. If we put a voltage across the junction, a large current will flow if the polarity is in one direction, but a very small current will flow if the same voltage is applied in the opposite direction. If an alternating voltage is applied across the junction, a net current will flow in one direction\u2014the current is \u201crectified.\u201d Let\u2019s look again at what is going on in the equilibrium condition described by the graphs of Fig. 14\u20139. In the p -type material there is a large concentration N p of positive carriers. These carriers are diffusing around and a certain number of them each second approach the junction. This current of positive carriers which approaches the junction is proportional to N p . Most of them, however, are turned back by the high potential hill at the junction and only the fraction e \u2212qV/\u03baT gets through. There is also a current of positive carriers approaching the junction from the other side. This current is also proportional to the density of positive carriers in the n -type region, but the carrier density here is much smaller than the density on the p -type side. When the positive carriers approach the junction from the n -type side, they find a hill with a negative slope and immediately slide downhill to the p-type side of the junction. Let\u2019s call this current I 0 . Under equilibrium the currents from the two directions are equal. We expect then the following relation: I 0 \u221d N p (n-side)= N p (p-side) e \u2212qV/\u03baT . (14.12) You will notice that this equation is really just the same as Eq. (14.10). We have just derived it in a different way. Suppose, however, that we lower the voltage on the n -side of the junction by an amount \u0394V \u2014which we can do by applying an external potential difference to the junction. Now the difference in potential across the potential hill is no longer V but V\u2212\u0394V . The current of positive carriers from the p -side to the n -side will now have this potential difference in its exponential factor. Calling this current I 1 , we have I 1 \u221d N p (p-side) e \u2212q(V\u2212\u0394V)/\u03baT . ( V \u0394 V ) / T This current is larger than I 0 by just the factor e q\u0394V/\u03baT . So we have the following relation between I 1 and I 0 : I 1 = I 0 e +q\u0394V/\u03baT . (14.13) The current from the p -side increases exponentially with the externally applied voltage \u0394V . The current of positive carriers from the n -side, however, remains constant so long as \u0394V is not too large. When they approach the barrier, these carriers will still find a downhill potential and will all fall down to the p -side. (If \u0394V is larger than the natural potential difference V , the situation would change, but we will not consider what happens at such high voltages.) The net current I of positive carriers which flows across the junction is then the difference between the currents from the two sides: I= I 0 ( e +q\u0394V/\u03baT \u22121). (14.14) The net current I of holes flows into the n -type region. There the holes diffuse into the body of the n -region, where they are eventually annihilated by the majority n -type carriers\u2014the electrons. The electrons which are lost in this annihilation will be made up by a current of electrons from the external terminal of the n -type material. When \u0394V is zero, the net current in Eq. (14.14) is zero. For positive \u0394V the current increases rapidly with the applied voltage. For negative \u0394V the current reverses in sign, but the exponential term soon becomes negligible and the negative current never exceeds I 0 \u2014which under our assumptions is rather small. This back current I 0 is limited by the small density of the minority p -type carriers on the n -side of the junction. If you go through exactly the same analysis for the current of negative carriers which flows across the junction, first with no potential difference and then with a small externally applied potential difference \u0394V , you get again an equation just like (14.14) for the net electron current. Since the total current is the sum of the currents contributed by the two carriers, Eq. (14.14) still applies for the total current provided we identify I 0 as the maximum current which can flow for a reversed voltage. The voltage-current characteristic of Eq. (14.14) is shown in Fig. 14\u201310. It shows the typical behavior of solid state diodes\u2014such as those used in modern computers. We should remark that Eq. (14.14) is true only for small voltages. For voltages comparable to or larger than the natural internal voltage difference V , other effects come into play and the current no longer obeys the simple equation. You may remember, incidentally, that we got exactly the same equation we have found here in Eq. (14.14) when we discussed the \u201cmechanical rectifier\u201d\u2014the ratchet and pawl\u2014in Chapter 46 of Volume I. We get the same equations in the two situations because the basic physical processes are quite similar. Perhaps the most important application of semiconductors is in the transistor. The transistor consists of two semiconductor junctions very close together. Its operation is based in part on the same principles that we just described for the semiconductor diode\u2014the rectifying junction. Suppose we make a little bar of germanium with three distinct regions, a p -type region, an n -type region, and another p -type region, as shown in Fig. 14\u201311(a). This combination is called a p - n - p transistor. Each of the two junctions in the transistor will behave much in the way we have described in the last section. In particular, there will be a potential gradient at each junction having a certain potential drop from the n -type region to each p -type region. If the two p -type regions have the same internal properties, the variation in potential as we go across the crystal will be as shown in the graph of Fig. 14\u201311(b). Now let\u2019s imagine that we connect each of the three regions to external voltage sources as shown in part (a) of Fig. 14\u201312. We will refer all voltages to the terminal connected to the left-hand p -region so it will be, by definition, at zero potential. We will call this terminal the emitter. The n -type region is called the base and it is connected to a slightly negative potential. The right-hand p -type region is called the collector, and is connected to a somewhat larger negative potential. Under these circumstances the variation of potential across the crystal will be as shown in the graph of Fig. 14\u201312(b). Let\u2019s first see what happens to the positive carriers, since it is primarily their behavior which controls the operation of the p - n - p transistor. Since the emitter is at a relatively more positive potential than the base, a current of positive carriers will flow from the emitter region into the base region. A relatively large current flows, since we have a junction operating with a \u201cforward voltage\u201d\u2014corresponding to the right-hand half of the graph in Fig. 14\u201310. With these conditions, positive carriers or holes are being \u201cemitted\u201d from the p -type region into the n -type region. You might think that this current would flow out of the n -type region through the base terminal b . Now, however, comes the secret of the transistor. The n -type region is made very thin\u2014typically 10 \u22123 cm or less, much narrower than its transverse dimensions. This means that as the holes enter the n -type region they have a very good chance of diffusing across to the other junction before they are annihilated by the electrons in the n -type region. When they get to the right-hand boundary of the n -type region they find a steep downward potential hill and immediately fall into the right-hand p -type region. This side of the crystal is called the collector because it \u201ccollects\u201d the holes after they have diffused across the n -type region. In a typical transistor, all but a fraction of a percent of the hole current which leaves the emitter and enters the base is collected in the collector region, and only the small remainder contributes to the net base current. The sum of the base and collector currents is, of course, equal to the emitter current. Now imagine what happens if we vary slightly the potential V b on the base terminal. Since we are on a relatively steep part of the curve of Fig. 14\u201310, a small variation of the potential V b will cause a rather large change in the emitter current I e . Since the collector voltage V c is much more negative than the base voltage, these slight variations in potential will not affect appreciably the steep potential hill between the base and the collector. Most of the positive carriers emitted into the n -region will still be caught by the collector. Thus as we vary the potential of the base electrode, there will be a corresponding variation in the collector current I c . The essential point, however, is that the base current I b always remains a small fraction of the collector current. The transistor is an amplifier; a small current I b introduced into the base electrode gives a large current\u2014 100 or so times higher\u2014at the collector electrode. What about the electrons\u2014the negative carriers that we have been neglecting so far? First, note that we do not expect any significant electron current to flow between the base and the collector. With a large negative voltage on the collector, the electrons in the base would have to climb a very high potential energy hill and the probability of doing that is very small. There is a very small current of electrons to the collector. On the other hand, the electrons in the base can go into the emitter region. In fact, you might expect the electron current in this direction to be comparable to the hole current from the emitter into the base. Such an electron current isn\u2019t useful, and, on the contrary, is bad because it increases the total base current required for a given current of holes to the collector. The transistor is, therefore, designed to minimize the electron current to the emitter. The electron current is proportional to N n (base) , the density of negative carriers in the base material while the hole current from the emitter depends on N p (emitter) , the density of positive carriers in the emitter region. By using relatively little doping in the n -type material N n (base) can be made much smaller than N p (emitter) . (The very thin base region also helps a great deal because the sweeping out of the holes in this region by the collector increases significantly the average hole current from the emitter into the base, while leaving the electron current unchanged.) The net result is that the electron current across the emitter-base junction can be made much less than the hole current, so that the electrons do not play any significant role in operation of the p - n - p transistor. The currents are dominated by motion of the holes, and the transistor performs as an amplifier as we have described above. It is also possible to make a transistor by interchanging the p -type and n -type materials in Fig. 14\u201311. Then we have what is called an n - p - n transistor. In the n - p - n transistor the main currents are carried by the electrons which flow from the emitter into the base and from there to the collector. Obviously, all the arguments we have made for the p - n - p transistor also apply to the n - p - n transistor if the potentials of the electrodes are chosen with the opposite signs."
    },
    {
        "input": "Cavity Resonators",
        "output": "When looked at from any one pair of terminals, any arbitrary circuit made up of ideal impedances and generators is, at any given frequency, equivalent to a generator E in series with an impedance z . That comes about because if we put a voltage V across the terminals and solve all the equations to find the current I , we must get a linear relation between the current and the voltage. Since all the equations are linear, the result for I must also depend only linearly on V . The most general linear form can be expressed as I= 1 z (V\u2212E). In general, both z and E may depend in some complicated way on the frequency \u03c9 . Equation (23.1), however, is the relation we would get if behind the two terminals there was just the generator E(\u03c9) in series with the impedance z(\u03c9) . There is also the opposite kind of question: If we have any electromagnetic device at all with two terminals and we measure the relation between I and V to determine E and z as functions of frequency, can we find a combination of our ideal elements that is equivalent to the internal impedance z ? The answer is that for any reasonable\u2014that is, physically meaningful\u2014function z(\u03c9) , it is possible to approximate the situation to as high an accuracy as you wish with a circuit containing a finite set of ideal elements. We don\u2019t want to consider the general problem now, but only look at what might be expected from physical arguments for a few cases. If we think of a real resistor, we know that the current through it will produce a magnetic field. So any real resistor should also have some inductance. Also, when a resistor has a potential difference across it, there must be charges on the ends of the resistor to produce the necessary electric fields. As the voltage changes, the charges will change in proportion, so the resistor will also have some capacitance. We expect that a real resistor might have the equivalent circuit shown in Fig. 23\u20131. In a well-designed resistor, the so-called \u201cparasitic\u201d elements L and C are small, so that at the frequencies for which it is intended, \u03c9L is much less than R , and 1/\u03c9C is much greater than R . It may therefore be possible to neglect them. As the frequency is raised, however, they will eventually become important, and a resistor begins to look like a resonant circuit. A real inductance is also not equal to the idealized inductance, whose impedance is i\u03c9L . A real coil of wire will have some resistance, so at low frequencies the coil is really equivalent to an inductance in series with some resistance, as shown in Fig. 23\u20132(a). But, you are thinking, the resistance and inductance are together in a real coil\u2014the resistance is spread all along the wire, so it is mixed in with the inductance. We should probably use a circuit more like the one in Fig. 23\u20132(b), which has several little R \u2019s and L \u2019s in series. But the total impedance of such a circuit is just \u2211R+\u2211i\u03c9L , which is equivalent to the simpler diagram of part (a). As we go up in frequency with a real coil, the approximation of an inductance plus a resistance is no longer very good. The charges that must build up on the wires to make the voltages will become important. It is as if there were little condensers across the turns of the coil, as sketched in Fig. 23\u20133(a). We might try to approximate the real coil by the circuit in Fig. 23\u20133(b). At low frequencies, this circuit can be imitated fairly well by the simpler one in part (c) of the figure (which is again the same resonant circuit we found for the high-frequency model of a resistor). For higher frequencies, however, the more complicated circuit of Fig. 23\u20133(b) is better. In fact, the more accurately you wish to represent the actual impedance of a real, physical inductance, the more ideal elements you will have to use in the artificial model of it. Let\u2019s look a little more closely at what goes on in a real coil. The impedance of an inductance goes as \u03c9L , so it becomes zero at low frequencies\u2014it is a \u201cshort circuit\u201d: all we see is the resistance of the wire. As we go up in frequency, \u03c9L soon becomes much larger than R , and the coil looks pretty much like an ideal inductance. As we go still higher, however, the capacities become important. Their impedance is proportional to 1/\u03c9C , which is large for small \u03c9 . For small enough frequencies a condenser is an \u201copen circuit,\u201d and when it is in parallel with something else, it draws no current. But at high frequencies, the current prefers to flow into the capacitance between the turns, rather than through the inductance. So the current in the coil jumps from one turn to the other and doesn\u2019t bother to go around and around where it has to buck the emf. So although we may have intended that the current should go around the loop, it will take the easier path\u2014the path of least impedance. If the subject had been one of popular interest, this effect would have been called \u201cthe high-frequency barrier,\u201d or some such name. The same kind of thing happens in all subjects. In aerodynamics, if you try to make things go faster than the speed of sound when they were designed for lower speeds, they don\u2019t work. It doesn\u2019t mean that there is a great \u201cbarrier\u201d there; it just means that the object should be redesigned. So this coil which we designed as an \u201cinductance\u201d is not going to work as a good inductance, but as some other kind of thing at very high frequencies. For high frequencies, we have to find a new design. Now we want to discuss in detail the behavior of a capacitor\u2014a geometrically ideal capacitor\u2014as the frequency gets larger and larger, so we can see the transition of its properties. (We prefer to use a capacitor instead of an inductance, because the geometry of a pair of plates is much less complicated than the geometry of a coil.) We consider the capacitor shown in Fig. 23\u20134(a), which consists of two parallel circular plates connected to an external generator by a pair of wires. If we charge the capacitor with dc, there will be a positive charge on one plate and a negative charge on the other; and there will be a uniform electric field between the plates. Now suppose that instead of dc, we put an ac of low frequency on the plates. (We will find out later what is \u201clow\u201d and what is \u201chigh\u201d.) Say we connect the capacitor to a lower-frequency generator. As the voltage alternates, the positive charge on the top plate is taken off and negative charge is put on. While that is happening, the electric field disappears and then builds up in the opposite direction. As the charge sloshes back and forth slowly, the electric field follows. At each instant the electric field is uniform, as shown in Fig. 23\u20134(b), except for some edge effects which we are going to disregard. We can write the magnitude of the electric field as E= E 0 e i\u03c9t , (23.2) where E 0 is a constant. Now will that continue to be right as the frequency goes up? No, because as the electric field is going up and down, there is a flux of electric field through any loop like \u0393 1 in Fig. 23\u20134(a). And, as you know, a changing electric field acts to produce a magnetic field. One of Maxwell\u2019s equations says that when there is a varying electric field, as there is here, there has got to be a line integral of the magnetic field. The integral of the magnetic field around a closed ring, multiplied by c 2 , is equal to the time rate-of-change of the electric flux through the area inside the ring (if there are no currents): c 2 \u222e \u0393 B\u22c5ds= d dt \u222b inside \u0393 E\u22c5nda. (23.3) So how much magnetic field is there? That\u2019s not very hard. Suppose that we take the loop \u0393 1 , which is a circle of radius r . We can see from symmetry that the magnetic field goes around as shown in the figure. Then the line integral of B is 2\u03c0rB . And, since the electric field is uniform, the flux of the electric field is simply E multiplied by \u03c0 r 2 , the area of the circle: c 2 B\u22c52\u03c0r= \u2202 \u2202t E\u22c5\u03c0 r 2 . (23.4) The derivative of E with respect to time is, for our alternating field, simply i\u03c9 E 0 e i\u03c9t . So we find that our capacitor has the magnetic field B= i\u03c9r 2 c 2 E 0 e i\u03c9t . (23.5) In other words, the magnetic field also oscillates and has a strength proportional to r . What is the effect of that? When there is a magnetic field that is varying, there will be induced electric fields and the capacitor will begin to act a little bit like an inductance. As the frequency goes up, the magnetic field gets stronger; it is proportional to the rate of change of E , and so to \u03c9 . The impedance of the capacitor will no longer be simply 1/i\u03c9C . Let\u2019s continue to raise the frequency and to analyze what happens more carefully. We have a magnetic field that goes sloshing back and forth. But then the electric field cannot be uniform, as we have assumed! When there is a varying magnetic field, there must be a line integral of the electric field\u2014because of Faraday\u2019s law. So if there is an appreciable magnetic field, as begins to happen at high frequencies, the electric field cannot be the same at all distances from the center. The electric field must change with r so that the line integral of the electric field can equal the changing flux of the magnetic field. Let\u2019s see if we can figure out the correct electric field. We can do that by computing a \u201ccorrection\u201d to the uniform field we originally assumed for low frequencies. Let\u2019s call the uniform field E 1 , which will still be E 0 e i\u03c9t , and write the correct field as E= E 1 + E 2 , E E E where E 2 is the correction due to the changing magnetic field. For any \u03c9 we will write the field at the center of the condenser as E 0 e i\u03c9t (thereby defining E 0 ), so that we have no correction at the center; E 2 =0 at r=0 . To find E 2 we can use the integral form of Faraday\u2019s law: \u222e \u0393 E\u22c5ds=\u2212 d dt (flux of B). \u222e The integrals are simple if we take them for the curve \u0393 2 , shown in Fig. 23\u20134(b), which goes up along the axis, out radially the distance r along the top plate, down vertically to the bottom plate, and back to the axis. The line integral of E 1 around this curve is, of course, zero; so only E 2 contributes, and its integral is just \u2212 E 2 (r)\u22c5h , where h is the spacing between the plates. (We call E positive if it points upward.) This is equal to minus the rate of change of the flux of B , which we have to get by an integral over the shaded area S inside \u0393 2 in Fig. 23\u20134(b). The flux through a vertical strip of width dr is B(r)hdr , so the total flux is h\u222bB(r)dr. \u222b Setting \u2212\u2202/\u2202t of the flux equal to the line integral of E 2 , we have E 2 (r)= \u2202 \u2202t \u222bB(r)dr. (23.6) Notice that the h cancels out; the fields don\u2019t depend on the separation of the plates. Using Eq. (23.5) for B(r) , we have E 2 (r)= \u2202 \u2202t i\u03c9 r 2 4 c 2 E 0 e i\u03c9t . 2 The time derivative just brings down another factor i\u03c9 ; we get E 2 (r)=\u2212 \u03c9 2 r 2 4 c 2 E 0 e i\u03c9t . (23.7) As we expect, the induced field tends to reduce the electric field farther out. The corrected field E= E 1 + E 2 is then E= E 1 + E 2 =(1\u2212 1 4 \u03c9 2 r 2 c 2 ) E 0 e i\u03c9t . (23.8) The electric field in the capacitor is no longer uniform; it has the parabolic shape shown by the broken line in Fig. 23\u20135. You see that our simple capacitor is getting slightly complicated. We could now use our results to calculate the impedance of the capacitor at high frequencies. Knowing the electric field, we could compute the charges on the plates and find out how the current through the capacitor depends on the frequency \u03c9 , but we are not interested in that problem for the moment. We are more interested in seeing what happens as we continue to go up with the frequency\u2014to see what happens at even higher frequencies. Aren\u2019t we already finished? No, because we have corrected the electric field, which means that the magnetic field we have calculated is no longer right. The magnetic field of Eq. (23.5) is approximately right, but it is only a first approximation. So let\u2019s call it B 1 . We should then rewrite Eq. (23.5) as B 1 = i\u03c9r 2 c 2 E 0 e i\u03c9t . (23.9) You will remember that this field was produced by the variation of E 1 . Now the correct magnetic field will be that produced by the total electric field E 1 + E 2 . If we write the magnetic field as B= B 1 + B 2 , the second term is just the additional field produced by E 2 . To find B 2 we can go through the same arguments we have used to find B 1 ; the line integral of B 2 around the curve \u0393 1 is equal to the rate of change of the flux of E 2 through \u0393 1 . We will just have Eq. (23.4) again with B replaced by B 2 and E replaced by E 2 : c 2 B 2 \u22c52\u03c0r= d dt (flux of E 2 through \u0393 1 ). d Since E 2 varies with radius, to obtain its flux we must integrate over the circular surface inside \u0393 1 . Using 2\u03c0rdr as the element of area, this integral is \u222b r 0 E 2 (r)\u22c52\u03c0rdr. r So we get for B 2 (r) B 2 (r)= 1 r c 2 \u2202 \u2202t \u222b E 2 (r)rdr. (23.10) Using E 2 (r) from Eq. (23.7), we need the integral of r 3 dr , which is, of course, r 4 /4 . Our correction to the magnetic field becomes B 2 (r)=\u2212 i \u03c9 3 r 3 16 c 4 E 0 e i\u03c9t . (23.11) But we are still not finished! If the magnetic field B is not the same as we first thought, then we have incorrectly computed E 2 . We must make a further correction to E , which comes from the extra magnetic field B 2 . Let\u2019s call this additional correction to the electric field E 3 . It is related to the magnetic field B 2 in the same way that E 2 was related to B 1 . We can use Eq. (23.6) all over again just by changing the subscripts: E 3 (r)= \u2202 \u2202t \u222b B 2 (r)dr. (23.12) Using our result, Eq. (23.11), for B 2 , the new correction to the electric field is E 3 (r)=+ \u03c9 4 r 4 64 c 4 E 0 e i\u03c9t . (23.13) Writing our doubly corrected electric field as E= E 1 + E 2 + E 3 , we get E= E 0 e i\u03c9t [1\u2212 1 2 2 ( \u03c9r c ) 2 + 1 2 2 \u22c5 4 2 ( \u03c9r c ) 4 ]. (23.14) The variation of the electric field with radius is no longer the simple parabola we drew in Fig. 23\u20135, but at large radii lies slightly above the curve ( E 1 + E 2 ) . We are not quite through yet. The new electric field produces a new correction to the magnetic field, and the newly corrected magnetic field will produce a further correction to the electric field, and on and on. However, we already have all the formulas that we need. For B 3 we can use Eq. (23.10), changing the subscripts of B and E from 2 to 3 . The next correction to the electric field is E 4 =\u2212 1 2 2 \u22c5 4 2 \u22c5 6 2 ( \u03c9r c ) 6 E 0 e i\u03c9t . 1 So to this order we have that the complete electric field is given by E= E 0 e i\u03c9t [1\u2212 1 (1! ) 2 ( \u03c9r 2c ) 2 + 1 (2! ) 2 ( \u03c9r 2c ) 4 \u2212 1 (3! ) 2 ( \u03c9r 2c ) 6 \u00b1\u22ef]. (23.15) where we have written the numerical coefficients in such a way that it is obvious how the series is to be continued. Our final result is that the electric field between the plates of the capacitor, for any frequency, is given by E 0 e i\u03c9t times the infinite series which contains only the variable \u03c9r/c . If we wish, we can define a special function, which we will call J 0 (x) , as the infinite series that appears in the brackets of Eq. (23.15): J 0 (x)= 1\u2212 1 (1! ) 2 ( x 2 ) 2 + 1 (2! ) 2 ( x 2 ) 4 \u2212 1 (3! ) 2 ( x 2 ) 6 \u00b1\u22ef (23.16) Then we can write our solution as E 0 e i\u03c9t times this function, with x=\u03c9r/c : E= E 0 e i\u03c9t J 0 ( \u03c9r c ). (23.17) The reason we have called our special function J 0 is that, naturally, this is not the first time anyone has ever worked out a problem with oscillations in a cylinder. The function has come up before and is usually called J 0 . It always comes up whenever you solve a problem about waves with cylindrical symmetry. The function J 0 is to cylindrical waves what the cosine function is to waves on a straight line. So it is an important function, invented a long time ago. Then a man named Bessel got his name attached to it. The subscript zero means that Bessel invented a whole lot of different functions and this is just the first of them. The other functions of Bessel\u2014 J 1 , J 2 , and so on\u2014have to do with cylindrical waves which have a variation of their strength with the angle around the axis of the cylinder. The completely corrected electric field between the plates of our circular capacitor, given by Eq. (23.17), is plotted as the solid line in Fig. 23\u20135. For frequencies that are not too high, our second approximation was already quite good. The third approximation was even better\u2014so good, in fact, that if we had plotted it, you would not have been able to see the difference between it and the solid curve. You will see in the next section, however, that the complete series is needed to get an accurate description for large radii, or for high frequencies. We want to look now at what our solution gives for the electric field between the plates of the capacitor as we continue to go to higher and higher frequencies. For large \u03c9 , the parameter x=\u03c9r/c also gets large, and the first few terms in the series for J 0 of x will increase rapidly. That means that the parabola we have drawn in Fig. 23\u20135 curves downward more steeply at higher frequencies. In fact, it looks as though the field would fall all the way to zero at some high frequency, perhaps when c/\u03c9 is approximately one-half of a . Let\u2019s see whether J 0 does indeed go through zero and become negative. We begin by trying x=2 : J 0 (2)=1\u22121+ 1 4 \u2212 1 36 =0.22. 1 1 The function is still not zero, so let\u2019s try a higher value of x , say, x=2.5 . Putting in numbers, we write J 0 (2.5)=1\u22121.56+0.61\u22120.11=\u22120.06. ( ) The function J 0 has already gone through zero by the time we get to x=2.5 . Comparing the results for x=2 and x=2.5 , it looks as though J 0 goes through zero at one-fifth of the way from 2.5 to 2 . We would guess that the zero occurs for x approximately equal to 2.4 . Let\u2019s see what that value of x gives: J 0 (2.4)=1\u22121.44+0.52\u22120.08=0.00. ( ) We get zero to the accuracy of our two decimal places. If we make the calculation more accurate (or since J 0 is a well-known function, if we look it up in a book), we find that it goes through zero at x=2.405 . We have worked it out by hand to show you that you too could have discovered these things rather than having to borrow them from a book. As long as we are looking up J 0 in a book, it is interesting to notice how it goes for larger values of x ; it looks like the graph in Fig. 23\u20136. As x increases, J 0 (x) oscillates between positive and negative values with a decreasing amplitude of oscillation. We have gotten the following interesting result: If we go high enough in frequency, the electric field at the center of our condenser will be one way and the electric field near the edge will point in the opposite direction. For example, suppose that we take an \u03c9 high enough so that x=\u03c9r/c at the outer edge of the capacitor is equal to 4 ; then the edge of the capacitor corresponds to the abscissa x=4 in Fig. 23\u20136. This means that our capacitor is being operated at the frequency \u03c9=4c/a . At the edge of the plates, the electric field will have a rather high magnitude opposite the direction we would expect. That is the terrible thing that can happen to a capacitor at high frequencies. If we go to very high frequencies, the direction of the electric field oscillates back and forth many times as we go out from the center of the capacitor. Also there are the magnetic fields associated with these electric fields. It is not surprising that our capacitor doesn\u2019t look like the ideal capacitance for high frequencies. We may even start to wonder whether it looks more like a capacitor or an inductance. We should emphasize that there are even more complicated effects that we have neglected which happen at the edges of the capacitor. For instance, there will be a radiation of waves out past the edges, so the fields are even more complicated than the ones we have computed, but we will not worry about those effects now. We could try to figure out an equivalent circuit for the capacitor, but perhaps it is better if we just admit that the capacitor we have designed for low-frequency fields is just no longer satisfactory when the frequency is too high. If we want to treat the operation of such an object at high frequencies, we should abandon the approximations to Maxwell\u2019s equations that we have made for treating circuits and return to the complete set of equations which describe completely the fields in space. Instead of dealing with idealized circuit elements, we have to deal with the real conductors as they are, taking into account all the fields in the spaces in between. For instance, if we want a resonant circuit at high frequencies we will not try to design one using a coil and a parallel-plate capacitor. We have already mentioned that the parallel-plate capacitor we have been analyzing has some of the aspects of both a capacitor and an inductance. With the electric field there are charges on the surfaces of the plates, and with the magnetic fields there are back emf\u2019s. Is it possible that we already have a resonant circuit? We do indeed. Suppose we pick a frequency for which the electric field pattern falls to zero at some radius inside the edge of the disc; that is, we choose \u03c9a/c greater than 2.405 . Everywhere on a circle coaxial with the plates the electric field will be zero. Now suppose we take a thin metal sheet and cut a strip just wide enough to fit between the plates of the capacitor. Then we bend it into a cylinder that will go around at the radius where the electric field is zero. Since there are no electric fields there, when we put this conducting cylinder in place, no currents will flow in it; and there will be no changes in the electric and magnetic fields. We have been able to put a direct short circuit across the capacitor without changing anything. And look what we have; we have a complete cylindrical can with electrical and magnetic fields inside and no connection at all to the outside world. The fields inside won\u2019t change even if we throw away the edges of the plates outside our can, and also the capacitor leads. All we have left is a closed can with electric and magnetic fields inside, as shown in Fig. 23\u20137(a). The electric fields are oscillating back and forth at the frequency \u03c9 \u2014which, don\u2019t forget, determined the diameter of the can. The amplitude of the oscillating E field varies with the distance from the axis of the can, as shown in the graph of Fig. 23\u20137(b). This curve is just the first arch of the Bessel function of zero order. There is also a magnetic field which goes in circles around the axis and oscillates in time 90 \u2218 out of phase with the electric field. We can also write out a series for the magnetic field and plot it, as shown in the graph of Fig. 23\u20137(c). How is it that we can have an electric and magnetic field inside a can with no external connections? It is because the electric and magnetic fields maintain themselves, the changing E makes a B and the changing B makes an E \u2014all according to the equations of Maxwell. The magnetic field has an inductive aspect, and the electric field a capacitive aspect; together they make something like a resonant circuit. Notice that the conditions we have described would only happen if the radius of the can is exactly 2.405c/\u03c9 . For a can of a given radius, the oscillating electric and magnetic fields will maintain themselves\u2014in the way we have described\u2014only at that particular frequency. So a cylindrical can of radius r is resonant at the frequency \u03c9 0 =2.405 c r . (23.18) We have said that the fields continue to oscillate in the same way after the can is completely closed. That is not exactly right. It would be possible if the walls of the can were perfect conductors. For a real can, however, the oscillating currents which exist on the inside walls of the can lose energy because of the resistance of the material. The oscillations of the fields will gradually die away. We can see from Fig. 23\u20137 that there must be strong currents associated with electric and magnetic fields inside the cavity. Because the vertical electrical field stops suddenly at the top and bottom plates of the can, it has a large divergence there; so there must be positive and negative electric charges on the inner surfaces of the can, as shown in Fig. 23\u20137(a). When the electric field reverses, the charges must reverse also, so there must be an alternating current between the top and bottom plates of the can. These charges will flow in the sides of the can, as shown in the figure. We can also see that there must be currents in the sides of the can by considering what happens to the magnetic field. The graph of Fig. 23\u20137(c) tells us that the magnetic field suddenly drops to zero at the edge of the can. Such a sudden change in the magnetic field can happen only if there is a current in the wall. This current is what gives the alternating electric charges on the top and bottom plates of the can. You may be wondering about our discovery of currents in the vertical sides of the can. What about our earlier statement that nothing would be changed when we introduced these vertical sides in a region where the electric field was zero? Remember, however, that when we first put in the sides of the can, the top and bottom plates extended out beyond them, so that there were also magnetic fields on the outside of our can. It was only when we threw away the parts of the capacitor plates beyond the edges of the can that net currents had to appear on the insides of the vertical walls. Although the electric and magnetic fields in the completely enclosed can will gradually die away because of the energy losses, we can stop this from happening if we make a little hole in the can and put in a little bit of electrical energy to make up the losses. We take a small wire, poke it through the hole in the side of the can, and fasten it to the inside wall so that it makes a small loop, as shown in Fig. 23\u20138. If we now connect this wire to a source of high-frequency alternating current, this current will couple energy into the electric and magnetic fields of the cavity and keep the oscillations going. This will happen, of course, only if the frequency of the driving source is at the resonant frequency of the can. If the source is at the wrong frequency, the electric and magnetic fields will not resonate, and the fields in the can will be very weak. The resonant behavior can easily be seen by making another small hole in the can and hooking in another coupling loop, as we have also drawn in Fig. 23\u20138. The changing magnetic field through this loop will generate an induced electromotive force in the loop. If this loop is now connected to some external measuring circuit, the currents will be proportional to the strength of the fields in the cavity. Suppose we now connect the input loop of our cavity to an RF signal generator, as shown in Fig. 23\u20139. The signal generator contains a source of alternating current whose frequency can be varied by varying the knob on the front of the generator. Then we connect the output loop of the cavity to a \u201cdetector,\u201d which is an instrument that measures the current from the output loop. It gives a meter reading proportional to this current. If we now measure the output current as a function of the frequency of the signal generator, we find a curve like that shown in Fig. 23\u201310. The output current is small for all frequencies except those very near the frequency \u03c9 0 , which is the resonant frequency of the cavity. The resonance curve is very much like those we described in Chapter 23 of Vol. I. The width of the resonance is however, much narrower than we usually find for resonant circuits made of inductances and capacitors; that is, the Q of the cavity is very high. It is not unusual to find Q \u2019s as high as 100,000 or more if the inside walls of the cavity are made of some material with a very good conductivity, such as silver. Suppose we now try to check our theory by making measurements with an actual can. We take a can which is a cylinder with a diameter of 3.0 inches and a height of about 2.5 inches. The can is fitted with an input and output loop, as shown in Fig. 23\u20138. If we calculate the resonant frequency expected for this can according to Eq. (23.18), we get that f 0 = \u03c9 0 /2\u03c0= 3010 megacycles. When we set the frequency of our signal generator near 3000 megacycles and vary it slightly until we find the resonance, we observe that the maximum output current occurs for a frequency of 3050 megacycles, which is quite close to the predicted resonant frequency, but not exactly the same. There are several possible reasons for the discrepancy. Perhaps the resonant frequency is changed a little bit because of the holes we have cut to put in the coupling loops. A little thought, however, shows that the holes should lower the resonant frequency a little bit, so that cannot be the reason. Perhaps there is some slight error in the frequency calibration of the signal generator, or perhaps our measurement of the diameter of the cavity is not accurate enough. Anyway, the agreement is fairly close. Much more important is something that happens if we vary the frequency of our signal generator somewhat further from 3000 megacycles. When we do that we get the results shown in Fig. 23\u201311. We find that, in addition to the resonance we expected near 3000 megacycles, there is also a resonance near 3300 megacycles and one near 3820 megacycles. What do these extra resonances mean? We might get a clue from Fig. 23\u20136. Although we have been assuming that the first zero of the Bessel function occurs at the edge of the can, it could also be that the second zero of the Bessel function corresponds to the edge of the can, so that there is one complete oscillation of the electric field as we move from the center of the can out to the edge, as shown in Fig. 23\u201312. This is another possible mode for the oscillating fields. We should certainly expect the can to resonate in such a mode. But notice, the second zero of the Bessel function occurs at x=5.52 , which is over twice as large as the value at the first zero. The resonant frequency of this mode should therefore be higher than 6000 megacycles. We would, no doubt, find it there, but it doesn\u2019t explain the resonance we observe at 3300 . The trouble is that in our analysis of the behavior of a resonant cavity we have considered only one possible geometric arrangement of the electric and magnetic fields. We have assumed that the electric fields are vertical and that the magnetic fields lie in horizontal circles. But other fields are possible. The only requirements are that the fields should satisfy Maxwell\u2019s equations inside the can and that the electric field should meet the wall at right angles. We have considered the case in which the top and the bottom of the can are flat, but things would not be completely different if the top and bottom were curved. In fact, how is the can supposed to know which is its top and bottom, and which are its sides? It is, in fact, possible to show that there is a mode of oscillation of the fields inside the can in which the electric fields go more or less across the diameter of the can, as shown in Fig. 23\u201313. It is not too hard to understand why the natural frequency of this mode should be not very different from the natural frequency of the first mode we have considered. Suppose that instead of our cylindrical cavity we had taken a cavity which was a cube 3 inches on a side. It is clear that this cavity would have three different modes, but all with the same frequency. A mode with the electric field going more or less up and down would certainly have the same frequency as the mode in which the electric field was directed right and left. If we now distort the cube into a cylinder, we will change these frequencies somewhat. We would still expect them not to be changed too much, provided we keep the dimensions of the cavity more or less the same. So the frequency of the mode of Fig. 23\u201313 should not be too different from the mode of Fig. 23\u20138. We could make a detailed calculation of the natural frequency of the mode shown in Fig. 23\u201313, but we will not do that now. When the calculations are carried through, it is found that, for the dimensions we have assumed, the resonant frequency comes out very close to the observed resonance at 3300 megacycles. By similar calculations it is possible to show that there should be still another mode at the other resonant frequency we found near 3800 megacycles. For this mode, the electric and magnetic fields are as shown in Fig. 23\u201314. The electric field does not bother to go all the way across the cavity. It goes from the sides to the ends, as shown. As you will probably now believe, if we go higher and higher in frequency we should expect to find more and more resonances. There are many different modes, each of which will have a different resonant frequency corresponding to some particular complicated arrangement of the electric and magnetic fields. Each of these field arrangements is called a resonant mode. The resonance frequency of each mode can be calculated by solving Maxwell\u2019s equations for the electric and magnetic fields in the cavity. When we have a resonance at some particular frequency, how can we know which mode is being excited? One way is to poke a little wire into the cavity through a small hole. If the electric field is along the wire, as in Fig. 23\u201315(a), there will be relatively large currents in the wire, sapping energy from the fields, and the resonance will be suppressed. If the electric field is as shown in Fig. 23\u201315(b), the wire will have a much smaller effect. We could find which way the field points in this mode by bending the end of the wire, as shown in Fig. 23\u201315(c). Then, as we rotate the wire, there will be a big effect when the end of the wire is parallel to E and a small effect when it is rotated so as to be at 90 \u2218 to E . Although the resonant cavity we have been describing seems to be quite different from the ordinary resonant circuit consisting of an inductance and a capacitor, the two resonant systems are, of course, closely related. They are both members of the same family; they are just two extreme cases of electromagnetic resonators\u2014and there are many intermediate cases between these two extremes. Suppose we start by considering the resonant circuit of a capacitor in parallel with an inductance, as shown in Fig. 23\u201316(a). This circuit will resonate at the frequency \u03c9 0 =1/ LC \u2212 \u2212 \u2212 \u221a . If we want to raise the resonant frequency of this circuit, we can do so by lowering the inductance L . One way is to decrease the number of turns in the coil. We can, however, go only so far in this direction. Eventually we will get down to the last turn, and we will have just a piece of wire joining the top and bottom plates of the condenser. We could raise the resonant frequency still further by making the capacitance smaller; however, we can also continue to decrease the inductance by putting several inductances in parallel. Two one-turn inductances in parallel will have only half the inductance of each turn. So when our inductance has been reduced to a single turn, we can continue to raise the resonant frequency by adding other single loops from the top plate to the bottom plate of the condenser. For instance, Fig. 23\u201316(b) shows the condenser plates connected by six such \u201csingle-turn inductances.\u201d If we continue to add many such pieces of wire, we can make the transition to the completely enclosed resonant system shown in part (c) of the figure, which is a drawing of the cross section of a cylindrically symmetrical object. Our inductance is now a cylindrical hollow can attached to the edges of the condenser plates. The electric and magnetic fields will be as shown in the figure. Such an object is, of course, a resonant cavity. It is called a \u201cloaded\u201d cavity. But we can still think of it as an L - C circuit in which the capacity section is the region where we find most of the electric field and the inductance section is that region where we find most of the magnetic field. If we want to make the frequency of the resonator in Fig. 23\u201316(c) still higher, we can do so by continuing to decrease the inductance L . To do that, we must decrease the geometric dimensions of the inductance section, for example by decreasing the dimension h in the drawing. As h is decreased, the resonant frequency will be increased. Eventually, of course, we will get to the situation in which the height h is just equal to the separation between the condenser plates. We then have just a cylindrical can; our resonant circuit has become the cavity resonator of Fig. 23\u20137. You will notice that in the original L - C resonant circuit of Fig. 23\u201316 the electric and magnetic fields are quite separate. As we have gradually modified the resonant system to make higher and higher frequencies, the magnetic field has been brought closer and closer to the electric field until in the cavity resonator the two are quite intermixed. Although the cavity resonators we have talked about in this chapter have been cylindrical cans, there is nothing magic about the cylindrical shape. A can of any shape will have resonant frequencies corresponding to various possible modes of oscillations of the electric and magnetic fields. For example, the \u201ccavity\u201d shown in Fig. 23\u201317 will have its own particular set of resonant frequencies\u2014although they would be rather difficult to calculate."
    },
    {
        "input": "Paramagnetism and Magnetic Resonance",
        "output": "In the last chapter we described how in quantum mechanics the angular momentum of a thing does not have an arbitrary direction, but its component along a given axis can take on only certain equally spaced, discrete values. It is a shocking and peculiar thing. You may think that perhaps we should not go into such things until your minds are more advanced and ready to accept this kind of an idea. Actually, your minds will never become more advanced\u2014in the sense of being able to accept such a thing easily. There isn\u2019t any descriptive way of making it intelligible that isn\u2019t so subtle and advanced in its own form that it is more complicated than the thing you were trying to explain. The behavior of matter on a small scale\u2014as we have remarked many times\u2014is different from anything that you are used to and is very strange indeed. As we proceed with classical physics, it is a good idea to try to get a growing acquaintance with the behavior of things on a small scale, at first as a kind of experience without any deep understanding. Understanding of these matters comes very slowly, if at all. Of course, one does get better able to know what is going to happen in a quantum-mechanical situation\u2014if that is what understanding means\u2014but one never gets a comfortable feeling that these quantum-mechanical rules are \u201cnatural.\u201d Of course they are, but they are not natural to our own experience at an ordinary level. We should explain that the attitude that we are going to take with regard to this rule about angular momentum is quite different from many of the other things we have talked about. We are not going to try to \u201cexplain\u201d it, but we must at least tell you what happens; it would be dishonest to describe the magnetic properties of materials without mentioning the fact that the classical description of magnetism\u2014of angular momentum and magnetic moments\u2014is incorrect. One of the most shocking and disturbing features about quantum mechanics is that if you take the angular momentum along any particular axis you find that it is always an integer or half-integer times \u210f . This is so no matter which axis you take. The subtleties involved in that curious fact\u2014that you can take any other axis and find that the component for it is also locked to the same set of values\u2014we will leave to a later chapter, when you will experience the delight of seeing how this apparent paradox is ultimately resolved. We will now just accept the fact that for every atomic system there is a number j , called the spin of the system\u2014which must be an integer or a half-integer\u2014and that the component of the angular momentum along any particular axis will always have one of the following values between +j\u210f and \u2212j\u210f : Jz=one of{ j j\u22121 j\u22122 \u22ee \u2212j+2 \u2212j+1 \u2212j }\u22c5\u210f. We have also mentioned that every simple atomic system has a magnetic moment which has the same direction as the angular momentum. This is true not only for atoms and nuclei but also for the fundamental particles. Each fundamental particle has its own characteristic value of j and its magnetic moment. (For some particles, both are zero.) What we mean by \u201cthe magnetic moment\u201d in this statement is that the energy of the system in a magnetic field, say in the z -direction, can be written as \u2212\u03bczB for small magnetic fields. We must have the condition that the field should not be too great, otherwise it could disturb the internal motions of the system and the energy would not be a measure of the magnetic moment that was there before the field was turned on. But if the field is sufficiently weak, the field changes the energy by the amount \u0394U=\u2212\u03bczB, with the understanding that in this equation we are to replace \u03bcz by \u03bcz=g( q 2m )Jz, where Jz has one of the values in Eq. (35.1). Suppose we take a system with a spin j=3/2 . Without a magnetic field, the system has four different possible states corresponding to the different values of Jz , all of which have exactly the same energy. But the moment we turn on the magnetic field, there is an additional energy of interaction which separates these states into four slightly different energy levels. The energies of these levels are given by a certain energy proportional to B , multiplied by \u210f times 3/2 , 1/2 , \u22121/2 , and \u22123/2 \u2014the values of Jz . The splitting of the energy levels for atomic systems with spins of 1/2 , 1 , and 3/2 are shown in the diagrams of Fig. 35-1. (Remember that for any arrangement of electrons the magnetic moment is always directed opposite to the angular momentum.) You will notice from the diagrams that the \u201ccenter of gravity\u201d of the energy levels is the same with and without a magnetic field. Also notice that the spacings from one level to the next are always equal for a given particle in a given magnetic field. We are going to write the energy spacing, for a given magnetic field B , as \u210f\u03c9p \u2014which is just a definition of \u03c9p . Using Eqs. (35.2) and (35.3), we have \u210f\u03c9p=g q 2m \u210fB or \u03c9p=g q 2m B. The quantity g(q/2m) is just the ratio of the magnetic moment to the angular momentum\u2014it is a property of the particle. Equation (35.4) is the same formula that we got in Chapter 34 for the angular velocity of precession in a magnetic field, for a gyroscope whose angular momentum is J and whose magnetic moment is \u03bc . The fact that the angular momentum is quantized is such a surprising thing that we will talk a little bit about it historically. It was a shock from the moment it was discovered (although it was expected theoretically). It was first observed in an experiment done in 1922 by Stern and Gerlach. If you wish, you can consider the experiment of Stern-Gerlach as a direct justification for a belief in the quantization of angular momentum. Stern and Gerlach devised an experiment for measuring the magnetic moment of individual silver atoms. They produced a beam of silver atoms by evaporating silver in a hot oven and letting some of them come out through a series of small holes. This beam was directed between the pole tips of a special magnet, as shown in Fig. 35-2. Their idea was the following. If the silver atom has a magnetic moment \u03bc , then in a magnetic field B it has an energy \u2212\u03bczB , where z is the direction of the magnetic field. In the classical theory, \u03bcz would be equal to the magnetic moment times the cosine of the angle between the moment and the magnetic field, so the extra energy in the field would be \u0394U=\u2212\u03bcBcos\u03b8. Of course, as the atoms come out of the oven, their magnetic moments would point in every possible direction, so there would be all values of \u03b8 . Now if the magnetic field varies very rapidly with z \u2014if there is a strong field gradient\u2014then the magnetic energy will also vary with position, and there will be a force on the magnetic moments whose direction will depend on whether cosine \u03b8 is positive or negative. The atoms will be pulled up or down by a force proportional to the derivative of the magnetic energy; from the principle of virtual work, Fz=\u2212 \u2202U \u2202z =\u03bccos\u03b8 \u2202B \u2202z . Stern and Gerlach made their magnet with a very sharp edge on one of the pole tips in order to produce a very rapid variation of the magnetic field. The beam of silver atoms was directed right along this sharp edge, so that the atoms would feel a vertical force in the inhomogeneous field. A silver atom with its magnetic moment directed horizontally would have no force on it and would go straight past the magnet. An atom whose magnetic moment was exactly vertical would have a force pulling it up toward the sharp edge of the magnet. An atom whose magnetic moment was pointed downward would feel a downward push. Thus, as they left the magnet, the atoms would be spread out according to their vertical components of magnetic moment. In the classical theory all angles are possible, so that when the silver atoms are collected by deposition on a glass plate, one should expect a smear of silver along a vertical line. The height of the line would be proportional to the magnitude of the magnetic moment. The abject failure of classical ideas was completely revealed when Stern and Gerlach saw what actually happened. They found on the glass plate two distinct spots. The silver atoms had formed two beams. That a beam of atoms whose spins would apparently be randomly oriented gets split up into two separate beams is most miraculous. How does the magnetic moment know that it is only allowed to take on certain components in the direction of the magnetic field? Well, that was really the beginning of the discovery of the quantization of angular momentum, and instead of trying to give you a theoretical explanation, we will just say that you are stuck with the result of this experiment just as the physicists of that day had to accept the result when the experiment was done. It is an experimental fact that the energy of an atom in a magnetic field takes on a series of individual values. For each of these values the energy is proportional to the field strength. So in a region where the field varies, the principle of virtual work tells us that the possible magnetic force on the atoms will have a set of separate values; the force is different for each state, so the beam of atoms is split into a small number of separate beams. From a measurement of the deflection of the beams, one can find the strength of the magnetic moment. We would now like to describe an improved apparatus for the measurement of magnetic moments which was developed by I. I. Rabi and his collaborators. In the Stern-Gerlach experiment the deflection of atoms is very small, and the measurement of the magnetic moment is not very precise. Rabi\u2019s technique permits a fantastic precision in the measurement of the magnetic moments. The method is based on the fact that the original energy of the atoms in a magnetic field is split up into a finite number of energy levels. That the energy of an atom in the magnetic field can have only certain discrete energies is really not more surprising than the fact that atoms in general have only certain discrete energy levels\u2014something we mentioned often in Volume I. Why should the same thing not hold for atoms in a magnetic field? It does. But it is the attempt to correlate this with the idea of an oriented magnetic moment that brings out some of the strange implications of quantum mechanics. When an atom has two levels which differ in energy by the amount \u0394U , it can make a transition from the upper level to the lower level by emitting a light quantum of frequency \u03c9 , where \u210f\u03c9=\u0394U. (35.7) The same thing can happen with atoms in a magnetic field. Only then, the energy differences are so small that the frequency does not correspond to light, but to microwaves or to radiofrequencies. The transitions from the lower energy level to an upper energy level of an atom can also take place with the absorption of light or, in the case of atoms in a magnetic field, by the absorption of microwave energy. Thus if we have an atom in a magnetic field, we can cause transitions from one state to another by applying an additional electromagnetic field of the proper frequency. In other words, if we have an atom in a strong magnetic field and we \u201ctickle\u201d the atom with a weak varying electromagnetic field, there will be a certain probability of knocking it to another level if the frequency is near to the \u03c9 in Eq. (35.7). For an atom in a magnetic field, this frequency is just what we have earlier called \u03c9 p and it is given in terms of the magnetic field by Eq. (35.4). If the atom is tickled with the wrong frequency, the chance of causing a transition is very small. Thus there is a sharp resonance at \u03c9 p in the probability of causing a transition. By measuring the frequency of this resonance in a known magnetic field B , we can measure the quantity g(q/2m) \u2014and hence the g -factor\u2014with great precision. It is interesting that one comes to the same conclusion from a classical point of view. According to the classical picture, when we place a small gyroscope with a magnetic moment \u03bc and an angular momentum J in an external magnetic field, the gyroscope will precess about an axis parallel to the magnetic field. (See Fig. 35-3.) Suppose we ask: How can we change the angle of the classical gyroscope with respect to the field\u2014namely, with respect to the z -axis? The magnetic field produces a torque around a horizontal axis. Such a torque you would think is trying to line up the magnet with the field, but it only causes the precession. If we want to change the angle of the gyroscope with respect to the z -axis, we must exert a torque on it about the z -axis. If we apply a torque which goes in the same direction as the precession, the angle of the gyroscope will change to give a smaller component of J in the z -direction. In Fig. 35-3, the angle between J and the z -axis would increase. If we try to hinder the precession, J moves toward the vertical. For our precessing atom in a uniform magnetic field, how can we apply the kind of torque we want? The answer is: with a weak magnetic field from the side. You might at first think that the direction of this magnetic field would have to rotate with the precession of the magnetic moment, so that it was always at right angles to the moment, as indicated by the field B \u2032 in Fig. 35-4(a). Such a field works very well, but an alternating horizontal field is almost as good. If we have a small horizontal field B \u2032 , which is always in the x -direction (plus or minus) and which oscillates with the frequency \u03c9 p , then on each one-half cycle the torque on the magnetic moment reverses, so that it has a cumulative effect which is almost as effective as a rotating magnetic field. Classically, then, we would expect the component of the magnetic moment along the z -direction to change if we have a very weak oscillating magnetic field at a frequency which is exactly \u03c9 p . Classically, of course, \u03bc z would change continuously, but in quantum mechanics the z -component of the magnetic moment cannot adjust continuously. It must jump suddenly from one value to another. We have made the comparison between the consequences of classical mechanics and quantum mechanics to give you some clue as to what might happen classically and how it is related to what actually happens in quantum mechanics. You will notice, incidentally, that the expected resonant frequency is the same in both cases. One additional remark: From what we have said about quantum mechanics, there is no apparent reason why there couldn\u2019t also be transitions at the frequency 2 \u03c9 p . It happens that there isn\u2019t any analog of this in the classical case, and also it doesn\u2019t happen in the quantum theory either\u2014at least not for the particular method of inducing the transitions that we have described. With an oscillating horizontal magnetic field, the probability that a frequency 2 \u03c9 p would cause a jump of two steps at once is zero. It is only at the frequency \u03c9 p that transitions, either upward or downward, are likely to occur. Now we are ready to describe Rabi\u2019s method for measuring magnetic moments. We will consider here only the operation for atoms with a spin of 1/2 . A diagram of the apparatus is shown in Fig. 35-5. There is an oven which gives out a stream of neutral atoms which passes down a line of three magnets. Magnet 1 is just like the one in Fig. 35-2, and has a field with a strong field gradient\u2014say, with \u2202 B z /\u2202z positive. If the atoms have a magnetic moment, they will be deflected downward if J z =+\u210f/2 , or upward if J z =\u2212\u210f/2 (since for electrons \u03bc is directed opposite to J ). If we consider only those atoms which can get through the slit S 1 , there are two possible trajectories, as shown. Atoms with J z =+\u210f/2 must go along curve a to get through the slit, and those with J z =\u2212\u210f/2 must go along curve b . Atoms which start out from the oven along other paths will not get through the slit. Magnet 2 has a uniform field. There are no forces on the atoms in this region, so they go straight through and enter magnet 3 . Magnet 3 is just like magnet 1 but with the field inverted, so that \u2202 B z /\u2202z has the opposite sign. The atoms with J z =+\u210f/2 (we say \u201cwith spin up\u201d), that felt a downward push in magnet 1 , get an upward push in magnet 3 ; they continue on the path a and go through slit S 2 to a detector. The atoms with J z =\u2212\u210f/2 (\u201cwith spin down\u201d) also have opposite forces in magnets 1 and 3 and go along the path b , which also takes them through slit S 2 to the detector. The detector may be made in various ways, depending on the atom being measured. For example, for atoms of an alkali metal like sodium, the detector can be a thin, hot tungsten wire connected to a sensitive current meter. When sodium atoms land on the wire, they are evaporated off as Na + ions, leaving an electron behind. There is a current from the wire proportional to the number of sodium atoms arriving per second. In the gap of magnet 2 there is a set of coils that produces a small horizontal magnetic field B \u2032 . The coils are driven with a current which oscillates at a variable frequency \u03c9 . So between the poles of magnet 2 there is a strong, constant, vertical field B 0 and a weak, oscillating, horizontal field B \u2032 . Suppose now that the frequency \u03c9 of the oscillating field is set at \u03c9 p \u2014the \u201cprecession\u201d frequency of the atoms in the field B . The alternating field will cause some of the atoms passing by to make transitions from one J z to the other. An atom whose spin was initially \u201cup\u201d ( J z =+\u210f/2 ) may be flipped \u201cdown\u201d ( J z =\u2212\u210f/2 ). Now this atom has the direction of its magnetic moment reversed, so it will feel a downward force in magnet 3 and will move along the path a \u2032 , shown in Fig. 35-5. It will no longer get through the slit S 2 to the detector. Similarly, some of the atoms whose spins were initially down ( J z =\u2212\u210f/2 ) will have their spins flipped up ( J z =+\u210f/2 ) as they pass through magnet 2 . They will then go along the path b \u2032 and will not get to the detector. If the oscillating field B \u2032 has a frequency appreciably different from \u03c9 p , it will not cause any spin flips, and the atoms will follow their undisturbed paths to the detector. So you can see that the \u201cprecession\u201d frequency \u03c9 p of the atoms in the field B 0 can be found by varying the frequency \u03c9 of the field B \u2032 until a decrease is observed in the current of atoms arriving at the detector. A decrease in the current will occur when \u03c9 is \u201cin resonance\u201d with \u03c9 p . A plot of the detector current as a function of \u03c9 might look like the one shown in Fig. 35-6. Knowing \u03c9 p , we can obtain the g -value of the atom. Such atomic-beam or, as they are usually called, \u201cmolecular\u201d beam resonance experiments are a beautiful and delicate way of measuring the magnetic properties of atomic objects. The resonance frequency \u03c9 p can be determined with great precision\u2014in fact, with a greater precision than we can measure the magnetic field B 0 , which we must know to find g . We would like now to describe the phenomenon of the paramagnetism of bulk materials. Suppose we have a substance whose atoms have permanent magnetic moments, for example a crystal like copper sulfate. In the crystal there are copper ions whose inner electron shells have a net angular momentum and a net magnetic moment. So the copper ion is an object which has a permanent magnetic moment. Let\u2019s say just a word about which atoms have magnetic moments and which ones don\u2019t. Any atom, like sodium for instance, which has an odd number of electrons, will have a magnetic moment. Sodium has one electron in its unfilled shell. This electron gives the atom a spin and a magnetic moment. Ordinarily, however, when compounds are formed the extra electrons in the outside shell are coupled together with other electrons whose spin directions are exactly opposite, so that all the angular momenta and magnetic moments of the valence electrons usually cancel out. That\u2019s why, in general, molecules do not have a magnetic moment. Of course if you have a gas of sodium atoms, there is no such cancellation.1 Also, if you have what is called in chemistry a \u201cfree radical\u201d\u2014an object with an odd number of valence electrons\u2014then the bonds are not completely satisfied, and there is a net angular momentum. In most bulk materials there is a net magnetic moment only if there are atoms present whose inner electron shell is not filled. Then there can be a net angular momentum and a magnetic moment. Such atoms are found in the \u201ctransition element\u201d part of the periodic table\u2014for instance, chromium, manganese, iron, nickel, cobalt, palladium, and platinum are elements of this kind. Also, all of the rare earth elements have unfilled inner shells and permanent magnetic moments. There are a couple of other strange things that also happen to have magnetic moments, such as liquid oxygen, but we will leave it to the chemistry department to explain the reason. Now suppose that we have a box full of atoms or molecules with permanent moments\u2014say a gas, or a liquid, or a crystal. We would like to know what happens if we apply an external magnetic field. With no magnetic field, the atoms are kicked around by the thermal motions, and the moments wind up pointing in all directions. But when there is a magnetic field, it acts to line up the little magnets; then there are more moments lying toward the field than away from it. The material is \u201cmagnetized.\u201d We define the magnetization M of a material as the net magnetic moment per unit volume, by which we mean the vector sum of all the atomic magnetic moments in a unit volume. If there are N atoms per unit volume and their average moment is \u27e8\u03bc \u27e9 av then M can be written as N times the average atomic moment: M=N\u27e8\u03bc \u27e9 av . (35.8) The definition of M corresponds to the definition of the electric polarization P of Chapter 10. The classical theory of paramagnetism is just like the theory of the dielectric constant we showed you in Chapter 11. One assumes that each of the atoms has a magnetic moment \u03bc , which always has the same magnitude but which can point in any direction. In a field B , the magnetic energy is \u2212\u03bc\u22c5B=\u2212\u03bcBcos\u03b8 , where \u03b8 is the angle between the moment and the field. From statistical mechanics, the relative probability of having any angle is e \u2212energy/kT , so angles near zero are more likely than angles near \u03c0 . Proceeding exactly as we did in Section 11-3, we find that for small magnetic fields M is directed parallel to B and has the magnitude M= N \u03bc 2 B 3kT . (35.9) [See Eq. (11.20).] This approximate formula is correct only for \u03bcB/kT much less than one. We find that the induced magnetization\u2014the magnetic moment per unit volume\u2014is proportional to the magnetic field. This is the phenomenon of paramagnetism. You will see that the effect is stronger at lower temperatures and weaker at higher temperatures. When we put a field on a substance, it develops, for small fields, a magnetic moment proportional to the field. The ratio of M to B (for small fields) is called the magnetic susceptibility. Now we want to look at paramagnetism from the point of view of quantum mechanics. We take first the case of an atom with a spin of 1/2 . In the absence of a magnetic field the atoms have a certain energy, but in a magnetic field there are two possible energies, one for each value of J z . For J z =+\u210f/2 , the energy is changed by the magnetic field by the amount \u0394 U 1 =+g( q e \u210f 2m )\u22c5 1 2 \u22c5B. (35.10) (The energy shift \u0394U is positive for an atom because the electron charge is negative.) For J z =\u2212\u210f/2 , the energy is changed by the amount \u0394 U 2 =\u2212g( q e \u210f 2m )\u22c5 1 2 \u22c5B. (35.11) To save writing, let\u2019s set \u03bc 0 =g( q e \u210f 2m )\u22c5 1 2 ; (35.12) then \u0394U=\u00b1 \u03bc 0 B. (35.13) The meaning of \u03bc 0 is clear: \u2212 \u03bc 0 is the z -component of the magnetic moment in the up-spin case, and + \u03bc 0 is the z -component of the magnetic moment in the down-spin case. Now statistical mechanics tells us that the probability that an atom is in one state or another is proportional to e \u2212(Energy of state)/kT . ( Energy of state ) / k T With no magnetic field the two states have the same energy; so when there is equilibrium in a magnetic field, the probabilities are proportional to e \u2212\u0394U/kT . (35.14) The number of atoms per unit volume with spin up is N up =a e \u2212 \u03bc 0 B/kT , (35.15) and the number with spin down is N down =a e + \u03bc 0 B/kT . (35.16) The constant a is to be determined so that N up + N down =N, (35.17) the total number of atoms per unit volume. So we get that a= N e + \u03bc 0 B/kT + e \u2212 \u03bc 0 B/kT . (35.18) What we are interested in is the average magnetic moment along the z -axis. The atoms with spin up will contribute a moment of \u2212 \u03bc 0 , and those with spin down will have a moment of + \u03bc 0 ; so the average moment is \u27e8\u03bc \u27e9 av = N up (\u2212 \u03bc 0 )+ N down (+ \u03bc 0 ) N . (35.19) The magnetic moment per unit volume M is then N\u27e8\u03bc \u27e9 av . Using Eqs. (35.15), (35.16), and (35.17), we get that M=N \u03bc 0 e + \u03bc 0 B/kT \u2212 e \u2212 \u03bc 0 B/kT e + \u03bc 0 B/kT + e \u2212 \u03bc 0 B/kT . (35.20) This is the quantum-mechanical formula for M for atoms with j=1/2 . Incidentally, this formula can also be written somewhat more concisely in terms of the hyperbolic tangent function: M=N \u03bc 0 tanh \u03bc 0 B kT . (35.21) A plot of M as a function of B is given in Fig. 35-7. When B gets very large, the hyperbolic tangent approaches 1 , and M approaches the limiting value N \u03bc 0 . So at high fields, the magnetization saturates. We can see why that is; at high enough fields the moments are all lined up in the same direction. In other words, they are all in the spin-down state, and each atom contributes the moment \u03bc 0 . In most normal cases\u2014say, for typical moments, room temperatures, and the fields one can normally get (like 10,000 gauss)\u2014the ratio \u03bc 0 B/kT is about 0.002 . One must go to very low temperatures to see the saturation. For normal temperatures, we can usually replace tanhx by x , and write M= N \u03bc 2 0 B kT . (35.22) Just as we saw in the classical theory, M is proportional to B . In fact, the formula is almost exactly the same, except that there seems to be a factor of 1/3 missing. But we still need to relate the \u03bc 0 in our quantum formula to the \u03bc that appears in the classical result, Eq. (35.9). In the classical formula, what appears is \u03bc 2 =\u03bc\u22c5\u03bc , the square of the vector magnetic moment, or \u03bc\u22c5\u03bc=(g q e 2m ) 2 J\u22c5J. (35.23) We pointed out in the last chapter that you can very likely get the right answer from a classical calculation by replacing J\u22c5J by j(j+1) \u210f 2 . In our particular example, we have j=1/2 , so j(j+1) \u210f 2 = 3 4 \u210f 2 . 3 Substituting this for J\u22c5J in Eq. (35.23), we get \u03bc\u22c5\u03bc=(g q e 2m ) 2 3 \u210f 2 4 , 2 or in terms of \u03bc 0 , defined in Eq. (35.12), we get \u03bc\u22c5\u03bc=3 \u03bc 2 0 . 2 Substituting this for \u03bc 2 in the classical formula, Eq. (35.9), does indeed reproduce the correct quantum formula, Eq. (35.22). The quantum theory of paramagnetism is easily extended to atoms of any spin j . The low-field magnetization is M=N g 2 j(j+1) 3 \u03bc 2 B B kT , (35.24) where \u03bc B = q e \u210f 2m (35.25) is a combination of constants with the dimensions of a magnetic moment. Most atoms have moments of roughly this size. It is called the Bohr magneton. The spin magnetic moment of the electron is almost exactly one Bohr magneton. There is a very interesting special application of paramagnetism. At very low temperatures it is possible to line up the atomic magnets in a strong field. It is then possible to get down to extremely low temperatures by a process called adiabatic demagnetization. We can take a paramagnetic salt (for example, one containing a number of rare-earth atoms like praseodymium-ammonium-nitrate), and start by cooling it down with liquid helium to one or two degrees absolute in a strong magnetic field. Then the factor \u03bcB/kT is larger than 1 \u2014say more like 2 or 3 . Most of the spins are lined up, and the magnetization is nearly saturated. Let\u2019s say, to make it easy, that the field is very powerful and the temperature is very low, so that nearly all the atoms are lined up. Then you isolate the salt thermally (say, by removing the liquid helium and leaving a good vacuum) and turn off the magnetic field. The temperature of the salt goes way down. Now if you were to turn off the field suddenly, the jiggling and shaking of the atoms in the crystal lattice would gradually knock all the spins out of alignment. Some of them would be up and some down. But if there is no field (and disregarding the interactions between the atomic magnets, which will make only a slight error), it takes no energy to turn over the atomic magnets. They could randomize their spins without any energy change and, therefore, without any temperature change. Suppose, however, that while the atomic magnets are being flipped over by the thermal motion there is still some magnetic field present. Then it requires some work to flip them over opposite to the field\u2014they must do work against the field. This takes energy from the thermal motions and lowers the temperature. So if the strong magnetic field is not removed too rapidly, the temperature of the salt will decrease\u2014it is cooled by the demagnetization. From the quantum-mechanical view, when the field is strong all the atoms are in the lowest state, because the odds against any being in the upper state are impossibly big. But as the field is lowered, it gets more and more likely that thermal fluctuations will knock an atom into the upper state. When that happens, the atom absorbs the energy \u0394U= \u03bc 0 B . So if the field is turned off slowly, the magnetic transitions can take energy out of the thermal vibrations of the crystal, cooling it off. It is possible in this way to go from a temperature of a few degrees absolute down to a temperature of a few thousandths of a degree. Would you like to make something even colder than that? It turns out that Nature has provided a way. We have already mentioned that there are also magnetic moments for the atomic nuclei. Our formulas for paramagnetism work just as well for nuclei, except that the moments of nuclei are roughly a thousand times smaller. [They are of the order of magnitude of q\u210f/2 m p , where m p is the proton mass, so they are smaller by the ratio of the masses of the electron and proton.] With such magnetic moments, even at a temperature of 2 \u2218 K, the factor \u03bcB/kT is only a few parts in a thousand. But if we use the paramagnetic demagnetization process to get down to a temperature of a few thousandths of a degree, \u03bcB/kT becomes a number near 1 \u2014at these low temperatures we can begin to saturate the nuclear moments. That is good luck, because we can then use the adiabatic demagnetization of the nuclear magnetism to reach still lower temperatures. Thus it is possible to do two stages of magnetic cooling. First we use adiabatic demagnetization of paramagnetic ions to reach a few thousandths of a degree. Then we use the cold paramagnetic salt to cool some material which has a strong nuclear magnetism. Finally, when we remove the magnetic field from this material, its temperature will go down to within a millionth of a degree of absolute zero\u2014if we have done everything very carefully. We have said that atomic paramagnetism is very small and that nuclear magnetism is even a thousand times smaller. Yet it is relatively easy to observe the nuclear magnetism by the phenomenon of \u201cnuclear magnetic resonance.\u201d Suppose we take a substance like water, in which all of the electron spins are exactly balanced so that their net magnetic moment is zero. The molecules will still have a very, very tiny magnetic moment due to the nuclear magnetic moment of the hydrogen nuclei. Suppose we put a small sample of water in a magnetic field B . Since the protons (of the hydrogen) have a spin of 1/2 , they will have two possible energy states. If the water is in thermal equilibrium, there will be slightly more protons in the lower energy states\u2014with their moments directed parallel to the field. There is a small net magnetic moment per unit volume. Since the proton moment is only about one-thousandth of an atomic moment, the magnetization which goes as \u03bc 2 \u2014using Eq. (35.22)\u2014is only about one-millionth as strong as typical atomic paramagnetism. (That\u2019s why we have to pick a material with no atomic magnetism.) If you work it out, the difference between the number of protons with spin up and with spin down is only one part in 10 8 , so the effect is indeed very small! It can still be observed, however, in the following way. Suppose we surround the water sample with a small coil that produces a small horizontal oscillating magnetic field. If this field oscillates at the frequency \u03c9 p , it will induce transitions between the two energy states\u2014just as we described for the Rabi experiment in Section 35-3. When a proton flips from an upper energy state to a lower one, it will give up the energy 2 \u03bc z B which, as we have seen, is equal to \u210f \u03c9 p . If it flips from the lower energy state to the upper one, it will absorb the energy \u210f \u03c9 p from the coil. Since there are slightly more protons in the lower state than in the upper one, there will be a net absorption of energy from the coil. Although the effect is very small, the slight energy absorption can be seen with a sensitive electronic amplifier. Just as in the Rabi molecular-beam experiment, the energy absorption will be seen only when the oscillating field is in resonance, that is, when \u03c9= \u03c9 p =g( q e 2 m p )B. q It is often more convenient to search for the resonance by varying B while keeping \u03c9 fixed. The energy absorption will evidently appear when B= 2 m p g q e \u03c9. 2 A typical nuclear magnetic resonance apparatus is shown in Fig. 35-8. A high-frequency oscillator drives a small coil placed between the poles of a large electromagnet. Two small auxiliary coils around the pole tips are driven with a 60 -cycle current so that the magnetic field is \u201cwobbled\u201d about its average value by a very small amount. As an example, say that the main current of the magnet is set to give a field of 5000 gauss, and the auxiliary coils produce a variation of \u00b11 gauss about this value. If the oscillator is set at 21.2 megacycles per second, it will then be at the proton resonance each time the field sweeps through 5000 gauss [using Eq. (34.13) with g=5.58 for the proton]. The circuit of the oscillator is arranged to give an additional output signal proportional to any change in the power being absorbed from the oscillator. This signal is fed to the vertical deflection amplifier of an oscilloscope. The horizontal sweep of the oscilloscope is triggered once during each cycle of the field-wobbling frequency. (More usually, the horizontal deflection is made to follow in proportion to the wobbling field.) Before the water sample is placed inside the high-frequency coil, the power drawn from the oscillator is some value. (It doesn\u2019t change with the magnetic field.) When a small bottle of water is placed in the coil, however, a signal appears on the oscilloscope, as shown in the figure. We see a picture of the power being absorbed by the flipping over of the protons! In practice, it is difficult to know how to set the main magnet to exactly 5000 gauss. What one does is to adjust the main magnet current until the resonance signal appears on the oscilloscope. It turns out that this is now the most convenient way to make an accurate measurement of the strength of a magnetic field. Of course, at some time someone had to measure accurately the magnetic field and frequency to determine the g -value of the proton. But now that this has been done, a proton resonance apparatus like that of the figure can be used as a \u201cproton resonance magnetometer.\u201d We should say a word about the shape of the signal. If we were to wobble the magnetic field very slowly, we would expect to see a normal resonance curve. The energy absorption would read a maximum when \u03c9 p arrived exactly at the oscillator frequency. There would be some absorption at nearby frequencies because all the protons are not in exactly the same field\u2014and different fields mean slightly different resonant frequencies. One might wonder, incidentally, whether at the resonance frequency we should see any signal at all. Shouldn\u2019t we expect the high-frequency field to equalize the populations of the two states\u2014so that there should be no signal except when the water is first put in? Not exactly, because although we are trying to equalize the two populations, the thermal motions on their part are trying to keep the proper ratios for the temperature T . If we sit at the resonance, the power being absorbed by the nuclei is just what is being lost to the thermal motions. There is, however, relatively little \u201cthermal contact\u201d between the proton magnetic moments and the atomic motions. The protons are relatively isolated down in the center of the electron distributions. So in pure water, the resonance signal is, in fact, usually too small to be seen. To increase the absorption, it is necessary to increase the \u201cthermal contact.\u201d This is usually done by adding a little iron oxide to the water. The iron atoms are like small magnets; as they jiggle around in their thermal dance, they make tiny jiggling magnetic fields at the protons. These varying fields \u201ccouple\u201d the proton magnets to the atomic vibrations and tend to establish thermal equilibrium. It is through this \u201ccoupling\u201d that protons in the higher energy states can lose their energy so that they are again capable of absorbing energy from the oscillator. In practice the output signal of a nuclear resonance apparatus does not look like a normal resonance curve. It is usually a more complicated signal with oscillations\u2014like the one drawn in the figure. Such signal shapes appear because of the changing fields. The explanation should be given in terms of quantum mechanics, but it can be shown that in such experiments the classical ideas of precessing moments always give the correct answer. Classically, we would say that when we arrive at resonance we start driving a lot of the precessing nuclear magnets synchronously. In so doing, we make them precess together. These nuclear magnets, all rotating together, will set up an induced emf in the oscillator coil at the frequency \u03c9 p . But because the magnetic field is increasing with time, the precession frequency is increasing also, and the induced voltage is soon at a frequency a little higher than the oscillator frequency. As the induced emf goes alternately in phase and out of phase with the oscillator, the \u201cabsorbed\u201d power goes alternately positive and negative. So on the oscilloscope we see the beat note between the proton frequency and the oscillator frequency. Because the proton frequencies are not all identical (different protons are in slightly different fields) and also possibly because of the disturbance from the iron oxide in the water, the freely precessing moments soon get out of phase, and the beat signal disappears. These phenomena of magnetic resonance have been put to use in many ways as tools for finding out new things about matter\u2014especially in chemistry and nuclear physics. It goes without saying that the numerical values of the magnetic moments of nuclei tell us something about their structure. In chemistry, much has been learned from the structure (or shape) of the resonances. Because of magnetic fields produced by nearby nuclei, the exact position of a nuclear resonance is shifted somewhat, depending on the environment in which any particular nucleus finds itself. Measuring these shifts helps determine which atoms are near which other ones and helps to elucidate the details of the structure of molecules. Equally important is the electron spin resonance of free radicals. Although not present to any very large extent in equilibrium, such radicals are often intermediate states of chemical reactions. A measurement of an electron spin resonance is a delicate test for the presence of free radicals and is often the key to understanding the mechanism of certain chemical reactions."
    },
    {
        "input": "Tensors",
        "output": "Physicists always have a habit of taking the simplest example of any phenomenon and calling it \u201cphysics,\u201d leaving the more complicated examples to become the concern of other fields\u2014say of applied mathematics, electrical engineering, chemistry, or crystallography. Even solid-state physics is almost only half physics because it worries too much about special substances. So in these lectures we will be leaving out many interesting things. For instance, one of the important properties of crystals\u2014or of most substances\u2014is that their electric polarizability is different in different directions. If you apply a field in any direction, the atomic charges shift a little and produce a dipole moment, but the magnitude of the moment depends very much on the direction of the field. That is, of course, quite a complication. But in physics we usually start out by talking about the special case in which the polarizability is the same in all directions, to make life easier. We leave the other cases to some other field. Therefore, for our later work, we will not need at all what we are going to talk about in this chapter. The mathematics of tensors is particularly useful for describing properties of substances which vary in direction\u2014although that\u2019s only one example of their use. Since most of you are not going to become physicists, but are going to go into the real world, where things depend severely upon direction, sooner or later you will need to use tensors. In order not to leave anything out, we are going to describe tensors, although not in great detail. We want the feeling that our treatment of physics is complete. For example, our electrodynamics is complete\u2014as complete as any electricity and magnetism course, even a graduate course. Our mechanics is not complete, because we studied mechanics when you didn\u2019t have a high level of mathematical sophistication, and we were not able to discuss subjects like the principle of least action, or Lagrangians, or Hamiltonians, and so on, which are more elegant ways of describing mechanics. Except for general relativity, however, we do have the complete laws of mechanics. Our electricity and magnetism is complete, and a lot of other things are quite complete. The quantum mechanics, naturally, will not be\u2014we have to leave something for the future. But you should at least know what a tensor is. We emphasized in Chapter 30 that the properties of crystalline substances are different in different directions\u2014we say they are anisotropic. The variation of the induced dipole moment with the direction of the applied electric field is only one example, the one we will use for our example of a tensor. Let\u2019s say that for a given direction of the electric field the induced dipole moment per unit volume P is proportional to the strength of the applied field E . (This is a good approximation for many substances if E is not too large.) We will call the proportionality constant \u03b1 .1 We want now to consider substances in which \u03b1 depends on the direction of the applied field, as, for example, in crystals like calcite, which make double images when you look through them. Suppose, in a particular crystal, we find that an electric field E1 in the x -direction produces the polarization P1 in the x -direction. Then we find that an electric field E2 in the y -direction, with the same strength as E1 , produces a different polarization P2 in the y -direction. What would happen if we put an electric field at 45\u2218 ? Well, that\u2019s a superposition of two fields along x and y , so the polarization P will be the vector sum of P1 and P2 , as shown in Fig. 31\u20131(a). The polarization is no longer in the same direction as the electric field. You can see how that might come about. There may be charges which can move easily up and down, but which are rather stiff for sidewise motions. When a force is applied at 45\u2218 , the charges move farther up than they do toward the side. The displacements are not in the direction of the external force, because there are asymmetric internal elastic forces. There is, of course, nothing special about 45\u2218 . It is generally true that the induced polarization of a crystal is not in the direction of the electric field. In our example above, we happened to make a \u201clucky\u201d choice of our x - and y -axes, for which P was along E for both the x - and y -directions. If the crystal were rotated with respect to the coordinate axes, the electric field E2 in the y -direction would have produced a polarization P with both an x - and a y -component. Similarly, the polarization due to an electric field in the x -direction would have produced a polarization with an x -component and a y -component. Then the polarizations would be as shown in Fig. 31\u20131(b), instead of as in part (a). Things get more complicated\u2014but for any field E , the magnitude of P is still proportional to the magnitude of E . We want now to treat the general case of an arbitrary orientation of a crystal with respect to the coordinate axes. An electric field in the x -direction will produce a polarization P with x -, y -, and z -components; we can write Px=\u03b1xxEx,Py=\u03b1yxEx,Pz=\u03b1zxEx. All we are saying here is that if the electric field is in the x -direction, the polarization does not have to be in that same direction, but rather has an x -, a y -, and a z -component\u2014each proportional to Ex . We are calling the constants of proportionality \u03b1xx , \u03b1yx , and \u03b1zx , respectively (the first letter to tell us which component of P is involved, the last to refer to the direction of the electric field). Similarly, for a field in the y -direction, we can write P x = \u03b1 xy E y , P y = \u03b1 yy E y , P z = \u03b1 zy E y ; (31.2) and for a field in the z -direction, P x = \u03b1 xz E z , P y = \u03b1 yz E z , P z = \u03b1 zz E z . (31.3) Now we have said that polarization depends linearly on the fields, so if there is an electric field E that has both an x - and a y -component, the resulting x -component of P will be the sum of the two P x \u2019s of Eqs. (31.1) and (31.2). If E has components along x , y , and z , the resulting components of P will be the sum of the three contributions in Eqs. (31.1), (31.2), and (31.3). In other words, P will be given by P x P y P z = \u03b1 xx = \u03b1 yx = \u03b1 zx E x + \u03b1 xy E x + \u03b1 yy E x + \u03b1 zy E y + \u03b1 xz E y + \u03b1 yz E y + \u03b1 zz E z , E z , E z . (31.4) The dielectric behavior of the crystal is then completely described by the nine quantities ( \u03b1 xx , \u03b1 xy , \u03b1 xz , \u03b1 yx , \u2026), which we can represent by the symbol \u03b1 ij . (The subscripts i and j each stand for any one of the three possible letters x , y , and z .) Any arbitrary electric field E can be resolved with the components E x , E y , and E z ; from these we can use the \u03b1 ij to find P x , P y , and P z , which together give the total polarization P . The set of nine coefficients \u03b1 ij is called a tensor\u2014in this instance, the tensor of polarizability. Just as we say that the three numbers ( E x , E y , E z ) \u201cform the vector E ,\u201d we say that the nine numbers ( \u03b1 xx , \u03b1 xy , \u2026) \u201cform the tensor \u03b1 ij .\u201d You know that when we change to a different coordinate system x \u2032 , y \u2032 , and z \u2032 , the components E x \u2032 , E y \u2032 , and E z \u2032 of the vector will be quite different\u2014as will also the components of P . So all the coefficients \u03b1 ij will be different for a different set of coordinates. You can, in fact, see how the \u03b1 \u2019s must be changed by changing the components of E and P in the proper way, because if we describe the same physical electric field in the new coordinate system we should get the same polarization. For any new set of coordinates, P x \u2032 is a linear combination of P x , P y , and P z : P x \u2032 =a P x +b P y +c P z , P P b P P and similarly for the other components. If you substitute for P x , P y , and P z in terms of the E \u2019s, using Eq. (31.4), you get P x \u2032 = + + a b c ( \u03b1 xx ( \u03b1 yx ( \u03b1 zx E x + \u03b1 xy E x + \u03b1 yy E x + \u03b1 zy E y + \u03b1 xz E y + \u03b1 yz E y + \u03b1 zz E z ) E z ) E z ). Then you write E x , E y , and E z in terms of E x \u2032 , E y \u2032 , and E z \u2032 ; for instance, E x = a \u2032 E x \u2032 + b \u2032 E y \u2032 + c \u2032 E z \u2032 , \u2032 where a \u2032 , b \u2032 , c \u2032 are related to, but not equal to, a , b , c . So you have P x \u2032 , expressed in terms of the components E x \u2032 , E y \u2032 , and E z \u2032 ; that is, you have the new \u03b1 ij . It is fairly messy, but quite straightforward. When we talk about changing the axes we are assuming that the crystal stays put in space. If the crystal were rotated with the axes, the \u03b1 \u2019s would not change. Conversely, if the orientation of the crystal were changed with respect to the axes, we would have a new set of \u03b1 \u2019s. But if they are known for any one orientation of the crystal, they can be found for any other orientation by the transformation we have just described. In other words, the dielectric property of a crystal is described completely by giving the components of the polarization tensor \u03b1 ij with respect to any arbitrarily chosen set of axes. Just as we can associate a vector velocity v=( v x , v y , v z ) with a particle, knowing that the three components will change in a certain definite way if we change our coordinate axes, so with a crystal we associate its polarization tensor \u03b1 ij , whose nine components will transform in a certain definite way if the coordinate system is changed. The relation between P and E written in Eq. (31.4) can be put in the more compact notation: P i = \u2211 j \u03b1 ij E j , (31.5) where it is understood that i represents either x , y , or z and that the sum is taken on j=x , y , and z . Many special notations have been invented for dealing with tensors, but each of them is convenient only for a limited class of problems. One common convention is to omit the sum sign (\u2211) in Eq. (31.5), leaving it understood that whenever the same subscript occurs twice (here j ), a sum is to be taken over that index. Since we will be using tensors so little, we will not bother to adopt any such special notations or conventions. We want now to get some experience with tensors. Suppose we ask the interesting question: What energy is required to polarize the crystal (in addition to the energy in the electric field which we know is \u03f5 0 E 2 /2 per unit volume)? Consider for a moment the atomic charges that are being displaced. The work done in displacing the charge the distance dx is q E x dx , and if there are N charges per unit volume, the work done is q E x Ndx . But qNdx is the change d P x in the dipole moment per unit volume. So the energy required per unit volume is E x d P x . E d P Combining the work for the three components of the field, the work per unit volume is found to be E\u22c5dP. E d P Since the magnitude of P is proportional to E , the work done per unit volume in bringing the polarization from 0 to P is the integral of E\u22c5dP . Calling this work u P ,2 we write u P = 1 2 E\u22c5P= 1 2 \u2211 i E i P i . (31.6) Now we can express P in terms of E by Eq. (31.5), and we have that u P = 1 2 \u2211 i \u2211 j \u03b1 ij E i E j . (31.7) The energy density u P is a number independent of the choice of axes, so it is a scalar. A tensor has then the property that when it is summed over one index (with a vector), it gives a new vector; and when it is summed over both indexes (with two vectors), it gives a scalar. The tensor \u03b1 ij should really be called a \u201ctensor of second rank,\u201d because it has two indexes. A vector\u2014with one index\u2014is a tensor of the first rank, and a scalar\u2014with no index\u2014is a tensor of zero rank. So we say that the electric field E is a tensor of the first rank and that the energy density u P is a tensor of zero rank. It is possible to extend the ideas of a tensor to three or more indexes, and so to make tensors of ranks higher than two. The subscripts of the polarization tensor range over three possible values\u2014they are tensors in three dimensions. The mathematicians consider tensors in four, five, or more dimensions. We have already used a four-dimensional tensor F \u03bc\u03bd in our relativistic description of the electromagnetic field (Chapter 26). The polarization tensor \u03b1 ij has the interesting property that it is symmetric, that is, that \u03b1 xy = \u03b1 yx , and so on for any pair of indexes. (This is a physical property of a real crystal and not necessary for all tensors.) You can prove for yourself that this must be true by computing the change in energy of a crystal through the following cycle: (1) Turn on a field in the x -direction; (2) turn on a field in the y -direction; (3) turn off the x -field; (4) turn off the y -field. The crystal is now back where it started, and the net work done on the polarization must be back to zero. You can show, however, that for this to be true, \u03b1 xy must be equal to \u03b1 yx . The same kind of argument can, of course, be given for \u03b1 xz , etc. So the polarization tensor is symmetric. This also means that the polarization tensor can be measured by just measuring the energy required to polarize the crystal in various directions. Suppose we apply an E -field with only an x - and a y -component; then according to Eq. (31.7), u P = 1 2 [ \u03b1 xx E 2 x +( \u03b1 xy + \u03b1 yx ) E x E y + \u03b1 yy E 2 y ]. (31.8) With an E x alone, we can determine \u03b1 xx ; with an E y alone, we can determine \u03b1 yy ; with both E x and E y , we get an extra energy due to the term with ( \u03b1 xy + \u03b1 yx ) . Since the \u03b1 xy and \u03b1 yx are equal, this term is 2 \u03b1 xy and can be related to the energy. The energy expression, Eq. (31.8), has a nice geometric interpretation. Suppose we ask what fields E x and E y correspond to some given energy density\u2014say u 0 . That is just the mathematical problem of solving the equation \u03b1 xx E 2 x +2 \u03b1 xy E x E y + \u03b1 yy E 2 y =2 u 0 . 2 2 This is a quadratic equation, so if we plot E x and E y the solutions of this equation are all the points on an ellipse (Fig. 31\u20132). (It must be an ellipse, rather than a parabola or a hyperbola, because the energy for any field is always positive and finite.) The vector E with components E x and E y can be drawn from the origin to the ellipse. So such an \u201cenergy ellipse\u201d is a nice way of \u201cvisualizing\u201d the polarization tensor. If we now generalize to include all three components, the electric vector E in any direction required to give a unit energy density gives a point which will be on the surface of an ellipsoid, as shown in Fig. 31\u20133. The shape of this ellipsoid of constant energy uniquely characterizes the tensor polarizability. Now an ellipsoid has the nice property that it can always be described simply by giving the directions of three \u201cprincipal axes\u201d and the diameters of the ellipse along these axes. The \u201cprincipal axes\u201d are the directions of the longest and shortest diameters and the direction at right angles to both. They are indicated by the axes a , b , and c in Fig. 31\u20133. With respect to these axes, the ellipsoid has the particularly simple equation \u03b1 aa E 2 a + \u03b1 bb E 2 b + \u03b1 cc E 2 c =2 u 0 . 2 2 2 So with respect to these axes, the dielectric tensor has only three components that are not zero: \u03b1 aa , \u03b1 bb , and \u03b1 cc . That is to say, no matter how complicated a crystal is, it is always possible to choose a set of axes (not necessarily the crystal axes) for which the polarization tensor has only three components. With such a set of axes, Eq. (31.4) becomes simply P a = \u03b1 aa E a , P b = \u03b1 bb E b , P c = \u03b1 cc E c . (31.9) An electric field along any one of the principal axes produces a polarization along the same axis, but the coefficients for the three axes may, of course, be different. Often, a tensor is described by listing the nine coefficients in a table inside of a pair of brackets: \u23a1 \u23a3 \u23a2 \u03b1 xx \u03b1 yx \u03b1 zx \u03b1 xy \u03b1 yy \u03b1 zy \u03b1 xz \u03b1 yz \u03b1 zz \u23a4 \u23a6 \u23a5 . (31.10) For the principal axes a , b , and c , only the diagonal terms are not zero; we say then that \u201cthe tensor is diagonal.\u201d The complete tensor is \u23a1 \u23a3 \u23a2 \u03b1 aa 0 0 0 \u03b1 bb 0 0 0 \u03b1 cc \u23a4 \u23a6 \u23a5 . (31.11) The important point is that any polarization tensor (in fact, any symmetric tensor of rank two in any number of dimensions) can be put in this form by choosing a suitable set of coordinate axes. If the three elements of the polarization tensor in diagonal form are all equal, that is, if \u03b1 aa = \u03b1 bb = \u03b1 cc =\u03b1, (31.12) the energy ellipsoid becomes a sphere, and the polarizability is the same in all directions. The material is isotropic. In the tensor notation, \u03b1 ij =\u03b1 \u03b4 ij (31.13) where \u03b4 ij is the unit tensor \u03b4 ij = \u23a1 \u23a3 \u23a2 1 0 0 0 1 0 0 0 1 \u23a4 \u23a6 \u23a5 . (31.14) That means, of course, \u03b4 ij =1,ifi=j; \u03b4 ij =0,ifi\u2260j. (31.15) The tensor \u03b4 ij is often called the \u201cKronecker delta.\u201d You may amuse yourself by proving that the tensor (31.14) has exactly the same form if you change the coordinate system to any other rectangular one. The polarization tensor of Eq. (31.13) gives P i =\u03b1 \u2211 j \u03b4 ij E j =\u03b1 E i , \u2211 which means the same as our old result for isotropic dielectrics: P=\u03b1E. P E The shape and orientation of the polarization ellipsoid can sometimes be related to the symmetry properties of the crystal. We have said in Chapter 30 that there are 230 different possible internal symmetries of a three-dimensional lattice and that they can, for many purposes, be conveniently grouped into seven classes, according to the shape of the unit cell. Now the ellipsoid of polarizability must share the internal geometric symmetries of the crystal. For example, a triclinic crystal has low symmetry\u2014the ellipsoid of polarizability will have unequal axes, and its orientation will not, in general, be aligned with the crystal axes. On the other hand, a monoclinic crystal has the property that its properties are unchanged if the crystal is rotated 180 \u2218 about one axis. So the polarization tensor must be the same after such a rotation. It follows that the ellipsoid of the polarizability must return to itself after a 180 \u2218 rotation. That can happen only if one of the axes of the ellipsoid is in the same direction as the symmetry axis of the crystal. Otherwise, the orientation and dimensions of the ellipsoid are unrestricted. For an orthorhombic crystal, however, the axes of the ellipsoid must correspond to the crystal axes, because a 180 \u2218 rotation about any one of the three axes repeats the same lattice. If we go to a tetragonal crystal, the ellipse must have the same symmetry, so it must have two equal diameters. Finally, for a cubic crystal, all three diameters of the ellipsoid must be equal; it becomes a sphere, and the polarizability of the crystal is the same in all directions. There is a big game of figuring out the possible kinds of tensors for all the possible symmetries of a crystal. It is called a \u201cgroup-theoretical\u201d analysis. But for the simple case of the polarizability tensor, it is relatively easy to see what the relations must be. There are many other examples of tensors appearing in physics. For example, in a metal, or in any conductor, one often finds that the current density j is approximately proportional to the electric field E ; the proportionality constant is called the conductivity \u03c3 : j=\u03c3E. j E For crystals, however, the relation between j and E is more complicated; the conductivity is not the same in all directions. The conductivity is a tensor, and we write j i =\u2211 \u03c3 ij E j . \u2211 Another example of a physical tensor is the moment of inertia. In Chapter 18 of Volume I we saw that a solid object rotating about a fixed axis has an angular momentum L proportional to the angular velocity \u03c9 , and we called the proportionality factor I , the moment of inertia: L=I\u03c9. L I For an arbitrarily shaped object, the moment of inertia depends on its orientation with respect to the axis of rotation. For instance, a rectangular block will have different moments about each of its three orthogonal axes. Now angular velocity \u03c9 and angular momentum L are both vectors. For rotations about one of the axes of symmetry, they are parallel. But if the moment of inertia is different for the three principal axes, then \u03c9 and L are, in general, not in the same direction (see Fig. 31\u20134). They are related in a way analogous to the relation between E and P . In general, we must write L x L y L z = I xx = I yx = I zx \u03c9 x + I xy \u03c9 x + I yy \u03c9 x + I zy \u03c9 y + I xz \u03c9 y + I yz \u03c9 y + I zz \u03c9 z , \u03c9 z , \u03c9 z . (31.16) The nine coefficients I ij are called the tensor of inertia. Following the analogy with the polarization, the kinetic energy for any angular momentum must be some quadratic form in the components \u03c9 x , \u03c9 y , and \u03c9 z : KE= 1 2 \u2211 ij I ij \u03c9 i \u03c9 j . (31.17) We can use the energy to define the ellipsoid of inertia. Also, energy arguments can be used to show that the tensor is symmetric\u2014that I ij = I ji . The tensor of inertia for a rigid body can be worked out if the shape of the object is known. We need only to write down the total kinetic energy of all the particles in the body. A particle of mass m and velocity v has the kinetic energy 1 2 m v 2 , and the total kinetic energy is just the sum \u2211 1 2 m v 2 1 over all of the particles of the body. The velocity v of each particle is related to the angular velocity \u03c9 of the solid body. Let\u2019s assume that the body is rotating about its center of mass, which we take to be at rest. Then if r is the displacement of a particle from the center of mass, its velocity v is given by \u03c9\u00d7r . So the total kinetic energy is KE=\u2211 1 2 m(\u03c9\u00d7r ) 2 . (31.18) Now all we have to do is write \u03c9\u00d7r out in terms of the components \u03c9 x , \u03c9 y , \u03c9 z , and x , y , z , and compare the result with Eq. (31.17); we find I ij by identifying terms. Carrying out the algebra, we write (\u03c9\u00d7r ) 2 =(\u03c9\u00d7r ) 2 x +(\u03c9\u00d7r ) 2 y +(\u03c9\u00d7r ) 2 z =( \u03c9 y z\u2212 \u03c9 z y ) 2 +( \u03c9 z x\u2212 \u03c9 x z ) 2 +( \u03c9 x y\u2212 \u03c9 y x ) 2 = + \u03c9 2 y + \u03c9 2 z + \u03c9 2 x z 2 x 2 y 2 \u22122 \u03c9 y \u22122 \u03c9 z \u22122 \u03c9 x \u03c9 z \u03c9 x \u03c9 y zy xz yx + \u03c9 2 z + \u03c9 2 x + \u03c9 2 y y 2 z 2 x 2 . Multiplying this equation by m/2 , summing over all particles, and comparing with Eq. (31.17), we see that I xx , for instance, is given by I xx =\u2211m( y 2 + z 2 ). \u2211 This is the formula we have had before (Chapter 19, Vol. I) for the moment of inertia of a body about the x -axis. Since r 2 = x 2 + y 2 + z 2 , we can also write this term as I xx =\u2211m( r 2 \u2212 x 2 ). \u2211 Working out all of the other terms, the tensor of inertia can be written as I ij = \u23a1 \u23a3 \u23a2 \u23a2 \u23a2 \u2211 \u2212 \u2212 m( r 2 \u2212 x 2 ) \u2211myx \u2211mzx \u2212 \u2211 \u2212 \u2211mxy m( r 2 \u2212 y 2 ) \u2211mzy \u2212 \u2212 \u2211 \u2211mxz \u2211myz m( r 2 \u2212 z 2 ) \u23a4 \u23a6 \u23a5 \u23a5 \u23a5 (31.19) If you wish, this may be written in \u201ctensor notation\u201d as I ij =\u2211m( r 2 \u03b4 ij \u2212 r i r j ), (31.20) where the r i are the components (x,y,z) of the position vector of a particle and the \u2211 means to sum over all the particles. The moment of inertia, then, is a tensor of the second rank whose terms are a property of the body and relate L to \u03c9 by L i = \u2211 j I ij \u03c9 j . (31.21) For a body of any shape whatever, we can find the ellipsoid of inertia and, therefore, the three principal axes. Referred to these axes, the tensor will be diagonal, so for any object there are always three orthogonal axes for which the angular velocity and angular momentum are parallel. They are called the principal axes of inertia. We should point out that we have been using tensors of the second rank since Chapter 20 of Volume I. There, we defined a \u201ctorque in a plane,\u201d such as \u03c4 xy by \u03c4 xy =x F y \u2212y F x . F F Generalized to three dimensions, we could write \u03c4 ij = r i F j \u2212 r j F i . (31.22) The quantity \u03c4 ij is a tensor of the second rank. One way to see that this is so is by combining \u03c4 ij with some vector, say the unit vector e , according to \u2211 j \u03c4 ij e j . \u2211 If this quantity is a vector, then \u03c4 ij must transform as a tensor\u2014this is our definition of a tensor. Substituting for \u03c4 ij , we have \u2211 j \u03c4 ij e j = \u2211 j r i F j e j \u2212 \u2211 j r j e j F i = r i (F\u22c5e)\u2212(r\u22c5e) F i . Since the dot products are scalars, the two terms on the right-hand side are vectors, and likewise their difference. So \u03c4 ij is a tensor. But \u03c4 ij is a special kind of tensor; it is antisymmetric, that is, \u03c4 ij =\u2212 \u03c4 ji , \u03c4 \u03c4 so it has only three nonzero terms\u2014 \u03c4 xy , \u03c4 yz , and \u03c4 zx . We were able to show in Chapter 20 of Volume I that these three terms, almost \u201cby accident,\u201d transform like the three components of a vector, so that we could define \u03c4=( \u03c4 x , \u03c4 y , \u03c4 z )=( \u03c4 yz , \u03c4 zx , \u03c4 xy ) ( ) ( ) We say \u201cby accident,\u201d because it happens only in three dimensions. In four dimensions, for instance, an antisymmetric tensor of the second rank has up to six nonzero terms and certainly cannot be replaced by a vector with four components. Just as the axial vector \u03c4=r\u00d7F is a tensor, so also is every cross product of two polar vectors\u2014all the same arguments apply. By luck, however, they are also representable by vectors (really pseudo vectors), so our mathematics has been made easier for us. Mathematically, if a and b are any two vectors, the nine quantities a i b j form a tensor (although it may have no useful physical purpose). Thus, for the position vector r , r i r j is a tensor, and since \u03b4 ij is also, we see that the right side of Eq. (31.20) is indeed a tensor. Likewise Eq. (31.22) is a tensor, since the two terms on the right-hand side are tensors. The symmetric tensors we have described so far arose as coefficients in relating one vector to another. We would like to look now at a tensor which has a different physical significance\u2014the tensor of stress. Suppose we have a solid object with various forces on it. We say that there are various \u201cstresses\u201d inside, by which we mean that there are internal forces between neighboring parts of the material. We have talked a little about such stresses in a two-dimensional case when we considered the surface tension in a stretched diaphragm in Section 12\u20133. We will now see that the internal forces in the material of a three-dimensional body can be described in terms of a tensor. Consider a body of some elastic material\u2014say a block of jello. If we make a cut through the block, the material on each side of the cut will, in general, get displaced by the internal forces. Before the cut was made, there must have been forces between the two parts of the block that kept the material in place; we can define the stresses in terms of these forces. Suppose we look at an imaginary plane perpendicular to the x -axis\u2014like the plane \u03c3 in Fig. 31\u20135\u2014and ask about the force across a small area \u0394y\u0394z in this plane. The material on the left of the area exerts the force \u0394 F 1 on the material to the right, as shown in part (b) of the figure. There is, of course, the opposite reaction force \u2212\u0394 F 1 exerted on the material to the left of the surface. If the area is small enough, we expect that \u0394 F 1 is proportional to the area \u0394y\u0394z . You are already familiar with one kind of stress\u2014the pressure in a static liquid. There the force is equal to the pressure times the area and is at right angles to the surface element. For solids\u2014also for viscous liquids in motion\u2014the force need not be normal to the surface; there are shear forces in addition to pressures (positive or negative). (By a \u201cshear\u201d force we mean the tangential components of the force across a surface.) All three components of the force must be taken into account. Notice also that if we make our cut on a plane with some other orientation, the forces will be different. A complete description of the internal stress requires a tensor. We define the stress tensor in the following way: First, we imagine a cut perpendicular to the x -axis and resolve the force \u0394 F 1 across the cut into its components \u0394 F x1 , \u0394 F y1 , \u0394 F z1 , as in Fig. 31\u20136. The ratio of these forces to the area \u0394y\u0394z , we call S xx , S yx , and S zx . For example, S yx = \u0394 F y1 \u0394y\u0394z . \u0394 F The first index y refers to the direction force component; the second index x is normal to the area. If you wish, you can write the area \u0394y\u0394z as \u0394 a x , meaning an element of area perpendicular to x . Then S yx = \u0394 F y1 \u0394 a x . \u0394 F Next, we think of an imaginary cut perpendicular to the y -axis. Across a small area \u0394x\u0394z there will be a force \u0394 F 2 . Again we resolve this force into three components, as shown in Fig. 31\u20137, and define the three components of the stress, S xy , S yy , S zy , as the force per unit area in the three directions. Finally, we make an imaginary cut perpendicular to z and define the three components S xz , S yz , and S zz . So we have the nine numbers S ij = \u23a1 \u23a3 \u23a2 S xx S yx S zx S xy S yy S zy S xz S yz S zz \u23a4 \u23a6 \u23a5 . (31.23) We want to show now that these nine numbers are sufficient to describe completely the internal state of stress, and that S ij is indeed a tensor. Suppose we want to know the force across a surface oriented at some arbitrary angle. Can we find it from S ij ? Yes, in the following way: We imagine a little solid figure which has one face N in the new surface, and the other faces parallel to the coordinate axes. If the face N happened to be parallel to the z -axis, we would have the triangular piece shown in Fig. 31\u20138. (This is a somewhat special case, but will illustrate well enough the general method.) Now the stress forces on the little solid triangle in Fig. 31\u20138 are in equilibrium (at least in the limit of infinitesimal dimensions), so the total force on it must be zero. We know the forces on the faces parallel to the coordinate axes directly from S ij . Their vector sum must equal the force on the face N , so we can express this force in terms of S ij . Our assumption that the surface forces on the small triangular volume are in equilibrium neglects any other body forces that might be present, such as gravity or pseudo forces if our coordinate system is not an inertial frame. Notice, however, that such body forces will be proportional to the volume of the little triangle and, therefore, to \u0394x\u0394y\u0394z , whereas all the surface forces are proportional to the areas such as \u0394x\u0394y , \u0394y\u0394z , etc. So if we take the scale of the little wedge small enough, the body forces can always be neglected in comparison with the surface forces. Let\u2019s now add up the forces on the little wedge. We take first the x -component, which is the sum of five parts\u2014one from each face. However, if \u0394z is small enough, the forces on the triangular faces (perpendicular to the z -axis) will be equal and opposite, so we can forget them. The x -component of the force on the bottom rectangle is \u0394 F x2 = S xy \u0394x\u0394z. \u0394 F S \u0394 \u0394 The x -component of the force on the vertical rectangle is \u0394 F x1 = S xx \u0394y\u0394z. \u0394 F S \u0394 \u0394 These two must be equal to the x -component of the force outward across the face N . Let\u2019s call n the unit vector normal to the face N , and the force on it F n ; then we have \u0394 F xn = S xx \u0394y\u0394z+ S xy \u0394x\u0394z. \u0394 F S \u0394 \u0394 S \u0394 \u0394 The x -component S xn of the stress across this plane is equal to \u0394 F xn divided by the area, which is \u0394z \u0394 x 2 +\u0394 y 2 \u2212 \u2212 \u2212 \u2212 \u2212 \u2212 \u2212 \u2212 \u2212 \u221a , or S xn = S xx \u0394y \u0394 x 2 +\u0394 y 2 \u2212 \u2212 \u2212 \u2212 \u2212 \u2212 \u2212 \u2212 \u2212 \u221a + S xy \u0394x \u0394 x 2 +\u0394 y 2 \u2212 \u2212 \u2212 \u2212 \u2212 \u2212 \u2212 \u2212 \u2212 \u221a . \u0394 \u0394 Now \u0394x/ \u0394 x 2 +\u0394 y 2 \u2212 \u2212 \u2212 \u2212 \u2212 \u2212 \u2212 \u2212 \u2212 \u221a is the cosine of the angle \u03b8 between n and the y -axis, as shown in Fig. 31\u20138, so it can also be written as n y , the y -component of n . Similarly, \u0394y/ \u0394 x 2 +\u0394 y 2 \u2212 \u2212 \u2212 \u2212 \u2212 \u2212 \u2212 \u2212 \u2212 \u221a is sin\u03b8= n x . We can write S xn = S xx n x + S xy n y . S S S If we now generalize to an arbitrary surface element, we would get that S xn = S xx n x + S xy n y + S xz n z S S S S or, in general, S in = \u2211 j S ij n j . (31.24) We can find the force across any surface element in terms of the S ij , so it does describe completely the state of internal stress of the material. Equation (31.24) says that the tensor S ij relates the stress S n to the unit vector n , just as \u03b1 ij relates P to E . Since n and S n are vectors, the components of S ij must transform as a tensor with changes in coordinate axes. So S ij is indeed a tensor. We can also show that S ij is a symmetric tensor by looking at the forces on a little cube of material. Suppose we take a little cube, oriented with its faces parallel to our coordinate axes, and look at it in cross section, as shown in Fig. 31\u20139. If we let the edge of the cube be one unit, the x - and y -components of the forces on the faces normal to the x - and y -axes might be as shown in the figure. If the cube is small, the stresses do not change appreciably from one side of the cube to the opposite side, so the force components are equal and opposite as shown. Now there must be no torque on the cube, or it would start spinning. The total torque about the center is ( S yx \u2212 S xy ) (times the unit edge of the cube), and since the total is zero, S yx is equal to S xy , and the stress tensor is symmetric. Since S ij is a symmetric tensor, it can be described by an ellipsoid which will have three principal axes. For surfaces normal to these axes, the stresses are particularly simple\u2014they correspond to pushes or pulls perpendicular to the surfaces. There are no shear forces along these faces. For any stress, we can always choose our axes so that the shear components are zero. If the ellipsoid is a sphere, there are only normal forces in any direction. This corresponds to a hydrostatic pressure (positive or negative). So for a hydrostatic pressure, the tensor is diagonal and all three components are equal; they are, in fact, just equal to the pressure p . We can write S ij =p \u03b4 ij . (31.25) The stress tensor\u2014and also its ellipsoid\u2014will, in general, vary from point to point in a block of material; to describe the whole block we need to give the value of each component of S ij as a function of position. So the stress tensor is a field. We have had scalar fields, like the temperature T(x,y,z) , which give one number for each point in space, and vector fields like E(x,y,z) , which give three numbers for each point. Now we have a tensor field which gives nine numbers for each point in space\u2014or really six for the symmetric tensor S ij . A complete description of the internal forces in an arbitrarily distorted solid requires six functions of x , y , and z . The stress tensor S ij describes the internal forces of matter. If the material is elastic, it is convenient to describe the internal distortion in terms of another tensor T ij \u2014called the strain tensor. For a simple object like a bar of metal, you know that the change in length, \u0394L , is approximately proportional to the force, so we say it obeys Hooke\u2019s law: \u0394L=\u03b3F. \u0394 L F For a solid elastic body with arbitrary distortions, the strain T ij is related to the stress S ij by a set of linear equations: T ij = \u2211 k,l \u03b3 ijkl S kl . (31.26) Also, you know that the potential energy of a spring (or bar) is 1 2 F\u0394L= 1 2 \u03b3 F 2 . 1 1 The generalization for the elastic energy density in a solid body is U elastic = \u2211 ijkl 1 2 \u03b3 ijkl S ij S kl . (31.27) The complete description of the elastic properties of a crystal must be given in terms of the coefficients \u03b3 ijkl . This introduces us to a new beast. It is a tensor of the fourth rank. Since each index can take on any one of three values, x , y , or z , there are 3 4 =81 coefficients. But there are really only 21 different numbers. First, since S ij is symmetric, it has only six different values, and only 36 different coefficients are needed in Eq. (31.27). But also, S ij can be interchanged with S kl without changing the energy, so \u03b3 ijkl must be symmetric if we interchange ij and kl . This reduces the number of different coefficients to 21 . So to describe the elastic properties of a crystal of the lowest possible symmetry requires 21 elastic constants! This number is, of course, reduced for crystals of higher symmetry. For example, a cubic crystal has only three elastic constants, and an isotropic substance has only two. That the latter is true can be seen as follows. How can the components of \u03b3 ijkl be independent of the direction of the axes, as they must be if the material is isotropic? Answer: They can be independent only if they are expressible in terms of the tensor \u03b4 ij . There are two possible expressions, \u03b4 ij \u03b4 kl and \u03b4 ik \u03b4 jl + \u03b4 il \u03b4 jk , which have the required symmetry, so \u03b3 ijkl must be a linear combination of them. Therefore, for isotropic materials, \u03b3 ijkl =a( \u03b4 ij \u03b4 kl )+b( \u03b4 ik \u03b4 jl + \u03b4 il \u03b4 jk ), ( \u03b4 \u03b4 ) b ( \u03b4 \u03b4 \u03b4 \u03b4 ) and the material requires two constants, a and b , to describe its elastic properties. We will leave it for you to show that a cubic crystal needs only three. As a final example, this time of a third-rank tensor, we have the piezoelectric effect. Under stress, a crystal generates an electric field proportional to the stress; hence, in general, the law is E i = \u2211 j,k P ijk S jk , \u2211 where E i is the electric field, and the P ijk are the piezoelectric coefficients\u2014or the piezoelectric tensor. Can you show that if the crystal has a center of inversion (invariant under x,y,z\u2192\u2212x,\u2212y,\u2212z ) the piezoelectric coefficients are all zero? All the tensors we have looked at so far in this chapter relate to the three dimensions of space; they are defined to have a certain transformation property under spatial rotations. In Chapter 26 we had occasion to use a tensor in the four dimensions of relativistic space-time\u2014the electromagnetic field tensor F \u03bc\u03bd . The components of such a four-tensor transform under a Lorentz transformation of the coordinates in a special way that we worked out. (Although we did not do it that way, we could have considered the Lorentz transformation as a \u201crotation\u201d in a four-dimensional \u201cspace\u201d called Minkowski space; then the analogy with what we are doing here would have been clearer.) As our last example, we want to consider another tensor in the four dimensions (t,x,y,z) of relativity theory. When we wrote the stress tensor, we defined S ij as a component of a force across a unit area. But a force is equal to the time rate of change of a momentum. Therefore, instead of saying \u201c S xy is the x -component of the force across a unit area perpendicular to y ,\u201d we could equally well say, \u201c S xy is the rate of flow of the x -component of momentum through a unit area perpendicular to y .\u201d In other words, each term of S ij also represents the flow of the i -component of momentum through a unit area perpendicular to the j -direction. These are pure space components, but they are parts of a \u201clarger\u201d tensor S \u03bc\u03bd in four dimensions ( \u03bc and \u03bd=t,x,y,z ) containing additional components like S tx , S yt , S tt , etc. We will now try to find the physical meaning of these extra components. We know that the space components represent flow of momentum. We can get a clue on how to extend this to the time dimension by studying another kind of \u201cflow\u201d\u2014the flow of electric charge. For the scalar quantity, charge, the rate of flow (per unit area perpendicular to the flow) is a space vector\u2014the current density vector j . We have seen that the time component of this flow vector is the density of the stuff that is flowing. For instance, j can be combined with a time component, j t =\u03c1 , the charge density, to make the four-vector j \u03bc =(\u03c1,j) ; that is, the \u03bc in j \u03bc takes on the values t , x , y , z to mean \u201cdensity, rate of flow in the x -direction, rate of flow in y , rate of flow in z \u201d of the scalar charge. Now by analogy with our statement about the time component of the flow of a scalar quantity, we might expect that with S xx , S xy , and S xz , describing the flow of the x -component of momentum, there should be a time component S xt which would be the density of whatever is flowing; that is, S xt should be the density of x -momentum. So we can extend our tensor horizontally to include a t -component. We have S xt S xx S xy S xz =density of x-momentum, =x-flow of x-momentum, =y-flow of x-momentum, =z-flow of x-momentum. Similarly, for the y -component of momentum we have the three components of flow\u2014 S yx , S yy , S yz \u2014to which we should add a fourth term: S yt =density of y-momentum. S density of And, of course, to S zx , S zy , S zz we would add S zt =density of z-momentum. S density of In four dimensions there is also a t -component of momentum, which is, we know, energy. So the tensor S ij should be extended vertically with S tx , S ty , and S tz , where S tx S ty S tz =x-flow of energy, =y-flow of energy, =z-flow of energy; (31.28) that is, S tx is the flow of energy per unit area and per unit time across a surface perpendicular to the x -axis, and so on. Finally, to complete our tensor we need S tt , which would be the density of energy. We have extended our stress tensor S ij of three dimensions to the four-dimensional stress-energy tensor S \u03bc\u03bd . The index \u03bc can take on the four values t , x , y , and z , meaning, respectively, \u201cdensity,\u201d \u201cflow per unit area in the x -direction,\u201d \u201cflow per unit area in the y -direction,\u201d and \u201cflow per unit area in the z -direction.\u201d In the same way, \u03bd takes on the four values t , x , y , z to tell us what flows, namely, \u201cenergy,\u201d \u201cmomentum in the x -direction,\u201d \u201cmomentum in the y -direction,\u201d and \u201cmomentum in the z -direction.\u201d As an example, we will discuss this tensor not in matter, but in a region of free space in which there is an electromagnetic field. We know that the flow of energy is the Poynting vector S= \u03f5 0 c 2 E\u00d7B . So the x -, y -, and z -components of S are, from the relativistic point of view, the components S tx , S ty , and S tz of our four-dimensional stress-energy tensor. The symmetry of the tensor S ij carries over into the time components as well, so the four-dimensional tensor S \u03bc\u03bd is symmetric: S \u03bc\u03bd = S \u03bd\u03bc . (31.29) In other words, the components S xt , S yt , S zt , which are the densities of x , y , and z momentum, are also equal to the x -, y -, and z -components of the Poynting vector S , the energy flow\u2014as we have already shown in an earlier chapter by a different kind of argument. The remaining components of the electromagnetic stress tensor S \u03bc\u03bd can also be expressed in terms of the electric and magnetic fields E and B . That is to say, we must admit stress or, to put it less mysteriously, flow of momentum in the electromagnetic field. We discussed this in Chapter 27 in connection with Eq. (27.21), but did not work out the details. Those who want to exercise their prowess in tensors in four dimensions might like to see the formula for S \u03bc\u03bd in terms of the fields: S \u03bc\u03bd =\u2212 \u03f5 0 ( \u2211 \u03b1 F \u03bc\u03b1 F \u03bd\u03b1 \u2212 1 4 \u03b4 \u03bc\u03bd \u2211 \u03b1,\u03b2 F \u03b2\u03b1 F \u03b2\u03b1 ), 1 where sums on \u03b1 , \u03b2 are on t , x , y , z but (as usual in relativity) we adopt a special meaning for the sum sign \u2211 and for the symbol \u03b4 . In the sums the x , y , z terms are to be subtracted and \u03b4 tt =+1 , while \u03b4 xx = \u03b4 yy = \u03b4 zz = \u22121 and \u03b4 \u03bc\u03bd =0 for \u03bc\u2260\u03bd ( c=1 ). Can you verify that it gives the energy density S tt =( \u03f5 0 /2)( E 2 + B 2 ) and the Poynting vector \u03f5 0 E\u00d7B ? Can you show that in an electrostatic field with B=0 the principal axes of stress are in the direction of the electric field, that there is a tension ( \u03f5 0 /2) E 2 along the direction of the field, and that there is an equal pressure in directions perpendicular to the field direction?"
    },
    {
        "input": "Dynamical Effects and Their Applications",
        "output": "I just want to announce that the lecture I give today is unlike the others, in that I\u2019ll talk about a large number of subjects which are only for your own entertainment and interest, and if you don\u2019t understand something because it\u2019s too complicated, you can just forget about it; it\u2019s absolutely unimportant. Every subject that we study could, of course, be studied in greater and greater detail\u2014certainly in greater detail than would be warranted for a first approach\u2014and we could continue to pursue the problems of rotational dynamics almost forever, but then we wouldn\u2019t have time to learn much else about physics. So we\u2019re going to take leave of the subject here. Now, someday you may want to return to rotational dynamics, each in your own way, whether as a mechanical engineer, or an astronomer worrying about the spinning stars, or in quantum mechanics (you have rotation in quantum mechanics)\u2014however it comes back to you again, that\u2019s up to you. But this is the first time that we will leave a subject unfinished; we have a lot of broken ideas, or threads of ideas, that go out and aren\u2019t continued, and I\u2019d like to tell you where they go, so that you get some better appreciation of what you know. In particular, most of the lectures up until now have been, to a large extent, theoretical\u2014full of equations, and so on\u2014and many of you with an interest in practical engineering may be longing to see a few instances of the \u201ccleverness of man\u201d in making use of some of these effects. If that\u2019s so, our subject today is ideally suited to delight you, because there\u2019s nothing more exquisite in mechanical engineering than the practical development of inertial guidance over the last few years. This was dramatically illustrated by the voyage of the submarine Nautilus under the polar ice cap: no stars could be observed; maps of the bottom of the sea, under the ice cap, were practically non-existent; inside the ship there was no way to see where you were\u2014and nevertheless they knew at any moment exactly where they were.1 The trip would have been impossible without the development of inertial guidance, and I would like to explain to you today how it works. But before I get to that, it will be better if I explain a few of the older, less sensitive devices in order for you to more fully appreciate the principles and problems involved in the more delicate and marvelous developments that came later. In case you haven\u2019t seen one of these things, Figure 4-1 shows a demonstration gyroscope, set in gimbals. Once the wheel is set spinning it stays in the same orientation even if the base is picked up and moved around in an arbitrary direction\u2014the gyroscope remains with its spin axis, AB, fixed in space. For practical applications, where the gyro must be kept spinning, a small motor is used to compensate for friction in the gyro\u2019s pivots. If you try to change the direction of axis AB by pushing downward on point A (creating a torque on the gyro around axis XY), point A does not move downward but actually moves sideways, towards Y in Figure 4-1. Applying a torque to the gyro around any axis (other than the spin axis) produces a rotation of the gyro around an axis that is mutually perpendicular to the applied torque and the gyro\u2019s spin axis. I start with the simplest possible application of a gyroscope: if it\u2019s in an airplane which is turning from one direction to another, the gyro\u2019s axis of rotation\u2014set horizontally, for example\u2014stays pointed in the same direction. This is very useful: as the airplane goes through various motions, you can maintain a direction\u2014it\u2019s called a directional gyro. (See Fig. 4-2.) You say, \u201cThat is like a compass.\u201d It is not like a compass, because it doesn\u2019t seek north. It\u2019s used like this: when the airplane is on the ground, you calibrate the magnetic compass and use it to set the gyro\u2019s axis in some direction, say north. Then as you fly around, the gyro maintains its orientation, and so you can always use it to find north. \u201cWhy not just use the magnetic compass?\u201d It\u2019s very difficult to use a magnetic compass in an airplane because the needle swings and dips from the motion, and there\u2019s iron and other sources of magnetic fields in the airplane. On the other hand, when the airplane quiets down and goes in a straight line for a while, you\u2019ll find that the gyro doesn\u2019t point north anymore, because of friction in the gimbals. The airplane has been turning, slowly, and there has been friction, small torques have been generated, the gyro has had precessional motions, and it is no longer pointing in exactly the same direction. So, from time to time it\u2019s necessary for the pilot to reset his directional gyro against the compass\u2014every hour, or perhaps more, depending on how perfectly frictionless the thing is made. The same system works with the artificial horizon, a device to determine \u201cup.\u201d When you\u2019re on the ground, you set a gyro with its axis vertical. Then you go up in the air, and the airplane pitches and rolls; the gyro maintains its vertical orientation, but it also needs to be reset every once in a while. What can we check the artificial horizon against? We could use gravity to find out which way is up, but as you can well appreciate, when you\u2019re going in a curve, the apparent gravity is off at an angle, and it\u2019s not so easy to check. But in the long run, on average, the gravity is in a certain direction\u2014unless the airplane ultimately ends up flying upside down! (See Fig. 4-3.) And so, consider what would happen if we added a weight to the gimbals at point A of the gyro shown in Figure 4-1, then set the gyro spinning with its axis vertical, and A down. When the plane flies straight and level, the weight pulls straight down which tends to keep the spin axis vertical. As the airplane goes around a corner, the weight tries to pull the axis off vertical, but the gyroscope resists through the precession and the axis drifts away from vertical only very slowly. Eventually the airplane stops its maneuver, and the weight pulls straight down again. In the long run, on average, the weight tends to orient the axis of the gyro in the direction of gravity. This is much like the comparison of the directional gyro to the magnetic compass, except instead of being done every hour or so, it\u2019s done perpetually, all during the flight, so that in spite of the gyro\u2019s tendency to drift very slowly, its orientation is maintained by the average effect of gravity over long periods of time. The slower the gyro drifts, naturally, the longer the period of time over which this average is effectively taken, and the better the instrument is for more complex maneuvers. It\u2019s not unusual to make maneuvers in an airplane that throw gravity off for half a minute, so if the averaging period were only half a minute, the artificial horizon wouldn\u2019t work right. The devices I have just described\u2014the artificial horizon and the directional gyro\u2014are the machinery used to guide automatic pilots in airplanes. That is, information taken from these devices is used to steer the airplane in a certain direction. If, for example, the airplane turns away from the axis of the directional gyro, electrical contacts are made which, working their way through a lot of things, result in some flaps being moved, steering the airplane back on course. Automatic pilots have at their heart such gyroscopes. Another interesting application of gyroscopes that is no longer used today, but was once proposed and built, is to stabilize ships. Of course everybody thinks you do this just by spinning a big wheel on an axle affixed to the ship, but that\u2019s not right. If you were to do that with the spin axis vertical, for example, and a force pitched the front of the ship up, the net result would be to make the gyro precess to one side, and the ship would flip over\u2014so that doesn\u2019t work! A gyroscope doesn\u2019t stabilize anything by itself. What\u2019s done instead illustrates a principle used in inertial guidance. The trick is this: somewhere in the ship there is a very small, but beautifully built, master gyroscope, with its axis, say, vertical. The moment the ship rolls a little bit out of vertical, electrical contacts in the master gyro operate a tremendous slave gyro that is used to stabilize the ship\u2014these were probably the biggest gyroscopes ever built! (See Fig. 4-4.) Ordinarily the slave gyro\u2019s axis is kept vertical, but it is gimbaled so it can be swiveled around the pitch axis of the ship. If the ship starts to roll right or left, then to straighten it out, the slave gyro is wrenched back or forward\u2014you know how gyros are always obstinate and go the wrong way. The sudden rotation around the pitch axis produces a torque about the roll axis that opposes the roll of the ship. The pitching of the ship is not corrected by this gyro, but of course the pitching of a big ship is relatively small. I\u2019d like now to describe another device used on ships, the \u201cgyrocompass.\u201d Unlike the directional gyro, which always drifts away from north and must be reset periodically, a gyrocompass actually seeks north\u2014in fact, it\u2019s better than the magnetic compass because it seeks true north, in the sense of the axis of the earth\u2019s rotation. It works as follows: suppose that we look at the earth from above the North Pole, going around counterclockwise, and we have set up a gyroscope somewhere, say on the equator, with its axis pointing east-west, parallel to the equator, as shown in Figure 4-5(a). For the moment let\u2019s just take the example of an ideal free gyroscope, with lots of gimbals and whatnot. (It could be in a ball floating in oil\u2014however you want it so that there is no friction.) Six hours later, the gyroscope would be still pointing in the same absolute direction (because there are no torques on it from friction), but if we were standing next to it on the equator, we would see it slowly turning over: six hours later it would be pointing straight up, as shown in Figure 4-5(c). But now imagine what would happen if we put a weight on the gyroscope as shown in Figure 4-6; the weight would tend to keep the spin axis of the gyroscope perpendicular to gravity. As the earth rotates, the weight will be lifted, and the weight lifting up, of course, will want to come back down, and that will produce a torque parallel to the earth\u2019s rotation which will make the gyroscope turn at right angles to everything; in this particular case, if you figure it out, it means that instead of lifting the weight up, the gyro will turn over. And so it turns its axis around toward the north, as shown in Figure 4-7. Now, suppose the gyro\u2019s axis is finally pointing north: will it stay there? If we draw the same picture with the axis pointing north, as shown in Figure 4-8, then as the earth rotates, the arm swings around the gyro\u2019s axis and the weight stays down; there are no torques on the axis from the weight being lifted, and the axis is still pointing north later. So, if the gyrocompass has its axis pointing north, there\u2019s no reason why it can\u2019t stay that way, but if its axis is pointing even slightly east-west, then as the earth rotates, the weight will turn the axis toward the north. This, therefore, is a north-seeking device. (Actually, if I built it just this way, it would seek north and pass, coast on the other side, and go back and forth\u2014so a little bit of damping has to be introduced.) We have made an artificial gyrocompass kind of a gadget, which is shown in Figure 4-9. The gyroscope unfortunately hasn\u2019t got all the axes free; it\u2019s got two of them free, and you have to do a little thinking to figure out that that\u2019s almost the same. You turn the thing around to simulate the motion of the earth, and gravity is imitated by a rubber band tied to the gyro, analogous to the weight on the end of the arm. When you start turning the thing around, the gyro precesses for a while, but if you\u2019re patient enough, and keep the thing going, it settles down. The only place where it can stay without trying to turn in some other direction is parallel to the axis of rotation of its frame\u2014the imaginary earth in this case\u2014and so it settles down, very nicely, pointing toward the north. When I stop the rotation, the axis drifts, because there are various frictions and forces in the bearings. Real gyros always drift; they don\u2019t do the ideal thing. The best gyros that could be made about ten years ago had a drift of between 2 and 3 degrees in an hour\u2014that was the limitation of inertial guidance: it was impossible to determine your direction in space more accurately than that. For instance, if you went on a trip in a submarine for 10 hours, the axis of your directional gyro could be off by as much as 30 degrees! (The gyrocompass and the artificial horizon would work all right, because they are \u201cchecked\u201d by gravity, but the free-rotating directional gyros wouldn\u2019t be accurate.) The development of inertial guidance required the development of much better gyroscopes\u2014gyroscopes in which the uncontrollable frictional forces that tend to make them precess are at an absolute minimum. A number of inventions have been made to make this possible, and I\u2019d like to illustrate the general principles involved. In the first place, the gyros we\u2019ve been talking about so far are \u201ctwo-degrees-of-freedom\u201d gyroscopes, because there are two ways that the spin axis can turn. It turns out to be better if you only need to worry about one way at a time\u2014that is, it is better to set up your gyros so that you only need to consider the rotations of each one about a single axis. A \u201cone-degree-of-freedom\u201d gyroscope is illustrated in Figure 4-10. (I have to thank Mr. Skull of the Jet Propulsion Laboratory for not only lending me these slides, but also explaining to me everything that\u2019s been going on the last few years.) The gyro wheel is spinning around a horizontal axis (\u201cSpin axis\u201d in the figure), which is only allowed to turn freely around one axis (IA), not two. Nevertheless, this is a useful device for the following reason: imagine that the gyro is being turned around the vertical input axis (IA), because it\u2019s in a car or a ship which is turning. Then the gyro wheel will try to precess around the horizontal output axis (OA); more accurately, a torque will be developed about the output axis, and if the torque is not opposed, the gyro wheel will precess about that axis. So, if we have a signal generator (SG) which can detect the angle through which the wheel precesses, then we can use it to discover that the ship is turning. Now, there are several features to be taken into account here: the delicate part is that the torque around the output axis must represent the result of rotation around the input axis with absolute accuracy. Any other torques about the output axis are noise, and we have to get rid of them to avoid confusion. And the difficulty is that the gyro wheel itself has some weight, which has to be supported against the weight of the pivots on the output axis\u2014and those are the real problem, because they produce a friction which is uncertain and indefinite. So the first and main trick that improved the gyroscope was to put the gyro wheel in a can and float the can in oil. The can is a cylinder completely surrounded by oil, and free to turn about its axis (\u201cOutput axis\u201d in Figure 4-11). The weight of the can, with the wheel and air in it, is exactly the same as the oil it displaces (or as near as it can be made) so that the can is neutrally balanced. That way there\u2019s very little weight to support at the pivots, so very fine jewel bearings can be used, like the ones inside a watch, consisting of a pin and a jewel. Jewel bearings can take very little sideways force, but they don\u2019t have to take much sideways force in this case\u2014and they have very little friction. So that was the first great improvement: to float the gyro wheel, and use jewel bearings at the pivots that support it. The next important improvement was to never actually use the gyroscope to create any forces\u2014or very great forces. The way we\u2019ve been talking about this thing so far, the gyro wheel precesses about the output axis and we measure how far it precesses. But another interesting technique for measuring the effect of rotation about the input axis is based on the following idea (see Figures 4-10 and 4-11): suppose we have a device carefully built, so that by giving it a definite amount of electric current we can, very accurately, generate a certain torque on the output axis\u2014an electromagnetic torque generator. Then we can make a feedback device with tremendous amplification between the signal generator and the torque generator, so that when the ship turns around the input axis, the gyro wheel starts to precess around the output axis, but as soon as it moves a shade, a hair\u2014just a hair\u2014the signal generator says, \u201cHey! It\u2019s moving!\u201d and the torque generator immediately puts a torque on the output axis that counteracts the torque making the gyro wheel precess, and holds it in place. And then we ask the question, \u201cHow hard do we have to hold it?\u201d In other words, we measure the amount of juice going into the torque generator. Essentially, we measure the torque making the gyro wheel precess, by measuring how much torque is needed to counterbalance it. This feedback principle is very important in the design and development of gyroscopes. Now, another interesting method of feeding back, which is in fact used even more often, is illustrated in Figure 4-12. The gyro is the little can (\u201cGyro\u201d in Figure 4-12) on the horizontal platform (Platform) in the center of the supporting framework. (You can ignore the accelerometer (Accel) for the moment; we\u2019ll just worry about the gyro.) Unlike the previous example, this gyro\u2019s spin axis (SRA) is vertical; however, the output axis (OA) is still horizontal. If we imagine that the framework is mounted in an airplane traveling in the indicated direction (\u201cForward motion\u201d in Figure 4-12), then the input axis is the airplane\u2019s pitch axis. When the airplane pitches up or down, the gyro wheel starts to precess around the output axis and the signal generator makes a signal, but instead of balancing it by a torque, this feedback system works as follows: as soon as the airplane starts to turn around the pitch axis, the framework which supports the gyroscope in relation to the airplane is turned the opposite way, so as to undo the motion; we turn it back, so that we get no signal. In other words, we keep the platform stable via feedback, and we never really move the gyroscope! That\u2019s a heck of a lot better than having it swinging and turning, and trying to figure out the airplane\u2019s pitch by measuring the output of the signal generator! It\u2019s much easier to feed the signal back like this, so that the platform doesn\u2019t turn at all, and the gyroscope maintains its axis\u2014then we can just see the pitch angle, by comparing the platform to the floor of the airplane. Figure 4-13 is a cutaway drawing that shows how an actual \u201cone-degree-of-freedom\u201d gyroscope is built. The gyro wheel looks very big in this picture, but the entire apparatus fits in the palm of my hand. The gyro wheel is inside of a can, which is floating in a very small amount of oil\u2014it\u2019s all in a little crevice around the can\u2014but it\u2019s enough so that no weight needs to be supported by the minuscule jewel bearings at each end. The gyro wheel is spinning all the time. The bearings it spins on need not be frictionless, because they are opposed\u2014the friction is opposed by the engine, which turns a little motor, which turns the gyro wheel around. There are electromagnetic coils (\u201cSignal-torquer dualsyn\u201d in Figure 4-13) which detect the very slight motions of the can, and those provide the feedback signals which are used either to produce a torque on the can around the output axis, or to turn the platform that the gyro\u2019s standing on around the input axis. There is a technical problem here of some difficulty: to power the motor that makes the gyro wheel go around, we have to get electricity from a fixed part of the apparatus into the turning can. That means wires have to come in contact with the can, yet the contacts must be practically frictionless, which is very difficult. The way it\u2019s done is as follows: four carefully made springs in semicircular form are connected to conductors on the can, as shown in Figure 4-14; the springs are made of very good material, like watch spring material, only very fine. They are balanced so that when the can is exactly in the zero position they make no torque; if the can is even slightly rotated, they make a little torque\u2014however, because the springs are so perfectly made, that torque is exactly known\u2014we know the right equations for it\u2014and it\u2019s corrected for in the electrical circuits of the feedback devices. There\u2019s also plenty of friction on the can from the oil, which creates torque around the output axis when the can rotates. But the law of friction for liquid oil is very accurately known: the torque is exactly proportional to the speed of the can\u2019s rotation. And so it can be completely corrected for in the calculational parts of the circuit that make the feedback, same as the springs. The big principle of all the accurate devices of this kind is not so much to make everything perfect, but to make everything very definite and precise. This device is like the wonderful \u201cone-horse shay\u201d:2 everything is made at the absolute limit of mechanical possibilities at the present time, and they\u2019re still trying to make it better. But the most serious problem is this: what happens if the gyro wheel\u2019s axle is a little off-center in the can, as shown in Figure 4-15? Then the can\u2019s center of gravity won\u2019t coincide with the output axis, and the weight of the wheel will turn the can around, creating plenty of unwanted torque. To fix that, the first thing you do is drill little holes, or put weights on the can, to make it as balanced as possible. Then you measure very carefully what remaining drift there is, and use that measurement for calibration. When you\u2019ve measured a particular device you\u2019ve built, and find that you can\u2019t reduce the drift to zero, you can always correct that in the feedback circuit. The problem in this case, though, is that the drift is indefinite: after the gyro runs for two or three hours, the position of the center of gravity moves slightly because of wear in the axle\u2019s bearings. Nowadays, gyroscopes of this kind are over a hundred times better than the ones made 10 years ago. The very best ones have a drift of not more than of a 1/100th degree per hour. For the device shown in Figure 4-13, that means the gyro wheel\u2019s center of gravity cannot move more than 1/10th of one-millionth of an inch from the center of the can! Good mechanical practice is something like 100 millionths of an inch, so this has to be a thousand times better than good mechanical practice. Indeed, this is one of the most serious problems\u2014to keep the axle bearings from wearing, so that the gyro wheel moves no more than 20 atoms to either side of the center. The devices we\u2019ve been talking about can be used to tell which way is up, or to keep something from turning around an axis. If we have three such devices set on three axes, with all kinds of gimbals, and so on, then we can keep something absolutely stationary. While the airplane goes around, the platform inside stays horizontal, it never turns to the right or the left; it doesn\u2019t do anything. That way we can maintain our north, or east, or up and down, or any other direction. But the next problem is to find out where we are: how far have we gone? Now, you know you can\u2019t make a measurement inside an airplane to find out how fast it\u2019s going, so you certainly can\u2019t measure how far it\u2019s gone, but you can measure how much it\u2019s accelerating. So, if we initially measure no acceleration, we say, \u201cWell, we have zero position and no acceleration.\u201d When we start going we have to accelerate. When we accelerate we can measure that. And then, if we integrate the acceleration with a calculating machine, we can calculate the speed of the airplane, and, integrating again, we can find its position. Therefore, the method of determining how far something has gone is to measure the acceleration and integrate it twice. How do you measure the acceleration? An obvious device for measuring acceleration is shown schematically in Figure 4-16. The most important component is just a weight (\u201cSeismic mass\u201d in the figure). There\u2019s also a kind of weak spring (Elastic restraint) to hold the weight more or less in place, and a damper to keep it from oscillating, but these details are unimportant. Now, suppose this whole device is accelerated forward, in the direction indicated by the arrow (Sensitive axis). Then, of course, the weight starts to move back, and we use the scale (Scale of indicated accelerations) to measure how far back it moves; from this we can find the acceleration, and by integrating it twice we get the distance. Naturally, if we make a little error in measuring the position of the weight, so that the acceleration we find is slightly off at some point, then after a long time, over which we integrate twice, the distance is going to be way off. So, we have to make the device better. The next stage of improvement, shown schematically in Figure 4-17, uses our familiar feedback principle: when this device accelerates, the mass moves, and the motion causes a signal generator to output a voltage proportional to the displacement. Then, instead of just measuring the voltage, the trick is to feed it back through an amplifier to a device that pulls the weight back, to find out how much force is needed to keep the weight from moving. In other words, rather than letting the weight move and measuring how far it goes, we measure the reaction force needed to balance it, and then, by F=ma , we find the acceleration. One embodiment of this device is shown schematically in Figure 4-18. Figure 4-19 is a cutaway drawing that shows how the actual device is built. It\u2019s much like the gyro in Figures 4-11 and 4-13, except the can looks empty: instead of a gyroscope, there\u2019s just a weight attached to one side, near the bottom. The whole can is floating so that it is entirely supported and balanced by liquid oil (it\u2019s on perfectly beautiful, fine, jewel pivots), and, of course, the weighted side of the can stays down, due to gravity. This device is used to measure horizontal acceleration in the direction perpendicular to the axis of the can; as soon as it accelerates in that direction, the weight lags behind and slops up the side of the can, which turns on its pivots; the signal generator immediately makes a signal, and that signal is put on the torque generator\u2019s coils to pull the can back to its original position. Just as before, we feed torque back to straighten things out, and we measure how much is needed to keep the thing from shaking, and that torque tells us how much we\u2019re accelerating. Another interesting device for measuring acceleration, which, in fact, automatically does one of the integrations, is shown schematically in Figure 4-20. The scheme is the same as the device shown in Figure 4-11, except that there\u2019s a weight (\u201cPendulous mass\u201d in Figure 4-20) on one side of the spin axis. If this device is accelerated upward, a torque is generated on the gyroscope, and then it\u2019s the same as our other device\u2014only the torque is caused by an acceleration, instead of by turning the can. The signal generator, the torque generator, and all the rest of the stuff are the same. The feedback is used to twist the can back around the output axis. In order to balance the can, the upward force on the weight must be proportional to the acceleration, but the upward force on the weight is proportional to the angular velocity at which the can is twisted, so the can\u2019s angular velocity is proportional to the acceleration. This implies that the can\u2019s angle is proportional to velocity. Measuring how far the can has turned gives you the velocity\u2014and so one integration is already done. (That doesn\u2019t mean this accelerometer is better than the other one; what works best in a particular application depends on a whole lot of technical details, and that\u2019s a problem of design.) Now, if we build some devices like these, we can put them together on a platform as shown in Figure 4-21, which represents a complete navigational system. The three little cylinders (Gx, Gy, Gz) are gyroscopes with axes set in three mutually perpendicular directions, and the three rectangular boxes (Ax, Ay, Az) are accelerometers, one for each axis. These gyroscopes, with their feedback systems, maintain the platform in absolute space without turning in any direction\u2014neither yaw, nor pitch, nor roll\u2014while the airplane (or ship, or whatever it\u2019s in) goes around, so that the plane of the platform is very accurately fixed. This is very important for the accelerating-measuring gadgets because you\u2019ve got to know precisely which directions they\u2019re measuring in: if they\u2019ve gotten cockeyed, so the navigational system thinks they\u2019re turned one way when they\u2019re actually turned some other way, then the system will go haywire. The trick is to keep the accelerometers in a fixed orientation in space so it\u2019s easy to make the displacement calculations. The outputs of the x , y , and z accelerometers go into integrating circuits, which make the displacement calculations by integrating twice in each direction. So, assuming that we started at rest from a known position, we can know at any moment where we are. And we also know in what direction we\u2019re headed, because the platform is still in the same direction it was set when we started (ideally). That\u2019s the general idea. However, there are a few points I\u2019d like to make. First, when measuring acceleration, consider what happens if the device makes an error of, say, one part in a million. Suppose it\u2019s in a rocket, and it needs to measure accelerations up to 10 g. It would be hard to resolve less than with a device that can measure up to 10 \u22125 g (in fact, I doubt you could). But it turns out that a error in acceleration, after you integrate it twice for an hour, means an error in position of over half a kilometer\u2014after 10 hours, it\u2019s more like 50 kilometers, which is way off. So this system won\u2019t just keep on working. In rockets it doesn\u2019t matter because all the acceleration happens at the very beginning and afterwards they coast free. However, in an airplane or a boat you need to reset the system from time to time, just like an ordinary directional gyro, to make sure it is still pointed the same way. This can be done by looking at a star or the sun, but how do you check it inside a submarine? Well, if we have a map of the ocean, we can see if we went over a mountain top or something that was supposed to pass underneath us. But suppose we don\u2019t have a map\u2014there\u2019s still a way to check! Here\u2019s the idea: the earth is round, and, if we have determined that we\u2019ve gone, say, 100 miles in some direction, then the gravitational force should no longer be in the same direction as it was before. If we don\u2019t keep the platform perpendicular to gravity, the output of the acceleration-measuring devices will be all wrong. Therefore we do the following: we start with the platform horizontal, and use the accelerating-measuring devices to calculate our position; according to the position we figure out how we should turn the platform so that it remains horizontal, and we turn it at a rate predicted to keep it horizontal. That\u2019s a very handy thing\u2014but it\u2019s also the device which saves the day! Consider what would happen if there was an error. Suppose the machine was just standing in a room, not moving, and after some time, because it was built imperfectly, the platform was not horizontal, but rotated slightly, as shown on Figure 4-22(a). Then the weights in the accelerometers would be displaced, corresponding to an acceleration, and the positions calculated by the machinery would indicate motion to the right, towards (b). The mechanism which tries to keep the platform horizontal would rotate it slowly, and eventually, when the platform was level again, the machine would no longer think it\u2019s accelerating. However, because of the apparent acceleration, the machine would still think it had a velocity in the same direction, and so the mechanism which tries to keep the platform horizontal would continue to rotate it, very slowly, until it was no longer horizontal, as shown in Figure 4-22(c). In fact, it would go through the zero of acceleration, and then it would think it was accelerating in the opposite direction. So we\u2019d have an oscillatory motion which is very small, and the errors would only accumulate over one of these oscillations. If you figure out all the angles and turnings and whatnot, it takes 84 minutes for one of these oscillations. Thus, it is only necessary to make the device good enough to give the right accuracy within a period of 84 minutes, because it will correct itself in that time. It is much like what is done in an airplane where the gyrocompass is checked against a magnetic compass from time to time, but in this case the machine is checked against gravity as in the case of the artificial horizon. In roughly the same manner, the azimuth device on a submarine (which tells you which way is north) is set from time to time against a gyrocompass, which is averaging over long periods, so that the motions of the ship don\u2019t make any difference. Thus, you can correct the azimuth against the gyrocompass, and you can correct the accelerometers against gravity, and so the errors do not accumulate forever, but only for about an hour and a half. In the Nautilus submarine there were three monstrous platforms of this type, each in a great big ball, hung right next to each other from the ceiling of the navigator\u2019s room, all completely independent, in case any of them broke down\u2014or, if they didn\u2019t agree with each other, the navigator would take the best two out of three (which must have made him pretty nervous!). These platforms were all different when they were built, because you can\u2019t make anything perfect. The drift caused by slight inaccuracies had to be measured in each device, and the devices had to be calibrated to compensate for it. There\u2019s a laboratory at JPL where some of these new devices are tested. It\u2019s an interesting laboratory, if you consider how you would check such a device: you don\u2019t want to get in a ship and move around; no, in this laboratory they check the device against the rotation of the earth! If the device is sensitive, it will turn because of the rotation of the earth, and it will drift. By measuring the drift, corrections can be determined within a very short time. This laboratory is probably the only one in the world whose fundamental feature\u2014the thing that makes it go\u2014is the fact that the earth is turning. It wouldn\u2019t be useful for calibration if the earth didn\u2019t turn! The next thing I want to talk about is effects of the rotation of the earth (besides the effects on the calibration of inertial guidance devices). One of the most obvious effects of the rotation of the earth is on the large-scale motion of the winds. There\u2019s a famous tale, which you hear again and again, that if you have a bathtub, and you pull out the plug, the water goes around one way if you\u2019re in the Northern Hemisphere, and the other way if you\u2019re in the Southern Hemisphere\u2014but if you try it, it doesn\u2019t work. The reason it\u2019s supposed to go around one way is something like this: suppose we have a plug in a drain at the bottom of the ocean, under the North Pole. Then we pull the plug out, and the water starts moving down the drain. (See Fig. 4-23.) The ocean has a large radius, and the water is slowly turning around the drain because of the earth\u2019s rotation. As the water comes in toward the drain it goes from a larger radius to a smaller radius, and so it has to go around faster to maintain its angular momentum (like when the spinning ice skater pulls her arms in). The water goes around the same way the earth is turning, but it has to turn faster, so somebody standing on the earth would see the water swirling around the drain. That\u2019s right, and that\u2019s the way it should work. And that\u2019s the way it does work with the winds: if there\u2019s a place where there\u2019s low pressure, and the surrounding air is trying to move into it, then instead of moving straight in, it gets some sideways motion\u2014in fact, ultimately, the sideways motion becomes so great, that instead of moving in at all, the air is practically rotating around the low pressure area. So this is one of the laws of weather: if you face downwind in the Northern Hemisphere, low pressure is always on the left, high pressure on the right (see Figure 4-24), and the reason has to do with the rotation of the earth. (This is nearly always true; from time to time, under certain crazy circumstances, it doesn\u2019t work, because there are other forces involved besides the rotation of the earth.) The reason it doesn\u2019t work in your bathtub is as follows: what causes this phenomenon is the initial rotation of the water\u2014and the water in your bathtub is rotating. But how fast is the earth\u2019s rotation? Once around a day. Can you guarantee that the water in your bathtub hasn\u2019t got a little bit of motion equivalent to one swash around the bathtub in a day? No. Ordinarily, there\u2019s a lot of swishing and swashing in the tub! So this only works on a big enough scale, like a great big lake, where the water\u2019s pretty quiet, and you can easily demonstrate that the circulation is not so great as to correspond to once around the lake in a day. Then, if you make a hole in the bottom of the lake and let the water run out, it\u2019ll turn in the correct direction, as advertised. There are a few other points about the rotation of the earth which are interesting. One of them is that the earth is not exactly a sphere; it\u2019s a little bit off as a result of its spinning\u2014the centrifugal forces, balancing against gravity, make it oblate. And you can calculate how oblate, if you know how much the earth gives. If you assume it\u2019s like a perfect fluid that oozes into its ultimate position and ask what the oblateness should be, you\u2019ll find that it agrees with the actual oblateness of the earth within the accuracy of the calculations and the measurements (an accuracy of about 1 percent). This is not true of the moon. The moon is more lopsided than it ought to be, for the speed at which it\u2019s turning. In other words, either the moon was turning faster when it was liquefied, and it froze strong enough to resist the tendency to get into the right shape, or else it was never molten, but was formed by throwing together a bunch of meteors\u2014and the god who did it didn\u2019t do it in a perfectly precise and balanced manner, so it\u2019s a little lopsided. I also want to talk about the fact that the oblate earth is spinning around an axis which is not perpendicular to the plane of the earth\u2019s rotation around the sun (or the moon\u2019s rotation around the earth, which is almost the same plane). If the earth were a sphere, the gravitational and centrifugal forces on it would be balanced with respect to its center, but because it\u2019s a little lopsided, the force is not balanced; there\u2019s a torque due to gravitation which tends to turn the earth\u2019s axis perpendicular to the line of force, and so, like a great gyroscope, the earth precesses in space. (See Fig. 4-25.) The axis of the earth, which today points to the North Star, is actually drifting slowly around, and in time it will point to all the stars in the heavens on a big cone subtending an angle of 23 1 2 degrees. It takes 26,000 years for it to come back to the pole star, so if you are reincarnated 26,000 years from now, you may have nothing new to learn, but if it\u2019s any other time, you\u2019ll have to learn another position (and maybe another name) for the \u201cpole\u201d star. In the last lecture (see FLP Vol. I, Ch. 20, \u201cRotation in Space\u201d) we discussed the interesting fact that the angular momentum of a rigid body is not necessarily in the same direction as its angular velocity. We took as an example a disk that is fastened onto a rotating shaft in a lopsided fashion, as shown in Figure 4-26. I\u2019d like to explore this example in further detail. First, let me remind you of an interesting thing that we\u2019ve already talked about: that for any rigid body, there is an axis through the body\u2019s center of mass about which the moment of inertia is maximal, there is another axis through the body\u2019s center of mass about which the moment of inertia is minimal, and these are always at right angles. It\u2019s easy enough to see this for a rectangular block as shown in Figure 4-27, but surprisingly it\u2019s true for any rigid body. These two axes, and the axis which is perpendicular to them both, are called the principal axes of the body. The principal axes of a body have the following special property: the component of the body\u2019s angular momentum in the direction of a principal axis is equal to the component of its angular velocity in that direction times the body\u2019s moment of inertia about that axis. So, if i , j , and k are unit vectors along the principal axes of a body, with respective principal moments of inertia A , B , and C , then when the body rotates about its center of mass with angular velocity \u03c9=( \u03c9 i , \u03c9 j , \u03c9 k ) , its angular momentum is L=A \u03c9 i i+B \u03c9 j j+C \u03c9 k k. (4.1) For a thin disk of mass m and radius r , the principal axes are as follows: the main axis is perpendicular to the disk, with maximal moment of inertia A= 1 2 m r 2 ; any axis perpendicular to the main axis has the minimum moment of inertia B=C= 1 4 m r 2 The principal moments of inertia are not equal; in fact, A=2B=2C . So, when the shaft in Figure 4-26 is rotated, the disk\u2019s angular momentum is not parallel to its angular velocity. The disk is statically balanced because it is attached to the shaft at its center of mass. But it is not dynamically balanced. When we turn the shaft, we have to turn the disk\u2019s angular momentum, so we must exert a torque. Figure 4-28 shows the disk\u2019s angular velocity \u03c9 and its angular momentum L , and their components along the principal axes of the disk. But now, consider this interesting, additional thing: suppose we put a bearing on the disk, so that we can also spin the disk around its main axis with angular velocity \u03a9 as shown in Figure 4-29. Then while the shaft is turning, the disk would have an actual angular momentum which is the result of the shaft turning and the disk spinning. If we spin the disk in the direction opposite to the way the shaft is turning it, as shown in the figure, we will reduce the component of the disk\u2019s angular velocity along its main axis. In fact, since the ratio of the disk\u2019s principal moments of inertia is exactly 2:1 , Eq. (4.1) tells us that by spinning the disk backwards at exactly half the speed the shaft turns it around (such that \u03a9=\u2212( \u03c9 i /2)i , we can put this thing together in such a miraculous manner that the total angular momentum is exactly along the shaft\u2014and then we can take the shaft away, because there are no forces! (See Fig. 4-30.) And that is the way a free body turns: if you throw an object into space alone, like a plate3 or a coin, you see it doesn\u2019t just turn around one axis. What it does is a combination of spinning around its main axis, and spinning around some other cockeyed axis in such a nice balance, that the net result is that the angular momentum is constant. That makes it wobble\u2014and the earth wobbles, too. From the period of the earth\u2019s precession\u2014 26,000 years\u2014it\u2019s been shown that the maximum moment of inertia (around the pole) and the minimum moment of inertia (around an axis in the equator) differ by only 1 part in 306 \u2014the earth is almost a sphere. However, since the two moments of inertia do differ, any disturbance of the earth could result in a slight rotation around some other axis, or, what amounts to the same thing: the earth nutates as well as precesses. You can calculate the nutation frequency of the earth: it turns out, in fact, to be 306 days. And you can measure it very accurately: the pole wobbles in space by 50 feet measured at the earth\u2019s surface; it wobbles around, and back and forth, rather irregularly, but the major motion has a period of 439 days, not 306 days, and therein lies a mystery. However, this mystery is easily resolved: the analysis was made for rigid bodies, but the earth is not rigid; it\u2019s got liquid goop on the inside, and so, first of all, its period is different from that of a rigid body, and secondly, the motion is damped out so it should stop eventually\u2014that\u2019s why it\u2019s so small. What makes it nutate at all, despite the damping, are various irregular effects which jiggle the earth, such as the sudden motions of winds, and ocean currents. One of the most striking characteristics of the solar system, discovered by Kepler, is that everything goes around in ellipses. This was explained, ultimately, by the law of gravitation. But there are a whole lot of other things about the solar system\u2014peculiar simplifications\u2014which are harder to explain. For example, all the planets seem to go around the sun in roughly the same plane, and, except for one or two, they all rotate around their poles the same way\u2014west to east, like Earth; almost all the planetary moons go around in the same direction, and so with few exceptions, everything turns the same way. It\u2019s an interesting question to ask: How did the solar system get that way? In studying the origin of the solar system, one of the most important considerations is that of angular momentum. If you imagine a whole lot of dust or gas contracting as a result of gravitation, even if it only has a small amount of internal motion, the angular momentum must remain constant; those \u201carms\u201d are coming in and the moment of inertia is going down, so the angular velocity has to increase. It\u2019s possible that the planets are merely the result of a necessity the solar system has to dump its angular momentum from time to time in order to be able to contract still further\u2014we don\u2019t know. But it is true that 95% of the angular momentum in the solar system is in the planets, and not in the sun. (The sun is spinning, all right, but it\u2019s only got 5% of the total angular momentum.) This problem has been discussed many times, but it is still not understood how a gas contracts or how a pile of dust falls together when it is rotating slightly. Most discussions pay lip service to the angular momentum at the beginning; then, when they make the analysis, they disregard it. Another serious problem in astronomy has to do with the development of the galaxies\u2014the nebulae. What determines their form? Figure 4-31 shows several different types of nebulae: the famous ordinary spiral (much like our own galaxy), barred spiral nebulae (whose long arms extend from a central bar), and elliptic nebulae (which don\u2019t even have arms). And the question is: How did they become different? It could be, of course, that the masses of different nebulae are different, and that if you start with different amounts of mass, you come out with different results. That\u2019s possible, but because the spiral character of nebulae almost certainly has something to do with angular momentum, it seems more likely that differences from one nebula to another are explained by differences in the initial angular momentum of the original masses of gas and dust (or whatever you assume they start with). Another possibility, which some people have proposed, is that the different types of nebulae represent different stages of development. That would mean that they are all different ages\u2014which, of course, would have dramatic implications for our theory of the universe: Did it all explode at one time, after which the gas condensed to form different types of nebulae? Then they would all have to be the same age. Or, are the nebulae perpetually being formed from debris in space, in which case they could have different ages? A real understanding of the formation of these nebulae is a problem in mechanics, one involving angular momentum, and one which is still not solved. The physicists should be ashamed of themselves: astronomers keep asking, \u201cWhy don\u2019t you figure out for us what will happen if you have a big mass of junk pulled together by gravity and spinning? Can you understand the shapes of these nebulae?\u201d And nobody ever answers them. In quantum mechanics the fundamental law F=ma fails. Nevertheless, some things remain: the law of conservation of energy remains; the law of conservation of momentum remains; and the law of conservation of angular momentum also remains\u2014it remains in a very beautiful form, very deep in the heart of the quantum mechanics. Angular momentum is a central feature in the analyses of quantum mechanics, and that\u2019s in fact one of the main reasons for going so far into it in mechanics\u2014in order to be able to understand the phenomena in atoms. One of the interesting differences between classical and quantum mechanics is this: in classical mechanics, a given object can have arbitrary amounts of angular momentum by spinning at different speeds; in quantum mechanics, the angular momentum along a given axis cannot be arbitrary\u2014it can only have a value that is an integral or half-integral multiple of Planck\u2019s constant over two pi ( h/2\u03c0 , or \u210f )and it must jump from one value to another in increments of \u210f . This is one of the deeper principles of quantum mechanics associated with angular momentum. Finally, an interesting point: we think of the electron as a fundamental particle, as simple as it can be. Nevertheless, it has an intrinsic angular momentum. We picture the electron not simply as a point charge, but as a point charge that is a sort of limit of a real object that has angular momentum. It is something like an object spinning on its axis in the classical theory, but not exactly: it turns out that the electron is analogous to the simplest kind of gyro, which we imagine to have a very small moment of inertia, spinning extremely fast about its main axis. And, interestingly, the thing that we always do in the first approximation in classical mechanics, which is to neglect the moments of inertia around the precession axis\u2014that seems to be exactly right for the electron! In other words, the electron seems to be like a gyroscope with an infinitesimal moment of inertia, spinning at infinite angular velocity, so as to have a finite angular momentum. It\u2019s a limiting case; it\u2019s not exactly the same as a gyro\u2014it\u2019s even simpler. But it\u2019s still a curiosity. I have here the insides of the gyro shown in Figure 4-13, if you want to look at it. That\u2019s all for today. If you look through the magnifier very carefully, you can see the veeeerrrry fine, semicircular wires which feed power into the can, and are connected to these little pins here, on the outside. How much does one of these things cost? Oh, god knows how much they cost. There\u2019s so much precision work involved, not so much to make the thing, but to get it all calibrated and measured. See the tiny holes, and the four gold pins that look like somebody bent them? They bent those pins just so, so that the can would be perfectly balanced. However, if the oil density changes the can won\u2019t float: it\u2019ll sink in the oil, or rise in the oil, and there\u2019ll be forces on the pivots. To keep the oil density right, so the can just floats, you have to keep its temperature right within a few thousandths of a degree with a heating coil. And then there\u2019s the jeweled pivot, the point that goes into the jewel, like in a watch. So you see, it must be very expensive\u2014I don\u2019t even know how expensive. Hasn\u2019t there been some work done on a sort of gyroscope that\u2019s a weight on the end of a flexible rod? Yes, yes. They have been trying to design other ways, other methods. Wouldn\u2019t that reduce the bearing problem? Well, it reduces one thing and creates something else. Is it being used? Not that I know of. The gyros we\u2019ve discussed are the only ones that are actually used so far, and I don\u2019t think the others are in a position to match them yet, but they\u2019re close. It\u2019s a frontier subject. People are still designing new gyros, new devices, new ways, and it may well be that one of them will solve the problems, for instance, this insanity of having to have the axle bearings so accurate. If you play with the gyro for a while you will see that the friction on its axle is not small. The reason is, if the bearings were made too frictionless, the axle would wobble, and you\u2019d have to worry about that tenth of a millionth of an inch\u2014which is ridiculous. There must be a better way. I used to work in a machine shop. Then you can appreciate what is meant by a tenth of a millionth of an inch: it\u2019s impossible! What about ferroceramics? This business of supporting a superconductor in a magnetic field? Apparently if there\u2019s a fingerprint on the sphere, then the currents that are generated by the changing field make a little bit of loss. They\u2019re trying to get the thing straightened out, but it doesn\u2019t work yet. There\u2019re a lot of other clever ideas, but I only wanted to show one in its final, engineered form, with all the details. The springs on that thing are awfully fine. Yeah. Not only are they fine, in the sense that they\u2019re small, but they\u2019re fine in the sense of the way they\u2019re made: you know, they\u2019re very good steel, spring steel, everything just right. This kind of gyro is really impractical. It\u2019s so difficult to get it as accurate as it needs to be. It has to be made in rooms in which there\u2019s absolutely no dust\u2014the people wear special coats, gloves, booties, and masks, because if there\u2019s one grain of dirt in one of these things, it makes the friction wrong. I\u2019ll bet they throw away more than they make successfully, because everything has to be so carefully built. It\u2019s not just some little thing you put together; it\u2019s quite difficult. This remarkable precision is just about at the edge of our present ability, so it\u2019s interesting, and any improvement you can invent or design into it, of course, would be a great thing. One of the major problems is when the can\u2019s axis gets off center, and the thing turns; then you measure the twist around the wrong axis, and so you get a funny answer. But it seems to me self-evident (or almost\u2014I may be wrong) that that\u2019s not essential; that there must be some way to support a rotating thing, so that the support follows the center of gravity. At the same time, you can measure that it\u2019s being twisted, because twisting is a different thing than having the center of gravity off. What we would like to do is get a device that directly measures the twist about the center of gravity. If we could figure some way that the thing that\u2019s measuring the twist is sure to measure it about the center of gravity, it wouldn\u2019t make any difference if the center of gravity wobbled. If the whole platform always wobbled with just the same kind of motion as the thing you\u2019re trying to measure, then there\u2019d be no way to get out of it. But this off-center wheel is not exactly the same as the thing you want to measure, so there must be some way out. In general, are mechanical/analog integrators on the way out, in favor of the electrical/digital ones? Well, yes. Most integrating devices are electrical, but there are two general types. One is what they call \u201canalog\u201d: such devices use a physical method, one for which the results of a measurement is an integral of something. For example, if you have a resistor and you develop a certain voltage, you get a certain current through the resistor, which is proportional to the voltage. But if you measure the total charge, not the current, that\u2019s the integral of the current, you see. When we integrated an acceleration by measuring an angle\u2014that was a mechanical example. You can integrate in various ways of this kind, and it doesn\u2019t make any difference if it\u2019s mechanical or electrical\u2014usually, it\u2019s electrical\u2014but still, it\u2019s an analog method. Then there\u2019s another way, and that\u2019s to get the signal out and to make the signal, for instance, into a frequency: the thing makes a lot of pulses, and when the signal is stronger, it makes pulses more rapidly. And then you count the pulses, you see? And integrate the number of pulses? Just count the pulses; you could count them on a device like one of those little pedometers, where you push it once for each pulse, or you could do the same thing electrically, with tubes flipping back and forth. Then, if you want to integrate that again, you can do something numerically\u2014like we did our numerical integration on the blackboard. You can make essentially an adding machine\u2014not an integrator, but an adding machine\u2014and we use the adding machine to add the numbers together, and those numbers will have no appreciable errors in them if you design it right. So the errors due to the integrating devices can be reduced to zero, though the errors in the measuring equipment, from friction and so on, are still there. They don\u2019t use digital integrators much in actual rockets and submarines\u2014yet. But they\u2019re coming to that. They might as well get rid of the errors which are produced by the inaccuracies of the integrating machinery\u2014and they can be gotten rid of, once you convert the signal to what they call digital information\u2014dots\u2014countable things. And then you just have a digital computer? Then you just have some kind of little digital computer that does two integrations, numerically. That\u2019s better than doing it the analog way in the long run. Computing is mostly analog at the moment, but it\u2019s very likely that it\u2019ll turn into digital\u2014in a year or two, probably\u2014because that has no errors in it. You could use hundred-megacycle logic! It isn\u2019t the speed that\u2019s essential; it\u2019s simply a question of design. Analog integrators are getting so they\u2019re not quite accurate enough now, and so it\u2019s easiest to just change to digital. That\u2019s probably the next step, I would guess. But the real problem, of course, is the gyro itself; that has to be made better and better. Thanks a lot for the lecture on applications. Do you think maybe later in the term you\u2019ll do more? You like that kind of stuff, about applications? I\u2019m thinking about going into engineering. Okay. Well, this is one of the most beautiful things in mechanical engineering, of course. Let\u2019s try it\u2026 \u2014Did it turn on? No. I guess it\u2019s not plugged in. Oh, excuse me. Here. I got it. Now switch it on It says \u2018OFF\u2019 when I do that. What? I don\u2019t know what happened. Never mind. I\u2019m sorry. Could you go over again how the Coriolis force works on a gyroscope? Yes. I can see how it works on the merry-go-round, already. All right. Here\u2019s a wheel which is turning on its axle\u2014like a merry-go-round which is turning. I want to show that in order to rotate the axle, I have to resist the precession . . . or, that there\u2019ll be strains in the rods that support the axle, okay? Okay. Now, let\u2019s try to watch the way a particular particle of matter on the gyro wheel actually moves when we rotate the axle. If the wheel weren\u2019t turning, the answer would be that the particle goes in a circle. There\u2019s centrifugal force on it, which is balanced by the strains on the spokes of the wheel. But the wheel is turning very rapidly. So when we rotate the axle, the piece of matter moves, and the wheel has also turned, you see? First it\u2019s here; now it\u2019s here: we\u2019ve moved up to here, but the gyro turned. So the little piece of matter moves in a curve. Now, when you go around a curve, you\u2019ve got to pull\u2014it makes centrifugal force, if it\u2019s going in a curve. This force is not balanced by the spokes, which are radial; it must be balanced by some sideways push on the wheel. Oh! Yeah! So in order to hold this axle while it rotates I have to push sideways on it. You follow? Yeah. There\u2019s just one more point to make. You might ask, \u201cIf there\u2019s a sideways force, why doesn\u2019t the whole gyro move?\u201d And the answer is, of course, that the other side of the wheel is moving the opposite way. And if you go through the same game, following a particle on the other side of the wheel when it\u2019s turning, it makes an opposite force on that side. So, there\u2019s no net force on the gyroscope. I\u2019m starting to see it, but I can\u2019t see what difference the rotation of the wheel makes. Well, you see, it makes all the difference in the world. And the faster it goes around, the stronger is the effect\u2014although it takes a little fiddling around to see why. Because if it goes faster, then the curve the particle makes isn\u2019t as sharp. On the other hand, it\u2019s going faster, and it\u2019s a problem of checking one against the other. Anyway, it turns out the force is greater when it\u2019s going faster\u2014proportional to the speed, in fact. Dr. Feynman,\u2026 Yes, sir. Is it true that you can multiply seven-digit numbers in your head? No. It is not true. It\u2019s not even true that I can multiply two-digit numbers in my head. I can do one-digit numbers only. Do you know any philosophy teachers at Central College in Washington? Why? Well, I have a friend there. I hadn\u2019t seen him for a while and during Christmas vacation he asked me what I\u2019ve been doing. I told him I was going to Caltech. So he asked, \u201cDo you have a teacher there named Feynman?\u201d\u2014because his philosophy teacher told him that there\u2019s a guy named Feynman at Caltech who could multiply seven-digit numbers in his head. Not true. But I can do other things. Can I take some pictures of the apparatus? Sure! You want a close picture, or what? I think this\u2019ll do. But first, one to remember you by. I\u2019ll remember you."
    },
    {
        "input": "The Harmonic Oscillator",
        "output": "In the study of physics, usually the course is divided into a series of subjects, such as mechanics, electricity, optics, etc., and one studies one subject after the other. For example, this course has so far dealt mostly with mechanics. But a strange thing occurs again and again: the equations which appear in different fields of physics, and even in other sciences, are often almost exactly the same, so that many phenomena have analogs in these different fields. To take the simplest example, the propagation of sound waves is in many ways analogous to the propagation of light waves. If we study acoustics in great detail we discover that much of the work is the same as it would be if we were studying optics in great detail. So the study of a phenomenon in one field may permit an extension of our knowledge in another field. It is best to realize from the first that such extensions are possible, for otherwise one might not understand the reason for spending a great deal of time and energy on what appears to be only a small part of mechanics. The harmonic oscillator, which we are about to study, has close analogs in many other fields; although we start with a mechanical example of a weight on a spring, or a pendulum with a small swing, or certain other mechanical devices, we are really studying a certain differential equation. This equation appears again and again in physics and in other sciences, and in fact it is a part of so many phenomena that its close study is well worth our while. Some of the phenomena involving this equation are the oscillations of a mass on a spring; the oscillations of charge flowing back and forth in an electrical circuit; the vibrations of a tuning fork which is generating sound waves; the analogous vibrations of the electrons in an atom, which generate light waves; the equations for the operation of a servosystem, such as a thermostat trying to adjust a temperature; complicated interactions in chemical reactions; the growth of a colony of bacteria in interaction with the food supply and the poisons the bacteria produce; foxes eating rabbits eating grass, and so on; all these phenomena follow equations which are very similar to one another, and this is the reason why we study the mechanical oscillator in such detail. The equations are called linear differential equations with constant coefficients. A linear differential equation with constant coefficients is a differential equation consisting of a sum of several terms, each term being a derivative of the dependent variable with respect to the independent variable, and multiplied by some constant. Thus a n d n x/d t n + a n\u22121 d n\u22121 x/d t n\u22121 +\u22ef + a 1 dx/dt+ a 0 x=f(t) (21.1) is called a linear differential equation of order n with constant coefficients (each a i is constant). Perhaps the simplest mechanical system whose motion follows a linear differential equation with constant coefficients is a mass on a spring: first the spring stretches to balance the gravity; once it is balanced, we then discuss the vertical displacement of the mass from its equilibrium position (Fig. 21\u20131). We shall call this upward displacement x , and we shall also suppose that the spring is perfectly linear, in which case the force pulling back when the spring is stretched is precisely proportional to the amount of stretch. That is, the force is \u2212kx (with a minus sign to remind us that it pulls back). Thus the mass times the acceleration must equal \u2212kx : m d 2 x/d t 2 =\u2212kx. (21.2) For simplicity, suppose it happens (or we change our unit of time measurement) that the ratio k/m=1 . We shall first study the equation d 2 x/d t 2 =\u2212x. (21.3) Later we shall come back to Eq. (21.2) with the k and m explicitly present. We have already analyzed Eq. (21.3) in detail numerically; when we first introduced the subject of mechanics we solved this equation (see Eq. 9.12) to find the motion. By numerical integration we found a curve (Fig. 9\u20134) which showed that if m was initially displaced, but at rest, it would come down and go through zero; we did not then follow it any farther, but of course we know that it just keeps going up and down\u2014it oscillates. When we calculated the motion numerically, we found that it went through the equilibrium point at t=1.570 . The length of the whole cycle is four times this long, or t 0 =6.28 \u201csec.\u201d This was found numerically, before we knew much calculus. We assume that in the meantime the Mathematics Department has brought forth a function which, when differentiated twice, is equal to itself with a minus sign. (There are, of course, ways of getting at this function in a direct fashion, but they are more complicated than already knowing what the answer is.) The function is x=cost . If we differentiate this we find dx/dt=\u2212sint and d 2 x/d t 2 = \u2212cost= \u2212x . The function x=cost starts, at t=0 , with x=1 , and no initial velocity; that was the situation with which we started when we did our numerical work. Now that we know that x=cost , we can calculate a precise value for the time at which it should pass x=0 . The answer is t=\u03c0/2 , or 1.57080 . We were wrong in the last figure because of the errors of numerical analysis, but it was very close! Now to go further with the original problem, we restore the time units to real seconds. What is the solution then? First of all, we might think that we can get the constants k and m in by multiplying cost by something. So let us try the equation x=Acost ; then we find dx/dt=\u2212Asint , and d 2 x/d t 2 = \u2212Acost= \u2212x . Thus we discover to our horror that we did not succeed in solving Eq. (21.2), but we got Eq. (21.3) again! That fact illustrates one of the most important properties of linear differential equations: if we multiply a solution of the equation by any constant, it is again a solution. The mathematical reason for this is clear. If x is a solution, and we multiply both sides of the equation, say by A , we see that all derivatives are also multiplied by A , and therefore Ax is just as good a solution of the original equation as x was. The physics of it is the following. If we have a weight on a spring, and pull it down twice as far, the force is twice as much, the resulting acceleration is twice as great, the velocity it acquires in a given time is twice as great, the distance covered in a given time is twice as great; but it has to cover twice as great a distance in order to get back to the origin because it is pulled down twice as far. So it takes the same time to get back to the origin, irrespective of the initial displacement. In other words, with a linear equation, the motion has the same time pattern, no matter how \u201cstrong\u201d it is. That was the wrong thing to do\u2014it only taught us that we can multiply the solution by anything, and it satisfies the same equation, but not a different equation. After a little cut and try to get to an equation with a different constant multiplying x , we find that we must alter the scale of time. In other words, Eq. (21.2) has a solution of the form x=cos \u03c9 0 t. (21.4) (It is important to realize that in the present case, \u03c9 0 is not an angular velocity of a spinning body, but we run out of letters if we are not allowed to use the same letter for more than one thing.) The reason we put a subscript \u201c 0 \u201d on \u03c9 is that we are going to have more omegas before long; let us remember that \u03c9 0 refers to the natural motion of this oscillator. Now we try Eq. (21.4) and this time we are more successful, because dx/dt=\u2212 \u03c9 0 sin \u03c9 0 t and d 2 x/d t 2 = \u2212 \u03c9 2 0 cos \u03c9 0 t= \u2212 \u03c9 2 0 x . So at last we have solved the equation that we really wanted to solve. The equation d 2 x/d t 2 =\u2212 \u03c9 2 0 x is the same as Eq. (21.2) if \u03c9 2 0 =k/m . The next thing we must investigate is the physical significance of \u03c9 0 . We know that the cosine function repeats itself when the angle it refers to is 2\u03c0 . So x=cos \u03c9 0 t will repeat its motion, it will go through a complete cycle, when the \u201cangle\u201d changes by 2\u03c0 . The quantity \u03c9 0 t is often called the phase of the motion. In order to change \u03c9 0 t by 2\u03c0 , the time must change by an amount t 0 , called the period of one complete oscillation; of course t 0 must be such that \u03c9 0 t 0 =2\u03c0 . That is, \u03c9 0 t 0 must account for one cycle of the angle, and then everything will repeat itself\u2014if we increase t by t 0 , we add 2\u03c0 to the phase. Thus t 0 =2\u03c0/ \u03c9 0 =2\u03c0 m/k \u2212 \u2212 \u2212 \u2212 \u221a . (21.5) Thus if we had a heavier mass, it would take longer to oscillate back and forth on a spring. That is because it has more inertia, and so, while the forces are the same, it takes longer to get the mass moving. Or, if the spring is stronger, it will move more quickly, and that is right: the period is less if the spring is stronger. Note that the period of oscillation of a mass on a spring does not depend in any way on how it has been started, how far down we pull it. The period is determined, but the amplitude of the oscillation is not determined by the equation of motion (21.2). The amplitude is determined, in fact, by how we let go of it, by what we call the initial conditions or starting conditions. Actually, we have not quite found the most general possible solution of Eq. (21.2). There are other solutions. It should be clear why: because all of the cases covered by x=acos \u03c9 0 t start with an initial displacement and no initial velocity. But it is possible, for instance, for the mass to start at x=0 , and we may then give it an impulsive kick, so that it has some speed at t=0 . Such a motion is not represented by a cosine\u2014it is represented by a sine. To put it another way, if x=cos \u03c9 0 t is a solution, then is it not obvious that if we were to happen to walk into the room at some time (which we would call \u201c t=0 \u201d) and saw the mass as it was passing x=0 , it would keep on going just the same? Therefore, x=cos \u03c9 0 t cannot be the most general solution; it must be possible to shift the beginning of time, so to speak. As an example, we could write the solution this way: x=acos \u03c9 0 (t\u2212 t 1 ) , where t 1 is some constant. This also corresponds to shifting the origin of time to some new instant. Furthermore, we may expand cos( \u03c9 0 t+\u0394)=cos \u03c9 0 tcos\u0394\u2212sin \u03c9 0 tsin\u0394, ( ) and write x=Acos \u03c9 0 t+Bsin \u03c9 0 t, A B sin where A=acos\u0394 and B=\u2212asin\u0394 . Any one of these forms is a possible way to write the complete, general solution of (21.2): that is, every solution of the differential equation d 2 x/d t 2 =\u2212 \u03c9 2 0 x that exists in the world can be written as or or (a)x (b)x (c)x = = = acos \u03c9 0 (t\u2212 t 1 ), acos( \u03c9 0 t+\u0394) Acos \u03c9 0 t+Bsin \u03c9 0 t. (21.6) Some of the quantities in (21.6) have names: \u03c9 0 is called the angular frequency; it is the number of radians by which the phase changes in a second. That is determined by the differential equation. The other constants are not determined by the equation, but by how the motion is started. Of these constants, a measures the maximum displacement attained by the mass, and is called the amplitude of oscillation. The constant \u0394 is sometimes called the phase of the oscillation, but that is a confusion, because other people call \u03c9 0 t+\u0394 the phase, and say the phase changes with time. We might say that \u0394 is a phase shift from some defined zero. Let us put it differently. Different \u0394 \u2019s correspond to motions in different phases. That is true, but whether we want to call \u0394 the phase, or not, is another question. The fact that cosines are involved in the solution of Eq. (21.2) suggests that there might be some relationship to circles. This is artificial, of course, because there is no circle actually involved in the linear motion\u2014it just goes up and down. We may point out that we have, in fact, already solved that differential equation when we were studying the mechanics of circular motion. If a particle moves in a circle with a constant speed v , the radius vector from the center of the circle to the particle turns through an angle whose size is proportional to the time. If we call this angle \u03b8=vt/R (Fig. 21\u20132) then d\u03b8/dt= \u03c9 0 = v/R . We know that there is an acceleration a= v 2 /R= \u03c9 2 0 R toward the center. Now we also know that the position x , at a given moment, is the radius of the circle times cos\u03b8 , and that y is the radius times sin\u03b8 : x=Rcos\u03b8,y=Rsin\u03b8. R \u03b8 R sin \u03b8 Now what about the acceleration? What is the x -component of acceleration, d 2 x/d t 2 ? We have already worked that out geometrically; it is the magnitude of the acceleration times the cosine of the projection angle, with a minus sign because it is toward the center. a x =\u2212acos\u03b8=\u2212 \u03c9 2 0 Rcos\u03b8=\u2212 \u03c9 2 0 x. (21.7) In other words, when a particle is moving in a circle, the horizontal component of its motion has an acceleration which is proportional to the horizontal displacement from the center. Of course we also have the solution for motion in a circle: x=Rcos \u03c9 0 t . Equation (21.7) does not depend upon the radius of the circle, so for a circle of any radius, one finds the same equation for a given \u03c9 0 . Thus, for several reasons, we expect that the displacement of a mass on a spring will turn out to be proportional to cos \u03c9 0 t , and will, in fact, be exactly the same motion as we would see if we looked at the x -component of the position of an object rotating in a circle with angular velocity \u03c9 0 . As a check on this, one can devise an experiment to show that the up-and-down motion of a mass on a spring is the same as that of a point going around in a circle. In Fig. 21\u20133 an arc light projected on a screen casts shadows of a crank pin on a shaft and of a vertically oscillating mass, side by side. If we let go of the mass at the right time from the right place, and if the shaft speed is carefully adjusted so that the frequencies match, each should follow the other exactly. One can also check the numerical solution we obtained earlier with the cosine function, and see whether that agrees very well. Here we may point out that because uniform motion in a circle is so closely related mathematically to oscillatory up-and-down motion, we can analyze oscillatory motion in a simpler way if we imagine it to be a projection of something going in a circle. In other words, although the distance y means nothing in the oscillator problem, we may still artificially supplement Eq. (21.2) with another equation using y , and put the two together. If we do this, we will be able to analyze our one-dimensional oscillator with circular motions, which is a lot easier than having to solve a differential equation. The trick in doing this is to use complex numbers, a procedure we shall introduce in the next chapter. Now let us consider what determines the constants A and B , or a and \u0394 . Of course these are determined by how we start the motion. If we start the motion with just a small displacement, that is one type of oscillation; if we start with an initial displacement and then push up when we let go, we get still a different motion. The constants A and B , or a and \u0394 , or any other way of putting it, are determined, of course, by the way the motion started, not by any other features of the situation. These are called the initial conditions. We would like to connect the initial conditions with the constants. Although this can be done using any one of the forms (21.6), it turns out to be easiest if we use Eq. (21.6c). Suppose that at t=0 we have started with an initial displacement x 0 and a certain velocity v 0 . This is the most general way we can start the motion. (We cannot specify the acceleration with which it started, true, because that is determined by the spring, once we specify x 0 .) Now let us calculate A and B . We start with the equation for x , x=Acos \u03c9 0 t+Bsin \u03c9 0 t. A B sin Since we shall later need the velocity also, we differentiate x and obtain v=\u2212 \u03c9 0 Asin \u03c9 0 t+ \u03c9 0 Bcos \u03c9 0 t. A sin B These expressions are valid for all t , but we have special knowledge about x and v at t=0 . So if we put t=0 into these equations, on the left we get x 0 and v 0 , because that is what x and v are at t=0 ; also, we know that the cosine of zero is unity, and the sine of zero is zero. Therefore we get x 0 =A\u22c51+B\u22c50=A A 1 B 0 A and v 0 =\u2212 \u03c9 0 A\u22c50+ \u03c9 0 B\u22c51= \u03c9 0 B. A 0 B 1 B So for this particular case we find that A= x 0 ,B= v 0 / \u03c9 0 . A B / From these values of A and B , we can get a and \u0394 if we wish. That is the end of our solution, but there is one physically interesting thing to check, and that is the conservation of energy. Since there are no frictional losses, energy ought to be conserved. Let us use the formula x=acos( \u03c9 0 t+\u0394); ( ) then v=\u2212 \u03c9 0 asin( \u03c9 0 t+\u0394). ( ) Now let us find out what the kinetic energy T is, and what the potential energy U is. The potential energy at any moment is 1 2 k x 2 , where x is the displacement and k is the constant of the spring. If we substitute for x , using our expression above, we get U= 1 2 k x 2 = 1 2 k a 2 cos 2 ( \u03c9 0 t+\u0394). 1 1 Of course the potential energy is not constant; the potential never becomes negative, naturally\u2014there is always some energy in the spring, but the amount of energy fluctuates with x . The kinetic energy, on the other hand, is 1 2 m v 2 , and by substituting for v we get T= 1 2 m v 2 = 1 2 m \u03c9 2 0 a 2 sin 2 ( \u03c9 0 t+\u0394). 1 1 Now the kinetic energy is zero when x is at the maximum, because then there is no velocity; on the other hand, it is maximal when x is passing through zero, because then it is moving fastest. This variation of the kinetic energy is just the opposite of that of the potential energy. But the total energy ought to be a constant. If we note that k=m \u03c9 2 0 , we see that T+U = 1 2 m \u03c9 2 0 a 2 [ cos 2 ( \u03c9 0 t+\u0394)+ sin 2 ( \u03c9 0 t+\u0394)] = 1 2 m \u03c9 2 0 a 2 . The energy is dependent on the square of the amplitude; if we have twice the amplitude, we get an oscillation which has four times the energy. The average potential energy is half the maximum and, therefore, half the total, and the average kinetic energy is likewise half the total energy. Next we shall discuss the forced harmonic oscillator, i.e., one in which there is an external driving force acting. The equation then is the following: m d 2 x/d t 2 =\u2212kx+F(t). (21.8) We would like to find out what happens in these circumstances. The external driving force can have various kinds of functional dependence on the time; the first one that we shall analyze is very simple\u2014we shall suppose that the force is oscillating: F(t)= F 0 cos\u03c9t. (21.9) Notice, however, that this \u03c9 is not necessarily \u03c9 0 : we have \u03c9 under our control; the forcing may be done at different frequencies. So we try to solve Eq. (21.8) with the special force (21.9). What is the solution of (21.8)? One special solution, (we shall discuss the more general cases later) is x=Ccos\u03c9t, (21.10) where the constant is to be determined. In other words, we might suppose that if we kept pushing back and forth, the mass would follow back and forth in step with the force. We can try it anyway. So we put (21.10) and (21.9) into (21.8), and get \u2212m \u03c9 2 Ccos\u03c9t=\u2212m \u03c9 2 0 Ccos\u03c9t+ F 0 cos\u03c9t. (21.11) We have also put in k=m \u03c9 2 0 , so that we will understand the equation better at the end. Now because the cosine appears everywhere, we can divide it out, and that shows that (21.10) is, in fact, a solution, provided we pick C just right. The answer is that C must be C= F 0 /m( \u03c9 2 0 \u2212 \u03c9 2 ). (21.12) That is, m oscillates at the same frequency as the force, but with an amplitude which depends on the frequency of the force, and also upon the frequency of the natural motion of the oscillator. It means, first, that if \u03c9 is very small compared with \u03c9 0 , then the displacement and the force are in the same direction. On the other hand, if we shake it back and forth very fast, then (21.12) tells us that C is negative if \u03c9 is above the natural frequency \u03c9 0 of the harmonic oscillator. (We will call \u03c9 0 the natural frequency of the harmonic oscillator, and \u03c9 the applied frequency.) At very high frequency the denominator may become very large, and there is then not much amplitude. Of course the solution we have found is the solution only if things are started just right, for otherwise there is a part which usually dies out after a while. This other part is called the transient response to F(t) , while (21.10) and (21.12) are called the steady-state response. According to our formula (21.12), a very remarkable thing should also occur: if \u03c9 is almost exactly the same as \u03c9 0 , then C should approach infinity. So if we adjust the frequency of the force to be \u201cin time\u201d with the natural frequency, then we should get an enormous displacement. This is well known to anybody who has pushed a child on a swing. It does not work very well to close our eyes and push at a certain speed at random. If we happen to get the right timing, then the swing goes very high, but if we have the wrong timing, then sometimes we may be pushing when we should be pulling, and so on, and it does not work. If we make \u03c9 exactly equal to \u03c9 0 , we find that it should oscillate at an infinite amplitude, which is, of course, impossible. The reason it does not is that something goes wrong with the equation, there are some other frictional terms, and other forces, which are not in (21.8) but which occur in the real world. So the amplitude does not reach infinity for some reason; it may be that the spring breaks!"
    },
    {
        "input": "Electricity in the Atmosphere",
        "output": "On an ordinary day over flat desert country, or over the sea, as one goes upward from the surface of the ground the electric potential increases by about 100 volts per meter. Thus there is a vertical electric field E of 100 volts/m in the air. The sign of the field corresponds to a negative charge on the earth\u2019s surface. This means that outdoors the potential at the height of your nose is 200 volts higher than the potential at your feet! You might ask: \u201cWhy don\u2019t we just stick a pair of electrodes out in the air one meter apart and use the 100 volts to power our electric lights?\u201d Or you might wonder: \u201cIf there is really a potential difference of 200 volts between my nose and my feet, why is it I don\u2019t get a shock when I go out into the street?\u201d We will answer the second question first. Your body is a relatively good conductor. If you are in contact with the ground, you and the ground will tend to make one equipotential surface. Ordinarily, the equipotentials are parallel to the surface, as shown in Fig. 9\u20131(a), but when you are there, the equipotentials are distorted, and the field looks somewhat as shown in Fig. 9\u20131(b). So you still have very nearly zero potential difference between your head and your feet. There are charges that come from the earth to your head, changing the field. Some of them may be discharged by ions collected from the air, but the current of these is very small because air is a poor conductor. How can we measure such a field if the field is changed by putting something there? There are several ways. One way is to place an insulated conductor at some distance above the ground and leave it there until it is at the same potential as the air. If we leave it long enough, the very small conductivity in the air will let the charges leak off (or onto) the conductor until it comes to the potential at its level. Then we can bring it back to the ground, and measure the shift of its potential as we do so. A faster way is to let the conductor be a bucket of water with a small leak. As the water drops out, it carries away any excess charges and the bucket will approach the same potential as the air. (The charges, as you know, reside on the surface, and as the drops come off \u201cpieces of surface\u201d break off.) We can measure the potential of the bucket with an electrometer. There is another way to directly measure the potential gradient. Since there is an electric field, there is a surface charge on the earth (\u03c3=\u03f50E ). If we place a flat metal plate at the earth\u2019s surface and ground it, negative charges appear on it (Fig. 9\u20132a). If this plate is now covered by another grounded conducting cover B , the charges will appear on the cover, and there will be no charges on the original plate A . If we measure the charge that flows from plate A to the ground (by, say, a galvanometer in the grounding wire) as we cover it, we can find the surface charge density that was there, and therefore also find the electric field. Having suggested how we can measure the electric field in the atmosphere, we now continue our description of it. Measurements show, first of all, that the field continues to exist, but gets weaker, as one goes up to high altitudes. By about 50 kilometers, the field is very small, so most of the potential change (the integral of E ) is at lower altitudes. The total potential difference from the surface of the earth to the top of the atmosphere is about 400,000 volts. Another thing that can be measured, in addition to the potential gradient, is the current in the atmosphere. The current density is small\u2014about 10 micromicroamperes crosses each square meter parallel to the earth. The air is evidently not a perfect insulator, and because of this conductivity, a small current\u2014caused by the electric field we have just been describing\u2014passes from the sky down to the earth. Why does the atmosphere have conductivity? Here and there among the air molecules there is an ion\u2014a molecule of oxygen, say, which has acquired an extra electron, or perhaps lost one. These ions do not stay as single molecules; because of their electric field they usually accumulate a few other molecules around them. Each ion then becomes a little lump which, along with other lumps, drifts in the field\u2014moving slowly upward or downward\u2014making the observed current. Where do the ions come from? It was first guessed that the ions were produced by the radioactivity of the earth. (It was known that the radiation from radioactive materials would make air conducting by ionizing the air molecules.) Particles like \u03b2 -rays coming out of the atomic nuclei are moving so fast that they tear electrons from the atoms, leaving ions behind. This would imply, of course, that if we were to go to higher altitudes, we should find less ionization, because the radioactivity is all in the dirt on the ground\u2014in the traces of radium, uranium, potassium, etc. To test this theory, some physicists carried an experiment up in balloons to measure the ionization of the air (Hess, in 1912) and discovered that the opposite was true\u2014the ionization per unit volume increased with altitude! (The apparatus was like that of Fig. 9\u20133. The two plates were charged periodically to the potential V . Due to the conductivity of the air, the plates slowly discharged; the rate of discharge was measured with the electrometer.) This was a most mysterious result\u2014the most dramatic finding in the entire history of atmospheric electricity. It was so dramatic, in fact, that it required a branching off of an entirely new subject\u2014cosmic rays. Atmospheric electricity itself remained less dramatic. Ionization was evidently being produced by something from outside the earth; the investigation of this source led to the discovery of the cosmic rays. We will not discuss the subject of cosmic rays now, except to say that they maintain the supply of ions. Although the ions are being swept away all the time, new ones are being created by the cosmic-ray particles coming from the outside. To be precise, we must say that besides the ions made of molecules, there are also other kinds of ions. Tiny pieces of dirt, like extremely fine bits of dust, float in the air and become charged. They are sometimes called \u201cnuclei.\u201d For example, when a wave breaks in the sea, little bits of spray are thrown into the air. When one of these drops evaporates, it leaves an infinitesimal crystal of NaCl floating in the air. These tiny crystals can then pick up charges and become ions; they are called \u201clarge ions.\u201d The small ions\u2014those formed by cosmic rays\u2014are the most mobile. Because they are so small, they move rapidly through the air\u2014with a speed of about 1 cm/sec in a field of 100 volts/meter, or 1 volt/cm. The much bigger and heavier ions move much more slowly. It turns out that if there are many \u201cnuclei,\u201d they will pick up the charges from the small ions. Then, since the \u201clarge ions\u201d move so slowly in a field, the total conductivity is reduced. The conductivity of air, therefore, is quite variable, since it is very sensitive to the amount of \u201cdirt\u201d there is in it. There is much more of such dirt over land\u2014where the winds can blow up dust or where man throws all kinds of pollution into the air\u2014than there is over water. It is not surprising that from day to day, from moment to moment, from place to place, the conductivity near the earth\u2019s surface varies enormously. The voltage gradient observed at any particular place on the earth\u2019s surface also varies greatly because roughly the same current flows down from high altitudes in different places, and the varying conductivity near the earth results in a varying voltage gradient. The conductivity of the air due to the drifting of ions also increases rapidly with altitude\u2014for two reasons. First of all, the ionization from cosmic rays increases with altitude. Secondly, as the density of air goes down, the mean free path of the ions increases, so that they can travel farther in the electric field before they have a collision\u2014resulting in a rapid increase of conductivity as one goes up. Although the electric current-density in the air is only a few micromicroamperes per square meter, there are very many square meters on the earth\u2019s surface. The total electric current reaching the earth\u2019s surface at any time is very nearly constant at 1800 amperes. This current, of course, is \u201cpositive\u201d\u2014it carries plus charges to the earth. So we have a voltage supply of 400,000 volts with a current of 1800 amperes\u2014a power of 700 megawatts! With such a large current coming down, the negative charge on the earth should soon be discharged. In fact, it should take only about half an hour to discharge the entire earth. But the atmospheric electric field has already lasted more than a half-hour since its discovery. How is it maintained? What maintains the voltage? And between what and the earth? There are many questions. The earth is negative, and the potential in the air is positive. If you go high enough, the conductivity is so great that horizontally there is no more chance for voltage variations. The air, for the scale of times that we are talking about, becomes effectively a conductor. This occurs at a height in the neighborhood of 50 kilometers. This is not as high as what is called the \u201cionosphere,\u201d in which there are very large numbers of ions produced by photoelectricity from the sun. Nevertheless, for our discussions of atmospheric electricity, the air becomes sufficiently conductive at about 50 kilometers that we can imagine that there is practically a perfect conducting surface at this height, from which the currents come down. Our picture of the situation is shown in Fig. 9\u20134. The problem is: How is the positive charge maintained there? How is it pumped back? Because if it comes down to the earth, it has to be pumped back somehow. That was one of the greatest puzzles of atmospheric electricity for quite a while. Each piece of information we can get should give a clue or, at least, tell you something about it. Here is an interesting phenomenon: If we measure the current (which is more stable than the potential gradient) over the sea, for instance, or in careful conditions, and average very carefully so that we get rid of the irregularities, we discover that there is still a daily variation. The average of many measurements over the oceans has a variation with time roughly as shown in Fig. 9\u20135. The current varies by about \u00b115 percent, and it is largest at 7:00 p.m. in London. The strange part of the thing is that no matter where you measure the current\u2014in the Atlantic Ocean, the Pacific Ocean, or the Arctic Ocean\u2014it is at its peak value when the clocks in London say 7:00 p.m.! All over the world the current is at its maximum at 7:00 p.m. London time and it is at a minimum at 4:00 a.m. London time. In other words, it depends upon the absolute time on the earth, not upon the local time at the place of observation. In one respect this is not mysterious; it checks with our idea that there is a very high conductivity laterally at the top, because that makes it impossible for the voltage difference from the ground to the top to vary locally. Any potential variations should be worldwide, as indeed they are. What we now know, therefore, is that the voltage at the \u201ctop\u201d surface is dropping and rising by 15 percent with the absolute time on the earth. We must next talk about the source of the large negative currents which must be flowing from the \u201ctop\u201d to the surface of the earth to keep charging it up negatively. Where are the batteries that do this? The \u201cbattery\u201d is shown in Fig. 9\u20136. It is the thunderstorm and its lightning. It turns out that the bolts of lightning do not \u201cdischarge\u201d the potential we have been talking about (as you might at first guess). Lightning storms carry negative charges to the earth. When a lightning bolt strikes, nine times out of ten it brings down negative charges to the earth in large amounts. It is the thunderstorms throughout the world that are charging the earth with an average of 1800 amperes, which is then being discharged through regions of fair weather. There are about 40,000 thunderstorms per day all over the earth, and we can think of them as batteries pumping the electricity to the upper layer and maintaining the voltage difference. Then take into account the geography of the earth\u2014there are thunderstorms in the afternoon in Brazil, tropical thunderstorms in Africa, and so forth. People have made estimates of how much lightning is striking world-wide at any time, and perhaps needless to say, their estimates more or less agree with the voltage difference measurements: the total amount of thunderstorm activity is highest on the whole earth at about 7:00 p.m. in London. However, the thunderstorm estimates are very difficult to make and were made only after it was known that the variation should have occurred. These things are very difficult because we don\u2019t have enough observations on the seas and over all parts of the world to know the number of thunderstorms accurately. But those people who think they \u201cdo it right\u201d obtain the result that there are about 100 lightning flashes per second world-wide with a peak in the activity at 7:00 p.m. Greenwich Mean Time. In order to understand how these batteries work, we will look at a thunderstorm in detail. What is going on inside a thunderstorm? We will describe this insofar as it is known. As we get into this marvelous phenomenon of real nature\u2014instead of the idealized spheres of perfect conductors inside of other spheres that we can solve so neatly\u2014we discover that we don\u2019t know very much. Yet it is really quite exciting. Anyone who has been in a thunderstorm has enjoyed it, or has been frightened, or at least has had some emotion. And in those places in nature where we get an emotion, we find that there is generally a corresponding complexity and mystery about it. It is not going to be possible to describe exactly how a thunderstorm works, because we do not yet know very much. But we will try to describe a little bit about what happens. In the first place, an ordinary thunderstorm is made up of a number of \u201ccells\u201d fairly close together, but almost independent of each other. So it is best to analyze one cell at a time. By a \u201ccell\u201d we mean a region with a limited area in the horizontal direction in which all of the basic processes occur. Usually there are several cells side by side, and in each one about the same thing is happening, although perhaps with a different timing. Figure 9\u20137 indicates in an idealized fashion what such a cell looks like in the early stage of the thunderstorm. It turns out that in a certain place in the air, under certain conditions which we shall describe, there is a general rising of the air, with higher and higher velocities near the top. As the warm, moist air at the bottom rises, it cools and the water vapor in it condenses. In the figure the little stars indicate snow and the dots indicate rain, but because the updraft currents are great enough and the drops are small enough, the snow and rain do not come down at this stage. This is the beginning stage, and not the real thunderstorm yet\u2014in the sense that we don\u2019t have anything happening at the ground. At the same time that the warm air rises, there is an entrainment of air from the sides\u2014an important point which was neglected for many years. Thus it is not just the air from below which is rising, but also a certain amount of other air from the sides. Why does the air rise like this? As you know, when you go up in altitude the air is colder. The ground is heated by the sun, and the re-radiation of heat to the sky comes from water vapor high in the atmosphere; so at high altitudes the air is cold\u2014very cold\u2014whereas lower down it is warm. You may say, \u201cThen it\u2019s very simple. Warm air is lighter than cold; therefore the combination is mechanically unstable and the warm air rises.\u201d Of course, if the temperature is different at different heights, the air is unstable thermodynamically. Left to itself infinitely long, the air would all come to the same temperature. But it is not left to itself; the sun is always shining (during the day). So the problem is indeed not one of thermodynamic equilibrium, but of mechanical equilibrium. Suppose we plot\u2014as in Fig. 9\u20138\u2014the temperature of the air against height above the ground. In ordinary circumstances we would get a decrease along a curve like the one labeled (a); as the height goes up, the temperature goes down. How can the atmosphere be stable? Why doesn\u2019t the hot air below simply rise up into the cold air? The answer is this: if the air were to go up, its pressure would go down, and if we consider a particular parcel of air going up, it would be expanding adiabatically. (There would be no heat coming in or out because in the large dimensions considered here, there isn\u2019t time for much heat flow.) Thus the parcel of air would cool as it rises. Such an adiabatic process would give a temperature-height relationship like curve (b) in Fig. 9\u20138. Any air which rose from below would be colder than the environment it goes into. Thus there is no reason for the hot air below to rise; if it were to rise, it would cool to a lower temperature than the air already there, would be heavier than the air there, and would just want to come down again. On a good, bright day with very little humidity there is a certain rate at which the temperature in the atmosphere falls, and this rate is, in general, lower than the \u201cmaximum stable gradient,\u201d which is represented by curve (b). The air is in stable mechanical equilibrium. On the other hand, if we think of a parcel of air that contains a lot of water vapor being carried up into the air, its adiabatic cooling curve will be different. As it expands and cools, the water vapor in it will condense, and the condensing water will liberate heat. Moist air, therefore, does not cool nearly as much as dry air does. So if air that is wetter than the average starts to rise, its temperature will follow a curve like (c) in Fig. 9\u20138. It will cool off somewhat, but will still be warmer than the surrounding air at the same level. If we have a region of warm moist air and something starts it rising, it will always find itself lighter and warmer than the air around it and will continue to rise until it gets to enormous heights. This is the machinery that makes the air in the thunderstorm cell rise. For many years the thunderstorm cell was explained simply in this manner. But then measurements showed that the temperature of the cloud at different heights was not nearly as high as indicated by curve (c). The reason is that as the moist air \u201cbubble\u201d goes up, it entrains air from the environment and is cooled off by it. The temperature-versus-height curve looks more like curve (d), which is much closer to the original curve (a) than to curve (c). After the convection just described gets under way, the cross section of a thunderstorm cell looks like Fig. 9\u20139. We have what is called a \u201cmature\u201d thunderstorm. There is a very rapid updraft which, in this stage, goes up to about 10,000 to 15,000 meters\u2014sometimes even much higher. The thunderheads, with their condensation, climb way up out of the general cloud bank, carried by an updraft that is usually about 60 miles an hour. As the water vapor is carried up and condenses, it forms tiny drops which are rapidly cooled to temperatures below zero degrees. They should freeze, but do not freeze immediately\u2014they are \u201csupercooled.\u201d Water and other liquids will usually cool well below their freezing points before crystallizing if there are no \u201cnuclei\u201d present to start the crystallization process. Only if there is some small piece of material present, like a tiny crystal of NaCl, will the water drop freeze into a little piece of ice. Then the equilibrium is such that the water drops evaporate and the ice crystals grow. Thus at a certain point there is a rapid disappearance of the water and a rapid buildup of ice. Also, there may be direct collisions between the water drops and the ice\u2014collisions in which the supercooled water becomes attached to the ice crystals, which causes it to suddenly crystallize. So at a certain point in the cloud expansion there is a rapid accumulation of large ice particles. When the ice particles are heavy enough, they begin to fall through the rising air\u2014they get too heavy to be supported any longer in the updraft. As they come down, they draw a little air with them and start a downdraft. And surprisingly enough, it is easy to see that once the downdraft is started, it will maintain itself. The air now drives itself down! Notice that the curve (d) in Fig. 9\u20138 for the actual distribution of temperature in the cloud is steeper than curve (c), which applies to wet air. So if we have wet air falling, its temperature will drop with the slope of curve (c) and will go below the temperature of the environment if it gets down far enough, as indicated by curve (e) in the figure. The moment it does that, it is denser than the environment and continues to fall rapidly. You say, \u201cThat is perpetual motion. First, you argue that the air should rise, and when you have it up there, you argue equally well that the air should fall.\u201d But it isn\u2019t perpetual motion. When the situation is unstable and the warm air should rise, then clearly something has to replace the warm air. It is equally true that cold air coming down would energetically replace the warm air, but you realize that what is coming down is not the original air. The early arguments, that had a particular cloud without entrainment going up and then coming down, had some kind of a puzzle. They needed the rain to maintain the downdraft\u2014an argument which is hard to believe. As soon as you realize that there is a lot of original air mixed in with the rising air, the thermodynamic argument shows that there can be a descent of the cold air which was originally at some great height. This explains the picture of the active thunderstorm sketched in Fig. 9\u20139. As the air comes down, rain begins to come out of the bottom of the thunderstorm. In addition, the relatively cold air spreads out when it arrives at the earth\u2019s surface. So just before the rain comes there is a certain little cold wind that gives us a forewarning of the coming storm. In the storm itself there are rapid and irregular gusts of air, there is an enormous turbulence in the cloud, and so on. But basically we have an updraft, then a downdraft\u2014in general, a very complicated process. The moment at which precipitation starts is the same moment that the large downdraft begins and is the same moment, in fact, when the electrical phenomena arise. Before we describe lightning, however, we can finish the story by looking at what happens to the thunderstorm cell after about one-half an hour to an hour. The cell looks as shown in Fig. 9\u201310. The updraft stops because there is no longer enough warm air to maintain it. The downward precipitation continues for a while, the last little bits of water come out, and things get quieter and quieter\u2014although there are small ice crystals left way up in the air. Because the winds at very great altitude are in different directions, the top of the cloud usually spreads into an anvil shape. The cell comes to the end of its life. We want now to discuss the most important aspect for our purposes\u2014the development of the electrical charges. Experiments of various kinds\u2014including flying airplanes through thunderstorms (the pilots who do this are brave men!)\u2014tell us that the charge distribution in a thunderstorm cell is something like that shown in Fig. 9\u201311. The top of the thunderstorm has a positive charge, and the bottom a negative one\u2014except for a small local region of positive charge in the bottom of the cloud, which has caused everybody a lot of worry. No one seems to know why it is there, how important it is\u2014whether it is a secondary effect of the positive rain coming down, or whether it is an essential part of the machinery. Things would be much simpler if it weren\u2019t there. Anyway, the predominantly negative charge at the bottom and the positive charge at the top have the correct sign for the battery needed to drive the earth negative. The positive charges are 6 or 7 kilometers up in the air, where the temperature is about \u2212 20 \u2218 C, whereas the negative charges are 3 or 4 kilometers high, where the temperature is between zero and \u2212 10 \u2218 C. The charge at the bottom of the cloud is large enough to produce potential differences of 20 , or 30 , or even 100 million volts between the cloud and the earth\u2014much bigger than the 0.4 million volts from the \u201csky\u201d to the ground in a clear atmosphere. These large voltages break down the air and create giant arc discharges. When the breakdown occurs the negative charges at the bottom of the thunderstorm are carried down to the earth in the lightning strokes. Now we will describe in some detail the character of the lightning. First of all, there are large voltage differences around, so that the air breaks down. There are lightning strokes between one piece of a cloud and another piece of a cloud, or between one cloud and another cloud, or between a cloud and the earth. In each of the independent discharge flashes\u2014the kind of lightning strokes you see there are approximately 20 or 30 coulombs of charge brought down. One question is: How long does it take for the cloud to regenerate the 20 or 30 coulombs which are taken away by the lightning bolt? This can be seen by measuring, far from a cloud, the electric field produced by the cloud\u2019s dipole moment. In such measurements you see a sudden decrease in the field when the lightning strikes, and then an exponential return to the previous value with a time constant which is slightly different for different cases but which is in the neighborhood of 5 seconds. It takes a thunderstorm only 5 seconds after each lightning stroke to build its charge up again. That doesn\u2019t necessarily mean that another stroke is going to occur in exactly 5 seconds every time, because, of course, the geometry is changed, and so on. The strokes occur more or less irregularly, but the important point is that it takes about 5 seconds to recreate the original condition. Thus there are approximately 4 amperes of current in the generating machine of the thunderstorm. This means that any model made to explain how this storm generates its electricity must be one with plenty of juice\u2014it must be a big, rapidly operating device. Before we go further we shall consider something which is almost certainly completely irrelevant, but nevertheless interesting, because it does show the effect of an electric field on water drops. We say that it may be irrelevant because it relates to an experiment one can do in the laboratory with a stream of water to show the rather strong effects of the electric field on drops of water. In a thunderstorm there is no stream of water; there is a cloud of condensing ice and drops of water. So the question of the mechanisms at work in a thunderstorm is probably not at all related to what you can see in the simple experiment we will describe. If you take a small nozzle connected to a water faucet and direct it upward at a steep angle, as in Fig. 9\u201312, the water will come out in a fine stream that eventually breaks up into a spray of fine drops. If you now put an electric field across the stream at the nozzle (by bringing up a charged rod, for example), the form of the stream will change. With a weak electric field you will find that the stream breaks up into a smaller number of large-sized drops. But if you apply a stronger field, the stream breaks up into many, many fine drops\u2014smaller than before.1 With a weak electric field there is a tendency to inhibit the breakup of the stream into drops. With a stronger field, however, there is an increase in the tendency to separate into drops. The explanation of these effects is probably the following. If we have the stream of water coming out of the nozzle and we put a small electric field across it one side of the water gets slightly positive and the other side gets slightly negative. Then, when the stream breaks, the drops on one side may be positive, and those on the other side may be negative. They will attract each other and will have a tendency to stick together more than they would have before\u2014the stream doesn\u2019t break up as much. On the other hand, if the field is stronger, the charge in each one of the drops gets much larger, and there is a tendency for the charge itself to help break up the drops through their own repulsion. Each drop will break into many smaller ones, each carrying a charge, so that they are all repelled, and spread out so rapidly. So as we increase the field, the stream becomes more finely separated. The only point we wish to make is that in certain circumstances electric fields can have considerable influence on the drops. The exact machinery by which something happens in a thunderstorm is not at all known, and is not at all necessarily related to what we have just described. We have included it just so that you will appreciate the complexities that could come into play. In fact, nobody has a theory applicable to clouds based on that idea. We would like to describe two theories which have been invented to account for the separation of the charges in a thunderstorm. All the theories involve the idea that there should be some charge on the precipitation particles and a different charge in the air. Then by the movement of the precipitation particles\u2014the water or the ice\u2014through the air there is a separation of electric charge. The only question is: How does the charging of the drops begin? One of the older theories is called the \u201cbreaking-drop\u201d theory. Somebody discovered that if you have a drop of water that breaks into two pieces in a windstream, there is positive charge on the water and negative charge in the air. This breaking-drop theory has several disadvantages, among which the most serious is that the sign is wrong. Second, in the large number of temperate-zone thunderstorms which do exhibit lightning, the precipitation effects at high altitudes are in ice, not in water. From what we have just said, we note that if we could imagine some way for the charge to be different at the top and bottom of a drop and if we could also see some reason why drops in a high-speed airstream would break up into unequal pieces\u2014a large one in the front and a smaller one in the back because of the motion through the air or something\u2014we would have a theory. (Different from any known theory!) Then the small drops would not fall through the air as fast as the big ones, because of the air resistance, and we would get a charge separation. You see, it is possible to concoct all kinds of possibilities. One of the more ingenious theories, which is more satisfactory in many respects than the breaking-drop theory, is due to C. T. R. Wilson. We will describe it, as Wilson did, with reference to water drops, although the same phenomenon would also work with ice. Suppose we have a water drop that is falling in the electric field of about 100 volts per meter toward the negatively charged earth. The drop will have an induced dipole moment\u2014with the bottom of the drop positive and the top of the drop negative, as drawn in Fig. 9\u201313. Now there are in the air the \u201cnuclei\u201d that we mentioned earlier\u2014the large slow-moving ions. (The fast ions do not have an important effect here.) Suppose that as a drop comes down, it approaches a large ion. If the ion is positive, it is repelled by the positive bottom of the drop and is pushed away. So it does not become attached to the drop. If the ion were to approach from the top, however, it might attach to the negative, top side. But since the drop is falling through the air, there is an air drift relative to it, going upwards, which carries the ions away if their motion through the air is slow enough. Thus the positive ions cannot attach at the top either. This would apply, you see, only to the large, slow-moving ions. The positive ions of this type will not attach themselves either to the front or the back of a falling drop. On the other hand, as the large, slow, negative ions are approached by a drop, they will be attracted and will be caught. The drop will acquire negative charge\u2014the sign of the charge having been determined by the original potential difference on the entire earth\u2014and we get the right sign. Negative charge will be brought down to the bottom part of the cloud by the drops, and the positively charged ions which are left behind will be blown to the top of the cloud by the various updraft currents. The theory looks pretty good, and it at least gives the right sign. Also it doesn\u2019t depend on having liquid drops. We will see, when we learn about polarization in a dielectric, that pieces of ice will do the same thing. They also will develop positive and negative charges on their extremities when they are in an electric field. There are, however, some problems even with this theory. First of all, the total charge involved in a thunderstorm is very high. After a short time, the supply of large ions would get used up. So Wilson and others have had to propose that there are additional sources of the large ions. Once the charge separation starts, very large electric fields are developed, and in these large fields there may be places where the air will become ionized. If there is a highly charged point, or any small object like a drop, it may concentrate the field enough to make a \u201cbrush discharge.\u201d When there is a strong enough electric field\u2014let us say it is positive\u2014electrons will fall into the field and will pick up a lot of speed between collisions. Their speed will be such that in hitting another atom they will tear electrons off at that atom, leaving positive charges behind. These new electrons also pick up speed and collide with more electrons. So a kind of chain reaction or avalanche occurs, and there is a rapid accumulation of ions. The positive charges are left near their original positions, so the net effect is to distribute the positive charge on the point into a region around the point. Then, of course, there is no longer a strong field, and the process stops. This is the character of a brush discharge. It is possible that the fields may become strong enough in the cloud to produce a little bit of brush discharge; there may also be other mechanisms, once the thing is started, to produce a large amount of ionization. But nobody knows exactly how it works. So the fundamental origin of lightning is really not thoroughly understood. We know it comes from the thunderstorms. (And we know, of course, that thunder comes from the lightning\u2014from the thermal energy released by the bolt.) At least we can understand, in part, the origin of atmospheric electricity. Due to the air currents, ions, and water drops on ice particles in a thunderstorm, positive and negative charges are separated. The positive charges are carried upward to the top of the cloud (see Fig. 9\u201311), and the negative charges are dumped into the ground in lightning strokes. The positive charges leave the top of the cloud, enter the high-altitude layers of more highly conducting air, and spread throughout the earth. In regions of clear weather, the positive charges in this layer are slowly conducted to the earth by the ions in the air\u2014ions formed by cosmic rays, by the sea, and by man\u2019s activities. The atmosphere is a busy electrical machine! The first evidence of what happens in a lightning stroke was obtained in photographs taken with a camera held by hand and moved back and forth with the shutter open\u2014while pointed toward a place where lightning was expected. The first photographs obtained this way showed clearly that lightning strokes are usually multiple discharges along the same path. Later, the \u201cBoys\u201d camera, which has two lenses mounted 180 \u2218 apart on a rapidly rotating disc, was developed. The image made by each lens moves across the film\u2014the picture is spread out in time. If, for instance, the stroke repeats, there will be two images side by side. By comparing the images of the two lenses, it is possible to work out the details of the time sequence of the flashes. Figure 9\u201314 shows a photograph taken with a \u201cBoys\u201d camera. We will now describe the lightning. Again, we don\u2019t understand exactly how it works. We will give a qualitative description of what it looks like, but we won\u2019t go into any details of why it does what it appears to do. We will describe only the ordinary case of the cloud with a negative bottom over flat country. Its potential is much more negative than the earth underneath, so negative electrons will be accelerated toward the earth. What happens is the following. It all starts with a thing called a \u201cstep leader,\u201d which is not as bright as the stroke of lightning. On the photographs one can see a little bright spot at the beginning that starts from the cloud and moves downward very rapidly\u2014at a sixth of the speed of light! It goes only about 50 meters and stops. It pauses for about 50 microseconds, and then takes another step. It pauses again and then goes another step, and so on. It moves in a series of steps toward the ground, along a path like that shown in Fig. 9\u201315. In the leader there are negative charges from the cloud; the whole column is full of negative charge. Also, the air is becoming ionized by the rapidly moving charges that produce the leader, so the air becomes a conductor along the path traced out. The moment the leader touches the ground, we have a conducting \u201cwire\u201d that runs all the way up to the cloud and is full of negative charge. Now, at last, the negative charge of the cloud can simply escape and run out. The electrons at the bottom of the leader are the first ones to realize this; they dump out, leaving positive charge behind that attracts more negative charge from higher up in the leader, which in its turn pours out, etc. So finally all the negative charge in a part of the cloud runs out along the column in a rapid and energetic way. So the lightning stroke you see runs upwards from the ground, as indicated in Fig. 9\u201316. In fact, this main stroke\u2014by far the brightest part\u2014is called the return stroke. It is what produces the very bright light, and the heat, which by causing a rapid expansion of the air makes the thunder clap. The current in a lightning stroke is about 10,000 amperes at its peak, and it carries down about 20 coulombs. But we are still not finished. After a time of, perhaps, a few hundredths of a second, when the return stroke has disappeared, another leader comes down. But this time there are no pauses. It is called a \u201cdart leader\u201d this time, and it goes all the way down\u2014from top to bottom in one swoop. It goes full steam on exactly the old track, because there is enough debris there to make it the easiest route. The new leader is again full of negative charge. The moment it touches the ground\u2014zing!\u2014there is a return stroke going straight up along the path. So you see the lightning strike again, and again, and again. Sometimes it strikes only once or twice, sometimes five or ten times\u2014once as many as 42 times on the same track was seen\u2014but always in rapid succession. Sometimes things get even more complicated. For instance, after one of its pauses the leader may develop a branch by sending out two steps\u2014both toward the ground but in somewhat different directions, as shown in Fig. 9\u201315. What happens then depends on whether one branch reaches the ground definitely before the other. If that does happen, the bright return stroke (of negative charge dumping into the ground) works its way up along the branch that touches the ground, and when it reaches and passes the branching point on its way up to the cloud, a bright stroke appears to go down the other branch. Why? Because negative charge is dumping out and that is what lights up the bolt. This charge begins to move at the top of the secondary branch, emptying successive, longer pieces of the branch, so the bright lightning bolt appears to work its way down that branch, at the same time as it works up toward the cloud. If, however, one of these extra leader branches happens to have reached the ground almost simultaneously with the original leader, it can sometimes happen that the dart leader of the second stroke will take the second branch. Then you will see the first main flash in one place and the second flash in another place. It is a variant of the original idea. Also, our description is oversimplified for the region very near the ground. When the step leader gets to within a hundred meters or so from the ground, there is evidence that a discharge rises from the ground to meet it. Presumably, the field gets big enough for a brush-type discharge to occur. If, for instance, there is a sharp object, like a building with a point at the top, then as the leader comes down nearby the fields are so large that a discharge starts from the sharp point and reaches up to the leader. The lightning tends to strike such a point. It has apparently been known for a long time that high objects are struck by lightning. There is a quotation of Artabanus, the advisor to Xerxes, giving his master advice on a contemplated attack on the Greeks\u2014during Xerxes\u2019 campaign to bring the entire known world under the control of the Persians. Artabanus said, \u201cSee how God with his lightning always smites the bigger animals and will not suffer them to wax insolent, while these of a lesser bulk chafe him not. How likewise his bolts fall ever on the highest houses and tallest trees.\u201d And then he explains the reason: \u201cSo, plainly, doth he love to bring down everything that exalts itself.\u201d Do you think\u2014now that you know a true account of lightning striking tall trees\u2014that you have a greater wisdom in advising kings on military matters than did Artabanus 2400 years ago? Do not exalt yourself. You could only do it less poetically."
    },
    {
        "input": "Solutions of Maxwells Equations in Free Space",
        "output": "In Chapter 18 we had reached the point where we had the Maxwell equations in complete form. All there is to know about the classical theory of the electric and magnetic fields can be found in the four equations: I. \u2207\u22c5E = \u03c1 \u03f50 II. \u2207\u00d7E = \u2212 \u2202B \u2202t III. \u2207\u22c5B = 0 IV. c2 \u2207\u00d7B = j \u03f50 + \u2202E \u2202t When we put all these equations together, a remarkable new phenomenon occurs: fields generated by moving charges can leave the sources and travel alone through space. We considered a special example in which an infinite current sheet is suddenly turned on. After the current has been on for the time t , there are uniform electric and magnetic fields extending out the distance ct from the source. Suppose that the current sheet lies in the yz -plane with a surface current density J going toward positive y . The electric field will have only a y -component, and the magnetic field, only a z -component. The field components are given by Ey=cBz=\u2212 J 2\u03f50c , for positive values of x less than ct . For larger x the fields are zero. There are, of course, similar fields extending the same distance from the current sheet in the negative x -direction. In Fig. 20\u20131 we show a graph of the magnitude of the fields as a function of x at the instant t . As time goes on, the \u201cwavefront\u201d at ct moves outward in x at the constant velocity c . Now consider the following sequence of events. We turn on a current of unit strength for a while, then suddenly increase the current strength to three units, and hold it constant at this value. What do the fields look like then? We can see what the fields will look like in the following way. First, we imagine a current of unit strength that is turned on at t=0 and left constant forever. The fields for positive x are then given by the graph in part (a) of Fig. 20\u20132. Next, we ask what would happen if we turn on a steady current of two units at the time t1 . The fields in this case will be twice as high as before, but will extend out in x only the distance c(t\u2212t1) , as shown in part (b) of the figure. When we add these two solutions, using the principle of superposition, we find that the sum of the two sources is a current of one unit for the time from zero to t1 and a current of three units for times greater than t1 . At the time t the fields will vary with x as shown in part (c) of Fig. 20\u20132. Now let\u2019s take a more complicated problem. Consider a current which is turned on to one unit for a while, then turned up to three units, and later turned off to zero. What are the fields for such a current? We can find the solution in the same way\u2014by adding the solutions of three separate problems. First, we find the fields for a step current of unit strength. (We have solved that problem already.) Next, we find the fields produced by a step current of two units. Finally, we solve for the fields of a step current of minus three units. When we add the three solutions, we will have a current which is one unit strong from t=0 to some later time, say t1 , then three units strong until a still later time t2 , and then turned off\u2014that is, to zero. A graph of the current as a function of time is shown in Fig. 20\u20133(a). When we add the three solutions for the electric field, we find that its variation with x , at a given instant t , is as shown in Fig. 20\u20133(b). The field is an exact representation of the current. The field distribution in space is a nice graph of the current variation with time\u2014only drawn backwards. As time goes on the whole picture moves outward at the speed c , so there is a little blob of field, travelling toward positive x , which contains a completely detailed memory of the history of all the current variations. If we were to stand miles away, we could tell from the variation of the electric or magnetic field exactly how the current had varied at the source. You will also notice that long after all activity at the source has completely stopped and all charges and currents are zero, the block of field continues to travel through space. We have a distribution of electric and magnetic fields that exist independently of any charges or currents. That is the new effect that comes from the complete set of Maxwell\u2019s equations. If we want, we can give a complete mathematical representation of the analysis we have just done by writing that the electric field at a given place and a given time is proportional to the current at the source, only not at the same time, but at the earlier time t\u2212x/c . We can write Ey(t)=\u2212 J(t\u2212x/c) 2\u03f50c . We have, believe it or not, already derived this same equation from another point of view in Vol. I, when we were dealing with the theory of the index of refraction. Then, we had to figure out what fields were produced by a thin layer of oscillating dipoles in a sheet of dielectric material with the dipoles set in motion by the electric field of an incoming electromagnetic wave. Our problem was to calculate the combined fields of the original wave and the waves radiated by the oscillating dipoles. How could we have calculated the fields generated by moving charges when we didn\u2019t have Maxwell\u2019s equations? At that time we took as our starting point (without any derivation) a formula for the radiation fields produced at large distances from an accelerating point charge. If you will look in Chapter 31 of Vol. I, you will see that Eq. (31.9) there is just the same as the Eq. (20.3) that we have just written down. Although our earlier derivation was correct only at large distances from the source, we see now that the same result continues to be correct even right up to the source. We want now to look in a general way at the behavior of electric and magnetic fields in empty space far away from the sources, i.e., from the currents and charges. Very near the sources\u2014near enough so that during the delay in transmission, the source has not had time to change much\u2014the fields are very much the same as we have found in what we called the electrostatic or magnetostatic cases. If we go out to distances large enough so that the delays become important, however, the nature of the fields can be radically different from the solutions we have found. In a sense, the fields begin to take on a character of their own when they have gone a long way from all the sources. So we can begin by discussing the behavior of the fields in a region where there are no currents or charges. Suppose we ask: What kind of fields can there be in regions where \u03c1 and j are both zero? In Chapter 18 we saw that the physics of Maxwell\u2019s equations could also be expressed in terms of differential equations for the scalar and vector potentials: \u22072\u03d5\u2212 1 c2 \u22022\u03d5 \u2202t2 =\u2212 \u03c1 \u03f50 , \u22072A\u2212 1 c2 \u22022A \u2202t2 =\u2212 j \u03f50c2 . If \u03c1 and j are zero, these equations take on the simpler form \u22072\u03d5\u2212 1 c2 \u22022\u03d5 \u2202t2 =0, \u22072A\u2212 1 c2 \u22022A \u2202t2 =0. Thus in free space the scalar potential \u03d5 and each component of the vector potential A all satisfy the same mathematical equation. Suppose we let \u03c8 (psi) stand for any one of the four quantities \u03d5 , Ax , Ay , Az ; then we want to investigate the general solutions of the following equation: \u22072\u03c8\u2212 1 c2 \u22022\u03c8 \u2202t2 =0. This equation is called the three-dimensional wave equation\u2014three-dimensional, because the function \u03c8 may depend in general on x , y , and z , and we need to worry about variations in all three coordinates. This is made clear if we write out explicitly the three terms of the Laplacian operator: \u22022\u03c8 \u2202x2 + \u22022\u03c8 \u2202y2 + \u22022\u03c8 \u2202z2 \u2212 1 c2 \u22022\u03c8 \u2202t2 =0. In free space, the electric fields E and B also satisfy the wave equation. For example, since B=\u2207\u00d7A , we can get a differential equation for B by taking the curl of Eq. (20.7). Since the Laplacian is a scalar operator, the order of the Laplacian and curl operations can be interchanged: \u2207\u00d7( \u2207 2 A)= \u2207 2 (\u2207\u00d7A)= \u2207 2 B. Similarly, the order of the operations curl and \u2202/\u2202t can be interchanged: \u2207\u00d7 1 c 2 \u2202 2 A \u2202 t 2 = 1 c 2 \u2202 2 \u2202 t 2 (\u2207\u00d7A)= 1 c 2 \u2202 2 B \u2202 t 2 . Using these results, we get the following differential equation for B : \u2207 2 B\u2212 1 c 2 \u2202 2 B \u2202 t 2 =0. (20.10) So each component of the magnetic field B satisfies the three-dimensional wave equation. Similarly, using the fact that E=\u2212\u2207\u03d5\u2212\u2202A/\u2202t , it follows that the electric field E in free space also satisfies the three-dimensional wave equation: \u2207 2 E\u2212 1 c 2 \u2202 2 E \u2202 t 2 =0. (20.11) All of our electromagnetic fields satisfy the same wave equation, Eq. (20.8). We might well ask: What is the most general solution to this equation? However, rather than tackling that difficult question right away, we will look first at what can be said in general about those solutions in which nothing varies in y and z . (Always do an easy case first so that you can see what is going to happen, and then you can go to the more complicated cases.) Let\u2019s suppose that the magnitudes of the fields depend only upon x \u2014that there are no variations of the fields with y and z . We are, of course, considering plane waves again. We should expect to get results something like those in the previous section. In fact, we will find precisely the same answers. You may ask: \u201cWhy do it all over again?\u201d It is important to do it again, first, because we did not show that the waves we found were the most general solutions for plane waves, and second, because we found the fields only from a very particular kind of current source. We would like to ask now: What is the most general kind of one-dimensional wave there can be in free space? We cannot find that by seeing what happens for this or that particular source, but must work with greater generality. Also we are going to work this time with differential equations instead of with integral forms. Although we will get the same results, it is a way of practicing back and forth to show that it doesn\u2019t make any difference which way you go. You should know how to do things every which way, because when you get a hard problem, you will often find that only one of the various ways is tractable. We could consider directly the solution of the wave equation for some electromagnetic quantity. Instead, we want to start right from the beginning with Maxwell\u2019s equations in free space so that you can see their close relationship to the electromagnetic waves. So we start with the equations in (20.1), setting the charges and currents equal to zero. They become I. II. III. IV. c 2 \u2207\u22c5E \u2207\u00d7E \u2207\u22c5B \u2207\u00d7B = = = = 0 \u2212 \u2202B \u2202t 0 \u2202E \u2202t (20.12) We write the first equation out in components: \u2207\u22c5E= \u2202 E x \u2202x + \u2202 E y \u2202y + \u2202 E z \u2202z =0. (20.13) We are assuming that there are no variations with y and z , so the last two terms are zero. This equation then tells us that \u2202 E x \u2202x =0. (20.14) Its solution is that E x , the component of the electric field in the x -direction, is a constant in space. If you look at IV in (20.12), supposing no B -variation in y and z either, you can see that E x is also constant in time. Such a field could be the steady dc field from some charged condenser plates a long distance away. We are not interested now in such an uninteresting static field; we are at the moment interested only in dynamically varying fields. For dynamic fields, E x =0 . We have then the important result that for the propagation of plane waves in any direction, the electric field must be at right angles to the direction of propagation. It can, of course, still vary in a complicated way with the coordinate x . The transverse E -field can always be resolved into two components, say the y -component and the z -component. So let\u2019s first work out a case in which the electric field has only one transverse component. We\u2019ll take first an electric field that is always in the y -direction, with zero z -component. Evidently, if we solve this problem we can also solve for the case where the electric field is always in the z -direction. The general solution can always be expressed as the superposition of two such fields. How easy our equations now get. The only component of the electric field that is not zero is E y , and all derivatives\u2014except those with respect to x \u2014are zero. The rest of Maxwell\u2019s equations then become quite simple. Let\u2019s look next at the second of Maxwell\u2019s equations [II of Eq. (20.12)]. Writing out the components of the curl E , we have (\u2207\u00d7E ) x (\u2207\u00d7E ) y (\u2207\u00d7E ) z = \u2202 E z \u2202y = \u2202 E x \u2202z = \u2202 E y \u2202x \u2212 \u2202 E y \u2202z \u2212 \u2202 E z \u2202x \u2212 \u2202 E x \u2202y =0, =0, = \u2202 E y \u2202x . The x -component of \u2207\u00d7E is zero because the derivatives with respect to y and z are zero. The y -component is also zero; the first term is zero because the derivative with respect to z is zero, and the second term is zero because E z is zero. The only components of the curl of E that is not zero is the z -component, which is equal to \u2202 E y /\u2202x . Setting the three components of \u2207\u00d7E equal to the corresponding components of \u2212\u2202B/\u2202t , we can conclude the following: \u2202 B x \u2202t =0, \u2202 B y \u2202t =0. \u2202 B z \u2202t =\u2212 \u2202 E y \u2202x . (20.15) (20.16) Since the x -component of the magnetic field and the y -component of the magnetic field both have zero time derivatives, these two components are just constant fields and correspond to the magnetostatic solutions we found earlier. Somebody may have left some permanent magnets near where the waves are propagating. We will ignore these constant fields and set B x and B y equal to zero. Incidentally, we would already have concluded that the x -component of B should be zero for a different reason. Since the divergence of B is zero (from the third Maxwell equation), applying the same arguments we used above for the electric field, we would conclude that the longitudinal component of the magnetic field can have no variation with x . Since we are ignoring such uniform fields in our wave solutions, we would have set B x equal to zero. In plane electromagnetic waves the B -field, as well as the E -field, must be directed at right angles to the direction of propagation. Equation (20.16) gives us the additional proposition that if the electric field has only a y -component, the magnetic field will have only a z -component. So E and B are at right angles to each other. This is exactly what happened in the special wave we have already considered. We are now ready to use the last of Maxwell\u2019s equations for free space [IV of Eq. (20.12)]. Writing out the components, we have c 2 (\u2207\u00d7B ) x c 2 (\u2207\u00d7B ) y c 2 (\u2207\u00d7B ) z = c 2 \u2202 B z \u2202y = c 2 \u2202 B x \u2202z = c 2 \u2202 B y \u2202x \u2212 c 2 \u2202 B y \u2202z \u2212 c 2 \u2202 B z \u2202x \u2212 c 2 \u2202 B x \u2202y = \u2202 E x \u2202t , = \u2202 E y \u2202t , = \u2202 E z \u2202t . (20.17) Of the six derivatives of the components of B , only the term \u2202 B z /\u2202x is not equal to zero. So the three equations give us simply \u2212 c 2 \u2202 B z \u2202x = \u2202 E y \u2202t . (20.18) The result of all our work is that only one component each of the electric and magnetic fields is not zero, and that these components must satisfy Eqs. (20.16) and (20.18). The two equations can be combined into one if we differentiate the first with respect to x and the second with respect to t ; the left-hand sides of the two equations will then be the same (except for the factor c 2 ). So we find that E y satisfies the equation \u2202 2 E y \u2202 x 2 \u2212 1 c 2 \u2202 2 E y \u2202 t 2 =0. (20.19) We have seen the same differential equation before, when we studied the propagation of sound. It is the wave equation for one-dimensional waves. You should note that in the process of our derivation we have found something more than is contained in Eq. (20.11). Maxwell\u2019s equations have given us the further information that electromagnetic waves have field components only at right angles to the direction of the wave propagation. Let\u2019s review what we know about the solutions of the one-dimensional wave equation. If any quantity \u03c8 satisfies the one-dimensional wave equation \u2202 2 \u03c8 \u2202 x 2 \u2212 1 c 2 \u2202 2 \u03c8 \u2202 t 2 =0, (20.20) then one possible solution is a function \u03c8(x,t) of the form \u03c8(x,t)=f(x\u2212ct), (20.21) that is, some function of the single variable (x\u2212ct) . The function f(x\u2212ct) represents a \u201crigid\u201d pattern in x which travels toward positive x at the speed c (see Fig. 20\u20134). For example, if the function f has a maximum when its argument is zero, then for t=0 the maximum of \u03c8 , will occur at x=0 . At some later time, say t=10 , \u03c8 will have its maximum at x=10c . As time goes on, the maximum moves toward positive x at the speed c . Sometimes it is more convenient to say that a solution of the one-dimensional wave equation is a function of (t\u2212x/c) . However, this is saying the same thing, because any function of (t\u2212x/c) is also a function of (x\u2212ct) : F(t\u2212x/c)=F[\u2212 x\u2212ct c ]=f(x\u2212ct). [ ] Let\u2019s show that f(x\u2212ct) is indeed a solution of the wave equation. Since it is a function of only one variable\u2014the variable (x\u2212ct) \u2014we will let f \u2032 represent the derivative of f with respect to its variable and f \u2032\u2032 represent the second derivative of f . Differentiating Eq. (20.21) with respect to x , we have \u2202\u03c8 \u2202x = f \u2032 (x\u2212ct), \u2202 \u03c8 since the derivative of (x\u2212ct) with respect to x is 1 . The second derivative of \u03c8 , with respect to x is clearly \u2202 2 \u03c8 \u2202 x 2 = f \u2032\u2032 (x\u2212ct). (20.22) Taking derivatives of \u03c8 with respect to t , we find \u2202\u03c8 \u2202t = f \u2032 (x\u2212ct)(\u2212c), \u2202 2 \u03c8 \u2202 t 2 =+ c 2 f \u2032\u2032 (x\u2212ct). (20.23) We see that \u03c8 does indeed satisfy the one-dimensional wave equation. You may be wondering: \u201cIf I have the wave equation, how do I know that I should take f(x\u2212ct) as a solution? I don\u2019t like this backward method. Isn\u2019t there some forward way to find the solution?\u201d Well, one good forward way is to know the solution. It is possible to \u201ccook up\u201d an apparently forward mathematical argument, especially because we know what the solution is supposed to be, but with an equation as simple as this we don\u2019t have to play games. Soon you will get so that when you see Eq. (20.20), you nearly simultaneously see \u03c8=f(x\u2212ct) as a solution. (Just as now when you see the integral of x 2 dx , you know right away that the answer is x 3 /3 .) Actually you should also see a little more. Not only is any function of (x\u2212ct) a solution, but any function of (x+ct) is also a solution. Since the wave equation contains only c 2 , changing the sign of c makes no difference. In fact, the most general solution of the one-dimensional wave equation is the sum of two arbitrary functions, one of (x\u2212ct) and the other of (x+ct) : \u03c8=f(x\u2212ct)+g(x+ct). (20.24) The first term represents a wave travelling toward positive x , and the second term an arbitrary wave travelling toward negative x . The general solution is the superposition of two such waves both existing at the same time. We will leave the following amusing question for you to think about. Take a function \u03c8 of the following form: \u03c8=coskxcoskct. \u03c8 k k This equation isn\u2019t in the form of a function of (x\u2212ct) or of (x+ct) . Yet you can easily show that this function is a solution of the wave equation by direct substitution into Eq. (20.20). How can we then say that the general solution is of the form of Eq. (20.24)? Applying our conclusions about the solution of the wave equation to the y -component of the electric field, E y , we conclude that E y can vary with x in any arbitrary fashion. However, the fields which do exist can always be considered as the sum of two patterns. One wave is sailing through space in one direction with speed c , with an associated magnetic field perpendicular to the electric field; another wave is travelling in the opposite direction with the same speed. Such waves correspond to the electromagnetic waves that we know about\u2014light, radiowaves, infrared radiation, ultraviolet radiation, x-rays, and so on. We have already discussed the radiation of light in great detail in Vol. I. Since everything we learned there applies to any electromagnetic wave, we don\u2019t need to consider in great detail here the behavior of these waves. We should perhaps make a few further remarks on the question of the polarization of the electromagnetic waves. In our solution we chose to consider the special case in which the electric field has only a y -component. There is clearly another solution for waves travelling in the plus or minus x -direction, with an electric field which has only a z -component. Since Maxwell\u2019s equations are linear, the general solution for one-dimensional waves propagating in the x -direction is the sum of waves of E y and waves of E z . This general solution is summarized in the following equations: E E y E z B c B z c B y =(0, E y , E z ) =f(x\u2212ct)+g(x+ct) =F(x\u2212ct)+G(x+ct) =(0, B y , B z ) =f(x\u2212ct)\u2212g(x+ct) =\u2212F(x\u2212ct)+G(x+ct). (20.25) Such electromagnetic waves have an E -vector whose direction is not constant but which gyrates around in some arbitrary way in the yz -plane. At every point the magnetic field is always perpendicular to the electric field and to the direction of propagation. If there are only waves travelling in one direction, say the positive x -direction, there is a simple rule which tells the relative orientation of the electric and magnetic fields. The rule is that the cross product E\u00d7B \u2014which is, of course, a vector at right angles to both E and B \u2014points in the direction in which the wave is travelling. If E is rotated into B by a right-hand screw, the screw points in the direction of the wave velocity. (We shall see later that the vector E\u00d7B has a special physical significance: it is a vector which describes the flow of energy in an electromagnetic field.) We want now to turn to the subject of three-dimensional waves. We have already seen that the vector E satisfies the wave equation. It is also easy to arrive at the same conclusion by arguing directly from Maxwell\u2019s equations. Suppose we start with the equation \u2207\u00d7E=\u2212 \u2202B \u2202t \u2202 B and take the curl of both sides: \u2207\u00d7(\u2207\u00d7E)=\u2212 \u2202 \u2202t (\u2207\u00d7B). (20.26) You will remember that the curl of the curl of any vector can be written as the sum of two terms, one involving the divergence and the other the Laplacian, \u2207\u00d7(\u2207\u00d7E)=\u2207(\u2207\u22c5E)\u2212 \u2207 2 E. 2 In free space, however, the divergence of E is zero, so only the Laplacian term remains. Also, from the fourth of Maxwell\u2019s equations in free space [Eq. (20.12)] the time derivative of c 2 \u2207\u00d7B is the second derivative of E with respect to t : c 2 \u2202 \u2202t (\u2207\u00d7B)= \u2202 2 E \u2202 t 2 . 2 Equation (20.26) then becomes \u2207 2 E= 1 c 2 \u2202 2 E \u2202 t 2 , 2 which is the three-dimensional wave equation. Written out in all its glory, this equation is, of course, \u2202 2 E \u2202 x 2 + \u2202 2 E \u2202 y 2 + \u2202 2 E \u2202 z 2 \u2212 1 c 2 \u2202 2 E \u2202 t 2 =0. (20.27) How shall we find the general wave solution? The answer is that all the solutions of the three-dimensional wave equation can be represented as a superposition of the one-dimensional solutions we have already found. We obtained the equation for waves which move in the x -direction by supposing that the field did not depend on y and z . Obviously, there are other solutions in which the fields do not depend on x and z , representing waves going in the y -direction. Then there are solutions which do not depend on x and y , representing waves travelling in the z -direction. Or in general, since we have written our equations in vector form, the three-dimensional wave equation can have solutions which are plane waves moving in any direction at all. Again, since the equations are linear, we may have simultaneously as many plane waves as we wish, travelling in as many different directions. Thus the most general solution of the three-dimensional wave equation is a superposition of all sorts of plane waves moving in all sorts of directions. Try to imagine what the electric and magnetic fields look like at present in the space in this lecture room. First of all, there is a steady magnetic field; it comes from the currents in the interior of the earth\u2014that is, the earth\u2019s steady magnetic field. Then there are some irregular, nearly static electric fields produced perhaps by electric charges generated by friction as various people move about in their chairs and rub their coat sleeves against the chair arms. Then there are other magnetic fields produced by oscillating currents in the electrical wiring\u2014fields which vary at a frequency of 60 cycles per second, in synchronism with the generator at Boulder Dam. But more interesting are the electric and magnetic fields varying at much higher frequencies. For instance, as light travels from window to floor and wall to wall, there are little wiggles of the electric and magnetic fields moving along at 186,000 miles per second. Then there are also infrared waves travelling from the warm foreheads to the cold blackboard. And we have forgotten the ultraviolet light, the x-rays, and the radiowaves travelling through the room. Flying across the room are electromagnetic waves which carry music of a jazz band. There are waves modulated by a series of impulses representing pictures of events going on in other parts of the world, or of imaginary aspirins dissolving in imaginary stomachs. To demonstrate the reality of these waves it is only necessary to turn on electronic equipment that converts these waves into pictures and sounds. If we go into further detail to analyze even the smallest wiggles, there are tiny electromagnetic waves that have come into the room from enormous distances. There are now tiny oscillations of the electric field, whose crests are separated by a distance of one foot, that have come from millions of miles away, transmitted to the earth from the Mariner II space craft which has just passed Venus. Its signals carry summaries of information it has picked up about the planets (information obtained from electromagnetic waves that travelled from the planet to the space craft). There are very tiny wiggles of the electric and magnetic fields that are waves which originated billions of light years away\u2014from galaxies in the remotest corners of the universe. That this is true has been found by \u201cfilling the room with wires\u201d\u2014by building antennas as large as this room. Such radiowaves have been detected from places in space beyond the range of the greatest optical telescopes. Even they, the optical telescopes, are simply gatherers of electromagnetic waves. What we call the stars are only inferences, inferences drawn from the only physical reality we have yet gotten from them\u2014from a careful study of the unendingly complex undulations of the electric and magnetic fields reaching us on earth. There is, of course, more: the fields produced by lightning miles away, the fields of the charged cosmic ray particles as they zip through the room, and more, and more. What a complicated thing is the electric field in the space around you! Yet it always satisfies the three-dimensional wave equation. I have asked you to imagine these electric and magnetic fields. What do you do? Do you know how? How do I imagine the electric and magnetic field? What do I actually see? What are the demands of scientific imagination? Is it any different from trying to imagine that the room is full of invisible angels? No, it is not like imagining invisible angels. It requires a much higher degree of imagination to understand the electromagnetic field than to understand invisible angels. Why? Because to make invisible angels understandable, all I have to do is to alter their properties a little bit\u2014I make them slightly visible, and then I can see the shapes of their wings, and bodies, and halos. Once I succeed in imagining a visible angel, the abstraction required\u2014which is to take almost invisible angels and imagine them completely invisible\u2014is relatively easy. So you say, \u201cProfessor, please give me an approximate description of the electromagnetic waves, even though it may be slightly inaccurate, so that I too can see them as well as I can see almost invisible angels. Then I will modify the picture to the necessary abstraction.\u201d I\u2019m sorry I can\u2019t do that for you. I don\u2019t know how. I have no picture of this electromagnetic field that is in any sense accurate. I have known about the electromagnetic field a long time\u2014I was in the same position 25 years ago that you are now, and I have had 25 years more of experience thinking about these wiggling waves. When I start describing the magnetic field moving through space, I speak of the E - and B -fields and wave my arms and you may imagine that I can see them. I\u2019ll tell you what I see. I see some kind of vague shadowy, wiggling lines\u2014here and there is an E and B written on them somehow, and perhaps some of the lines have arrows on them\u2014an arrow here or there which disappears when I look too closely at it. When I talk about the fields swishing through space, I have a terrible confusion between the symbols I use to describe the objects and the objects themselves. I cannot really make a picture that is even nearly like the true waves. So if you have some difficulty in making such a picture, you should not be worried that your difficulty is unusual. Our science makes terrific demands on the imagination. The degree of imagination that is required is much more extreme than that required for some of the ancient ideas. The modern ideas are much harder to imagine. We use a lot of tools, though. We use mathematical equations and rules, and make a lot of pictures. What I realize now is that when I talk about the electromagnetic field in space, I see some kind of a superposition of all of the diagrams which I\u2019ve ever seen drawn about them. I don\u2019t see little bundles of field lines running about because it worries me that if I ran at a different speed the bundles would disappear, I don\u2019t even always see the electric and magnetic fields because sometimes I think I should have made a picture with the vector potential and the scalar potential, for those were perhaps the more physically significant things that were wiggling. Perhaps the only hope, you say, is to take a mathematical view. Now what is a mathematical view? From a mathematical view, there is an electric field vector and a magnetic field vector at every point in space; that is, there are six numbers associated with every point. Can you imagine six numbers associated with each point in space? That\u2019s too hard. Can you imagine even one number associated with every point? I cannot! I can imagine such a thing as the temperature at every point in space. That seems to be understandable. There is a hotness and coldness that varies from place to place. But I honestly do not understand the idea of a number at every point. So perhaps we should put the question: Can we represent the electric field by something more like a temperature, say like the displacement of a piece of jello? Suppose that we were to begin by imagining that the world was filled with thin jello and that the fields represented some distortion\u2014say a stretching or twisting\u2014of the jello. Then we could visualize the field. After we \u201csee\u201d what it is like we could abstract the jello away. For many years that\u2019s what people tried to do. Maxwell, Amp\u00e8re, Faraday, and others tried to understand electromagnetism this way. (Sometimes they called the abstract jello \u201cether.\u201d) But it turned out that the attempt to imagine the electromagnetic field in that way was really standing in the way of progress. We are unfortunately limited to abstractions, to using instruments to detect the field, to using mathematical symbols to describe the field, etc. But nevertheless, in some sense the fields are real, because after we are all finished fiddling around with mathematical equations\u2014with or without making pictures and drawings or trying to visualize the thing\u2014we can still make the instruments detect the signals from Mariner II and find out about galaxies a billion miles away, and so on. The whole question of imagination in science is often misunderstood by people in other disciplines. They try to test our imagination in the following way. They say, \u201cHere is a picture of some people in a situation. What do you imagine will happen next?\u201d When we say, \u201cI can\u2019t imagine,\u201d they may think we have a weak imagination. They overlook the fact that whatever we are allowed to imagine in science must be consistent with everything else we know: that the electric fields and the waves we talk about are not just some happy thoughts which we are free to make as we wish, but ideas which must be consistent with all the laws of physics we know. We can\u2019t allow ourselves to seriously imagine things which are obviously in contradiction to the known laws of nature. And so our kind of imagination is quite a difficult game. One has to have the imagination to think of something that has never been seen before, never been heard of before. At the same time the thoughts are restricted in a strait jacket, so to speak, limited by the conditions that come from our knowledge of the way nature really is. The problem of creating something which is new, but which is consistent with everything which has been seen before, is one of extreme difficulty. While I\u2019m on this subject I want to talk about whether it will ever be possible to imagine beauty that we can\u2019t see. It is an interesting question. When we look at a rainbow, it looks beautiful to us. Everybody says, \u201cOoh, a rainbow.\u201d (You see how scientific I am. I am afraid to say something is beautiful unless I have an experimental way of defining it.) But how would we describe a rainbow if we were blind? We are blind when we measure the infrared reflection coefficient of sodium chloride, or when we talk about the frequency of the waves that are coming from some galaxy that we can\u2019t see\u2014we make a diagram, we make a plot. For instance, for the rainbow, such a plot would be the intensity of radiation vs. wavelength measured with a spectrophotometer for each direction in the sky. Generally, such measurements would give a curve that was rather flat. Then some day, someone would discover that for certain conditions of the weather, and at certain angles in the sky, the spectrum of intensity as a function of wavelength would behave strangely; it would have a bump. As the angle of the instrument was varied only a little bit, the maximum of the bump would move from one wavelength to another. Then one day the physical review of the blind men might publish a technical article with the title \u201cThe Intensity of Radiation as a Function of Angle under Certain Conditions of the Weather.\u201d In this article there might appear a graph such as the one in Fig. 20\u20135. The author would perhaps remark that at the larger angles there was more radiation at long wavelengths, whereas for the smaller angles the maximum in the radiation came at shorter wavelengths. (From our point of view, we would say that the light at 40 \u2218 is predominantly green and the light at 42 \u2218 is predominantly red.) Now do we find the graph of Fig. 20\u20135 beautiful? It contains much more detail than we apprehend when we look at a rainbow, because our eyes cannot see the exact details in the shape of a spectrum. The eye, however, finds the rainbow beautiful. Do we have enough imagination to see in the spectral curves the same beauty we see when we look directly at the rainbow? I don\u2019t know. But suppose I have a graph of the reflection coefficient of a sodium chloride crystal as a function of wavelength in the infrared, and also as a function of angle. I would have a representation of how it would look to my eyes if they could see in the infrared\u2014perhaps some glowing, shiny \u201cgreen,\u201d mixed with reflections from the surface in a \u201cmetallic red.\u201d That would be a beautiful thing, but I don\u2019t know whether I can ever look at a graph of the reflection coefficient of NaCl measured with some instrument and say that it has the same beauty. On the other hand, even if we cannot see beauty in particular measured results, we can already claim to see a certain beauty in the equations which describe general physical laws. For example, in the wave equation (20.9), there\u2019s something nice about the regularity of the appearance of the x , the y , the z , and the t . And this nice symmetry in appearance of the x , y , z , and t suggests to the mind still a greater beauty which has to do with the four dimensions, the possibility that space has four-dimensional symmetry, the possibility of analyzing that and the developments of the special theory of relativity. So there is plenty of intellectual beauty associated with the equations. We have seen that there are solutions of the wave equation which correspond to plane waves, and that any electromagnetic wave can be described as a superposition of many plane waves. In certain special cases, however, it is more convenient to describe the wave field in a different mathematical form. We would like to discuss now the theory of spherical waves\u2014waves which correspond to spherical surfaces that are spreading out from some center. When you drop a stone into a lake, the ripples spread out in circular waves on the surface\u2014they are two-dimensional waves. A spherical wave is a similar thing except that it spreads out in three dimensions. Before we start describing spherical waves, we need a little mathematics. Suppose we have a function that depends only on the radial distance r from a certain origin\u2014in other words, a function that is spherically symmetric. Let\u2019s call the function \u03c8(r) , where by r we mean r= x 2 + y 2 + z 2 \u2212 \u2212 \u2212 \u2212 \u2212 \u2212 \u2212 \u2212 \u2212 \u2212 \u221a , the radial distance from the origin. In order to find out what functions \u03c8(r) satisfy the wave equation, we will need an expression for the Laplacian of \u03c8 . So we want to find the sum of the second derivatives of \u03c8 with respect to x , y , and z . We will use the notation that \u03c8 \u2032 (r) represents the derivative of \u03c8 with respect to r and \u03c8 \u2032\u2032 (r) represents the second derivative of \u03c8 with respect to r . First, we find the derivatives with respect to x . The first derivative is \u2202\u03c8(r) \u2202x = \u03c8 \u2032 (r) \u2202r \u2202x . \u2202 \u03c8 ( ) \u2202 The second derivative of \u03c8 with respect to x is \u2202 2 \u03c8 \u2202 x 2 = \u03c8 \u2032\u2032 ( \u2202r \u2202x ) 2 + \u03c8 \u2032 \u2202 2 r \u2202 x 2 . 2 2 We can evaluate the partial derivatives of r with respect to x from \u2202r \u2202x = x r , \u2202 2 r \u2202 x 2 = 1 r (1\u2212 x 2 r 2 ). 2 So the second derivative of \u03c8 with respect to x is \u2202 2 \u03c8 \u2202 x 2 = x 2 r 2 \u03c8 \u2032\u2032 + 1 r (1\u2212 x 2 r 2 ) \u03c8 \u2032 . (20.28) Likewise, \u2202 2 \u03c8 \u2202 y 2 \u2202 2 \u03c8 \u2202 z 2 = y 2 r 2 = z 2 r 2 \u03c8 \u2032\u2032 + 1 r (1\u2212 y 2 r 2 \u03c8 \u2032\u2032 + 1 r (1\u2212 z 2 r 2 ) \u03c8 \u2032 , ) \u03c8 \u2032 . (20.29) (20.30) The Laplacian is the sum of these three derivatives. Remembering that x 2 + y 2 + z 2 = r 2 , we get \u2207 2 \u03c8(r)= \u03c8 \u2032\u2032 (r)+ 2 r \u03c8 \u2032 (r). (20.31) It is often more convenient to write this equation in the following form: \u2207 2 \u03c8(r)= 1 r d 2 d r 2 (r\u03c8). (20.32) If you carry out the differentiation indicated in Eq. (20.32), you will see that the right-hand side is the same as in Eq. (20.31). If we wish to consider spherically symmetric fields which can propagate as spherical waves, our field quantity must be a function of both r and t . Suppose we ask, then, what functions \u03c8(r,t) are solutions of the three-dimensional wave equation \u2207 2 \u03c8(r,t)\u2212 1 c 2 \u2202 2 \u2202 t 2 \u03c8(r,t)=0. (20.33) Since \u03c8(r,t) depends only on the spatial coordinates through r , we can use the equation for the Laplacian we found above, Eq. (20.32). To be precise, however, since \u03c8 is also a function of t , we should write the derivatives with respect to r as partial derivatives. Then the wave equation becomes 1 r \u2202 2 \u2202 r 2 (r\u03c8)\u2212 1 c 2 \u2202 2 \u2202 t 2 \u03c8=0. 2 2 We must now solve this equation, which appears to be much more complicated than the plane wave case. But notice that if we multiply this equation by r , we get \u2202 2 \u2202 r 2 (r\u03c8)\u2212 1 c 2 \u2202 2 \u2202 t 2 (r\u03c8)=0. (20.34) This equation tells us that the function r\u03c8 satisfies the one-dimensional wave equation in the variable r . Using the general principle which we have emphasized so often, that the same equations always have the same solutions, we know that if r\u03c8 is a function only of (r\u2212ct) then it will be a solution of Eq. (20.34). So we know that spherical waves must have the form r\u03c8(r,t)=f(r\u2212ct). \u03c8 ( ) f ( ) Or, as we have seen before, we can equally well say that r\u03c8 can have the form r\u03c8=f(t\u2212r/c). \u03c8 f ( / ) Dividing by r , we find that the field quantity \u03c8 (whatever it may be) has the following form: \u03c8= f(t\u2212r/c) r . (20.35) Such a function represents a general spherical wave travelling outward from the origin at the speed c . If we forget about the r in the denominator for a moment, the amplitude of the wave as a function of the distance from the origin at a given time has a certain shape that travels outward at the speed c . The factor r in the denominator, however, says that the amplitude of the wave decreases in proportion to 1/r as the wave propagates. In other words, unlike a plane wave in which the amplitude remains constant as the wave runs along, in a spherical wave the amplitude steadily decreases, as shown in Fig. 20\u20136. This effect is easy to understand from a simple physical argument. We know that the energy density in a wave depends on the square of the wave amplitude. As the wave spreads, its energy is spread over larger and larger areas proportional to the radial distance squared. If the total energy is conserved, the energy density must fall as 1/ r 2 , and the amplitude of the wave must decrease as 1/r . So Eq. (20.35) is the \u201creasonable\u201d form for a spherical wave. We have disregarded the second possible solution to the one-dimensional wave equation: r\u03c8=g(t+r/c), \u03c8 ( / ) or \u03c8= g(t+r/c) r . ( / ) This also represents a spherical wave, but one which travels inward from large r toward the origin. We are now going to make a special assumption. We say, without any demonstration whatever, that the waves generated by a source are only the waves which go outward. Since we know that waves are caused by the motion of charges, we want to think that the waves proceed outward from the charges. It would be rather strange to imagine that before charges were set in motion, a spherical wave started out from infinity and arrived at the charges just at the time they began to move. That is a possible solution, but experience shows that when charges are accelerated the waves travel outward from the charges. Although Maxwell\u2019s equations would allow either possibility, we will put in an additional fact\u2014based on experience\u2014that only the outgoing wave solution makes \u201cphysical sense.\u201d We should remark, however, that there is an interesting consequence to this additional assumption: we are removing the symmetry with respect to time that exists in Maxwell\u2019s equations. The original equations for E and B , and also the wave equations we derived from them, have the property that if we change the sign of t , the equation is unchanged. These equations say that for every solution corresponding to a wave going in one direction there is an equally valid solution for a wave travelling in the opposite direction. Our statement that we will consider only the outgoing spherical waves is an important additional assumption. (A formulation of electrodynamics in which this additional assumption is avoided has been carefully studied. Surprisingly, in many circumstances it does not lead to physically absurd conclusions, but it would take us too far astray to discuss these ideas just now. We will talk about them a little more in Chapter 28.) We must mention another important point. In our solution for an outgoing wave, Eq. (20.35), the function \u03c8 is infinite at the origin. That is somewhat peculiar. We would like to have a wave solution which is smooth everywhere. Our solution must represent physically a situation in which there is some source at the origin. In other words, we have inadvertently made a mistake. We have not solved the free wave equation (20.33) everywhere; we have solved Eq. (20.33) with zero on the right everywhere, except at the origin. Our mistake crept in because some of the steps in our derivation are not \u201clegal\u201d when r=0 . Let\u2019s show that it is easy to make the same kind of mistake in an electrostatic problem. Suppose we want a solution of the equation for an electrostatic potential in free space, \u2207 2 \u03d5=0 . The Laplacian is equal to zero, because we are assuming that there are no charges anywhere. But what about a spherically symmetric solution to this equation\u2014that is, some function \u03d5 that depends only on r . Using the formula of Eq. (20.32) for the Laplacian, we have 1 r d 2 d r 2 (r\u03d5)=0. 2 Multiplying this equation by r , we have an equation which is readily integrated: d 2 d r 2 (r\u03d5)=0. 2 If we integrate once with respect to r , we find that the first derivative of r\u03d5 is a constant, which we may call a : d dr (r\u03d5)=a. d Integrating again, we find that r\u03d5 is of the form r\u03d5=ar+b, \u03d5 b where b is another constant of integration. So we have found that the following \u03d5 is a solution for the electrostatic potential in free space: \u03d5=a+ b r . b Something is evidently wrong. In the region where there are no electric charges, we know the solution for the electrostatic potential: the potential is everywhere a constant. That corresponds to the first term in our solution. But we also have the second term, which says that there is a contribution to the potential that varies as one over the distance from the origin. We know, however, that such a potential corresponds to a point charge at the origin. So, although we thought we were solving for the potential in free space, our solution also gives the field for a point source at the origin. Do you see the similarity between what happened now and what happened when we solved for a spherically symmetric solution to the wave equation? If there were really no charges or currents at the origin, there would not be spherical outgoing waves. The spherical waves must, of course, be produced by sources at the origin. In the next chapter we will investigate the connection between the outgoing electromagnetic waves and the currents and voltages which produce them."
    },
    {
        "input": "Propagation in a Crystal Lattice",
        "output": "You would, at first sight, think that a low-energy electron would have great difficulty passing through a solid crystal. The atoms are packed together with their centers only a few angstroms apart, and the effective diameter of the atom for electron scattering is roughly an angstrom or so. That is, the atoms are large, relative to their spacing, so that you would expect the mean free path between collisions to be of the order of a few angstroms\u2014which is practically nothing. You would expect the electron to bump into one atom or another almost immediately. Nevertheless, it is a ubiquitous phenomenon of nature that if the lattice is perfect, the electrons are able to travel through the crystal smoothly and easily\u2014almost as if they were in a vacuum. This strange fact is what lets metals conduct electricity so easily; it has also permitted the development of many practical devices. It is, for instance, what makes it possible for a transistor to imitate the radio tube. In a radio tube electrons move freely through a vacuum, while in the transistor they move freely through a crystal lattice. The machinery behind the behavior of a transistor will be described in this chapter; the next one will describe the application of these principles in various practical devices. The conduction of electrons in a crystal is one example of a very common phenomenon. Not only can electrons travel through crystals, but other \u201cthings\u201d like atomic excitations can also travel in a similar manner. So the phenomenon which we want to discuss appears in many ways in the study of the physics of the solid state. You will remember that we have discussed many examples of two-state systems. Let\u2019s now think of an electron which can be in either one of two positions, in each of which it is in the same kind of environment. Let\u2019s also suppose that there is a certain amplitude to go from one position to the other, and, of course, the same amplitude to go back, just as we have discussed for the hydrogen molecular ion in Section 10\u20131. The laws of quantum mechanics then give the following results. There are two possible states of definite energy for the electron. Each state can be described by the amplitude for the electron to be in each of the two basic positions. In either of the definite-energy states, the magnitudes of these two amplitudes are constant in time, and the phases vary in time with the same frequency. On the other hand, if we start the electron in one position, it will later have moved to the other, and still later will swing back again to the first position. The amplitude is analogous to the motions of two coupled pendulums. Now consider a perfect crystal lattice in which we imagine that an electron can be situated in a kind of \u201cpit\u201d at one particular atom and with some particular energy. Suppose also that the electron has some amplitude to move into a different pit at one of the nearby atoms. It is something like the two-state system\u2014but with an additional complication. When the electron arrives at the neighboring atom, it can afterward move on to still another position as well as return to its starting point. Now we have a situation analogous not to two coupled pendulums, but to an infinite number of pendulums all coupled together. It is something like what you see in one of those machines\u2014made with a long row of bars mounted on a torsion wire\u2014that is used in first-year physics to demonstrate wave propagation. If you have a harmonic oscillator which is coupled to another harmonic oscillator, and that one to another, and so on \u2026, and if you start an irregularity in one place, the irregularity will propagate as a wave along the line. The same situation exists if you place an electron at one atom of a long chain of atoms. Usually, the simplest way of analyzing the mechanical problem is not to think in terms of what happens if a pulse is started at a definite place, but rather in terms of steady-wave solutions. There exist certain patterns of displacements which propagate through the crystal as a wave of a single, fixed frequency. Now the same thing happens with the electron\u2014and for the same reason, because it\u2019s described in quantum mechanics by similar equations. You must appreciate one thing, however; the amplitude for the electron to be at a place is an amplitude, not a probability. If the electron were simply leaking from one place to another, like water going through a hole, the behavior would be completely different. For example, if we had two tanks of water connected by a tube to permit some leakage from one to the other, then the levels would approach each other exponentially. But for the electron, what happens is amplitude leakage and not just a plain probability leakage. And it\u2019s a characteristic of the imaginary term\u2014the i in the differential equations of quantum mechanics\u2014which changes the exponential solution to an oscillatory solution. What happens then is quite different from the leakage between interconnected tanks. We want now to analyze quantitatively the quantum mechanical situation. Imagine a one-dimensional system made of a long line of atoms as shown in Fig. 13\u20131(a). (A crystal is, of course, three-dimensional but the physics is very much the same; once you understand the one-dimensional case you will be able to understand what happens in three dimensions.) Next, we want to see what happens if we put a single electron on this line of atoms. Of course, in a real crystal there are already millions of electrons. But most of them (nearly all for an insulating crystal) take up positions in some pattern of motion each around its own atom\u2014and everything is quite stationary. However, we now want to think about what happens if we put an extra electron in. We will not consider what the other ones are doing because we suppose that to change their motion involves a lot of excitation energy. We are going to add an electron as if to produce one slightly bound negative ion. In watching what the one extra electron does we are making an approximation which disregards the mechanics of the inside workings of the atoms. Of course the electron could then move to another atom, transferring the negative ion to another place. We will suppose that just as in the case of an electron jumping between two protons, the electron can jump from one atom to the neighbor on either side with a certain amplitude. Now how do we describe such a system? What will be reasonable base states? If you remember what we did when we had only two possible positions, you can guess how it will go. Suppose that in our line of atoms the spacings are all equal; and that we number the atoms in sequence, as shown in Fig. 13\u20131(a). One of the base states is that the electron is at atom number 6 , another base state is that the electron is at atom number 7 , or at atom number 8 , and so on. We can describe the n th base state by saying that the electron is at atom number n . Let\u2019s say that this is the base state |n\u27e9 . Figure 13\u20131 shows what we mean by the three base states |n\u22121\u27e9,|n\u27e9,and |n+1\u27e9. | \u27e9 | \u27e9 and | \u27e9 Using these base states, any state |\u03d5\u27e9 of the electron in our one-dimensional crystal can be described by giving all the amplitudes \u27e8n|\u03d5\u27e9 that the state |\u03d5\u27e9 is in one of the base states\u2014which means the amplitude that it is located at one particular atom. Then we can write the state |\u03d5\u27e9 as a superposition of the base states |\u03d5\u27e9= \u2211 n |n\u27e9\u27e8n|\u03d5\u27e9. (13.1) Next, we are going to suppose that when the electron is at one atom, there is a certain amplitude that it will leak to the atom on either side. And we\u2019ll take the simplest case for which it can only leak to the nearest neighbors\u2014to get to the next-nearest neighbor, it has to go in two steps. We\u2019ll take that the amplitudes for the electron jump from one atom to the next is iA/\u210f (per unit time). For the moment we would like to write the amplitude \u27e8n|\u03d5\u27e9 to be on the n th atom as C n . Then Eq. (13.1) will be written |\u03d5\u27e9= \u2211 n |n\u27e9 C n . (13.2) If we knew each of the amplitudes C n at a given moment, we could take their absolute squares and get the probability that you would find the electron if you looked at atom n at that time. What will the situation be at some later time? By analogy with the two-state systems we have studied, we would propose that the Hamiltonian equations for this system should be made up of equations like this: i\u210f d C n (t) dt = E 0 C n (t)\u2212A C n+1 (t)\u2212A C n\u22121 (t). (13.3) The first coefficient on the right, E 0 , is, physically, the energy the electron would have if it couldn\u2019t leak away from one of the atoms. (It doesn\u2019t matter what we call E 0 ; as we have seen many times, it represents really nothing but our choice of the zero of energy.) The next term represents the amplitude per unit time that the electron is leaking into the n th pit from the (n+1) st pit; and the last term is the amplitude for leakage from the (n\u22121) st pit. As usual, we\u2019ll assume that A is a constant (independent of t ). For a full description of the behavior of any state |\u03d5\u27e9 , we would have one equation like (13.3) for every one of the amplitudes C n . Since we want to consider a crystal with a very large number of atoms, we\u2019ll assume that there are an indefinitely large number of states\u2014that the atoms go on forever in both directions. (To do the finite case, we will have to pay special attention to what happens at the ends.) If the number N of our base states is indefinitely large, then also our full Hamiltonian equations are infinite in number! We\u2019ll write down just a sample: \u22ee i\u210f d C n\u22121 dt i\u210f d C n dt i\u210f d C n+1 dt \u22ee \u22ee = E 0 C n\u22121 \u2212A C n\u22122 \u2212A C n , = E 0 C n \u2212A C n\u22121 \u2212A C n+1 , = E 0 C n+1 \u2212A C n \u2212A C n+2 , \u22ee (13.4) We could study many things about an electron in a lattice, but first let\u2019s try to find the states of definite energy. As we have seen in earlier chapters this means that we have to find a situation in which the amplitudes all change at the same frequency if they change with time at all. We look for solutions of the form C n = a n e \u2212iEt/\u210f . (13.5) The complex numbers a n tell us about the non-time-varying part of the amplitude to find the electron at the n th atom. If we put this trial solution into the equations of (13.4) to test them out, we get the result E a n = E 0 a n \u2212A a n+1 \u2212A a n\u22121 . (13.6) We have an infinite number of such equations for the infinite number of unknowns a n \u2014which is rather petrifying. All we have to do is take the determinant \u2026 but wait! Determinants are fine when there are 2 , 3 , or 4 equations. But if there are a large number\u2014or an infinite number\u2014of equations, the determinants are not very convenient. We\u2019d better just try to solve the equations directly. First, let\u2019s label the atoms by their positions; we\u2019ll say that the atom n is at x n and the atom (n+1) is at x n+1 . If the atomic spacing is b \u2014as in Fig. 13\u20131\u2014we will have that x n+1 = x n +b . By choosing our origin at atom zero, we can even have it that x n =nb . We can rewrite Eq. (13.5) as C n =a( x n ) e \u2212iEt/\u210f , (13.7) and Eq. (13.6) would become Ea( x n )= E 0 a( x n )\u2212Aa( x n+1 )\u2212Aa( x n\u22121 ). (13.8) Or, using the fact that x n+1 = x n +b , we could also write Ea( x n )= E 0 a( x n )\u2212Aa( x n +b)\u2212Aa( x n \u2212b). (13.9) This equation is somewhat similar to a differential equation. It tells us that a quantity, a(x) , at one point, ( x n ), is related to the same physical quantity at some neighboring points, ( x n \u00b1b ). (A differential equation relates the value of a function at a point to the values at infinitesimally nearby points.) Perhaps the methods we usually use for solving differential equations will also work here; let\u2019s try. Linear differential equations with constant coefficients can always be solved in terms of exponential functions. We can try the same thing here; let\u2019s take as a trial solution a( x n )= e ik x n . (13.10) Then Eq. (13.9) becomes E e ik x n = E 0 e ik x n \u2212A e ik( x n +b) \u2212A e ik( x n \u2212b) . (13.11) We can now divide out the common factor e ik x n ; we get E= E 0 \u2212A e ikb \u2212A e \u2212ikb . (13.12) The last two terms are just equal to (2Acoskb) , so E= E 0 \u22122Acoskb. (13.13) We have found that for any choice at all for the constant k there is a solution whose energy is given by this equation. There are various possible energies depending on k , and each k corresponds to a different solution. There are an infinite number of solutions\u2014which is not surprising, since we started out with an infinite number of base states. Let\u2019s see what these solutions mean. For each k , the a \u2019s are given by Eq. (13.10). The amplitudes C n are then given by C n = e ik x n e \u2212(i/\u210f)Et , (13.14) where you should remember that the energy E also depends on k as given in Eq. (13.13). The space dependence of the amplitudes is e ik x n . The amplitudes oscillate as we go along from one atom to the next. We mean that, in space, the amplitude goes as a complex oscillation\u2014the magnitude is the same at every atom, but the phase at a given time advances by the amount (ikb) from one atom to the next. We can visualize what is going on by plotting a vertical line to show just the real part at each atom as we have done in Fig. 13\u20132. The envelope of these vertical lines (as shown by the broken-line curve) is, of course, a cosine curve. The imaginary part of C n is also an oscillating function, but is shifted 90 \u2218 in phase so that the absolute square (which is the sum of the squares of the real and imaginary parts) is the same for all the C \u2019s. Thus if we pick a k , we get a stationary state of a particular energy E . And for any such state, the electron is equally likely to be found at every atom\u2014there is no preference for one atom or the other. Only the phase is different for different atoms. Also, as time goes on the phases vary. From Eq. (13.14) the real and imaginary parts propagate along the crystal as waves\u2014namely as the real or imaginary parts of e i[k x n \u2212(E/\u210f)t] . (13.15) The wave can travel toward positive or negative x depending on the sign we have picked for k . Notice that we have been assuming that the number k that we put in our trial solution, Eq. (13.10), was a real number. We can see now why that must be so if we have an infinite line of atoms. Suppose that k were an imaginary number, say i k \u2032 . Then the amplitudes a n would go as e \u2212 k \u2032 x n , which means that the amplitude would get larger and larger as we go toward large negative x \u2019s\u2014or toward large positive x \u2019s if k \u2032 is a negative number. This kind of solution would be O.K. if we were dealing with a line of atoms that ended, but cannot be a physical solution for an infinite chain of atoms. It would give infinite amplitudes\u2014and, therefore, infinite probabilities\u2014which can\u2019t represent a real situation. Later on we will see an example in which an imaginary k does make sense. The relation between the energy E and the wave number k as given in Eq. (13.13) is plotted in Fig. 13\u20133. As you can see from the figure, the energy can go from ( E 0 \u22122A) at k=0 to ( E 0 +2A) at k=\u00b1\u03c0/b . The graph is plotted for positive A ; if A were negative, the curve would simply be inverted, but the range would be the same. The significant result is that any energy is possible within a certain range or \u201cband\u201d of energies, but no others. According to our assumptions, if an electron in a crystal is in a stationary state, it can have no energy other than values in this band. According to Eq. (13.13), the smallest k \u2019s correspond to low-energy states\u2014 E\u2248( E 0 \u22122A) . As k increases in magnitude (toward either positive or negative values) the energy at first increases, but then reaches a maximum at k=\u00b1\u03c0/b , as shown in Fig. 13\u20133. For k \u2019s larger than \u03c0/b , the energy would start to decrease again. But we do not really need to consider such values of k , because they do not give new states\u2014they just repeat states we already have for smaller k . We can see that in the following way. Consider the lowest energy state for which k=0 . The coefficient a( x n ) is the same for all x n . Now we would get the same energy for k=2\u03c0/b . But then, using Eq. (13.10), we have that a( x n )= e i(2\u03c0/b) x n . i ( / b ) However, taking x 0 to be at the origin, we can set x n =nb ; then a( x n ) becomes a( x n )= e i2\u03c0n =1. i 2 The state described by these a( x n ) is physically the same state we got for k=0 . It does not represent a different solution. As another example, suppose that k were \u2212\u03c0/4b . The real part of a( x n ) would vary as shown by curve 1 in Fig. 13\u20134. If k were 7\u03c0/4b , the real part of a( x n ) would vary as shown by curve 2 in the figure. (The complete cosine curves don\u2019t mean anything, of course; all that matters is their values at the points x n . The curves are just to help you see how things are going.) You see that both values of k give the same amplitudes at all of the x n \u2019s. The upshot is that we have all the possible solutions of our problem if we take only k \u2019s in a certain limited range. We\u2019ll pick the range between \u2212\u03c0/b and +\u03c0/b \u2014the one shown in Fig. 13\u20133. In this range, the energy of the stationary states increases uniformly with an increase in the magnitude of k . One side remark about something you can play with. Suppose that the electron cannot only jump to the nearest neighbor with amplitude iA/\u210f , but also has the possibility to jump in one direct leap to the next nearest neighbor with some other amplitude iB/\u210f . You will find that the solution can again be written in the form a n = e ik x n \u2014this type of solution is universal. You will also find that the stationary states with wave number k have an energy equal to ( E 0 \u22122Acoskb\u22122Bcos2kb) . This shows that the shape of the curve of E against k is not universal, but depends upon the particular assumptions of the problem. It is not always a cosine wave\u2014it\u2019s not even necessarily symmetrical about some horizontal line. It is true, however, that the curve always repeats itself outside of the interval from \u2212\u03c0/b to \u03c0/b , so you never need to worry about other values of k . Let\u2019s look a little more closely at what happens for small k \u2014that is, when the variations of the amplitudes from one x n to the next are quite slow. Suppose we choose our zero of energy by defining E 0 =2A ; then the minimum of the curve in Fig. 13\u20133 is at the zero of energy. For small enough k , we can write that coskb\u22481\u2212 k 2 b 2 /2, 2 2 and the energy of Eq. (13.13) becomes E=A k 2 b 2 . (13.16) We have that the energy of the state is proportional to the square of the wave number which describes the spatial variations of the amplitudes C n . In this section we would like to discuss the behavior of states in the one-dimensional lattice in more detail. If the amplitude for an electron to be at x n is C n , the probability of finding it there is | C n | 2 . For the stationary states described by Eq. (13.14), this probability is the same for all x n and does not change with time. How can we represent a situation which we would describe roughly by saying an electron of a certain energy is localized in a certain region\u2014so that it is more likely to be found at one place than at some other place? We can do that by making a superposition of several solutions like Eq. (13.14) with slightly different values of k \u2014and, therefore, slightly different energies. Then at t=0 , at least, the amplitude C n will vary with position because of the interference between the various terms, just as one gets beats when there is a mixture of waves of different wavelengths (as we discussed in Chapter 48, Vol. I). So we can make up a \u201cwave packet\u201d with a predominant wave number k 0 , but with various other wave numbers near k 0 .1 In our superposition of stationary states, the amplitudes with different k \u2019s will represent states of slightly different energies, and, therefore, of slightly different frequencies; the interference pattern of the total C n will, therefore, also vary with time\u2014there will be a pattern of \u201cbeats.\u201d As we have seen in Chapter 48 of Volume I, the peaks of the beats [the place where |C( x n ) | 2 is large] will move along in x as time goes on; they move with the speed we have called the \u201cgroup velocity.\u201d We found that this group velocity was related to the variation of k with frequency by v group = d\u03c9 dk ; (13.17) the same derivation would apply equally well here. An electron state which is a \u201cclump\u201d\u2014namely one for which the C n vary in space like the wave packet of Fig. 13\u20135\u2014will move along our one-dimensional \u201ccrystal\u201d with the speed v equal to d\u03c9/dk , where \u03c9=E/\u210f . Using (13.16) for E , we get that v= 2A b 2 \u210f k. (13.18) In other words, the electrons move along with a speed proportional to the typical k . Equation (13.16) then says that the energy of such an electron is proportional to the square of its velocity\u2014it acts like a classical particle. So long as we look at things on a scale gross enough that we don\u2019t see the fine structure, our quantum mechanical picture begins to give results like classical physics. In fact, if we solve Eq. (13.18) for k and substitute into (13.16), we can write E= 1 2 m eff v 2 , (13.19) where m eff is a constant. The extra \u201cenergy of motion\u201d of the electron in a packet depends on the velocity just as for a classical particle. The constant m eff \u2014called the \u201ceffective mass\u201d\u2014is given by m eff = \u210f 2 2A b 2 . (13.20) Also notice that we can write m eff v=\u210fk. (13.21) If we choose to call m eff v the \u201cmomentum,\u201d it is related to the wave number k in the way we have described earlier for a free particle. Don\u2019t forget that m eff has nothing to do with the real mass of an electron. It may be quite different\u2014although in commonly used metals and semiconductors it often happens to turn out to be the same general order of magnitude, about 0.1 to 30 times the free-space mass of the electron. We have now explained a remarkable mystery\u2014how an electron in a crystal (like an extra electron put into germanium) can ride right through the crystal and flow perfectly freely even though it has to hit all the atoms. It does so by having its amplitudes going pip-pip-pip from one atom to the next, working its way through the crystal. That is how a solid can conduct electricity. Let\u2019s look for a moment at how we could apply the same ideas to see what happens to an electron in three dimensions. The results turn out to be very similar. Suppose we have a rectangular lattice of atoms with lattice spacings of a , b , c in the three directions. (If you want a cubic lattice, take the three spacings all equal.) Also suppose that the amplitude to leap in the x -direction to a neighbor is (i A x /\u210f) , to leap in the y -direction is (i A y /\u210f) , and to leap in the z -direction is (i A z /\u210f) . Now how should we describe the base states? As in the one-dimensional case, one base state is that the electron is at the atom whose locations are x , y , z , where (x,y,z) is one of the lattice points. Choosing our origin at one atom, these points are all at x= n x a,y= n y b,andz= n z c, b and where n x , n y , n z are any three integers. Instead of using subscripts to indicate such points, we will now just use x , y , and z , understanding that they take on only their values at the lattice points. Thus the base state is represented by the symbol |electron at x,y,z\u27e9 , and the amplitude for an electron in some state |\u03c8\u27e9 to be in this base state is C(x,y,z)=\u27e8electron at x,y,z|\u03c8\u27e9 . As before, the amplitudes C(x,y,z) may vary with time. With our assumptions, the Hamiltonian equations should be like this: i\u210f dC(x,y,z) dt \u2212 \u2212 \u2212 = E 0 C(x,y,z) A x C(x+a,y,z)\u2212 A x C(x\u2212a,y,z) A y C(x,y+b,z)\u2212 A y C(x,y\u2212b,z) A z C(x,y,z+c)\u2212 A z C(x,y,z\u2212c). (13.22) It looks rather long, but you can see where each term comes from. Again we can try to find a stationary state in which all the C \u2019s vary with time in the same way. Again the solution is an exponential: C(x,y,z)= e \u2212iEt/\u210f e i( k x x+ k y y+ k z z) . (13.23) If you substitute this into (13.22) you see that it works, provided that the energy E is related to k x , k y , and k z in the following way: E= E 0 \u22122 A x cos k x a\u22122 A y cos k y b\u22122 A z cos k z c. (13.24) The energy now depends on the three wave numbers k x , k y , k z , which, incidentally, are the components of a three-dimensional vector k . In fact, we can write Eq. (13.23) in vector notation as C(x,y,z)= e \u2212iEt/\u210f e ik\u22c5r . (13.25) The amplitude varies as a complex plane wave in three dimensions, moving in the direction of k , and with the wave number k=( k 2 x + k 2 y + k 2 z ) 1/2 . The energy associated with these stationary states depends on the three components of k in the complicated way given in Eq. (13.24). The nature of the variation of E with k depends on relative signs and magnitudes of A x , A y , and A z . If these three numbers are all positive, and if we are interested in small values of k , the dependence is relatively simple. Expanding the cosines as we did before to get Eq. (13.16), we can now get that E= E min + A x a 2 k 2 x + A y b 2 k 2 y + A z c 2 k 2 z . (13.26) For a simple cubic lattice with lattice spacing a we expect that A x and A y and A z would be equal\u2014say all are just A \u2014and we would have just E= E min +A a 2 ( k 2 x + k 2 y + k 2 z ), 2 2 2 or E= E min +A a 2 k 2 . (13.27) This is just like Eq. (13.16). Following the arguments used there, we would conclude that an electron packet in three dimensions (made up by superposing many states with nearly equal energies) also moves like a classical particle with some effective mass. In a crystal with a lower symmetry than cubic (or even in a cubic crystal in which the state of the electron at each atom is not symmetrical) the three coefficients A x , A y , and A z are different. Then the \u201ceffective mass\u201d of an electron localized in a small region depends on its direction of motion. It could, for instance, have a different inertia for motion in the x -direction than for motion in the y -direction. (The details of such a situation are sometimes described in terms of an \u201ceffective mass tensor.\u201d) According to Eq. (13.24) the electron states we have been talking about can have energies only in a certain \u201cband\u201d of energies which covers the energy range from the minimum energy E 0 \u22122( A x + A y + A z ) ( ) to the maximum energy E 0 +2( A x + A y + A z ). ( ) Other energies are possible, but they belong to a different class of electron states. For the states we have described, we imagined base states in which an electron is placed on an atom of the crystal in some particular state, say the lowest energy state. If you have an atom in empty space, and add an electron to make an ion, the ion can be formed in many ways. The electron can go on in such a way as to make the state of lowest energy, or it can go on to make one or another of many possible \u201cexcited states\u201d of the ion each with a definite energy above the lowest energy. The same thing can happen in a crystal. Let\u2019s suppose that the energy E 0 we picked above corresponds to base states which are ions of the lowest possible energy. We could also imagine a new set of base states in which the electron sits near the n th atom in a different way\u2014in one of the excited states of the ion\u2014so that the energy E 0 is now quite a bit higher. As before there is some amplitude A (different from before) that the electron will jump from its excited state at one atom to the same excited state at a neighboring atom. The whole analysis goes as before; we find a band of possible energies centered at a higher energy. There can, in general, be many such bands each corresponding to a different level of excitation. There are also other possibilities. There may be some amplitude that the electron jumps from an excited condition at one atom to an unexcited condition at the next atom. (This is called an interaction between bands.) The mathematical theory gets more and more complicated as you take into account more and more bands and add more and more coefficients for leakage between the possible states. No new ideas are involved, however; the equations are set up much as we have done in our simple example. We should remark also that there is not much more to be said about the various coefficients, such as the amplitude A , which appear in the theory. Generally they are very hard to calculate, so in practical cases very little is known theoretically about these parameters and for any particular real situation we can only take values determined experimentally. There are other situations where the physics and mathematics are almost exactly like what we have found for an electron moving in a crystal, but in which the \u201cobject\u201d that moves is quite different. For instance, suppose that our original crystal\u2014or rather linear lattice\u2014was a line of neutral atoms, each with a loosely bound outer electron. Then imagine that we were to remove one electron. Which atom has lost its electron? Let C n now represent the amplitude that the electron is missing from the atom at x n . There will, in general, be some amplitude iA/\u210f that the electron at a neighboring atom\u2014say the (n\u22121) st atom\u2014will jump to the n th leaving the (n\u22121) st atom without its electron. This is the same as saying that there is an amplitude iA/\u210f for the \u201cmissing electron\u201d to jump from the n th atom to the (n\u22121) st atom. You can see that the equations will be exactly the same\u2014of course, the value of A need not be the same as we had before. Again we will get the same formulas for the energy levels, for the \u201cwaves\u201d of probability which move through the crystal with the group velocity of Eq. (13.18), for the effective mass, and so on. Only now the waves describe the behavior of the missing electron\u2014or \u201chole\u201d as it is called. So a \u201chole\u201d acts just like a particle with a certain mass m eff . You can see that this particle will appear to have a positive charge. We\u2019ll have some more to say about such holes in the next chapter. As another example, we can think of a line of identical neutral atoms one of which has been put into an excited state\u2014that is, with more than its normal ground state energy. Let C n be the amplitude that the n th atom has the excitation. It can interact with a neighboring atom by handing over to it the extra energy and returning to the ground state. Call the amplitude for this process iA/\u210f . You can see that it\u2019s the same mathematics all over again. Now the object which moves is called an exciton. It behaves like a neutral \u201cparticle\u201d moving through the crystal, carrying the excitation energy. Such motion may be involved in certain biological processes such as vision, or photosynthesis. It has been guessed that the absorption of light in the retina produces an \u201cexciton\u201d which moves through some periodic structure (such as the layers in the rods we described in Chapter 36, Vol. I; see Fig. 36\u20135) to be accumulated at some special station where the energy is used to induce a chemical reaction. We want now to consider the case of a single electron in a crystal which is not perfect. Our earlier analysis says that perfect crystals have perfect conductivity\u2014that electrons can go slipping through the crystal, as in a vacuum, without friction. One of the most important things that can stop an electron from going on forever is an imperfection or irregularity in the crystal. As an example, suppose that somewhere in the crystal there is a missing atom; or suppose that someone put one wrong atom at one of the atomic sites so that things there are different than at the other atomic sites. Say the energy E 0 or the amplitude A could be different. How would we describe what happens then? To be specific, we will return to the one-dimensional case and we will assume that atom number \u201czero\u201d is an \u201cimpurity\u201d atom and has a different value of E 0 than any of the other atoms. Let\u2019s call this energy ( E 0 +F) . What happens? When an electron arrives at atom \u201czero\u201d there is some probability that the electron is scattered backwards. If a wave packet is moving along and it reaches a place where things are a little bit different, some of it will continue onward and some of it will bounce back. It\u2019s quite difficult to analyze such a situation using a wave packet, because everything varies in time. It is much easier to work with steady-state solutions. So we will work with stationary states, which we will find can be made up of continuous waves which have transmitted and reflected parts. In three dimensions we would call the reflected part the scattered wave, since it would spread out in various directions. We start out with a set of equations which are just like the ones in Eq. (13.6) except that the equation for n=0 is different from all the rest. The five equations for n=\u22122 , \u22121 , 0 , +1 , and +2 look like this: \u22ee E a \u22122 E a \u22121 E a 0 E a 1 E a 2 \u22ee \u22ee = E 0 a \u22122 \u2212A a \u22121 \u2212A a \u22123 , = E 0 a \u22121 \u2212A a 0 \u2212A a \u22122 , =( E 0 +F) a 0 \u2212A a 1 \u2212A a \u22121 , = E 0 a 1 \u2212A a 2 \u2212A a 0 , = E 0 a 2 \u2212A a 3 \u2212A a 1 , \u22ee (13.28) There are, of course, all the other equations for |n| is greater than 2. They will look just like Eq. (13.6). For the general case, we really ought to use a different A for the amplitude that the electron jumps to or from atom \u201czero,\u201d but the main features of what goes on will come out of a simplified example in which all the A \u2019s are equal. Equation (13.10) would still work as a solution for all of the equations except the one for atom \u201czero\u201d\u2014it isn\u2019t right for that one equation. We need a different solution which we can cook up in the following way. Equation (13.10) represents a wave going in the positive x -direction. A wave going in the negative x -direction would have been an equally good solution. It would be written a( x n )= e \u2212ik x n . i k The most general solution we could have taken for Eq. (13.6) would be a combination of a forward and a backward wave, namely a n =\u03b1 e ik x n +\u03b2 e \u2212ik x n . (13.29) This solution represents a complex wave of amplitude \u03b1 moving in the +x -direction and a wave of amplitude \u03b2 moving in the \u2212x -direction. Now take a look at the set of equations for our new problem\u2014the ones in (13.28) together with those for all the other atoms. The equations involving a n \u2019s with n\u2264\u22121 are all satisfied by Eq. (13.29), with the condition that k is related to E and the lattice spacing b by E= E 0 \u22122Acoskb. (13.30) The physical meaning is an \u201cincident\u201d wave of amplitude \u03b1 approaching atom \u201czero\u201d (the \u201cscatterer\u201d) from the left, and a \u201cscattered\u201d or \u201creflected\u201d wave of amplitude \u03b2 going back toward the left. We do not lose any generality if we set the amplitude \u03b1 of the incident wave equal to 1 . Then the amplitude \u03b2 is, in general, a complex number. We can say all the same things about the solutions of a n for n\u22651 . The coefficients could be different, so we would have for them a n =\u03b3 e ik x n +\u03b4 e \u2212ik x n ,forn\u22651. (13.31) Here, \u03b3 is the amplitude of a wave going to the right and \u03b4 a wave coming from the right. We want to consider the physical situation in which a wave is originally started only from the left, and there is only a \u201ctransmitted\u201d wave that comes out beyond the scatterer\u2014or impurity atom. We will try for a solution in which \u03b4=0 . We can, certainly, satisfy all of the equations for the a n except for the middle three in Eq. (13.28) by the following trial solutions. a n (for n<0) a n (for n>0) = e ik x n +\u03b2 e \u2212ik x n , =\u03b3 e ik x n . (13.32) The situation we are talking about is illustrated in Fig. 13\u20136. By using the formulas in Eq. (13.32) for a \u22121 and a +1 , the three middle equations of Eq. (13.28) will allow us to solve for a 0 and also for the two coefficients \u03b2 and \u03b3 . So we have found a complete solution. Setting x n =nb , we have to solve the three equations (E\u2212 E 0 ){ e ik(\u2212b) (E\u2212 E 0 \u2212F) a 0 = (E\u2212 E 0 )\u03b3 e ikb = +\u03b2 e \u2212ik(\u2212b) }= \u2212A{ a 0 + e ik(\u22122b) +\u03b2 e \u2212ik(\u22122b) }, \u2212A{\u03b3 e ikb + e ik(\u2212b) +\u03b2 e \u2212ik(\u2212b) }, \u2212A{\u03b3 e ik(2b) + a 0 }. (13.33) Remember that E is given in terms of k by Eq. (13.30). If you substitute this value for E into the equations, and remember that cosx= 1 2 ( e ix + e \u2212ix ) , you get from the first equation that a 0 =1+\u03b2, (13.34) and from the third equation that a 0 =\u03b3. (13.35) These are consistent only if \u03b3=1+\u03b2. (13.36) This equation says that the transmitted wave ( \u03b3 ) is just the original incident wave ( 1 ) with an added wave ( \u03b2 ) equal to the reflected wave. This is not always true, but happens to be so for a scattering at one atom only. If there were a clump of impurity atoms, the amount added to the forward wave would not necessarily be the same as the reflected wave. We can get the amplitude \u03b2 of the reflected wave from the middle equation of Eq. (13.33); we find that \u03b2= \u2212F F\u22122iAsinkb . (13.37) We have the complete solution for the lattice with one unusual atom. You may be wondering how the transmitted wave can be \u201cmore\u201d than the incident wave as it appears in Eq. (13.34). Remember, though, that \u03b2 and \u03b3 are complex numbers and that the number of particles (or rather, the probability of finding a particle) in a wave is proportional to the absolute square of the amplitude. In fact, there will be \u201cconservation of electrons\u201d only if |\u03b2 | 2 +|\u03b3 | 2 =1. (13.38) You can show that this is true for our solution. There is another interesting situation that can arise if F is a negative number. If the energy of the electron is lower at the impurity atom (at n=0 ) than it is anywhere else, then the electron can get caught on this atom. That is, if ( E 0 +F) is below the bottom of the band at ( E 0 \u22122A) , then the electron can get \u201ctrapped\u201d in a state with E< E 0 \u22122A . Such a solution cannot come out of what we have done so far. We can get this solution, however, if we permit the trial solution we took in Eq. (13.10) to have an imaginary number for k . Let\u2019s set k=\u00b1i\u03ba . Again, we can have different solutions for n<0 and for n>0 . A possible solution for n<0 might be a n (for n<0)=c e +\u03ba x n . (13.39) We have to take a plus sign in the exponent; otherwise the amplitude would get indefinitely large for large negative values of n . Similarly, a possible solution for n>0 would be a n (for n>0)= c \u2032 e \u2212\u03ba x n . (13.40) If we put these trial solutions into Eq. (13.28) all but the middle three are satisfied provided that E= E 0 \u2212A( e \u03bab + e \u2212\u03bab ). (13.41) Since the sum of the two exponential terms is always greater than 2 , this energy is below the regular band, and is what we are looking for. The remaining three equations in Eq. (13.28) are satisfied if a 0 =c= c \u2032 and if \u03ba is chosen so that A( e \u03bab \u2212 e \u2212\u03bab )=\u2212F. (13.42) Combining this equation with Eq. (13.41) we can find the energy of the trapped electron; we get E= E 0 \u2212 4 A 2 + F 2 \u2212 \u2212 \u2212 \u2212 \u2212 \u2212 \u2212 \u2212 \u221a . (13.43) The trapped electron has a unique energy\u2014located somewhat below the conduction band. Notice that the amplitudes we have in Eq. (13.39) and (13.40) do not say that the trapped electron sits right on the impurity atom. The probability of finding the electron at nearby atoms is given by the square of these amplitudes. For one particular choice of the parameters it might vary as shown in the bar graph of Fig. 13\u20137. The probability is greatest for finding the electron on the impurity atom. For nearby atoms the probability drops off exponentially with the distance from the impurity atom. This is another example of \u201cbarrier penetration.\u201d From the point-of-view of classical physics the electron doesn\u2019t have enough energy to get away from the energy \u201chole\u201d at the trapping center. But quantum mechanically it can leak out a little way. Finally, our example can be used to illustrate a point which is very useful these days in the physics of high-energy particles. It has to do with a relationship between scattering amplitudes and bound states. Suppose we have discovered\u2014through experiment and theoretical analysis\u2014the way that pions scatter from protons. Then a new particle is discovered and someone wonders whether maybe it is just a combination of a pion and a proton held together in some bound state (in an analogy to the way an electron is bound to a proton to make a hydrogen atom). By a bound state we mean a combination which has a lower energy than the two free-particles. There is a general theory which says that a bound state will exist at that energy at which the scattering amplitude becomes infinite if extrapolated algebraically (the mathematical term is \u201canalytically continued\u201d) to energy regions outside of the permitted band. The physical reason for this is as follows. A bound state is a situation in which there are only waves tied on to a point and there\u2019s no wave coming in to get it started, it just exists there by itself. The relative proportion between the so-called \u201cscattered\u201d or created wave and the wave being \u201csent in\u201d is infinite. We can test this idea in our example. Let\u2019s write our expression Eq. (13.37) for the scattered amplitude directly in terms of the energy E of the particle being scattered (instead of in terms of k ). Since Equation (13.30) can be rewritten as 2Asinkb= 4 A 2 \u2212(E\u2212 E 0 ) 2 \u2212 \u2212 \u2212 \u2212 \u2212 \u2212 \u2212 \u2212 \u2212 \u2212 \u2212 \u2212 \u2212 \u221a , the scattered amplitude is \u03b2= \u2212F F\u2212i 4 A 2 \u2212(E\u2212 E 0 ) 2 \u2212 \u2212 \u2212 \u2212 \u2212 \u2212 \u2212 \u2212 \u2212 \u2212 \u2212 \u2212 \u2212 \u221a . (13.44) From our derivation, this equation should be used only for real states\u2014those with energies in the energy band, E= E 0 \u00b12A . But suppose we forget that fact and extend the formula into the \u201cunphysical\u201d energy regions where |E\u2212 E 0 |>2A . For these unphysical regions we can write2 4 A 2 \u2212(E\u2212 E 0 ) 2 \u2212 \u2212 \u2212 \u2212 \u2212 \u2212 \u2212 \u2212 \u2212 \u2212 \u2212 \u2212 \u2212 \u221a =i (E\u2212 E 0 ) 2 \u22124 A 2 \u2212 \u2212 \u2212 \u2212 \u2212 \u2212 \u2212 \u2212 \u2212 \u2212 \u2212 \u2212 \u2212 \u221a . Then the \u201cscattering amplitude,\u201d whatever it may mean, is \u03b2= \u2212F F+ (E\u2212 E 0 ) 2 \u22124 A 2 \u2212 \u2212 \u2212 \u2212 \u2212 \u2212 \u2212 \u2212 \u2212 \u2212 \u2212 \u2212 \u2212 \u221a . (13.45) Now we ask: Is there any energy E for which \u03b2 becomes infinite (i.e., for which the expression for \u03b2 has a \u201cpole\u201d)? Yes, so long as F is negative, the denominator of Eq. (13.45) will be zero when (E\u2212 E 0 ) 2 \u22124 A 2 = F 2 , 2 or when E= E 0 \u00b1 4 A 2 + F 2 \u2212 \u2212 \u2212 \u2212 \u2212 \u2212 \u2212 \u2212 \u221a . The minus sign gives just the energy we found in Eq. (13.43) for the trapped energy. What about the plus sign? This gives an energy above the allowed energy band. And indeed there is another bound state there which we missed when we solved the equations of Eq. (13.28). We leave it as a puzzle for you to find the energy and amplitudes a n for this bound state. The relation between scattering and bound states provides one of the most useful clues in the current search for an understanding of the experimental observations about the new strange particles."
    },
    {
        "input": "The Special Theory of Relativity",
        "output": "For over 200 years the equations of motion enunciated by Newton were believed to describe nature correctly, and the first time that an error in these laws was discovered, the way to correct it was also discovered. Both the error and its correction were discovered by Einstein in 1905. Newton\u2019s Second Law, which we have expressed by the equation F=d(mv)/dt, was stated with the tacit assumption that m is a constant, but we now know that this is not true, and that the mass of a body increases with velocity. In Einstein\u2019s corrected formula m has the value m= m0 \u221a 1\u2212v2/c2 , where the \u201crest mass\u201d m0 represents the mass of a body that is not moving and c is the speed of light, which is about 3\u00d7105 km\u22c5sec\u22121 or about 186,000 mi\u22c5sec\u22121. For those who want to learn just enough about it so they can solve problems, that is all there is to the theory of relativity\u2014it just changes Newton\u2019s laws by introducing a correction factor to the mass. From the formula itself it is easy to see that this mass increase is very small in ordinary circumstances. If the velocity is even as great as that of a satellite, which goes around the earth at 5 mi/sec, then v/c=5/186,000 : putting this value into the formula shows that the correction to the mass is only one part in two to three billion, which is nearly impossible to observe. Actually, the correctness of the formula has been amply confirmed by the observation of many kinds of particles, moving at speeds ranging up to practically the speed of light. However, because the effect is ordinarily so small, it seems remarkable that it was discovered theoretically before it was discovered experimentally. Empirically, at a sufficiently high velocity, the effect is very large, but it was not discovered that way. Therefore it is interesting to see how a law that involved so delicate a modification (at the time when it was first discovered) was brought to light by a combination of experiments and physical reasoning. Contributions to the discovery were made by a number of people, the final result of whose work was Einstein\u2019s discovery. There are really two Einstein theories of relativity. This chapter is concerned with the Special Theory of Relativity, which dates from 1905. In 1915 Einstein published an additional theory, called the General Theory of Relativity. This latter theory deals with the extension of the Special Theory to the case of the law of gravitation; we shall not discuss the General Theory here. The principle of relativity was first stated by Newton, in one of his corollaries to the laws of motion: \u201cThe motions of bodies included in a given space are the same among themselves, whether that space is at rest or moves uniformly forward in a straight line.\u201d This means, for example, that if a space ship is drifting along at a uniform speed, all experiments performed in the space ship and all the phenomena in the space ship will appear the same as if the ship were not moving, provided, of course, that one does not look outside. That is the meaning of the principle of relativity. This is a simple enough idea, and the only question is whether it is true that in all experiments performed inside a moving system the laws of physics will appear the same as they would if the system were standing still. Let us first investigate whether Newton\u2019s laws appear the same in the moving system. Suppose that Moe is moving in the x -direction with a uniform velocity u , and he measures the position of a certain point, shown in Fig. 15\u20131. He designates the \u201c x -distance\u201d of the point in his coordinate system as x \u2032 . Joe is at rest, and measures the position of the same point, designating its x -coordinate in his system as x . The relationship of the coordinates in the two systems is clear from the diagram. After time t Moe\u2019s origin has moved a distance ut , and if the two systems originally coincided, x \u2032 y \u2032 z \u2032 t \u2032 =x\u2212ut, =y, =z, =t. (15.2) If we substitute this transformation of coordinates into Newton\u2019s laws we find that these laws transform to the same laws in the primed system; that is, the laws of Newton are of the same form in a moving system as in a stationary system, and therefore it is impossible to tell, by making mechanical experiments, whether the system is moving or not. The principle of relativity has been used in mechanics for a long time. It was employed by various people, in particular Huygens, to obtain the rules for the collision of billiard balls, in much the same way as we used it in Chapter 10 to discuss the conservation of momentum. In the 19th century interest in it was heightened as the result of investigations into the phenomena of electricity, magnetism, and light. A long series of careful studies of these phenomena by many people culminated in Maxwell\u2019s equations of the electromagnetic field, which describe electricity, magnetism, and light in one uniform system. However, the Maxwell equations did not seem to obey the principle of relativity. That is, if we transform Maxwell\u2019s equations by the substitution of equations (15.2), their form does not remain the same; therefore, in a moving space ship the electrical and optical phenomena should be different from those in a stationary ship. Thus one could use these optical phenomena to determine the speed of the ship; in particular, one could determine the absolute speed of the ship by making suitable optical or electrical measurements. One of the consequences of Maxwell\u2019s equations is that if there is a disturbance in the field such that light is generated, these electromagnetic waves go out in all directions equally and at the same speed c , or 186,000 mi/sec. Another consequence of the equations is that if the source of the disturbance is moving, the light emitted goes through space at the same speed c . This is analogous to the case of sound, the speed of sound waves being likewise independent of the motion of the source. This independence of the motion of the source, in the case of light, brings up an interesting problem: Suppose we are riding in a car that is going at a speed u , and light from the rear is going past the car with speed c . Differentiating the first equation in (15.2) gives d x \u2032 /dt=dx/dt\u2212u, \u2032 which means that according to the Galilean transformation the apparent speed of the passing light, as we measure it in the car, should not be c but should be c\u2212u . For instance, if the car is going 100,000 mi/sec, and the light is going 186,000 mi/sec, then apparently the light going past the car should go 86,000 mi/sec. In any case, by measuring the speed of the light going past the car (if the Galilean transformation is correct for light), one could determine the speed of the car. A number of experiments based on this general idea were performed to determine the velocity of the earth, but they all failed\u2014they gave no velocity at all. We shall discuss one of these experiments in detail, to show exactly what was done and what was the matter; something was the matter, of course, something was wrong with the equations of physics. What could it be? When the failure of the equations of physics in the above case came to light, the first thought that occurred was that the trouble must lie in the new Maxwell equations of electrodynamics, which were only 20 years old at the time. It seemed almost obvious that these equations must be wrong, so the thing to do was to change them in such a way that under the Galilean transformation the principle of relativity would be satisfied. When this was tried, the new terms that had to be put into the equations led to predictions of new electrical phenomena that did not exist at all when tested experimentally, so this attempt had to be abandoned. Then it gradually became apparent that Maxwell\u2019s laws of electrodynamics were correct, and the trouble must be sought elsewhere. In the meantime, H. A. Lorentz noticed a remarkable and curious thing when he made the following substitutions in the Maxwell equations: x \u2032 y \u2032 z \u2032 t \u2032 = x\u2212ut 1\u2212 u 2 / c 2 \u2212 \u2212 \u2212 \u2212 \u2212 \u2212 \u2212 \u2212 \u221a , =y, =z, = t\u2212ux/ c 2 1\u2212 u 2 / c 2 \u2212 \u2212 \u2212 \u2212 \u2212 \u2212 \u2212 \u2212 \u221a , (15.3) namely, Maxwell\u2019s equations remain in the same form when this transformation is applied to them! Equations (15.3) are known as a Lorentz transformation. Einstein, following a suggestion originally made by Poincar\u00e9, then proposed that all the physical laws should be of such a kind that they remain unchanged under a Lorentz transformation. In other words, we should change, not the laws of electrodynamics, but the laws of mechanics. How shall we change Newton\u2019s laws so that they will remain unchanged by the Lorentz transformation? If this goal is set, we then have to rewrite Newton\u2019s equations in such a way that the conditions we have imposed are satisfied. As it turned out, the only requirement is that the mass m in Newton\u2019s equations must be replaced by the form shown in Eq. (15.1). When this change is made, Newton\u2019s laws and the laws of electrodynamics will harmonize. Then if we use the Lorentz transformation in comparing Moe\u2019s measurements with Joe\u2019s, we shall never be able to detect whether either is moving, because the form of all the equations will be the same in both coordinate systems! It is interesting to discuss what it means that we replace the old transformation between the coordinates and time with a new one, because the old one (Galilean) seems to be self-evident, and the new one (Lorentz) looks peculiar. We wish to know whether it is logically and experimentally possible that the new, and not the old, transformation can be correct. To find that out, it is not enough to study the laws of mechanics but, as Einstein did, we too must analyze our ideas of space and time in order to understand this transformation. We shall have to discuss these ideas and their implications for mechanics at some length, so we say in advance that the effort will be justified, since the results agree with experiment. As mentioned above, attempts were made to determine the absolute velocity of the earth through the hypothetical \u201cether\u201d that was supposed to pervade all space. The most famous of these experiments is one performed by Michelson and Morley in 1887. It was 18 years later before the negative results of the experiment were finally explained, by Einstein. The Michelson-Morley experiment was performed with an apparatus like that shown schematically in Fig. 15\u20132. This apparatus is essentially comprised of a light source A , a partially silvered glass plate B , and two mirrors C and E , all mounted on a rigid base. The mirrors are placed at equal distances L from B . The plate B splits an oncoming beam of light, and the two resulting beams continue in mutually perpendicular directions to the mirrors, where they are reflected back to B . On arriving back at B , the two beams are recombined as two superposed beams, D and F . If the time taken for the light to go from B to E and back is the same as the time from B to C and back, the emerging beams D and F will be in phase and will reinforce each other, but if the two times differ slightly, the beams will be slightly out of phase and interference will result. If the apparatus is \u201cat rest\u201d in the ether, the times should be precisely equal, but if it is moving toward the right with a velocity u , there should be a difference in the times. Let us see why. First, let us calculate the time required for the light to go from B to E and back. Let us say that the time for light to go from plate B to mirror E is t 1 , and the time for the return is t 2 . Now, while the light is on its way from B to the mirror, the apparatus moves a distance u t 1 , so the light must traverse a distance L+u t 1 , at the speed c . We can also express this distance as c t 1 , so we have c t 1 =L+u t 1 ,or t 1 =L/(c\u2212u). / ( ) (This result is also obvious from the point of view that the velocity of light relative to the apparatus is c\u2212u , so the time is the length L divided by c\u2212u .) In a like manner, the time t 2 can be calculated. During this time the plate B advances a distance u t 2 , so the return distance of the light is L\u2212u t 2 . Then we have c t 2 =L\u2212u t 2 ,or t 2 =L/(c+u). / ( ) Then the total time is t 1 + t 2 =2Lc/( c 2 \u2212 u 2 ). 2 2 For convenience in later comparison of times we write this as t 1 + t 2 = 2L/c 1\u2212 u 2 / c 2 . (15.4) Our second calculation will be of the time t 3 for the light to go from B to the mirror C . As before, during time t 3 the mirror C moves to the right a distance u t 3 to the position C \u2032 ; in the same time, the light travels a distance c t 3 along the hypotenuse of a triangle, which is B C \u2032 . For this right triangle we have (c t 3 ) 2 = L 2 +(u t 3 ) 2 2 2 or L 2 = c 2 t 2 3 \u2212 u 2 t 2 3 =( c 2 \u2212 u 2 ) t 2 3 , 2 2 2 2 from which we get t 3 =L/ c 2 \u2212 u 2 \u2212 \u2212 \u2212 \u2212 \u2212 \u2212 \u221a . For the return trip from C \u2032 the distance is the same, as can be seen from the symmetry of the figure; therefore the return time is also the same, and the total time is 2 t 3 . With a little rearrangement of the form we can write 2 t 3 = 2L c 2 \u2212 u 2 \u2212 \u2212 \u2212 \u2212 \u2212 \u2212 \u221a = 2L/c 1\u2212 u 2 / c 2 \u2212 \u2212 \u2212 \u2212 \u2212 \u2212 \u2212 \u2212 \u221a . (15.5) We are now able to compare the times taken by the two beams of light. In expressions (15.4) and (15.5) the numerators are identical, and represent the time that would be taken if the apparatus were at rest. In the denominators, the term u 2 / c 2 will be small, unless u is comparable in size to c . The denominators represent the modifications in the times caused by the motion of the apparatus. And behold, these modifications are not the same\u2014the time to go to C and back is a little less than the time to E and back, even though the mirrors are equidistant from B , and all we have to do is to measure that difference with precision. Here a minor technical point arises\u2014suppose the two lengths L are not exactly equal? In fact, we surely cannot make them exactly equal. In that case we simply turn the apparatus 90 degrees, so that BC is in the line of motion and BE is perpendicular to the motion. Any small difference in length then becomes unimportant, and what we look for is a shift in the interference fringes when we rotate the apparatus. In carrying out the experiment, Michelson and Morley oriented the apparatus so that the line BE was nearly parallel to the earth\u2019s motion in its orbit (at certain times of the day and night). This orbital speed is about 18 miles per second, and any \u201cether drift\u201d should be at least that much at some time of the day or night and at some time during the year. The apparatus was amply sensitive to observe such an effect, but no time difference was found\u2014the velocity of the earth through the ether could not be detected. The result of the experiment was null. The result of the Michelson-Morley experiment was very puzzling and most disturbing. The first fruitful idea for finding a way out of the impasse came from Lorentz. He suggested that material bodies contract when they are moving, and that this foreshortening is only in the direction of the motion, and also, that if the length is L 0 when a body is at rest, then when it moves with speed u parallel to its length, the new length, which we call L \u2225 ( L -parallel), is given by L \u2225 = L 0 1\u2212 u 2 / c 2 \u2212 \u2212 \u2212 \u2212 \u2212 \u2212 \u2212 \u2212 \u221a . (15.6) When this modification is applied to the Michelson-Morley interferometer apparatus the distance from B to C does not change, but the distance from B to E is shortened to L 1\u2212 u 2 / c 2 \u2212 \u2212 \u2212 \u2212 \u2212 \u2212 \u2212 \u2212 \u221a . Therefore Eq. (15.5) is not changed, but the L of Eq. (15.4) must be changed in accordance with Eq. (15.6). When this is done we obtain t 1 + t 2 = (2L/c) 1\u2212 u 2 / c 2 \u2212 \u2212 \u2212 \u2212 \u2212 \u2212 \u2212 \u2212 \u221a 1\u2212 u 2 / c 2 = 2L/c 1\u2212 u 2 / c 2 \u2212 \u2212 \u2212 \u2212 \u2212 \u2212 \u2212 \u2212 \u221a . (15.7) Comparing this result with Eq. (15.5), we see that t 1 + t 2 =2 t 3 . So if the apparatus shrinks in the manner just described, we have a way of understanding why the Michelson-Morley experiment gives no effect at all. Although the contraction hypothesis successfully accounted for the negative result of the experiment, it was open to the objection that it was invented for the express purpose of explaining away the difficulty, and was too artificial. However, in many other experiments to discover an ether wind, similar difficulties arose, until it appeared that nature was in a \u201cconspiracy\u201d to thwart man by introducing some new phenomenon to undo every phenomenon that he thought would permit a measurement of u . It was ultimately recognized, as Poincar\u00e9 pointed out, that a complete conspiracy is itself a law of nature! Poincar\u00e9 then proposed that there is such a law of nature, that it is not possible to discover an ether wind by any experiment; that is, there is no way to determine an absolute velocity. In checking out whether the contraction idea is in harmony with the facts in other experiments, it turns out that everything is correct provided that the times are also modified, in the manner expressed in the fourth equation of the set (15.3). That is because the time 2 t 3 , calculated for the trip from B to C and back, is not the same when calculated by a man performing the experiment in a moving space ship as when calculated by a stationary observer who is watching the space ship. To the man in the ship the time is simply 2L/c , but to the other observer it is (2L/c)/ 1\u2212 u 2 / c 2 \u2212 \u2212 \u2212 \u2212 \u2212 \u2212 \u2212 \u2212 \u221a (Eq. 15.5). In other words, when the outsider sees the man in the space ship lighting a cigar, all the actions appear to be slower than normal, while to the man inside, everything moves at a normal rate. So not only must the lengths shorten, but also the time-measuring instruments (\u201cclocks\u201d) must apparently slow down. That is, when the clock in the space ship records 1 second elapsed, as seen by the man in the ship, it shows 1/ 1\u2212 u 2 / c 2 \u2212 \u2212 \u2212 \u2212 \u2212 \u2212 \u2212 \u2212 \u221a second to the man outside. This slowing of the clocks in a moving system is a very peculiar phenomenon, and is worth an explanation. In order to understand this, we have to watch the machinery of the clock and see what happens when it is moving. Since that is rather difficult, we shall take a very simple kind of clock. The one we choose is rather a silly kind of clock, but it will work in principle: it is a rod (meter stick) with a mirror at each end, and when we start a light signal between the mirrors, the light keeps going up and down, making a click every time it comes down, like a standard ticking clock. We build two such clocks, with exactly the same lengths, and synchronize them by starting them together; then they agree always thereafter, because they are the same in length, and light always travels with speed c . We give one of these clocks to the man to take along in his space ship, and he mounts the rod perpendicular to the direction of motion of the ship; then the length of the rod will not change. How do we know that perpendicular lengths do not change? The men can agree to make marks on each other\u2019s y -meter stick as they pass each other. By symmetry, the two marks must come at the same y - and y \u2032 -coordinates, since otherwise, when they get together to compare results, one mark will be above or below the other, and so we could tell who was really moving. Now let us see what happens to the moving clock. Before the man took it aboard, he agreed that it was a nice, standard clock, and when he goes along in the space ship he will not see anything peculiar. If he did, he would know he was moving\u2014if anything at all changed because of the motion, he could tell he was moving. But the principle of relativity says this is impossible in a uniformly moving system, so nothing has changed. On the other hand, when the external observer looks at the clock going by, he sees that the light, in going from mirror to mirror, is \u201creally\u201d taking a zigzag path, since the rod is moving sidewise all the while. We have already analyzed such a zigzag motion in connection with the Michelson-Morley experiment. If in a given time the rod moves forward a distance proportional to u in Fig. 15\u20133, the distance the light travels in the same time is proportional to c , and the vertical distance is therefore proportional to c 2 \u2212 u 2 \u2212 \u2212 \u2212 \u2212 \u2212 \u2212 \u221a . That is, it takes a longer time for light to go from end to end in the moving clock than in the stationary clock. Therefore the apparent time between clicks is longer for the moving clock, in the same proportion as shown in the hypotenuse of the triangle (that is the source of the square root expressions in our equations). From the figure it is also apparent that the greater u is, the more slowly the moving clock appears to run. Not only does this particular kind of clock run more slowly, but if the theory of relativity is correct, any other clock, operating on any principle whatsoever, would also appear to run slower, and in the same proportion\u2014we can say this without further analysis. Why is this so? To answer the above question, suppose we had two other clocks made exactly alike with wheels and gears, or perhaps based on radioactive decay, or something else. Then we adjust these clocks so they both run in precise synchronism with our first clocks. When light goes up and back in the first clocks and announces its arrival with a click, the new models also complete some sort of cycle, which they simultaneously announce by some doubly coincident flash, or bong, or other signal. One of these clocks is taken into the space ship, along with the first kind. Perhaps this clock will not run slower, but will continue to keep the same time as its stationary counterpart, and thus disagree with the other moving clock. Ah no, if that should happen, the man in the ship could use this mismatch between his two clocks to determine the speed of his ship, which we have been supposing is impossible. We need not know anything about the machinery of the new clock that might cause the effect\u2014we simply know that whatever the reason, it will appear to run slow, just like the first one. Now if all moving clocks run slower, if no way of measuring time gives anything but a slower rate, we shall just have to say, in a certain sense, that time itself appears to be slower in a space ship. All the phenomena there\u2014the man\u2019s pulse rate, his thought processes, the time he takes to light a cigar, how long it takes to grow up and get old\u2014all these things must be slowed down in the same proportion, because he cannot tell he is moving. The biologists and medical men sometimes say it is not quite certain that the time it takes for a cancer to develop will be longer in a space ship, but from the viewpoint of a modern physicist it is nearly certain; otherwise one could use the rate of cancer development to determine the speed of the ship! A very interesting example of the slowing of time with motion is furnished by muons, which are particles that disintegrate spontaneously after an average lifetime of 2.2\u00d7 10 \u22126 sec. They come to the earth in cosmic rays, and can also be produced artificially in the laboratory. Some of them disintegrate in midair, but the remainder disintegrate only after they encounter a piece of material and stop. It is clear that in its short lifetime a muon cannot travel, even at the speed of light, much more than 600 meters. But although the muons are created at the top of the atmosphere, some 10 kilometers up, yet they are actually found in a laboratory down here, in cosmic rays. How can that be? The answer is that different muons move at various speeds, some of which are very close to the speed of light. While from their own point of view they live only about 2 \u03bc sec, from our point of view they live considerably longer\u2014enough longer that they may reach the earth. The factor by which the time is increased has already been given as 1/ 1\u2212 u 2 / c 2 \u2212 \u2212 \u2212 \u2212 \u2212 \u2212 \u2212 \u2212 \u221a . The average life has been measured quite accurately for muons of different velocities, and the values agree closely with the formula. We do not know why the muon disintegrates or what its machinery is, but we do know its behavior satisfies the principle of relativity. That is the utility of the principle of relativity\u2014it permits us to make predictions, even about things that otherwise we do not know much about. For example, before we have any idea at all about what makes the muon disintegrate, we can still predict that when it is moving at nine-tenths of the speed of light, the apparent length of time that it lasts is (2.2\u00d7 10 \u22126 )/ 1\u2212 9 2 / 10 2 \u2212 \u2212 \u2212 \u2212 \u2212 \u2212 \u2212 \u2212 \u2212 \u221a sec; and our prediction works\u2014that is the good thing about it. Now let us return to the Lorentz transformation (15.3) and try to get a better understanding of the relationship between the (x,y,z,t) and the ( x \u2032 , y \u2032 , z \u2032 , t \u2032 ) coordinate systems, which we shall call the S and S \u2032 systems, or Joe and Moe systems, respectively. We have already noted that the first equation is based on the Lorentz suggestion of contraction along the x -direction; how can we prove that a contraction takes place? In the Michelson-Morley experiment, we now appreciate that the transverse arm BC cannot change length, by the principle of relativity; yet the null result of the experiment demands that the times must be equal. So, in order for the experiment to give a null result, the longitudinal arm BE must appear shorter, by the square root 1\u2212 u 2 / c 2 \u2212 \u2212 \u2212 \u2212 \u2212 \u2212 \u2212 \u2212 \u221a . What does this contraction mean, in terms of measurements made by Joe and Moe? Suppose that Moe, moving with the S \u2032 system in the x -direction, is measuring the x \u2032 -coordinate of some point with a meter stick. He lays the stick down x \u2032 times, so he thinks the distance is x \u2032 meters. From the viewpoint of Joe in the S system, however, Moe is using a foreshortened ruler, so the \u201creal\u201d distance measured is x \u2032 1\u2212 u 2 / c 2 \u2212 \u2212 \u2212 \u2212 \u2212 \u2212 \u2212 \u2212 \u221a meters. Then if the S \u2032 system has travelled a distance ut away from the S system, the S observer would say that the same point, measured in his coordinates, is at a distance x= x \u2032 1\u2212 u 2 / c 2 \u2212 \u2212 \u2212 \u2212 \u2212 \u2212 \u2212 \u2212 \u221a +ut , or x \u2032 = x\u2212ut 1\u2212 u 2 / c 2 \u2212 \u2212 \u2212 \u2212 \u2212 \u2212 \u2212 \u2212 \u221a , t which is the first equation of the Lorentz transformation. In an analogous way, because of the difference in time scales, the denominator expression is introduced into the fourth equation of the Lorentz transformation. The most interesting term in that equation is the ux/ c 2 in the numerator, because that is quite new and unexpected. Now what does that mean? If we look at the situation carefully we see that events that occur at two separated places at the same time, as seen by Moe in S \u2032 , do not happen at the same time as viewed by Joe in S . If one event occurs at point x 1 at time t 0 and the other event at x 2 and t 0 (the same time), we find that the two corresponding times t \u2032 1 and t \u2032 2 differ by an amount t \u2032 2 \u2212 t \u2032 1 = u( x 1 \u2212 x 2 )/ c 2 1\u2212 u 2 / c 2 \u2212 \u2212 \u2212 \u2212 \u2212 \u2212 \u2212 \u2212 \u221a . 2 This circumstance is called \u201cfailure of simultaneity at a distance,\u201d and to make the idea a little clearer let us consider the following experiment. Suppose that a man moving in a space ship (system S \u2032 ) has placed a clock at each end of the ship and is interested in making sure that the two clocks are in synchronism. How can the clocks be synchronized? There are many ways. One way, involving very little calculation, would be first to locate exactly the midpoint between the clocks. Then from this station we send out a light signal which will go both ways at the same speed and will arrive at both clocks, clearly, at the same time. This simultaneous arrival of the signals can be used to synchronize the clocks. Let us then suppose that the man in S \u2032 synchronizes his clocks by this particular method. Let us see whether an observer in system S would agree that the two clocks are synchronous. The man in S \u2032 has a right to believe they are, because he does not know that he is moving. But the man in S reasons that since the ship is moving forward, the clock in the front end was running away from the light signal, hence the light had to go more than halfway in order to catch up; the rear clock, however, was advancing to meet the light signal, so this distance was shorter. Therefore the signal reached the rear clock first, although the man in S \u2032 thought that the signals arrived simultaneously. We thus see that when a man in a space ship thinks the times at two locations are simultaneous, equal values of t \u2032 in his coordinate system must correspond to different values of t in the other coordinate system! Let us see what else we can discover in the Lorentz transformation. It is interesting to note that the transformation between the x \u2019s and t \u2019s is analogous in form to the transformation of the x \u2019s and y \u2019s that we studied in Chapter 11 for a rotation of coordinates. We then had x \u2032 y \u2032 =x =y cos\u03b8+y cos\u03b8\u2212x sin\u03b8, sin\u03b8, (15.8) in which the new x \u2032 mixes the old x and y , and the new y \u2032 also mixes the old x and y ; similarly, in the Lorentz transformation we find a new x \u2032 which is a mixture of x and t , and a new t \u2032 which is a mixture of t and x . So the Lorentz transformation is analogous to a rotation, only it is a \u201crotation\u201d in space and time, which appears to be a strange concept. A check of the analogy to rotation can be made by calculating the quantity x \u20322 + y \u20322 + z \u20322 \u2212 c 2 t \u20322 = x 2 + y 2 + z 2 \u2212 c 2 t 2 . (15.9) In this equation the first three terms on each side represent, in three-dimensional geometry, the square of the distance between a point and the origin (surface of a sphere) which remains unchanged (invariant) regardless of rotation of the coordinate axes. Similarly, Eq. (15.9) shows that there is a certain combination which includes time, that is invariant to a Lorentz transformation. Thus, the analogy to a rotation is complete, and is of such a kind that vectors, i.e., quantities involving \u201ccomponents\u201d which transform the same way as the coordinates and time, are also useful in connection with relativity. Thus we contemplate an extension of the idea of vectors, which we have so far considered to have only space components, to include a time component. That is, we expect that there will be vectors with four components, three of which are like the components of an ordinary vector, and with these will be associated a fourth component, which is the analog of the time part. This concept will be analyzed further in the next chapters, where we shall find that if the ideas of the preceding paragraph are applied to momentum, the transformation gives three space parts that are like ordinary momentum components, and a fourth component, the time part, which is the energy. We are now ready to investigate, more generally, what form the laws of mechanics take under the Lorentz transformation. [We have thus far explained how length and time change, but not how we get the modified formula for m (Eq. 15.1). We shall do this in the next chapter.] To see the consequences of Einstein\u2019s modification of m for Newtonian mechanics, we start with the Newtonian law that force is the rate of change of momentum, or F=d(mv)/dt. d ( ) / d Momentum is still given by mv , but when we use the new m this becomes p=mv= m 0 v 1\u2212 v 2 / c 2 \u2212 \u2212 \u2212 \u2212 \u2212 \u2212 \u2212 \u2212 \u221a . (15.10) This is Einstein\u2019s modification of Newton\u2019s laws. Under this modification, if action and reaction are still equal (which they may not be in detail, but are in the long run), there will be conservation of momentum in the same way as before, but the quantity that is being conserved is not the old mv with its constant mass, but instead is the quantity shown in (15.10), which has the modified mass. When this change is made in the formula for momentum, conservation of momentum still works. Now let us see how momentum varies with speed. In Newtonian mechanics it is proportional to the speed and, according to (15.10), over a considerable range of speed, but small compared with c , it is nearly the same in relativistic mechanics, because the square-root expression differs only slightly from 1 . But when v is almost equal to c , the square-root expression approaches zero, and the momentum therefore goes toward infinity. What happens if a constant force acts on a body for a long time? In Newtonian mechanics the body keeps picking up speed until it goes faster than light. But this is impossible in relativistic mechanics. In relativity, the body keeps picking up, not speed, but momentum, which can continually increase because the mass is increasing. After a while there is practically no acceleration in the sense of a change of velocity, but the momentum continues to increase. Of course, whenever a force produces very little change in the velocity of a body, we say that the body has a great deal of inertia, and that is exactly what our formula for relativistic mass says (see Eq. 15.10)\u2014it says that the inertia is very great when v is nearly as great as c . As an example of this effect, to deflect the high-speed electrons in the synchrotron that is used here at Caltech, we need a magnetic field that is 2000 times stronger than would be expected on the basis of Newton\u2019s laws. In other words, the mass of the electrons in the synchrotron is 2000 times as great as their normal mass, and is as great as that of a proton! That m should be 2000 times m 0 means that 1\u2212 v 2 / c 2 must be 1/4,000,000 , and that means that v differs from c by one part in 8,000,000 , so the electrons are getting pretty close to the speed of light. If the electrons and light were both to start from the synchrotron (estimated as 700 feet away) and rush out to Bridge Lab, which would arrive first? The light, of course, because light always travels faster.1 How much earlier? That is too hard to tell\u2014instead, we tell by what distance the light is ahead: it is about 1/1000 of an inch, or 1 4 the thickness of a piece of paper! When the electrons are going that fast their masses are enormous, but their speed cannot exceed the speed of light. Now let us look at some further consequences of relativistic change of mass. Consider the motion of the molecules in a small tank of gas. When the gas is heated, the speed of the molecules is increased, and therefore the mass is also increased and the gas is heavier. An approximate formula to express the increase of mass, for the case when the velocity is small, can be found by expanding m 0 / 1\u2212 v 2 / c 2 \u2212 \u2212 \u2212 \u2212 \u2212 \u2212 \u2212 \u2212 \u221a = m 0 (1\u2212 v 2 / c 2 ) \u22121/2 in a power series, using the binomial theorem. We get m 0 (1\u2212 v 2 / c 2 ) \u22121/2 = m 0 (1+ 1 2 v 2 / c 2 + 3 8 v 4 / c 4 +\u22ef). / 1 3 We see clearly from the formula that the series converges rapidly when v is small, and the terms after the first two or three are negligible. So we can write m\u2245 m 0 + 1 2 m 0 v 2 ( 1 c 2 ) (15.11) in which the second term on the right expresses the increase of mass due to molecular velocity. When the temperature increases the v 2 increases proportionately, so we can say that the increase in mass is proportional to the increase in temperature. But since 1 2 m 0 v 2 is the kinetic energy in the old-fashioned Newtonian sense, we can also say that the increase in mass of all this body of gas is equal to the increase in kinetic energy divided by c 2 , or \u0394m=\u0394(K.E.)/ c 2 . The above observation led Einstein to the suggestion that the mass of a body can be expressed more simply than by the formula (15.1), if we say that the mass is equal to the total energy content divided by c 2 . If Eq. (15.11) is multiplied by c 2 the result is m c 2 = m 0 c 2 + 1 2 m 0 v 2 +\u22ef (15.12) Here, the term on the left expresses the total energy of a body, and we recognize the last term as the ordinary kinetic energy. Einstein interpreted the large constant term, m 0 c 2 , to be part of the total energy of the body, an intrinsic energy known as the \u201crest energy.\u201d Let us follow out the consequences of assuming, with Einstein, that the energy of a body always equals m c 2 . As an interesting result, we shall find the formula (15.1) for the variation of mass with speed, which we have merely assumed up to now. We start with the body at rest, when its energy is m 0 c 2 . Then we apply a force to the body, which starts it moving and gives it kinetic energy; therefore, since the energy has increased, the mass has increased\u2014this is implicit in the original assumption. So long as the force continues, the energy and the mass both continue to increase. We have already seen (Chapter 13) that the rate of change of energy with time equals the force times the velocity, or dE dt =F\u22c5v. (15.13) We also have (Chapter 9, Eq. 9.1) that F=d(mv)/dt . When these relations are put together with the definition of E , Eq. (15.13) becomes d(m c 2 ) dt =v\u22c5 d(mv) dt . (15.14) We wish to solve this equation for m . To do this we first use the mathematical trick of multiplying both sides by 2m , which changes the equation to c 2 (2m) dm dt =2mv\u22c5 d(mv) dt . (15.15) We need to get rid of the derivatives, which can be accomplished by integrating both sides. The quantity (2m)dm/dt can be recognized as the time derivative of m 2 , and (2mv)\u22c5d(mv)/dt is the time derivative of (mv ) 2 . So, Eq. (15.15) is the same as c 2 d( m 2 ) dt = d( m 2 v 2 ) dt . (15.16) If the derivatives of two quantities are equal, the quantities themselves differ at most by a constant, say C . This permits us to write m 2 c 2 = m 2 v 2 +C. (15.17) We need to define the constant C more explicitly. Since Eq. (15.17) must be true for all velocities, we can choose a special case where v=0 , and say that in this case the mass is m 0 . Substituting these values into Eq. (15.17) gives m 2 0 c 2 =0+C. 2 2 We can now use this value of C in Eq. (15.17), which becomes m 2 c 2 = m 2 v 2 + m 2 0 c 2 . (15.18) Dividing by c 2 and rearranging terms gives m 2 (1\u2212 v 2 / c 2 )= m 2 0 , 2 2 2 2 from which we get m= m 0 / 1\u2212 v 2 / c 2 \u2212 \u2212 \u2212 \u2212 \u2212 \u2212 \u2212 \u2212 \u221a . (15.19) This is the formula (15.1), and is exactly what is necessary for the agreement between mass and energy in Eq. (15.12). Ordinarily these energy changes represent extremely slight changes in mass, because most of the time we cannot generate much energy from a given amount of material; but in an atomic bomb of explosive energy equivalent to 20 kilotons of TNT, for example, it can be shown that the dirt after the explosion is lighter by 1 gram than the initial mass of the reacting material, because of the energy that was released, i.e., the released energy had a mass of 1 gram, according to the relationship \u0394E=\u0394(m c 2 ) . This theory of equivalence of mass and energy has been beautifully verified by experiments in which matter is annihilated\u2014converted totally to energy: An electron and a positron come together at rest, each with a rest mass m 0 . When they come together they disintegrate and two gamma rays emerge, each with the measured energy of m 0 c 2 . This experiment furnishes a direct determination of the energy associated with the existence of the rest mass of a particle."
    },
    {
        "input": "The Flow of Wet Water",
        "output": "In the last chapter we discussed the behavior of water, disregarding the phenomenon of viscosity. Now we would like to discuss the phenomena of the flow of fluids, including the effects of viscosity. We want to look at the real behavior of fluids. We will describe qualitatively the actual behavior of the fluids under various different circumstances so that you will get some feel for the subject. Although you will see some complicated equations and hear about some complicated things, it is not our purpose that you should learn all these things. This is, in a sense, a \u201ccultural\u201d chapter which will give you some idea of the way the world is. There is only one item which is worth learning, and that is the simple definition of viscosity which we will come to in a moment. The rest is only for your entertainment. In the last chapter we found that the laws of motion of a fluid are contained in the equation \u2202v \u2202t +(v\u22c5\u2207)v=\u2212 \u2207p \u03c1 \u2212\u2207\u03d5+ fvisc \u03c1 . In our \u201cdry\u201d water approximation we left out the last term, so we were neglecting all viscous effects. Also, we sometimes made an additional approximation by considering the fluid as incompressible; then we had the additional equation \u2207\u22c5v=0. This last approximation is often quite good\u2014particularly when flow speeds are much slower than the speed of sound. But in real fluids it is almost never true that we can neglect the internal friction that we call viscosity; most of the interesting things that happen come from it in one way or another. For example, we saw that in \u201cdry\u201d water the circulation never changes\u2014if there is none to start out with, there will never be any. Yet, circulation in fluids is an everyday occurrence. We must fix up our theory. We begin with an important experimental fact. When we worked out the flow of \u201cdry\u201d water around or past a cylinder\u2014the so-called \u201cpotential flow\u201d\u2014we had no reason not to permit the water to have a velocity tangent to the surface; only the normal component had to be zero. We took no account of the possibility that there might be a shear force between the liquid and the solid. It turns out\u2014although it is not at all self-evident\u2014that in all circumstances where it has been experimentally checked, the velocity of a fluid is exactly zero at the surface of a solid. You have noticed, no doubt, that the blade of a fan will collect a thin layer of dust\u2014and that it is still there after the fan has been churning up the air. You can see the same effect even on the great fan of a wind tunnel. Why isn\u2019t the dust blown off by the air? In spite of the fact that the fan blade is moving at high speed through the air, the speed of the air relative to the fan blade goes to zero right at the surface. So the very smallest dust particles are not disturbed.1 We must modify the theory to agree with the experimental fact that in all ordinary fluids, the molecules next to a solid surface have zero velocity (relative to the surface).2 We originally characterized a liquid by the fact that if you put a shearing stress on it\u2014no matter how small\u2014it would give way. It flows. In static situations, there are no shear stresses. But before equilibrium is reached\u2014as long as you still push on it\u2014there can be shear forces. Viscosity describes these shear forces which exist in a moving fluid. To get a measure of the shear forces during the motion of a fluid, we consider the following kind of experiment. Suppose that we have two solid plane surfaces with water between them, as in Fig. 41\u20131, and we keep one stationary while moving the other parallel to it at the slow speed v0 . If you measure the force required to keep the upper plate moving, you find that it is proportional to the area of the plates and to v0/d , where d is the distance between the plates. So the shear stress F/A is proportional to v0/d : F A =\u03b7 v0 d . The constant of proportionality \u03b7 is called the coefficient of viscosity. If we have a more complicated situation, we can always consider a little, flat, rectangular cell in the water with its faces parallel to the flow, as in Fig. 41\u20132. The shear force across this cell is given by \u0394F \u0394A =\u03b7 \u0394 v x \u0394y =\u03b7 \u2202 v x \u2202y . (41.2) Now, \u2202 v x /\u2202y is the rate of change of the shear strain we defined in Chapter 39, so for a liquid, the shear stress is proportional to the rate of change of the shear strain. In the general case we write S xy =\u03b7( \u2202 v y \u2202x + \u2202 v x \u2202y ). (41.3) If there is a uniform rotation of the fluid, \u2202 v x /\u2202y is the negative of \u2202 v y /\u2202x and S xy is zero\u2014as it should be since there are no stresses in a uniformly rotating fluid. (We did a similar thing in defining e xy in Chapter 39.) There are, of course, the corresponding expressions for S yz and S zx . As an example of the application of these ideas, we consider the motion of a fluid between two coaxial cylinders. Let the inner one have the radius a and the peripheral velocity v a , and let the outer one have radius b and velocity v b . See Fig. 41\u20133. We might ask, what is the velocity distribution between the cylinders? To answer this question, we begin by finding a formula for the viscous shear in the fluid at a distance r from the axis. From the symmetry of the problem, we can assume that the flow is always tangential and that its magnitude depends only on r ; v=v(r) . If we watch a speck in the water at the radius r , its coordinates as a function of time are x=rcos\u03c9t,y=rsin\u03c9t, sin where \u03c9=v/r . Then the x - and y -components of velocity are v x v y = = \u2212r\u03c9sin\u03c9t r\u03c9cos\u03c9t = = \u2212\u03c9 \u03c9 y, x. (41.4) From Eq. (41.3), we have S xy =\u03b7[ \u2202 \u2202x (x\u03c9)\u2212 \u2202 \u2202y (y\u03c9)] =\u03b7[x \u2202\u03c9 \u2202x \u2212y \u2202\u03c9 \u2202y ]. (41.5) For a point at y=0 , \u2202\u03c9/\u2202y=0 , and x\u2202\u03c9/\u2202x is the same as rd\u03c9/dr . So at that point ( S xy ) y=0 =\u03b7r d\u03c9 dr . (41.6) (It is reasonable that S should depend on \u2202\u03c9/\u2202r ; when there is no change in \u03c9 with r , the liquid is in uniform rotation and there are no stresses.) The stress we have calculated is the tangential shear which is the same all around the cylinder. We can get the torque acting across a cylindrical surface at the radius r by multiplying the shear stress by the moment arm r and the area 2\u03c0rl (where l is the length of the cylinder). We get \u03c4=2\u03c0 r 2 l( S xy ) y=0 =2\u03c0\u03b7l r 3 d\u03c9 dr . (41.7) Since the motion of the water is steady\u2014there is no angular acceleration\u2014the net torque on the cylindrical shell of water between r and r+dr must be zero; that is, the torque at r must be balanced by an equal and opposite torque at r+dr , so that \u03c4 must be independent of r . In other words, r 3 d\u03c9/dr is equal to some constant, say A , and d\u03c9 dr = A r 3 . (41.8) Integrating, we find that \u03c9 varies with r as \u03c9=\u2212 A 2 r 2 +B. (41.9) The constants A and B are to be determined to fit the conditions that \u03c9= \u03c9 a at r=a , and \u03c9= \u03c9 b at r=b . We get that A B = 2 a 2 b 2 b 2 \u2212 a 2 ( \u03c9 b \u2212 \u03c9 a ), = b 2 \u03c9 b \u2212 a 2 \u03c9 a b 2 \u2212 a 2 . (41.10) So we know \u03c9 as a function of r , and from it v=\u03c9r . If we want the torque, we can get it from Eqs. (41.7) and (41.8): \u03c4=2\u03c0\u03b7lA 2 l A or \u03c4= 4\u03c0\u03b7l a 2 b 2 b 2 \u2212 a 2 ( \u03c9 b \u2212 \u03c9 a ). (41.11) It is proportional to the relative angular velocities of the two cylinders. One standard apparatus for measuring the coefficients of viscosity is built this way. One cylinder\u2014say the outer one\u2014is on pivots but is held stationary by a spring balance which measures the torque on it, while the inner one is rotated at a constant angular velocity. The coefficient of viscosity is then determined from Eq. (41.11). From its definition, you see that the units of \u03b7 are newton \u22c5 sec/m 2 . For water at 20 \u2218 C, \u03b7= 10 \u22123 newton\u22c5sec/m 2 . 3 2 It is usually more convenient to use the kinematic viscosity, which is \u03b7 divided by the density \u03c1 . The values for water and air are then comparable: water at 20 \u2218 C, air at 20 \u2218 C, \u03b7/\u03c1= 10 \u22126 m 2 /sec, \u03b7/\u03c1=15\u00d7 10 \u22126 m 2 /sec. (41.12) Viscosities usually depend strongly on temperature. For instance, for water just above the freezing point, \u03b7/\u03c1 is 1.8 times larger than it is at 20 \u2218 C. We now go to a general theory of viscous flow\u2014at least in the most general form known to man. We already understand that the shear stress components are proportional to the spatial derivatives of the various velocity components such as \u2202 v x /\u2202y or \u2202 v y /\u2202x . However, in the general case of a compressible fluid there is another term in the stress which depends on other derivatives of the velocity. The general expression is S ij =\u03b7( \u2202 v i \u2202 x j + \u2202 v j \u2202 x i )+ \u03b7 \u2032 \u03b4 ij (\u2207\u22c5v), (41.13) where x i is any one of the rectangular coordinates x , y , or z , and v i is any one of the rectangular coordinates of the velocity. (The symbol \u03b4 ij is the Kronecker delta which is 1 when i=j and 0 for i\u2260j .) The additional term adds \u03b7 \u2032 \u2207\u22c5v to all the diagonal elements S ii of the stress tensor. If the liquid is incompressible \u2207\u22c5v=0 , and this extra term doesn\u2019t appear. So it has to do with internal forces during compression. So two constants are required to describe the liquid, just as we had two constants to describe a homogeneous elastic solid. The coefficient \u03b7 is the \u201cordinary\u201d coefficient of viscosity which we have already encountered. It is also called the first coefficient of viscosity or the \u201cshear viscosity coefficient,\u201d and the new coefficient \u03b7 \u2032 is called the second coefficient of viscosity. Now we want to determine the viscous force per unit volume, f visc , so we can put it into Eq. (41.1) to get the equation of motion for a real fluid. The force on a small cubical volume element of a fluid is the resultant of the forces on all the six faces. Taking them two at a time, we will get differences that depend on the derivatives of the stresses, and, therefore, on the second derivatives of the velocity. This is nice because it will get us back to a vector equation. The component of the viscous force per unit volume in the direction of the rectangular coordinate x i is ( f visc ) i = = \u2211 j=1 3 \u2202 S ij \u2202 x j \u2211 j=1 3 \u2202 \u2202 x j {\u03b7( \u2202 v i \u2202 x j + \u2202 v j \u2202 x i )} + \u2202 \u2202 x i ( \u03b7 \u2032 \u2207\u22c5v). (41.14) Usually, the variation of the viscosity coefficients with position is not significant and can be neglected. Then, the viscous force per unit volume contains only second derivatives of the velocity. We saw in Chapter 39 that the most general form of second derivatives that can occur in a vector equation is the sum of a term in the Laplacian ( \u2207\u22c5\u2207v= \u2207 2 v ), and a term in the gradient of the divergence (\u2207(\u2207\u22c5v)) ( . Equation (41.14) is just such a sum with the coefficients \u03b7 and (\u03b7+ \u03b7 \u2032 ) . We get f visc =\u03b7 \u2207 2 v+(\u03b7+ \u03b7 \u2032 )\u2207(\u2207\u22c5v). (41.15) In the incompressible case, \u2207\u22c5v=0 , and the viscous force per unit volume is just \u03b7 \u2207 2 v . That is all that many people use; however, if you should want to calculate the absorption of sound in a fluid, you would need the second term. We can now complete our general equation of motion for a real fluid. Substituting Eq. (41.15) into Eq. (41.1), we get \u03c1{ \u2202v \u2202t +(v\u22c5\u2207)v}= \u2212\u2207p\u2212\u03c1\u2207\u03d5+\u03b7 \u2207 2 v+(\u03b7+ \u03b7 \u2032 )\u2207(\u2207\u22c5v). It\u2019s complicated. But that\u2019s the way nature is. If we introduce the vorticity \u03a9=\u2207\u00d7v , as we did before, we can write our equation as \u03c1{ \u2202v \u2202t +\u03a9\u00d7v+ 1 2 \u2207 v 2 }= \u2212\u2207p\u2212\u03c1\u2207\u03d5+\u03b7 \u2207 2 v+(\u03b7+ \u03b7 \u2032 )\u2207(\u2207\u22c5v). (41.16) We are supposing again that the only body forces acting are conservative forces like gravity. To see what the new term means, let\u2019s look at the incompressible fluid case. Then, if we take the curl of Eq. (41.16), we get \u2202\u03a9 \u2202t +\u2207\u00d7(\u03a9\u00d7v)= \u03b7 \u03c1 \u2207 2 \u03a9. (41.17) This is like Eq. (40.9) except for the new term on the right-hand side. When the right-hand side was zero, we had the Helmholtz theorem that the vorticity stays with the fluid. Now, we have the rather complicated nonzero term on the right-hand side which, however, has straightforward physical consequences. If we disregard for the moment the term \u2207\u00d7(\u03a9\u00d7v) , we have a diffusion equation. The new term means that the vorticity \u03a9 diffuses through the fluid. If there is a large gradient in the vorticity, it will spread out into the neighboring fluid. This is the term that causes the smoke ring to get thicker as it goes along. Also, it shows up nicely if you send a \u201cclean\u201d vortex (a \u201csmokeless\u201d ring made by the apparatus described in the last chapter) through a cloud of smoke. When it comes out of the cloud, it will have picked up some smoke, and you will see a hollow shell of a smoke ring. Some of the \u03a9 diffuses outward into the smoke, while still maintaining its forward motion with the vortex. We will now describe the changes which are made in the character of fluid flow as a consequence of the new viscosity term. We will look at two problems in some detail. The first of these is the flow of a fluid past a cylinder\u2014a flow which we tried to calculate in the previous chapter using the theory for nonviscous flow. It turns out that the viscous equations can be solved by man today only for a few special cases. So some of what we will tell you is based on experimental measurements\u2014assuming that the experimental model satisfies Eq. (41.17). The mathematical problem is this: We would like the solution for the flow of an incompressible, viscous fluid past a long cylinder of diameter D . The flow should be given by Eq. (41.17) and by \u03a9=\u2207\u00d7v (41.18) with the conditions that the velocity at large distances is some constant velocity, say V (parallel to the x -axis), and at the surface of the cylinder is zero. That is, v x = v y = v z =0 (41.19) for x 2 + y 2 = D 2 4 . 2 That specifies completely the mathematical problem. If you look at the equations, you see that there are four different parameters to the problem: \u03b7 , \u03c1 , D , and V . You might think that we would have to give a whole series of cases for different V \u2019s, different D \u2019s, and so on. However, that is not the case. All the different possible solutions correspond to different values of one parameter. This is the most important general thing we can say about viscous flow. To see why this is so, notice first that the viscosity and density appear only in the ratio \u03b7/\u03c1 \u2014the kinematic viscosity. That reduces the number of independent parameters to three. Now suppose we measure all distances in the only length that appears in the problem, the diameter D of the cylinder; that is, we substitute for x , y , z , the new variables x \u2032 , y \u2032 , z \u2032 with x= x \u2032 D,y= y \u2032 D,z= z \u2032 D. \u2032 \u2032 \u2032 Then D disappears from (41.19). In the same way, if we measure all velocities in terms of V \u2014that is, we set v= v \u2032 V \u2014we get rid of the V , and v \u2032 is just equal to 1 at large distances. Since we have fixed our units of length and velocity, our unit of time is now D/V ; so we should set t= t \u2032 D V . (41.20) With our new variables, the derivatives in Eq. (41.18) get changed from \u2202/\u2202x to (1/D)\u2202/\u2202 x \u2032 , and so on; so Eq. (41.18) becomes \u03a9=\u2207\u00d7v= V D \u2207 \u2032 \u00d7 v \u2032 = V D \u03a9 \u2032 . (41.21) Our main equation (41.17) then reads \u2202 \u03a9 \u2032 \u2202 t \u2032 + \u2207 \u2032 \u00d7( \u03a9 \u2032 \u00d7 v \u2032 )= \u03b7 \u03c1VD \u2207 \u20322 \u03a9 \u2032 . \u2032 All the constants condense into one factor which we write, following tradition, as 1/R : R= \u03c1 \u03b7 VD. (41.22) If we just remember that all of our equations are to be written with all quantities in the new units, we can omit all the primes. Our equations for the flow are then \u2202\u03a9 \u2202t +\u2207\u00d7(\u03a9\u00d7v)= 1 R \u2207 2 \u03a9. (41.23) and \u03a9=\u2207\u00d7v \u03a9 \u2207 with the conditions v=0 0 for x 2 + y 2 =1/4 (41.24) and v x =1, v y = v z =0 1 0 for x 2 + y 2 + z 2 \u226b1. 2 2 2 What this all means physically is very interesting. It means, for example, that if we solve the problem of the flow for one velocity V 1 and a certain cylinder diameter D 1 , and then ask about the flow for a different diameter D 2 and a different fluid, the flow will be the same for the velocity V 2 which gives the same Reynolds number\u2014that is, when R 1 = \u03c1 1 \u03b7 1 V 1 D 1 = R 2 = \u03c1 2 \u03b7 2 V 2 D 2 . (41.25) For any two situations which have the same Reynolds number, the flows will \u201clook\u201d the same\u2014in terms of the appropriate scaled x \u2032 , y \u2032 , z \u2032 , and t \u2032 . This is an important proposition because it means that we can determine what the behavior of the flow of air past an airplane wing will be without having to build an airplane and try it. We can, instead, make a model and make measurements using a velocity that gives the same Reynolds number. This is the principle which allows us to apply the results of \u201cwind-tunnel\u201d measurements on small-scale airplanes, or \u201cmodel-basin\u201d results on scale model boats, to the full-scale objects. Remember, however, that we can only do this provided the compressibility of the fluid can be neglected. Otherwise, a new quantity enters\u2014the speed of sound. And different situations will really correspond to each other only if the ratio of V to the sound speed is also the same. This latter ratio is called the Mach number. So, for velocities near the speed of sound or above, the flows are the same in two situations if both the Mach number and the Reynolds number are the same for both situations. Let\u2019s go back to the problem of low-speed (nearly incompressible) flow over the cylinder. We will give a qualitative description of the flow of a real fluid. There are many things we might want to know about such a flow\u2014for instance, what is the drag force on the cylinder? The drag force on a cylinder is plotted in Fig. 41\u20134 as a function of R \u2014which is proportional to the air speed V if everything else is held fixed. What is actually plotted is the so-called drag coefficient C D , which is a dimensionless number equal to the force divided by 1 2 \u03c1 V 2 Dl , where D is the diameter, l is the length of the cylinder, and \u03c1 is the density of the liquid: C D = F 1 2 \u03c1 V 2 Dl . F The coefficient of drag varies in a rather complicated way, giving us a pre-hint that something rather interesting and complicated is happening in the flow. We will now describe the nature of flow for the different ranges of the Reynolds number. First, when the Reynolds number is very small, the flow is quite steady; that is, the velocity is constant at any place, and the flow goes around the cylinder. The actual distribution of the flow lines is, however, not like it is in potential flow. They are solutions of a somewhat different equation. When the velocity is very low or, what is equivalent, when the viscosity is very high so the stuff is like honey, then the inertial terms are negligible and the flow is described by the equation \u2207 2 \u03a9=0. 2 This equation was first solved by Stokes. He also solved the same problem for a sphere. If you have a small sphere moving under such conditions of low Reynolds number, the force needed to drag it is equal to 6\u03c0\u03b7aV , where a is the radius of the sphere and V is its velocity. This is a very useful formula because it tells the speed at which tiny grains of dirt (or other particles which can be approximated as spheres) move through a fluid under a given force\u2014as, for instance, in a centrifuge, or in sedimentation, or diffusion. In the low Reynolds number region\u2014for R less than 1 \u2014the lines of v around a cylinder are as drawn in Fig. 41\u20135. If we now increase the fluid speed to get a Reynolds number somewhat greater than 1 , we find that the flow is different. There is a circulation behind the sphere, as shown in Fig. 41\u20136(b). It is still an open question as to whether there is always a circulation there even at the smallest Reynolds number or whether things suddenly change at a certain Reynolds number. It used to be thought that the circulation grew continuously. But it is now thought that it appears suddenly, and it is certain that the circulation increases with R . In any case, there is a different character to the flow for R in the region from about 10 to 30 . There is a pair of vortices behind the cylinder. The flow changes again by the time we get to a number of 40 or so. There is suddenly a complete change in the character of the motion. What happens is that one of the vortices behind the cylinder gets so long that it breaks off and travels downstream with the fluid. Then the fluid curls around behind the cylinder and makes a new vortex. The vortices peel off alternately on each side, so an instantaneous view of the flow looks roughly as sketched in Fig. 41\u20136(c). The stream of vortices is called a \u201cK\u00e1rm\u00e1n vortex street.\u201d They always appear for R>40 . We show a photograph of such a flow in Fig. 41\u20137. The difference between the two flows in Fig. 41\u20136(c) and 41\u20136(b) or 41\u20136(a) is almost a complete difference in regime. In Fig. 41\u20136(a) or (b), the velocity is constant, whereas in Fig. 41\u20136(c), the velocity at any point varies with time. There is no steady solution above R=40 \u2014which we have marked on Fig. 41\u20134 by a dashed line. For these higher Reynolds numbers, the flow varies with time but in a regular, cyclic fashion. We can get a physical idea of how these vortices are produced. We know that the fluid velocity must be zero at the surface of the cylinder and that it also increases rapidly away from that surface. Vorticity is created by this large local variation in fluid velocity. Now when the main stream velocity is low enough, there is sufficient time for this vorticity to diffuse out of the thin region near the solid surface where it is produced and to grow into a large region of vorticity. This physical picture should help to prepare us for the next change in the nature of the flow as the main stream velocity, or R , is increased still more. As the velocity gets higher and higher, there is less and less time for the vorticity to diffuse into a larger region of fluid. By the time we reach a Reynolds number of several hundred, the vorticity begins to fill in a thin band, as shown in Fig. 41\u20136(d). In this layer the flow is chaotic and irregular. The region is called the boundary layer and this irregular flow region works its way farther and farther upstream as R is increased. In the turbulent region, the velocities are very irregular and \u201cnoisy\u201d; also the flow is no longer two-dimensional but twists and turns in all three dimensions. There is still a regular alternating motion superimposed on the turbulent one. As the Reynolds number is increased further, the turbulent region works its way forward until it reaches the point where the flow lines leave the cylinder\u2014for flows somewhat above R= 10 5 . The flow is as shown in Fig. 41\u20136(e), and we have what is called a \u201cturbulent boundary layer.\u201d Also, there is a drastic change in the drag force; it drops by a large factor, as shown in Fig. 41\u20134. In this speed region, the drag force actually decreases with increasing speed. There seems to be little evidence of periodicity. What happens for still larger Reynolds numbers? As we increase the speed further, the wake increases in size again and the drag increases. The latest experiments\u2014which go up to R= 10 7 or so\u2014indicate that a new periodicity appears in the wake, either because the whole wake is oscillating back and forth in a gross motion or because some new kind of vortex is occurring together with an irregular noisy motion. The details are as yet not entirely clear, and are still being studied experimentally. We would like to point out that none of the flows we have described are anything like the potential flow solution we found in the preceding chapter. This is, at first sight, quite surprising. After all, R is proportional to 1/\u03b7 . So \u03b7 going to zero is equivalent to R going to infinity. And if we take the limit of large R in Eq. (41.23), we get rid of the right-hand side and get just the equations of the last chapter. Yet, you would find it hard to believe that the highly turbulent flow at R= 10 7 was approaching the smooth flow computed from the equations of \u201cdry\u201d water. How can it be that as we approach R=\u221e , the flow described by Eq. (41.23) gives a completely different solution from the one we obtained taking \u03b7=0 to start out with? The answer is very interesting. Note that the right-hand term of Eq. (41.23) has 1/R times a second derivative. It is a higher derivative than any other derivative in the equation. What happens is that although the coefficient 1/R is small, there are very rapid variations of \u03a9 in the space near the surface. These rapid variations compensate for the small coefficient, and the product does not go to zero with increasing R . The solutions do not approach the limiting case as the coefficient of \u2207 2 \u03a9 goes to zero. You may be wondering, \u201cWhat is the fine-grain turbulence and how does it maintain itself? How can the vorticity which is made somewhere at the edge of the cylinder generate so much noise in the background?\u201d The answer is again interesting. Vorticity has a tendency to amplify itself. If we forget for a moment about the diffusion of vorticity which causes a loss, the laws of flow say (as we have seen) that the vortex lines are carried along with the fluid, at the velocity v . We can imagine a certain number of lines of \u03a9 which are being distorted and twisted by the complicated flow pattern of v . This pulls the lines closer together and mixes them all up. Lines that were simple before will get knotted and pulled close together. They will be longer and tighter together. The strength of the vorticity will increase and its irregularities\u2014the pluses and minuses\u2014will, in general, increase. So the magnitude of vorticity in three dimensions increases as we twist the fluid about. You might well ask, \u201cWhen is the potential flow a satisfactory theory at all?\u201d In the first place, it is satisfactory outside the turbulent region where the vorticity has not entered appreciably by diffusion. By making special streamlined bodies, we can keep the turbulent region as small as possible; the flow around airplane wings\u2014which are carefully designed\u2014is almost entirely true potential flow. It is possible to demonstrate that the complex and shifting character of the flow past a cylinder is not special but that the great variety of flow possibilities occurs generally. We have worked out in Section 41\u20131 a solution for the viscous flow between two cylinders, and we can compare the results with what actually happens. If we take two concentric cylinders with an oil in the space between them and put a fine aluminum powder as a suspension in the oil, the flow is easy to see. Now if we turn the outer cylinder slowly, nothing unexpected happens; see Fig. 41\u20138(a). Alternatively, if we turn the inner cylinder slowly, nothing very striking occurs. However, if we turn the inner cylinder at a higher rate, we get a surprise. The fluid breaks into horizontal bands, as indicated in Fig. 41\u20138(b). When the outer cylinder rotates at a similar rate with the inner one at rest, no such effect occurs. How can it be that there is a difference between rotating the inner or the out cylinder? After all, the flow pattern we derived in Section 41\u20131 depended only on \u03c9 b \u2212 \u03c9 a . We can get the answer by looking at the cross sections shown in Fig. 41\u20139. When the inner layers of the fluid are moving more rapidly than the outer ones, they tend to move outward\u2014the centrifugal force is larger than the pressure holding them in place. A whole layer cannot move out uniformly because the outer layers are in the way. It must break into cells and circulate, as shown in Fig. 41\u20139(b). It is like the convection currents in a room which has hot air at the bottom. When the inner cylinder is at rest and the outer cylinder has a high velocity, the centrifugal forces build up a pressure gradient which keeps everything in equilibrium\u2014see Fig. 41\u20139(c) (as in a room with hot air at the top). Now let\u2019s speed up the inner cylinder. At first, the number of bands increases. Then suddenly you see the bands become wavy, as in Fig. 41\u20138(c), and the waves travel around the cylinder. The speed of these waves is easily measured. For high rotation speeds they approach 1/3 the speed of the inner cylinder. And no one knows why! There\u2019s a challenge. A simple number like 1/3 , and no explanation. In fact, the whole mechanism of the wave formation is not very well understood; yet it is steady laminar flow. If we now start rotating the outer cylinder also\u2014but in the opposite direction\u2014the flow pattern starts to break up. We get wavy regions alternating with apparently quiet regions, as sketched in Fig. 41\u20138(d), making a spiral pattern. In these \u201cquiet\u201d regions, however, we can see that the flow is really quite irregular; it is, in fact completely turbulent. The wavy regions also begin to show irregular turbulent flow. If the cylinders are rotated still more rapidly, the whole flow becomes chaotically turbulent. In this simple experiment we see many interesting regimes of flow which are quite different, and yet which are all contained in our simple equation for various values of the one parameter R . With our rotating cylinders, we can see many of the effects which occur in the flow past a cylinder: first, there is a steady flow; second, a flow sets in which varies in time but in a regular, smooth way; finally, the flow becomes completely irregular. You have all seen the same effects in the column of smoke rising from a cigarette in quiet air. There is a smooth steady column followed by a series of twistings as the stream of smoke begins to break up, ending finally in an irregular churning cloud of smoke. The main lesson to be learned from all of this is that a tremendous variety of behavior is hidden in the simple set of equations in (41.23). All the solutions are for the same equations, only with different values of R . We have no reason to think that there are any terms missing from these equations. The only difficulty is that we do not have the mathematical power today to analyze them except for very small Reynolds numbers\u2014that is, in the completely viscous case. That we have written an equation does not remove from the flow of fluids its charm or mystery or its surprise. If such variety is possible in a simple equation with only one parameter, how much more is possible with more complex equations! Perhaps the fundamental equation that describes the swirling nebulae and the condensing, revolving, and exploding stars and galaxies is just a simple equation for the hydrodynamic behavior of nearly pure hydrogen gas. Often, people in some unjustified fear of physics say you can\u2019t write an equation for life. Well, perhaps we can. As a matter of fact, we very possibly already have the equation to a sufficient approximation when we write the equation of quantum mechanics: H\u03c8=\u2212 \u210f i \u2202\u03c8 \u2202t . \u210f \u2202 \u03c8 We have just seen that the complexities of things can so easily and dramatically escape the simplicity of the equations which describe them. Unaware of the scope of simple equations, man has often concluded that nothing short of God, not mere equations, is required to explain the complexities of the world. We have written the equations of water flow. From experiment, we find a set of concepts and approximations to use to discuss the solution\u2014vortex streets, turbulent wakes, boundary layers. When we have similar equations in a less familiar situation, and one for which we cannot yet experiment, we try to solve the equations in a primitive, halting, and confused way to try to determine what new qualitative features may come out, or what new qualitative forms are a consequence of the equations. Our equations for the sun, for example, as a ball of hydrogen gas, describe a sun without sunspots, without the rice-grain structure of the surface, without prominences, without coronas. Yet, all of these are really in the equations; we just haven\u2019t found the way to get them out. There are those who are going to be disappointed when no life is found on other planets. Not I\u2014I want to be reminded and delighted and surprised once again, through interplanetary exploration, with the infinite variety and novelty of phenomena that can be generated from such simple principles. The test of science is its ability to predict. Had you never visited the earth, could you predict the thunderstorms, the volcanos, the ocean waves, the auroras, and the colorful sunset? A salutary lesson it will be when we learn of all that goes on on each of those dead planets\u2014those eight or ten balls, each agglomerated from the same dust cloud and each obeying exactly the same laws of physics. The next great era of awakening of human intellect may well produce a method of understanding the qualitative content of equations. Today we cannot. Today we cannot see that the water flow equations contain such things as the barber pole structure of turbulence that one sees between rotating cylinders. Today we cannot see whether Schr\u00f6dinger\u2019s equation contains frogs, musical composers, or morality\u2014or whether it does not. We cannot say whether something beyond it like God is needed, or not. And so we can all hold strong opinions either way."
    },
    {
        "input": "Symmetry in Physical Laws",
        "output": "The subject of this chapter is what we may call symmetry in physical laws. We have already discussed certain features of symmetry in physical laws in connection with vector analysis (Chapter 11), the theory of relativity (Chapter 16), and rotation (Chapter 20). Why should we be concerned with symmetry? In the first place, symmetry is fascinating to the human mind, and everyone likes objects or patterns that are in some way symmetrical. It is an interesting fact that nature often exhibits certain kinds of symmetry in the objects we find in the world around us. Perhaps the most symmetrical object imaginable is a sphere, and nature is full of spheres\u2014stars, planets, water droplets in clouds. The crystals found in rocks exhibit many different kinds of symmetry, the study of which tells us some important things about the structure of solids. Even the animal and vegetable worlds show some degree of symmetry, although the symmetry of a flower or of a bee is not as perfect or as fundamental as is that of a crystal. But our main concern here is not with the fact that the objects of nature are often symmetrical. Rather, we wish to examine some of the even more remarkable symmetries of the universe\u2014the symmetries that exist in the basic laws themselves which govern the operation of the physical world. First, what is symmetry? How can a physical law be \u201csymmetrical\u201d? The problem of defining symmetry is an interesting one and we have already noted that Weyl gave a good definition, the substance of which is that a thing is symmetrical if there is something we can do to it so that after we have done it, it looks the same as it did before. For example, a symmetrical vase is of such a kind that if we reflect or turn it, it will look the same as it did before. The question we wish to consider here is what we can do to physical phenomena, or to a physical situation in an experiment, and yet leave the result the same. A list of the known operations under which various physical phenomena remain invariant is shown in Table 52\u20131. The first thing we might try to do, for example, is to translate the phenomenon in space. If we do an experiment in a certain region, and then build another apparatus at another place in space (or move the original one over) then, whatever went on in one apparatus, in a certain order in time, will occur in the same way if we have arranged the same condition, with all due attention to the restrictions that we mentioned before: that all of those features of the environment which make it not behave the same way have also been moved over\u2014we talked about how to define how much we should include in those circumstances, and we shall not go into those details again. In the same way, we also believe today that displacement in time will have no effect on physical laws. (That is, as far as we know today\u2014all of these things are as far as we know today!) That means that if we build a certain apparatus and start it at a certain time, say on Thursday at 10:00 a.m., and then build the same apparatus and start it, say, three days later in the same condition, the two apparatuses will go through the same motions in exactly the same way as a function of time no matter what the starting time, provided again, of course, that the relevant features of the environment are also modified appropriately in time. That symmetry means, of course, that if one bought General Motors stock three months ago, the same thing would happen to it if he bought it now! We have to watch out for geographical differences too, for there are, of course, variations in the characteristics of the earth\u2019s surface. So, for example, if we measure the magnetic field in a certain region and move the apparatus to some other region, it may not work in precisely the same way because the magnetic field is different, but we say that is because the magnetic field is associated with the earth. We can imagine that if we move the whole earth and the equipment, it would make no difference in the operation of the apparatus. Another thing that we discussed in considerable detail was rotation in space: if we turn an apparatus at an angle it works just as well, provided we turn everything else that is relevant along with it. In fact, we discussed the problem of symmetry under rotation in space in some detail in Chapter 11, and we invented a mathematical system called vector analysis to handle it as neatly as possible. On a more advanced level we had another symmetry\u2014the symmetry under uniform velocity in a straight line. That is to say\u2014a rather remarkable effect\u2014that if we have a piece of apparatus working a certain way and then take the same apparatus and put it in a car, and move the whole car, plus all the relevant surroundings, at a uniform velocity in a straight line, then so far as the phenomena inside the car are concerned there is no difference: all the laws of physics appear the same. We even know how to express this more technically, and that is that the mathematical equations of the physical laws must be unchanged under a Lorentz transformation. As a matter of fact, it was a study of the relativity problem that concentrated physicists\u2019 attention most sharply on symmetry in physical laws. Now the above-mentioned symmetries have all been of a geometrical nature, time and space being more or less the same, but there are other symmetries of a different kind. For example, there is a symmetry which describes the fact that we can replace one atom by another of the same kind; to put it differently, there are atoms of the same kind. It is possible to find groups of atoms such that if we change a pair around, it makes no difference\u2014the atoms are identical. Whatever one atom of oxygen of a certain type will do, another atom of oxygen of that type will do. One may say, \u201cThat is ridiculous, that is the definition of equal types!\u201d That may be merely the definition, but then we still do not know whether there are any \u201catoms of the same type\u201d; the fact is that there are many, many atoms of the same type. Thus it does mean something to say that it makes no difference if we replace one atom by another of the same type. The so-called elementary particles of which the atoms are made are also identical particles in the above sense\u2014all electrons are the same; all protons are the same; all positive pions are the same; and so on. After such a long list of things that can be done without changing the phenomena, one might think we could do practically anything; so let us give some examples to the contrary, just to see the difference. Suppose that we ask: \u201cAre the physical laws symmetrical under a change of scale?\u201d Suppose we build a certain piece of apparatus, and then build another apparatus five times bigger in every part, will it work exactly the same way? The answer is, in this case, no! The wavelength of light emitted, for example, by the atoms inside one box of sodium atoms and the wavelength of light emitted by a gas of sodium atoms five times in volume is not five times longer, but is in fact exactly the same as the other. So the ratio of the wavelength to the size of the emitter will change. Another example: we see in the newspaper, every once in a while pictures of a great cathedral made with little matchsticks\u2014a tremendous work of art by some retired fellow who keeps gluing matchsticks together. It is much more elaborate and wonderful than any real cathedral. If we imagine that this wooden cathedral were actually built on the scale of a real cathedral, we see where the trouble is; it would not last\u2014the whole thing would collapse because of the fact that scaled-up matchsticks are just not strong enough. \u201cYes,\u201d one might say, \u201cbut we also know that when there is an influence from the outside, it also must be changed in proportion!\u201d We are talking about the ability of the object to withstand gravitation. So what we should do is first to take the model cathedral of real matchsticks and the real earth, and then we know it is stable. Then we should take the larger cathedral and take a bigger earth. But then it is even worse, because the gravitation is increased still more! Today, of course, we understand the fact that phenomena depend on the scale on the grounds that matter is atomic in nature, and certainly if we built an apparatus that was so small there were only five atoms in it, it would clearly be something we could not scale up and down arbitrarily. The scale of an individual atom is not at all arbitrary\u2014it is quite definite. The fact that the laws of physics are not unchanged under a change of scale was discovered by Galileo. He realized that the strengths of materials were not in exactly the right proportion to their sizes, and he illustrated this property that we were just discussing, about the cathedral of matchsticks, by drawing two bones, the bone of one dog, in the right proportion for holding up his weight, and the imaginary bone of a \u201csuper dog\u201d that would be, say, ten or a hundred times bigger\u2014that bone was a big, solid thing with quite different proportions. We do not know whether he ever carried the argument quite to the conclusion that the laws of nature must have a definite scale, but he was so impressed with this discovery that he considered it to be as important as the discovery of the laws of motion, because he published them both in the same volume, called \u201cOn Two New Sciences.\u201d Another example in which the laws are not symmetrical, that we know quite well, is this: a system in rotation at a uniform angular velocity does not give the same apparent laws as one that is not rotating. If we make an experiment and then put everything in a space ship and have the space ship spinning in empty space, all alone at a constant angular velocity, the apparatus will not work the same way because, as we know, things inside the equipment will be thrown to the outside, and so on, by the centrifugal or Coriolis forces, etc. In fact, we can tell that the earth is rotating by using a so-called Foucault pendulum, without looking outside. Next we mention a very interesting symmetry which is obviously false, i.e., reversibility in time. The physical laws apparently cannot be reversible in time, because, as we know, all obvious phenomena are irreversible on a large scale: \u201cThe moving finger writes, and having writ, moves on.\u201d So far as we can tell, this irreversibility is due to the very large number of particles involved, and if we could see the individual molecules, we would not be able to discern whether the machinery was working forward or backwards. To make it more precise: we build a small apparatus in which we know what all the atoms are doing, in which we can watch them jiggling. Now we build another apparatus like it, but which starts its motion in the final condition of the other one, with all the velocities precisely reversed. It will then go through the same motions, but exactly in reverse. Putting it another way: if we take a motion picture, with sufficient detail, of all the inner works of a piece of material and shine it on a screen and run it backwards, no physicist will be able to say, \u201cThat is against the laws of physics, that is doing something wrong!\u201d If we do not see all the details, of course, the situation will be perfectly clear. If we see the egg splattering on the sidewalk and the shell cracking open, and so on, then we will surely say, \u201cThat is irreversible, because if we run the moving picture backwards the egg will all collect together and the shell will go back together, and that is obviously ridiculous!\u201d But if we look at the individual atoms themselves, the laws look completely reversible. This is, of course, a much harder discovery to have made, but apparently it is true that the fundamental physical laws, on a microscopic and fundamental level, are completely reversible in time! The symmetries of the physical laws are very interesting at this level, but they turn out, in the end, to be even more interesting and exciting when we come to quantum mechanics. For a reason which we cannot make clear at the level of the present discussion\u2014a fact that most physicists still find somewhat staggering, a most profound and beautiful thing, is that, in quantum mechanics, for each of the rules of symmetry there is a corresponding conservation law; there is a definite connection between the laws of conservation and the symmetries of physical laws. We can only state this at present, without any attempt at explanation. The fact, for example, that the laws are symmetrical for translation in space when we add the principles of quantum mechanics, turns out to mean that momentum is conserved. That the laws are symmetrical under translation in time means, in quantum mechanics, that energy is conserved. Invariance under rotation through a fixed angle in space corresponds to the conservation of angular momentum. These connections are very interesting and beautiful things, among the most beautiful and profound things in physics. Incidentally, there are a number of symmetries which appear in quantum mechanics which have no classical analog, which have no method of description in classical physics. One of these is as follows: If \u03c8 is the amplitude for some process or other, we know that the absolute square of \u03c8 is the probability that the process will occur. Now if someone else were to make his calculations, not with this \u03c8 , but with a \u03c8 \u2032 which differs merely by a change in phase (let \u0394 be some constant, and multiply e i\u0394 times the old \u03c8 ), the absolute square of \u03c8 \u2032 , which is the probability of the event, is then equal to the absolute square of \u03c8 : \u03c8 \u2032 =\u03c8 e i\u0394 ;| \u03c8 \u2032 | 2 =|\u03c8 | 2 . (52.1) Therefore the physical laws are unchanged if the phase of the wave function is shifted by an arbitrary constant. That is another symmetry. Physical laws must be of such a nature that a shift in the quantum-mechanical phase makes no difference. As we have just mentioned, in quantum mechanics there is a conservation law for every symmetry. The conservation law which is connected with the quantum-mechanical phase seems to be the conservation of electrical charge. This is altogether a very interesting business! Now the next question, which is going to concern us for most of the rest of this chapter, is the question of symmetry under reflection in space. The problem is this: Are the physical laws symmetrical under reflection? We may put it this way: Suppose we build a piece of equipment, let us say a clock, with lots of wheels and hands and numbers; it ticks, it works, and it has things wound up inside. We look at the clock in the mirror. How it looks in the mirror is not the question. But let us actually build another clock which is exactly the same as the first clock looks in the mirror\u2014every time there is a screw with a right-hand thread in one, we use a screw with a left-hand thread in the corresponding place of the other; where one is marked \u201c 2 \u201d on the face, we mark a \u201c\u201d on the face of the other; each coiled spring is twisted one way in one clock and the other way in the mirror-image clock; when we are all finished, we have two clocks, both physical, which bear to each other the relation of an object and its mirror image, although they are both actual, material objects, we emphasize. Now the question is: If the two clocks are started in the same condition, the springs wound to corresponding tightnesses, will the two clocks tick and go around, forever after, as exact mirror images? (This is a physical question, not a philosophical question.) Our intuition about the laws of physics would suggest that they would. We would suspect that, at least in the case of these clocks, reflection in space is one of the symmetries of physical laws, that if we change everything from \u201cright\u201d to \u201cleft\u201d and leave it otherwise the same, we cannot tell the difference. Let us, then, suppose for a moment that this is true. If it is true, then it would be impossible to distinguish \u201cright\u201d and \u201cleft\u201d by any physical phenomenon, just as it is, for example, impossible to define a particular absolute velocity by a physical phenomenon. So it should be impossible, by any physical phenomenon, to define absolutely what we mean by \u201cright\u201d as opposed to \u201cleft,\u201d because the physical laws should be symmetrical. Of course, the world does not have to be symmetrical. For example, using what we may call \u201cgeography,\u201d surely \u201cright\u201d can be defined. For instance, we stand in New Orleans and look at Chicago, and Florida is to our right (when our feet are on the ground!). So we can define \u201cright\u201d and \u201cleft\u201d by geography. Of course, the actual situation in any system does not have to have the symmetry that we are talking about; it is a question of whether the laws are symmetrical\u2014in other words, whether it is against the physical laws to have a sphere like the earth with \u201cleft-handed dirt\u201d on it and a person like ourselves standing looking at a city like Chicago from a place like New Orleans, but with everything the other way around, so Florida is on the other side. It clearly seems not impossible, not against the physical laws, to have everything changed left for right. Another point is that our definition of \u201cright\u201d should not depend on history. An easy way to distinguish right from left is to go to a machine shop and pick up a screw at random. The odds are it has a right-hand thread\u2014not necessarily, but it is much more likely to have a right-hand thread than a left-hand one. This is a question of history or convention, or the way things happen to be, and is again not a question of fundamental laws. As we can well appreciate, everyone could have started out making left-handed screws! So we must try to find some phenomenon in which \u201cright hand\u201d is involved fundamentally. The next possibility we discuss is the fact that polarized light rotates its plane of polarization as it goes through, say, sugar water. As we saw in Chapter 33, it rotates, let us say, to the right in a certain sugar solution. That is a way of defining \u201cright-hand,\u201d because we may dissolve some sugar in the water and then the polarization goes to the right. But sugar has come from living things, and if we try to make the sugar artificially, then we discover that it does not rotate the plane of polarization! But if we then take that same sugar which is made artificially and which does not rotate the plane of polarization, and put bacteria in it (they eat some of the sugar) and then filter out the bacteria, we find that we still have sugar left (almost half as much as we had before), and this time it does rotate the plane of polarization, but the other way! It seems very confusing, but is easily explained. Take another example: One of the substances which is common to all living creatures and that is fundamental to life is protein. Proteins consist of chains of amino acids. Figure 52\u20131 shows a model of an amino acid that comes out of a protein. This amino acid is called alanine, and the molecular arrangement would look like that in Fig. 52\u20131(a) if it came out of a protein of a real living thing. On the other hand, if we try to make alanine from carbon dioxide, ethane, and ammonia (and we can make it, it is not a complicated molecule), we discover that we are making equal amounts of this molecule and the one shown in Fig. 52\u20131(b)! The first molecule, the one that comes from the living thing, is called L-alanine. The other one, which is the same chemically, in that it has the same kinds of atoms and the same connections of the atoms, is a \u201cright-hand\u201d molecule, compared with the \u201cleft-hand\u201d L-alanine, and it is called D-alanine. The interesting thing is that when we make alanine at home in a laboratory from simple gases, we get an equal mixture of both kinds. However, the only thing that life uses is L-alanine. (This is not exactly true. Here and there in living creatures there is a special use for D-alanine, but it is very rare. All proteins use L-alanine exclusively.) Now if we make both kinds, and we feed the mixture to some animal which likes to \u201ceat,\u201d or use up, alanine, it cannot use D-alanine, so it only uses the L-alanine; that is what happened to our sugar\u2014after the bacteria eat the sugar that works well for them, only the \u201cwrong\u201d kind is left! (Left-handed sugar tastes sweet, but not the same as right-handed sugar.) So it looks as though the phenomena of life permit a distinction between \u201cright\u201d and \u201cleft,\u201d or chemistry permits a distinction, because the two molecules are chemically different. But no, it does not! So far as physical measurements can be made, such as of energy, the rates of chemical reactions, and so on, the two kinds work exactly the same way if we make everything else in a mirror image too. One molecule will rotate light to the right, and the other will rotate it to the left in precisely the same amount, through the same amount of fluid. Thus, so far as physics is concerned, these two amino acids are equally satisfactory. So far as we understand things today, the fundamentals of the Schr\u00f6dinger equation have it that the two molecules should behave in exactly corresponding ways, so that one is to the right as the other is to the left. Nevertheless, in life it is all one way! It is presumed that the reason for this is the following. Let us suppose, for example, that life is somehow at one moment in a certain condition in which all the proteins in some creatures have left-handed amino acids, and all the enzymes are lopsided\u2014every substance in the living creature is lopsided\u2014it is not symmetrical. So when the digestive enzymes try to change the chemicals in the food from one kind to another, one kind of chemical \u201cfits\u201d into the enzyme, but the other kind does not (like Cinderella and the slipper, except that it is a \u201cleft foot\u201d that we are testing). So far as we know, in principle, we could build a frog, for example, in which every molecule is reversed, everything is like the \u201cleft-hand\u201d mirror image of a real frog; we have a left-hand frog. This left-hand frog would go on all right for a while, but he would find nothing to eat, because if he swallows a fly, his enzymes are not built to digest it. The fly has the wrong \u201ckind\u201d of amino acids (unless we give him a left-hand fly). So as far as we know, the chemical and life processes would continue in the same manner if everything were reversed. If life is entirely a physical and chemical phenomenon, then we can understand that the proteins are all made in the same corkscrew only from the idea that at the very beginning some living molecules, by accident, got started and a few won. Somewhere, once, one organic molecule was lopsided in a certain way, and from this particular thing the \u201cright\u201d happened to evolve in our particular geography; a particular historical accident was one-sided, and ever since then the lopsidedness has propagated itself. Once having arrived at the state that it is in now, of course, it will always continue\u2014all the enzymes digest the right things, manufacture the right things: when the carbon dioxide and the water vapor, and so on, go in the plant leaves, the enzymes that make the sugars make them lopsided because the enzymes are lopsided. If any new kind of virus or living thing were to originate at a later time, it would survive only if it could \u201ceat\u201d the kind of living matter already present. Thus it, too, must be of the same kind. There is no conservation of the number of right-handed molecules. Once started, we could keep increasing the number of right-handed molecules. So the presumption is, then, that the phenomena in the case of life do not show a lack of symmetry in physical laws, but do show, on the contrary, the universal nature and the commonness of ultimate origin of all creatures on earth, in the sense described above. Now we go further. We observe that in physics there are a lot of other places where we have \u201cright\u201d and \u201cleft\u201d hand rules. As a matter of fact, when we learned about vector analysis we learned about the right-hand rules we have to use in order to get the angular momentum, torque, magnetic field, and so on, to come out right. The force on a charge moving in a magnetic field, for example, is F=qv\u00d7B . In a given situation, in which we know F , v , and B , isn\u2019t that equation enough to define right-handedness? As a matter of fact, if we go back and look at where the vectors came from, we know that the \u201cright-hand rule\u201d was merely a convention; it was a trick. The original quantities, like the angular momenta and the angular velocities, and things of this kind, were not really vectors at all! They are all somehow associated with a certain plane, and it is just because there are three dimensions in space that we can associate the quantity with a direction perpendicular to that plane. Of the two possible directions, we chose the \u201cright-hand\u201d direction. So if the laws of physics are symmetrical, we should find that if some demon were to sneak into all the physics laboratories and replace the word \u201cright\u201d for \u201cleft\u201d in every book in which \u201cright-hand rules\u201d are given, and instead we were to use all \u201cleft-hand rules,\u201d uniformly, then it should make no difference whatever in the physical laws. Let us give an illustration. There are two kinds of vectors. There are \u201chonest\u201d vectors, for example a step r in space. If in our apparatus there is a piece here and something else there, then in a mirror apparatus there will be the image piece and the image something else, and if we draw a vector from the \u201cpiece\u201d to the \u201csomething else,\u201d one vector is the mirror image of the other (Fig. 52\u20132). The vector arrow changes its head, just as the whole space turns inside out; such a vector we call a polar vector. But the other kind of vector, which has to do with rotations, is of a different nature. For example, suppose that in three dimensions something is rotating as shown in Fig. 52\u20133. Then if we look at it in a mirror, it will be rotating as indicated, namely, as the mirror image of the original rotation. Now we have agreed to represent the mirror rotation by the same rule, it is a \u201cvector\u201d which, on reflection, does not change about as the polar vector does, but is reversed relative to the polar vectors and to the geometry of the space; such a vector is called an axial vector. Now if the law of reflection symmetry is right in physics, then it must be true that the equations must be so designed that if we change the sign of each axial vector and each cross-product of vectors, which would be what corresponds to reflection, nothing will happen. For instance, when we write a formula which says that the angular momentum is L=r\u00d7p , that equation is all right, because if we change to a left-hand coordinate system, we change the sign of L , but p and r do not change; the cross-product sign is changed, since we must change from a right-hand rule to a left-hand rule. As another example, we know that the force on a charge moving in a magnetic field is F=qv\u00d7B , but if we change from a right- to a left-handed system, since F and v are known to be polar vectors the sign change required by the cross-product must be cancelled by a sign change in B , which means that B must be an axial vector. In other words, if we make such a reflection, B must go to \u2212B . So if we change our coordinates from right to left, we must also change the poles of magnets from north to south. Let us see how that works in an example. Suppose that we have two magnets, as in Fig. 52\u20134. One is a magnet with the coils going around a certain way, and with current in a given direction. The other magnet looks like the reflection of the first magnet in a mirror\u2014the coil will wind the other way, everything that happens inside the coil is exactly reversed, and the current goes as shown. Now, from the laws for the production of magnetic fields, which we do not know yet officially, but which we most likely learned in high school, it turns out that the magnetic field is as shown in the figure. In one case the pole is a south magnetic pole, while in the other magnet the current is going the other way and the magnetic field is reversed\u2014it is a north magnetic pole. So we see that when we go from right to left we must indeed change from north to south! Never mind changing north to south; these too are mere conventions. Let us talk about phenomena. Suppose, now, that we have an electron moving through one field, going into the page. Then, if we use the formula for the force, v\u00d7B (remember the charge is minus), we find that the electron will deviate in the indicated direction according to the physical law. So the phenomenon is that we have a coil with a current going in a specified sense and an electron curves in a certain way\u2014that is the physics\u2014never mind how we label everything. Now let us do the same experiment with a mirror: we send an electron through in a corresponding direction and now the force is reversed, if we calculate it from the same rule, and that is very good because the corresponding motions are then mirror images! So the fact of the matter is that in studying any phenomenon there are always two right-hand rules, or an even number of them, and the net result is that the phenomena always look symmetrical. In short, therefore, we cannot tell right from left if we also are not able to tell north from south. However, it may seem that we can tell the north pole of a magnet. The north pole of a compass needle, for example, is one that points to the north. But of course that is again a local property that has to do with geography of the earth; that is just like talking about in which direction is Chicago, so it does not count. If we have seen compass needles, we may have noticed that the north-seeking pole is a sort of bluish color. But that is just due to the man who painted the magnet. These are all local, conventional criteria. However, if a magnet were to have the property that if we looked at it closely enough we would see small hairs growing on its north pole but not on its south pole, if that were the general rule, or if there were any unique way to distinguish the north from the south pole of a magnet, then we could tell which of the two cases we actually had, and that would be the end of the law of reflection symmetry. To illustrate the whole problem still more clearly, imagine that we were talking to a Martian, or someone very far away, by telephone. We are not allowed to send him any actual samples to inspect; for instance, if we could send light, we could send him right-hand circularly polarized light and say, \u201cThat is right-hand light\u2014just watch the way it is going.\u201d But we cannot give him anything, we can only talk to him. He is far away, or in some strange location, and he cannot see anything we can see. For instance, we cannot say, \u201cLook at Ursa major; now see how those stars are arranged. What we mean by \u2018right\u2019 is \u2026\u201d We are only allowed to telephone him. Now we want to tell him all about us. Of course, first we start defining numbers, and say, \u201cTick, tick, two, tick, tick, tick, three, \u2026,\u201d so that gradually he can understand a couple of words, and so on. After a while we may become very familiar with this fellow, and he says, \u201cWhat do you guys look like?\u201d We start to describe ourselves, and say, \u201cWell, we are six feet tall.\u201d He says, \u201cWait a minute, what is six feet?\u201d Is it possible to tell him what six feet is? Certainly! We say, \u201cYou know about the diameter of hydrogen atoms\u2014we are 17,000,000,000 hydrogen atoms high!\u201d That is possible because physical laws are not invariant under change of scale, and therefore we can define an absolute length. And so we define the size of the body, and tell him what the general shape is\u2014it has prongs with five bumps sticking out on the ends, and so on, and he follows us along, and we finish describing how we look on the outside, presumably without encountering any particular difficulties. He is even making a model of us as we go along. He says, \u201cMy, you are certainly very handsome fellows; now what is on the inside?\u201d So we start to describe the various organs on the inside, and we come to the heart, and we carefully describe the shape of it, and say, \u201cNow put the heart on the left side.\u201d He says, \u201cDuhhh\u2014the left side?\u201d Now our problem is to describe to him which side the heart goes on without his ever seeing anything that we see, and without our ever sending any sample to him of what we mean by \u201cright\u201d\u2014no standard right-handed object. Can we do it? It turns out that the laws of gravitation, the laws of electricity and magnetism, nuclear forces, all satisfy the principle of reflection symmetry, so these laws, or anything derived from them, cannot be used. But associated with the many particles that are found in nature there is a phenomenon called beta decay, or weak decay. One of the examples of weak decay, in connection with a particle discovered in about 1954, posed a strange puzzle. There was a certain charged particle which disintegrated into three \u03c0 -mesons, as shown schematically in Fig. 52\u20135. This particle was called, for a while, a \u03c4 -meson. Now in Fig. 52\u20135 we also see another particle which disintegrates into two mesons; one must be neutral, from the conservation of charge. This particle was called a \u03b8 -meson. So on the one hand we have a particle called a \u03c4 , which disintegrates into three \u03c0 -mesons, and a \u03b8 , which disintegrates into two \u03c0 -mesons. Now it was soon discovered that the \u03c4 and the \u03b8 are almost equal in mass; in fact, within the experimental error, they are equal. Next, the length of time it took for them to disintegrate into three \u03c0 \u2019s and two \u03c0 \u2019s was found to be almost exactly the same; they live the same length of time. Next, whenever they were made, they were made in the same proportions, say, 14 percent \u03c4 \u2019s to 86 percent \u03b8 \u2019s. Anyone in his right mind realizes immediately that they must be the same particle, that we merely produce an object which has two different ways of disintegrating\u2014not two different particles. This object that can disintegrate in two different ways has, therefore, the same lifetime and the same production ratio (because this is simply the ratio of the odds with which it disintegrates into these two kinds). However, it was possible to prove (and we cannot here explain at all how), from the principle of reflection symmetry in quantum mechanics, that it was impossible to have these both come from the same particle\u2014the same particle could not disintegrate in both of these ways. The conservation law corresponding to the principle of reflection symmetry is something which has no classical analog, and so this kind of quantum-mechanical conservation was called the conservation of parity. So, it was a result of the conservation of parity or, more precisely, from the symmetry of the quantum-mechanical equations of the weak decays under reflection, that the same particle could not go into both, so it must be some kind of coincidence of masses, lifetimes, and so on. But the more it was studied, the more remarkable the coincidence, and the suspicion gradually grew that possibly the deep law of the reflection symmetry of nature may be false. As a result of this apparent failure, the physicists Lee and Yang suggested that other experiments be done in related decays to try to test whether the law was correct in other cases. The first such experiment was carried out by Miss Wu from Columbia, and was done as follows. Using a very strong magnet at a very low temperature, it turns out that a certain isotope of cobalt, which disintegrates by emitting an electron, is magnetic, and if the temperature is low enough that the thermal oscillations do not jiggle the atomic magnets about too much, they line up in the magnetic field. So the cobalt atoms will all line up in this strong field. They then disintegrate, emitting an electron, and it was discovered that when the atoms were lined up in a field whose B vector points upward, most of the electrons were emitted in a downward direction. If one is not really \u201chep\u201d to the world, such a remark does not sound like anything of significance, but if one appreciates the problems and interesting things in the world, then he sees that it is a most dramatic discovery: When we put cobalt atoms in an extremely strong magnetic field, more disintegration electrons go down than up. Therefore if we were to put it in a corresponding experiment in a \u201cmirror,\u201d in which the cobalt atoms would be lined up in the opposite direction, they would spit their electrons up, not down; the action is unsymmetrical. The magnet has grown hairs! The south pole of a magnet is of such a kind that the electrons in a \u03b2 -disintegration tend to go away from it; that distinguishes, in a physical way, the north pole from the south pole. After this, a lot of other experiments were done: the disintegration of the \u03c0 into \u03bc and \u03bd ; \u03bc into an electron and two neutrinos; nowadays, the \u039b into proton and \u03c0 ; disintegration of \u03a3 \u2019s; and many other disintegrations. In fact, in almost all cases where it could be expected, all have been found not to obey reflection symmetry! Fundamentally, the law of reflection symmetry, at this level in physics, is incorrect. In short, we can tell a Martian where to put the heart: we say, \u201cListen, build yourself a magnet, and put the coils in, and put the current on, and then take some cobalt and lower the temperature. Arrange the experiment so the electrons go from the foot to the head, then the direction in which the current goes through the coils is the direction that goes in on what we call the right and comes out on the left.\u201d So it is possible to define right and left, now, by doing an experiment of this kind. There are a lot of other features that were predicted. For example, it turns out that the spin, the angular momentum, of the cobalt nucleus before disintegration is 5 units of \u210f , and after disintegration it is 4 units. The electron carries spin angular momentum, and there is also a neutrino involved. It is easy to see from this that the electron must carry its spin angular momentum aligned along its direction of motion, the neutrino likewise. So it looks as though the electron is spinning to the left, and that was also checked. In fact, it was checked right here at Caltech by Boehm and Wapstra, that the electrons spin mostly to the left. (There were some other experiments that gave the opposite answer, but they were wrong!) The next problem, of course, was to find the law of the failure of parity conservation. What is the rule that tells us how strong the failure is going to be? The rule is this: it occurs only in these very slow reactions, called weak decays, and when it occurs, the rule is that the particles which carry spin, like the electron, neutrino, and so on, come out with a spin tending to the left. That is a lopsided rule; it connects a polar vector velocity and an axial vector angular momentum, and says that the angular momentum is more likely to be opposite to the velocity than along it. Now that is the rule, but today we do not really understand the whys and wherefores of it. Why is this the right rule, what is the fundamental reason for it, and how is it connected to anything else? At the moment we have been so shocked by the fact that this thing is unsymmetrical that we have not been able to recover enough to understand what it means with regard to all the other rules. However, the subject is interesting, modern, and still unsolved, so it seems appropriate that we discuss some of the questions associated with it. The first thing to do when one of the symmetries is lost is to immediately go back over the list of known or assumed symmetries and ask whether any of the others are lost. Now we did not mention one operation on our list, which must necessarily be questioned, and that is the relation between matter and antimatter. Dirac predicted that in addition to electrons there must be another particle, called the positron (discovered at Caltech by Anderson), that is necessarily related to the electron. All the properties of these two particles obey certain rules of correspondence: the energies are equal; the masses are equal; the charges are reversed; but, more important than anything, the two of them, when they come together, can annihilate each other and liberate their entire mass in the form of energy, say \u03b3 -rays. The positron is called an antiparticle to the electron, and these are the characteristics of a particle and its antiparticle. It was clear from Dirac\u2019s argument that all the rest of the particles in the world should also have corresponding antiparticles. For instance, for the proton there should be an antiproton, which is now symbolized by a p \u00af \u00af \u00af . The p \u00af \u00af \u00af would have a negative electrical charge and the same mass as a proton, and so on. The most important feature, however, is that a proton and an antiproton coming together can annihilate each other. The reason we emphasize this is that people do not understand it when we say there is a neutron and also an antineutron, because they say, \u201cA neutron is neutral, so how can it have the opposite charge?\u201d The rule of the \u201canti\u201d is not just that it has the opposite charge, it has a certain set of properties, the whole lot of which are opposite. The antineutron is distinguished from the neutron in this way: if we bring two neutrons together, they just stay as two neutrons, but if we bring a neutron and an antineutron together, they annihilate each other with a great explosion of energy being liberated, with various \u03c0 -mesons, \u03b3 -rays, and whatnot. Now if we have antineutrons, antiprotons, and antielectrons, we can make antiatoms, in principle. They have not been made yet, but it is possible in principle. For instance, a hydrogen atom has a proton in the center with an electron going around outside. Now imagine that somewhere we can make an antiproton with a positron going around, would it go around? Well, first of all, the antiproton is electrically negative and the antielectron is electrically positive, so they attract each other in a corresponding manner\u2014the masses are all the same; everything is the same. It is one of the principles of the symmetry of physics, the equations seem to show, that if a clock, say, were made of matter on one hand, and then we made the same clock of antimatter, it would run in this way. (Of course, if we put the clocks together, they would annihilate each other, but that is different.) An immediate question then arises. We can build, out of matter, two clocks, one which is \u201cleft-hand\u201d and one which is \u201cright-hand.\u201d For example, we could build a clock which is not built in a simple way, but has cobalt and magnets and electron detectors which detect the presence of \u03b2 -decay electrons and count them. Each time one is counted, the second hand moves over. Then the mirror clock, receiving fewer electrons, will not run at the same rate. So evidently we can make two clocks such that the left-hand clock does not agree with the right-hand one. Let us make, out of matter, a clock which we call the standard or right-hand clock. Now let us make, also out of matter, a clock which we call the left-hand clock. We have just discovered that, in general, these two will not run the same way; prior to that famous physical discovery, it was thought that they would. Now it was also supposed that matter and antimatter were equivalent. That is, if we made an antimatter clock, right-hand, the same shape, then it would run the same as the right-hand matter clock, and if we made the same clock to the left it would run the same. In other words, in the beginning it was believed that all four of these clocks were the same; now of course we know that the right-hand and left-hand matter are not the same. Presumably, therefore, the right-handed antimatter and the left-handed antimatter are not the same. So the obvious question is, which goes with which, if either? In other words, does the right-handed matter behave the same way as the right-handed antimatter? Or does the right-handed matter behave the same as the left-handed antimatter? \u03b2 -decay experiments, using positron decay instead of electron decay, indicate that this is the interconnection: matter to the \u201cright\u201d works the same way as antimatter to the \u201cleft.\u201d Therefore, at long last, it is really true that right and left symmetry is still maintained! If we made a left-hand clock, but made it out of the other kind of matter, antimatter instead of matter, it would run in the same way. So what has happened is that instead of having two independent rules in our list of symmetries, two of these rules go together to make a new rule, which says that matter to the right is symmetrical with antimatter to the left. So if our Martian is made of antimatter and we give him instructions to make this \u201cright\u201d handed model like us, it will, of course, come out the other way around. What would happen when, after much conversation back and forth, we each have taught the other to make space ships and we meet halfway in empty space? We have instructed each other on our traditions, and so forth, and the two of us come rushing out to shake hands. Well, if he puts out his left hand, watch out! The next question is, what can we make out of laws which are nearly symmetrical? The marvelous thing about it all is that for such a wide range of important, strong phenomena\u2014nuclear forces, electrical phenomena, and even weak ones like gravitation\u2014over a tremendous range of physics, all the laws for these seem to be symmetrical. On the other hand, this little extra piece says, \u201cNo, the laws are not symmetrical!\u201d How is it that nature can be almost symmetrical, but not perfectly symmetrical? What shall we make of this? First, do we have any other examples? The answer is, we do, in fact, have a few other examples. For instance, the nuclear part of the force between proton and proton, between neutron and neutron, and between neutron and proton, is all exactly the same\u2014there is a symmetry for nuclear forces, a new one, that we can interchange neutron and proton\u2014but it evidently is not a general symmetry, for the electrical repulsion between two protons at a distance does not exist for neutrons. So it is not generally true that we can always replace a proton with a neutron, but only to a good approximation. Why good? Because the nuclear forces are much stronger than the electrical forces. So this is an \u201calmost\u201d symmetry also. So we do have examples in other things. We have, in our minds, a tendency to accept symmetry as some kind of perfection. In fact it is like the old idea of the Greeks that circles were perfect, and it was rather horrible to believe that the planetary orbits were not circles, but only nearly circles. The difference between being a circle and being nearly a circle is not a small difference, it is a fundamental change so far as the mind is concerned. There is a sign of perfection and symmetry in a circle that is not there the moment the circle is slightly off\u2014that is the end of it\u2014it is no longer symmetrical. Then the question is why it is only nearly a circle\u2014that is a much more difficult question. The actual motion of the planets, in general, should be ellipses, but during the ages, because of tidal forces, and so on, they have been made almost symmetrical. Now the question is whether we have a similar problem here. The problem from the point of view of the circles is if they were perfect circles there would be nothing to explain, that is clearly simple. But since they are only nearly circles, there is a lot to explain, and the result turned out to be a big dynamical problem, and now our problem is to explain why they are nearly symmetrical by looking at tidal forces and so on. So our problem is to explain where symmetry comes from. Why is nature so nearly symmetrical? No one has any idea why. The only thing we might suggest is something like this: There is a gate in Japan, a gate in Nikk\u014d, which is sometimes called by the Japanese the most beautiful gate in all Japan; it was built in a time when there was great influence from Chinese art. This gate is very elaborate, with lots of gables and beautiful carving and lots of columns and dragon heads and princes carved into the pillars, and so on. But when one looks closely he sees that in the elaborate and complex design along one of the pillars, one of the small design elements is carved upside down; otherwise the thing is completely symmetrical. If one asks why this is, the story is that it was carved upside down so that the gods will not be jealous of the perfection of man. So they purposely put an error in there, so that the gods would not be jealous and get angry with human beings. We might like to turn the idea around and think that the true explanation of the near symmetry of nature is this: that God made the laws only nearly symmetrical so that we should not be jealous of His perfection!"
    },
    {
        "input": "The Ammonia Maser",
        "output": "In this chapter we are going to discuss the application of quantum mechanics to a practical device, the ammonia maser. You may wonder why we stop our formal development of quantum mechanics to do a special problem, but you will find that many of the features of this special problem are quite common in the general theory of quantum mechanics, and you will learn a great deal by considering this one problem in detail. The ammonia maser is a device for generating electromagnetic waves, whose operation is based on the properties of the ammonia molecule which we discussed briefly in the last chapter. We begin by summarizing what we found there. The ammonia molecule has many states, but we are considering it as a two-state system, thinking now only about what happens when the molecule is in any specific state of rotation or translation. A physical model for the two states can be visualized as follows. If the ammonia molecule is considered to be rotating about an axis passing through the nitrogen atom and perpendicular to the plane of the hydrogen atoms, as shown in Fig. 9\u20131, there are still two possible conditions\u2014the nitrogen may be on one side of the plane of hydrogen atoms or on the other. We call these two states |1\u27e9 and |2\u27e9 . They are taken as a set of base states for our analysis of the behavior of the ammonia molecule. In a system with two base states, any state |\u03c8\u27e9 of the system can always be described as a linear combination of the two base states; that is, there is a certain amplitude C1 to be in one base state and an amplitude C2 to be in the other. We can write its state vector as |\u03c8\u27e9=|1\u27e9C1+|2\u27e9C2, where C1=\u27e81|\u03c8\u27e9andC2=\u27e82|\u03c8\u27e9. These two amplitudes change with time according to the Hamiltonian equations, Eq. (8.43). Making use of the symmetry of the two states of the ammonia molecule, we set H11=H22=E0 , and H12=H21=\u2212A , and get the solution [see Eqs. (8.50) and (8.51)] C1 = a 2 e\u2212(i/\u210f)(E0\u2212A)t+ b 2 e\u2212(i/\u210f)(E0+A)t, C2 = a 2 e\u2212(i/\u210f)(E0\u2212A)t\u2212 b 2 e\u2212(i/\u210f)(E0+A)t. We want now to take a closer look at these general solutions. Suppose that the molecule was initially put into a state |\u03c8II\u27e9 for which the coefficient b was equal to zero. Then at t=0 the amplitudes to be in the states |1\u27e9 and |2\u27e9 are identical, and they stay that way for all time. Their phases both vary with time in the same way\u2014with the frequency (E0\u2212A)/\u210f . Similarly, if we were to put the molecule into a state |\u03c8I\u27e9 for which a=0 , the amplitude C2 is the negative of C1 , and this relationship would stay that way forever. Both amplitudes would now vary with time with the frequency (E0+A)/\u210f . These are the only two possibilities of states for which the relation between C1 and C2 is independent of time. We have found two special solutions in which the two amplitudes do not vary in magnitude and, furthermore, have phases which vary at the same frequencies. These are stationary states as we defined them in Section 7\u20131, which means that they are states of definite energy. The state |\u03c8II\u27e9 has the energy EII=E0\u2212A , and the state |\u03c8I\u27e9 has the energy EI=E0+A . They are the only two stationary states that exist, so we find that the molecule has two energy levels, with the energy difference 2A . (We mean, of course, two energy levels for the assumed state of rotation and vibration which we referred to in our initial assumptions.)1 If we hadn\u2019t allowed for the possibility of the nitrogen flipping back and forth, we would have taken A equal to zero and the two energy levels would be on top of each other at energy E0 . The actual levels are not this way; their average energy is E0 , but they are split apart by \u00b1A , giving a separation of 2A between the energies of the two states. Since A is, in fact, very small, the difference in energy is also very small. In order to excite an electron inside an atom, the energies involved are relatively very high\u2014requiring photons in the optical or ultraviolet range. To excite the vibrations of the molecules involves photons in the infrared. If you talk about exciting rotations, the energy differences of the states correspond to photons in the far infrared. But the energy difference 2A is lower than any of those and is, in fact, below the infrared and well into the microwave region. Experimentally, it has been found that there is a pair of energy levels with a separation of 10\u22124 electron volt\u2014corresponding to a frequency 24,000 megacycles. Evidently this means that 2A=hf , with f=24,000 megacycles (corresponding to a wavelength of 1 1 4 cm). So here we have a molecule that has a transition which does not emit light in the ordinary sense, but emits microwaves. For the work that follows we need to describe these two states of definite energy a little bit better. Suppose we were to construct an amplitude CII by taking the sum of the two numbers C1 and C2 : CII=C1+C2=\u27e81|\u03d5\u27e9+\u27e82|\u03d5\u27e9. What would that mean? Well, this is just the amplitude to find the state |\u03d5\u27e9 in a new state |II\u27e9 in which the amplitudes of the original base states are equal. That is, writing CII=\u27e8II|\u03d5\u27e9 , we can abstract the |\u03d5\u27e9 away from Eq. (9.4)\u2014because it is true for any \u03d5 \u2014and get \u27e8II|=\u27e81|+\u27e82|, which means the same as |II\u27e9=|1\u27e9+|2\u27e9. The amplitude for the state |II\u27e9 to be in the state |1\u27e9 is \u27e81|II\u27e9=\u27e81|1\u27e9+\u27e81|2\u27e9, which is, of course, just 1 , since |1\u27e9 and |2\u27e9 are base states. The amplitude for the state |II\u27e9 to be in the state |2\u27e9 is also 1 , so the state |II\u27e9 is one which has equal amplitudes to be in the two base states |1\u27e9 and |2\u27e9 . We are, however, in a bit of trouble. The state |II\u27e9 has a total probability greater than one of being in some base state or other. That simply means, however, that the state vector is not properly \u201cnormalized.\u201d We can take care of that by remembering that we should have \u27e8II|II\u27e9=1 , which must be so for any state. Using the general relation that \u27e8\u03c7|\u03d5\u27e9= \u2211 i \u27e8\u03c7|i\u27e9\u27e8i|\u03d5\u27e9, letting both \u03d5 and \u03c7 be the state II , and taking the sum over the base states |1\u27e9 and |2\u27e9 , we get that \u27e8II|II\u27e9=\u27e8II|1\u27e9\u27e81|II\u27e9+\u27e8II|2\u27e9\u27e82|II\u27e9. This will be equal to one as it should if we change our definition of CII \u2014in Eq. (9.4)\u2014to read CII= 1 \u221a 2 [C1+C2]. In the same way we can construct an amplitude CI= 1 \u221a 2 [C1\u2212C2], or CI= 1 \u221a 2 [\u27e81|\u03d5\u27e9\u2212\u27e82|\u03d5\u27e9]. This amplitude is the projection of the state |\u03d5\u27e9 into a new state |I\u27e9 which has opposite amplitudes to be in the states |1\u27e9 and |2\u27e9 . Namely, Eq. (9.6) means the same as \u27e8I|= 1 \u221a 2 [\u27e81|\u2212\u27e82|], or |I\u27e9= 1 \u221a 2 [|1\u27e9\u2212|2\u27e9], from which it follows that \u27e81|I\u27e9= 1 \u221a 2 =\u2212\u27e82|I\u27e9. Now the reason we have done all this is that the states |I\u27e9 and |II\u27e9 can be taken as a new set of base states which are especially convenient for describing the stationary states of the ammonia molecule. You remember that the requirement for a set of base states is that \u27e8i|j\u27e9=\u03b4ij. We have already fixed things so that \u27e8I|I\u27e9=\u27e8II|II\u27e9=1. You can easily show from Eqs. (9.5) and (9.7) that \u27e8I|II\u27e9=\u27e8II|I\u27e9=0. The amplitudes CI=\u27e8I|\u03d5\u27e9 and CII=\u27e8II|\u03d5\u27e9 for any state \u03d5 to be in our new base states |I\u27e9 and |II\u27e9 must also satisfy a Hamiltonian equation with the form of Eq. (8.39). In fact, if we just subtract the two equations (9.2) and (9.3) and differentiate with respect to t , we see that i\u210f dCI dt =(E0+A)CI=EICI. And taking the sum of Eqs. (9.2) and (9.3), we see that i\u210f dCII dt =(E0\u2212A)CII=EIICII. Using |I\u27e9 and |II\u27e9 for base states, the Hamiltonian matrix has the simple form HI,I =EI, HI,II =0, HII,I =0, HII,II =EII. Note that each of the Eqs. (9.8) and (9.9) look just like what we had in Section 8\u20136 for the equation of a one-state system. They have a simple exponential time dependence corresponding to a single energy. As time goes on, the amplitudes to be in each state act independently. The two stationary states |\u03c8I\u27e9 and |\u03c8II\u27e9 we found above are, of course, solutions of Eqs. (9.8) and (9.9). The state |\u03c8I\u27e9 (for which C1=\u2212C2 ) has CI=e\u2212(i/\u210f)(E0+A)t,CII=0. And the state |\u03c8II\u27e9 (for which C1=C2 ) has CI=0,CII=e\u2212(i/\u210f)(E0\u2212A)t. Remember that the amplitudes in Eq. (9.10) are CI=\u27e8I|\u03c8I\u27e9,andCII=\u27e8II|\u03c8I\u27e9; so Eq. (9.10) means the same thing as |\u03c8I\u27e9=|I\u27e9e\u2212(i/\u210f)(E0+A)t. That is, the state vector of the stationary state |\u03c8I\u27e9 is the same as the state vector of the base state |I\u27e9 except for the exponential factor appropriate to the energy of the state. In fact at t=0 |\u03c8I\u27e9=|I\u27e9; the state |I\u27e9 has the same physical configuration as the stationary state of energy E0+A . In the same way, we have for the second stationary state that |\u03c8II\u27e9=|II\u27e9e\u2212(i/\u210f)(E0\u2212A)t. The state |II\u27e9 is just the stationary state of energy E0\u2212A at t=0 . Thus our two new base states |I\u27e9 and |II\u27e9 have physically the form of the states of definite energy, with the exponential time factor taken out so that they can be time-independent base states. (In what follows we will find it convenient not to have to distinguish always between the stationary states |\u03c8I\u27e9 and |\u03c8II\u27e9 and their base states |I\u27e9 and |II\u27e9 , since they differ only by the obvious time factors.) In summary, the state vectors |I\u27e9 and |II\u27e9 are a pair of base vectors which are appropriate for describing the definite energy states of the ammonia molecule. They are related to our original base vectors by |I\u27e9= 1 2 \u2013 \u221a [|1\u27e9\u2212|2\u27e9],|II\u27e9= 1 2 \u2013 \u221a [|1\u27e9+|2\u27e9]. (9.12) The amplitudes to be in |I\u27e9 and |II\u27e9 are related to C 1 and C 2 by C I = 1 2 \u2013 \u221a [ C 1 \u2212 C 2 ], C II = 1 2 \u2013 \u221a [ C 1 + C 2 ]. (9.13) Any state at all can be represented by a linear combination of |1\u27e9 and |2\u27e9 \u2014with the coefficients C 1 and C 2 \u2014or by a linear combination of the definite energy base states |I\u27e9 and |II\u27e9 \u2014with the coefficients C I and C II . Thus, |\u03d5\u27e9=|1\u27e9 C 1 +|2\u27e9 C 2 | \u03d5 \u27e9 | \u27e9 | \u27e9 or |\u03d5\u27e9=|I\u27e9 C I +|II\u27e9 C II . | \u03d5 \u27e9 | \u27e9 | \u27e9 The second form gives us the amplitudes for finding the state |\u03d5\u27e9 in a state with the energy E I = E 0 +A or in a state with the energy E II = E 0 \u2212A . If the ammonia molecule is in either of the two states of definite energy and we disturb it at a frequency \u03c9 such that \u210f\u03c9= E I \u2212 E II = 2A , the system may make a transition from one state to the other. Or, if it is in the upper state, it may change to the lower state and emit a photon. But in order to induce such transitions you must have a physical connection to the states\u2014some way of disturbing the system. There must be some external machinery for affecting the states, such as magnetic or electric fields. In this particular case, these states are sensitive to an electric field. We will, therefore, look next at the problem of the behavior of the ammonia molecule in an external electric field. To discuss the behavior in an electric field, we will go back to the original base system |1\u27e9 and |2\u27e9 , rather than using |I\u27e9 and |II\u27e9 . Suppose that there is an electric field in a direction perpendicular to the plane of the hydrogen atoms. Disregarding for the moment the possibility of flipping back and forth, would it be true that the energy of this molecule is the same for the two positions of the nitrogen atom? Generally, no. The electrons tend to lie closer to the nitrogen than to the hydrogen nuclei, so the hydrogens are slightly positive. The actual amount depends on the details of electron distribution. It is a complicated problem to figure out exactly what this distribution is, but in any case the net result is that the ammonia molecule has an electric dipole moment, as indicated in Fig. 9\u20131. We can continue our analysis without knowing in detail the direction or amount of displacement of the charge. However, to be consistent with the notation of others, let\u2019s suppose that the electric dipole moment is \u03bc , with its direction pointing from the nitrogen atom and perpendicular to the plane of the hydrogen atoms. Now, when the nitrogen flips from one side to the other, the center of mass will not move, but the electric dipole moment will flip over. As a result of this moment, the energy in an electric field E will depend on the molecular orientation.2 With the assumption made above, the potential energy will be higher if the nitrogen atom points in the direction of the field, and lower if it is in the opposite direction; the separation in the two energies will be 2\u03bcE . In the discussion up to this point, we have assumed values of E 0 and A without knowing how to calculate them. According to the correct physical theory, it should be possible to calculate these constants in terms of the positions and motions of all the nuclei and electrons. But nobody has ever done it. Such a system involves ten electrons and four nuclei and that\u2019s just too complicated a problem. As a matter of fact, there is no one who knows much more about this molecule than we do. All anyone can say is that when there is an electric field, the energy of the two states is different, the difference being proportional to the electric field. We have called the coefficient of proportionality 2\u03bc , but its value must be determined experimentally. We can also say that the molecule has the amplitude A to flip over, but this will have to be measured experimentally. Nobody can give us accurate theoretical values of \u03bc and A , because the calculations are too complicated to do in detail. For the ammonia molecule in an electric field, our description must be changed. If we ignored the amplitude for the molecule to flip from one configuration to the other, we would expect the energies of the two states |1\u27e9 and |2\u27e9 to be ( E 0 \u00b1\u03bcE) . Following the procedure of the last chapter, we take H 11 = E 0 +\u03bcE, H 22 = E 0 \u2212\u03bcE. (9.14) Also we will assume that for the electric fields of interest the field does not affect appreciably the geometry of the molecule and, therefore, does not affect the amplitude that the nitrogen will jump from one position to the other. We can then take that H 12 and H 21 are not changed; so H 12 = H 21 =\u2212A. (9.15) We must now solve the Hamiltonian equations, Eq. (8.43), with these new values of H ij . We could solve them just as we did before, but since we are going to have several occasions to want the solutions for two-state systems, let\u2019s solve the equations once and for all in the general case of arbitrary H ij \u2014assuming only that they do not change with time. We want the general solution of the pair of Hamiltonian equations i\u210f d C 1 dt i\u210f d C 2 dt = H 11 C 1 + H 12 C 2 , = H 21 C 1 + H 22 C 2 . (9.16) (9.17) Since these are linear differential equations with constant coefficients, we can always find solutions which are exponential functions of the dependent variable t . We will first look for a solution in which C 1 and C 2 both have the same time dependence; we can use the trial functions C 1 = a 1 e \u2212i\u03c9t , C 2 = a 2 e \u2212i\u03c9t . i t i t Since such a solution corresponds to a state of energy E=\u210f\u03c9 , we may as well write right away C 1 C 2 = a 1 e \u2212(i/\u210f)Et , = a 2 e \u2212(i/\u210f)Et , (9.18) (9.19) where E is as yet unknown and to be determined so that the differential equations (9.16) and (9.17) are satisfied. When we substitute C 1 and C 2 from (9.18) and (9.19) in the differential equations (9.16) and (9.17), the derivatives give us just \u2212iE/\u210f times C 1 or C 2 , so the left sides become just E C 1 and E C 2 . Cancelling the common exponential factors, we get E a 1 = H 11 a 1 + H 12 a 2 ,E a 2 = H 21 a 1 + H 22 a 2 . E H H E H H Or, rearranging the terms, we have (E\u2212 H 11 ) a 1 \u2212 H 12 a 2 \u2212 H 21 a 1 +(E\u2212 H 22 ) a 2 =0, =0. (9.20) (9.21) With such a set of homogeneous algebraic equations, there will be nonzero solutions for a 1 and a 2 only if the determinant of the coefficients of a 1 and a 2 is zero, that is, if Det ( E\u2212 H 11 \u2212 H 21 \u2212 H 12 E\u2212 H 22 )=0. (9.22) However, when there are only two equations and two unknowns, we don\u2019t need such a sophisticated idea. The two equations (9.20) and (9.21) each give a ratio for the two coefficients a 1 and a 2 , and these two ratios must be equal. From (9.20) we have that a 1 a 2 = H 12 E\u2212 H 11 , (9.23) and from (9.21) that a 1 a 2 = E\u2212 H 22 H 21 . (9.24) Equating these two ratios, we get that E must satisfy (E\u2212 H 11 )(E\u2212 H 22 )\u2212 H 12 H 21 =0. ( ) ( ) This is the same result we would get by solving Eq. (9.22). Either way, we have a quadratic equation for E which has two solutions: E= H 11 + H 22 2 \u00b1 ( H 11 \u2212 H 22 ) 2 4 + H 12 H 21 \u2212 \u2212 \u2212 \u2212 \u2212 \u2212 \u2212 \u2212 \u2212 \u2212 \u2212 \u2212 \u2212 \u2212 \u2212 \u2212 \u2212 \u2212 \u221a . (9.25) There are two possible values for the energy E . Note that both solutions give real numbers for the energy, because H 11 and H 22 are real, and H 12 H 21 is equal to H 12 H \u2217 12 =| H 12 | 2 , which is both real and positive. Using the same convention we took before, we will call the upper energy E I and the lower energy E II . We have E I E II = H 11 + H 22 2 + ( H 11 \u2212 H 22 ) 2 4 + H 12 H 21 \u2212 \u2212 \u2212 \u2212 \u2212 \u2212 \u2212 \u2212 \u2212 \u2212 \u2212 \u2212 \u2212 \u2212 \u2212 \u2212 \u2212 \u2212 \u221a , = H 11 + H 22 2 \u2212 ( H 11 \u2212 H 22 ) 2 4 + H 12 H 21 \u2212 \u2212 \u2212 \u2212 \u2212 \u2212 \u2212 \u2212 \u2212 \u2212 \u2212 \u2212 \u2212 \u2212 \u2212 \u2212 \u2212 \u2212 \u221a . (9.26) (9.27) Using each of these two energies separately in Eqs. (9.18) and (9.19), we have the amplitudes for the two stationary states (the states of definite energy). If there are no external disturbances, a system initially in one of these states will stay that way forever\u2014only its phase changes. We can check our results for two special cases. If H 12 = H 21 =0 , we have that E I = H 11 and E II = H 22 . This is certainly correct, because then Eqs. (9.16) and (9.17) are uncoupled, and each represents a state of energy H 11 and H 22 . Next, if we set H 11 = H 22 = E 0 and H 21 = H 12 =\u2212A , we get the solution we found before: E I = E 0 +Aand E II = E 0 \u2212A. E E A and E E A For the general case, the two solutions E I and E II refer to two states\u2014which we can again call the states | \u03c8 I \u27e9=|I\u27e9 e \u2212(i/\u210f) E I t and| \u03c8 II \u27e9=|II\u27e9 e \u2212(i/\u210f) E II t . ( i / \u210f ) E ( i / \u210f ) E These states will have C 1 and C 2 as given in Eqs. (9.18) and (9.19), where a 1 and a 2 are still to be determined. Their ratio is given by either Eq. (9.23) or Eq. (9.24). They must also satisfy one more condition. If the system is known to be in one of the stationary states, the sum of the probabilities that it will be found in |1\u27e9 or |2\u27e9 must equal one. We must have that | C 1 | 2 +| C 2 | 2 =1, (9.28) or, equivalently, | a 1 | 2 +| a 2 | 2 =1. (9.29) These conditions do not uniquely specify a 1 and a 2 ; they are still undetermined by an arbitrary phase\u2014in other words, by a factor like e i\u03b4 . Although general solutions for the a \u2019s can be written down,3 it is usually more convenient to work them out for each special case. Let\u2019s go back now to our particular example of the ammonia molecule in an electric field. Using the values for H 11 , H 22 , and H 12 given in (9.14) and (9.15), we get for the energies of the two stationary states E I E II = E 0 + A 2 + \u03bc 2 E 2 \u2212 \u2212 \u2212 \u2212 \u2212 \u2212 \u2212 \u2212 \u221a , = E 0 \u2212 A 2 + \u03bc 2 E 2 \u2212 \u2212 \u2212 \u2212 \u2212 \u2212 \u2212 \u2212 \u221a . (9.30) These two energies are plotted as a function of the electric field strength E in Fig. 9\u20132. When the electric field is zero, the two energies are, of course, just E 0 \u00b1A . When an electric field is applied, the splitting between the two levels increases. The splitting increases at first slowly with E , but eventually becomes proportional to E . (The curve is a hyperbola.) For enormously strong fields, the energies are just E I E II = E 0 +\u03bcE= H 11 , = E 0 \u2212\u03bcE= H 22 . (9.31) The fact that there is an amplitude for the nitrogen to flip back and forth has little effect when the two positions have very different energies. This is an interesting point which we will come back to again later. We are at last ready to understand the operation of the ammonia maser. The idea is the following. First, we find a way of separating molecules in the state |I\u27e9 from those in the state |II\u27e9 .4 Then the molecules in the higher energy state |I\u27e9 are passed through a cavity which has a resonant frequency of 24,000 megacycles. The molecules can deliver energy to the cavity\u2014in a way we will discuss later\u2014and leave the cavity in the state |II\u27e9 . Each molecule that makes such a transition will deliver the energy E= E I \u2212 E II to the cavity. The energy from the molecules will appear as electrical energy in the cavity. How can we separate the two molecular states? One method is as follows. The ammonia gas is let out of a little jet and passed through a pair of slits to give a narrow beam, as shown in Fig. 9\u20133. The beam is then sent through a region in which there is a large transverse electric field. The electrodes to produce the field are shaped so that the electric field varies rapidly across the beam. Then the square of the electric field E\u22c5E will have a large gradient perpendicular to the beam. Now a molecule in state |I\u27e9 has an energy which increases with E 2 , and therefore this part of the beam will be deflected toward the region of lower E 2 . A molecule in state |II\u27e9 will, on the other hand, be deflected toward the region of larger E 2 , since its energy decreases as E 2 increases. Incidentally, with the electric fields which can be generated in the laboratory, the energy \u03bcE is always much smaller than A . In such cases, the square root in Eqs. (9.30) can be approximated by A(1+ 1 2 \u03bc 2 E 2 A 2 ). (9.32) So the energy levels are, for all practical purposes, E I = E 0 +A+ \u03bc 2 E 2 2A (9.33) and E II = E 0 \u2212A\u2212 \u03bc 2 E 2 2A . (9.34) And the energies vary approximately linearly with E 2 . The force on the molecules is then F= \u03bc 2 2A \u2207 E 2 . (9.35) Many molecules have an energy in an electric field which is proportional to E 2 . The coefficient is the polarizability of the molecule. Ammonia has an unusually high polarizability because of the small value of A in the denominator. Thus, ammonia molecules are unusually sensitive to an electric field. (What would you expect for the dielectric coefficient of NH 3 gas?) In the ammonia maser, the beam with molecules in the state |I\u27e9 and with the energy E I is sent through a resonant cavity, as shown in Fig. 9\u20134. The other beam is discarded. Inside the cavity, there will be a time-varying electric field, so the next problem we must discuss is the behavior of a molecule in an electric field that varies with time. We have a completely different kind of a problem\u2014one with a time-varying Hamiltonian. Since H ij depends upon E , the H ij vary with time, and we must determine the behavior of the system in this circumstance. To begin with, we write down the equations to be solved: i\u210f d C 1 dt i\u210f d C 2 dt =( E 0 +\u03bcE) C 1 \u2212A C 2 , =\u2212A C 1 +( E 0 \u2212\u03bcE) C 2 . (9.36) To be definite, let\u2019s suppose that the electric field varies sinusoidally; then we can write E=2 E 0 cos\u03c9t= E 0 ( e i\u03c9t + e \u2212i\u03c9t ). (9.37) In actual operation the frequency \u03c9 will be very nearly equal to the resonant frequency of the molecular transition \u03c9 0 =2A/\u210f , but for the time being we want to keep things general, so we\u2019ll let it have any value at all. The best way to solve our equations is to form linear combinations of C 1 and C 2 as we did before. So we add the two equations, divide by the square root of 2 , and use the definitions of C I and C II that we had in Eq. (9.13). We get i\u210f d C II dt =( E 0 \u2212A) C II +\u03bcE C I . (9.38) You\u2019ll note that this is the same as Eq. (9.9) with an extra term due to the electric field. Similarly, if we subtract the two equations (9.36), we get i\u210f d C I dt =( E 0 +A) C I +\u03bcE C II . (9.39) Now the question is, how to solve these equations? They are more difficult than our earlier set, because E depends on t ; and, in fact, for a general E(t) the solution is not expressible in elementary functions. However, we can get a good approximation so long as the electric field is small. First we will write C I = \u03b3 I e \u2212i( E 0 +A)t/\u210f = \u03b3 I e \u2212i( E I )t/\u210f , C II = \u03b3 II e \u2212i( E 0 \u2212A)t/\u210f = \u03b3 II e \u2212i( E II )t/\u210f . (9.40) If there were no electric field, these solutions would be correct with \u03b3 I and \u03b3 II just chosen as two complex constants. In fact, since the probability of being in state |I\u27e9 is the absolute square of C I and the probability of being in state |II\u27e9 is the absolute square of C II , the probability of being in state |I\u27e9 or in state |II\u27e9 is just | \u03b3 I | 2 or | \u03b3 II | 2 . For instance, if the system were to start originally in state |II\u27e9 so that \u03b3 I was zero and | \u03b3 II | 2 was one, this condition would go on forever. There would be no chance, if the molecule were originally in state |II\u27e9 , ever to get into state |I\u27e9 . Now the idea of writing our equations in the form of Eq. (9.40) is that if \u03bcE is small in comparison with A , the solutions can still be written in this way, but then \u03b3 I and \u03b3 II become slowly varying functions of time\u2014where by \u201cslowly varying\u201d we mean slowly in comparison with the exponential functions. That is the trick. We use the fact that \u03b3 I and \u03b3 II vary slowly to get an approximate solution. We want now to substitute C I from Eq. (9.40) in the differential equation (9.39), but we must remember that \u03b3 I is also a function of t . We have i\u210f d C I dt = E I \u03b3 I e \u2212i E I t/\u210f +i\u210f d \u03b3 I dt e \u2212i E I t/\u210f . d The differential equation becomes ( E I \u03b3 I +i\u210f d \u03b3 I dt ) e \u2212(i/\u210f) E I t = E I \u03b3 I e \u2212(i/\u210f) E I t +\u03bcE \u03b3 II e \u2212(i/\u210f) E II t . (9.41) Similarly, the equation in d C II /dt becomes ( E II \u03b3 II +i\u210f d \u03b3 II dt ) e \u2212(i/\u210f) E II t = E II \u03b3 II e \u2212(i/\u210f) E II t +\u03bcE \u03b3 I e \u2212(i/\u210f) E I t . (9.42) Now you will notice that we have equal terms on both sides of each equation. We cancel these terms, and we also multiply the first equation by e +i E I t/\u210f and the second by e +i E II t/\u210f . Remembering that ( E I \u2212 E II )= 2A= \u210f \u03c9 0 , we have finally, i\u210f d \u03b3 I dt i\u210f d \u03b3 II dt =\u03bcE(t) e i \u03c9 0 t \u03b3 II , =\u03bcE(t) e \u2212i \u03c9 0 t \u03b3 I . (9.43) Now we have an apparently simple pair of equations\u2014and they are still exact, of course. The derivative of one variable is a function of time \u03bcE(t) e i \u03c9 0 t , multiplied by the second variable; the derivative of the second is a similar time function, multiplied by the first. Although these simple equations cannot be solved in general, we will solve them for some special cases. We are, for the moment at least, interested only in the case of an oscillating electric field. Taking E(t) as given in Eq. (9.37), we find that the equations for \u03b3 I and \u03b3 II become i\u210f d \u03b3 I dt i\u210f d \u03b3 II dt =\u03bc E 0 [ e i(\u03c9+ \u03c9 0 )t + e \u2212i(\u03c9\u2212 \u03c9 0 )t ] \u03b3 II , =\u03bc E 0 [ e i(\u03c9\u2212 \u03c9 0 )t + e \u2212i(\u03c9+ \u03c9 0 )t ] \u03b3 I . (9.44) Now if E 0 is sufficiently small, the rates of change of \u03b3 I and \u03b3 II are also small. The two \u03b3 \u2019s will not vary much with t , especially in comparison with the rapid variations due to the exponential terms. These exponential terms have real and imaginary parts that oscillate at the frequency \u03c9+ \u03c9 0 or \u03c9\u2212 \u03c9 0 . The terms with \u03c9+ \u03c9 0 oscillate very rapidly about an average value of zero and, therefore, do not contribute very much on the average to the rate of change of \u03b3 . So we can make a reasonably good approximation by replacing these terms by their average value, namely, zero. We will just leave them out, and take as our approximation: i\u210f d \u03b3 I dt i\u210f d \u03b3 II dt =\u03bc E 0 e \u2212i(\u03c9\u2212 \u03c9 0 )t \u03b3 II , =\u03bc E 0 e i(\u03c9\u2212 \u03c9 0 )t \u03b3 I . (9.45) Even the remaining terms, with exponents proportional to (\u03c9\u2212 \u03c9 0 ) , will also vary rapidly unless \u03c9 is near \u03c9 0 . Only then will the right-hand side vary slowly enough that any appreciable amount will accumulate when we integrate the equations with respect to t . In other words, with a weak electric field the only significant frequencies are those near \u03c9 0 . With the approximation made in getting Eq. (9.45), the equations can be solved exactly, but the work is a little elaborate, so we won\u2019t do that until later when we take up another problem of the same type. Now we\u2019ll just solve them approximately\u2014or rather, we\u2019ll find an exact solution for the case of perfect resonance, \u03c9= \u03c9 0 , and an approximate solution for frequencies near resonance. Let\u2019s take the case of perfect resonance first. If we take \u03c9= \u03c9 0 , the exponentials are equal to one in both equations of (9.45), and we have just d \u03b3 I dt =\u2212 i\u03bc E 0 \u210f \u03b3 II , d \u03b3 II dt =\u2212 i\u03bc E 0 \u210f \u03b3 I . (9.46) If we eliminate first \u03b3 I and then \u03b3 II from these equations, we find that each satisfies the differential equation of simple harmonic motion: d 2 \u03b3 d t 2 =\u2212( \u03bc E 0 \u210f ) 2 \u03b3. (9.47) The general solutions for these equations can be made up of sines and cosines. As you can easily verify, the following equations are a solution: \u03b3 I \u03b3 II =acos( \u03bc E 0 \u210f )t+bsin( \u03bc E 0 \u210f )t, =ibcos( \u03bc E 0 \u210f )t\u2212iasin( \u03bc E 0 \u210f )t, (9.48) where a and b are constants to be determined to fit any particular physical situation. For instance, suppose that at t=0 our molecular system was in the upper energy state |I\u27e9 , which would require\u2014from Eq. (9.40)\u2014that \u03b3 I =1 and \u03b3 II =0 at t=0 . For this situation we would need a=1 and b=0 . The probability that the molecule is in the state |I\u27e9 at some later t is the absolute square of \u03b3 I , or P I =| \u03b3 I | 2 = cos 2 ( \u03bc E 0 \u210f )t. (9.49) Similarly, the probability that the molecule will be in the state |II\u27e9 is given by the absolute square of \u03b3 II , P II =| \u03b3 II | 2 = sin 2 ( \u03bc E 0 \u210f )t. (9.50) So long as E is small and we are on resonance, the probabilities are given by simple oscillating functions. The probability to be in state |I\u27e9 falls from one to zero and back again, while the probability to be in the state |II\u27e9 rises from zero to one and back. The time variation of the two probabilities is shown in Fig. 9\u20135. Needless to say, the sum of the two probabilities is always equal to one; the molecule is always in some state! Let\u2019s suppose that it takes the molecule the time T to go through the cavity. If we make the cavity just long enough so that \u03bc E 0 T/\u210f=\u03c0/2 , then a molecule which enters in state |I\u27e9 will certainly leave it in state |II\u27e9 . If it enters the cavity in the upper state, it will leave the cavity in the lower state. In other words, its energy is decreased, and the loss of energy can\u2019t go anywhere else but into the machinery which generates the field. The details by which you can see how the energy of the molecule is fed into the oscillations of the cavity are not simple; however, we don\u2019t need to study these details, because we can use the principle of conservation of energy. (We could study them if we had to, but then we would have to deal with the quantum mechanics of the field in the cavity in addition to the quantum mechanics of the atom.) In summary: the molecule enters the cavity, the cavity field\u2014oscillating at exactly the right frequency\u2014induces transitions from the upper to the lower state, and the energy released is fed into the oscillating field. In an operating maser the molecules deliver enough energy to maintain the cavity oscillations\u2014not only providing enough power to make up for the cavity losses but even providing small amounts of excess power that can be drawn from the cavity. Thus, the molecular energy is converted into the energy of an external electromagnetic field. Remember that before the beam enters the cavity, we have to use a filter which separates the beam so that only the upper state enters. It is easy to demonstrate that if you were to start with molecules in the lower state, the process will go the other way and take energy out of the cavity. If you put the unfiltered beam in, as many molecules are taking energy out as are putting energy in, so nothing much would happen. In actual operation it isn\u2019t necessary, of course, to make (\u03bc E 0 T/\u210f) exactly \u03c0/2 . For any other value (except an exact integral multiple of \u03c0 ), there is some probability for transitions from state |I\u27e9 to state |II\u27e9 . For other values, however, the device isn\u2019t 100 percent efficient; many of the molecules which leave the cavity could have delivered some energy to the cavity but didn\u2019t. In actual use, the velocity of all the molecules is not the same; they have some kind of Maxwell distribution. This means that the ideal periods of time for different molecules will be different, and it is impossible to get 100 percent efficiency for all the molecules at once. In addition, there is another complication which is easy to take into account, but we don\u2019t want to bother with it at this stage. You remember that the electric field in a cavity usually varies from place to place across the cavity. Thus, as the molecules drift across the cavity, the electric field at the molecule varies in a way that is more complicated than the simple sinusoidal oscillation in time that we have assumed. Clearly, one would have to use a more complicated integration to do the problem exactly, but the general idea is still the same. There are other ways of making masers. Instead of separating the atoms in state |I\u27e9 from those in state |II\u27e9 by a Stern-Gerlach apparatus, one can have the atoms already in the cavity (as a gas or a solid) and shift atoms from state |II\u27e9 to state |I\u27e9 by some means. One way is one used in the so-called three-state maser. For it, atomic systems are used which have three energy levels, as shown in Fig. 9\u20136, with the following special properties. The system will absorb radiation (say, light) of frequency \u210f \u03c9 1 and go from the lowest energy level E II , to some high-energy level E \u2032 , and then will quickly emit photons of frequency \u210f \u03c9 2 and go to the state |I\u27e9 with energy E I . The state |I\u27e9 has a long lifetime so its population can be raised, and the conditions are then appropriate for maser operation between states |I\u27e9 and |II\u27e9 . Although such a device is called a \u201cthree-state\u201d maser, the maser operation really works just as a two-state system such as we are describing. A laser (Light Amplification by Stimulated Emission of Radiation) is just a maser working at optical frequencies. The \u201ccavity\u201d for a laser usually consists of just two plane mirrors between which standing waves are generated. Finally, we would like to find out how the states vary in the circumstance that the cavity frequency is nearly, but not exactly, equal to \u03c9 0 . We could solve this problem exactly, but instead of trying to do that, we\u2019ll take the important case that the electric field is small and also the period of time T is small, so that \u03bc E 0 T/\u210f is much less than one. Then, even in the case of perfect resonance which we have just worked out, the probability of making a transition is small. Suppose that we start again with \u03b3 I =1 and \u03b3 II =0 . During the time T we would expect \u03b3 I to remain nearly equal to one, and \u03b3 II to remain very small compared with unity. Then the problem is very easy. We can calculate \u03b3 II from the second equation in (9.45), taking \u03b3 I equal to one and integrating from t=0 to t=T . We get \u03b3 II = \u03bc E 0 \u210f [ 1\u2212 e i(\u03c9\u2212 \u03c9 0 )T \u03c9\u2212 \u03c9 0 ]. (9.51) This \u03b3 II , used with Eq. (9.40), gives the amplitude to have made a transition from the state |I\u27e9 to the state |II\u27e9 during the time interval T . The probability P(I\u2192II) to make the transition is | \u03b3 II | 2 , or P(I\u2192II)=| \u03b3 II | 2 =[ \u03bc E 0 T \u210f ] 2 sin 2 [(\u03c9\u2212 \u03c9 0 )T/2] [(\u03c9\u2212 \u03c9 0 )T/2 ] 2 . (9.52) It is interesting to plot this probability for a fixed length of time as a function of the frequency of the cavity in order to see how sensitive it is to frequencies near the resonant frequency \u03c9 0 . We show such a plot of P(I\u2192II) in Fig. 9\u20137. (The vertical scale has been adjusted to be 1 at the peak by dividing by the value of the probability when \u03c9= \u03c9 0 .) We have seen a curve like this in the diffraction theory, so you should already be familiar with it. The curve falls rather abruptly to zero for (\u03c9\u2212 \u03c9 0 )=2\u03c0/T and never regains significant size for large frequency deviations. In fact, by far the greatest part of the area under the curve lies within the range \u00b1\u03c0/T . It is possible to show5 that the area under the curve is just 2\u03c0/T and is equal to the area of the shaded rectangle drawn in the figure. Let\u2019s examine the implication of our results for a real maser. Suppose that the ammonia molecule is in the cavity for a reasonable length of time, say for one millisecond. Then for f 0 =24,000 megacycles, we can calculate that the probability for a transition falls to zero for a frequency deviation of (f\u2212 f 0 )/ f 0 =1/ f 0 T , which is four parts in 10 8 . Evidently the frequency must be very close to \u03c9 0 to get a significant transition probability. Such an effect is the basis of the great precision that can be obtained with \u201catomic\u201d clocks, which work on the maser principle. Our treatment above applies to a more general situation than the ammonia maser. We have treated the behavior of a molecule under the influence of an electric field, whether that field was confined in a cavity or not. So we could be simply shining a beam of \u201clight\u201d\u2014at microwave frequencies\u2014at the molecule and ask for the probability of emission or absorption. Our equations apply equally well to this case, but let\u2019s rewrite them in terms of the intensity of the radiation rather than the electric field. If we define the intensity I to be the average energy flow per unit area per second, then from Chapter 27 of Volume II, we can write I= \u03f5 0 c 2 |E\u00d7B | ave = 1 2 \u03f5 0 c 2 |E\u00d7B | max =2 \u03f5 0 c E 2 0 . 1 (The maximum value of E is 2 E 0 .) The transition probability now becomes: P(I\u2192II)= 2\u03c0[ \u03bc 2 4\u03c0 \u03f5 0 \u210f 2 c ]I T 2 sin 2 [(\u03c9\u2212 \u03c9 0 )T/2] [(\u03c9\u2212 \u03c9 0 )T/2 ] 2 . (9.53) Ordinarily the light shining on such a system is not exactly monochromatic. It is, therefore, interesting to solve one more problem\u2014that is, to calculate the transition probability when the light has intensity I(\u03c9) per unit frequency interval, covering a broad range which includes \u03c9 0 . Then, the probability of going from |I\u27e9 to |II\u27e9 will become an integral: P(I\u2192II)= 2\u03c0[ \u03bc 2 4\u03c0 \u03f5 0 \u210f 2 c ] T 2 \u222b \u221e 0 I(\u03c9) sin 2 [(\u03c9\u2212 \u03c9 0 )T/2] [(\u03c9\u2212 \u03c9 0 )T/2 ] 2 d\u03c9. (9.54) In general, I(\u03c9) will vary much more slowly with \u03c9 than the sharp resonance term. The two functions might appear as shown in Fig. 9\u20138. In such cases, we can replace I(\u03c9) by its value I( \u03c9 0 ) at the center of the sharp resonance curve and take it outside of the integral. What remains is just the integral under the curve of Fig. 9\u20137, which is, as we have seen, just equal to 2\u03c0/T . We get the result that P(I\u2192II)=4 \u03c0 2 [ \u03bc 2 4\u03c0 \u03f5 0 \u210f 2 c ]I( \u03c9 0 )T. (9.55) This is an important result, because it is the general theory of the absorption of light by any molecular or atomic system. Although we began by considering a case in which state |I\u27e9 had a higher energy than state |II\u27e9 , none of our arguments depended on that fact. Equation (9.55) still holds if the state |I\u27e9 has a lower energy than the state |II\u27e9 ; then P(I\u2192II) represents the probability for a transition with the absorption of energy from the incident electromagnetic wave. The absorption of light by any atomic system always involves the amplitude for a transition in an oscillating electric field between two states separated by an energy E=\u210f \u03c9 0 . For any particular case, it is always worked out in just the way we have done here and gives an expression like Eq. (9.55). We, therefore, emphasize the following features of this result. First, the probability is proportional to T . In other words, there is a constant probability per unit time that transitions will occur. Second, this probability is proportional to the intensity of the light incident on the system. Finally, the transition probability is proportional to \u03bc 2 , where, you remember, \u03bcE defined the shift in energy due to the electric field E . Because of this, \u03bcE also appeared in Eqs. (9.38) and (9.39) as the coupling term that is responsible for the transition between the otherwise stationary states |I\u27e9 and |II\u27e9 . In other words, for the small E we have been considering, \u03bcE is the so-called \u201cperturbation term\u201d in the Hamiltonian matrix element which connects the states |I\u27e9 and |II\u27e9 . In the general case, we would have that \u03bcE gets replaced by the matrix element \u27e8II|H|I\u27e9 (see Section 5\u20136). In Volume I (Section 42\u20135) we talked about the relations among light absorption, induced emission, and spontaneous emission in terms of the Einstein A - and B -coefficients. Here, we have at last the quantum mechanical procedure for computing these coefficients. What we have called P(I\u2192II) for our two-state ammonia molecule corresponds precisely to the absorption coefficient B nm of the Einstein radiation theory. For the complicated ammonia molecule\u2014which is too difficult for anyone to calculate\u2014we have taken the matrix element \u27e8II|H|I\u27e9 as \u03bcE , saying that \u03bc is to be gotten from experiment. For simpler atomic systems, the \u03bc mn which belongs to any particular transition can be calculated from the definition \u03bc mn E=\u27e8m|H|n\u27e9= H mn , (9.56) where H mn is the matrix element of the Hamiltonian which includes the effects of a weak electric field. The \u03bc mn calculated in this way is called the electric dipole matrix element. The quantum mechanical theory of the absorption and emission of light is, therefore, reduced to a calculation of these matrix elements for particular atomic systems. Our study of a simple two-state system has thus led us to an understanding of the general problem of the absorption and emission of light."
    }
]